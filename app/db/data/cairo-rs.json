[
  {
    "pageContent": "use std::fmt::Display;\n\nuse cairo_lang_utils::casts::usize_as_i16;\nuse thiserror::Error;\n\nuse crate::operand::{BinOpOperand, CellRef, DerefOrImmediate, Register, ResOperand};\n\n#[cfg(test)]\n#[path = \"ap_change_test.rs\"]\nmod test;\n\n#[derive(Copy, Clone, Debug, Eq, Hash, PartialEq)]\npub enum ApChange {\n    Known(usize),\n    Unknown,\n}\nimpl Display for ApChange {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            ApChange::Known(change) => write!(f, \"ApChange::Known({change})\"),\n            ApChange::Unknown => write!(f, \"ApChange::Unknown\"),\n        }\n    }\n}\n\n#[derive(Debug, Error, Eq, PartialEq)]\npub enum ApChangeError {\n    #[error(\"Unknown ap change\")]\n    UnknownApChange,\n    #[error(\"Offset overflow\")]\n    OffsetOverflow,\n}\n\n/// Trait for applying ap changes.\npub trait ApplyApChange: Sized {\n    /// Attempts to apply ap change, fail on overflow only.\n    fn apply_known_ap_change(self, ap_change: usize) -> Option<Self>;\n    /// Can unknown ap change be applied.\n    fn can_apply_unknown(&self) -> bool;\n\n    /// Attempts to apply ap change.\n    fn apply_ap_change(self, ap_change: ApChange) -> Result<Self, ApChangeError> {\n        match ap_change {\n            ApChange::Unknown if self.can_apply_unknown() => Ok(self),\n            ApChange::Unknown => Err(ApChangeError::UnknownApChange),\n            ApChange::Known(ap_change) => {\n                self.apply_known_ap_change(ap_change).ok_or(ApChangeError::OffsetOverflow)\n            }\n        }\n    }\n\n    /// Same as [Self::apply_known_ap_change] but unchecked.\n    fn unchecked_apply_known_ap_change(self, ap_change: usize) -> Self {\n        self.apply_known_ap_change(ap_change).unwrap()\n    }\n}\n\nimpl ApplyApChange for ResOperand {\n    fn apply_known_ap_change(self, ap_change: usize) -> Option<Self> {\n        Some(match self {\n            ResOperand::Deref(operand) => {\n                ResOperand::Deref(operand.apply_known_ap_change(ap_change)?)\n            }\n            ResOperand::DoubleDeref(operand, offset) => {\n                ResOperand::DoubleDeref(operand.apply_known_ap_change(ap_change)?, offset)\n            }\n            ResOperand::Immediate(value) => ResOperand::Immediate(value),\n            ResOperand::BinOp(operand) => {\n                ResOperand::BinOp(operand.apply_known_ap_change(ap_change)?)\n            }\n        })\n    }\n\n    fn can_apply_unknown(&self) -> bool {\n        match self {\n            ResOperand::Deref(operand) => operand.can_apply_unknown(),\n            ResOperand::DoubleDeref(operand, ..) => operand.can_apply_unknown(),\n            ResOperand::Immediate(_) => true,\n            ResOperand::BinOp(operand) => operand.can_apply_unknown(),\n        }\n    }\n}\n\nimpl ApplyApChange for CellRef {\n    fn apply_known_ap_change(self, ap_change: usize) -> Option<Self> {\n        Some(match &self.register {\n            Register::AP => CellRef {\n                register: Register::AP,\n                offset: self.offset.checked_sub(usize_as_i16(ap_change))?,\n            },\n            Register::FP => self,\n        })\n    }\n\n    fn can_apply_unknown(&self) -> bool {\n        match &self.register {\n            Register::AP => false,\n            Register::FP => true,\n        }\n    }\n}\n\nimpl ApplyApChange for DerefOrImmediate {\n    fn apply_known_ap_change(self, ap_change: usize) -> Option<Self> {\n        Some(match self {\n            DerefOrImmediate::Deref(operand) => {\n                DerefOrImmediate::Deref(operand.apply_known_ap_change(ap_change)?)\n            }\n            DerefOrImmediate::Immediate(operand) => DerefOrImmediate::Immediate(operand),\n        })\n    }\n\n    fn can_apply_unknown(&self) -> bool {\n        match self {\n            DerefOrImmediate::Deref(operand) => operand.can_apply_unknown(),\n            DerefOrImmediate::Immediate(_) => true,\n        }\n    }\n}\n\nimpl ApplyApChange for BinOpOperand {\n    fn apply_known_ap_change(self, ap_change: usize) -> Option<Self> {\n        Some(BinOpOperand {\n            op: self.op,\n            a: self.a.apply_known_ap_change(ap_change)?,\n            b: self.b.apply_known_ap_change(ap_change)?,\n        })\n    }\n\n    fn can_apply_unknown(&self) -> bool {\n        self.a.can_apply_unknown() && self.b.can_apply_unknown()\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use test_log::test;\n\nuse super::{BinOpOperand, DerefOrImmediate};\nuse crate::ap_change::{ApChange, ApChangeError, ApplyApChange};\nuse crate::operand::{CellRef, Operation, Register, ResOperand};\n\n#[test]\nfn test_res_operand_ap_change() {\n    let fp_based_operand = CellRef { register: Register::FP, offset: -3 };\n    let ap_based_operand = CellRef { register: Register::AP, offset: 3 };\n\n    let operand = ResOperand::BinOp(BinOpOperand {\n        op: Operation::Mul,\n        a: fp_based_operand,\n        b: DerefOrImmediate::Deref(ap_based_operand),\n    });\n\n    assert_eq!(\n        operand.clone().apply_ap_change(ApChange::Known(5)).unwrap().to_string(),\n        \"[fp + -3] * [ap + -2]\"\n    );\n\n    assert_eq!(operand.apply_ap_change(ApChange::Unknown), Err(ApChangeError::UnknownApChange));\n\n    assert_eq!(fp_based_operand.apply_ap_change(ApChange::Unknown).unwrap(), fp_based_operand);\n}\n\n#[test]\nfn test_overflow() {\n    let ap_based_operand = CellRef { register: Register::AP, offset: i16::MIN };\n\n    assert_eq!(\n        ap_based_operand.apply_ap_change(ApChange::Known(1)),\n        Err(ApChangeError::OffsetOverflow)\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use num_bigint::{BigInt, ToBigInt};\n\nuse crate::instructions::{Instruction, InstructionBody};\nuse crate::operand::{DerefOrImmediate, Operation, Register, ResOperand};\n\n#[cfg(test)]\n#[path = \"assembler_test.rs\"]\nmod test;\n\n/// Cairo instruction structure flags.\n#[derive(Debug, Eq, PartialEq)]\npub enum Op1Addr {\n    Imm,\n    AP,\n    FP,\n    Op0,\n}\n#[derive(Debug, Eq, PartialEq)]\npub enum Res {\n    Op1,\n    Add,\n    Mul,\n    Unconstrained,\n}\n#[derive(Debug, Eq, PartialEq)]\npub enum PcUpdate {\n    Regular,\n    Jump,\n    JumpRel,\n    Jnz,\n}\n\n#[derive(Debug, Eq, PartialEq)]\npub enum ApUpdate {\n    Regular,\n    Add,\n    Add1,\n    Add2,\n}\n\n#[derive(Debug, Eq, PartialEq)]\npub enum FpUpdate {\n    Regular,\n    ApPlus2,\n    Dst,\n}\n\n#[derive(Debug, Eq, PartialEq)]\npub enum Opcode {\n    Nop,\n    AssertEq,\n    Call,\n    Ret,\n}\n\n/// The low level representation of a cairo instruction.\n#[allow(dead_code)]\n#[derive(Debug, Eq, PartialEq)]\npub struct InstructionRepr {\n    pub off0: i16,\n    pub off1: i16,\n    pub off2: i16,\n    pub imm: Option<BigInt>,\n    pub dst_register: Register,\n    pub op0_register: Register,\n    pub op1_addr: Op1Addr,\n    pub res: Res,\n    pub pc_update: PcUpdate,\n    pub ap_update: ApUpdate,\n    pub fp_update: FpUpdate,\n    pub opcode: Opcode,\n}\n\nimpl Instruction {\n    pub fn assemble(&self) -> InstructionRepr {\n        match &self.body {\n            InstructionBody::AddAp(insn) => {\n                assert!(!self.inc_ap, \"An add_ap instruction cannot have an ap++.\");\n                let res = insn.operand.to_res_description();\n                InstructionRepr {\n                    off0: -1,\n                    off1: res.off1,\n                    off2: res.off2,\n                    imm: res.imm,\n                    dst_register: Register::FP,\n                    op0_register: res.op0_register,\n                    op1_addr: res.op1_addr,\n                    res: res.res,\n                    pc_update: PcUpdate::Regular,\n                    ap_update: ApUpdate::Add,\n                    fp_update: FpUpdate::Regular,\n                    opcode: Opcode::Nop,\n                }\n            }\n            InstructionBody::AssertEq(insn) => {\n                let res = insn.b.to_res_description();\n                InstructionRepr {\n                    off0: insn.a.offset,\n                    off1: res.off1,\n                    off2: res.off2,\n                    imm: res.imm,\n                    dst_register: insn.a.register,\n                    op0_register: res.op0_register,\n                    op1_addr: res.op1_addr,\n                    res: res.res,\n                    pc_update: PcUpdate::Regular,\n                    ap_update: if self.inc_ap { ApUpdate::Add1 } else { ApUpdate::Regular },\n                    fp_update: FpUpdate::Regular,\n                    opcode: Opcode::AssertEq,\n                }\n            }\n            InstructionBody::Call(insn) => {\n                assert!(!self.inc_ap, \"A call instruction cannot have an ap++.\");\n                let res = insn.target.to_res_description();\n                InstructionRepr {\n                    off0: 0,\n                    off1: 1,\n                    off2: res.off2,\n                    imm: res.imm,\n                    dst_register: Register::AP,\n                    op0_register: Register::AP,\n                    op1_addr: res.op1_addr,\n                    res: Res::Op1,\n                    pc_update: if insn.relative { PcUpdate::JumpRel } else { PcUpdate::Jump },\n                    ap_update: ApUpdate::Add2,\n                    fp_update: FpUpdate::ApPlus2,\n                    opcode: Opcode::Call,\n                }\n            }\n            InstructionBody::Jump(insn) => {\n                let res = insn.target.to_res_description();\n                InstructionRepr {\n                    off0: -1,\n                    off1: res.off1,\n                    off2: res.off2,\n                    imm: res.imm,\n                    dst_register: Register::FP,\n                    op0_register: Register::FP,\n                    op1_addr: res.op1_addr,\n                    res: Res::Op1,\n                    pc_update: if insn.relative { PcUpdate::JumpRel } else { PcUpdate::Jump },\n                    ap_update: if self.inc_ap { ApUpdate::Add1 } else { ApUpdate::Regular },\n                    fp_update: FpUpdate::Regular,\n                    opcode: Opcode::Nop,\n                }\n            }\n            InstructionBody::Jnz(insn) => {\n                let res = insn.jump_offset.to_res_description();\n                InstructionRepr {\n                    off0: insn.condition.offset,\n                    off1: -1,\n                    off2: res.off2,\n                    imm: res.imm,\n                    dst_register: insn.condition.register,\n                    op0_register: Register::FP,\n                    op1_addr: res.op1_addr,\n                    res: Res::Unconstrained,\n                    pc_update: PcUpdate::Jnz,\n                    ap_update: if self.inc_ap { ApUpdate::Add1 } else { ApUpdate::Regular },\n                    fp_update: FpUpdate::Regular,\n                    opcode: Opcode::Nop,\n                }\n            }\n            InstructionBody::Ret(_) => {\n                assert!(!self.inc_ap);\n                InstructionRepr {\n                    off0: -2,\n                    off1: -1,\n                    off2: -1,\n                    imm: None,\n                    dst_register: Register::FP,\n                    op0_register: Register::FP,\n                    op1_addr: Op1Addr::FP,\n                    res: Res::Op1,\n                    pc_update: PcUpdate::Jump,\n                    ap_update: ApUpdate::Regular,\n                    fp_update: FpUpdate::Dst,\n                    opcode: Opcode::Ret,\n                }\n            }\n        }\n    }\n}\n\nimpl Register {\n    fn to_op1_addr(self) -> Op1Addr {\n        match self {\n            Register::AP => Op1Addr::AP,\n            Register::FP => Op1Addr::FP,\n        }\n    }\n}\n\nimpl Operation {\n    fn to_res(&self) -> Res {\n        match self {\n            Operation::Add => Res::Add,\n            Operation::Mul => Res::Mul,\n        }\n    }\n}\n\nimpl DerefOrImmediate {\n    fn to_res_operand(&self) -> ResOperand {\n        match self {\n            DerefOrImmediate::Deref(operand) => ResOperand::Deref(*operand),\n            DerefOrImmediate::Immediate(operand) => ResOperand::Immediate(operand.clone()),\n        }\n    }\n    fn to_res_description(&self) -> ResDescription {\n        self.to_res_operand().to_res_description()\n    }\n}\n\n/// The part of the instruction describing the res operand.\nstruct ResDescription {\n    off1: i16,\n    off2: i16,\n    imm: Option<BigInt>,\n    op0_register: Register,\n    op1_addr: Op1Addr,\n    res: Res,\n}\n\nimpl ResOperand {\n    fn to_res_description(&self) -> ResDescription {\n        match self {\n            ResOperand::Deref(operand) => ResDescription {\n                off1: -1,\n                off2: operand.offset,\n                imm: None,\n                op0_register: Register::FP,\n                op1_addr: operand.register.to_op1_addr(),\n                res: Res::Op1,\n            },\n            ResOperand::DoubleDeref(operand, offset) => ResDescription {\n                off1: operand.offset,\n                off2: *offset,\n                imm: None,\n                op0_register: operand.register,\n                op1_addr: Op1Addr::Op0,\n                res: Res::Op1,\n            },\n            ResOperand::Immediate(operand) => ResDescription {\n                off1: -1,\n                off2: 1,\n                // TODO(alon): Change immediate to always work with bigint.\n                imm: operand.value.to_bigint(),\n                op0_register: Register::FP,\n                op1_addr: Op1Addr::Imm,\n                res: Res::Op1,\n            },\n            ResOperand::BinOp(operand) => {\n                let a_res = ResOperand::Deref(operand.a).to_res_description();\n                let b_res = operand.b.to_res_description();\n                ResDescription {\n                    off1: a_res.off2,\n                    off2: b_res.off2,\n                    imm: b_res.imm,\n                    op0_register: operand.a.register,\n                    op1_addr: match operand.b {\n                        DerefOrImmediate::Immediate(_) => Op1Addr::Imm,\n                        DerefOrImmediate::Deref(b) => b.register.to_op1_addr(),\n                    },\n                    res: operand.op.to_res(),\n                }\n            }\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use num_bigint::ToBigInt;\nuse pretty_assertions::assert_eq;\nuse test_log::test;\n\nuse super::InstructionRepr;\nuse crate::assembler::{ApUpdate, FpUpdate, Op1Addr, Opcode, PcUpdate, Res};\nuse crate::casm;\nuse crate::inline::CasmContext;\nuse crate::operand::Register;\n\n/// Takes a casm instruction, which can be constructed using the macro casm!, and\n/// returns its assembled representation.\nfn assemble_instruction(mut casm: CasmContext) -> InstructionRepr {\n    casm.instructions.remove(0).assemble()\n}\n\n#[test]\nfn test_jump_assemble() {\n    assert_eq!(\n        assemble_instruction(casm!(jmp abs 3;)),\n        InstructionRepr {\n            off0: -1,\n            off1: -1,\n            off2: 1,\n            imm: 3.to_bigint(),\n            dst_register: Register::FP,\n            op0_register: Register::FP,\n            op1_addr: Op1Addr::Imm,\n            res: Res::Op1,\n            pc_update: PcUpdate::Jump,\n            ap_update: ApUpdate::Regular,\n            fp_update: FpUpdate::Regular,\n            opcode: Opcode::Nop,\n        },\n    );\n\n    assert_eq!(\n        assemble_instruction(casm!(jmp rel -5, ap++;)),\n        InstructionRepr {\n            off0: -1,\n            off1: -1,\n            off2: 1,\n            imm: (-5).to_bigint(),\n            dst_register: Register::FP,\n            op0_register: Register::FP,\n            op1_addr: Op1Addr::Imm,\n            res: Res::Op1,\n            pc_update: PcUpdate::JumpRel,\n            ap_update: ApUpdate::Add1,\n            fp_update: FpUpdate::Regular,\n            opcode: Opcode::Nop,\n        },\n    );\n}\n\n#[test]\nfn test_call_assemble() {\n    assert_eq!(\n        assemble_instruction(casm!(call abs 3;)),\n        InstructionRepr {\n            off0: 0,\n            off1: 1,\n            off2: 1,\n            imm: 3.to_bigint(),\n            dst_register: Register::AP,\n            op0_register: Register::AP,\n            op1_addr: Op1Addr::Imm,\n            res: Res::Op1,\n            pc_update: PcUpdate::Jump,\n            ap_update: ApUpdate::Add2,\n            fp_update: FpUpdate::ApPlus2,\n            opcode: Opcode::Call,\n        },\n    );\n    assert_eq!(\n        assemble_instruction(casm!(call rel (-5);)),\n        InstructionRepr {\n            off0: 0,\n            off1: 1,\n            off2: 1,\n            imm: (-5).to_bigint(),\n            dst_register: Register::AP,\n            op0_register: Register::AP,\n            op1_addr: Op1Addr::Imm,\n            res: Res::Op1,\n            pc_update: PcUpdate::JumpRel,\n            ap_update: ApUpdate::Add2,\n            fp_update: FpUpdate::ApPlus2,\n            opcode: Opcode::Call,\n        },\n    );\n}\n\n#[test]\nfn test_jnz_assemble() {\n    assert_eq!(\n        assemble_instruction(casm!(jmp rel 205 if [ap + 5] != 0;)),\n        InstructionRepr {\n            off0: 5,\n            off1: -1,\n            off2: 1,\n            imm: 205.to_bigint(),\n            dst_register: Register::AP,\n            op0_register: Register::FP,\n            op1_addr: Op1Addr::Imm,\n            res: Res::Unconstrained,\n            pc_update: PcUpdate::Jnz,\n            ap_update: ApUpdate::Regular,\n            fp_update: FpUpdate::Regular,\n            opcode: Opcode::Nop,\n        },\n    );\n    assert_eq!(\n        assemble_instruction(casm!(jmp rel 2 if [ap - 2] != 0, ap++;)),\n        InstructionRepr {\n            off0: -2,\n            off1: -1,\n            off2: 1,\n            imm: 2.to_bigint(),\n            dst_register: Register::AP,\n            op0_register: Register::FP,\n            op1_addr: Op1Addr::Imm,\n            res: Res::Unconstrained,\n            pc_update: PcUpdate::Jnz,\n            ap_update: ApUpdate::Add1,\n            fp_update: FpUpdate::Regular,\n            opcode: Opcode::Nop,\n        },\n    );\n}\n\n#[test]\nfn test_assert_eq_assemble() {\n    assert_eq!(\n        assemble_instruction(casm!([ap + 5] = 205;)),\n        InstructionRepr {\n            off0: 5,\n            off1: -1,\n            off2: 1,\n            imm: 205.to_bigint(),\n            dst_register: Register::AP,\n            op0_register: Register::FP,\n            op1_addr: Op1Addr::Imm,\n            res: Res::Op1,\n            pc_update: PcUpdate::Regular,\n            ap_update: ApUpdate::Regular,\n            fp_update: FpUpdate::Regular,\n            opcode: Opcode::AssertEq,\n        },\n    );\n\n    assert_eq!(\n        assemble_instruction(casm!([fp] = [ap - 1] + [ap - 2];)),\n        InstructionRepr {\n            off0: 0,\n            off1: -1,\n            off2: -2,\n            imm: None,\n            dst_register: Register::FP,\n            op0_register: Register::AP,\n            op1_addr: Op1Addr::AP,\n            res: Res::Add,\n            pc_update: PcUpdate::Regular,\n            ap_update: ApUpdate::Regular,\n            fp_update: FpUpdate::Regular,\n            opcode: Opcode::AssertEq,\n        },\n    );\n\n    assert_eq!(\n        assemble_instruction(casm!([ap + 0] = [fp + -5], ap++;)),\n        InstructionRepr {\n            off0: 0,\n            off1: -1,\n            off2: -5,\n            imm: None,\n            dst_register: Register::AP,\n            op0_register: Register::FP,\n            op1_addr: Op1Addr::FP,\n            res: Res::Op1,\n            pc_update: PcUpdate::Regular,\n            ap_update: ApUpdate::Add1,\n            fp_update: FpUpdate::Regular,\n            opcode: Opcode::AssertEq,\n        },\n    );\n\n    assert_eq!(\n        assemble_instruction(casm!([ap] = [ap - 3], ap++;)),\n        InstructionRepr {\n            off0: 0,\n            off1: -1,\n            off2: -3,\n            imm: None,\n            dst_register: Register::AP,\n            op0_register: Register::FP,\n            op1_addr: Op1Addr::AP,\n            res: Res::Op1,\n            pc_update: PcUpdate::Regular,\n            ap_update: ApUpdate::Add1,\n            fp_update: FpUpdate::Regular,\n            opcode: Opcode::AssertEq,\n        },\n    );\n}\n\n#[test]\nfn test_ret_assemble() {\n    assert_eq!(\n        assemble_instruction(casm!(ret;)),\n        InstructionRepr {\n            off0: -2,\n            off1: -1,\n            off2: -1,\n            imm: None,\n            dst_register: Register::FP,\n            op0_register: Register::FP,\n            op1_addr: Op1Addr::FP,\n            res: Res::Op1,\n            pc_update: PcUpdate::Jump,\n            ap_update: ApUpdate::Regular,\n            fp_update: FpUpdate::Dst,\n            opcode: Opcode::Ret,\n        },\n    );\n}\n\n#[test]\nfn test_add_ap_assemble() {\n    assert_eq!(\n        assemble_instruction(casm!(ap += 205;)),\n        InstructionRepr {\n            off0: -1,\n            off1: -1,\n            off2: 1,\n            imm: 205.to_bigint(),\n            dst_register: Register::FP,\n            op0_register: Register::FP,\n            op1_addr: Op1Addr::Imm,\n            res: Res::Op1,\n            pc_update: PcUpdate::Regular,\n            ap_update: ApUpdate::Add,\n            fp_update: FpUpdate::Regular,\n            opcode: Opcode::Nop,\n        },\n    );\n}\n\n#[test]\nfn test_instruction_with_hint() {\n    assert_eq!(\n        assemble_instruction(casm!(jmp abs 3;)),\n        InstructionRepr {\n            off0: -1,\n            off1: -1,\n            off2: 1,\n            imm: 3.to_bigint(),\n            dst_register: Register::FP,\n            op0_register: Register::FP,\n            op1_addr: Op1Addr::Imm,\n            res: Res::Op1,\n            pc_update: PcUpdate::Jump,\n            ap_update: ApUpdate::Regular,\n            fp_update: FpUpdate::Regular,\n            opcode: Opcode::Nop,\n        },\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::hash_map::Entry;\nuse std::collections::HashMap;\n\nuse cairo_lang_utils::extract_matches;\nuse num_bigint::BigInt;\nuse num_traits::One;\n\nuse crate::ap_change::ApplyApChange;\nuse crate::cell_expression::{CellExpression, CellOperator};\nuse crate::deref_or_immediate;\nuse crate::hints::Hint;\nuse crate::instructions::{\n    AddApInstruction, AssertEqInstruction, CallInstruction, Instruction, InstructionBody,\n    JnzInstruction, JumpInstruction, RetInstruction,\n};\nuse crate::operand::{BinOpOperand, CellRef, DerefOrImmediate, Operation, Register, ResOperand};\n\n#[cfg(test)]\n#[path = \"builder_test.rs\"]\nmod test;\n\n/// Variables for casm builder, representing a `CellExpression`.\n#[derive(Copy, Clone, Debug, Eq, PartialEq, Hash)]\npub struct Var(usize);\n\n/// The state of the variables at some line.\n#[derive(Clone, Debug, Default, Eq, PartialEq)]\npub struct State {\n    /// The value per variable.\n    vars: HashMap<Var, CellExpression>,\n    /// The number of allocated variables from the beginning of the run.\n    allocated: i16,\n    /// The AP change since the beginning of the run.\n    pub ap_change: usize,\n    /// The number of casm steps since the beginning of the run.\n    pub steps: usize,\n}\nimpl State {\n    /// Returns the value, in relation to the initial ap value.\n    fn get_value(&self, var: Var) -> CellExpression {\n        self.vars[&var].clone()\n    }\n\n    /// Returns the value, in relation to the current ap value.\n    pub fn get_adjusted(&self, var: Var) -> CellExpression {\n        self.get_value(var).unchecked_apply_known_ap_change(self.ap_change)\n    }\n\n    /// Returns the value, assumming it is a direct cell reference.\n    pub fn get_adjusted_as_cell_ref(&self, var: Var) -> CellRef {\n        extract_matches!(self.get_adjusted(var), CellExpression::Deref)\n    }\n\n    /// Validates that the state is valid, as it had enough ap change.\n    fn validate_finality(&self) {\n        assert!(\n            self.ap_change >= self.allocated as usize,\n            \"Not enough commands to update ap, add `add_ap` calls.\"\n        );\n    }\n\n    /// Intersect the states of branches leading to the same label, validating that the states can\n    /// intersect.\n    fn intersect(&mut self, other: &Self) {\n        assert_eq!(self.ap_change, other.ap_change, \"Merged branches not aligned on AP change.\");\n        assert_eq!(\n            self.allocated, other.allocated,\n            \"Merged branches not aligned on number of allocations.\"\n        );\n        self.steps = self.steps.max(other.steps);\n        self.vars.retain(|var, value| {\n            other\n                .vars\n                .get(var)\n                .map(|x| assert_eq!(x, value, \"Var mismatch between branches.\"))\n                .is_some()\n        });\n    }\n}\n\n/// A statement added to the builder.\nenum Statement {\n    /// A final instruction, no need for further editting.\n    Final(Instruction),\n    /// A jump or call command, requires fixing the actual target label.\n    Jump(String, Instruction),\n    /// A target label for jumps.\n    Label(String),\n}\n\n/// The builder result.\npub struct CasmBuildResult<const BRANCH_COUNT: usize> {\n    /// The actual casm code.\n    pub instructions: Vec<Instruction>,\n    /// The state and relocations per branch.\n    pub branches: [(State, Vec<usize>); BRANCH_COUNT],\n}\n\n/// Builder to more easily write casm code without specifically thinking about ap changes and the\n/// sizes of opcodes. Wrong usages of it would panic instead of returning a result, as this builder\n/// assumes we are in a post validation of parameters stage.\npub struct CasmBuilder {\n    /// The state at a point of jumping into a label, per label.\n    label_state: HashMap<String, State>,\n    /// The state at the last added statement.\n    main_state: State,\n    /// The added statements.\n    statements: Vec<Statement>,\n    /// The current set of added hints.\n    current_hints: Vec<Hint>,\n    /// The number of vars created. Used to not reuse var names.\n    var_count: usize,\n    /// Is the current state reachable.\n    /// Example for unreachable state is after a unconditional jump, before any label is stated.\n    reachable: bool,\n}\nimpl CasmBuilder {\n    /// Finalizes the builder, with the requested labels as the returning branches.\n    /// \"Fallthrough\" is a special case for the fallthrough case.\n    pub fn build<const BRANCH_COUNT: usize>(\n        mut self,\n        branch_names: [&str; BRANCH_COUNT],\n    ) -> CasmBuildResult<BRANCH_COUNT> {\n        assert!(\n            self.current_hints.is_empty(),\n            \"Build cannot be called with hints as the last addition.\"\n        );\n        let label_offsets = self.compute_label_offsets();\n        if self.reachable {\n            self.label_state.insert(\"Fallthrough\".to_owned(), self.main_state);\n        }\n        let mut instructions = vec![];\n        let mut branch_relocations = HashMap::<String, Vec<usize>>::default();\n        let mut offset = 0;\n        for statement in self.statements {\n            match statement {\n                Statement::Final(inst) => {\n                    offset += inst.body.op_size();\n                    instructions.push(inst);\n                }\n                Statement::Jump(label, mut inst) => {\n                    match label_offsets.get(&label) {\n                        Some(label_offset) => match &mut inst.body {\n                            InstructionBody::Jnz(JnzInstruction {\n                                jump_offset: DerefOrImmediate::Immediate(value),\n                                ..\n                            })\n                            | InstructionBody::Jump(JumpInstruction {\n                                target: DerefOrImmediate::Immediate(value),\n                                ..\n                            })\n                            | InstructionBody::Call(CallInstruction {\n                                target: DerefOrImmediate::Immediate(value),\n                                ..\n                            }) => {\n                                // Updating the value, instead of assigning into it, to avoid\n                                // allocating a BigInt since it is already 0.\n                                value.value += *label_offset as i128 - offset as i128;\n                            }\n\n                            _ => unreachable!(\"Only jump or call statements should be here.\"),\n                        },\n                        None => match branch_relocations.entry(label) {\n                            Entry::Occupied(mut e) => e.get_mut().push(instructions.len()),\n                            Entry::Vacant(e) => {\n                                e.insert(vec![instructions.len()]);\n                            }\n                        },\n                    }\n                    offset += inst.body.op_size();\n                    instructions.push(inst);\n                }\n                Statement::Label(name) => {\n                    self.label_state.remove(&name);\n                }\n            }\n        }\n        let branches = branch_names.map(|label| {\n            let state = self\n                .label_state\n                .remove(label)\n                .unwrap_or_else(|| panic!(\"Requested a non existing final label: {label:?}.\"));\n            state.validate_finality();\n            (state, branch_relocations.remove(label).unwrap_or_default())\n        });\n        assert!(self.label_state.is_empty(), \"Did not use all branches.\");\n        assert!(branch_relocations.is_empty(), \"Did not use all branch relocations.\");\n        CasmBuildResult { instructions, branches }\n    }\n\n    /// Computes the code offsets of all the labels.\n    fn compute_label_offsets(&self) -> HashMap<String, usize> {\n        let mut label_offsets = HashMap::<String, usize>::default();\n        let mut offset = 0;\n        for statement in &self.statements {\n            match statement {\n                Statement::Final(inst) | Statement::Jump(_, inst) => {\n                    offset += inst.body.op_size();\n                }\n                Statement::Label(name) => {\n                    label_offsets.insert(name.clone(), offset);\n                }\n            }\n        }\n        label_offsets\n    }\n\n    /// Adds a variable pointing to `value`.\n    pub fn add_var(&mut self, value: CellExpression) -> Var {\n        let var = Var(self.var_count);\n        self.var_count += 1;\n        self.main_state.vars.insert(var, value);\n        var\n    }\n\n    /// Allocates a new variable in memory, either local (FP-based) or temp (AP-based).\n    pub fn alloc_var(&mut self, local_var: bool) -> Var {\n        let var = self.add_var(CellExpression::Deref(CellRef {\n            offset: self.main_state.allocated,\n            register: if local_var { Register::FP } else { Register::AP },\n        }));\n        self.main_state.allocated += 1;\n        var\n    }\n\n    /// Returns an additional variable pointing to the same value.\n    pub fn duplicate_var(&mut self, var: Var) -> Var {\n        self.add_var(self.get_value(var, false))\n    }\n\n    /// Adds a hint, generated from `inputs` which are cell refs or immediates and `outputs` which\n    /// must be cell refs.\n    pub fn add_hint<\n        const INPUTS_COUNT: usize,\n        const OUTPUTS_COUNT: usize,\n        F: FnOnce([ResOperand; INPUTS_COUNT], [CellRef; OUTPUTS_COUNT]) -> Hint,\n    >(\n        &mut self,\n        f: F,\n        inputs: [Var; INPUTS_COUNT],\n        outputs: [Var; OUTPUTS_COUNT],\n    ) {\n        self.current_hints.push(f(\n            inputs.map(|v| match self.get_value(v, true) {\n                CellExpression::Deref(cell) => ResOperand::Deref(cell),\n                CellExpression::DoubleDeref(cell, offset) => ResOperand::DoubleDeref(cell, offset),\n                CellExpression::Immediate(imm) => ResOperand::Immediate(imm.into()),\n                CellExpression::BinOp { op, a: other, b } => match op {\n                    CellOperator::Add => {\n                        ResOperand::BinOp(BinOpOperand { op: Operation::Add, a: other, b })\n                    }\n                    CellOperator::Mul => {\n                        ResOperand::BinOp(BinOpOperand { op: Operation::Mul, a: other, b })\n                    }\n                    CellOperator::Sub | CellOperator::Div => {\n                        panic!(\"hints to non ResOperand references are not supported.\")\n                    }\n                },\n            }),\n            outputs.map(|v| self.as_cell_ref(v, true)),\n        ));\n    }\n\n    /// Adds an assertion that `dst = res`.\n    /// `dst` must be a cell reference.\n    pub fn assert_vars_eq(&mut self, dst: Var, res: Var) {\n        let a = self.as_cell_ref(dst, true);\n        let b = self.get_value(res, true);\n        let (a, b) = match b {\n            CellExpression::Deref(cell) => (a, ResOperand::Deref(cell)),\n            CellExpression::DoubleDeref(cell, offset) => (a, ResOperand::DoubleDeref(cell, offset)),\n            CellExpression::Immediate(imm) => (a, imm.into()),\n            CellExpression::BinOp { op, a: other, b } => match op {\n                CellOperator::Add => {\n                    (a, ResOperand::BinOp(BinOpOperand { op: Operation::Add, a: other, b }))\n                }\n                CellOperator::Mul => {\n                    (a, ResOperand::BinOp(BinOpOperand { op: Operation::Mul, a: other, b }))\n                }\n                CellOperator::Sub => {\n                    (other, ResOperand::BinOp(BinOpOperand { op: Operation::Add, a, b }))\n                }\n                CellOperator::Div => {\n                    (other, ResOperand::BinOp(BinOpOperand { op: Operation::Mul, a, b }))\n                }\n            },\n        };\n        let instruction =\n            self.get_instruction(InstructionBody::AssertEq(AssertEqInstruction { a, b }), true);\n        self.statements.push(Statement::Final(instruction));\n    }\n\n    /// Writes and increments a buffer.\n    /// Useful for RangeCheck and similar buffers.\n    /// `buffer` must be a cell reference, or a cell reference with a small added constant.\n    /// `value` must be a cell reference.\n    pub fn buffer_write_and_inc(&mut self, buffer: Var, value: Var) {\n        let (cell, offset) = self.buffer_get_and_inc(buffer);\n        let location = self.add_var(CellExpression::DoubleDeref(cell, offset));\n        self.assert_vars_eq(value, location);\n    }\n\n    /// Increments a buffer and allocates and returns variable pointing to its previous value.\n    pub fn get_ref_and_inc(&mut self, buffer: Var) -> Var {\n        let (cell, offset) = self.as_cell_ref_plus_const(buffer, 0, false);\n        self.main_state.vars.insert(\n            buffer,\n            CellExpression::BinOp {\n                op: CellOperator::Add,\n                a: cell,\n                b: deref_or_immediate!(BigInt::from(offset) + 1),\n            },\n        );\n        self.add_var(CellExpression::DoubleDeref(cell, offset))\n    }\n\n    /// Increments a buffer and returning the previous value it pointed to.\n    /// Useful for writing, reading and referencing values.\n    /// `buffer` must be a cell reference, or a cell reference with a small added constant.\n    fn buffer_get_and_inc(&mut self, buffer: Var) -> (CellRef, i16) {\n        let (base, offset) = match self.get_value(buffer, false) {\n            CellExpression::Deref(cell) => (cell, 0),\n            CellExpression::BinOp {\n                op: CellOperator::Add,\n                a,\n                b: DerefOrImmediate::Immediate(imm),\n            } => (a, imm.value.try_into().expect(\"Too many buffer writes.\")),\n            _ => panic!(\"Not a valid buffer.\"),\n        };\n        self.main_state.vars.insert(\n            buffer,\n            CellExpression::BinOp {\n                op: CellOperator::Add,\n                a: base,\n                b: deref_or_immediate!(offset + 1),\n            },\n        );\n        (base, offset)\n    }\n\n    /// Increases AP by `size`.\n    pub fn add_ap(&mut self, size: usize) {\n        let instruction = self.get_instruction(\n            InstructionBody::AddAp(AddApInstruction {\n                operand: ResOperand::Immediate(BigInt::from(size).into()),\n            }),\n            false,\n        );\n        self.statements.push(Statement::Final(instruction));\n        self.main_state.ap_change += size;\n    }\n\n    /// Returns a variable that is the `op` of `lhs` and `rhs`.\n    /// `lhs` must be a cell reference and `rhs` must be deref or immediate.\n    pub fn bin_op(&mut self, op: CellOperator, lhs: Var, rhs: Var) -> Var {\n        self.add_var(CellExpression::BinOp {\n            op,\n            a: self.as_cell_ref(lhs, false),\n            b: self.as_deref_or_imm(rhs, false),\n        })\n    }\n\n    /// Returns a variable that is `[[var] + offset]`.\n    /// `var` must be a cell reference, or a cell ref plus a small constant.\n    pub fn double_deref(&mut self, var: Var, offset: i16) -> Var {\n        let (cell, full_offset) = self.as_cell_ref_plus_const(var, offset, false);\n        self.add_var(CellExpression::DoubleDeref(cell, full_offset))\n    }\n\n    /// Sets the label to have the set states, otherwise tests if the state matches the existing one\n    /// by merging.\n    fn set_or_test_label_state(&mut self, label: String, state: State) {\n        match self.label_state.entry(label) {\n            Entry::Occupied(mut e) => {\n                e.get_mut().intersect(&state);\n            }\n            Entry::Vacant(e) => {\n                e.insert(state);\n            }\n        }\n    }\n\n    /// Add a statement to jump to `label`.\n    pub fn jump(&mut self, label: String) {\n        let instruction = self.get_instruction(\n            InstructionBody::Jump(JumpInstruction {\n                target: deref_or_immediate!(0),\n                relative: true,\n            }),\n            true,\n        );\n        self.statements.push(Statement::Jump(label.clone(), instruction));\n        let mut state = State::default();\n        std::mem::swap(&mut state, &mut self.main_state);\n        self.set_or_test_label_state(label, state);\n        self.reachable = false;\n    }\n\n    /// Add a statement to jump to `label` if `condition != 0`.\n    /// `condition` must be a cell reference.\n    pub fn jump_nz(&mut self, condition: Var, label: String) {\n        let cell = self.as_cell_ref(condition, true);\n        let instruction = self.get_instruction(\n            InstructionBody::Jnz(JnzInstruction {\n                condition: cell,\n                jump_offset: deref_or_immediate!(0),\n            }),\n            true,\n        );\n        self.statements.push(Statement::Jump(label.clone(), instruction));\n        self.set_or_test_label_state(label, self.main_state.clone());\n    }\n\n    /// Adds a label here named `name`.\n    pub fn label(&mut self, name: String) {\n        if self.reachable {\n            self.set_or_test_label_state(name.clone(), self.main_state.clone());\n        }\n        self.main_state = self\n            .label_state\n            .get(&name)\n            .unwrap_or_else(|| panic!(\"No known value for state on reaching {name}.\"))\n            .clone();\n        self.statements.push(Statement::Label(name));\n        self.reachable = true;\n    }\n\n    /// Rescoping the values, while ignoring all vars not stated in `vars` and giving the vars on\n    /// the left side the values of the vars on the right side.\n    pub fn rescope<const VAR_COUNT: usize>(&mut self, vars: [(Var, Var); VAR_COUNT]) {\n        self.main_state.validate_finality();\n        let values =\n            vars.map(|(new_var, value_var)| (new_var, self.main_state.get_adjusted(value_var)));\n        self.main_state.ap_change = 0;\n        self.main_state.allocated = 0;\n        self.main_state.vars.clear();\n        self.main_state.vars.extend(values.into_iter());\n    }\n\n    /// Adds a call command to 'label'. All AP based variables are passed to the called function\n    /// state and dropped from the calling function state.\n    pub fn call(&mut self, label: String) {\n        self.main_state.validate_finality();\n        // Vars to be passed to the called function state.\n        let mut function_vars: HashMap<Var, CellExpression> = HashMap::default();\n        // FP based vars which will remain in the current state.\n        let mut main_vars: HashMap<Var, CellExpression> = HashMap::default();\n        let ap_change = self.main_state.ap_change;\n        let cell_to_var_flags = |cell: &CellRef| {\n            if cell.register == Register::AP { (true, false) } else { (false, true) }\n        };\n        for (var, value) in self.main_state.vars.iter() {\n            let (function_var, main_var) = match value {\n                CellExpression::DoubleDeref(cell, _) | CellExpression::Deref(cell) => {\n                    cell_to_var_flags(cell)\n                }\n                CellExpression::Immediate(_) => (true, true),\n                CellExpression::BinOp { op: _, a, b } => match b {\n                    DerefOrImmediate::Deref(cell) => {\n                        if a.register == cell.register {\n                            cell_to_var_flags(cell)\n                        } else {\n                            // Mixed FP and AP based, dropped from both states.\n                            (false, false)\n                        }\n                    }\n                    DerefOrImmediate::Immediate(_) => (true, true),\n                },\n            };\n            if function_var {\n                // Apply ap change (+2 because of the call statement) and change to FP based before\n                // the function call.\n                let mut value = value.clone().unchecked_apply_known_ap_change(ap_change + 2);\n                match &mut value {\n                    CellExpression::DoubleDeref(cell, _) | CellExpression::Deref(cell) => {\n                        cell.register = Register::FP\n                    }\n                    CellExpression::Immediate(_) => {}\n                    CellExpression::BinOp { a, b, .. } => {\n                        a.register = Register::FP;\n                        match b {\n                            DerefOrImmediate::Deref(cell) => cell.register = Register::FP,\n                            DerefOrImmediate::Immediate(_) => {}\n                        }\n                    }\n                }\n                function_vars.insert(*var, value);\n            }\n            if main_var {\n                main_vars.insert(*var, value.clone());\n            }\n        }\n\n        let instruction = self.get_instruction(\n            InstructionBody::Call(CallInstruction {\n                relative: true,\n                target: deref_or_immediate!(0),\n            }),\n            false,\n        );\n        self.statements.push(Statement::Jump(label.clone(), instruction));\n\n        self.main_state.vars = main_vars;\n        self.main_state.allocated = 0;\n        self.main_state.ap_change = 0;\n        self.main_state.steps += 2;\n        let function_state = State { vars: function_vars, ..Default::default() };\n        self.set_or_test_label_state(label, function_state);\n    }\n\n    /// A return statement in the code.\n    pub fn ret(&mut self) {\n        self.main_state.validate_finality();\n        let instruction = self.get_instruction(InstructionBody::Ret(RetInstruction {}), false);\n        self.statements.push(Statement::Final(instruction));\n        self.reachable = false;\n    }\n\n    /// The number of steps at the last added statement.\n    pub fn steps(&self) -> usize {\n        self.main_state.steps\n    }\n\n    /// Resets the steps counter.\n    pub fn reset_steps(&mut self) {\n        self.main_state.steps = 0;\n    }\n\n    /// Create an assert that would always fail.\n    pub fn fail(&mut self) {\n        let cell = CellRef { offset: -1, register: Register::FP };\n        let instruction = self.get_instruction(\n            InstructionBody::AssertEq(AssertEqInstruction {\n                a: cell,\n                b: ResOperand::BinOp(BinOpOperand {\n                    op: Operation::Add,\n                    a: cell,\n                    b: DerefOrImmediate::Immediate(BigInt::one().into()),\n                }),\n            }),\n            false,\n        );\n        self.statements.push(Statement::Final(instruction));\n        self.reachable = false;\n    }\n\n    /// Returns `var`s value, with fixed ap if `adjust_ap` is true.\n    fn get_value(&self, var: Var, adjust_ap: bool) -> CellExpression {\n        if adjust_ap { self.main_state.get_adjusted(var) } else { self.main_state.get_value(var) }\n    }\n\n    /// Returns `var`s value as a cell reference, with fixed ap if `adjust_ap` is true.\n    fn as_cell_ref(&self, var: Var, adjust_ap: bool) -> CellRef {\n        extract_matches!(self.get_value(var, adjust_ap), CellExpression::Deref)\n    }\n\n    /// Returns `var`s value as a cell reference or immediate, with fixed ap if `adjust_ap` is true.\n    fn as_deref_or_imm(&self, var: Var, adjust_ap: bool) -> DerefOrImmediate {\n        match self.get_value(var, adjust_ap) {\n            CellExpression::Deref(cell) => DerefOrImmediate::Deref(cell),\n            CellExpression::Immediate(imm) => DerefOrImmediate::Immediate(imm.into()),\n            CellExpression::DoubleDeref(_, _) | CellExpression::BinOp { .. } => {\n                panic!(\"wrong usage.\")\n            }\n        }\n    }\n\n    /// Returns `var`s value as a cell reference plus a small const offset, with fixed ap if\n    /// `adjust_ap` is true.\n    fn as_cell_ref_plus_const(\n        &self,\n        var: Var,\n        additional_offset: i16,\n        adjust_ap: bool,\n    ) -> (CellRef, i16) {\n        match self.get_value(var, adjust_ap) {\n            CellExpression::Deref(cell) => (cell, additional_offset),\n            CellExpression::BinOp {\n                op: CellOperator::Add,\n                a,\n                b: DerefOrImmediate::Immediate(imm),\n            } => (\n                a,\n                (imm.value + additional_offset).try_into().expect(\"Offset too large for deref.\"),\n            ),\n            _ => panic!(\"Not a valid ptr.\"),\n        }\n    }\n\n    /// Returns an instruction wrapping the instruction body.\n    /// If `inc_ap_supported` may add an `ap++` to the instruction.\n    fn get_instruction(&mut self, body: InstructionBody, inc_ap_supported: bool) -> Instruction {\n        let inc_ap =\n            inc_ap_supported && self.main_state.allocated as usize > self.main_state.ap_change;\n        if inc_ap {\n            self.main_state.ap_change += 1;\n        }\n        self.main_state.steps += 1;\n        let mut hints = vec![];\n        std::mem::swap(&mut hints, &mut self.current_hints);\n        Instruction { body, inc_ap, hints }\n    }\n}\n\nimpl Default for CasmBuilder {\n    fn default() -> Self {\n        Self {\n            label_state: Default::default(),\n            main_state: Default::default(),\n            statements: Default::default(),\n            current_hints: Default::default(),\n            var_count: Default::default(),\n            reachable: true,\n        }\n    }\n}\n\n#[macro_export]\nmacro_rules! casm_build_extend {\n    ($builder:ident,) => {};\n    ($builder:ident, tempvar $var:ident; $($tok:tt)*) => {\n        let $var = $builder.alloc_var(false);\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, localvar $var:ident; $($tok:tt)*) => {\n        let $var = $builder.alloc_var(true);\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, ap += $value:expr; $($tok:tt)*) => {\n        $builder.add_ap($value);\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, const $imm:ident = $value:expr; $($tok:tt)*) => {\n        let $imm = $builder.add_var($crate::cell_expression::CellExpression::Immediate(($value).into()));\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, assert $dst:ident = $res:ident; $($tok:tt)*) => {\n        $builder.assert_vars_eq($dst, $res);\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, assert $dst:ident = $a:ident + $b:ident; $($tok:tt)*) => {\n        {\n            let __sum = $builder.bin_op($crate::cell_expression::CellOperator::Add, $a, $b);\n            $builder.assert_vars_eq($dst, __sum);\n        }\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, assert $dst:ident = $a:ident * $b:ident; $($tok:tt)*) => {\n        {\n            let __product = $builder.bin_op($crate::cell_expression::CellOperator::Mul, $a, $b);\n            $builder.assert_vars_eq($dst, __product);\n        }\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, assert $dst:ident = $a:ident - $b:ident; $($tok:tt)*) => {\n        {\n            let __diff = $builder.bin_op($crate::cell_expression::CellOperator::Sub, $a, $b);\n            $builder.assert_vars_eq($dst, __diff);\n        }\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, assert $dst:ident = $a:ident / $b:ident; $($tok:tt)*) => {\n        {\n            let __division = $builder.bin_op($crate::cell_expression::CellOperator::Div, $a, $b);\n            $builder.assert_vars_eq($dst, __division);\n        }\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, assert $dst:ident = $buffer:ident [ $offset:expr ] ; $($tok:tt)*) => {\n        {\n            let __deref = $builder.double_deref($buffer, $offset);\n            $builder.assert_vars_eq($dst, __deref);\n        }\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, assert $dst:ident = * $buffer:ident; $($tok:tt)*) => {\n        {\n            let __deref = $builder.double_deref($buffer, 0);\n            $builder.assert_vars_eq($dst, __deref);\n        }\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, assert $value:ident = * ( $buffer:ident ++ ); $($tok:tt)*) => {\n        $builder.buffer_write_and_inc($buffer, $value);\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, tempvar $var:ident = $value:ident; $($tok:tt)*) => {\n        $crate::casm_build_extend!($builder, tempvar $var; assert $var = $value; $($tok)*);\n    };\n    ($builder:ident, tempvar $var:ident = $lhs:ident + $rhs:ident; $($tok:tt)*) => {\n        $crate::casm_build_extend!($builder, tempvar $var; assert $var = $lhs + $rhs; $($tok)*);\n    };\n    ($builder:ident, tempvar $var:ident = $lhs:ident * $rhs:ident; $($tok:tt)*) => {\n        $crate::casm_build_extend!($builder, tempvar $var; assert $var = $lhs * $rhs; $($tok)*);\n    };\n    ($builder:ident, tempvar $var:ident = $lhs:ident - $rhs:ident; $($tok:tt)*) => {\n        $crate::casm_build_extend!($builder, tempvar $var; assert $var = $lhs - $rhs; $($tok)*);\n    };\n    ($builder:ident, tempvar $var:ident = $lhs:ident / $rhs:ident; $($tok:tt)*) => {\n        $crate::casm_build_extend!($builder, tempvar $var; assert $var = $lhs / $rhs; $($tok)*);\n    };\n    ($builder:ident, tempvar $var:ident = * ( $buffer:ident ++ ); $($tok:tt)*) => {\n        $crate::casm_build_extend!($builder, tempvar $var; assert $var = *($buffer++); $($tok)*);\n    };\n    ($builder:ident, tempvar $var:ident = $buffer:ident [ $offset:expr ]; $($tok:tt)*) => {\n        $crate::casm_build_extend!($builder, tempvar $var; assert $var = $buffer[$offset]; $($tok)*);\n    };\n    ($builder:ident, tempvar $var:ident = * $buffer:ident ; $($tok:tt)*) => {\n        $crate::casm_build_extend!($builder, tempvar $var; assert $var = *$buffer; $($tok)*);\n    };\n    ($builder:ident, localvar $var:ident = $value:ident; $($tok:tt)*) => {\n        $crate::casm_build_extend!($builder, localvar $var; assert $var = $value; $($tok)*);\n    };\n    ($builder:ident, localvar $var:ident = $lhs:ident + $rhs:ident; $($tok:tt)*) => {\n        $crate::casm_build_extend!($builder, localvar $var; assert $var = $lhs + $rhs; $($tok)*);\n    };\n    ($builder:ident, localvar $var:ident = $lhs:ident * $rhs:ident; $($tok:tt)*) => {\n        $crate::casm_build_extend!($builder, localvar $var; assert $var = $lhs * $rhs; $($tok)*);\n    };\n    ($builder:ident, localvar $var:ident = $lhs:ident - $rhs:ident; $($tok:tt)*) => {\n        $crate::casm_build_extend!($builder, localvar $var; assert $var = $lhs - $rhs; $($tok)*);\n    };\n    ($builder:ident, localvar $var:ident = $lhs:ident / $rhs:ident; $($tok:tt)*) => {\n        $crate::casm_build_extend!($builder, localvar $var; assert $var = $lhs / $rhs; $($tok)*);\n    };\n    ($builder:ident, localvar $var:ident = * ( $buffer:ident ++ ); $($tok:tt)*) => {\n        $crate::casm_build_extend!($builder, localvar $var; assert $var = *($buffer++); $($tok)*);\n    };\n    ($builder:ident, localvar $var:ident = $buffer:ident [ $offset:expr ]; $($tok:tt)*) => {\n        $crate::casm_build_extend!($builder, localvar $var; assert $var = $buffer[$offset]; $($tok)*);\n    };\n    ($builder:ident, localvar $var:ident = * $buffer:ident ; $($tok:tt)*) => {\n        $crate::casm_build_extend!($builder, localvar $var; assert $var = *$buffer; $($tok)*);\n    };\n    ($builder:ident, let $dst:ident = $a:ident + $b:ident; $($tok:tt)*) => {\n        let $dst = $builder.bin_op($crate::cell_expression::CellOperator::Add, $a, $b);\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, let $dst:ident = $a:ident * $b:ident; $($tok:tt)*) => {\n        let $dst = $builder.bin_op($crate::cell_expression::CellOperator::Mul, $a, $b);\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, let $dst:ident = $a:ident - $b:ident; $($tok:tt)*) => {\n        let $dst = $builder.bin_op($crate::cell_expression::CellOperator::Sub, $a, $b);\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, let $dst:ident = $a:ident / $b:ident; $($tok:tt)*) => {\n        let $dst = $builder.bin_op($crate::cell_expression::CellOperator::Div, $a, $b);\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, let $dst:ident = * ( $buffer:ident ++ ); $($tok:tt)*) => {\n        let $dst = $builder.get_ref_and_inc($buffer);\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, let $dst:ident = $buffer:ident [ $offset:expr ] ; $($tok:tt)*) => {\n        let $dst = $builder.double_deref($buffer, $offset);\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, let $dst:ident = *$buffer:ident; $($tok:tt)*) => {\n        let $dst = $builder.double_deref($buffer, 0);\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, let $dst:ident = $src:ident; $($tok:tt)*) => {\n        let $dst = $builder.duplicate_var($src);\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, jump $target:ident; $($tok:tt)*) => {\n        $builder.jump(std::stringify!($target).to_owned());\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, jump $target:ident if $condition:ident != 0; $($tok:tt)*) => {\n        $builder.jump_nz($condition, std::stringify!($target).to_owned());\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, let ($($var_name:ident),*) = call $target:ident; $($tok:tt)*) => {\n        $builder.call(std::stringify!($target).to_owned());\n\n        let __var_count = {0i16 $(+ (stringify!($var_name), 1i16).1)*};\n        let mut __var_index = 0;\n        $(\n            let $var_name = $builder.add_var($crate::cell_expression::CellExpression::Deref($crate::operand::CellRef {\n                offset: __var_index - __var_count,\n                register: $crate::operand::Register::AP,\n            }));\n            __var_index += 1;\n        )*\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, ret; $($tok:tt)*) => {\n        $builder.ret();\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, $label:ident: $($tok:tt)*) => {\n        $builder.label(std::stringify!($label).to_owned());\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, fail; $($tok:tt)*) => {\n        $builder.fail();\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, hint $hint_name:ident {\n            $($input_name:ident : $input_value:ident),*\n        } into {\n            $($output_name:ident : $output_value:ident),*\n        }; $($tok:tt)*) => {\n        $builder.add_hint(\n            |[$($input_name),*], [$($output_name),*]| $crate::hints::Hint::$hint_name {\n                $($input_name,)* $($output_name,)*\n            },\n            [$($input_value,)*],\n            [$($output_value,)*],\n        );\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, hint $hint_name:ident {\n        $buffer_name:ident : $buffer_value:ident\n    }; $($tok:tt)*) => {\n        $builder.add_hint(\n            |[$buffer_name], []| $crate::hints::Hint::$hint_name { $buffer_name },\n            [$buffer_value], []\n        );\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, rescope { $($new_var:ident = $value_var:ident),* }; $($tok:tt)*) => {\n        $builder.rescope([$(($new_var, $value_var)),*]);\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, #{ validate steps == $count:expr; } $($tok:tt)*) => {\n        assert_eq!($builder.steps(), $count);\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, #{ steps = 0; } $($tok:tt)*) => {\n        $builder.reset_steps();\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n    ($builder:ident, #{ $counter:ident += steps; steps = 0; } $($tok:tt)*) => {\n        $counter += $builder.steps() as i32;\n        $builder.reset_steps();\n        $crate::casm_build_extend!($builder, $($tok)*)\n    };\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use indoc::indoc;\nuse itertools::join;\nuse pretty_assertions::assert_eq;\n\nuse super::CasmBuilder;\nuse crate::builder::CasmBuildResult;\nuse crate::cell_expression::CellExpression;\nuse crate::{casm_build_extend, res};\n\n#[test]\nfn test_ap_change_fixes() {\n    let mut builder = CasmBuilder::default();\n    let ap_at_7_mul_34 = builder.add_var(CellExpression::from_res_operand(res!([ap + 7] * 34)));\n    let fp_at_minus_3 = builder.add_var(CellExpression::from_res_operand(res!([fp - 3])));\n    let imm5 = builder.add_var(CellExpression::from_res_operand(res!(5)));\n    let ap_at_5 = builder.add_var(CellExpression::from_res_operand(res!([ap + 5])));\n    casm_build_extend! {builder,\n        let ap_at_5_mul5 = ap_at_5 * imm5;\n        ap += 2;\n        let fp_at_minus_3_plus_ap_at_5 = fp_at_minus_3 + ap_at_5;\n    };\n    let CasmBuildResult { instructions, branches: [(state, awaiting_relocations)] } =\n        builder.build([\"Fallthrough\"]);\n    assert_eq!(\n        state.get_adjusted(ap_at_7_mul_34),\n        CellExpression::from_res_operand(res!([ap + 5] * 34))\n    );\n    assert_eq!(state.get_adjusted(fp_at_minus_3), CellExpression::from_res_operand(res!([fp - 3])));\n    assert_eq!(state.get_adjusted(ap_at_5), CellExpression::from_res_operand(res!([ap + 3])));\n    assert_eq!(state.get_adjusted(imm5), CellExpression::from_res_operand(res!(5)));\n    assert_eq!(\n        state.get_adjusted(ap_at_5_mul5),\n        CellExpression::from_res_operand(res!([ap + 3] * 5))\n    );\n    assert_eq!(\n        state.get_adjusted(fp_at_minus_3_plus_ap_at_5),\n        CellExpression::from_res_operand(res!([fp - 3] + [ap + 3]))\n    );\n    assert_eq!(state.ap_change, 2);\n    assert_eq!(state.steps, 1);\n    assert_eq!(\n        join(instructions.iter().map(|inst| format!(\"{inst};\\n\")), \"\"),\n        indoc! {\"\n            ap += 2;\n        \"}\n    );\n    assert!(awaiting_relocations.is_empty());\n}\n\n#[test]\nfn test_awaiting_relocations() {\n    let mut builder = CasmBuilder::default();\n    casm_build_extend! {builder,\n        ap += 5;\n        jump Target;\n    };\n    let CasmBuildResult { instructions, branches: [(state, awaiting_relocations)] } =\n        builder.build([\"Target\"]);\n    assert_eq!(state.ap_change, 5);\n    assert_eq!(state.steps, 2);\n    assert_eq!(awaiting_relocations, [1]);\n    assert_eq!(\n        join(instructions.iter().map(|inst| format!(\"{inst};\\n\")), \"\"),\n        indoc! {\"\n            ap += 5;\n            jmp rel 0;\n        \"}\n    );\n}\n\n#[test]\nfn test_noop_branch() {\n    let mut builder = CasmBuilder::default();\n    casm_build_extend! {builder,\n        ap += 3;\n        jump Target;\n        Target:\n    };\n    let CasmBuildResult { instructions, branches: [(state, awaiting_relocations)] } =\n        builder.build([\"Fallthrough\"]);\n    assert!(awaiting_relocations.is_empty());\n    assert_eq!(state.ap_change, 3);\n    assert_eq!(state.steps, 2);\n    assert_eq!(\n        join(instructions.iter().map(|inst| format!(\"{inst};\\n\")), \"\"),\n        indoc! {\"\n            ap += 3;\n            jmp rel 2;\n        \"}\n    );\n}\n\n#[test]\nfn test_allocations() {\n    let mut builder = CasmBuilder::default();\n    casm_build_extend! {builder,\n        tempvar a;\n        tempvar b;\n        tempvar c;\n        assert a = b;\n        assert b = c;\n        assert c = a;\n    };\n    let CasmBuildResult { instructions, branches: [(state, awaiting_relocations)] } =\n        builder.build([\"Fallthrough\"]);\n    assert!(awaiting_relocations.is_empty());\n    assert_eq!(state.ap_change, 3);\n    assert_eq!(state.steps, 3);\n    assert_eq!(\n        join(instructions.iter().map(|inst| format!(\"{inst};\\n\")), \"\"),\n        indoc! {\"\n            [ap + 0] = [ap + 1], ap++;\n            [ap + 0] = [ap + 1], ap++;\n            [ap + 0] = [ap + -2], ap++;\n        \"}\n    );\n}\n\n#[test]\n#[should_panic]\nfn test_allocations_not_enough_commands() {\n    let mut builder = CasmBuilder::default();\n    casm_build_extend! {builder,\n        tempvar a;\n        tempvar b;\n        tempvar c;\n        assert a = b;\n        assert b = c;\n    };\n    builder.build([\"Fallthrough\"]);\n}\n\n#[test]\nfn test_aligned_branch_intersect() {\n    let mut builder = CasmBuilder::default();\n    let var = builder.add_var(CellExpression::from_res_operand(res!([ap + 7])));\n    casm_build_extend! {builder,\n        tempvar _unused;\n        jump X if var != 0;\n        jump ONE_ALLOC;\n        X:\n        ONE_ALLOC:\n    };\n    let CasmBuildResult { instructions, branches: [(state, awaiting_relocations)] } =\n        builder.build([\"Fallthrough\"]);\n    assert!(awaiting_relocations.is_empty());\n    assert_eq!(state.ap_change, 1);\n    assert_eq!(state.allocated, 1);\n    assert_eq!(state.steps, 2);\n    assert_eq!(\n        join(instructions.iter().map(|inst| format!(\"{inst};\\n\")), \"\"),\n        indoc! {\"\n            jmp rel 4 if [ap + 7] != 0, ap++;\n            jmp rel 2;\n        \"}\n    );\n}\n\n#[test]\n#[should_panic]\nfn test_unaligned_branch_intersect() {\n    let mut builder = CasmBuilder::default();\n    let var = builder.add_var(CellExpression::from_res_operand(res!([ap + 7])));\n    casm_build_extend! {builder,\n        jump X if var != 0;\n        // A single tempvar in this branch.\n        tempvar _unused;\n        jump ONESIDED_ALLOC;\n        // No allocs in this branch.\n        X:\n        // When the merge occurs here we will panic on a mismatch.\n        ONESIDED_ALLOC:\n    };\n    builder.build([\"Fallthrough\"]);\n}\n\n#[test]\nfn test_calculation_loop() {\n    let mut builder = CasmBuilder::default();\n    casm_build_extend! {builder,\n        const one = 1;\n        const ten = 10;\n        tempvar a = one;\n        tempvar n = ten;\n        tempvar b = one;\n        rescope{a = a, b = b, n = n, one = one};\n        FIB:\n        tempvar new_n = n - one;\n        tempvar new_b = a + b;\n        rescope{a = b, b = new_b, n = new_n, one = one};\n        jump FIB if n != 0;\n    };\n    let CasmBuildResult { instructions, branches: [(state, awaiting_relocations)] } =\n        builder.build([\"Fallthrough\"]);\n    assert!(awaiting_relocations.is_empty());\n    assert_eq!(state.get_adjusted(b), CellExpression::from_res_operand(res!([ap - 1])));\n    assert_eq!(\n        join(instructions.iter().map(|inst| format!(\"{inst};\\n\")), \"\"),\n        indoc! {\"\n            [ap + 0] = 1, ap++;\n            [ap + 0] = 10, ap++;\n            [ap + 0] = 1, ap++;\n            [ap + -2] = [ap + 0] + 1, ap++;\n            [ap + 0] = [ap + -4] + [ap + -2], ap++;\n            jmp rel -3 if [ap + -2] != 0;\n        \"}\n    );\n}\n\n#[test]\nfn test_call_ret() {\n    let mut builder = CasmBuilder::default();\n    casm_build_extend! {builder,\n        const zero = 0;\n        const one = 1;\n        const ten = 10;\n        const fib10 = 89;\n        const fib11 = 144;\n        tempvar a = one;\n        tempvar n = ten;\n        tempvar b = one;\n        let (res_a, res_n, res_b) = call FIB;\n        assert res_a = fib10;\n        assert res_n = zero;\n        assert res_b = fib11;\n        jump FT;\n        FIB:\n        tempvar new_a = b;\n        tempvar new_n = n - one;\n        tempvar new_b = a + b;\n        jump REC_CALL if new_n != 0;\n        rescope {};\n        jump FIB_END;\n        REC_CALL:\n        let () = call FIB;\n        FIB_END:\n        ret;\n        FT:\n    };\n    let CasmBuildResult { instructions, branches: [(_, awaiting_relocations)] } =\n        builder.build([\"Fallthrough\"]);\n    assert!(awaiting_relocations.is_empty());\n    assert_eq!(\n        join(instructions.iter().map(|inst| format!(\"{inst};\\n\")), \"\"),\n        indoc! {\"\n            [ap + 0] = 1, ap++;\n            [ap + 0] = 10, ap++;\n            [ap + 0] = 1, ap++;\n            call rel 10;\n            [ap + -3] = 89;\n            [ap + -2] = 0;\n            [ap + -1] = 144;\n            jmp rel 13;\n            [ap + 0] = [fp + -3], ap++;\n            [fp + -4] = [ap + 0] + 1, ap++;\n            [ap + 0] = [fp + -5] + [fp + -3], ap++;\n            jmp rel 4 if [ap + -2] != 0;\n            jmp rel 4;\n            call rel -8;\n            ret;\n        \"}\n    );\n}\n\n#[test]\nfn test_local_fib() {\n    let mut builder = CasmBuilder::default();\n    casm_build_extend! {builder,\n        const one = 1;\n        const ten = 10;\n        const fib11 = 144;\n        localvar res = fib11;\n        tempvar a = one;\n        tempvar n = ten;\n        tempvar b = one;\n        rescope{a = a, b = b, n = n, one = one, res = res};\n        FIB:\n        tempvar new_n = n - one;\n        tempvar new_b = a + b;\n        rescope{a = b, b = new_b, n = new_n, one = one, res = res};\n        jump FIB if n != 0;\n        assert res = b;\n    };\n    let CasmBuildResult { instructions, branches: [(_, awaiting_relocations)] } =\n        builder.build([\"Fallthrough\"]);\n    assert!(awaiting_relocations.is_empty());\n    assert_eq!(\n        join(instructions.iter().map(|inst| format!(\"{inst};\\n\")), \"\"),\n        indoc! {\"\n            [fp + 0] = 144, ap++;\n            [ap + 0] = 1, ap++;\n            [ap + 0] = 10, ap++;\n            [ap + 0] = 1, ap++;\n            [ap + -2] = [ap + 0] + 1, ap++;\n            [ap + 0] = [ap + -4] + [ap + -2], ap++;\n            jmp rel -3 if [ap + -2] != 0;\n            [fp + 0] = [ap + -1];\n        \"}\n    );\n}\n\n#[test]\nfn test_array_access() {\n    let mut builder = CasmBuilder::default();\n    casm_build_extend! {builder,\n        const zero = 0;\n        const one = 1;\n        tempvar a = zero;\n        tempvar b = one;\n        tempvar ptr;\n        hint AllocSegment {} into {dst: ptr};\n        assert a = ptr[0];\n        assert b = ptr[1];\n    };\n    let CasmBuildResult { instructions, branches: [(_, awaiting_relocations)] } =\n        builder.build([\"Fallthrough\"]);\n    assert!(awaiting_relocations.is_empty());\n    assert_eq!(\n        join(instructions.iter().map(|inst| format!(\"{inst};\\n\")), \"\"),\n        indoc! {\"\n            [ap + 0] = 0, ap++;\n            [ap + 0] = 1, ap++;\n            %{ memory[ap + 0] = segments.add() %}\n            [ap + -2] = [[ap + 0] + 0], ap++;\n            [ap + -2] = [[ap + -1] + 1];\n        \"}\n    );\n}\n\n#[test]\nfn test_fail() {\n    let mut builder = CasmBuilder::default();\n    casm_build_extend! {builder,\n        const three = 3;\n        tempvar var = three;\n        jump X if var != 0;\n        fail;\n        X:\n    };\n    let CasmBuildResult { instructions, branches: [(_, awaiting_relocations)] } =\n        builder.build([\"Fallthrough\"]);\n    assert!(awaiting_relocations.is_empty());\n    assert_eq!(\n        join(instructions.iter().map(|inst| format!(\"{inst};\\n\")), \"\"),\n        indoc! {\"\n            [ap + 0] = 3, ap++;\n            jmp rel 4 if [ap + -1] != 0;\n            [fp + -1] = [fp + -1] + 1;\n        \"}\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_utils::try_extract_matches;\nuse num_bigint::BigInt;\nuse num_traits::cast::ToPrimitive;\n\nuse crate::ap_change::ApplyApChange;\nuse crate::operand::{BinOpOperand, CellRef, DerefOrImmediate, Operation, ResOperand};\n\n#[derive(Clone, Debug, Eq, PartialEq)]\npub enum CellOperator {\n    Add,\n    Sub,\n    Mul,\n    Div,\n}\n\n/// The expression representing a cell in the casm memory.\n#[derive(Clone, Debug, Eq, PartialEq)]\npub enum CellExpression {\n    Deref(CellRef),\n    /// Represents an expression of the form `[[cell_ref] + offset]`.\n    DoubleDeref(CellRef, i16),\n    Immediate(BigInt),\n    /// Represents an expression of the form `[cell_ref] + [cell_ref]` or `[cell_ref] + imm`.\n    ///\n    /// If `op` is [CellOperator::Div], `b` must not be zero.\n    BinOp {\n        op: CellOperator,\n        a: CellRef,\n        b: DerefOrImmediate,\n    },\n}\nimpl CellExpression {\n    pub fn from_res_operand(operand: ResOperand) -> Self {\n        match operand {\n            ResOperand::Deref(cell) => Self::Deref(cell),\n            ResOperand::DoubleDeref(cell, offset) => Self::DoubleDeref(cell, offset),\n            ResOperand::Immediate(imm) => Self::Immediate(imm.value),\n            ResOperand::BinOp(BinOpOperand { op, a, b }) => Self::BinOp {\n                op: match op {\n                    Operation::Add => CellOperator::Add,\n                    Operation::Mul => CellOperator::Mul,\n                },\n                a,\n                b,\n            },\n        }\n    }\n\n    /// Extract the cell reference from the cell expression.\n    pub fn to_deref(&self) -> Option<CellRef> {\n        try_extract_matches!(self, CellExpression::Deref).cloned()\n    }\n\n    /// Extract a deref or immediate from the cell expression.\n    pub fn to_deref_or_immediate(&self) -> Option<DerefOrImmediate> {\n        match self {\n            CellExpression::Deref(cell) => Some(DerefOrImmediate::Deref(*cell)),\n            CellExpression::Immediate(imm) => Some(imm.clone().into()),\n            _ => None,\n        }\n    }\n\n    /// Given `[ref] + offset` returns `([ref], offset)`.\n    pub fn to_deref_with_offset(&self) -> Option<(CellRef, i16)> {\n        match self {\n            CellExpression::Deref(cell) => Some((*cell, 0i16)),\n            CellExpression::BinOp {\n                op: CellOperator::Add,\n                a: cell,\n                b: DerefOrImmediate::Immediate(offset),\n            } => Some((*cell, offset.value.to_i16()?)),\n            _ => None,\n        }\n    }\n\n    /// Returns the reference as a buffer with at least `required_slack` next cells that can be\n    /// written as an instruction offset.\n    pub fn to_buffer(&self, required_slack: i16) -> Option<CellExpression> {\n        let (base, offset) = self.to_deref_with_offset()?;\n        offset.checked_add(required_slack)?;\n        if offset == 0 {\n            Some(CellExpression::Deref(base))\n        } else {\n            Some(CellExpression::BinOp {\n                op: CellOperator::Add,\n                a: base,\n                b: DerefOrImmediate::Immediate(offset.into()),\n            })\n        }\n    }\n}\n\nimpl ApplyApChange for CellExpression {\n    fn apply_known_ap_change(self, ap_change: usize) -> Option<Self> {\n        Some(match self {\n            CellExpression::Deref(operand) => {\n                CellExpression::Deref(operand.apply_known_ap_change(ap_change)?)\n            }\n            CellExpression::DoubleDeref(operand, offset) => {\n                CellExpression::DoubleDeref(operand.apply_known_ap_change(ap_change)?, offset)\n            }\n            CellExpression::BinOp { op, a, b } => CellExpression::BinOp {\n                op,\n                a: a.apply_known_ap_change(ap_change)?,\n                b: b.apply_known_ap_change(ap_change)?,\n            },\n            expr @ CellExpression::Immediate(_) => expr,\n        })\n    }\n\n    fn can_apply_unknown(&self) -> bool {\n        match self {\n            CellExpression::Deref(operand) | CellExpression::DoubleDeref(operand, _) => {\n                operand.can_apply_unknown()\n            }\n            CellExpression::Immediate(_) => true,\n            CellExpression::BinOp { a, b, .. } => a.can_apply_unknown() && b.can_apply_unknown(),\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use num_bigint::BigInt;\n\nuse crate::assembler::{ApUpdate, FpUpdate, InstructionRepr, Op1Addr, Opcode, PcUpdate, Res};\nuse crate::operand::Register;\n\n#[cfg(test)]\n#[path = \"encoder_test.rs\"]\nmod test;\n\nconst OFFSET_BITS: u32 = 16;\n\nconst DST_REG_BIT: i32 = 0;\nconst OP0_REG_BIT: i32 = 1;\nconst OP1_IMM_BIT: i32 = 2;\nconst OP1_FP_BIT: i32 = 3;\nconst OP1_AP_BIT: i32 = 4;\nconst RES_ADD_BIT: i32 = 5;\nconst RES_MUL_BIT: i32 = 6;\nconst PC_JUMP_ABS_BIT: i32 = 7;\nconst PC_JUMP_REL_BIT: i32 = 8;\nconst PC_JNZ_BIT: i32 = 9;\nconst AP_ADD_BIT: i32 = 10;\nconst AP_ADD1_BIT: i32 = 11;\nconst OPCODE_CALL_BIT: i32 = 12;\nconst OPCODE_RET_BIT: i32 = 13;\nconst OPCODE_ASSERT_EQ_BIT: i32 = 14;\n\nimpl InstructionRepr {\n    pub fn encode(&self) -> Vec<BigInt> {\n        // Convert the offsets from possibly negative numbers in the range [-2^15, 2^15)\n        // to positive numbers in the range [0, 2^16) centered around 2^15.\n        let off0_enc: u64 = ((self.off0 as i32) + (1 << (OFFSET_BITS - 1))) as u64;\n        let off1_enc: u64 = ((self.off1 as i32) + (1 << (OFFSET_BITS - 1))) as u64;\n        let off2_enc: u64 = ((self.off2 as i32) + (1 << (OFFSET_BITS - 1))) as u64;\n\n        let mut flags = 0;\n        if self.dst_register == Register::FP {\n            flags |= 1 << DST_REG_BIT;\n        }\n        if self.op0_register == Register::FP {\n            flags |= 1 << OP0_REG_BIT;\n        }\n        assert_eq!(\n            self.imm.is_some(),\n            self.op1_addr == Op1Addr::Imm,\n            \"Immediate must appear iff op1_addr is Op1Addr.IMM\"\n        );\n        flags |= match self.op1_addr {\n            Op1Addr::Imm => 1 << OP1_IMM_BIT,\n            Op1Addr::AP => 1 << OP1_AP_BIT,\n            Op1Addr::FP => 1 << OP1_FP_BIT,\n            Op1Addr::Op0 => 0,\n        };\n\n        flags |= match self.res {\n            Res::Add => 1 << RES_ADD_BIT,\n            Res::Mul => 1 << RES_MUL_BIT,\n            Res::Op1 => 0,\n            Res::Unconstrained => 0,\n        };\n\n        assert_eq!(\n            self.res == Res::Unconstrained,\n            self.pc_update == PcUpdate::Jnz,\n            \"res must be Unconstrained iff pc_update is Jnz\"\n        );\n\n        flags |= match self.pc_update {\n            PcUpdate::Jump => 1 << PC_JUMP_ABS_BIT,\n            PcUpdate::JumpRel => 1 << PC_JUMP_REL_BIT,\n            PcUpdate::Jnz => 1 << PC_JNZ_BIT,\n            PcUpdate::Regular => 0,\n        };\n\n        assert_eq!(\n            self.ap_update == ApUpdate::Add2,\n            self.opcode == Opcode::Call,\n            \"ap_update is Add2 iff opcode is Call\"\n        );\n\n        flags |= match self.ap_update {\n            ApUpdate::Add => 1 << AP_ADD_BIT,\n            ApUpdate::Add1 => 1 << AP_ADD1_BIT,\n            ApUpdate::Add2 => 0,\n            ApUpdate::Regular => 0,\n        };\n\n        assert_eq!(\n            self.fp_update,\n            match self.opcode {\n                Opcode::Nop => FpUpdate::Regular,\n                Opcode::Call => FpUpdate::ApPlus2,\n                Opcode::Ret => FpUpdate::Dst,\n                Opcode::AssertEq => FpUpdate::Regular,\n            },\n            \"fp_update {:?} does not match opcode {:?}.\",\n            self.fp_update,\n            self.opcode\n        );\n\n        flags |= match self.opcode {\n            Opcode::Call => 1 << OPCODE_CALL_BIT,\n            Opcode::Ret => 1 << OPCODE_RET_BIT,\n            Opcode::AssertEq => 1 << OPCODE_ASSERT_EQ_BIT,\n            Opcode::Nop => 0,\n        };\n\n        let mut encoding: u64 = flags << (3 * OFFSET_BITS);\n        encoding |= off2_enc << (2 * OFFSET_BITS);\n        encoding |= off1_enc << (OFFSET_BITS);\n        encoding |= off0_enc;\n\n        let bigint_encoding = BigInt::from(encoding);\n        if let Some(imm) = self.imm.clone() {\n            vec![bigint_encoding, imm]\n        } else {\n            vec![bigint_encoding]\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use num_bigint::BigInt;\nuse pretty_assertions::assert_eq;\nuse test_case::test_case;\n\nuse crate::casm;\nuse crate::inline::CasmContext;\n\n#[test_case(\n    casm!(jmp abs 3;),\n    0x8780017fff7fffu64,\n    Some(3);\n    \"jmp abs 3;\"\n)]\n#[test_case(\n    casm!(jmp rel -5, ap++;),\n    0x90780017fff7fffu64,\n    Some(-5); \"jmp rel -5, ap++;\"\n)]\n#[test_case(\n    casm!(call abs 3;),\n    0x1084800180018000u64,\n    Some(3);\n    \"call abs 3;\"\n)]\n#[test_case(\n    casm!(call rel (-5);),\n    0x1104800180018000u64,\n    Some(-5);\n    \"call rel (-5);\"\n)]\n#[test_case(\n    casm!(jmp rel 205 if [ap + 5] != 0;),\n    0x20680017fff8005u64,\n    Some(205);\n    \"jmp rel 205 if [ap + 5] != 0;\"\n)]\n#[test_case(\n    casm!(jmp rel 2 if [ap - 1] != 0, ap++;),\n    0xa0680017fff7fffu64,\n    Some(2);\n    \"jmp rel 2 if [ap + (-1)] != 0;\"\n)]\n#[test_case(\n    casm!([ap + 5] = 205;),\n    0x400680017fff8005u64,\n    Some(205);\n    \"[ap + 5] = 205;\"\n)]\n#[test_case(\n    casm!(ret;),\n    0x208b7fff7fff7ffeu64,\n    None;\n    \"ret;\"\n)]\n#[test_case(\n    casm!(ap += 205;),\n    0x40780017fff7fffu64,\n    Some(205);\n    \"ap += 205;\"\n)]\n#[test_case(\n    casm!([ap + 0] = [fp + -5], ap++;),\n    0x480a7ffb7fff8000,\n    None;\n    \"[ap + 0] = [fp + -5], ap++;\"\n)]\n#[test_case(\n    casm!([ap] = [ap - 3], ap++;),\n    0x48127ffd7fff8000,\n    None;\n    \"[ap + 0] = [ap + -3], ap++;\"\n)]\nfn test_encode(mut casm: CasmContext, encoding: u64, immediate: Option<i16>) {\n    let enc = BigInt::from(encoding);\n    assert_eq!(\n        casm.instructions.remove(0).assemble().encode(),\n        if let Some(imm) = immediate { vec![enc, BigInt::from(imm)] } else { vec![enc] }\n    );\n}\n\n#[test_case(\n    casm! {\n        [ap + 0] = 1, ap++;\n        [ap + 0] = 1, ap++;\n        [ap + 0] = 13, ap++;\n        call rel 3;\n        ret;\n        jmp rel 5 if [fp + -3] != 0;\n        [ap + 0] = [fp + -5], ap++;\n        jmp rel 8;\n        [ap + 0] = [fp + -4], ap++;\n        [ap + 0] = [fp + -5] + [fp + -4], ap++;\n        [fp + -3] = [ap + 0] + 1, ap++;\n        call rel (-9);\n        ret;\n    },\n    vec![\n        0x480680017fff8000, 1, 0x480680017fff8000, 1, 0x480680017fff8000, 13, 0x1104800180018000,\n        3, 0x208b7fff7fff7ffe, 0x20780017fff7ffd, 5, 0x480a7ffb7fff8000, 0x10780017fff7fff, 8,\n        0x480a7ffc7fff8000, 0x482a7ffc7ffb8000, 0x4825800180007ffd, 1, 0x1104800180018000, -9,\n        0x208b7fff7fff7ffe\n    ];\n    \"fib(1, 1, 13)\"\n)]\nfn test_encode_multiple(casm: CasmContext, expected: Vec<i128>) {\n    let exp: Vec<BigInt> = expected.into_iter().map(BigInt::from).collect();\n    let enc: Vec<BigInt> =\n        casm.instructions.iter().flat_map(|inst| inst.assemble().encode()).collect();\n    assert_eq!(enc, exp);\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::fmt::{Display, Formatter};\n\nuse indoc::writedoc;\nuse serde::{Deserialize, Serialize};\n\nuse crate::operand::{CellRef, DerefOrImmediate, ResOperand};\n\n#[cfg(test)]\nmod test;\n\n// Represents a cairo hint.\n#[derive(Serialize, Deserialize, Debug, Eq, PartialEq, Clone)]\npub enum Hint {\n    AllocSegment {\n        dst: CellRef,\n    },\n    TestLessThan {\n        lhs: ResOperand,\n        rhs: ResOperand,\n        dst: CellRef,\n    },\n    TestLessThanOrEqual {\n        lhs: ResOperand,\n        rhs: ResOperand,\n        dst: CellRef,\n    },\n    DivMod {\n        lhs: ResOperand,\n        rhs: ResOperand,\n        quotient: CellRef,\n        remainder: CellRef,\n    },\n    SquareRoot {\n        value: ResOperand,\n        dst: CellRef,\n    },\n    /// Finds some `x` and `y` such that `x * scalar + y = value` and `x <= max_x`.\n    LinearSplit {\n        value: ResOperand,\n        scalar: ResOperand,\n        max_x: ResOperand,\n        x: CellRef,\n        y: CellRef,\n    },\n    /// Allocates a new dict segment, and write its start address into the dict_infos segment.\n    AllocFelt252Dict {\n        segment_arena_ptr: ResOperand,\n    },\n    /// Retrives and writes the value corresponding to the given dict and key from the vm\n    /// dict_manager.\n    Felt252DictRead {\n        dict_ptr: ResOperand,\n        key: ResOperand,\n        value_dst: CellRef,\n    },\n    /// Sets the value correspoinding to the key in the vm dict_manager.\n    Felt252DictWrite {\n        dict_ptr: ResOperand,\n        key: ResOperand,\n        value: ResOperand,\n    },\n    /// Retrives the index of the given dict in the dict_infos segment.\n    GetSegmentArenaIndex {\n        dict_end_ptr: ResOperand,\n        dict_index: CellRef,\n    },\n    /// Initialized the lists of accesses of each key of a dict as a preparation of squash_dict.\n    InitSquashData {\n        dict_accesses: ResOperand,\n        ptr_diff: ResOperand,\n        n_accesses: ResOperand,\n        big_keys: CellRef,\n        first_key: CellRef,\n    },\n    /// Retrives the current index of a dict access to process.\n    GetCurrentAccessIndex {\n        range_check_ptr: ResOperand,\n    },\n    /// Writes if the squash_dict loop should be skipped.\n    ShouldSkipSquashLoop {\n        should_skip_loop: CellRef,\n    },\n    /// Writes the delta from the current access index to the next one.\n    GetCurrentAccessDelta {\n        index_delta_minus1: CellRef,\n    },\n    /// Writes if the squash_dict loop should be continued.\n    ShouldContinueSquashLoop {\n        should_continue: CellRef,\n    },\n    /// Asserts that the current access indices list is empty (after the loop).\n    AssertCurrentAccessIndicesIsEmpty,\n    /// Asserts that the number of used accesses is equal to the length of the original accesses\n    /// list.\n    AssertAllAccessesUsed {\n        n_used_accesses: CellRef,\n    },\n    /// Asserts that the keys list is empty.\n    AssertAllKeysUsed,\n    /// Writes the next dict key to process.\n    GetNextDictKey {\n        next_key: CellRef,\n    },\n    /// Asserts that the input represents integers and that a<b.\n    AssertLtAssertValidInput {\n        a: ResOperand,\n        b: ResOperand,\n    },\n    /// Finds the two small arcs from within [(0,a),(a,b),(b,PRIME)] and writes it to the\n    /// range_check segment.\n    AssertLeFindSmallArcs {\n        range_check_ptr: ResOperand,\n        a: ResOperand,\n        b: ResOperand,\n    },\n    /// Writes if the arc (0,a) was excluded.\n    AssertLeIsFirstArcExcluded {\n        skip_exclude_a_flag: CellRef,\n    },\n    /// Writes if the arc (a,b) was excluded.\n    AssertLeIsSecondArcExcluded {\n        skip_exclude_b_minus_a: CellRef,\n    },\n    /// Asserts that the arc (b, PRIME) was excluded.\n    AssertLeAssertThirdArcExcluded,\n    /// Samples a random point on the EC.\n    RandomEcPoint {\n        x: CellRef,\n        y: CellRef,\n    },\n    /// Computes the square root of `val`, if `val` is a quadratic residue, and of `3 * val`\n    /// otherwise.\n    ///\n    /// Since 3 is not a quadratic residue, exactly one of `val` and `3 * val` is a quadratic\n    /// residue (unless `val` is 0). This allows proving that `val` is not a quadratic residue.\n    FieldSqrt {\n        val: ResOperand,\n        sqrt: CellRef,\n    },\n    /// Represents a hint that triggers a system call.\n    SystemCall {\n        system: ResOperand,\n    },\n    /// Prints the values from start to end.\n    /// Both must be pointers.\n    DebugPrint {\n        start: ResOperand,\n        end: ResOperand,\n    },\n    /// Returns an address with `size` free locations afterwards.\n    AllocConstantSize {\n        size: ResOperand,\n        dst: CellRef,\n    },\n    SetBlockNumber {\n        value: ResOperand,\n    },\n    SetBlockTimestamp {\n        value: ResOperand,\n    },\n    SetCallerAddress {\n        value: ResOperand,\n    },\n    SetContractAddress {\n        value: ResOperand,\n    },\n    SetSequencerAddress {\n        value: ResOperand,\n    },\n}\n\nstruct DerefOrImmediateFormatter<'a>(&'a DerefOrImmediate);\nimpl<'a> Display for DerefOrImmediateFormatter<'a> {\n    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {\n        match self.0 {\n            DerefOrImmediate::Deref(d) => write!(f, \"memory{d}\"),\n            DerefOrImmediate::Immediate(i) => write!(f, \"{}\", i.value),\n        }\n    }\n}\n\nstruct ResOperandFormatter<'a>(&'a ResOperand);\nimpl<'a> Display for ResOperandFormatter<'a> {\n    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {\n        match self.0 {\n            ResOperand::Deref(d) => write!(f, \"memory{d}\"),\n            ResOperand::DoubleDeref(d, i) => write!(f, \"memory[memory{d} + {i}]\"),\n            ResOperand::Immediate(i) => write!(f, \"{}\", i.value),\n            ResOperand::BinOp(bin_op) => {\n                write!(\n                    f,\n                    \"memory{} {} {}\",\n                    bin_op.a,\n                    bin_op.op,\n                    DerefOrImmediateFormatter(&bin_op.b)\n                )\n            }\n        }\n    }\n}\n\nimpl Display for Hint {\n    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {\n        match self {\n            Hint::AllocSegment { dst } => write!(f, \"memory{dst} = segments.add()\"),\n            Hint::AllocFelt252Dict { segment_arena_ptr } => {\n                let segment_arena_ptr = ResOperandFormatter(segment_arena_ptr);\n                writedoc!(\n                    f,\n                    \"\n\n                        if '__dict_manager' not in globals():\n                            from starkware.cairo.common.dict import DictManager\n                            __dict_manager = DictManager()\n\n                        if '__segment_index_to_arena_index' not in globals():\n                            # A map from the relocatable value segment index to the index in the\n                            # arena.\n                            __segment_index_to_arena_index = {{}}\n\n                        # {segment_arena_ptr} is the address of the next SegmentArenaBuiltin.\n                        # memory[{segment_arena_ptr} - 2] is the number of allocated segments.\n                        index = memory[{segment_arena_ptr} - 2]\n\n                        segment_start = __dict_manager.new_default_dict(\n                            segments, 0, temp_segment=index > 0\n                        )\n\n                        # Update '__segment_index_to_arena_index'.\n                        __segment_index_to_arena_index[segment_start.segment_index] = index\n\n                        # Update 'SegmentInfo::start'.\n                        # memory[{segment_arena_ptr} - 3] is the address of the segment arena infos\n                        # segment. index * 3 is added to get the address of the new SegmentInfo.\n                        memory[memory[{segment_arena_ptr} - 3] + index * 3] = segment_start\n                \"\n                )\n            }\n            // TODO(Gil): get the 3 from DictAccess or pass it as an argument.\n            Hint::Felt252DictRead { dict_ptr, key, value_dst } => {\n                let (dict_ptr, key) = (ResOperandFormatter(dict_ptr), ResOperandFormatter(key));\n                writedoc!(\n                    f,\n                    \"\n\n                        dict_tracker = __dict_manager.get_tracker({dict_ptr})\n                        dict_tracker.current_ptr += 3\n                        memory{value_dst} = dict_tracker.data[{key}]\n                    \"\n                )\n            }\n            Hint::Felt252DictWrite { dict_ptr, key, value } => {\n                let (dict_ptr, key, value) = (\n                    ResOperandFormatter(dict_ptr),\n                    ResOperandFormatter(key),\n                    ResOperandFormatter(value),\n                );\n                writedoc!(\n                    f,\n                    \"\n\n                        dict_tracker = __dict_manager.get_tracker({dict_ptr})\n                        memory[{dict_ptr} + 1] = dict_tracker.data[{key}]\n                        dict_tracker.current_ptr += 3\n                        dict_tracker.data[{key}] = {value}\n                    \"\n                )\n            }\n            Hint::TestLessThan { lhs, rhs, dst } => write!(\n                f,\n                \"memory{dst} = {} < {}\",\n                ResOperandFormatter(lhs),\n                ResOperandFormatter(rhs)\n            ),\n            Hint::TestLessThanOrEqual { lhs, rhs, dst } => write!(\n                f,\n                \"memory{dst} = {} <= {}\",\n                ResOperandFormatter(lhs),\n                ResOperandFormatter(rhs)\n            ),\n            Hint::DivMod { lhs, rhs, quotient, remainder } => write!(\n                f,\n                \"(memory{quotient}, memory{remainder}) = divmod({}, {})\",\n                ResOperandFormatter(lhs),\n                ResOperandFormatter(rhs)\n            ),\n            Hint::SquareRoot { value, dst } => {\n                write!(f, \"(memory{dst}) = sqrt({})\", ResOperandFormatter(value))\n            }\n            Hint::LinearSplit { value, scalar, max_x, x, y } => {\n                let (value, scalar, max_x) = (\n                    ResOperandFormatter(value),\n                    ResOperandFormatter(scalar),\n                    ResOperandFormatter(max_x),\n                );\n                writedoc!(\n                    f,\n                    \"\n\n                        (value, scalar) = ({value}, {scalar})\n                        x = min(value // scalar, {max_x})\n                        y = value - x * scalar\n                        memory{x} = x\n                        memory{y} = y\n                    \"\n                )\n            }\n            Hint::RandomEcPoint { x, y } => {\n                writedoc!(\n                    f,\n                    \"\n\n                        from starkware.crypto.signature.signature import ALPHA, BETA, FIELD_PRIME\n                        from starkware.python.math_utils import random_ec_point\n                        (memory{x}, memory{y}) = random_ec_point(FIELD_PRIME, ALPHA, BETA)\n                    \"\n                )\n            }\n            Hint::FieldSqrt { val, sqrt } => {\n                writedoc!(\n                    f,\n                    \"\n\n                        from starkware.crypto.signature.signature import FIELD_PRIME\n                        from starkware.python.math_utils import is_quad_residue, sqrt\n\n                        val = {}\n                        if is_quad_residue(val, FIELD_PRIME):\n                            memory{sqrt} = sqrt(val, FIELD_PRIME)\n                        else:\n                            memory{sqrt} = sqrt(val * 3, FIELD_PRIME)\n                        \",\n                    ResOperandFormatter(val)\n                )\n            }\n            Hint::SystemCall { system } => {\n                write!(f, \"syscall_handler.syscall(syscall_ptr={})\", ResOperandFormatter(system))\n            }\n            Hint::GetCurrentAccessIndex { range_check_ptr } => writedoc!(\n                f,\n                \"\n\n                    current_access_indices = sorted(access_indices[key])[::-1]\n                    current_access_index = current_access_indices.pop()\n                    memory[{}] = current_access_index\n                \",\n                ResOperandFormatter(range_check_ptr)\n            ),\n            Hint::ShouldSkipSquashLoop { should_skip_loop } => {\n                write!(f, \"memory{should_skip_loop} = 0 if current_access_indices else 1\")\n            }\n            Hint::GetCurrentAccessDelta { index_delta_minus1 } => writedoc!(\n                f,\n                \"\n\n                    new_access_index = current_access_indices.pop()\n                    memory{index_delta_minus1} = new_access_index - current_access_index - 1\n                    current_access_index = new_access_index\n                \"\n            ),\n            Hint::ShouldContinueSquashLoop { should_continue } => {\n                write!(f, \"memory{should_continue} = 1 if current_access_indices else 0\")\n            }\n            Hint::AssertCurrentAccessIndicesIsEmpty => {\n                write!(f, \"assert len(current_access_indices) == 0\")\n            }\n            Hint::AssertAllAccessesUsed { n_used_accesses } => {\n                write!(f, \"assert memory{n_used_accesses} == len(access_indices[key])\")\n            }\n            Hint::AssertAllKeysUsed => write!(f, \"assert len(keys) == 0\"),\n            Hint::GetNextDictKey { next_key } => writedoc!(\n                f,\n                \"\n                    assert len(keys) > 0, 'No keys left but remaining_accesses > 0.'\n                    memory{next_key} = key = keys.pop()\n                \"\n            ),\n            Hint::GetSegmentArenaIndex { dict_end_ptr, dict_index } => {\n                let dict_end_ptr = ResOperandFormatter(dict_end_ptr);\n                writedoc!(\n                    f,\n                    \"\n\n                    memory{dict_index} = __segment_index_to_arena_index[\n                        {dict_end_ptr}.segment_index\n                    ]\n                \"\n                )\n            }\n            Hint::InitSquashData { dict_accesses, ptr_diff, n_accesses, big_keys, first_key } => {\n                let (dict_accesses, ptr_diff, n_accesses) = (\n                    ResOperandFormatter(dict_accesses),\n                    ResOperandFormatter(ptr_diff),\n                    ResOperandFormatter(n_accesses),\n                );\n                writedoc!(\n                    f,\n                    \"\n\n                    dict_access_size = 3\n                    address = {dict_accesses}\n                    assert {ptr_diff} % dict_access_size == 0, 'Accesses array size must be \\\n                     divisible by DictAccess.SIZE'\n                    n_accesses = {n_accesses}\n                    if '__squash_dict_max_size' in globals():\n                        assert n_accesses <= __squash_dict_max_size, f'squash_dict() can only be \\\n                     used with n_accesses<={{__squash_dict_max_size}}. ' f'Got: \\\n                     n_accesses={{n_accesses}}.'\n                    # A map from key to the list of indices accessing it.\n                    access_indices = {{}}\n                    for i in range(n_accesses):\n                        key = memory[address + dict_access_size * i]\n                        access_indices.setdefault(key, []).append(i)\n                    # Descending list of keys.\n                    keys = sorted(access_indices.keys(), reverse=True)\n                    # Are the keys used bigger than range_check bound.\n                    memory{big_keys} = 1 if keys[0] >= range_check_builtin.bound else 0\n                    memory{first_key} = key = keys.pop()\n                \"\n                )\n            }\n            Hint::AssertLtAssertValidInput { a, b } => {\n                let (a, b) = (ResOperandFormatter(a), ResOperandFormatter(b));\n                writedoc!(\n                    f,\n                    \"\n\n                    from starkware.cairo.common.math_utils import assert_integer\n                    assert_integer({a})\n                    assert_integer({b})\n                    assert ({a} % PRIME) < ({b} % PRIME), f'a = {{{a} % PRIME}} is not less than b \\\n                     = {{{b} % PRIME}}.'\n                \"\n                )\n            }\n            Hint::AssertLeFindSmallArcs { range_check_ptr, a, b } => {\n                let (range_check_ptr, a, b) = (\n                    ResOperandFormatter(range_check_ptr),\n                    ResOperandFormatter(a),\n                    ResOperandFormatter(b),\n                );\n                writedoc!(\n                    f,\n                    \"\n\n                    import itertools\n\n                    from starkware.cairo.common.math_utils import assert_integer\n                    assert_integer({a})\n                    assert_integer({b})\n                    a = {a} % PRIME\n                    b = {b} % PRIME\n                    assert a <= b, f'a = {{a}} is not less than or equal to b = {{b}}.'\n\n                    # Find an arc less than PRIME / 3, and another less than PRIME / 2.\n                    lengths_and_indices = [(a, 0), (b - a, 1), (PRIME - 1 - b, 2)]\n                    lengths_and_indices.sort()\n                    assert lengths_and_indices[0][0] <= PRIME // 3 and lengths_and_indices[1][0] \\\n                     <= PRIME // 2\n                    excluded = lengths_and_indices[2][1]\n\n                    memory[{range_check_ptr} + 1], memory[{range_check_ptr} + 0] = (\n                        divmod(lengths_and_indices[0][0], 3544607988759775765608368578435044694))\n                    memory[{range_check_ptr} + 3], memory[{range_check_ptr} + 2] = (\n                        divmod(lengths_and_indices[1][0], 5316911983139663648412552867652567041))\n                \"\n                )\n            }\n            Hint::AssertLeIsFirstArcExcluded { skip_exclude_a_flag } => {\n                write!(f, \"memory{skip_exclude_a_flag} = 1 if excluded != 0 else 0\",)\n            }\n            Hint::AssertLeIsSecondArcExcluded { skip_exclude_b_minus_a } => {\n                write!(f, \"memory{skip_exclude_b_minus_a} = 1 if excluded != 1 else 0\",)\n            }\n            Hint::AssertLeAssertThirdArcExcluded => write!(f, \"assert excluded == 2\"),\n            Hint::DebugPrint { start, end } => writedoc!(\n                f,\n                \"\n\n                    start = {}\n                    end = {}\n                    for i in range(start, end):\n                        print(memory[i])\n                \",\n                ResOperandFormatter(start),\n                ResOperandFormatter(end),\n            ),\n            Hint::AllocConstantSize { size, dst } => {\n                writedoc!(\n                    f,\n                    \"\n\n                        if '__boxed_segment' not in globals():\n                            __boxed_segment = segments.add()\n                        memory{dst} = __boxed_segment\n                        __boxed_segment += {}\n                    \",\n                    ResOperandFormatter(size)\n                )\n            }\n            Hint::SetBlockNumber { value } => {\n                write!(f, \"syscall_handler.block_number = {}\", ResOperandFormatter(value))\n            }\n            Hint::SetBlockTimestamp { value } => {\n                write!(f, \"syscall_handler.block_timestamp = {}\", ResOperandFormatter(value))\n            }\n            Hint::SetCallerAddress { value } => {\n                write!(f, \"syscall_handler.caller_address = {}\", ResOperandFormatter(value))\n            }\n            Hint::SetContractAddress { value } => {\n                write!(f, \"syscall_handler.contract_address = {}\", ResOperandFormatter(value))\n            }\n            Hint::SetSequencerAddress { value } => {\n                write!(f, \"syscall_handler.sequencer_address = {}\", ResOperandFormatter(value))\n            }\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use indoc::indoc;\nuse test_log::test;\n\nuse crate::hints::Hint;\nuse crate::operand::{BinOpOperand, CellRef, DerefOrImmediate, Operation, Register, ResOperand};\nuse crate::res;\n\n#[test]\nfn test_alloc_segment_format() {\n    let dst = CellRef { register: Register::AP, offset: 5 };\n    let hint = Hint::AllocSegment { dst };\n\n    assert_eq!(hint.to_string(), \"memory[ap + 5] = segments.add()\");\n}\n\n#[test]\nfn test_less_than_format() {\n    let ap_based = res!([ap + 6]);\n    let fp_based = res!([fp + 4]);\n    let immediate = res!(3);\n\n    assert_eq!(\n        Hint::TestLessThan {\n            lhs: ap_based.clone(),\n            rhs: fp_based.clone(),\n            dst: CellRef { register: Register::AP, offset: 0 }\n        }\n        .to_string(),\n        \"memory[ap + 0] = memory[ap + 6] < memory[fp + 4]\"\n    );\n    assert_eq!(\n        Hint::TestLessThan {\n            lhs: fp_based,\n            rhs: immediate.clone(),\n            dst: CellRef { register: Register::AP, offset: 0 }\n        }\n        .to_string(),\n        \"memory[ap + 0] = memory[fp + 4] < 3\"\n    );\n    assert_eq!(\n        Hint::TestLessThan {\n            lhs: immediate,\n            rhs: ap_based,\n            dst: CellRef { register: Register::AP, offset: 0 }\n        }\n        .to_string(),\n        \"memory[ap + 0] = 3 < memory[ap + 6]\"\n    );\n}\n\n#[test]\nfn test_less_than_or_equal_format() {\n    let ap_based = res!([ap + 6]);\n    let fp_based = res!([fp + 4]);\n    let immediate = res!(3);\n\n    assert_eq!(\n        Hint::TestLessThanOrEqual {\n            lhs: ap_based.clone(),\n            rhs: fp_based.clone(),\n            dst: CellRef { register: Register::AP, offset: 0 }\n        }\n        .to_string(),\n        \"memory[ap + 0] = memory[ap + 6] <= memory[fp + 4]\"\n    );\n    assert_eq!(\n        Hint::TestLessThanOrEqual {\n            lhs: fp_based,\n            rhs: immediate.clone(),\n            dst: CellRef { register: Register::AP, offset: 0 }\n        }\n        .to_string(),\n        \"memory[ap + 0] = memory[fp + 4] <= 3\"\n    );\n    assert_eq!(\n        Hint::TestLessThanOrEqual {\n            lhs: immediate,\n            rhs: ap_based,\n            dst: CellRef { register: Register::AP, offset: 0 }\n        }\n        .to_string(),\n        \"memory[ap + 0] = 3 <= memory[ap + 6]\"\n    );\n}\n\n#[test]\nfn test_syscall_hint_format() {\n    let system = ResOperand::BinOp(BinOpOperand {\n        op: Operation::Add,\n        a: CellRef { register: Register::FP, offset: -3 },\n        b: DerefOrImmediate::from(3),\n    });\n\n    assert_eq!(\n        Hint::SystemCall { system }.to_string(),\n        \"syscall_handler.syscall(syscall_ptr=memory[fp + -3] + 3)\"\n    );\n}\n\n#[test]\nfn test_debug_hint_format() {\n    assert_eq!(\n        Hint::DebugPrint { start: res!([ap + 6]), end: res!([fp - 8]) }.to_string(),\n        indoc! {\"\n\n            start = memory[ap + 6]\n            end = memory[fp + -8]\n            for i in range(start, end):\n                print(memory[i])\n        \"}\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use crate::hints::Hint;\nuse crate::instructions::Instruction;\n\n#[cfg(test)]\n#[path = \"inline_test.rs\"]\nmod test;\n\n#[macro_export]\nmacro_rules! casm {\n    {$($tok:tt)*} => {\n        {\n            let mut ctx = $crate::inline::CasmContext::default();\n            $crate::casm_extend!(ctx, $($tok)*);\n            ctx\n        }\n    }\n}\n\n#[macro_export]\nmacro_rules! casm_extend {\n    ($ctx:ident,) => {};\n    ($ctx:ident, $dst:tt = $a:tt $(+ $b0:tt)? $(* $b1:tt)? $(,$ap:ident++)? ; $($tok:tt)*) => {\n        let body = $crate::instructions::InstructionBody::AssertEq(\n            $crate::instructions::AssertEqInstruction {\n                a: $crate::deref!($dst),\n                b: $crate::res!($a $(+ $b0)? $(* $b1)?),\n            }\n        );\n        $crate::append_instruction!($ctx, body $(,$ap++)?);\n        $crate::casm_extend!($ctx, $($tok)*)\n    };\n    ($ctx:ident, call rel $target:tt $(,$ap:ident++)? ; $($tok:tt)*) => {\n        let body = $crate::instructions::InstructionBody::Call(\n            $crate::instructions::CallInstruction {\n                target: $crate::deref_or_immediate!($target),\n                relative: true,\n            }\n        );\n        $crate::append_instruction!($ctx, body $(,$ap++)?);\n        $crate::casm_extend!($ctx, $($tok)*)\n    };\n    ($ctx:ident, call abs $target:tt $(,$ap:ident++)? ; $($tok:tt)*) => {\n        let body = $crate::instructions::InstructionBody::Call(\n            $crate::instructions::CallInstruction {\n                target: $crate::deref_or_immediate!($target),\n                relative: false,\n            }\n        );\n        $crate::append_instruction!($ctx, body $(,$ap++)?);\n        $crate::casm_extend!($ctx, $($tok)*)\n    };\n    ($ctx:ident, jmp rel $target:expr $(,$ap:ident++)? ; $($tok:tt)*) => {\n        let body = $crate::instructions::InstructionBody::Jump(\n            $crate::instructions::JumpInstruction {\n                target: $crate::deref_or_immediate!($target),\n                relative: true,\n            }\n        );\n        $crate::append_instruction!($ctx, body $(,$ap++)?);\n        $crate::casm_extend!($ctx, $($tok)*)\n    };\n    ($ctx:ident, jmp abs $target:tt $(,$ap:ident++)? ; $($tok:tt)*) => {\n        let body = $crate::instructions::InstructionBody::Jump(\n            $crate::instructions::JumpInstruction {\n                target: $crate::deref_or_immediate!($target),\n                relative: false,\n            }\n        );\n        $crate::append_instruction!($ctx, body $(,$ap++)?);\n        $crate::casm_extend!($ctx, $($tok)*)\n    };\n    ($ctx:ident, jmp rel $target:tt if $cond:tt != 0 $(,$ap:ident++)? ; $($tok:tt)*) => {\n        let body = $crate::instructions::InstructionBody::Jnz(\n            $crate::instructions::JnzInstruction {\n                jump_offset: $crate::deref_or_immediate!($target),\n                condition: $crate::deref!($cond),\n            }\n        );\n        $crate::append_instruction!($ctx, body $(,$ap++)?);\n        $crate::casm_extend!($ctx, $($tok)*)\n    };\n    ($ctx:ident, jmp $target:tt if $cond:tt != 0 $(,$ap:ident++)? ; $($tok:tt)*) => {\n        let body = $crate::instructions::InstructionBody::Jnz(\n            $crate::instructions::JnzInstruction {\n                jump_offset: $crate::deref_or_immediate!($target),\n                condition: $crate::deref!($cond),\n            }\n        );\n        $crate::append_instruction!($ctx, body $(,$ap++)?);\n        $crate::casm_extend!($ctx, $($tok)*)\n    };\n    ($ctx:ident, ap += $operand:tt $(,$ap:ident++)? ; $($tok:tt)*) => {\n        let body = $crate::instructions::InstructionBody::AddAp(\n            $crate::instructions::AddApInstruction { operand: $crate::res!($operand) }\n        );\n        $crate::append_instruction!($ctx, body $(,$ap++)?);\n        $crate::casm_extend!($ctx, $($tok)*)\n    };\n    ($ctx:ident, ret $(,$ap:ident++)? ; $($tok:tt)*) => {\n        let body = $crate::instructions::InstructionBody::Ret(\n            $crate::instructions::RetInstruction {}\n        );\n        $crate::append_instruction!($ctx, body $(,$ap++)?);\n        $crate::casm_extend!($ctx, $($tok)*)\n    };\n    ($ctx:ident, %{ memory $dst:tt = segments . add ( ) %} $($tok:tt)*) => {\n        $ctx.current_hints.push($crate::hints::Hint::AllocSegment{dst: $crate::deref!($dst)});\n        $crate::casm_extend!($ctx, $($tok)*)\n    };\n    ($ctx:ident, %{ memory $dst:tt = memory $lhs:tt < memory $rhs:tt %} $($tok:tt)*) => {\n        $ctx.current_hints.push($crate::hints::Hint::TestLessThan{\n            lhs: $crate::res!($lhs),\n            rhs: $crate::res!($rhs),\n            dst: $crate::deref!($dst),\n        });\n        $crate::casm_extend!($ctx, $($tok)*)\n    };\n    ($ctx:ident, %{ memory $dst:tt = memory $lhs:tt < $rhs:tt %} $($tok:tt)*) => {\n        $ctx.current_hints.push($crate::hints::Hint::TestLessThan{\n            lhs: $crate::res!($lhs),\n            rhs: $crate::res!($rhs),\n            dst: $crate::deref!($dst),\n        });\n        $crate::casm_extend!($ctx, $($tok)*)\n    };\n    ($ctx:ident, %{ memory $dst:tt = $lhs:tt < memory $rhs:tt %} $($tok:tt)*) => {\n        $ctx.current_hints.push($crate::hints::Hint::TestLessThan{\n            lhs: $crate::res!($lhs),\n            rhs: $crate::res!($rhs),\n            dst: $crate::deref!($dst),\n        });\n        $crate::casm_extend!($ctx, $($tok)*)\n    };\n    ($ctx:ident, %{ memory $dst:tt = memory $lhs:tt <= memory $rhs:tt %} $($tok:tt)*) => {\n        $ctx.current_hints.push($crate::hints::Hint::TestLessThanOrEqual{\n            lhs: $crate::res!($lhs),\n            rhs: $crate::res!($rhs),\n            dst: $crate::deref!($dst),\n        });\n        $crate::casm_extend!($ctx, $($tok)*)\n    };\n    ($ctx:ident, %{ memory $dst:tt = memory $lhs:tt <= $rhs:tt %} $($tok:tt)*) => {\n        $ctx.current_hints.push($crate::hints::Hint::TestLessThanOrEqual{\n            lhs: $crate::res!($lhs),\n            rhs: $crate::res!($rhs),\n            dst: $crate::deref!($dst),\n        });\n        $crate::casm_extend!($ctx, $($tok)*)\n    };\n    ($ctx:ident, %{ memory $dst:tt = $lhs:tt <= memory $rhs:tt %} $($tok:tt)*) => {\n        $ctx.current_hints.push($crate::hints::Hint::TestLessThanOrEqual{\n            lhs: $crate::res!($lhs),\n            rhs: $crate::res!($rhs),\n            dst: $crate::deref!($dst),\n        });\n        $crate::casm_extend!($ctx, $($tok)*)\n    };\n    ($ctx:ident, %{ ( memory $quotient:tt, memory $remainder:tt )\n         = divmod ( memory $lhs:tt , memory $rhs:tt ) %} $($tok:tt)*) => {\n        $ctx.current_hints.push($crate::hints::Hint::DivMod{\n            lhs: $crate::res!($lhs),\n            rhs: $crate::res!($rhs),\n            quotient: $crate::deref!($quotient),\n            remainder: $crate::deref!($remainder),\n        });\n        $crate::casm_extend!($ctx, $($tok)*)\n    };\n    ($ctx:ident, %{ ( memory $quotient:tt, memory $remainder:tt )\n         = divmod ( memory $lhs:tt , $rhs:tt ) %} $($tok:tt)*) => {\n        $ctx.current_hints.push($crate::hints::Hint::DivMod{\n            lhs: $crate::res!($lhs),\n            rhs: $crate::res!($rhs),\n            quotient: $crate::deref!($quotient),\n            remainder: $crate::deref!($remainder),\n        });\n        $crate::casm_extend!($ctx, $($tok)*)\n    };\n    ($ctx:ident, %{ ( memory $quotient:tt, memory $remainder:tt )\n         = divmod ( $lhs:tt , memory $rhs:tt ) %} $($tok:tt)*) => {\n        $ctx.current_hints.push($crate::hints::Hint::DivMod{\n            lhs: $crate::res!($lhs),\n            rhs: $crate::res!($rhs),\n            quotient: $crate::deref!($quotient),\n            remainder: $crate::deref!($remainder),\n        });\n        $crate::casm_extend!($ctx, $($tok)*)\n    };\n    ($ctx:ident, %{ ( memory $quotient:tt, memory $remainder:tt )\n         = divmod ( $lhs:tt , $rhs:tt ) %} $($tok:tt)*) => {\n        $ctx.current_hints.push($crate::hints::Hint::DivMod{\n            lhs: $crate::res!($lhs),\n            rhs: $crate::res!($rhs),\n            quotient: $crate::deref!($quotient),\n            remainder: $crate::deref!($remainder),\n        });\n        $crate::casm_extend!($ctx, $($tok)*)\n    };\n    ($ctx:ident, %{ syscall_handler.syscall(syscall_ptr=memory $addr:tt + $offset:tt) %} $($tok:tt)*) => {\n        $ctx.current_hints.push($crate::hints::Hint::SystemCall {\n            system: $crate::operand::ResOperand::BinOp($crate::operand::BinOpOperand {\n                op: cairo_lang_casm::operand::Operation::Add,\n                a: $crate::deref!($addr),\n                b: $crate::deref_or_immediate!(num_bigint::BigInt::from($offset)),\n            })});\n        $crate::casm_extend!($ctx, $($tok)*)\n    };\n    ($ctx:ident, %{ syscall_handler.syscall(syscall_ptr=memory $addr:tt) %} $($tok:tt)*) => {\n        $ctx.current_hints.push($crate::hints::Hint::SystemCall {\n            system: $crate::operand::ResOperand::Deref($crate::deref!($addr))\n        });\n        $crate::casm_extend!($ctx, $($tok)*)\n    };\n}\n\n#[macro_export]\nmacro_rules! append_instruction {\n    ($ctx:ident, $body:ident $(,$ap:ident++)?) => {\n        let instr = $crate::instructions::Instruction {\n            body: $body,\n            inc_ap: $crate::is_inc_ap!($($ap++)?),\n            hints: $ctx.current_hints,\n        };\n        $ctx.current_code_offset += instr.body.op_size();\n        $ctx.current_hints = vec![];\n        $ctx.instructions.push(instr);\n    };\n}\n\n#[macro_export]\nmacro_rules! is_inc_ap {\n    () => {\n        false\n    };\n    (ap + +) => {\n        true\n    };\n}\n\n#[allow(dead_code)]\n#[derive(Default)]\npub struct CasmContext {\n    pub current_code_offset: usize,\n    pub current_hints: Vec<Hint>,\n    pub instructions: Vec<Instruction>,\n    // TODO(spapini): Branches.\n    // TODO(spapini): Relocations.\n}\n\n#[macro_export]\nmacro_rules! deref {\n    ([ap + $offset:expr]) => {\n        $crate::operand::CellRef { register: $crate::reg!(ap), offset: $offset }\n    };\n    ([fp + $offset:expr]) => {\n        $crate::operand::CellRef { register: $crate::reg!(fp), offset: $offset }\n    };\n    ([& $var:ident + $offset:expr]) => {\n        $crate::operand::CellRef { register: $var.register, offset: $var.offset + $offset }\n    };\n    ([ap - $offset:expr]) => {\n        $crate::operand::CellRef { register: $crate::reg!(ap), offset: -$offset }\n    };\n    ([fp - $offset:expr]) => {\n        $crate::operand::CellRef { register: $crate::reg!(fp), offset: -$offset }\n    };\n    ([& $var:ident - $offset:expr]) => {\n        $crate::operand::CellRef { register: $var.register, offset: $var.offset - $offset }\n    };\n    ([ap]) => {\n        $crate::operand::CellRef { register: $crate::reg!(ap), offset: 0 }\n    };\n    ([fp]) => {\n        $crate::operand::CellRef { register: $crate::reg!(fp), offset: 0 }\n    };\n    ([& $var:ident]) => {\n        $var\n    };\n    ($a:expr) => {\n        $a\n    };\n}\n\n#[macro_export]\nmacro_rules! reg {\n    (ap) => {\n        $crate::operand::Register::AP\n    };\n    (fp) => {\n        $crate::operand::Register::FP\n    };\n}\n\n#[macro_export]\nmacro_rules! deref_or_immediate {\n    ([$a:ident $($op:tt $offset:expr)?]) => {\n        $crate::operand::DerefOrImmediate::Deref($crate::deref!([$a $($op $offset)?]))\n    };\n    ($a:expr) => {\n        $crate::operand::DerefOrImmediate::from($a)\n    };\n}\n\n#[macro_export]\nmacro_rules! res {\n    ($a:tt + $b:tt) => {\n        $crate::operand::ResOperand::BinOp($crate::operand::BinOpOperand {\n            op: $crate::operand::Operation::Add,\n            a: $crate::deref!($a),\n            b: $crate::deref_or_immediate!($b),\n        })\n    };\n    ($a:tt * $b:tt) => {\n        $crate::operand::ResOperand::BinOp($crate::operand::BinOpOperand {\n            op: $crate::operand::Operation::Mul,\n            a: $crate::deref!($a),\n            b: $crate::deref_or_immediate!($b),\n        })\n    };\n    ([[ap $($op:tt $offset:expr)?]]) => {\n        $crate::operand::ResOperand::DoubleDeref($crate::deref!([ap $($op $offset)?]), 0)\n    };\n    ([[ap $($op:tt $offset:expr)?] + $outer:expr]) => {\n        $crate::operand::ResOperand::DoubleDeref($crate::deref!([ap $($op $offset)?]), $outer)\n    };\n    ([[ap $($op:tt $offset:expr)?] - $outer:expr]) => {\n        $crate::operand::ResOperand::DoubleDeref($crate::deref!([ap $($op $offset)?]), -$outer)\n    };\n    ([[fp $($op:tt $offset:expr)?]]) => {\n        $crate::operand::ResOperand::DoubleDeref($crate::deref!([fp $($op $offset)?]), 0)\n    };\n    ([[fp $($op:tt $offset:expr)?] + $outer:expr]) => {\n        $crate::operand::ResOperand::DoubleDeref($crate::deref!([fp $($op $offset)?]), $outer)\n    };\n    ([[fp $($op:tt $offset:expr)?] - $outer:expr]) => {\n        $crate::operand::ResOperand::DoubleDeref($crate::deref!([fp $($op $offset)?]), -$outer)\n    };\n    ([[&$a:expr]]) => {\n        $crate::operand::ResOperand::DoubleDeref($a, 0)\n    };\n    ([[&$a:expr] + $b:expr]) => {\n        $crate::operand::ResOperand::DoubleDeref($a, $b)\n    };\n    ($a:tt) => {\n        $crate::operand::ResOperand::from($crate::deref_or_immediate!($a))\n    };\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use indoc::indoc;\nuse itertools::join;\nuse pretty_assertions::assert_eq;\nuse test_log::test;\n\nuse crate::instructions::Instruction;\nuse crate::{casm, deref};\n\n#[test]\nfn test_assert() {\n    let x = 1;\n    let y = deref!([fp + 5]);\n    let z = 5;\n\n    let ctx = casm! {\n        [fp - 5] = x, ap++;\n        [fp - 5] = [ap + 1] + [fp - 5], ap++;\n        [fp + 5] = [ap + 1] + 2;\n        [ap + 5] = [[ap + 1] + 2];\n        [ap + 5] = [[ap - 1] + 2];\n        [ap + 5] = [[ap + 1] - 2];\n        [ap + 5] = [[ap] + 2];\n        [ap + 5] = [[ap + 1]];\n        [ap + 5] = [[ap]];\n        [ap] = [ap + 1] * [fp - 5];\n        %{ memory[ap + 5] = segments.add() %}\n        [fp - 5] = [ap + 1] * z;\n        [fp - 5] = [ap + 1] * y;\n        %{ memory[ap + 0] = memory[fp - 3] < 45 %}\n        %{ memory[ap + 0] = 13 < memory[fp + 9] %}\n        [fp - 5] = 1, ap++;\n        [fp - 5] = [ap + 1];\n        %{ memory[ap + 0] = memory[ap + 9] < memory[fp + 9] %}\n        jmp 123 if [ap + 17] != 0;\n        jmp rel [fp - 19] if [ap + 17] != 0;\n        %{ (memory[ap + 0], memory[ap + 1]) = divmod(memory[ap + 9], memory[fp + 9]) %}\n        %{ (memory[ap + 0], memory[ap + 1]) = divmod(50, memory[fp + 9]) %}\n        %{ (memory[ap + 0], memory[ap + 1]) = divmod(memory[ap + 9], 2) %}\n        call abs 5, ap++;\n        call rel y, ap++;\n        ret;\n    };\n\n    let code = join(ctx.instructions.iter().map(Instruction::to_string), \"\\n\");\n    assert_eq!(\n        code,\n        indoc! {\"\n            [fp + -5] = 1, ap++\n            [fp + -5] = [ap + 1] + [fp + -5], ap++\n            [fp + 5] = [ap + 1] + 2\n            [ap + 5] = [[ap + 1] + 2]\n            [ap + 5] = [[ap + -1] + 2]\n            [ap + 5] = [[ap + 1] + -2]\n            [ap + 5] = [[ap + 0] + 2]\n            [ap + 5] = [[ap + 1] + 0]\n            [ap + 5] = [[ap + 0] + 0]\n            [ap + 0] = [ap + 1] * [fp + -5]\n            %{ memory[ap + 5] = segments.add() %}\n            [fp + -5] = [ap + 1] * 5\n            [fp + -5] = [ap + 1] * [fp + 5]\n            %{ memory[ap + 0] = memory[fp + -3] < 45 %}\n            %{ memory[ap + 0] = 13 < memory[fp + 9] %}\n            [fp + -5] = 1, ap++\n            [fp + -5] = [ap + 1]\n            %{ memory[ap + 0] = memory[ap + 9] < memory[fp + 9] %}\n            jmp rel 123 if [ap + 17] != 0\n            jmp rel [fp + -19] if [ap + 17] != 0\n            %{ (memory[ap + 0], memory[ap + 1]) = divmod(memory[ap + 9], memory[fp + 9]) %}\n            %{ (memory[ap + 0], memory[ap + 1]) = divmod(50, memory[fp + 9]) %}\n            %{ (memory[ap + 0], memory[ap + 1]) = divmod(memory[ap + 9], 2) %}\n            call abs 5, ap++\n            call rel [fp + 5], ap++\n            ret\"}\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::fmt::Display;\nuse std::vec;\n\nuse crate::hints::Hint;\nuse crate::operand::{CellRef, DerefOrImmediate, ResOperand};\n\n#[cfg(test)]\n#[path = \"instructions_test.rs\"]\nmod test;\n\n// An enum of Cairo instructions.\n#[derive(Debug, Eq, PartialEq)]\npub enum InstructionBody {\n    AddAp(AddApInstruction),\n    AssertEq(AssertEqInstruction),\n    Call(CallInstruction),\n    Jnz(JnzInstruction),\n    Jump(JumpInstruction),\n    Ret(RetInstruction),\n}\nimpl InstructionBody {\n    pub fn op_size(&self) -> usize {\n        // TODO(spapini): Make this correct.\n        match self {\n            InstructionBody::AddAp(insn) => insn.op_size(),\n            InstructionBody::AssertEq(insn) => insn.op_size(),\n            InstructionBody::Call(insn) => insn.op_size(),\n            InstructionBody::Jump(insn) => insn.op_size(),\n            InstructionBody::Jnz(insn) => insn.op_size(),\n            InstructionBody::Ret(insn) => insn.op_size(),\n        }\n    }\n}\nimpl Display for InstructionBody {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            InstructionBody::AddAp(insn) => write!(f, \"{insn}\",),\n            InstructionBody::AssertEq(insn) => write!(f, \"{insn}\",),\n            InstructionBody::Call(insn) => write!(f, \"{insn}\",),\n            InstructionBody::Jnz(insn) => write!(f, \"{insn}\",),\n            InstructionBody::Jump(insn) => write!(f, \"{insn}\",),\n            InstructionBody::Ret(insn) => write!(f, \"{insn}\",),\n        }\n    }\n}\n\n/// Represents an instruction, including the ap++ flag (inc_ap).\n#[derive(Debug, Eq, PartialEq)]\npub struct Instruction {\n    pub body: InstructionBody,\n    pub inc_ap: bool,\n    pub hints: Vec<Hint>,\n}\nimpl Instruction {\n    pub fn new(body: InstructionBody, inc_ap: bool) -> Self {\n        Self { body, inc_ap, hints: vec![] }\n    }\n}\n\nimpl Display for Instruction {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        for hint in &self.hints {\n            let hint_str = hint.to_string();\n            // Skip leading and trailing space if hint starts with `\\n`.\n            if hint_str.starts_with('\\n') {\n                writeln!(f, \"%{{{hint_str}%}}\")\n            } else {\n                writeln!(f, \"%{{ {hint_str} %}}\")\n            }?\n        }\n\n        write!(f, \"{}\", self.body)?;\n        if self.inc_ap {\n            write!(f, \", ap++\")?\n        };\n        Ok(())\n    }\n}\n\n/// Represents a call instruction \"call rel/abs target\".\n#[derive(Debug, Eq, PartialEq)]\npub struct CallInstruction {\n    pub target: DerefOrImmediate,\n    pub relative: bool,\n}\nimpl Display for CallInstruction {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        write!(f, \"call {} {}\", if self.relative { \"rel\" } else { \"abs\" }, self.target,)\n    }\n}\nimpl CallInstruction {\n    pub fn op_size(&self) -> usize {\n        match &self.target {\n            DerefOrImmediate::Deref(_) => 1,\n            DerefOrImmediate::Immediate(_) => 2,\n        }\n    }\n}\n\n/// Represents the InstructionBody \"jmp rel/abs target\".\n#[derive(Debug, Eq, PartialEq)]\npub struct JumpInstruction {\n    pub target: DerefOrImmediate,\n    pub relative: bool,\n}\nimpl JumpInstruction {\n    pub fn op_size(&self) -> usize {\n        match &self.target {\n            DerefOrImmediate::Deref(_) => 1,\n            DerefOrImmediate::Immediate(_) => 2,\n        }\n    }\n}\nimpl Display for JumpInstruction {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        write!(f, \"jmp {} {}\", if self.relative { \"rel\" } else { \"abs\" }, self.target,)\n    }\n}\n\n/// Represents the InstructionBody \"jmp rel <jump_offset> if condition != 0\".\n#[derive(Debug, Eq, PartialEq)]\npub struct JnzInstruction {\n    pub jump_offset: DerefOrImmediate,\n    pub condition: CellRef,\n}\nimpl JnzInstruction {\n    pub fn op_size(&self) -> usize {\n        match &self.jump_offset {\n            DerefOrImmediate::Deref(_) => 1,\n            DerefOrImmediate::Immediate(_) => 2,\n        }\n    }\n}\nimpl Display for JnzInstruction {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        write!(f, \"jmp rel {} if {} != 0\", self.jump_offset, self.condition)\n    }\n}\n\n/// Returns the size of instruction based on whether the res operand includes an immediate or not.\npub fn op_size_based_on_res_operands(operand: &ResOperand) -> usize {\n    match operand {\n        ResOperand::Deref(_) => 1,\n        ResOperand::DoubleDeref(_, _) => 1,\n        ResOperand::Immediate(_) => 2,\n        ResOperand::BinOp(op) => match op.b {\n            DerefOrImmediate::Immediate(_) => 2,\n            DerefOrImmediate::Deref(_) => 1,\n        },\n    }\n}\n\n/// Represents the InstructionBody \"a = b\" for two operands a, b.\n#[derive(Debug, Eq, PartialEq)]\npub struct AssertEqInstruction {\n    pub a: CellRef,\n    pub b: ResOperand,\n}\nimpl AssertEqInstruction {\n    pub fn op_size(&self) -> usize {\n        op_size_based_on_res_operands(&self.b)\n    }\n}\nimpl Display for AssertEqInstruction {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        write!(f, \"{} = {}\", self.a, self.b)\n    }\n}\n\n/// Represents a return instruction, \"ret\".\n#[derive(Debug, Eq, PartialEq)]\npub struct RetInstruction {}\nimpl Display for RetInstruction {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        write!(f, \"ret\")\n    }\n}\n\nimpl RetInstruction {\n    pub fn op_size(&self) -> usize {\n        1\n    }\n}\n\n/// Represents the InstructionBody \"ap += op\" for a given operand op.\n#[derive(Debug, Eq, PartialEq)]\npub struct AddApInstruction {\n    pub operand: ResOperand,\n}\nimpl AddApInstruction {\n    pub fn op_size(&self) -> usize {\n        op_size_based_on_res_operands(&self.operand)\n    }\n}\nimpl Display for AddApInstruction {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        write!(f, \"ap += {}\", self.operand)\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use indoc::indoc;\nuse test_log::test;\n\nuse crate::hints::Hint;\nuse crate::instructions::{\n    AddApInstruction, AssertEqInstruction, CallInstruction, Instruction, InstructionBody,\n    JnzInstruction, JumpInstruction, RetInstruction,\n};\nuse crate::operand::{CellRef, DerefOrImmediate, Register, ResOperand};\n\n#[test]\nfn test_jump_format() {\n    let abs_jmp_insn = Instruction::new(\n        InstructionBody::Jump(JumpInstruction {\n            target: DerefOrImmediate::from(3),\n            relative: false,\n        }),\n        false,\n    );\n\n    assert_eq!(abs_jmp_insn.to_string(), \"jmp abs 3\");\n\n    let rel_jmp_insn = Instruction::new(\n        InstructionBody::Jump(JumpInstruction {\n            target: DerefOrImmediate::from(-5),\n            relative: true,\n        }),\n        true,\n    );\n\n    assert_eq!(rel_jmp_insn.to_string(), \"jmp rel -5, ap++\");\n}\n\n#[test]\nfn test_call_format() {\n    let abs_call_insn = CallInstruction { target: DerefOrImmediate::from(3), relative: false };\n\n    assert_eq!(abs_call_insn.to_string(), \"call abs 3\");\n\n    let rel_call_insn: InstructionBody = InstructionBody::Call(CallInstruction {\n        target: DerefOrImmediate::from(-5),\n        relative: true,\n    });\n\n    assert_eq!(rel_call_insn.to_string(), \"call rel -5\");\n}\n\n#[test]\nfn test_jnz_format() {\n    let jnz_insn = JnzInstruction {\n        jump_offset: DerefOrImmediate::from(205),\n        condition: CellRef { register: Register::AP, offset: 5 },\n    };\n\n    assert_eq!(jnz_insn.to_string(), \"jmp rel 205 if [ap + 5] != 0\");\n}\n\n#[test]\nfn test_assert_eq_format() {\n    let op1 = CellRef { register: Register::AP, offset: 5 };\n    let op2 = ResOperand::from(205);\n\n    let insn = AssertEqInstruction { a: op1, b: op2 };\n    assert_eq!(insn.to_string(), \"[ap + 5] = 205\");\n}\n\n#[test]\nfn test_ret_format() {\n    let insn = RetInstruction {};\n    assert_eq!(insn.to_string(), \"ret\");\n}\n\n#[test]\nfn test_add_ap_format() {\n    let operand = ResOperand::from(205);\n\n    let addap_insn: InstructionBody = InstructionBody::AddAp(AddApInstruction { operand });\n\n    assert_eq!(addap_insn.to_string(), \"ap += 205\");\n}\n\n#[test]\nfn test_instruction_with_hint() {\n    let dst = CellRef { register: Register::AP, offset: 5 };\n    let abs_jmp_insn = Instruction {\n        body: InstructionBody::Jump(JumpInstruction {\n            target: DerefOrImmediate::from(3),\n            relative: false,\n        }),\n        inc_ap: false,\n        hints: vec![Hint::AllocSegment { dst }],\n    };\n\n    assert_eq!(\n        abs_jmp_insn.to_string(),\n        indoc! {\"\n            %{ memory[ap + 5] = segments.add() %}\n            jmp abs 3\"\n        }\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Cairo assembly representation, formatting and construction utilities.\n\npub mod ap_change;\npub mod assembler;\npub mod builder;\npub mod cell_expression;\npub mod encoder;\npub mod hints;\npub mod inline;\npub mod instructions;\npub mod operand;\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::fmt::Display;\n\nuse cairo_lang_utils::bigint::BigIntAsHex;\nuse serde::{Deserialize, Serialize};\n\n#[cfg(test)]\n#[path = \"operand_test.rs\"]\nmod test;\n\n#[derive(Copy, Clone, Debug, Hash, PartialEq, Eq, Serialize, Deserialize)]\npub enum Register {\n    AP,\n    FP,\n}\nimpl Display for Register {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            Register::AP => write!(f, \"ap\"),\n            Register::FP => write!(f, \"fp\"),\n        }\n    }\n}\n\n// Represents the rhs operand of an assert equal InstructionBody.\n#[derive(Serialize, Deserialize, Clone, Debug, Eq, PartialEq)]\npub enum ResOperand {\n    Deref(CellRef),\n    DoubleDeref(CellRef, i16),\n    Immediate(BigIntAsHex),\n    BinOp(BinOpOperand),\n}\nimpl Display for ResOperand {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            ResOperand::Deref(operand) => write!(f, \"{operand}\"),\n            ResOperand::DoubleDeref(operand, offset) => write!(f, \"[{operand} + {offset}]\"),\n            ResOperand::Immediate(operand) => write!(f, \"{}\", operand.value),\n            ResOperand::BinOp(operand) => write!(f, \"{operand}\"),\n        }\n    }\n}\nimpl From<DerefOrImmediate> for ResOperand {\n    fn from(x: DerefOrImmediate) -> Self {\n        match x {\n            DerefOrImmediate::Deref(deref) => ResOperand::Deref(deref),\n            DerefOrImmediate::Immediate(imm) => ResOperand::Immediate(imm),\n        }\n    }\n}\n\nimpl<T: Into<BigIntAsHex>> From<T> for ResOperand {\n    fn from(imm: T) -> Self {\n        ResOperand::Immediate(imm.into())\n    }\n}\n\n/// Represents an operand of the form [reg + offset].\n#[derive(Serialize, Deserialize, Copy, Clone, Debug, Eq, PartialEq)]\npub struct CellRef {\n    pub register: Register,\n    pub offset: i16,\n}\nimpl Display for CellRef {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        write!(f, \"[{} + {}]\", self.register, self.offset)\n    }\n}\n\n/// Returns an AP DerefOperand with the given offset.\npub fn ap_cell_ref(offset: i16) -> CellRef {\n    CellRef { register: Register::AP, offset }\n}\n\n#[derive(Serialize, Deserialize, Clone, Debug, Eq, PartialEq)]\npub enum DerefOrImmediate {\n    Deref(CellRef),\n    Immediate(BigIntAsHex),\n}\nimpl Display for DerefOrImmediate {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            DerefOrImmediate::Deref(operand) => write!(f, \"{operand}\"),\n            DerefOrImmediate::Immediate(operand) => write!(f, \"{}\", operand.value),\n        }\n    }\n}\nimpl<T: Into<BigIntAsHex>> From<T> for DerefOrImmediate {\n    fn from(x: T) -> Self {\n        DerefOrImmediate::Immediate(x.into())\n    }\n}\nimpl From<CellRef> for DerefOrImmediate {\n    fn from(x: CellRef) -> Self {\n        DerefOrImmediate::Deref(x)\n    }\n}\n\n#[derive(Serialize, Deserialize, Clone, Debug, Eq, PartialEq)]\npub enum Operation {\n    Add,\n    Mul,\n}\nimpl Display for Operation {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            Operation::Add => write!(f, \"+\"),\n            Operation::Mul => write!(f, \"*\"),\n        }\n    }\n}\n\n#[derive(Serialize, Deserialize, Clone, Debug, Eq, PartialEq)]\npub struct BinOpOperand {\n    pub op: Operation,\n    pub a: CellRef,\n    pub b: DerefOrImmediate,\n}\nimpl Display for BinOpOperand {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        write!(f, \"{} {} {}\", self.a, self.op, self.b)\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use test_log::test;\n\nuse super::{BinOpOperand, DerefOrImmediate, Operation};\nuse crate::operand::{CellRef, Register, ResOperand};\n\n#[test]\nfn test_deref_operand_format() {\n    assert_eq!(CellRef { register: Register::AP, offset: 5 }.to_string(), \"[ap + 5]\");\n\n    assert_eq!(CellRef { register: Register::FP, offset: -3 }.to_string(), \"[fp + -3]\");\n}\n\n#[test]\nfn test_double_deref_op_format() {\n    assert_eq!(\n        ResOperand::DoubleDeref(CellRef { register: Register::AP, offset: 5 }, 12).to_string(),\n        \"[[ap + 5] + 12]\"\n    );\n}\n\n#[test]\nfn test_immediate_format() {\n    assert_eq!(DerefOrImmediate::from(1400).to_string(), \"1400\");\n}\n\n#[test]\nfn test_bin_op_format() {\n    let bin_op = BinOpOperand {\n        op: Operation::Mul,\n        a: CellRef { register: Register::FP, offset: -3 },\n        b: DerefOrImmediate::from(1400),\n    };\n    assert_eq!(bin_op.to_string(), \"[fp + -3] * 1400\")\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::fs;\nuse std::path::PathBuf;\n\nuse anyhow::Context;\nuse cairo_lang_compiler::{compile_cairo_project_at_path, CompilerConfig};\nuse cairo_lang_utils::logging::init_logging;\nuse clap::Parser;\n\n/// Command line args parser.\n/// Exits with 0/1 if the input is formatted correctly/incorrectly.\n#[derive(Parser, Debug)]\n#[clap(version, verbatim_doc_comment)]\nstruct Args {\n    /// The file to compile\n    path: PathBuf,\n    /// The output file name (default: stdout).\n    output: Option<String>,\n    /// Replaces sierra ids with human-readable ones.\n    #[arg(short, long, default_value_t = false)]\n    replace_ids: bool,\n}\n\nfn main() -> anyhow::Result<()> {\n    init_logging(log::LevelFilter::Off);\n    log::info!(\"Starting Cairo compilation.\");\n\n    let args = Args::parse();\n\n    let sierra_program = compile_cairo_project_at_path(\n        &args.path,\n        CompilerConfig { replace_ids: args.replace_ids, ..CompilerConfig::default() },\n    )?;\n\n    match args.output {\n        Some(path) => {\n            fs::write(path, format!(\"{sierra_program}\")).context(\"Failed to write output.\")?\n        }\n        None => println!(\"{sierra_program}\"),\n    }\n\n    Ok(())\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse anyhow::{anyhow, Result};\nuse cairo_lang_defs::db::{DefsDatabase, DefsGroup, HasMacroPlugins};\nuse cairo_lang_defs::plugin::MacroPlugin;\nuse cairo_lang_filesystem::db::{\n    init_dev_corelib, init_files_group, AsFilesGroupMut, FilesDatabase, FilesGroup, FilesGroupEx,\n    CORELIB_CRATE_NAME,\n};\nuse cairo_lang_filesystem::detect::detect_corelib;\nuse cairo_lang_filesystem::ids::CrateLongId;\nuse cairo_lang_lowering::db::{init_lowering_group, LoweringDatabase, LoweringGroup};\nuse cairo_lang_parser::db::ParserDatabase;\nuse cairo_lang_plugins::get_default_plugins;\nuse cairo_lang_project::ProjectConfig;\nuse cairo_lang_semantic::corelib::get_core_ty_by_name;\nuse cairo_lang_semantic::db::{SemanticDatabase, SemanticGroup, SemanticGroupEx};\nuse cairo_lang_semantic::plugin::SemanticPlugin;\nuse cairo_lang_sierra_generator::db::SierraGenDatabase;\nuse cairo_lang_syntax::node::db::{SyntaxDatabase, SyntaxGroup};\nuse cairo_lang_utils::Upcast;\n\nuse crate::project::update_crate_roots_from_project_config;\n\n#[salsa::database(\n    DefsDatabase,\n    FilesDatabase,\n    LoweringDatabase,\n    ParserDatabase,\n    SemanticDatabase,\n    SierraGenDatabase,\n    SyntaxDatabase\n)]\npub struct RootDatabase {\n    storage: salsa::Storage<RootDatabase>,\n}\nimpl salsa::Database for RootDatabase {}\nimpl RootDatabase {\n    pub fn new(plugins: Vec<Arc<dyn SemanticPlugin>>) -> Self {\n        let mut res = Self { storage: Default::default() };\n        init_files_group(&mut res);\n        init_lowering_group(&mut res);\n        res.set_semantic_plugins(plugins);\n        res\n    }\n\n    pub fn empty() -> Self {\n        Self::new(Vec::new())\n    }\n\n    pub fn builder() -> RootDatabaseBuilder {\n        RootDatabaseBuilder::default()\n    }\n\n    /// Snapshots the db for read only.\n    pub fn snapshot(&self) -> RootDatabase {\n        RootDatabase { storage: self.storage.snapshot() }\n    }\n}\n\nimpl Default for RootDatabase {\n    fn default() -> Self {\n        // TODO(spapini): Consider taking from config.\n        Self::new(get_default_plugins())\n    }\n}\n\n#[derive(Clone, Debug, Default)]\npub struct RootDatabaseBuilder {\n    plugins: Option<Vec<Arc<dyn SemanticPlugin>>>,\n    detect_corelib: bool,\n    project_config: Option<Box<ProjectConfig>>,\n    implicit_precedence: Option<Vec<String>>,\n}\n\nimpl RootDatabaseBuilder {\n    pub fn empty() -> Self {\n        Default::default()\n    }\n\n    pub fn with_plugins(&mut self, plugins: Vec<Arc<dyn SemanticPlugin>>) -> &mut Self {\n        self.plugins = Some(plugins);\n        self\n    }\n\n    pub fn detect_corelib(&mut self) -> &mut Self {\n        self.detect_corelib = true;\n        self\n    }\n\n    pub fn with_project_config(&mut self, config: ProjectConfig) -> &mut Self {\n        self.project_config = Some(Box::new(config));\n        self\n    }\n\n    pub fn with_implicit_precedence(&mut self, precedence: &[impl ToString]) -> &mut Self {\n        self.implicit_precedence = Some(precedence.iter().map(ToString::to_string).collect());\n        self\n    }\n\n    pub fn build(&mut self) -> Result<RootDatabase> {\n        // NOTE: Order of operations matters here!\n        //   Errors if something is not OK are very subtle, mostly this results in missing\n        //   identifier diagnostics, or panics regarding lack of corelib items.\n\n        let mut db = RootDatabase::default();\n\n        if self.detect_corelib {\n            let path =\n                detect_corelib().ok_or_else(|| anyhow!(\"Failed to find development corelib.\"))?;\n            init_dev_corelib(&mut db, path);\n        }\n\n        if let Some(config) = self.project_config.clone() {\n            update_crate_roots_from_project_config(&mut db, *config.clone());\n\n            if let Some(corelib) = config.corelib {\n                let core_crate = db.intern_crate(CrateLongId(CORELIB_CRATE_NAME.into()));\n                db.set_crate_root(core_crate, Some(corelib));\n            }\n        }\n\n        if let Some(precedence) = self.implicit_precedence.clone() {\n            db.set_implicit_precedence(Arc::new(\n                precedence\n                    .into_iter()\n                    .map(|name| get_core_ty_by_name(&db, name.into(), vec![]))\n                    .collect::<Vec<_>>(),\n            ));\n        }\n\n        if let Some(plugins) = self.plugins.clone() {\n            db.set_semantic_plugins(plugins);\n        }\n\n        Ok(db)\n    }\n}\n\nimpl AsFilesGroupMut for RootDatabase {\n    fn as_files_group_mut(&mut self) -> &mut (dyn FilesGroup + 'static) {\n        self\n    }\n}\nimpl Upcast<dyn FilesGroup> for RootDatabase {\n    fn upcast(&self) -> &(dyn FilesGroup + 'static) {\n        self\n    }\n}\nimpl Upcast<dyn SyntaxGroup> for RootDatabase {\n    fn upcast(&self) -> &(dyn SyntaxGroup + 'static) {\n        self\n    }\n}\nimpl Upcast<dyn DefsGroup> for RootDatabase {\n    fn upcast(&self) -> &(dyn DefsGroup + 'static) {\n        self\n    }\n}\nimpl Upcast<dyn SemanticGroup> for RootDatabase {\n    fn upcast(&self) -> &(dyn SemanticGroup + 'static) {\n        self\n    }\n}\nimpl Upcast<dyn LoweringGroup> for RootDatabase {\n    fn upcast(&self) -> &(dyn LoweringGroup + 'static) {\n        self\n    }\n}\nimpl HasMacroPlugins for RootDatabase {\n    fn macro_plugins(&self) -> Vec<Arc<dyn MacroPlugin>> {\n        self.get_macro_plugins()\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_defs::db::DefsGroup;\nuse cairo_lang_defs::ids::ModuleId;\nuse cairo_lang_filesystem::db::FilesGroup;\nuse cairo_lang_filesystem::ids::FileLongId;\nuse cairo_lang_lowering::db::LoweringGroup;\nuse cairo_lang_parser::db::ParserGroup;\nuse cairo_lang_semantic::db::SemanticGroup;\nuse thiserror::Error;\n\nuse crate::db::RootDatabase;\n\n#[cfg(test)]\n#[path = \"diagnostics_test.rs\"]\nmod test;\n\n#[derive(Error, Debug, Eq, PartialEq)]\n#[error(\"Compilation failed.\")]\npub struct DiagnosticsError;\n\ntrait DiagnosticCallback {\n    fn on_diagnostic(&mut self, diagnostic: String);\n}\n\nimpl<'a> DiagnosticCallback for Option<Box<dyn DiagnosticCallback + 'a>> {\n    fn on_diagnostic(&mut self, diagnostic: String) {\n        if let Some(callback) = self {\n            callback.on_diagnostic(diagnostic)\n        }\n    }\n}\n\n/// Collects compilation diagnostics and presents them in preconfigured way.\npub struct DiagnosticsReporter<'a> {\n    callback: Option<Box<dyn DiagnosticCallback + 'a>>,\n}\n\nimpl DiagnosticsReporter<'static> {\n    /// Create a reporter which does not print or collect diagnostics at all.\n    pub fn ignoring() -> Self {\n        Self { callback: None }\n    }\n\n    /// Create a reporter which prints all diagnostics to [`std::io::Stderr`].\n    pub fn stderr() -> Self {\n        Self::callback(|diagnostic| {\n            eprint!(\"{diagnostic}\");\n        })\n    }\n}\n\nimpl<'a> DiagnosticsReporter<'a> {\n    // NOTE(mkaput): If Rust will ever have intersection types, one could write\n    //   impl<F> DiagnosticCallback for F where F: FnMut(String)\n    //   and `new` could accept regular functions without need for this separate method.\n    /// Create a reporter which calls `callback` for each diagnostic.\n    pub fn callback(callback: impl FnMut(String) + 'a) -> Self {\n        struct Func<F>(F);\n\n        impl<F> DiagnosticCallback for Func<F>\n        where\n            F: FnMut(String),\n        {\n            fn on_diagnostic(&mut self, diagnostic: String) {\n                (self.0)(diagnostic)\n            }\n        }\n\n        Self::new(Func(callback))\n    }\n\n    /// Create a reporter which appends all diagnostics to provided string.\n    pub fn write_to_string(string: &'a mut String) -> Self {\n        Self::callback(|diagnostic| {\n            string.push_str(&diagnostic);\n        })\n    }\n\n    /// Create a reporter which calls [`DiagnosticCallback::on_diagnostic`].\n    fn new(callback: impl DiagnosticCallback + 'a) -> Self {\n        Self { callback: Some(Box::new(callback)) }\n    }\n\n    /// Checks if there are diagnostics and reports them to the provided callback as strings.\n    /// Returns `true` if diagnostics were found.\n    pub fn check(&mut self, db: &mut RootDatabase) -> bool {\n        let mut found_diagnostics = false;\n        for crate_id in db.crates() {\n            let Ok(module_file) = db.module_main_file(ModuleId::CrateRoot(crate_id)) else {\n                found_diagnostics = true;\n                self.callback.on_diagnostic(\"Failed to get main module file\".to_string());\n                continue;\n            };\n\n            if db.file_content(module_file).is_none() {\n                match db.lookup_intern_file(module_file) {\n                    FileLongId::OnDisk(path) => {\n                        self.callback.on_diagnostic(format!(\"{} not found\\n\", path.display()))\n                    }\n                    FileLongId::Virtual(_) => panic!(\"Missing virtual file.\"),\n                }\n                found_diagnostics = true;\n            }\n\n            for module_id in &*db.crate_modules(crate_id) {\n                for file_id in db.module_files(*module_id).unwrap_or_default() {\n                    let diag = db.file_syntax_diagnostics(file_id);\n                    if !diag.get_all().is_empty() {\n                        found_diagnostics = true;\n                        self.callback.on_diagnostic(diag.format(db));\n                    }\n                }\n\n                if let Ok(diag) = db.module_semantic_diagnostics(*module_id) {\n                    if !diag.get_all().is_empty() {\n                        found_diagnostics = true;\n                        self.callback.on_diagnostic(diag.format(db));\n                    }\n                }\n\n                if let Ok(diag) = db.module_lowering_diagnostics(*module_id) {\n                    if !diag.get_all().is_empty() {\n                        found_diagnostics = true;\n                        self.callback.on_diagnostic(diag.format(db));\n                    }\n                }\n            }\n        }\n        found_diagnostics\n    }\n\n    /// Checks if there are diagnostics and reports them to the provided callback as strings.\n    /// Returns `Err` if diagnostics were found.\n    pub fn ensure(&mut self, db: &mut RootDatabase) -> Result<(), DiagnosticsError> {\n        if self.check(db) { Err(DiagnosticsError) } else { Ok(()) }\n    }\n}\n\nimpl Default for DiagnosticsReporter<'static> {\n    fn default() -> Self {\n        DiagnosticsReporter::stderr()\n    }\n}\n\n/// Returns a string with all the diagnostics in the db.\n///\n/// This is a shortcut for `DiagnosticsReporter::write_to_string(&mut string).check(db)`.\npub fn get_diagnostics_as_string(db: &mut RootDatabase) -> String {\n    let mut diagnostics = String::default();\n    DiagnosticsReporter::write_to_string(&mut diagnostics).check(db);\n    diagnostics\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_filesystem::db::{FilesGroup, FilesGroupEx};\nuse cairo_lang_filesystem::ids::{CrateLongId, Directory};\n\nuse crate::db::RootDatabase;\nuse crate::diagnostics::get_diagnostics_as_string;\n\n#[test]\nfn test_diagnostics() {\n    let mut db = RootDatabase::default();\n\n    let crate_id = db.intern_crate(CrateLongId(\"bad_create\".into()));\n    db.set_crate_root(crate_id, Some(Directory(\"no/such/path\".into())));\n\n    assert_eq!(get_diagnostics_as_string(&mut db), \"no/such/path/lib.cairo not found\\n\");\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Cairo compiler.\n//!\n//! This crate is responsible for compiling a Cairo project into a Sierra program.\n//! It is the main entry point for the compiler.\nuse std::path::Path;\nuse std::sync::Arc;\n\nuse ::cairo_lang_diagnostics::ToOption;\nuse anyhow::{Context, Result};\nuse cairo_lang_filesystem::ids::CrateId;\nuse cairo_lang_sierra::program::Program;\nuse cairo_lang_sierra_generator::db::SierraGenGroup;\nuse cairo_lang_sierra_generator::replace_ids::replace_sierra_ids_in_program;\n\nuse crate::db::RootDatabase;\nuse crate::diagnostics::DiagnosticsReporter;\nuse crate::project::{get_main_crate_ids_from_project, setup_project, ProjectConfig};\n\npub mod db;\npub mod diagnostics;\npub mod project;\n\n/// Configuration for the compiler.\npub struct CompilerConfig<'c> {\n    pub diagnostics_reporter: DiagnosticsReporter<'c>,\n\n    /// Replaces sierra ids with human-readable ones.\n    pub replace_ids: bool,\n\n    /// The name of the allowed libfuncs list to use in compilation.\n    /// If None the default list of audited libfuncs will be used.\n    pub allowed_libfuncs_list_name: Option<String>,\n}\n\n/// The default compiler configuration.\nimpl Default for CompilerConfig<'static> {\n    fn default() -> Self {\n        CompilerConfig {\n            diagnostics_reporter: DiagnosticsReporter::default(),\n            replace_ids: false,\n            allowed_libfuncs_list_name: None,\n        }\n    }\n}\n\npub type SierraProgram = Arc<Program>;\n\n/// Compiles a Cairo project at the given path.\n/// The project must be a valid Cairo project:\n/// Either a standalone `.cairo` file (a single crate), or a directory with a `cairo_project.toml`\n/// file.\n/// # Arguments\n/// * `path` - The path to the project.\n/// * `compiler_config` - The compiler configuration.\n/// # Returns\n/// * `Ok(SierraProgram)` - The compiled program.\n/// * `Err(anyhow::Error)` - Compilation failed.\npub fn compile_cairo_project_at_path(\n    path: &Path,\n    compiler_config: CompilerConfig<'_>,\n) -> Result<SierraProgram> {\n    let mut db = RootDatabase::builder().detect_corelib().build()?;\n    let main_crate_ids = setup_project(&mut db, path)?;\n    compile_prepared_db(&mut db, main_crate_ids, compiler_config)\n}\n\n/// Compiles a Cairo project.\n/// The project must be a valid Cairo project.\n/// This function is a wrapper over [`RootDatabase::builder()`] and [`compile_prepared_db`].\n/// # Arguments\n/// * `project_config` - The project configuration.\n/// * `compiler_config` - The compiler configuration.\n/// # Returns\n/// * `Ok(SierraProgram)` - The compiled program.\n/// * `Err(anyhow::Error)` - Compilation failed.\npub fn compile(\n    project_config: ProjectConfig,\n    compiler_config: CompilerConfig<'_>,\n) -> Result<SierraProgram> {\n    let mut db = RootDatabase::builder().with_project_config(project_config.clone()).build()?;\n    let main_crate_ids = get_main_crate_ids_from_project(&mut db, &project_config);\n\n    compile_prepared_db(&mut db, main_crate_ids, compiler_config)\n}\n\n/// Runs Cairo compiler.\n///\n/// # Arguments\n/// * `db` - Preloaded compilation database.\n/// * `main_crate_ids` - [`CrateId`]s to compile. Do not include dependencies here, only pass\n///   top-level crates in order to eliminate unused code. Use `db.intern_crate(CrateLongId(name))`\n///   in order to obtain [`CrateId`] from its name.\n/// * `compiler_config` - The compiler configuration.\n/// # Returns\n/// * `Ok(SierraProgram)` - The compiled program.\n/// * `Err(anyhow::Error)` - Compilation failed.\npub fn compile_prepared_db(\n    db: &mut RootDatabase,\n    main_crate_ids: Vec<CrateId>,\n    mut compiler_config: CompilerConfig<'_>,\n) -> Result<SierraProgram> {\n    compiler_config.diagnostics_reporter.ensure(db)?;\n\n    let mut sierra_program = db\n        .get_sierra_program(main_crate_ids)\n        .to_option()\n        .context(\"Compilation failed without any diagnostics\")?;\n\n    if compiler_config.replace_ids {\n        sierra_program = Arc::new(replace_sierra_ids_in_program(db, &sierra_program));\n    }\n\n    Ok(sierra_program)\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::ffi::OsStr;\nuse std::path::{Path, PathBuf};\nuse std::sync::Arc;\n\nuse cairo_lang_defs::ids::ModuleId;\nuse cairo_lang_filesystem::db::FilesGroupEx;\nuse cairo_lang_filesystem::ids::{CrateId, CrateLongId, Directory};\npub use cairo_lang_project::*;\nuse cairo_lang_semantic::db::SemanticGroup;\n\n#[derive(thiserror::Error, Debug)]\npub enum ProjectError {\n    #[error(\"Only files with .cairo extension can be compiled.\")]\n    BadFileExtension,\n    #[error(\"Couldn't read {path}: No such file.\")]\n    NoSuchFile { path: String },\n    #[error(\"Couldn't handle {path}: Not a legal path.\")]\n    BadPath { path: String },\n    #[error(\"Failed to load project config.\")]\n    LoadProjectError,\n}\n\n/// Setup to 'db' to compile the file at the given path.\n/// Returns the id of the generated crate.\nfn setup_single_file_project(\n    db: &mut dyn SemanticGroup,\n    path: &Path,\n) -> Result<CrateId, ProjectError> {\n    match path.extension().and_then(OsStr::to_str) {\n        Some(\"cairo\") => (),\n        _ => {\n            return Err(ProjectError::BadFileExtension);\n        }\n    }\n    if !path.exists() {\n        return Err(ProjectError::NoSuchFile { path: path.to_string_lossy().to_string() });\n    }\n    let bad_path_err = || ProjectError::BadPath { path: path.to_string_lossy().to_string() };\n    let file_stem = path.file_stem().and_then(OsStr::to_str).ok_or_else(bad_path_err)?;\n    if file_stem == \"lib\" {\n        let canonical = path.canonicalize().map_err(|_| bad_path_err())?;\n        let file_dir = canonical.parent().ok_or_else(bad_path_err)?;\n        let crate_name = file_dir.to_str().ok_or_else(bad_path_err)?;\n        let crate_id = db.intern_crate(CrateLongId(crate_name.into()));\n        db.set_crate_root(crate_id, Some(Directory(file_dir.to_path_buf())));\n        Ok(crate_id)\n    } else {\n        // If file_stem is not lib, create a fake lib file.\n        let crate_id = db.intern_crate(CrateLongId(file_stem.into()));\n        db.set_crate_root(crate_id, Some(Directory(path.parent().unwrap().to_path_buf())));\n\n        let module_id = ModuleId::CrateRoot(crate_id);\n        let file_id = db.module_main_file(module_id).unwrap();\n        db.as_files_group_mut()\n            .override_file_content(file_id, Some(Arc::new(format!(\"mod {file_stem};\"))));\n        Ok(crate_id)\n    }\n}\n\n/// Updates the crate roots from a ProjectConfig object.\npub fn update_crate_roots_from_project_config(db: &mut dyn SemanticGroup, config: ProjectConfig) {\n    for (crate_name, directory_path) in config.content.crate_roots {\n        let crate_id = db.intern_crate(CrateLongId(crate_name));\n        let mut path = PathBuf::from(&directory_path);\n        if path.is_relative() {\n            path = PathBuf::from(&config.base_path).join(path);\n        }\n        let root = Directory(path);\n        db.set_crate_root(crate_id, Some(root));\n    }\n}\n\n/// Setup the 'db' to compile the project in the given path.\n/// The path can be either a directory with cairo project file or a .cairo file.\n/// Returns the ids of the project crates.\npub fn setup_project(\n    db: &mut dyn SemanticGroup,\n    path: &Path,\n) -> Result<Vec<CrateId>, ProjectError> {\n    if path.is_dir() {\n        match ProjectConfig::from_directory(path) {\n            Ok(config) => {\n                let main_crate_ids = get_main_crate_ids_from_project(db, &config);\n                update_crate_roots_from_project_config(db, config);\n                Ok(main_crate_ids)\n            }\n            _ => Err(ProjectError::LoadProjectError),\n        }\n    } else {\n        Ok(vec![setup_single_file_project(db, path)?])\n    }\n}\n\npub fn get_main_crate_ids_from_project(\n    db: &mut dyn SemanticGroup,\n    config: &ProjectConfig,\n) -> Vec<CrateId> {\n    config\n        .content\n        .crate_roots\n        .keys()\n        .map(|crate_id| db.intern_crate(CrateLongId(crate_id.clone())))\n        .collect()\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "#[cfg(test)]\n#[path = \"debug_test.rs\"]\nmod test;\n\n// Mostly taken from https://github.com/salsa-rs/salsa/blob/fd715619813f634fa07952f0d1b3d3a18b68fd65/components/salsa-2022/src/debug.rs\nuse std::collections::{HashMap, HashSet};\nuse std::rc::Rc;\nuse std::sync::Arc;\n\npub trait DebugWithDb<Db: ?Sized> {\n    fn debug<'me, 'db>(&'me self, db: &'me Db) -> DebugWith<'me, Db>\n    where\n        Self: Sized + 'me,\n    {\n        DebugWith { value: BoxRef::Ref(self), db }\n    }\n\n    #[allow(dead_code)]\n    fn into_debug<'me, 'db>(self, db: &'me Db) -> DebugWith<'me, Db>\n    where\n        Self: Sized + 'me,\n    {\n        DebugWith { value: BoxRef::Box(Box::new(self)), db }\n    }\n\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, db: &Db) -> std::fmt::Result;\n}\n\npub struct DebugWith<'me, Db: ?Sized> {\n    value: BoxRef<'me, dyn DebugWithDb<Db> + 'me>,\n    db: &'me Db,\n}\n\nenum BoxRef<'me, T: ?Sized> {\n    Box(Box<T>),\n    Ref(&'me T),\n}\n\nimpl<T: ?Sized> std::ops::Deref for BoxRef<'_, T> {\n    type Target = T;\n\n    fn deref(&self) -> &Self::Target {\n        match self {\n            BoxRef::Box(b) => b,\n            BoxRef::Ref(r) => r,\n        }\n    }\n}\n\nimpl<D: ?Sized> std::fmt::Debug for DebugWith<'_, D> {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        DebugWithDb::fmt(&*self.value, f, self.db)\n    }\n}\n\nimpl<Db: ?Sized, T: ?Sized> DebugWithDb<Db> for &T\nwhere\n    T: DebugWithDb<Db>,\n{\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, db: &Db) -> std::fmt::Result {\n        T::fmt(self, f, db)\n    }\n}\n\nimpl<Db: ?Sized, T: ?Sized> DebugWithDb<Db> for Box<T>\nwhere\n    T: DebugWithDb<Db>,\n{\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, db: &Db) -> std::fmt::Result {\n        T::fmt(self, f, db)\n    }\n}\n\nimpl<Db: ?Sized, T> DebugWithDb<Db> for Rc<T>\nwhere\n    T: DebugWithDb<Db>,\n{\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, db: &Db) -> std::fmt::Result {\n        T::fmt(self, f, db)\n    }\n}\n\nimpl<Db: ?Sized, T: ?Sized> DebugWithDb<Db> for Arc<T>\nwhere\n    T: DebugWithDb<Db>,\n{\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, db: &Db) -> std::fmt::Result {\n        T::fmt(self, f, db)\n    }\n}\n\nimpl<Db: ?Sized, T> DebugWithDb<Db> for Vec<T>\nwhere\n    T: DebugWithDb<Db>,\n{\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, db: &Db) -> std::fmt::Result {\n        let elements = self.iter().map(|e| e.debug(db));\n        f.debug_list().entries(elements).finish()\n    }\n}\n\nimpl<Db: ?Sized, T> DebugWithDb<Db> for Option<T>\nwhere\n    T: DebugWithDb<Db>,\n{\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, db: &Db) -> std::fmt::Result {\n        let me = self.as_ref().map(|v| v.debug(db));\n        std::fmt::Debug::fmt(&me, f)\n    }\n}\n\nimpl<Db: ?Sized, K, V, S> DebugWithDb<Db> for HashMap<K, V, S>\nwhere\n    K: DebugWithDb<Db>,\n    V: DebugWithDb<Db>,\n{\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, db: &Db) -> std::fmt::Result {\n        let elements = self.iter().map(|(k, v)| (k.debug(db), v.debug(db)));\n        f.debug_map().entries(elements).finish()\n    }\n}\n\nimpl<Db: ?Sized, A, B> DebugWithDb<Db> for (A, B)\nwhere\n    A: DebugWithDb<Db>,\n    B: DebugWithDb<Db>,\n{\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, db: &Db) -> std::fmt::Result {\n        f.debug_tuple(\"\").field(&self.0.debug(db)).field(&self.1.debug(db)).finish()\n    }\n}\n\nimpl<Db: ?Sized, A, B, C> DebugWithDb<Db> for (A, B, C)\nwhere\n    A: DebugWithDb<Db>,\n    B: DebugWithDb<Db>,\n    C: DebugWithDb<Db>,\n{\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, db: &Db) -> std::fmt::Result {\n        f.debug_tuple(\"\")\n            .field(&self.0.debug(db))\n            .field(&self.1.debug(db))\n            .field(&self.2.debug(db))\n            .finish()\n    }\n}\n\nimpl<Db: ?Sized, V, S> DebugWithDb<Db> for HashSet<V, S>\nwhere\n    V: DebugWithDb<Db>,\n{\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, db: &Db) -> std::fmt::Result {\n        let elements = self.iter().map(|e| e.debug(db));\n        f.debug_list().entries(elements).finish()\n    }\n}\n\n/// This is used by the macro generated code.\n/// If the field type implements `DebugWithDb`, uses that, otherwise, uses `Debug`.\n/// That's the \"has impl\" trick <https://github.com/nvzqz/impls#how-it-works>\n#[doc(hidden)]\npub mod helper {\n    use std::fmt;\n    use std::marker::PhantomData;\n\n    use super::{DebugWith, DebugWithDb};\n\n    pub trait Fallback<T: fmt::Debug, Db: ?Sized> {\n        fn helper_debug<'a>(a: &'a T, _db: &Db) -> &'a dyn fmt::Debug {\n            a\n        }\n    }\n\n    pub struct HelperDebug<T, Db: ?Sized>(PhantomData<T>, PhantomData<Db>);\n\n    impl<T: DebugWithDb<Db>, Db: ?Sized> HelperDebug<T, Db> {\n        #[allow(dead_code)]\n        pub fn helper_debug<'a, 'b: 'a>(a: &'a T, db: &'b Db) -> DebugWith<'a, Db> {\n            a.debug(db)\n        }\n    }\n\n    impl<Everything, Db: ?Sized, T: fmt::Debug> Fallback<T, Db> for Everything {}\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::fmt::Debug;\n\nuse cairo_lang_proc_macros::DebugWithDb;\nuse cairo_lang_utils::{define_short_id, Upcast};\nuse test_log::test;\n\nuse crate::debug as cairo_lang_debug;\nuse crate::debug::DebugWithDb;\n\n// Test database query group.\n#[salsa::query_group(TestDatabase)]\ntrait TestGroup {\n    #[salsa::interned]\n    fn intern_b(&self, crt: DummyLongId) -> DummyShortId;\n}\n// Database impl.\n#[salsa::database(TestDatabase)]\n#[derive(Default)]\npub struct DatabaseForTesting {\n    storage: salsa::Storage<DatabaseForTesting>,\n}\nimpl salsa::Database for DatabaseForTesting {}\n\nimpl Upcast<dyn TestGroup> for DatabaseForTesting {\n    fn upcast(&self) -> &(dyn TestGroup + 'static) {\n        self\n    }\n}\n\n// Structs.\n#[derive(Clone, Debug, PartialEq, Eq, Hash)]\nstruct DummyLongId(usize);\n\ndefine_short_id!(DummyShortId, DummyLongId, TestGroup, lookup_intern_b);\n\n#[derive(DebugWithDb)]\n#[debug_db(dyn TestGroup + 'static)]\nstruct ComplexStruct {\n    a: Option<usize>,\n    b: DummyShortId,\n    #[hide_field_debug_with_db]\n    c: usize,\n    #[hide_field_debug_with_db]\n    d: usize,\n}\n\n#[test]\nfn test_debug() {\n    let db = DatabaseForTesting::default();\n    let a = ComplexStruct { a: Some(5), b: db.intern_b(DummyLongId(6)), c: 7, d: 8 };\n    assert_eq!(format!(\"{:?}\", a.debug(&db)), \"ComplexStruct { a: Some(5), b: DummyLongId(6) }\");\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Debug utilities for types that need a salsa database for debug formatting.\n\npub mod debug;\npub use crate::debug::{helper, DebugWithDb};\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::VecDeque;\nuse std::sync::Arc;\n\nuse cairo_lang_diagnostics::{Maybe, ToMaybe};\nuse cairo_lang_filesystem::db::FilesGroup;\nuse cairo_lang_filesystem::ids::{CrateId, Directory, FileId, FileLongId, VirtualFile};\nuse cairo_lang_parser::db::ParserGroup;\nuse cairo_lang_syntax::node::ast::MaybeModuleBody;\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::ids::SyntaxStablePtrId;\nuse cairo_lang_syntax::node::{ast, TypedSyntaxNode};\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse cairo_lang_utils::Upcast;\n\nuse crate::ids::*;\nuse crate::plugin::{DynGeneratedFileAuxData, MacroPlugin, PluginDiagnostic};\n\n/// Salsa database interface.\n/// See [`super::ids`] for further details.\n#[salsa::query_group(DefsDatabase)]\npub trait DefsGroup:\n    FilesGroup\n    + SyntaxGroup\n    + Upcast<dyn SyntaxGroup>\n    + ParserGroup\n    + Upcast<dyn FilesGroup>\n    + HasMacroPlugins\n{\n    #[salsa::interned]\n    fn intern_constant(&self, id: ConstantLongId) -> ConstantId;\n    #[salsa::interned]\n    fn intern_submodule(&self, id: SubmoduleLongId) -> SubmoduleId;\n    #[salsa::interned]\n    fn intern_use(&self, id: UseLongId) -> UseId;\n    #[salsa::interned]\n    fn intern_free_function(&self, id: FreeFunctionLongId) -> FreeFunctionId;\n    #[salsa::interned]\n    fn intern_impl_function(&self, id: ImplFunctionLongId) -> ImplFunctionId;\n    #[salsa::interned]\n    fn intern_struct(&self, id: StructLongId) -> StructId;\n    #[salsa::interned]\n    fn intern_enum(&self, id: EnumLongId) -> EnumId;\n    #[salsa::interned]\n    fn intern_type_alias(&self, id: TypeAliasLongId) -> TypeAliasId;\n    #[salsa::interned]\n    fn intern_member(&self, id: MemberLongId) -> MemberId;\n    #[salsa::interned]\n    fn intern_variant(&self, id: VariantLongId) -> VariantId;\n    #[salsa::interned]\n    fn intern_trait(&self, id: TraitLongId) -> TraitId;\n    #[salsa::interned]\n    fn intern_trait_function(&self, id: TraitFunctionLongId) -> TraitFunctionId;\n    #[salsa::interned]\n    fn intern_impl(&self, id: ImplDefLongId) -> ImplDefId;\n    #[salsa::interned]\n    fn intern_extern_type(&self, id: ExternTypeLongId) -> ExternTypeId;\n    #[salsa::interned]\n    fn intern_extern_function(&self, id: ExternFunctionLongId) -> ExternFunctionId;\n    #[salsa::interned]\n    fn intern_param(&self, id: ParamLongId) -> ParamId;\n    #[salsa::interned]\n    fn intern_generic_param(&self, id: GenericParamLongId) -> GenericParamId;\n    #[salsa::interned]\n    fn intern_local_var(&self, id: LocalVarLongId) -> LocalVarId;\n\n    // Module to syntax.\n    /// Gets the main file of the module.\n    /// A module might have more virtual files generated by plugins.\n    fn module_main_file(&self, module_id: ModuleId) -> Maybe<FileId>;\n    /// Gets all the files of a module - main files and generated virtual files.\n    fn module_files(&self, module_id: ModuleId) -> Maybe<Vec<FileId>>;\n    /// Gets a file from a module and a FileIndex (i.e. ModuleFileId).\n    fn module_file(&self, module_id: ModuleFileId) -> Maybe<FileId>;\n    /// Gets the directory of a module.\n    fn module_dir(&self, module_id: ModuleId) -> Maybe<Directory>;\n\n    // File to module.\n    fn crate_modules(&self, crate_id: CrateId) -> Arc<Vec<ModuleId>>;\n    fn priv_file_to_module_mapping(&self) -> OrderedHashMap<FileId, Vec<ModuleId>>;\n    fn file_modules(&self, file_id: FileId) -> Maybe<Vec<ModuleId>>;\n\n    // Module level resolving.\n    fn priv_module_data(&self, module_id: ModuleId) -> Maybe<ModuleData>;\n    fn module_submodules(\n        &self,\n        module_id: ModuleId,\n    ) -> Maybe<OrderedHashMap<SubmoduleId, ast::ItemModule>>;\n    fn module_submodules_ids(&self, module_id: ModuleId) -> Maybe<Vec<SubmoduleId>>;\n    fn module_constants(\n        &self,\n        module_id: ModuleId,\n    ) -> Maybe<OrderedHashMap<ConstantId, ast::ItemConstant>>;\n    fn module_constants_ids(&self, module_id: ModuleId) -> Maybe<Vec<ConstantId>>;\n    fn module_free_functions(\n        &self,\n        module_id: ModuleId,\n    ) -> Maybe<OrderedHashMap<FreeFunctionId, ast::FunctionWithBody>>;\n    fn module_free_functions_ids(&self, module_id: ModuleId) -> Maybe<Vec<FreeFunctionId>>;\n    fn module_items(&self, module_id: ModuleId) -> Maybe<Arc<Vec<ModuleItemId>>>;\n    /// Returns the stable ptr of the name of a module item.\n    fn module_item_name_stable_ptr(\n        &self,\n        module_id: ModuleId,\n        item_id: ModuleItemId,\n    ) -> Maybe<SyntaxStablePtrId>;\n    fn module_uses(&self, module_id: ModuleId) -> Maybe<OrderedHashMap<UseId, ast::ItemUse>>;\n    fn module_uses_ids(&self, module_id: ModuleId) -> Maybe<Vec<UseId>>;\n    fn module_structs(\n        &self,\n        module_id: ModuleId,\n    ) -> Maybe<OrderedHashMap<StructId, ast::ItemStruct>>;\n    fn module_structs_ids(&self, module_id: ModuleId) -> Maybe<Vec<StructId>>;\n    fn module_enums(&self, module_id: ModuleId) -> Maybe<OrderedHashMap<EnumId, ast::ItemEnum>>;\n    fn module_enums_ids(&self, module_id: ModuleId) -> Maybe<Vec<EnumId>>;\n    fn module_type_aliases(\n        &self,\n        module_id: ModuleId,\n    ) -> Maybe<OrderedHashMap<TypeAliasId, ast::ItemTypeAlias>>;\n    fn module_type_aliases_ids(&self, module_id: ModuleId) -> Maybe<Vec<TypeAliasId>>;\n    fn module_traits(&self, module_id: ModuleId) -> Maybe<OrderedHashMap<TraitId, ast::ItemTrait>>;\n    fn module_traits_ids(&self, module_id: ModuleId) -> Maybe<Vec<TraitId>>;\n    fn module_impls(&self, module_id: ModuleId) -> Maybe<OrderedHashMap<ImplDefId, ast::ItemImpl>>;\n    fn module_impls_ids(&self, module_id: ModuleId) -> Maybe<Vec<ImplDefId>>;\n    fn module_extern_types(\n        &self,\n        module_id: ModuleId,\n    ) -> Maybe<OrderedHashMap<ExternTypeId, ast::ItemExternType>>;\n    fn module_extern_types_ids(&self, module_id: ModuleId) -> Maybe<Vec<ExternTypeId>>;\n    fn module_extern_functions(\n        &self,\n        module_id: ModuleId,\n    ) -> Maybe<OrderedHashMap<ExternFunctionId, ast::ItemExternFunction>>;\n    fn module_extern_functions_ids(&self, module_id: ModuleId) -> Maybe<Vec<ExternFunctionId>>;\n    fn module_generated_file_infos(\n        &self,\n        module_id: ModuleId,\n    ) -> Maybe<Vec<Option<GeneratedFileInfo>>>;\n    fn module_plugin_diagnostics(\n        &self,\n        module_id: ModuleId,\n    ) -> Maybe<Vec<(ModuleFileId, PluginDiagnostic)>>;\n}\n\npub trait HasMacroPlugins {\n    fn macro_plugins(&self) -> Vec<Arc<dyn MacroPlugin>>;\n}\n\nfn module_main_file(db: &dyn DefsGroup, module_id: ModuleId) -> Maybe<FileId> {\n    Ok(match module_id {\n        ModuleId::CrateRoot(crate_id) => {\n            db.crate_root_dir(crate_id).to_maybe()?.file(db.upcast(), \"lib.cairo\".into())\n        }\n        ModuleId::Submodule(submodule_id) => {\n            let parent = submodule_id.parent_module(db);\n            let item_module_ast = &db.priv_module_data(parent)?.submodules[submodule_id];\n            match item_module_ast.body(db.upcast()) {\n                MaybeModuleBody::Some(_) => {\n                    // This is an inline module, we return the file where the inline module was\n                    // defined. It can be either the file of the parent module\n                    // or a plugin-generated virtual file.\n                    db.module_file(submodule_id.module_file_id(db))?\n                }\n                MaybeModuleBody::None(_) => {\n                    let name = submodule_id.name(db);\n                    db.module_dir(parent)?.file(db.upcast(), format!(\"{name}.cairo\").into())\n                }\n            }\n        }\n    })\n}\n\nfn module_files(db: &dyn DefsGroup, module_id: ModuleId) -> Maybe<Vec<FileId>> {\n    Ok(db.priv_module_data(module_id)?.files)\n}\n\nfn module_file(db: &dyn DefsGroup, module_file_id: ModuleFileId) -> Maybe<FileId> {\n    Ok(db.module_files(module_file_id.0)?[module_file_id.1.0])\n}\n\nfn module_dir(db: &dyn DefsGroup, module_id: ModuleId) -> Maybe<Directory> {\n    match module_id {\n        ModuleId::CrateRoot(crate_id) => db.crate_root_dir(crate_id).to_maybe(),\n        ModuleId::Submodule(submodule_id) => {\n            let parent = submodule_id.parent_module(db);\n            let name = submodule_id.name(db);\n            Ok(db.module_dir(parent)?.subdir(name))\n        }\n    }\n}\n\n/// Appends all the modules under the given module, including nested modules.\nfn collect_modules_under(db: &dyn DefsGroup, modules: &mut Vec<ModuleId>, module_id: ModuleId) {\n    modules.push(module_id);\n    for submodule_module_id in db.module_submodules_ids(module_id).unwrap_or_default().into_iter() {\n        collect_modules_under(db, modules, ModuleId::Submodule(submodule_module_id));\n    }\n}\n\n/// Returns all the modules in the crate, including recursively.\nfn crate_modules(db: &dyn DefsGroup, crate_id: CrateId) -> Arc<Vec<ModuleId>> {\n    let mut modules = Vec::new();\n    collect_modules_under(db, &mut modules, ModuleId::CrateRoot(crate_id));\n    Arc::new(modules)\n}\n\nfn priv_file_to_module_mapping(db: &dyn DefsGroup) -> OrderedHashMap<FileId, Vec<ModuleId>> {\n    let mut mapping = OrderedHashMap::<FileId, Vec<ModuleId>>::default();\n    for crate_id in db.crates() {\n        for module_id in db.crate_modules(crate_id).iter().copied() {\n            if let Ok(files) = db.module_files(module_id) {\n                for file_id in files {\n                    match mapping.get_mut(&file_id) {\n                        Some(file_modules) => {\n                            file_modules.push(module_id);\n                        }\n                        None => {\n                            mapping.insert(file_id, vec![module_id]);\n                        }\n                    }\n                }\n            }\n        }\n    }\n    mapping\n}\nfn file_modules(db: &dyn DefsGroup, file_id: FileId) -> Maybe<Vec<ModuleId>> {\n    db.priv_file_to_module_mapping().get(&file_id).cloned().to_maybe()\n}\n\n/// Information about the generation of a virtual file.\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct GeneratedFileInfo {\n    pub aux_data: DynGeneratedFileAuxData,\n    /// The module and file index from which the current file was generated.\n    pub origin: ModuleFileId,\n}\n\n#[derive(Clone, Debug, Default, PartialEq, Eq)]\npub struct ModuleData {\n    items: Arc<Vec<ModuleItemId>>,\n    constants: OrderedHashMap<ConstantId, ast::ItemConstant>,\n    submodules: OrderedHashMap<SubmoduleId, ast::ItemModule>,\n    uses: OrderedHashMap<UseId, ast::ItemUse>,\n    free_functions: OrderedHashMap<FreeFunctionId, ast::FunctionWithBody>,\n    structs: OrderedHashMap<StructId, ast::ItemStruct>,\n    enums: OrderedHashMap<EnumId, ast::ItemEnum>,\n    type_aliases: OrderedHashMap<TypeAliasId, ast::ItemTypeAlias>,\n    traits: OrderedHashMap<TraitId, ast::ItemTrait>,\n    impls: OrderedHashMap<ImplDefId, ast::ItemImpl>,\n    extern_types: OrderedHashMap<ExternTypeId, ast::ItemExternType>,\n    extern_functions: OrderedHashMap<ExternFunctionId, ast::ItemExternFunction>,\n    files: Vec<FileId>,\n    /// Generation info for each file. Virtual files have Some. Other files have None.\n    generated_file_infos: Vec<Option<GeneratedFileInfo>>,\n    plugin_diagnostics: Vec<(ModuleFileId, PluginDiagnostic)>,\n}\n\n// TODO(spapini): Make this private.\nfn priv_module_data(db: &dyn DefsGroup, module_id: ModuleId) -> Maybe<ModuleData> {\n    let syntax_db = db.upcast();\n    let module_file = db.module_main_file(module_id)?;\n\n    let file_syntax = db.file_syntax(module_file)?;\n    let mut main_file_info: Option<GeneratedFileInfo> = None;\n    let item_asts = match module_id {\n        ModuleId::CrateRoot(_) => file_syntax.items(syntax_db),\n        ModuleId::Submodule(submodule_id) => {\n            let parent_module_data = db.priv_module_data(submodule_id.parent_module(db))?;\n            let item_module_ast = &parent_module_data.submodules[submodule_id];\n\n            match item_module_ast.body(syntax_db) {\n                MaybeModuleBody::Some(body) => {\n                    // TODO(spapini): Diagnostics in this module that get mapped to parent module\n                    // should lie in that modules ModuleData, or somehow collected by its\n                    // diagnostics collector function.\n\n                    // If this is an inline module, copy its generation file info from the parent\n                    // module, from the file where this submodule was defined.\n                    main_file_info = parent_module_data.generated_file_infos\n                        [submodule_id.file_index(db).0]\n                        .clone();\n                    body.items(syntax_db)\n                }\n                MaybeModuleBody::None(_) => file_syntax.items(syntax_db),\n            }\n        }\n    };\n\n    let mut module_queue = VecDeque::new();\n    module_queue.push_back((module_file, item_asts));\n    let mut res = ModuleData::default();\n\n    let mut items = vec![];\n    res.generated_file_infos.push(main_file_info);\n    while let Some((module_file, item_asts)) = module_queue.pop_front() {\n        let file_index = FileIndex(res.files.len());\n        let module_file_id = ModuleFileId(module_id, file_index);\n        res.files.push(module_file);\n\n        for item_ast in item_asts.elements(syntax_db) {\n            let mut remove_original_item = false;\n            // Iterate the plugins by their order. The first one to change something (either\n            // generate new code, remove the original code, or both), breaks the loop. If more\n            // plugins might have act on the item, they can do it on the generated code.\n            for plugin in db.macro_plugins() {\n                let result = plugin.generate_code(db.upcast(), item_ast.clone());\n                for plugin_diag in result.diagnostics {\n                    res.plugin_diagnostics.push((module_file_id, plugin_diag));\n                }\n                if result.remove_original_item {\n                    remove_original_item = true;\n                }\n\n                if let Some(generated) = result.code {\n                    let new_file = db.intern_file(FileLongId::Virtual(VirtualFile {\n                        parent: Some(module_file),\n                        name: generated.name,\n                        content: Arc::new(generated.content),\n                    }));\n                    res.generated_file_infos.push(Some(GeneratedFileInfo {\n                        aux_data: generated.aux_data,\n                        origin: module_file_id,\n                    }));\n                    module_queue.push_back((new_file, db.file_syntax(new_file)?.items(syntax_db)));\n                    // New code was generated for this item. If there are more plugins that should\n                    // operate on it, they should operate on the result (the rest of the attributes\n                    // should be copied to the new generated code).\n                    break;\n                }\n                if remove_original_item {\n                    break;\n                }\n            }\n            if remove_original_item {\n                // Don't add the original item to the module data.\n                continue;\n            }\n            let module_item = match item_ast {\n                ast::Item::Constant(constant) => {\n                    let item_id =\n                        db.intern_constant(ConstantLongId(module_file_id, constant.stable_ptr()));\n                    res.constants.insert(item_id, constant);\n                    ModuleItemId::Constant(item_id)\n                }\n                ast::Item::Module(module) => {\n                    let item_id =\n                        db.intern_submodule(SubmoduleLongId(module_file_id, module.stable_ptr()));\n                    res.submodules.insert(item_id, module);\n                    ModuleItemId::Submodule(item_id)\n                }\n                ast::Item::Use(us) => {\n                    let item_id = db.intern_use(UseLongId(module_file_id, us.stable_ptr()));\n                    res.uses.insert(item_id, us);\n                    ModuleItemId::Use(item_id)\n                }\n                ast::Item::FreeFunction(function) => {\n                    let item_id = db.intern_free_function(FreeFunctionLongId(\n                        module_file_id,\n                        function.stable_ptr(),\n                    ));\n                    res.free_functions.insert(item_id, function);\n                    ModuleItemId::FreeFunction(item_id)\n                }\n                ast::Item::ExternFunction(extern_function) => {\n                    let item_id = db.intern_extern_function(ExternFunctionLongId(\n                        module_file_id,\n                        extern_function.stable_ptr(),\n                    ));\n                    res.extern_functions.insert(item_id, extern_function);\n                    ModuleItemId::ExternFunction(item_id)\n                }\n                ast::Item::ExternType(extern_type) => {\n                    let item_id = db.intern_extern_type(ExternTypeLongId(\n                        module_file_id,\n                        extern_type.stable_ptr(),\n                    ));\n                    res.extern_types.insert(item_id, extern_type);\n                    ModuleItemId::ExternType(item_id)\n                }\n                ast::Item::Trait(trt) => {\n                    let item_id = db.intern_trait(TraitLongId(module_file_id, trt.stable_ptr()));\n                    res.traits.insert(item_id, trt);\n                    ModuleItemId::Trait(item_id)\n                }\n                ast::Item::Impl(imp) => {\n                    let item_id = db.intern_impl(ImplDefLongId(module_file_id, imp.stable_ptr()));\n                    res.impls.insert(item_id, imp);\n                    ModuleItemId::Impl(item_id)\n                }\n                ast::Item::Struct(structure) => {\n                    let item_id =\n                        db.intern_struct(StructLongId(module_file_id, structure.stable_ptr()));\n                    res.structs.insert(item_id, structure);\n                    ModuleItemId::Struct(item_id)\n                }\n                ast::Item::Enum(enm) => {\n                    let item_id = db.intern_enum(EnumLongId(module_file_id, enm.stable_ptr()));\n                    res.enums.insert(item_id, enm);\n                    ModuleItemId::Enum(item_id)\n                }\n                ast::Item::TypeAlias(type_alias) => {\n                    let item_id = db.intern_type_alias(TypeAliasLongId(\n                        module_file_id,\n                        type_alias.stable_ptr(),\n                    ));\n                    res.type_aliases.insert(item_id, type_alias);\n                    ModuleItemId::TypeAlias(item_id)\n                }\n            };\n            items.push(module_item);\n        }\n    }\n    res.items = items.into();\n    Ok(res)\n}\n\n/// Returns all the constant definitions of the given module.\npub fn module_constants(\n    db: &dyn DefsGroup,\n    module_id: ModuleId,\n) -> Maybe<OrderedHashMap<ConstantId, ast::ItemConstant>> {\n    Ok(db.priv_module_data(module_id)?.constants)\n}\npub fn module_constants_ids(db: &dyn DefsGroup, module_id: ModuleId) -> Maybe<Vec<ConstantId>> {\n    Ok(db.module_constants(module_id)?.keys().copied().collect())\n}\n\n/// Returns all the *direct* submodules of the given module - including those generated by macro\n/// plugins. To get all the submodules including nested modules, use [`collect_modules_under`].\nfn module_submodules(\n    db: &dyn DefsGroup,\n    module_id: ModuleId,\n) -> Maybe<OrderedHashMap<SubmoduleId, ast::ItemModule>> {\n    Ok(db.priv_module_data(module_id)?.submodules)\n}\nfn module_submodules_ids(db: &dyn DefsGroup, module_id: ModuleId) -> Maybe<Vec<SubmoduleId>> {\n    Ok(db.module_submodules(module_id)?.keys().copied().collect())\n}\n\n/// Returns all the free functions of the given module.\npub fn module_free_functions(\n    db: &dyn DefsGroup,\n    module_id: ModuleId,\n) -> Maybe<OrderedHashMap<FreeFunctionId, ast::FunctionWithBody>> {\n    Ok(db.priv_module_data(module_id)?.free_functions)\n}\npub fn module_free_functions_ids(\n    db: &dyn DefsGroup,\n    module_id: ModuleId,\n) -> Maybe<Vec<FreeFunctionId>> {\n    Ok(db.module_free_functions(module_id)?.keys().copied().collect())\n}\n\n/// Returns all the uses of the given module.\npub fn module_uses(\n    db: &dyn DefsGroup,\n    module_id: ModuleId,\n) -> Maybe<OrderedHashMap<UseId, ast::ItemUse>> {\n    Ok(db.priv_module_data(module_id)?.uses)\n}\npub fn module_uses_ids(db: &dyn DefsGroup, module_id: ModuleId) -> Maybe<Vec<UseId>> {\n    Ok(db.module_uses(module_id)?.keys().copied().collect())\n}\n\n/// Returns all the structs of the given module.\npub fn module_structs(\n    db: &dyn DefsGroup,\n    module_id: ModuleId,\n) -> Maybe<OrderedHashMap<StructId, ast::ItemStruct>> {\n    Ok(db.priv_module_data(module_id)?.structs)\n}\npub fn module_structs_ids(db: &dyn DefsGroup, module_id: ModuleId) -> Maybe<Vec<StructId>> {\n    Ok(db.module_structs(module_id)?.keys().copied().collect())\n}\n\n/// Returns all the enums of the given module.\npub fn module_enums(\n    db: &dyn DefsGroup,\n    module_id: ModuleId,\n) -> Maybe<OrderedHashMap<EnumId, ast::ItemEnum>> {\n    Ok(db.priv_module_data(module_id)?.enums)\n}\npub fn module_enums_ids(db: &dyn DefsGroup, module_id: ModuleId) -> Maybe<Vec<EnumId>> {\n    Ok(db.module_enums(module_id)?.keys().copied().collect())\n}\n\n/// Returns all the type aliases of the given module.\npub fn module_type_aliases(\n    db: &dyn DefsGroup,\n    module_id: ModuleId,\n) -> Maybe<OrderedHashMap<TypeAliasId, ast::ItemTypeAlias>> {\n    Ok(db.priv_module_data(module_id)?.type_aliases)\n}\npub fn module_type_aliases_ids(db: &dyn DefsGroup, module_id: ModuleId) -> Maybe<Vec<TypeAliasId>> {\n    Ok(db.module_type_aliases(module_id)?.keys().copied().collect())\n}\n\n/// Returns all the traits of the given module.\npub fn module_traits(\n    db: &dyn DefsGroup,\n    module_id: ModuleId,\n) -> Maybe<OrderedHashMap<TraitId, ast::ItemTrait>> {\n    Ok(db.priv_module_data(module_id)?.traits)\n}\npub fn module_traits_ids(db: &dyn DefsGroup, module_id: ModuleId) -> Maybe<Vec<TraitId>> {\n    Ok(db.module_traits(module_id)?.keys().copied().collect())\n}\n\n/// Returns all the impls of the given module.\npub fn module_impls(\n    db: &dyn DefsGroup,\n    module_id: ModuleId,\n) -> Maybe<OrderedHashMap<ImplDefId, ast::ItemImpl>> {\n    Ok(db.priv_module_data(module_id)?.impls)\n}\npub fn module_impls_ids(db: &dyn DefsGroup, module_id: ModuleId) -> Maybe<Vec<ImplDefId>> {\n    Ok(db.module_impls(module_id)?.keys().copied().collect())\n}\n\n/// Returns all the extern_types of the given module.\npub fn module_extern_types(\n    db: &dyn DefsGroup,\n    module_id: ModuleId,\n) -> Maybe<OrderedHashMap<ExternTypeId, ast::ItemExternType>> {\n    Ok(db.priv_module_data(module_id)?.extern_types)\n}\npub fn module_extern_types_ids(\n    db: &dyn DefsGroup,\n    module_id: ModuleId,\n) -> Maybe<Vec<ExternTypeId>> {\n    Ok(db.module_extern_types(module_id)?.keys().copied().collect())\n}\n\n/// Returns all the extern_functions of the given module.\npub fn module_extern_functions(\n    db: &dyn DefsGroup,\n    module_id: ModuleId,\n) -> Maybe<OrderedHashMap<ExternFunctionId, ast::ItemExternFunction>> {\n    Ok(db.priv_module_data(module_id)?.extern_functions)\n}\npub fn module_extern_functions_ids(\n    db: &dyn DefsGroup,\n    module_id: ModuleId,\n) -> Maybe<Vec<ExternFunctionId>> {\n    Ok(db.module_extern_functions(module_id)?.keys().copied().collect())\n}\n\n/// Returns the generated_file_infos of the given module.\npub fn module_generated_file_infos(\n    db: &dyn DefsGroup,\n    module_id: ModuleId,\n) -> Maybe<Vec<Option<GeneratedFileInfo>>> {\n    Ok(db.priv_module_data(module_id)?.generated_file_infos)\n}\n\n/// Returns all the plugin diagnostics of the given module.\npub fn module_plugin_diagnostics(\n    db: &dyn DefsGroup,\n    module_id: ModuleId,\n) -> Maybe<Vec<(ModuleFileId, PluginDiagnostic)>> {\n    Ok(db.priv_module_data(module_id)?.plugin_diagnostics)\n}\n\nfn module_items(db: &dyn DefsGroup, module_id: ModuleId) -> Maybe<Arc<Vec<ModuleItemId>>> {\n    Ok(db.priv_module_data(module_id)?.items)\n}\n\nfn module_item_name_stable_ptr(\n    db: &dyn DefsGroup,\n    module_id: ModuleId,\n    item_id: ModuleItemId,\n) -> Maybe<SyntaxStablePtrId> {\n    let data = db.priv_module_data(module_id)?;\n    let db = db.upcast();\n    Ok(match item_id {\n        ModuleItemId::Constant(id) => data.constants[id].name(db).stable_ptr().untyped(),\n        ModuleItemId::Submodule(id) => data.submodules[id].name(db).stable_ptr().untyped(),\n        ModuleItemId::Use(id) => {\n            let use_path = data.uses[id].name(db);\n            use_path\n                .elements(db)\n                .last()\n                .map(|last| last.stable_ptr().untyped())\n                .unwrap_or_else(|| use_path.stable_ptr().untyped())\n        }\n        ModuleItemId::FreeFunction(id) => {\n            data.free_functions[id].declaration(db).name(db).stable_ptr().untyped()\n        }\n        ModuleItemId::Struct(id) => data.structs[id].name(db).stable_ptr().untyped(),\n        ModuleItemId::Enum(id) => data.enums[id].name(db).stable_ptr().untyped(),\n        ModuleItemId::TypeAlias(id) => data.type_aliases[id].name(db).stable_ptr().untyped(),\n        ModuleItemId::Trait(id) => data.traits[id].name(db).stable_ptr().untyped(),\n        ModuleItemId::Impl(id) => data.impls[id].name(db).stable_ptr().untyped(),\n        ModuleItemId::ExternType(id) => data.extern_types[id].name(db).stable_ptr().untyped(),\n        ModuleItemId::ExternFunction(id) => {\n            data.extern_functions[id].declaration(db).name(db).stable_ptr().untyped()\n        }\n    })\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_diagnostics::DiagnosticLocation;\nuse cairo_lang_filesystem::span::TextSpan;\nuse cairo_lang_syntax::node::ids::SyntaxStablePtrId;\nuse cairo_lang_syntax::node::TypedSyntaxNode;\nuse cairo_lang_utils::extract_matches;\n\nuse crate::db::DefsGroup;\nuse crate::ids::ModuleFileId;\n\n/// A stable location that may be `None`. If it's None, it should not be used for diagnostics. If it\n/// is - it panics.\n#[derive(Copy, Clone, Debug, Eq, Hash, PartialEq)]\npub enum StableLocationOption {\n    None,\n    Some(StableLocation),\n}\nimpl StableLocationOption {\n    pub fn new(module_file_id: ModuleFileId, stable_ptr: SyntaxStablePtrId) -> Self {\n        Self::Some(StableLocation::new(module_file_id, stable_ptr))\n    }\n\n    pub fn from_ast<TNode: TypedSyntaxNode>(module_file_id: ModuleFileId, node: &TNode) -> Self {\n        Self::Some(StableLocation::from_ast(module_file_id, node))\n    }\n\n    /// Returns the contained 'Some' value, consuming the `self` value. Panics if self in 'None'.\n    pub fn unwrap(self) -> StableLocation {\n        extract_matches!(self, StableLocationOption::Some, \"Diagnostic in compiler-added code\")\n    }\n}\n\n/// A stable location of a real, concrete syntax.\n#[derive(Copy, Clone, Debug, Eq, Hash, PartialEq)]\npub struct StableLocation {\n    pub module_file_id: ModuleFileId,\n    pub stable_ptr: SyntaxStablePtrId,\n}\nimpl StableLocation {\n    pub fn new(module_file_id: ModuleFileId, stable_ptr: SyntaxStablePtrId) -> Self {\n        Self { module_file_id, stable_ptr }\n    }\n\n    pub fn from_ast<TNode: TypedSyntaxNode>(module_file_id: ModuleFileId, node: &TNode) -> Self {\n        Self { module_file_id, stable_ptr: node.as_syntax_node().stable_ptr() }\n    }\n\n    /// Returns the [DiagnosticLocation] that corresponds to the [StableLocation].\n    pub fn diagnostic_location(&self, db: &dyn DefsGroup) -> DiagnosticLocation {\n        let file_id =\n            db.module_file(self.module_file_id).expect(\"Module in diagnostic does not exist\");\n        let syntax_node = db\n            .file_syntax(file_id)\n            .expect(\"File for diagnostic not found\")\n            .as_syntax_node()\n            .lookup_ptr(db.upcast(), self.stable_ptr);\n        DiagnosticLocation { file_id, span: syntax_node.span_without_trivia(db.upcast()) }\n    }\n\n    /// Returns the [DiagnosticLocation] that corresponds to the [StableLocation].\n    pub fn diagnostic_location_until(\n        &self,\n        db: &dyn DefsGroup,\n        until_stable_ptr: SyntaxStablePtrId,\n    ) -> DiagnosticLocation {\n        let syntax_db = db.upcast();\n        let file_id =\n            db.module_file(self.module_file_id).expect(\"Module in diagnostic does not exist\");\n        let root_node =\n            db.file_syntax(file_id).expect(\"File for diagnostic not found\").as_syntax_node();\n        let start =\n            root_node.lookup_ptr(syntax_db, self.stable_ptr).span_start_without_trivia(syntax_db);\n        let end =\n            root_node.lookup_ptr(syntax_db, until_stable_ptr).span_end_without_trivia(syntax_db);\n        DiagnosticLocation { file_id, span: TextSpan { start, end } }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "// The following ids represent all the definitions in the code.\n// Roughly, this refers to the first appearance of each identifier.\n// Everything that can be returned by \"Go to definition\" is a definition.\n//\n// Examples:\n// * let x = 5.\n// Has a definition for the variable \"x\".\n// * fn foo<T>(a: T){ return (); }.\n// Has 3 definitions:\n//   * Function \"foo\".\n//   * Generic parameter \"T\" (only the first occurrence of \"T\").\n//   * Function parameter \"a\".\n// * trait MyTrait{ fn foo() -> (); }\n// Has 2 definitions:\n//   * Trait \"MyTrait\"\n//   * TraitFunction \"foo\".\n// * impl A for MyTrait{ fn foo() -> (){...} }\n// Has 2 definitions:\n//   * Impl \"A\"\n//   * ImplFunction \"foo\".\n//\n// Call sites, variable usages, assignments, etc. are NOT definitions.\n\nuse cairo_lang_debug::debug::DebugWithDb;\nuse cairo_lang_filesystem::ids::CrateId;\nuse cairo_lang_syntax::node::ast::TerminalIdentifierGreen;\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::helpers::{GetIdentifier, NameGreen};\nuse cairo_lang_syntax::node::ids::SyntaxStablePtrId;\nuse cairo_lang_syntax::node::kind::SyntaxKind;\nuse cairo_lang_syntax::node::stable_ptr::SyntaxStablePtr;\nuse cairo_lang_syntax::node::{ast, Terminal, TypedSyntaxNode};\nuse cairo_lang_utils::{define_short_id, OptionFrom};\nuse salsa;\nuse smol_str::SmolStr;\n\nuse crate::db::DefsGroup;\n\n// A trait for an id for a language element.\npub trait LanguageElementId {\n    fn module_file_id(&self, db: &dyn DefsGroup) -> ModuleFileId;\n    fn untyped_stable_ptr(&self, db: &(dyn DefsGroup + 'static)) -> SyntaxStablePtrId;\n\n    fn parent_module(&self, db: &dyn DefsGroup) -> ModuleId {\n        self.module_file_id(db).0\n    }\n    fn file_index(&self, db: &dyn DefsGroup) -> FileIndex {\n        self.module_file_id(db).1\n    }\n}\npub trait TopLevelLanguageElementId: LanguageElementId {\n    fn name(&self, db: &dyn DefsGroup) -> SmolStr;\n    fn full_path(&self, db: &dyn DefsGroup) -> String {\n        format!(\"{}::{}\", self.parent_module(db).full_path(db), self.name(db))\n    }\n}\n\n/// Utility macro for defining an id for a language element.\n/// Defines a long id representing some element by a module_id and a stable pointer.\n/// Also defines a short id to be used for interning of the long id.\n/// Also requires the lookup function name for the lookup fo the long id from the short id,\n/// as defined in DefsGroup.\n/// Gets an optional parameter `name`. If specified, implements the Named trait using a key_field\n/// with this name. See the documentation of 'define_short_id' and `stable_ptr.rs` for more details.\nmacro_rules! define_language_element_id {\n    ($short_id:ident, $long_id:ident, $ast_ty:ty, $lookup:ident $(, $name:ident)?) => {\n        define_language_element_id_partial!($short_id, $long_id, $ast_ty, $lookup $(, $name)?);\n        impl_top_level_language_element_id!($short_id, $lookup $(, $name)?);\n    };\n}\n\n/// Utility macro for *partially* defining an id for a language element.\n/// This is used by `define_language_element_id` (see its documentation), but doesn't implement\n/// TopLevelLanguageElementId for the type.\n///\n/// Note: prefer to use `define_language_element_id`, unless you need to overwrite the behavior of\n/// TopLevelLanguageElementId for the type.\nmacro_rules! define_language_element_id_partial {\n    ($short_id:ident, $long_id:ident, $ast_ty:ty, $lookup:ident $(,$name:ident)?) => {\n        #[derive(Clone, PartialEq, Eq, Hash, Debug)]\n        pub struct $long_id(pub ModuleFileId, pub <$ast_ty as TypedSyntaxNode>::StablePtr);\n        $(\n            impl $long_id {\n                pub fn $name(&self, db: &dyn DefsGroup) -> SmolStr {\n                    let syntax_db = db.upcast();\n                    let terminal_green = self.1.name_green(syntax_db);\n                    terminal_green.identifier(syntax_db)\n                }\n            }\n            impl<T: ?Sized + cairo_lang_utils::Upcast<dyn DefsGroup + 'static>> cairo_lang_debug::DebugWithDb<T>\n                for $long_id\n            {\n                fn fmt(&self, f: &mut std::fmt::Formatter<'_>, db: &T) -> std::fmt::Result {\n                    let db: &(dyn DefsGroup + 'static) = db.upcast();\n                    let $long_id(module_file_id, _stable_ptr) = self;\n                    write!(\n                        f,\n                        \"{}({}::{})\",\n                        stringify!($short_id),\n                        module_file_id.0.full_path(db),\n                        self.name(db)\n                    )\n                }\n            }\n        )?\n        define_short_id!($short_id, $long_id, DefsGroup, $lookup);\n        impl $short_id {\n            pub fn stable_ptr(self, db: &dyn DefsGroup) -> <$ast_ty as TypedSyntaxNode>::StablePtr {\n                db.$lookup(self).1\n            }\n            $(\n                pub fn $name(&self, db: &dyn DefsGroup) -> SmolStr {\n                    db.$lookup(*self).name(db)\n                }\n            )?\n        }\n        impl LanguageElementId for $short_id {\n            fn module_file_id(&self, db: &dyn DefsGroup) -> ModuleFileId {\n                db.$lookup(*self).0\n            }\n            fn untyped_stable_ptr(&self, db: &(dyn DefsGroup + 'static)) -> SyntaxStablePtrId {\n                self.stable_ptr(db).untyped()\n            }\n        }\n    };\n}\n\n/// A macro to implement TopLevelLanguageElementId for a type. Used by define_language_element_id.\n///\n/// Note: prefer to use `define_language_element_id`, unless you need to overwrite the behavior of\n/// TopLevelLanguageElementId for the type.\nmacro_rules! impl_top_level_language_element_id {\n    ($short_id:ident, $lookup:ident $(,$name:ident)?) => {\n        $(\n            impl TopLevelLanguageElementId for $short_id {\n                fn $name(&self, db: &dyn DefsGroup) -> SmolStr {\n                    db.$lookup(*self).name(db)\n                }\n            }\n        )?\n    };\n}\n\n/// Defines and implements LanguageElementId for a subset of other language elements.\nmacro_rules! define_language_element_id_as_enum {\n    (\n        #[toplevel]\n        $(#[doc = $doc:expr])*\n        pub enum $enum_name:ident {\n            $($variant:ident ($variant_ty:ty),)*\n        }\n    ) => {\n        toplevel_enum! {\n            pub enum $enum_name {\n                $($variant($variant_ty),)*\n            }\n        }\n        define_language_element_id_as_enum! {\n            $(#[doc = $doc])*\n            pub enum $enum_name {\n                $($variant($variant_ty),)*\n            }\n        }\n    };\n    (\n        $(#[doc = $doc:expr])*\n        pub enum $enum_name:ident {\n            $($variant:ident ($variant_ty:ty),)*\n        }\n    ) => {\n        $(#[doc = $doc])*\n        #[derive(Copy, Clone, Debug, Hash, PartialEq, Eq)]\n        pub enum $enum_name {\n            $($variant($variant_ty),)*\n        }\n        impl<T: ?Sized + cairo_lang_utils::Upcast<dyn DefsGroup + 'static>> cairo_lang_debug::DebugWithDb<T>\n            for $enum_name\n        {\n            fn fmt(\n                &self,\n                f: &mut std::fmt::Formatter<'_>,\n                db: &T,\n            ) -> std::fmt::Result {\n                let db : &(dyn DefsGroup + 'static) = db.upcast();\n                match self {\n                    $(\n                        $enum_name::$variant(id) => id.fmt(f, db),\n                    )*\n                }\n            }\n        }\n        impl LanguageElementId for $enum_name {\n            fn module_file_id(&self, db: &dyn DefsGroup) -> ModuleFileId {\n                match self {\n                    $(\n                        $enum_name::$variant(id) => id.module_file_id(db),\n                    )*\n                }\n            }\n            fn untyped_stable_ptr(&self, db: &(dyn DefsGroup + 'static)) -> SyntaxStablePtrId {\n                match self {\n                    $(\n                        $enum_name::$variant(id) => id.untyped_stable_ptr(db),\n                    )*\n                }\n            }\n        }\n\n        // Conversion from enum to its child.\n        $(\n            impl OptionFrom<$enum_name> for $variant_ty {\n                fn option_from(other: $enum_name) -> Option<Self> {\n                    if let $enum_name::$variant(id) = other {\n                        Some(id)\n                    } else {\n                        None\n                    }\n                }\n            }\n        )*\n    }\n}\n\nmacro_rules! toplevel_enum {\n    (\n        pub enum $enum_name:ident {\n            $($variant:ident ($variant_ty:ty),)*\n        }\n    ) => {\n        impl TopLevelLanguageElementId for $enum_name {\n            fn name(&self, db: &dyn DefsGroup) -> SmolStr {\n                match self {\n                    $(\n                        $enum_name::$variant(id) => id.name(db),\n                    )*\n                }\n            }\n        }\n\n    }\n}\n\n/// A trait for getting the internal salsa::InternId of a short id object.\n/// This id is unstable across runs and should not be used to anything that is externally visible.\n/// This is currently used to pick representative for strongly connected components.\npub trait UnstableSalsaId {\n    fn get_internal_id(&self) -> &salsa::InternId;\n}\n\n/// Id for a module. Either the root module of a crate, or a submodule.\n#[derive(Copy, Clone, Debug, Hash, PartialEq, Eq)]\npub enum ModuleId {\n    CrateRoot(CrateId),\n    Submodule(SubmoduleId),\n}\nimpl ModuleId {\n    pub fn full_path(&self, db: &dyn DefsGroup) -> String {\n        match self {\n            ModuleId::CrateRoot(id) => db.lookup_intern_crate(*id).0.to_string(),\n            ModuleId::Submodule(id) => {\n                format!(\"{}::{}\", id.parent_module(db).full_path(db), id.name(db))\n            }\n        }\n    }\n    pub fn owning_crate(&self, db: &dyn DefsGroup) -> CrateId {\n        match self {\n            ModuleId::CrateRoot(crate_id) => *crate_id,\n            ModuleId::Submodule(submodule) => submodule.parent_module(db).owning_crate(db),\n        }\n    }\n}\nimpl DebugWithDb<dyn DefsGroup> for ModuleId {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, db: &dyn DefsGroup) -> std::fmt::Result {\n        write!(f, \"ModuleId({})\", self.full_path(db))\n    }\n}\n/// Index of file in module.\n#[derive(Copy, Clone, Debug, Default, Hash, PartialEq, Eq)]\npub struct FileIndex(pub usize);\n#[derive(Copy, Clone, Debug, Hash, PartialEq, Eq)]\npub struct ModuleFileId(pub ModuleId, pub FileIndex);\n\ndefine_language_element_id_as_enum! {\n    /// Id for direct children of a module.\n    pub enum ModuleItemId {\n        Constant(ConstantId),\n        Submodule(SubmoduleId),\n        Use(UseId),\n        FreeFunction(FreeFunctionId),\n        Struct(StructId),\n        Enum(EnumId),\n        TypeAlias(TypeAliasId),\n        Trait(TraitId),\n        Impl(ImplDefId),\n        ExternType(ExternTypeId),\n        ExternFunction(ExternFunctionId),\n    }\n}\ndefine_language_element_id!(\n    SubmoduleId,\n    SubmoduleLongId,\n    ast::ItemModule,\n    lookup_intern_submodule,\n    name\n);\n\ndefine_language_element_id!(\n    ConstantId,\n    ConstantLongId,\n    ast::ItemConstant,\n    lookup_intern_constant,\n    name\n);\ndefine_language_element_id!(UseId, UseLongId, ast::ItemUse, lookup_intern_use, name);\ndefine_language_element_id!(\n    FreeFunctionId,\n    FreeFunctionLongId,\n    ast::FunctionWithBody,\n    lookup_intern_free_function,\n    name\n);\n\nimpl UnstableSalsaId for FreeFunctionId {\n    fn get_internal_id(&self) -> &salsa::InternId {\n        &self.0\n    }\n}\n\ndefine_language_element_id!(ImplDefId, ImplDefLongId, ast::ItemImpl, lookup_intern_impl, name);\ndefine_language_element_id_partial!(\n    ImplFunctionId,\n    ImplFunctionLongId,\n    ast::FunctionWithBody,\n    lookup_intern_impl_function,\n    name\n);\nimpl ImplFunctionId {\n    pub fn impl_def_id(&self, db: &dyn DefsGroup) -> ImplDefId {\n        let ImplFunctionLongId(module_file_id, ptr) = db.lookup_intern_impl_function(*self);\n        // TODO(spapini): Use a parent function.\n        let SyntaxStablePtr::Child{parent, ..} = db.lookup_intern_stable_ptr(ptr.untyped()) else {\n            panic!()\n        };\n        let SyntaxStablePtr::Child{parent, ..} = db.lookup_intern_stable_ptr(parent) else {\n            panic!()\n        };\n        let SyntaxStablePtr::Child{parent, ..} = db.lookup_intern_stable_ptr(parent) else {\n            panic!()\n        };\n        let impl_ptr = ast::ItemImplPtr(parent);\n        db.intern_impl(ImplDefLongId(module_file_id, impl_ptr))\n    }\n}\nimpl UnstableSalsaId for ImplFunctionId {\n    fn get_internal_id(&self) -> &salsa::InternId {\n        &self.0\n    }\n}\nimpl TopLevelLanguageElementId for ImplFunctionId {\n    fn full_path(&self, db: &dyn DefsGroup) -> String {\n        format!(\"{}::{}\", self.impl_def_id(db).name(db), self.name(db))\n    }\n\n    fn name(&self, db: &dyn DefsGroup) -> SmolStr {\n        db.lookup_intern_impl_function(*self).name(db)\n    }\n}\n\ndefine_language_element_id_as_enum! {\n    /// Represents a function that has a body.\n    pub enum FunctionWithBodyId {\n        Free(FreeFunctionId),\n        Impl(ImplFunctionId),\n    }\n}\nimpl FunctionWithBodyId {\n    pub fn name(&self, db: &dyn DefsGroup) -> SmolStr {\n        match self {\n            FunctionWithBodyId::Free(free_function) => free_function.name(db),\n            FunctionWithBodyId::Impl(impl_function) => impl_function.name(db),\n        }\n    }\n}\n\nimpl TopLevelLanguageElementId for FunctionWithBodyId {\n    fn name(&self, db: &dyn DefsGroup) -> SmolStr {\n        match self {\n            FunctionWithBodyId::Free(free_function_id) => {\n                db.lookup_intern_free_function(*free_function_id).name(db)\n            }\n            FunctionWithBodyId::Impl(impl_function_id) => {\n                db.lookup_intern_impl_function(*impl_function_id).name(db)\n            }\n        }\n    }\n}\n\ndefine_language_element_id!(\n    ExternFunctionId,\n    ExternFunctionLongId,\n    ast::ItemExternFunction,\n    lookup_intern_extern_function,\n    name\n);\ndefine_language_element_id!(StructId, StructLongId, ast::ItemStruct, lookup_intern_struct, name);\ndefine_language_element_id!(EnumId, EnumLongId, ast::ItemEnum, lookup_intern_enum, name);\ndefine_language_element_id!(\n    TypeAliasId,\n    TypeAliasLongId,\n    ast::ItemTypeAlias,\n    lookup_intern_type_alias,\n    name\n);\ndefine_language_element_id!(\n    ExternTypeId,\n    ExternTypeLongId,\n    ast::ItemExternType,\n    lookup_intern_extern_type,\n    name\n);\ndefine_language_element_id!(TraitId, TraitLongId, ast::ItemTrait, lookup_intern_trait, name);\ndefine_language_element_id_partial!(\n    TraitFunctionId,\n    TraitFunctionLongId,\n    ast::TraitItemFunction,\n    lookup_intern_trait_function,\n    name\n);\nimpl TraitFunctionId {\n    pub fn trait_id(&self, db: &dyn DefsGroup) -> TraitId {\n        let TraitFunctionLongId(module_file_id, ptr) = db.lookup_intern_trait_function(*self);\n        // Trait function ast lies a few levels bellow the trait ast.\n        // Fetch the grand grand grand parent.\n        // TODO(spapini): Use a parent function.\n        let SyntaxStablePtr::Child{parent, ..} = db.lookup_intern_stable_ptr(ptr.untyped()) else {\n            panic!()\n        };\n        let SyntaxStablePtr::Child{parent, ..} = db.lookup_intern_stable_ptr(parent) else {\n            panic!()\n        };\n        let SyntaxStablePtr::Child{parent, ..} = db.lookup_intern_stable_ptr(parent) else {\n            panic!()\n        };\n        let trait_ptr = ast::ItemTraitPtr(parent);\n        db.intern_trait(TraitLongId(module_file_id, trait_ptr))\n    }\n}\nimpl TopLevelLanguageElementId for TraitFunctionId {\n    fn full_path(&self, db: &dyn DefsGroup) -> String {\n        format!(\"{}::{}\", self.trait_id(db).name(db), self.name(db))\n    }\n\n    fn name(&self, db: &dyn DefsGroup) -> SmolStr {\n        db.lookup_intern_trait_function(*self).name(db)\n    }\n}\n\n// Struct items.\n// TODO(spapini): Override full_path for to include parents, for better debug.\ndefine_language_element_id!(MemberId, MemberLongId, ast::Member, lookup_intern_member, name);\ndefine_language_element_id!(VariantId, VariantLongId, ast::Member, lookup_intern_variant, name);\n\ndefine_language_element_id_as_enum! {\n    /// Id for any variable definition.\n    pub enum VarId {\n        Param(ParamId),\n        Local(LocalVarId),\n        // TODO(spapini): Add var from pattern matching.\n    }\n}\n\n// TODO(spapini): Override full_path for to include parents, for better debug.\ndefine_language_element_id!(ParamId, ParamLongId, ast::Param, lookup_intern_param, name);\ndefine_language_element_id!(\n    GenericParamId,\n    GenericParamLongId,\n    ast::GenericParam,\n    lookup_intern_generic_param\n);\nimpl GenericParamLongId {\n    pub fn name(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        let SyntaxStablePtr::Child {key_fields, .. }=\n            db.lookup_intern_stable_ptr(self.1.0) else {\n                unreachable!()\n            };\n        let name_green = TerminalIdentifierGreen(key_fields[0]);\n        name_green.identifier(db)\n    }\n    pub fn kind(&self, db: &dyn SyntaxGroup) -> GenericKind {\n        let SyntaxStablePtr::Child { kind, .. } =\n            db.lookup_intern_stable_ptr(self.1.0) else {\n                unreachable!()\n            };\n        match kind {\n            SyntaxKind::GenericParamType => GenericKind::Type,\n            SyntaxKind::GenericParamConst => GenericKind::Const,\n            SyntaxKind::GenericParamImpl => GenericKind::Impl,\n            _ => unreachable!(),\n        }\n    }\n    /// Retrieves the ID of the generic item holding this generic parameter.\n    pub fn generic_item(&self, db: &dyn DefsGroup) -> GenericItemId {\n        let SyntaxStablePtr::Child { parent, .. } =\n            db.lookup_intern_stable_ptr(self.1.0) else { panic!() };\n        let SyntaxStablePtr::Child { parent, .. } =\n            db.lookup_intern_stable_ptr(parent) else { panic!() };\n        let SyntaxStablePtr::Child { parent, .. } =\n            db.lookup_intern_stable_ptr(parent) else { panic!() };\n        GenericItemId::from_ptr(db, self.0, parent)\n    }\n}\nimpl GenericParamId {\n    pub fn name(&self, db: &dyn DefsGroup) -> SmolStr {\n        db.lookup_intern_generic_param(*self).name(db.upcast())\n    }\n    pub fn kind(&self, db: &dyn DefsGroup) -> GenericKind {\n        db.lookup_intern_generic_param(*self).kind(db.upcast())\n    }\n    pub fn generic_item(&self, db: &dyn DefsGroup) -> GenericItemId {\n        db.lookup_intern_generic_param(*self).generic_item(db.upcast())\n    }\n}\nimpl DebugWithDb<dyn DefsGroup> for GenericParamLongId {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, db: &dyn DefsGroup) -> std::fmt::Result {\n        write!(\n            f,\n            \"GenericParam{}({}::{})\",\n            self.kind(db.upcast()),\n            self.generic_item(db).full_path(db),\n            self.name(db.upcast())\n        )\n    }\n}\n\ndefine_language_element_id_as_enum! {\n    #[toplevel]\n    /// The ID of an item with generic parameters.\n    pub enum GenericItemId {\n        FreeFunc(FreeFunctionId),\n        ExternFunc(ExternFunctionId),\n        TraitFunc(TraitFunctionId),\n        ImplFunc(ImplFunctionId),\n        Trait(TraitId),\n        Impl(ImplDefId),\n        Struct(StructId),\n        Enum(EnumId),\n        ExternType(ExternTypeId),\n        TypeAlias(TypeAliasId),\n    }\n}\nimpl GenericItemId {\n    pub fn from_ptr(\n        db: &dyn DefsGroup,\n        module_file: ModuleFileId,\n        stable_ptr: SyntaxStablePtrId,\n    ) -> Self {\n        let SyntaxStablePtr::Child { parent: parent0, kind,.. } =\n            db.lookup_intern_stable_ptr(stable_ptr) else { panic!() };\n        match kind {\n            SyntaxKind::FunctionDeclaration => {\n                let SyntaxStablePtr::Child { parent: parent1, kind,.. } =\n                    db.lookup_intern_stable_ptr(parent0) else { panic!() };\n                match kind {\n                    SyntaxKind::FunctionWithBody => {\n                        let SyntaxStablePtr::Child { parent: parent2,.. } =\n                            db.lookup_intern_stable_ptr(parent1) else { panic!() };\n\n                        match db.lookup_intern_stable_ptr(parent2) {\n                            SyntaxStablePtr::Root => GenericItemId::FreeFunc(\n                                db.intern_free_function(FreeFunctionLongId(\n                                    module_file,\n                                    ast::FunctionWithBodyPtr(parent0),\n                                )),\n                            ),\n                            SyntaxStablePtr::Child { kind, .. } => match kind {\n                                SyntaxKind::ModuleBody => GenericItemId::FreeFunc(\n                                    db.intern_free_function(FreeFunctionLongId(\n                                        module_file,\n                                        ast::FunctionWithBodyPtr(parent0),\n                                    )),\n                                ),\n                                SyntaxKind::ImplBody => GenericItemId::ImplFunc(\n                                    db.intern_impl_function(ImplFunctionLongId(\n                                        module_file,\n                                        ast::FunctionWithBodyPtr(parent0),\n                                    )),\n                                ),\n                                _ => panic!(),\n                            },\n                        }\n                    }\n                    SyntaxKind::ItemExternFunction => {\n                        GenericItemId::ExternFunc(db.intern_extern_function(ExternFunctionLongId(\n                            module_file,\n                            ast::ItemExternFunctionPtr(parent0),\n                        )))\n                    }\n                    SyntaxKind::TraitItemFunction => {\n                        GenericItemId::TraitFunc(db.intern_trait_function(TraitFunctionLongId(\n                            module_file,\n                            ast::TraitItemFunctionPtr(parent0),\n                        )))\n                    }\n                    _ => panic!(),\n                }\n            }\n            SyntaxKind::ItemImpl => GenericItemId::Impl(\n                db.intern_impl(ImplDefLongId(module_file, ast::ItemImplPtr(stable_ptr))),\n            ),\n            SyntaxKind::ItemTrait => GenericItemId::Trait(\n                db.intern_trait(TraitLongId(module_file, ast::ItemTraitPtr(stable_ptr))),\n            ),\n            SyntaxKind::ItemStruct => GenericItemId::Struct(\n                db.intern_struct(StructLongId(module_file, ast::ItemStructPtr(stable_ptr))),\n            ),\n            SyntaxKind::ItemEnum => GenericItemId::Enum(\n                db.intern_enum(EnumLongId(module_file, ast::ItemEnumPtr(stable_ptr))),\n            ),\n            SyntaxKind::ItemExternType => GenericItemId::ExternType(db.intern_extern_type(\n                ExternTypeLongId(module_file, ast::ItemExternTypePtr(stable_ptr)),\n            )),\n            SyntaxKind::ItemTypeAlias => GenericItemId::TypeAlias(db.intern_type_alias(\n                TypeAliasLongId(module_file, ast::ItemTypeAliasPtr(stable_ptr)),\n            )),\n            _ => panic!(),\n        }\n    }\n}\n\n#[derive(Copy, Clone, Debug, PartialEq, Eq, Hash)]\npub enum GenericKind {\n    Type,\n    Const,\n    Impl,\n}\nimpl std::fmt::Display for GenericKind {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            GenericKind::Type => write!(f, \"Type\"),\n            GenericKind::Const => write!(f, \"Const\"),\n            GenericKind::Impl => write!(f, \"Impl\"),\n        }\n    }\n}\n\n// TODO(spapini): change this to a binding inside a pattern.\n// TODO(spapini): Override full_path to include parents, for better debug.\ndefine_language_element_id!(\n    LocalVarId,\n    LocalVarLongId,\n    ast::TerminalIdentifier,\n    lookup_intern_local_var\n);\nimpl DebugWithDb<dyn DefsGroup> for LocalVarLongId {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, db: &dyn DefsGroup) -> std::fmt::Result {\n        let syntax_db = db.upcast();\n        let LocalVarLongId(module_file_id, ptr) = self;\n        let file_id = db.module_file(*module_file_id).map_err(|_| std::fmt::Error)?;\n        let root = db.file_syntax(file_id).map_err(|_| std::fmt::Error)?;\n        let text = ast::TerminalIdentifier::from_ptr(syntax_db, &root, *ptr).text(syntax_db);\n        write!(f, \"LocalVarId({}::{})\", module_file_id.0.full_path(db), text)\n    }\n}\n\ndefine_language_element_id_as_enum! {\n    #[toplevel]\n    /// The ID of a function's signature in the code.\n    pub enum FunctionTitleId {\n        Free(FreeFunctionId),\n        Extern(ExternFunctionId),\n        Trait(TraitFunctionId),\n        Impl(ImplFunctionId),\n    }\n}\nimpl FunctionTitleId {\n    pub fn format(&self, db: &(dyn DefsGroup + 'static)) -> String {\n        let function_name = match *self {\n            FunctionTitleId::Free(_) | FunctionTitleId::Extern(_) => self.name(db).into(),\n            FunctionTitleId::Trait(id) => id.full_path(db),\n            FunctionTitleId::Impl(id) => id.full_path(db),\n        };\n        format!(\"{}::{}\", self.parent_module(db).full_path(db), function_name)\n    }\n}\n\ndefine_language_element_id_as_enum! {\n    #[toplevel]\n    /// Generic type ids enum.\n    pub enum GenericTypeId {\n        Struct(StructId),\n        Enum(EnumId),\n        Extern(ExternTypeId),\n        // TODO(spapini): associated types in impls.\n    }\n}\nimpl GenericTypeId {\n    pub fn format(&self, db: &(dyn DefsGroup + 'static)) -> String {\n        format!(\"{}::{}\", self.parent_module(db).full_path(db), self.name(db))\n    }\n}\n\n/// Conversion from ModuleItemId to GenericTypeId.\nimpl OptionFrom<ModuleItemId> for GenericTypeId {\n    fn option_from(item: ModuleItemId) -> Option<Self> {\n        match item {\n            ModuleItemId::Struct(id) => Some(GenericTypeId::Struct(id)),\n            ModuleItemId::Enum(id) => Some(GenericTypeId::Enum(id)),\n            ModuleItemId::ExternType(id) => Some(GenericTypeId::Extern(id)),\n            ModuleItemId::Constant(_)\n            | ModuleItemId::Submodule(_)\n            | ModuleItemId::TypeAlias(_)\n            | ModuleItemId::Use(_)\n            | ModuleItemId::FreeFunction(_)\n            | ModuleItemId::Trait(_)\n            | ModuleItemId::Impl(_)\n            | ModuleItemId::ExternFunction(_) => None,\n        }\n    }\n}\n\ndefine_language_element_id_as_enum! {\n    /// Items for resolver lookups.\n    /// These are top items that hold semantic information.\n    /// Semantic info lookups should be performed against these items.\n    pub enum LookupItemId {\n        ModuleItem(ModuleItemId),\n        // TODO(spapini): Replace with ImplItemId.\n        ImplFunction(ImplFunctionId),\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Representation and queries for definitions of module-level Cairo language elements.\n//! For example, resolving identifiers in the module level is done here.\n\npub mod db;\npub mod diagnostic_utils;\npub mod ids;\npub mod plugin;\n#[cfg(test)]\nmod test;\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::any::Any;\nuse std::ops::Deref;\nuse std::sync::Arc;\n\nuse cairo_lang_syntax::node::ast;\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::ids::SyntaxStablePtrId;\nuse smol_str::SmolStr;\n\n/// A trait for arbitrary data that a macro generates along with a generated file.\npub trait GeneratedFileAuxData: std::fmt::Debug + Sync + Send {\n    fn as_any(&self) -> &dyn Any;\n    fn eq(&self, other: &dyn GeneratedFileAuxData) -> bool;\n}\n\n#[derive(Clone, Debug)]\npub struct DynGeneratedFileAuxData(pub Arc<dyn GeneratedFileAuxData>);\nimpl DynGeneratedFileAuxData {\n    pub fn new<T: GeneratedFileAuxData + 'static>(aux_data: T) -> Self {\n        DynGeneratedFileAuxData(Arc::new(aux_data))\n    }\n}\nimpl Deref for DynGeneratedFileAuxData {\n    type Target = Arc<dyn GeneratedFileAuxData>;\n\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\nimpl PartialEq for DynGeneratedFileAuxData {\n    fn eq(&self, that: &DynGeneratedFileAuxData) -> bool {\n        GeneratedFileAuxData::eq(&*self.0, &*that.0)\n    }\n}\nimpl Eq for DynGeneratedFileAuxData {}\n\n/// Virtual code file generated by a plugin.\npub struct PluginGeneratedFile {\n    /// Name for the virtual file. Will appear in diagnostics.\n    pub name: SmolStr,\n    /// Code content for the file.\n    pub content: String,\n    /// A diagnostics mapper, to allow more readable diagnostics that originate in plugin generated\n    /// virtual files.\n    pub aux_data: DynGeneratedFileAuxData,\n}\n\n/// Result of plugin code generation.\n#[derive(Default)]\npub struct PluginResult {\n    /// Filename, content.\n    pub code: Option<PluginGeneratedFile>,\n    /// Diagnostics.\n    pub diagnostics: Vec<PluginDiagnostic>,\n    /// If true - the original item should be removed, if false - it should remain as is.\n    pub remove_original_item: bool,\n}\n\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct PluginDiagnostic {\n    pub stable_ptr: SyntaxStablePtrId,\n    pub message: String,\n}\n\n// TOD(spapini): Move to another place.\n/// A trait for a macro plugin: external plugin that generates additional code for items.\npub trait MacroPlugin: std::fmt::Debug + Sync + Send {\n    /// Generates code for an item. If no code should be generated returns None.\n    /// Otherwise, returns (virtual_module_name, module_content), and a virtual submodule\n    /// with that name and content should be created.\n    fn generate_code(&self, db: &dyn SyntaxGroup, item_ast: ast::Item) -> PluginResult;\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::fmt::Write as _;\nuse std::sync::Arc;\n\nuse cairo_lang_debug::debug::DebugWithDb;\nuse cairo_lang_filesystem::db::{\n    init_files_group, AsFilesGroupMut, FilesDatabase, FilesGroup, FilesGroupEx,\n};\nuse cairo_lang_filesystem::ids::{CrateLongId, Directory, FileLongId};\nuse cairo_lang_parser::db::{ParserDatabase, ParserGroup};\nuse cairo_lang_syntax::node::db::{SyntaxDatabase, SyntaxGroup};\nuse cairo_lang_syntax::node::kind::SyntaxKind;\nuse cairo_lang_syntax::node::{ast, SyntaxNode, Terminal, TypedSyntaxNode};\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse cairo_lang_utils::{extract_matches, try_extract_matches, Upcast};\nuse indoc::indoc;\n\nuse crate::db::{DefsDatabase, DefsGroup, HasMacroPlugins};\nuse crate::ids::{\n    FileIndex, GenericParamLongId, ModuleFileId, ModuleId, ModuleItemId, SubmoduleLongId,\n};\nuse crate::plugin::{\n    DynGeneratedFileAuxData, GeneratedFileAuxData, MacroPlugin, PluginDiagnostic,\n    PluginGeneratedFile, PluginResult,\n};\n\n#[salsa::database(DefsDatabase, ParserDatabase, SyntaxDatabase, FilesDatabase)]\npub struct DatabaseForTesting {\n    storage: salsa::Storage<DatabaseForTesting>,\n    plugins: Vec<Arc<dyn MacroPlugin>>,\n}\nimpl salsa::Database for DatabaseForTesting {}\nimpl Default for DatabaseForTesting {\n    fn default() -> Self {\n        let mut res = Self {\n            storage: Default::default(),\n            plugins: vec![\n                Arc::new(FooToBarPlugin {}),\n                Arc::new(RemoveOrigPlugin {}),\n                Arc::new(DummyPlugin {}),\n            ],\n        };\n        init_files_group(&mut res);\n        res\n    }\n}\nimpl AsFilesGroupMut for DatabaseForTesting {\n    fn as_files_group_mut(&mut self) -> &mut (dyn FilesGroup + 'static) {\n        self\n    }\n}\nimpl Upcast<dyn DefsGroup> for DatabaseForTesting {\n    fn upcast(&self) -> &(dyn DefsGroup + 'static) {\n        self\n    }\n}\nimpl Upcast<dyn FilesGroup> for DatabaseForTesting {\n    fn upcast(&self) -> &(dyn FilesGroup + 'static) {\n        self\n    }\n}\nimpl Upcast<dyn SyntaxGroup> for DatabaseForTesting {\n    fn upcast(&self) -> &(dyn SyntaxGroup + 'static) {\n        self\n    }\n}\nimpl HasMacroPlugins for DatabaseForTesting {\n    fn macro_plugins(&self) -> Vec<Arc<dyn MacroPlugin>> {\n        self.plugins.clone()\n    }\n}\n\ncairo_lang_test_utils::test_file_test!(\n    defs,\n    \"src/test_data\",\n    {\n        generic_item_id: \"generic_item_id\",\n    },\n    test_generic_item_id\n);\nfn test_generic_item_id(inputs: &OrderedHashMap<String, String>) -> OrderedHashMap<String, String> {\n    let mut db_val = DatabaseForTesting::default();\n    let module_id = setup_test_module(&mut db_val, inputs[\"module_code\"].as_str());\n\n    let module_file_id = ModuleFileId(module_id, FileIndex(0));\n    let db = &db_val;\n    let file_id = db.module_main_file(module_id).unwrap();\n    let syntax = db.file_syntax(file_id).unwrap();\n    let node = syntax.as_syntax_node();\n    let mut output = String::new();\n\n    fn find_generics(\n        db: &DatabaseForTesting,\n        mut module_file_id: ModuleFileId,\n        node: SyntaxNode,\n        output: &mut String,\n    ) {\n        match node.kind(db) {\n            SyntaxKind::ItemModule => {\n                let submodule_id = db.intern_submodule(SubmoduleLongId(\n                    module_file_id,\n                    ast::ItemModulePtr(node.stable_ptr()),\n                ));\n                module_file_id = ModuleFileId(ModuleId::Submodule(submodule_id), FileIndex(0));\n            }\n            SyntaxKind::GenericParamType\n            | SyntaxKind::GenericParamConst\n            | SyntaxKind::GenericParamImpl => {\n                let param_id = db.intern_generic_param(GenericParamLongId(\n                    module_file_id,\n                    ast::GenericParamPtr(node.stable_ptr()),\n                ));\n                let generic_item = param_id.generic_item(db);\n                writeln!(output, \"{:?} -> {:?}\", param_id.debug(db), generic_item.debug(db))\n                    .unwrap();\n            }\n            _ => {}\n        }\n        for child in node.children(db) {\n            find_generics(db, module_file_id, child, output);\n        }\n    }\n    find_generics(db, module_file_id, node, &mut output);\n\n    OrderedHashMap::from([(\"output\".into(), output)])\n}\n\npub fn setup_test_module<T: DefsGroup + AsFilesGroupMut + ?Sized>(\n    db: &mut T,\n    content: &str,\n) -> ModuleId {\n    let crate_id = db.intern_crate(CrateLongId(\"test\".into()));\n    let directory = Directory(\"src\".into());\n    db.set_crate_root(crate_id, Some(directory));\n    let file = db.module_main_file(ModuleId::CrateRoot(crate_id)).unwrap();\n    db.as_files_group_mut().override_file_content(file, Some(Arc::new(content.to_string())));\n    let syntax_diagnostics = db.file_syntax_diagnostics(file).format(Upcast::upcast(db));\n    assert_eq!(syntax_diagnostics, \"\");\n    ModuleId::CrateRoot(crate_id)\n}\n\n#[test]\nfn test_module_file() {\n    let mut db_val = DatabaseForTesting::default();\n    let module_id = setup_test_module(\n        &mut db_val,\n        indoc! {\"\n            mod mysubmodule;\n        \"},\n    );\n    let db = &db_val;\n    let item_id =\n        extract_matches!(db.module_items(module_id).ok().unwrap()[0], ModuleItemId::Submodule);\n    assert_eq!(item_id.name(db), \"mysubmodule\");\n\n    let submodule_id = ModuleId::Submodule(item_id);\n    assert_eq!(\n        db.lookup_intern_file(db.module_main_file(module_id).unwrap()),\n        FileLongId::OnDisk(\"src/lib.cairo\".into())\n    );\n    assert_eq!(\n        db.lookup_intern_file(db.module_main_file(submodule_id).unwrap()),\n        FileLongId::OnDisk(\"src/mysubmodule.cairo\".into())\n    );\n}\n\nfn set_file_content(db: &mut DatabaseForTesting, path: &str, content: &str) {\n    let file_id = db.intern_file(FileLongId::OnDisk(path.into()));\n    db.as_files_group_mut().override_file_content(file_id, Some(Arc::new(content.into())));\n}\n\n#[test]\nfn test_submodules() {\n    let mut db_val = DatabaseForTesting::default();\n    let db = &mut db_val;\n\n    let crate_id = db.intern_crate(CrateLongId(\"test\".into()));\n    let root = Directory(\"src\".into());\n    db.set_crate_root(crate_id, Some(root));\n\n    // Main module file.\n    set_file_content(db, \"src/lib.cairo\", \"mod submod;\");\n    set_file_content(db, \"src/submod.cairo\", \"mod subsubmod;\");\n    set_file_content(db, \"src/submod/subsubmod.cairo\", \"fn foo() {}\");\n\n    // Find submodules.\n    let module_id = ModuleId::CrateRoot(crate_id);\n    let submodule_id =\n        ModuleId::Submodule(*db.module_submodules_ids(module_id).unwrap().first().unwrap());\n    let subsubmodule_id =\n        ModuleId::Submodule(*db.module_submodules_ids(submodule_id).unwrap().first().unwrap());\n\n    assert_eq!(\n        format!(\"{:?}\", db.module_items(subsubmodule_id).unwrap().debug(db)),\n        \"[FreeFunctionId(test::submod::subsubmod::foo), ExternTypeId(test::submod::subsubmod::B)]\"\n    );\n\n    // Test file mappings.\n    assert_eq!(db.file_modules(db.module_main_file(module_id).unwrap()).unwrap(), vec![module_id]);\n    assert_eq!(\n        db.file_modules(db.module_main_file(submodule_id).unwrap()).unwrap(),\n        vec![submodule_id]\n    );\n    assert_eq!(\n        db.file_modules(db.module_main_file(subsubmodule_id).unwrap()).unwrap(),\n        vec![subsubmodule_id]\n    );\n}\n\n#[derive(Debug)]\nstruct DummyAuxData;\nimpl GeneratedFileAuxData for DummyAuxData {\n    fn as_any(&self) -> &dyn std::any::Any {\n        self\n    }\n\n    fn eq(&self, _other: &dyn GeneratedFileAuxData) -> bool {\n        false\n    }\n}\n\n#[derive(Debug)]\nstruct DummyPlugin {}\nimpl MacroPlugin for DummyPlugin {\n    fn generate_code(&self, db: &dyn SyntaxGroup, item_ast: ast::Item) -> PluginResult {\n        match item_ast {\n            ast::Item::Struct(struct_ast) => {\n                let remove_original_item = struct_ast\n                    .attributes(db)\n                    .elements(db)\n                    .iter()\n                    .any(|attr| attr.attr(db).text(db) == \"remove_original\");\n                PluginResult {\n                    code: Some(PluginGeneratedFile {\n                        name: \"virt\".into(),\n                        content: format!(\"fn f(x:{}){{}}\", struct_ast.name(db).text(db)),\n                        aux_data: DynGeneratedFileAuxData::new(DummyAuxData),\n                    }),\n                    diagnostics: vec![],\n                    remove_original_item,\n                }\n            }\n            ast::Item::FreeFunction(free_function_ast) => PluginResult {\n                code: Some(PluginGeneratedFile {\n                    name: \"virt2\".into(),\n                    content: \"extern type B;\".into(),\n                    aux_data: DynGeneratedFileAuxData::new(DummyAuxData),\n                }),\n                diagnostics: vec![PluginDiagnostic {\n                    stable_ptr: free_function_ast.stable_ptr().untyped(),\n                    message: \"bla\".into(),\n                }],\n                remove_original_item: false,\n            },\n            _ => PluginResult::default(),\n        }\n    }\n}\n\n#[test]\nfn test_plugin() {\n    let mut db_val = DatabaseForTesting::default();\n    let db = &mut db_val;\n\n    let crate_id = db.intern_crate(CrateLongId(\"test\".into()));\n    let root = Directory(\"src\".into());\n    db.set_crate_root(crate_id, Some(root));\n\n    // Main module file.\n    set_file_content(db, \"src/lib.cairo\", \"struct A{}\");\n\n    // Find submodules.\n    let module_id = ModuleId::CrateRoot(crate_id);\n\n    // Verify that:\n    // 1. The original struct still exists.\n    // 2. The expected items were generated.\n    assert_eq!(\n        format!(\"{:?}\", db.module_items(module_id).unwrap().debug(db)),\n        \"[StructId(test::A), FreeFunctionId(test::f), ExternTypeId(test::B)]\"\n    );\n}\n\n#[test]\nfn test_plugin_remove_original() {\n    let mut db_val = DatabaseForTesting::default();\n    let db = &mut db_val;\n\n    let crate_id = db.intern_crate(CrateLongId(\"test\".into()));\n    let root = Directory(\"src\".into());\n    db.set_crate_root(crate_id, Some(root));\n\n    // Main module file.\n    set_file_content(db, \"src/lib.cairo\", \"#[remove_original] struct A{}\");\n\n    // Find submodules.\n    let module_id = ModuleId::CrateRoot(crate_id);\n\n    // Verify that:\n    // 1. The original struct was removed.\n    // 2. The expected items were generated.\n    assert_eq!(\n        format!(\"{:?}\", db.module_items(module_id).unwrap().debug(db)),\n        \"[FreeFunctionId(test::f), ExternTypeId(test::B)]\"\n    );\n}\n\n/// If the original item is a function that is marked with #[remove_orig], only removes it, without\n/// generating any new code.\n#[derive(Debug)]\nstruct RemoveOrigPlugin {}\nimpl MacroPlugin for RemoveOrigPlugin {\n    fn generate_code(&self, db: &dyn SyntaxGroup, item_ast: ast::Item) -> PluginResult {\n        let Some(free_function_ast) = try_extract_matches!(item_ast, ast::Item::FreeFunction) else { return PluginResult::default(); };\n        if !free_function_ast\n            .attributes(db)\n            .elements(db)\n            .iter()\n            .any(|attr| attr.attr(db).text(db) == \"remove_orig\")\n        {\n            return PluginResult::default();\n        }\n        PluginResult { code: None, diagnostics: vec![], remove_original_item: true }\n    }\n}\n\n/// Changes a function 'foo' to 'bar' if annotated with #[foo_to_bar]. Doesn't remove the original\n/// item.\n#[derive(Debug)]\nstruct FooToBarPlugin {}\nimpl MacroPlugin for FooToBarPlugin {\n    fn generate_code(&self, db: &dyn SyntaxGroup, item_ast: ast::Item) -> PluginResult {\n        let Some(free_function_ast) = try_extract_matches!(item_ast, ast::Item::FreeFunction) else { return PluginResult::default(); };\n        if free_function_ast.declaration(db).name(db).text(db) != \"foo\" {\n            return PluginResult::default();\n        }\n        if !free_function_ast\n            .attributes(db)\n            .elements(db)\n            .iter()\n            .any(|attr| attr.attr(db).text(db) == \"foo_to_bar\")\n        {\n            return PluginResult::default();\n        }\n\n        PluginResult {\n            code: Some(PluginGeneratedFile {\n                name: \"virt\".into(),\n                content: \"fn bar() {}\".to_string(),\n                aux_data: DynGeneratedFileAuxData::new(DummyAuxData),\n            }),\n            diagnostics: vec![],\n            remove_original_item: false,\n        }\n    }\n}\n\n#[test]\nfn test_foo_to_bar() {\n    let mut db_val = DatabaseForTesting::default();\n    let db = &mut db_val;\n    let crate_id = db.intern_crate(CrateLongId(\"test\".into()));\n    let root = Directory(\"src\".into());\n    db.set_crate_root(crate_id, Some(root));\n\n    // Main module file.\n    set_file_content(db, \"src/lib.cairo\", \"#[foo_to_bar] fn foo() {}\");\n\n    // Find submodules.\n    let module_id = ModuleId::CrateRoot(crate_id);\n\n    // Verify that:\n    // 1. The original function remained.\n    // 2. The expected items were generated.\n    assert_eq!(\n        format!(\"{:?}\", db.module_items(module_id).unwrap().debug(db)),\n        \"[FreeFunctionId(test::foo), FreeFunctionId(test::bar), ExternTypeId(test::B)]\"\n    );\n}\n\n// Verify that if the first plugin removed the original item, the second item doesn't act on the\n// original item.\n#[test]\nfn test_first_plugin_removes() {\n    let mut db_val = DatabaseForTesting::default();\n    let db = &mut db_val;\n    let crate_id = db.intern_crate(CrateLongId(\"test\".into()));\n    let root = Directory(\"src\".into());\n    db.set_crate_root(crate_id, Some(root));\n\n    // Main module file.\n    set_file_content(db, \"src/lib.cairo\", \"#[remove_orig] fn foo() {}\");\n\n    // Find submodules.\n    let module_id = ModuleId::CrateRoot(crate_id);\n\n    // Verify that:\n    // 1. The original function was removed.\n    // 2. No 'B' was generated by DummyPlugin.\n    // Note RemoveOrigPlugin is before DummyPlugin in the plugins order. RemoveOrigPlugin already\n    // acted on 'foo', so DummyPlugin shouldn't.\n    assert_eq!(format!(\"{:?}\", db.module_items(module_id).unwrap().debug(db)), \"[]\");\n}\n\n// Verify that if the first plugin generates new code, the later plugins don't act on the\n// original // item.\n#[test]\nfn test_first_plugin_generates() {\n    let mut db_val = DatabaseForTesting::default();\n    let db = &mut db_val;\n    let crate_id = db.intern_crate(CrateLongId(\"test\".into()));\n    let root = Directory(\"src\".into());\n    db.set_crate_root(crate_id, Some(root));\n\n    // Main module file.\n    set_file_content(db, \"src/lib.cairo\", \"#[foo_to_bar] #[remove_orig] fn foo() {}\");\n\n    // Find submodules.\n    let module_id = ModuleId::CrateRoot(crate_id);\n\n    // Verify that:\n    // 1. 'bar' was generated by FooToBarPlugin.\n    // 2. the original function remained.\n    // Note RemoveOrigPlugin is after FooToBarPlugin in the plugins order. FooToBarPlugin already\n    // acted on the original 'foo' and thus RemoveOrigPlugin shouldn't act on it.\n    assert_eq!(\n        format!(\"{:?}\", db.module_items(module_id).unwrap().debug(db)),\n        \"[FreeFunctionId(test::foo), FreeFunctionId(test::bar), ExternTypeId(test::B)]\"\n    );\n}\n\n// Verify that the later plugins do act on items generated by earlier plugins.\n#[test]\nfn test_plugin_chain() {\n    let mut db_val = DatabaseForTesting::default();\n    let db = &mut db_val;\n    let crate_id = db.intern_crate(CrateLongId(\"test\".into()));\n    let root = Directory(\"src\".into());\n    db.set_crate_root(crate_id, Some(root));\n\n    // Main module file.\n    set_file_content(db, \"src/lib.cairo\", \"#[foo_to_bar] fn foo() {}\");\n\n    // Find submodules.\n    let module_id = ModuleId::CrateRoot(crate_id);\n\n    // Verify that:\n    // 1.  The original function remained.\n    // 2. 'bar' was generated by FooToBarPlugin.\n    // 3. 'B' were generated by DummyPlugin.\n    assert_eq!(\n        format!(\"{:?}\", db.module_items(module_id).unwrap().debug(db)),\n        \"[FreeFunctionId(test::foo), FreeFunctionId(test::bar), ExternTypeId(test::B)]\"\n    )\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "#[cfg(test)]\n#[path = \"diagnostics_test.rs\"]\nmod test;\n\nuse std::sync::Arc;\n\nuse cairo_lang_filesystem::db::FilesGroup;\nuse cairo_lang_filesystem::ids::FileId;\nuse cairo_lang_filesystem::span::TextSpan;\nuse cairo_lang_utils::Upcast;\nuse itertools::Itertools;\n\nuse crate::location_marks::get_location_marks;\n\n/// A trait for diagnostics (i.e., errors and warnings) across the compiler.\n/// Meant to be implemented by each module that may produce diagnostics.\npub trait DiagnosticEntry: Clone + std::fmt::Debug + Eq + std::hash::Hash {\n    type DbType: Upcast<dyn FilesGroup> + ?Sized;\n    fn format(&self, db: &Self::DbType) -> String;\n    fn location(&self, db: &Self::DbType) -> DiagnosticLocation;\n    // TODO(spapini): Add a way to inspect the diagnostic programmatically, e.g, downcast.\n}\npub struct DiagnosticLocation {\n    pub file_id: FileId,\n    pub span: TextSpan,\n}\nimpl DiagnosticLocation {\n    /// Get the location of right after this diagnostic's location (with width 0).\n    pub fn after(&self) -> Self {\n        Self { file_id: self.file_id, span: self.span.after() }\n    }\n}\n\n/// This struct is used to ensure that when an error occurs, a diagnostic is properly reported.\n///\n/// It must not be constructed directly. Instead it is returned by [DiagnosticsBuilder::add]\n/// when a diagnostic is reported.\n#[derive(Clone, Copy, Debug, Default, Eq, Hash, PartialEq)]\npub struct DiagnosticAdded;\n\npub fn skip_diagnostic() -> DiagnosticAdded {\n    // TODO(lior): Consider adding a log here.\n    DiagnosticAdded::default()\n}\n\n/// Represents an arbitrary type T or a missing output due to an error whose diagnostic was properly\n/// reported.\npub type Maybe<T> = Result<T, DiagnosticAdded>;\n\n/// Temporary trait to allow conversions from the old `Option<T>` mechanism to `Maybe<T>`.\n// TODO(lior): Remove this trait after converting all the functions.\npub trait ToMaybe<T> {\n    fn to_maybe(self) -> Maybe<T>;\n}\nimpl<T> ToMaybe<T> for Option<T> {\n    fn to_maybe(self) -> Maybe<T> {\n        match self {\n            Some(val) => Ok(val),\n            None => Err(skip_diagnostic()),\n        }\n    }\n}\n\n/// Temporary trait to allow conversions from `Maybe<T>` to `Option<T>`.\n/// The behavior is identical to [Result::ok]. It is used to mark all the location where there\n/// is a conversion between the two mechanisms.\n// TODO(lior): Remove this trait after converting all the functions.\npub trait ToOption<T> {\n    fn to_option(self) -> Option<T>;\n}\nimpl<T> ToOption<T> for Maybe<T> {\n    fn to_option(self) -> Option<T> {\n        self.ok()\n    }\n}\n\n/// A builder for Diagnostics, accumulating multiple diagnostic entries.\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct DiagnosticsBuilder<TEntry: DiagnosticEntry> {\n    pub count: usize,\n    pub leaves: Vec<TEntry>,\n    pub subtrees: Vec<Diagnostics<TEntry>>,\n}\nimpl<TEntry: DiagnosticEntry> DiagnosticsBuilder<TEntry> {\n    pub fn new() -> Self {\n        Self { leaves: Default::default(), subtrees: Default::default(), count: 0 }\n    }\n    pub fn add(&mut self, diagnostic: TEntry) -> DiagnosticAdded {\n        self.leaves.push(diagnostic);\n        self.count += 1;\n        DiagnosticAdded::default()\n    }\n    pub fn extend(&mut self, diagnostics: Diagnostics<TEntry>) {\n        self.count += diagnostics.len();\n        self.subtrees.push(diagnostics);\n    }\n    pub fn build(self) -> Diagnostics<TEntry> {\n        Diagnostics(Arc::new(self))\n    }\n}\n\nimpl<TEntry: DiagnosticEntry> Default for DiagnosticsBuilder<TEntry> {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\npub fn format_diagnostics(\n    db: &dyn FilesGroup,\n    message: &str,\n    location: DiagnosticLocation,\n) -> String {\n    let file_name = location.file_id.file_name(db);\n    let marks = get_location_marks(db, &location);\n    let pos = match location.span.start.position_in_file(db, location.file_id) {\n        Some(pos) => format!(\"{}:{}\", pos.line + 1, pos.col + 1),\n        None => \"?\".into(),\n    };\n    format!(\"error: {message}\\n --> {file_name}:{pos}\\n{marks}\\n\")\n}\n\n/// A set of diagnostic entries that arose during a computation.\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct Diagnostics<TEntry: DiagnosticEntry>(pub Arc<DiagnosticsBuilder<TEntry>>);\nimpl<TEntry: DiagnosticEntry> Diagnostics<TEntry> {\n    pub fn new() -> Self {\n        Self(DiagnosticsBuilder::default().into())\n    }\n\n    pub fn len(&self) -> usize {\n        self.0.count\n    }\n\n    pub fn is_empty(&self) -> bool {\n        self.0.count == 0\n    }\n\n    pub fn is_diagnostic_free(&self) -> Maybe<()> {\n        if self.is_empty() { Ok(()) } else { Err(DiagnosticAdded) }\n    }\n\n    pub fn format(&self, db: &TEntry::DbType) -> String {\n        let mut res = String::new();\n        // Format leaves.\n        for entry in &self.0.leaves {\n            let message = entry.format(db);\n            res += &format_diagnostics(db.upcast(), &message, entry.location(db));\n            res += \"\\n\";\n        }\n        // Format subtrees.\n        res += &self.0.subtrees.iter().map(|subtree| subtree.format(db)).join(\"\");\n        res\n    }\n\n    /// Asserts that no diagnostic has occurred, panicking with an error message on failure.\n    pub fn expect(&self, error_message: &str) {\n        assert!(self.0.leaves.is_empty(), \"{error_message}\\n{self:?}\");\n        for subtree in &self.0.subtrees {\n            subtree.expect(error_message);\n        }\n    }\n\n    /// Same as [Self::expect], except that the diagnostics are formatted.\n    pub fn expect_with_db(&self, db: &TEntry::DbType, error_message: &str) {\n        assert!(self.0.leaves.is_empty(), \"{}\\n{}\", error_message, self.format(db));\n        for subtree in &self.0.subtrees {\n            subtree.expect_with_db(db, error_message);\n        }\n    }\n\n    // TODO(spapini): This is temporary. Remove once the logic in language server doesn't use this.\n    pub fn get_all(&self) -> Vec<TEntry> {\n        let mut res = self.0.leaves.clone();\n        for subtree in &self.0.subtrees {\n            res.extend(subtree.get_all())\n        }\n        res\n    }\n}\nimpl<TEntry: DiagnosticEntry> Default for Diagnostics<TEntry> {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse cairo_lang_filesystem::db::FilesGroup;\nuse cairo_lang_filesystem::ids::{FileId, FileLongId, VirtualFile};\nuse cairo_lang_filesystem::span::{TextOffset, TextSpan, TextWidth};\nuse cairo_lang_filesystem::test_utils::FilesDatabaseForTesting;\nuse indoc::indoc;\nuse test_log::test;\n\nuse super::{DiagnosticEntry, DiagnosticLocation, DiagnosticsBuilder};\n\n// Test diagnostic.\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\nstruct SimpleDiag {\n    file_id: FileId,\n}\nimpl DiagnosticEntry for SimpleDiag {\n    type DbType = dyn FilesGroup;\n\n    fn format(&self, _db: &dyn cairo_lang_filesystem::db::FilesGroup) -> String {\n        \"Simple diagnostic.\".into()\n    }\n\n    fn location(&self, _db: &dyn cairo_lang_filesystem::db::FilesGroup) -> DiagnosticLocation {\n        DiagnosticLocation {\n            file_id: self.file_id,\n            span: TextSpan {\n                start: TextOffset::default().add_width(TextWidth::new_for_testing(0)),\n                end: TextOffset::default().add_width(TextWidth::new_for_testing(6)),\n            },\n        }\n    }\n}\n\nfn setup() -> (FilesDatabaseForTesting, FileId) {\n    let db_val = FilesDatabaseForTesting::default();\n    let file_id = db_val.intern_file(FileLongId::Virtual(VirtualFile {\n        parent: None,\n        name: \"dummy_file.sierra\".into(),\n        content: Arc::new(\"abcd\\nefg.\\n\".into()),\n    }));\n    (db_val, file_id)\n}\n\n#[test]\nfn test_diagnostics() {\n    let (db_val, file_id) = setup();\n\n    let mut diagnostics: DiagnosticsBuilder<SimpleDiag> = DiagnosticsBuilder::default();\n    let diagnostic = SimpleDiag { file_id };\n    diagnostics.add(diagnostic);\n\n    assert_eq!(\n        diagnostics.build().format(&db_val),\n        indoc! { \"\n            error: Simple diagnostic.\n             --> dummy_file.sierra:1:1\n            abcd\n            ^**^\n\n        \" }\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Diagnostics hold error information from around the compiler, associated with a location to the\n//! source files.\n\nmod diagnostics;\nmod location_marks;\n\npub use self::diagnostics::{\n    format_diagnostics, skip_diagnostic, DiagnosticAdded, DiagnosticEntry, DiagnosticLocation,\n    Diagnostics, DiagnosticsBuilder, Maybe, ToMaybe, ToOption,\n};\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_filesystem::span::{TextPosition, TextSpan, TextWidth};\n\nuse crate::DiagnosticLocation;\n\n#[cfg(test)]\n#[path = \"location_marks_test.rs\"]\nmod test;\n\npub fn get_location_marks(\n    db: &dyn cairo_lang_filesystem::db::FilesGroup,\n    location: &DiagnosticLocation,\n) -> String {\n    // TODO(ilya, 10/10/2023): Handle locations which spread over a few lines.\n    let content = db.file_content(location.file_id).expect(\"File missing from DB.\");\n    let summary = db.file_summary(location.file_id).expect(\"File missing from DB.\");\n\n    let span = &location.span;\n\n    let TextPosition { line: first_line_idx, col } = span\n        .start\n        .position_in_file(db, location.file_id)\n        .expect(\"Failed to find location in file.\");\n    let first_line_start = summary.line_offsets[first_line_idx];\n    let first_line_end = match summary.line_offsets.get(first_line_idx + 1) {\n        Some(offset) => offset.sub_width(TextWidth::from_char('\\n')),\n        None => summary.last_offset,\n    };\n\n    let first_line_span = TextSpan { start: first_line_start, end: first_line_end };\n    let mut res = first_line_span.take(&content).to_string();\n    res.push('\\n');\n    for _ in 0..col {\n        res.push(' ');\n    }\n    res.push('^');\n\n    let subspan_in_first_line =\n        TextSpan { start: span.start, end: std::cmp::min(first_line_end, span.end) };\n    let marker_length = subspan_in_first_line.n_chars(&content);\n    if marker_length > 1 {\n        for _ in 0..marker_length - 2 {\n            res.push('*');\n        }\n        res.push('^');\n    }\n\n    res\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse cairo_lang_filesystem::db::FilesGroup;\nuse cairo_lang_filesystem::ids::{FileLongId, VirtualFile};\nuse cairo_lang_filesystem::span::{TextSpan, TextWidth};\nuse cairo_lang_filesystem::test_utils::FilesDatabaseForTesting;\nuse indoc::indoc;\nuse pretty_assertions::assert_eq;\nuse test_log::test;\n\nuse super::get_location_marks;\nuse crate::DiagnosticLocation;\n\n#[test]\nfn test_location_marks() {\n    let content = indoc! {\"\n        First lin,\n        Second lin.\n        Third lin.\"};\n    // Note that content does not end with '\\n'.\n\n    let db = FilesDatabaseForTesting::default();\n    let file = db.intern_file(FileLongId::Virtual(VirtualFile {\n        parent: None,\n        name: \"name\".into(),\n        content: Arc::new(content.into()),\n    }));\n    let summary = db.file_summary(file).unwrap();\n    let second_line = summary.line_offsets[1];\n    let third_line = summary.line_offsets[2];\n\n    // Empty span.\n    let location = DiagnosticLocation {\n        file_id: file,\n        span: TextSpan {\n            start: second_line.add_width(TextWidth::new_for_testing(13)),\n            end: second_line.add_width(TextWidth::new_for_testing(13)),\n        },\n    };\n\n    assert_eq!(\n        get_location_marks(&db, &location) + \"\\n\",\n        indoc! {\"\n            Second lin.\n                        ^\n        \"}\n    );\n\n    // Span of length 1.\n    let location = DiagnosticLocation {\n        file_id: file,\n        span: TextSpan {\n            start: third_line.add_width(TextWidth::new_for_testing(3)),\n            end: third_line.add_width(TextWidth::new_for_testing(4)),\n        },\n    };\n\n    assert_eq!(\n        get_location_marks(&db, &location) + \"\\n\",\n        indoc! {\"\n            Third lin.\n               ^\n        \"}\n    );\n\n    // Span of length 2.\n    let location = DiagnosticLocation {\n        file_id: file,\n        span: TextSpan {\n            start: third_line.add_width(TextWidth::new_for_testing(3)),\n            end: third_line.add_width(TextWidth::new_for_testing(5)),\n        },\n    };\n\n    assert_eq!(\n        get_location_marks(&db, &location) + \"\\n\",\n        indoc! {\"\n            Third lin.\n               ^^\n        \"}\n    );\n\n    // Span of length > 1.\n    let location = DiagnosticLocation {\n        file_id: file,\n        span: TextSpan {\n            start: second_line.add_width(TextWidth::new_for_testing(7)),\n            end: second_line.add_width(TextWidth::new_for_testing(12)),\n        },\n    };\n\n    assert_eq!(\n        get_location_marks(&db, &location) + \"\\n\",\n        indoc! {\"\n            Second lin.\n                   ^**^\n        \"}\n    );\n\n    // Multiline span.\n    let location = DiagnosticLocation {\n        file_id: file,\n        span: TextSpan {\n            start: second_line.add_width(TextWidth::new_for_testing(7)),\n            end: third_line.add_width(TextWidth::new_for_testing(2)),\n        },\n    };\n\n    assert_eq!(\n        get_location_marks(&db, &location) + \"\\n\",\n        indoc! {\"\n            Second lin.\n                   ^***^\n        \"}\n    );\n\n    // Span that ends past the end of the file.\n    let location = DiagnosticLocation {\n        file_id: file,\n        span: TextSpan {\n            start: third_line.add_width(TextWidth::new_for_testing(7)),\n            end: summary.last_offset.add_width(TextWidth::from_char('\\n')),\n        },\n    };\n\n    assert_eq!(\n        get_location_marks(&db, &location) + \"\\n\",\n        indoc! {\"\n            Third lin.\n                   ^**^\n        \"}\n    );\n\n    // Empty span past the end of the file.\n    let location = DiagnosticLocation {\n        file_id: file,\n        span: TextSpan { start: summary.last_offset, end: summary.last_offset },\n    };\n\n    assert_eq!(\n        get_location_marks(&db, &location) + \"\\n\",\n        indoc! {\"\n            Third lin.\n                       ^\n        \"}\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::fmt::Debug;\nuse std::hash::Hash;\n\nuse cairo_lang_utils::collection_arithmetics::{add_maps, sub_maps, HasZero};\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\n\n#[cfg(test)]\n#[path = \"expr_test.rs\"]\nmod test;\n\n/// An linear expression of variables.\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct Expr<Var: Clone + Debug + PartialEq + Eq + Hash> {\n    /// The constant term of the expression.\n    pub const_term: i32,\n    /// The coefficient for every variable in the expression.\n    pub var_to_coef: OrderedHashMap<Var, i64>,\n}\nimpl<Var: Clone + Debug + PartialEq + Eq + Hash> Expr<Var> {\n    /// Creates a cost expression based on const value only.\n    pub fn from_const(const_term: i32) -> Self {\n        Self { const_term, var_to_coef: Default::default() }\n    }\n\n    /// Creates a cost expression based on variable only.\n    pub fn from_var(var: Var) -> Self {\n        Self { const_term: 0, var_to_coef: [(var, 1)].into_iter().collect() }\n    }\n}\n\nimpl<Var: Clone + Debug + PartialEq + Eq + Hash> HasZero for Expr<Var> {\n    fn zero() -> Self {\n        Self::from_const(0)\n    }\n}\n\n// Expr operators can be optimized if necessary.\nimpl<Var: Clone + Debug + PartialEq + Eq + Hash> std::ops::Add for Expr<Var> {\n    type Output = Self;\n    fn add(self, other: Self) -> Self {\n        Self {\n            const_term: self.const_term + other.const_term,\n            var_to_coef: add_maps(self.var_to_coef, other.var_to_coef),\n        }\n    }\n}\n\nimpl<Var: Clone + Debug + PartialEq + Eq + Hash> std::ops::Sub for Expr<Var> {\n    type Output = Self;\n    fn sub(self, other: Self) -> Self {\n        Self {\n            const_term: self.const_term - other.const_term,\n            var_to_coef: sub_maps(self.var_to_coef, other.var_to_coef),\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use test_log::test;\n\nuse super::Expr;\n\n#[test]\nfn operations() {\n    assert_eq!(\n        Expr::<usize>::from_const(1) + Expr::<usize>::from_const(2),\n        Expr::<usize>::from_const(3)\n    );\n    assert_eq!(\n        Expr::<usize>::from_const(1) - Expr::<usize>::from_const(2),\n        Expr::<usize>::from_const(-1)\n    );\n    assert_eq!(\n        Expr::<usize>::from_var(5) + Expr::<usize>::from_const(2),\n        Expr::<usize> { const_term: 2, var_to_coef: [(5, 1)].into_iter().collect() }\n    );\n    assert_eq!(\n        Expr::<usize>::from_var(5) - Expr::<usize>::from_const(2),\n        Expr::<usize> { const_term: -2, var_to_coef: [(5, 1)].into_iter().collect() }\n    );\n    assert_eq!(\n        Expr::<usize>::from_var(2) - Expr::<usize>::from_var(2),\n        Expr::<usize>::from_const(0)\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Equation solving for Sierra generation.\npub mod expr;\n\nuse std::fmt::Debug;\nuse std::hash::Hash;\n\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\npub use expr::Expr;\nuse good_lp::{default_solver, variable, variables, Expression, Solution, SolverModel};\n\n/// Solving a set of equations and returning the values of the symbols contained in them.\n/// # Arguments\n/// * `equations` - The equations to solve.\n/// * `minimization_vars` - Vars to minimize - in ranked ordering - first minimize the sum of the\n///   first set - then the sum of the second and so on.\n/// # Returns\n/// * `Some(OrderedHashMap<Var, i64>)` - The solutions to the equations.\n/// * `None` - The equations are unsolvable.\npub fn try_solve_equations<Var: Clone + Debug + PartialEq + Eq + Hash>(\n    mut equations: Vec<Expr<Var>>,\n    minimization_vars: Vec<Vec<Var>>,\n) -> Option<OrderedHashMap<Var, i64>> {\n    let (final_iter, high_rank_iters) = minimization_vars.split_last()?;\n    // Iterating over the non-last minimization var layers.\n    for target_vars in high_rank_iters {\n        let layer_solution = try_solve_equations_iteration(&equations, target_vars)?;\n        // Add constraints for the solution that we found for the target variables.\n        for v in target_vars {\n            let value = *layer_solution.get(v).unwrap();\n            equations.push(Expr::from_const(value.try_into().unwrap()) - Expr::from_var(v.clone()));\n        }\n    }\n    try_solve_equations_iteration(&equations, final_iter)\n}\n\n/// Solving a set of equations and returning the values of the symbols contained in them.\n/// # Arguments\n/// * `equations` - The equations to solve.\n/// * `target_vars` - Minimize the sum of those variables.\n/// # Returns\n/// * `Some(OrderedHashMap<Var, i64>)` - The solutions to the equations.\n/// * `None` - The equations are unsolvable.\nfn try_solve_equations_iteration<Var: Clone + Debug + PartialEq + Eq + Hash>(\n    equations: &[Expr<Var>],\n    target_vars: &[Var],\n) -> Option<OrderedHashMap<Var, i64>> {\n    let mut vars = variables!();\n    let mut orig_to_solver_var = OrderedHashMap::default();\n    // Add all variables to structure and map.\n    for eq in equations {\n        for var in eq.var_to_coef.keys() {\n            orig_to_solver_var\n                .entry(var.clone())\n                .or_insert_with_key(|var| vars.add(variable().min(0).name(format!(\"{var:?}\"))));\n        }\n    }\n    let target: Expression = target_vars.iter().map(|v| *orig_to_solver_var.get(v).unwrap()).sum();\n\n    let mut problem = vars.minimise(target).using(default_solver);\n    // Adding constraints for all equations.\n    for eq in equations.iter() {\n        let as_solver_expr = |expr: &Expr<Var>| {\n            Expression::from_other_affine(expr.const_term)\n                + expr\n                    .var_to_coef\n                    .iter()\n                    .map(|(var, coef)| (*coef as i32) * *orig_to_solver_var.get(var).unwrap())\n                    .sum::<Expression>()\n        };\n        problem = problem.with(as_solver_expr(eq).eq(Expression::from_other_affine(0)));\n    }\n    let solution = problem.solve().ok()?;\n    Some(\n        orig_to_solver_var\n            .into_iter()\n            .map(|(orig, solver)| (orig, solution.value(solver).round() as i64))\n            .collect(),\n    )\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "#[cfg(test)]\n#[path = \"db_test.rs\"]\nmod test;\n\nuse std::collections::HashMap;\nuse std::fs;\nuse std::path::PathBuf;\nuse std::sync::Arc;\n\nuse cairo_lang_utils::Upcast;\n\nuse crate::flag::Flag;\nuse crate::ids::{CrateId, CrateLongId, Directory, FileId, FileLongId, FlagId, FlagLongId};\nuse crate::span::{FileSummary, TextOffset, TextWidth};\n\npub const CORELIB_CRATE_NAME: &str = \"core\";\n\n// Salsa database interface.\n#[salsa::query_group(FilesDatabase)]\npub trait FilesGroup {\n    #[salsa::interned]\n    fn intern_crate(&self, crt: CrateLongId) -> CrateId;\n    #[salsa::interned]\n    fn intern_file(&self, file: FileLongId) -> FileId;\n    #[salsa::interned]\n    fn intern_flag(&self, flag: FlagLongId) -> FlagId;\n\n    /// Main input of the project. Lists all the crates.\n    #[salsa::input]\n    fn crate_roots(&self) -> Arc<HashMap<CrateId, Directory>>;\n\n    /// Overrides for file content. Mostly used by language server and tests.\n    /// TODO(spapini): Currently, when this input changes, all the file_content() queries will\n    /// be invalidated.\n    /// Change this mechanism to hold file_overrides on the db struct outside salsa mechanism,\n    /// and invalidate manually.\n    #[salsa::input]\n    fn file_overrides(&self) -> Arc<HashMap<FileId, Arc<String>>>;\n\n    // TODO(yuval): consider moving this to a separate crate, or rename this crate.\n    /// The compilation flags.\n    #[salsa::input]\n    fn flags(&self) -> Arc<HashMap<FlagId, Arc<Flag>>>;\n\n    /// List of crates in the project.\n    fn crates(&self) -> Vec<CrateId>;\n    /// Root directory of the crate.\n    fn crate_root_dir(&self, crate_id: CrateId) -> Option<Directory>;\n\n    /// Query for raw file contents. Private.\n    fn priv_raw_file_content(&self, file_id: FileId) -> Option<Arc<String>>;\n    /// Query for the file contents. This takes overrides into consideration.\n    fn file_content(&self, file_id: FileId) -> Option<Arc<String>>;\n    fn file_summary(&self, file_id: FileId) -> Option<Arc<FileSummary>>;\n\n    /// Query to get a compilation flag by its ID.\n    fn get_flag(&self, id: FlagId) -> Option<Arc<Flag>>;\n}\n\npub fn init_files_group(db: &mut (dyn FilesGroup + 'static)) {\n    // Initialize inputs.\n    db.set_file_overrides(Arc::new(HashMap::new()));\n    db.set_crate_roots(Arc::new(HashMap::new()));\n    db.set_flags(Arc::new(HashMap::new()));\n}\n\npub fn init_dev_corelib(db: &mut (dyn FilesGroup + 'static), path: PathBuf) {\n    let core_crate = db.intern_crate(CrateLongId(CORELIB_CRATE_NAME.into()));\n    let core_root_dir = Directory(path);\n    db.set_crate_root(core_crate, Some(core_root_dir));\n}\n\nimpl AsFilesGroupMut for dyn FilesGroup {\n    fn as_files_group_mut(&mut self) -> &mut (dyn FilesGroup + 'static) {\n        self\n    }\n}\n\npub trait FilesGroupEx: Upcast<dyn FilesGroup> + AsFilesGroupMut {\n    /// Overrides file content. None value removes the override.\n    fn override_file_content(&mut self, file: FileId, content: Option<Arc<String>>) {\n        let mut overrides = Upcast::upcast(self).file_overrides().as_ref().clone();\n        match content {\n            Some(content) => overrides.insert(file, content),\n            None => overrides.remove(&file),\n        };\n        self.as_files_group_mut().set_file_overrides(Arc::new(overrides));\n    }\n    /// Sets the root directory of the crate. None value removes the crate.\n    fn set_crate_root(&mut self, crt: CrateId, root: Option<Directory>) {\n        let mut crate_roots = Upcast::upcast(self).crate_roots().as_ref().clone();\n        match root {\n            Some(root) => crate_roots.insert(crt, root),\n            None => crate_roots.remove(&crt),\n        };\n        self.as_files_group_mut().set_crate_roots(Arc::new(crate_roots));\n    }\n    /// Sets the given flag value. None value removes the flag.\n    fn set_flag(&mut self, id: FlagId, value: Option<Arc<Flag>>) {\n        let mut flags = Upcast::upcast(self).flags().as_ref().clone();\n        match value {\n            Some(value) => flags.insert(id, value),\n            None => flags.remove(&id),\n        };\n        self.as_files_group_mut().set_flags(Arc::new(flags));\n    }\n}\nimpl<T: Upcast<dyn FilesGroup> + AsFilesGroupMut + ?Sized> FilesGroupEx for T {}\n\npub trait AsFilesGroupMut {\n    fn as_files_group_mut(&mut self) -> &mut (dyn FilesGroup + 'static);\n}\n\nfn crates(db: &dyn FilesGroup) -> Vec<CrateId> {\n    // TODO(spapini): Sort for stability.\n    db.crate_roots().keys().copied().collect()\n}\nfn crate_root_dir(db: &dyn FilesGroup, crt: CrateId) -> Option<Directory> {\n    db.crate_roots().get(&crt).cloned()\n}\n\nfn priv_raw_file_content(db: &dyn FilesGroup, file: FileId) -> Option<Arc<String>> {\n    match db.lookup_intern_file(file) {\n        FileLongId::OnDisk(path) => match fs::read_to_string(path) {\n            Ok(content) => Some(Arc::new(content)),\n            Err(_) => None,\n        },\n        FileLongId::Virtual(virt) => Some(virt.content),\n    }\n}\nfn file_content(db: &dyn FilesGroup, file: FileId) -> Option<Arc<String>> {\n    let overrides = db.file_overrides();\n    overrides.get(&file).cloned().or_else(|| db.priv_raw_file_content(file))\n}\nfn file_summary(db: &dyn FilesGroup, file: FileId) -> Option<Arc<FileSummary>> {\n    let content = db.file_content(file)?;\n    let mut line_offsets = vec![TextOffset::default()];\n    let mut offset = TextOffset::default();\n    for ch in content.chars() {\n        offset = offset.add_width(TextWidth::from_char(ch));\n        if ch == '\\n' {\n            line_offsets.push(offset);\n        }\n    }\n    Some(Arc::new(FileSummary { line_offsets, last_offset: offset }))\n}\nfn get_flag(db: &dyn FilesGroup, id: FlagId) -> Option<Arc<Flag>> {\n    db.flags().get(&id).cloned()\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse cairo_lang_utils::Upcast;\nuse test_log::test;\n\nuse super::FilesGroup;\nuse crate::db::FilesGroupEx;\nuse crate::flag::Flag;\nuse crate::ids::{CrateLongId, Directory, FlagId};\nuse crate::test_utils::FilesDatabaseForTesting;\n\n#[test]\nfn test_filesystem() {\n    let mut db = FilesDatabaseForTesting::default();\n\n    let crt = db.intern_crate(CrateLongId(\"my_crate\".into()));\n    let crt2 = db.intern_crate(CrateLongId(\"my_crate2\".into()));\n    let directory = Directory(\"src\".into());\n    let file_id = directory.file(&db, \"child.cairo\".into());\n    db.override_file_content(file_id, Some(Arc::new(\"content\\n\".into())));\n    db.set_crate_root(crt, Some(directory.clone()));\n\n    assert_eq!(db.crate_root_dir(crt), Some(directory));\n    assert!(db.crate_root_dir(crt2).is_none());\n\n    assert_eq!(*db.file_content(file_id).unwrap(), \"content\\n\");\n}\n\n#[test]\nfn test_flags() {\n    let mut db = FilesDatabaseForTesting::default();\n\n    let add_withdraw_gas_flag_id = FlagId::new(db.upcast(), \"add_withdraw_gas\");\n\n    db.set_flag(add_withdraw_gas_flag_id, Some(Arc::new(Flag::AddWithdrawGas(true))));\n\n    assert_eq!(*db.get_flag(add_withdraw_gas_flag_id).unwrap(), Flag::AddWithdrawGas(true));\n    assert!(db.get_flag(FlagId::new(db.upcast(), \"non_existing_flag\")).is_none());\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::path::{Path, PathBuf};\n\npub fn detect_corelib() -> Option<PathBuf> {\n    macro_rules! try_path {\n        ($base:expr, $up:expr) => {{\n            let mut path = $base.to_path_buf();\n            for _ in 0..$up {\n                path.pop();\n            }\n            path.push(\"corelib\");\n            path.push(\"src\");\n            if path.exists() {\n                return Some(path);\n            }\n        }};\n    }\n\n    if let Ok(cargo_dir) = std::env::var(\"CARGO_MANIFEST_DIR\") {\n        // This is the directory of Cargo.toml of the current crate.\n        // This is used for development of the compiler.\n        let dir = Path::new(&cargo_dir);\n        try_path!(dir, 1);\n        try_path!(dir, 2);\n    }\n\n    if let Ok(dir) = std::env::current_exe() {\n        try_path!(&dir, 2);\n        try_path!(&dir, 3);\n    }\n\n    None\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "/// A compilation flag.\n#[derive(PartialEq, Eq, Debug)]\npub enum Flag {\n    AddWithdrawGas(bool),\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::path::PathBuf;\nuse std::sync::Arc;\n\nuse cairo_lang_utils::define_short_id;\nuse path_clean::PathClean;\nuse smol_str::SmolStr;\n\nuse crate::db::FilesGroup;\n\npub const CAIRO_FILE_EXTENSION: &str = \"cairo\";\n\n/// A crate is a standalone file tree representing a single compilation unit.\n#[derive(Clone, Debug, Hash, PartialEq, Eq)]\npub struct CrateLongId(pub SmolStr);\ndefine_short_id!(CrateId, CrateLongId, FilesGroup, lookup_intern_crate);\n\n/// The long ID for a compilation flag.\n#[derive(Clone, Debug, Hash, PartialEq, Eq)]\npub struct FlagLongId(pub SmolStr);\ndefine_short_id!(FlagId, FlagLongId, FilesGroup, lookup_intern_flag);\nimpl FlagId {\n    pub fn new(db: &dyn FilesGroup, name: &str) -> Self {\n        db.intern_flag(FlagLongId(name.into()))\n    }\n}\n\n/// We use a higher level FileId struct, because not all files are on disk. Some might be online.\n/// Some might be virtual/computed on demand.\n#[derive(Clone, Debug, Hash, PartialEq, Eq)]\npub enum FileLongId {\n    OnDisk(PathBuf),\n    Virtual(VirtualFile),\n}\n#[derive(Clone, Debug, Hash, PartialEq, Eq)]\npub struct VirtualFile {\n    pub parent: Option<FileId>,\n    pub name: SmolStr,\n    pub content: Arc<String>,\n}\ndefine_short_id!(FileId, FileLongId, FilesGroup, lookup_intern_file);\nimpl FileId {\n    pub fn new(db: &dyn FilesGroup, path: PathBuf) -> FileId {\n        db.intern_file(FileLongId::OnDisk(path.clean()))\n    }\n    pub fn file_name(self, db: &dyn FilesGroup) -> String {\n        match db.lookup_intern_file(self) {\n            FileLongId::OnDisk(path) => {\n                path.file_name().and_then(|x| x.to_str()).unwrap_or(\"<unknown>\").to_string()\n            }\n            FileLongId::Virtual(vf) => vf.name.to_string(),\n        }\n    }\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq)]\npub struct Directory(pub PathBuf);\n\nimpl Directory {\n    /// Returns a file inside this directory. The file and directory don't necessarily exist on\n    /// the file system. These are ids/paths to them.\n    pub fn file(&self, db: &dyn FilesGroup, name: SmolStr) -> FileId {\n        FileId::new(db, self.0.join(name.to_string()))\n    }\n\n    /// Returns a sub directory inside this directory. These directories don't necessarily exist on\n    /// the file system. These are ids/paths to them.\n    pub fn subdir(&self, name: SmolStr) -> Directory {\n        Directory(self.0.join(name.to_string()))\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Files and modules abstraction.\n\npub mod db;\npub mod detect;\npub mod flag;\npub mod ids;\npub mod span;\npub mod test_utils;\n",
    "metadata": {}
  },
  {
    "pageContent": "#[cfg(test)]\n#[path = \"span_test.rs\"]\nmod test;\n\nuse std::iter::Sum;\nuse std::ops::{Add, Sub};\n\nuse crate::db::FilesGroup;\nuse crate::ids::FileId;\n\n/// Byte length of a utf8 string.\n// Note: The wrapped value is private to make sure no one gets confused with non utf8 sizes.\n#[derive(Copy, Clone, Default, Debug, PartialEq, Eq, PartialOrd, Ord, Hash)]\npub struct TextWidth(u32);\nimpl TextWidth {\n    pub fn from_char(c: char) -> Self {\n        Self(c.len_utf8() as u32)\n    }\n    #[allow(clippy::should_implement_trait)]\n    pub fn from_str(s: &str) -> Self {\n        Self(s.len() as u32)\n    }\n    pub fn new_for_testing(value: u32) -> Self {\n        Self(value)\n    }\n}\nimpl Add for TextWidth {\n    type Output = Self;\n\n    fn add(self, rhs: Self) -> Self::Output {\n        Self(self.0 + rhs.0)\n    }\n}\nimpl Sub for TextWidth {\n    type Output = Self;\n\n    fn sub(self, rhs: Self) -> Self::Output {\n        Self(self.0 - rhs.0)\n    }\n}\nimpl Sum for TextWidth {\n    fn sum<I: Iterator<Item = Self>>(iter: I) -> Self {\n        Self(iter.map(|x| x.0).sum())\n    }\n}\n\n/// Byte offset inside a utf8 string.\n#[derive(Copy, Clone, Debug, Default, PartialEq, Eq, PartialOrd, Ord, Hash)]\npub struct TextOffset(TextWidth);\nimpl TextOffset {\n    pub fn add_width(&self, width: TextWidth) -> Self {\n        TextOffset(self.0 + width)\n    }\n    pub fn sub_width(&self, width: TextWidth) -> Self {\n        TextOffset(self.0 - width)\n    }\n    pub fn take_from<'a>(&self, content: &'a str) -> &'a str {\n        &content[(self.0.0 as usize)..]\n    }\n}\nimpl Sub for TextOffset {\n    type Output = TextWidth;\n\n    fn sub(self, rhs: Self) -> Self::Output {\n        TextWidth(self.0.0 - rhs.0.0)\n    }\n}\n\n#[derive(Copy, Clone, Debug, Default, PartialEq, Eq, Hash)]\npub struct TextSpan {\n    pub start: TextOffset,\n    pub end: TextOffset,\n}\nimpl TextSpan {\n    pub fn width(&self) -> TextWidth {\n        self.end - self.start\n    }\n    pub fn contains(&self, other: Self) -> bool {\n        self.start <= other.start && self.end >= other.end\n    }\n    pub fn take<'b>(&self, content: &'b str) -> &'b str {\n        &content[(self.start.0.0 as usize)..(self.end.0.0 as usize)]\n    }\n    pub fn n_chars(&self, content: &str) -> usize {\n        self.take(content).chars().count()\n    }\n    /// Get the span of width 0, located right after this span.\n    pub fn after(&self) -> Self {\n        Self { start: self.end, end: self.end }\n    }\n}\n\n/// Human readable position inside a file, in lines and characters.\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct TextPosition {\n    /// Line index, 0 based.\n    pub line: usize,\n    /// Character index inside the line, 0 based.\n    pub col: usize,\n}\n\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct FileSummary {\n    pub line_offsets: Vec<TextOffset>,\n    pub last_offset: TextOffset,\n}\n\nimpl TextOffset {\n    pub fn get_line_number(&self, db: &dyn FilesGroup, file: FileId) -> Option<usize> {\n        let summary = db.file_summary(file)?;\n        assert!(\n            *self <= summary.last_offset,\n            \"TextOffset out of range. {:?} > {:?}.\",\n            self.0,\n            summary.last_offset.0\n        );\n        Some(summary.line_offsets.binary_search(self).unwrap_or_else(|x| x - 1))\n    }\n\n    pub fn position_in_file(&self, db: &dyn FilesGroup, file: FileId) -> Option<TextPosition> {\n        let summary = db.file_summary(file)?;\n        let line_number = self.get_line_number(db, file)?;\n        let line_offset = summary.line_offsets[line_number];\n        let content = db.file_content(file)?;\n        let col = TextSpan { start: line_offset, end: *self }.n_chars(&content);\n        Some(TextPosition { line: line_number, col })\n    }\n}\n\nimpl FileSummary {\n    /// Gets the number of lines\n    pub fn line_count(&self) -> usize {\n        self.line_offsets.len()\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse test_log::test;\n\nuse super::TextOffset;\nuse crate::db::FilesGroup;\nuse crate::ids::{FileLongId, VirtualFile};\nuse crate::span::{TextPosition, TextWidth};\nuse crate::test_utils::FilesDatabaseForTesting;\n\nconst TEST_STRING: &str = \"01\\n23\\u{1230}\\r\\n456\\n\\n\\r\\n789\";\n\n#[test]\nfn test_span() {\n    let db = FilesDatabaseForTesting::default();\n    let file = db.intern_file(FileLongId::Virtual(VirtualFile {\n        parent: None,\n        name: \"name\".into(),\n        content: Arc::new(TEST_STRING.into()),\n    }));\n    assert_eq!(\n        TextOffset(TextWidth(0)).position_in_file(&db, file),\n        Some(TextPosition { line: 0, col: 0 })\n    );\n    assert_eq!(\n        TextOffset(TextWidth(1)).position_in_file(&db, file),\n        Some(TextPosition { line: 0, col: 1 })\n    );\n    assert_eq!(\n        TextOffset(TextWidth(2)).position_in_file(&db, file),\n        Some(TextPosition { line: 0, col: 2 })\n    );\n    assert_eq!(\n        TextOffset(TextWidth(3)).position_in_file(&db, file),\n        Some(TextPosition { line: 1, col: 0 })\n    );\n    // Offsets 6,7 is inside a unicode char.\n    assert_eq!(\n        TextOffset(TextWidth(8)).position_in_file(&db, file),\n        Some(TextPosition { line: 1, col: 3 })\n    );\n    assert_eq!(\n        TextOffset(TextWidth(9)).position_in_file(&db, file),\n        Some(TextPosition { line: 1, col: 4 })\n    );\n    assert_eq!(\n        TextOffset(TextWidth(10)).position_in_file(&db, file),\n        Some(TextPosition { line: 2, col: 0 })\n    );\n    assert_eq!(\n        TextOffset(TextWidth(14)).position_in_file(&db, file),\n        Some(TextPosition { line: 3, col: 0 })\n    );\n    assert_eq!(\n        TextOffset(TextWidth(15)).position_in_file(&db, file),\n        Some(TextPosition { line: 4, col: 0 })\n    );\n    assert_eq!(\n        TextOffset(TextWidth(16)).position_in_file(&db, file),\n        Some(TextPosition { line: 4, col: 1 })\n    );\n    assert_eq!(\n        TextOffset(TextWidth(17)).position_in_file(&db, file),\n        Some(TextPosition { line: 5, col: 0 })\n    );\n    assert_eq!(\n        TextOffset(TextWidth(19)).position_in_file(&db, file),\n        Some(TextPosition { line: 5, col: 2 })\n    );\n    assert_eq!(\n        TextOffset(TextWidth(20)).position_in_file(&db, file),\n        Some(TextPosition { line: 5, col: 3 })\n    );\n}\n\n#[test]\n#[should_panic(expected = \"TextOffset out of range. TextWidth(21) > TextWidth(20).\")]\nfn test_span_out_of_range() {\n    let db = FilesDatabaseForTesting::default();\n    let file = db.intern_file(FileLongId::Virtual(VirtualFile {\n        parent: None,\n        name: \"name\".into(),\n        content: Arc::new(TEST_STRING.into()),\n    }));\n    TextOffset(TextWidth(TEST_STRING.len() as u32 + 1)).position_in_file(&db, file);\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_utils::Upcast;\n\nuse crate::db::{init_files_group, AsFilesGroupMut, FilesDatabase, FilesGroup};\n\n// Test salsa database.\n#[salsa::database(FilesDatabase)]\npub struct FilesDatabaseForTesting {\n    storage: salsa::Storage<FilesDatabaseForTesting>,\n}\nimpl salsa::Database for FilesDatabaseForTesting {}\nimpl Default for FilesDatabaseForTesting {\n    fn default() -> Self {\n        let mut res = Self { storage: Default::default() };\n        init_files_group(&mut res);\n        res\n    }\n}\nimpl Upcast<dyn FilesGroup> for FilesDatabaseForTesting {\n    fn upcast(&self) -> &(dyn FilesGroup + 'static) {\n        self\n    }\n}\nimpl AsFilesGroupMut for FilesDatabaseForTesting {\n    fn as_files_group_mut(&mut self) -> &mut (dyn FilesGroup + 'static) {\n        self\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::fmt::Debug;\nuse std::path::Path;\nuse std::process::ExitCode;\nuse std::sync::atomic::{AtomicBool, Ordering};\n\nuse cairo_lang_formatter::{CairoFormatter, FormatOutcome, FormatterConfig, StdinFmt};\nuse cairo_lang_utils::logging::init_logging;\nuse clap::Parser;\nuse colored::Colorize;\nuse ignore::WalkState::Continue;\nuse ignore::{DirEntry, Error, ParallelVisitor, ParallelVisitorBuilder, WalkState};\nuse log::warn;\n\n/// Outputs a string to stderr if the verbose flag is true.\nfn eprintln_if_verbose(s: &str, verbose: bool) {\n    if verbose {\n        eprintln!(\"{s}\");\n    }\n}\n\n/// Sierra to casm compiler.\n/// Exits with 0/1 if the compilation fails.\n#[derive(Parser, Debug)]\n#[clap(version, verbatim_doc_comment)]\nstruct FormatterArgs {\n    /// Check mode, don't write the formatted files,\n    /// just output the diff between the original and the formatted file.\n    #[arg(short, long, default_value_t = false)]\n    check: bool,\n    /// Format directories content recursively.\n    #[arg(short, long, default_value_t = false)]\n    recursive: bool,\n    /// Print verbose output.\n    #[arg(short, long, default_value_t = false)]\n    verbose: bool,\n    /// Print parsing errors.\n    #[arg(short, long, default_value_t = false)]\n    print_parsing_errors: bool,\n    /// A list of files and directories to format. Use \"-\" for stdin.\n    files: Vec<String>,\n}\n\nfn print_error(error: anyhow::Error, path: String, args: &FormatterArgs) {\n    let parsed_errors = if args.print_parsing_errors {\n        format!(\"{error}\").red()\n    } else {\n        \"Run with '--print-parsing-errors' to see error details.\".red()\n    };\n    eprintln!(\n        \"{}\",\n        format!(\n            \"A parsing error occurred in {path}. The content was not formatted.\\n{parsed_errors}\"\n        )\n        .red()\n    );\n}\n\nstruct PathFormatter<'t> {\n    all_correct: &'t AtomicBool,\n    args: &'t FormatterArgs,\n    fmt: &'t CairoFormatter,\n}\n\nstruct PathFormatterBuilder<'t> {\n    all_correct: &'t AtomicBool,\n    args: &'t FormatterArgs,\n    fmt: &'t CairoFormatter,\n}\n\nimpl<'s, 't> ParallelVisitorBuilder<'s> for PathFormatterBuilder<'t>\nwhere\n    't: 's,\n{\n    fn build(&mut self) -> Box<dyn ParallelVisitor + 's> {\n        Box::new(PathFormatter { all_correct: self.all_correct, args: self.args, fmt: self.fmt })\n    }\n}\n\nfn check_file_formatting(fmt: &CairoFormatter, args: &FormatterArgs, path: &Path) -> bool {\n    match fmt.format_to_string(&path) {\n        Ok(FormatOutcome::Identical(_)) => true,\n        Ok(FormatOutcome::DiffFound(diff)) => {\n            println!(\"Diff found in file {}:\\n {}\", path.display(), diff.display_colored());\n            false\n        }\n        Err(parsing_error) => {\n            print_error(parsing_error, path.display().to_string(), args);\n            false\n        }\n    }\n}\n\nfn format_file_in_place(fmt: &CairoFormatter, args: &FormatterArgs, path: &Path) -> bool {\n    if let Err(parsing_error) = fmt.format_in_place(&path) {\n        print_error(parsing_error, path.display().to_string(), args);\n        false\n    } else {\n        true\n    }\n}\n\nimpl<'t> ParallelVisitor for PathFormatter<'t> {\n    fn visit(&mut self, dir_entry_res: Result<DirEntry, Error>) -> WalkState {\n        let dir_entry = if let Ok(dir_entry) = dir_entry_res {\n            dir_entry\n        } else {\n            warn!(\"Failed to read the file.\");\n            return Continue;\n        };\n\n        let file_type = if let Some(file_type) = dir_entry.file_type() {\n            file_type\n        } else {\n            warn!(\"Failed to read filetype.\");\n            return Continue;\n        };\n\n        if !file_type.is_file() {\n            return Continue;\n        }\n\n        let file_path = dir_entry.path();\n\n        if self.args.verbose {\n            eprintln!(\"Formatting file: {}.\", file_path.display());\n        }\n\n        let success = if self.args.check {\n            check_file_formatting(self.fmt, self.args, file_path)\n        } else {\n            format_file_in_place(self.fmt, self.args, file_path)\n        };\n\n        if !success {\n            self.all_correct.store(false, Ordering::Release);\n        }\n        Continue\n    }\n}\n\nfn format_path(start_path: &str, args: &FormatterArgs, fmt: &CairoFormatter) -> bool {\n    let base = Path::new(start_path);\n    let mut walk = fmt.walk(base);\n    if !args.recursive {\n        walk.max_depth(Some(1));\n    }\n\n    let all_correct = AtomicBool::new(true);\n    let mut builder = PathFormatterBuilder { args, fmt, all_correct: &all_correct };\n    walk.build_parallel().visit(&mut builder);\n\n    builder.all_correct.load(Ordering::Acquire)\n}\n\nfn format_stdin(args: &FormatterArgs, fmt: &CairoFormatter) -> bool {\n    match fmt.format_to_string(&StdinFmt) {\n        Ok(outcome) => {\n            if args.check {\n                match outcome {\n                    FormatOutcome::Identical(_) => true,\n                    FormatOutcome::DiffFound(diff) => {\n                        println!(\"{diff}\");\n                        false\n                    }\n                }\n            } else {\n                print!(\"{}\", FormatOutcome::into_output_text(outcome));\n                true\n            }\n        }\n        Err(parsing_error) => {\n            print_error(parsing_error, String::from(\"standard input\"), args);\n            false\n        }\n    }\n}\n\nfn main() -> ExitCode {\n    init_logging(log::LevelFilter::Off);\n    log::info!(\"Starting formatting.\");\n\n    let args = FormatterArgs::parse();\n    let config = FormatterConfig::default();\n    let fmt = CairoFormatter::new(config);\n\n    eprintln_if_verbose(\n        &format!(\"Start formatting. Check: {}, Recursive: {}.\", args.check, args.recursive),\n        args.verbose,\n    );\n\n    let all_correct = if args.files.len() == 1 && args.files[0] == \"-\" {\n        // Input comes from stdin\n        format_stdin(&args, &fmt)\n    } else if args.files.is_empty() {\n        // Input comes from current directory walk\n        format_path(\".\", &args, &fmt)\n    } else {\n        // Input comes from walk of listed locations\n        args.files.iter().all(|file| format_path(file, &args, &fmt))\n    };\n    if !all_correct && args.check { ExitCode::FAILURE } else { ExitCode::SUCCESS }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::fmt::{Debug, Display};\nuse std::fs;\nuse std::io::{stdin, Read};\nuse std::path::{Path, PathBuf};\nuse std::sync::Arc;\n\nuse anyhow::{anyhow, bail, Context, Result};\nuse cairo_lang_filesystem::db::FilesGroup;\nuse cairo_lang_filesystem::ids::{FileId, FileLongId, VirtualFile, CAIRO_FILE_EXTENSION};\nuse cairo_lang_parser::utils::{get_syntax_root_and_diagnostics, SimpleParserDatabase};\nuse diffy::{create_patch, PatchFormatter};\nuse ignore::types::TypesBuilder;\nuse ignore::WalkBuilder;\n\nuse crate::{get_formatted_file, FormatterConfig, CAIRO_FMT_IGNORE};\n\n/// A struct encapsulating the changes made by the formatter in a single file.\n///\n/// This struct implements [`Display`] and [`Debug`] traits, showing differences between\n/// the original and modified file content.\n#[derive(Clone)]\npub struct FileDiff {\n    pub original: String,\n    pub formatted: String,\n}\n\nimpl FileDiff {\n    pub fn display_colored(&self) -> FileDiffColoredDisplay<'_> {\n        FileDiffColoredDisplay { diff: self }\n    }\n}\n\nimpl Display for FileDiff {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        write!(f, \"{}\", create_patch(&self.original, &self.formatted))\n    }\n}\n\nimpl Debug for FileDiff {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        writeln!(f, \"FileDiff({self})\")\n    }\n}\n\n/// A helper struct for displaying a file diff with colored output.\n///\n/// This is implements a [`Display`] trait, so it can be used with `format!` and `println!`.\n/// If you prefer output without colors, use [`FileDiff`] instead.\npub struct FileDiffColoredDisplay<'a> {\n    diff: &'a FileDiff,\n}\n\nimpl<'a> Display for FileDiffColoredDisplay<'a> {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        let patch = create_patch(&self.diff.original, &self.diff.formatted);\n        let patch_formatter = PatchFormatter::new().with_color();\n        let formatted_patch = patch_formatter.fmt_patch(&patch);\n        formatted_patch.fmt(f)\n    }\n}\n\nimpl<'a> Debug for FileDiffColoredDisplay<'a> {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        writeln!(f, \"FileDiffColoredDisplay({:?})\", self.diff)\n    }\n}\n\n/// An output from file formatting.\n///\n/// Differentiates between already formatted files and files that differ after formatting.\n/// Contains the original file content and the formatted file content.\n#[derive(Debug)]\npub enum FormatOutcome {\n    Identical(String),\n    DiffFound(FileDiff),\n}\n\nimpl FormatOutcome {\n    pub fn into_output_text(self) -> String {\n        match self {\n            FormatOutcome::Identical(original) => original,\n            FormatOutcome::DiffFound(diff) => diff.formatted,\n        }\n    }\n}\n\n/// A struct used to indicate that the formatter input should be read from stdin.\n/// Implements the [`FormattableInput`] trait.\npub struct StdinFmt;\n\n/// A trait for types that can be used as input for the cairo formatter.\npub trait FormattableInput {\n    /// Converts the input to a [`FileId`] that can be used by the formatter.\n    fn to_file_id(&self, db: &dyn FilesGroup) -> Result<FileId>;\n    /// Overwrites the content of the input with the given string.\n    fn overwrite_content(&self, _content: String) -> Result<()>;\n}\n\nimpl FormattableInput for &Path {\n    fn to_file_id(&self, db: &dyn FilesGroup) -> Result<FileId> {\n        Ok(FileId::new(db, PathBuf::from(self)))\n    }\n    fn overwrite_content(&self, content: String) -> Result<()> {\n        fs::write(self, content)?;\n        Ok(())\n    }\n}\n\nimpl FormattableInput for String {\n    fn to_file_id(&self, db: &dyn FilesGroup) -> Result<FileId> {\n        Ok(db.intern_file(FileLongId::Virtual(VirtualFile {\n            parent: None,\n            name: \"string_to_format\".into(),\n            content: Arc::new(self.clone()),\n        })))\n    }\n\n    fn overwrite_content(&self, _content: String) -> Result<()> {\n        Ok(())\n    }\n}\n\nimpl FormattableInput for StdinFmt {\n    fn to_file_id(&self, db: &dyn FilesGroup) -> Result<FileId> {\n        let mut buffer = String::new();\n        stdin().read_to_string(&mut buffer)?;\n        Ok(db.intern_file(FileLongId::Virtual(VirtualFile {\n            parent: None,\n            name: \"<stdin>\".into(),\n            content: Arc::new(buffer),\n        })))\n    }\n    fn overwrite_content(&self, content: String) -> Result<()> {\n        print!(\"{content}\");\n        Ok(())\n    }\n}\n\nfn format_input(input: &dyn FormattableInput, config: &FormatterConfig) -> Result<FormatOutcome> {\n    let db = SimpleParserDatabase::default();\n    let file_id = input.to_file_id(&db).context(\"Unable to create virtual file.\")?;\n    let original_text =\n        db.file_content(file_id).ok_or_else(|| anyhow!(\"Unable to read from input.\"))?;\n    let (syntax_root, diagnostics) = get_syntax_root_and_diagnostics(&db, file_id, &original_text);\n    if !diagnostics.0.leaves.is_empty() {\n        bail!(diagnostics.format(&db));\n    }\n    let formatted_text = get_formatted_file(&db, &syntax_root, config.clone());\n\n    if &formatted_text == original_text.as_ref() {\n        Ok(FormatOutcome::Identical(original_text.to_string()))\n    } else {\n        let diff = FileDiff { original: original_text.to_string(), formatted: formatted_text };\n        Ok(FormatOutcome::DiffFound(diff))\n    }\n}\n\n/// A struct for formatting cairo files.\n///\n/// The formatter can operate on all types implementing the [`FormattableInput`] trait.\n/// Allows formatting in place, and for formatting to a string.\n#[derive(Debug)]\npub struct CairoFormatter {\n    formatter_config: FormatterConfig,\n}\n\nimpl CairoFormatter {\n    pub fn new(formatter_config: FormatterConfig) -> Self {\n        Self { formatter_config }\n    }\n\n    /// Returns a preconfigured `ignore::WalkBuilder` for the given path.\n    ///\n    /// Can be used for recursively formatting a directory under given path.\n    pub fn walk(&self, path: &Path) -> WalkBuilder {\n        let mut builder = WalkBuilder::new(path);\n        builder.add_custom_ignore_filename(CAIRO_FMT_IGNORE);\n        builder.follow_links(false);\n        builder.skip_stdout(true);\n\n        let mut types_builder = TypesBuilder::new();\n        types_builder.add(CAIRO_FILE_EXTENSION, &format!(\"*.{CAIRO_FILE_EXTENSION}\")).unwrap();\n        types_builder.select(CAIRO_FILE_EXTENSION);\n        builder.types(types_builder.build().unwrap());\n\n        builder\n    }\n\n    /// Formats the path in place, writing changes to the files.\n    /// The ['FormattaableInput'] trait implementation defines the method for persisting changes.\n    pub fn format_in_place(&self, input: &dyn FormattableInput) -> Result<FormatOutcome> {\n        match format_input(input, &self.formatter_config)? {\n            FormatOutcome::DiffFound(diff) => {\n                // Persist changes.\n                input.overwrite_content(diff.formatted.clone())?;\n                Ok(FormatOutcome::DiffFound(diff))\n            }\n            FormatOutcome::Identical(original) => Ok(FormatOutcome::Identical(original)),\n        }\n    }\n\n    /// Formats the path and returns the formatted string.\n    /// No changes are persisted. The original file is not modified.\n    pub fn format_to_string(&self, input: &dyn FormattableInput) -> Result<FormatOutcome> {\n        format_input(input, &self.formatter_config)\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::cmp::Ordering;\nuse std::fmt;\n\nuse cairo_lang_filesystem::span::TextWidth;\nuse cairo_lang_syntax as syntax;\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::{ast, SyntaxNode, TypedSyntaxNode};\nuse itertools::Itertools;\nuse syntax::node::kind::SyntaxKind;\n\nuse crate::FormatterConfig;\n\n#[derive(Clone, Debug, Copy, PartialEq, Eq, PartialOrd, Ord)]\n/// Defines the break point behaviour.\n/// Defined in get_break_line_point_properties.\npub enum BreakLinePointIndentation {\n    /// Represents a break line point group which should be indented when broken. For example,\n    /// binary expr:\n    ///\n    /// let x = 1\n    ///     + 2\n    ///     + 3\n    ///     + 4\n    Indented,\n    /// Represents a break line point group which should be indented when broken, except for the\n    /// last one in the group. For example, the break points before and after a StructArgList\n    /// indent the list itself, but the closing braces should not be indented:\n    ///\n    /// let x = Struct {\n    ///     first_arg: first_arg, second_arg: second_arg,\n    /// };\n    IndentedWithTail,\n    /// Represents a break line point which should not be indented when broken. For example, the\n    /// break points after TerminalComma of StructArgList.\n    /// Notice that the break line points StructArgList wrapping it incur indentation.\n    ///\n    /// let x = Struct {\n    ///     first_arg: first_arg,\n    ///     second_arg: second_arg,\n    ///     third_arg: third_arg,\n    ///     fourth_arg: fourth_arg,\n    ///     fifth_arg: fifth_arg,\n    /// };\n    NotIndented,\n}\n\n#[derive(Clone, Debug, PartialEq, Eq)]\n/// Properties defining the behaviour of a break line point.\npub struct BreakLinePointProperties {\n    /// Indicates that the break line point was added instead of an empty line in the code, which\n    /// means it must be preserved in the output. Notice that the number of consecutive empty line\n    /// break points is limitted and not all empty lines in the code creates an empty line break\n    /// points.\n    pub is_empty_line_breakpoint: bool,\n    /// Breaking precedence, lower values will break first.\n    pub precedence: usize,\n    /// Dictates the breaking indentation behaviour.\n    pub break_indentation: BreakLinePointIndentation,\n    /// Indicates whether a breakpoint is optional. An optional breakpoint may be broken only if\n    /// the line is too long. A non-optional breakpoint is always broken.\n    pub is_optional: bool,\n    /// Indicates to put a space instead of the break line point if it were not broken.\n    pub space_if_not_broken: bool,\n}\nimpl Ord for BreakLinePointProperties {\n    fn cmp(&self, other: &Self) -> Ordering {\n        match (self.is_empty_line_breakpoint, other.is_empty_line_breakpoint) {\n            (true, true) | (false, false) => self.precedence.cmp(&other.precedence),\n            (true, false) => Ordering::Greater,\n            (false, true) => Ordering::Less,\n        }\n    }\n}\n\nimpl PartialOrd for BreakLinePointProperties {\n    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {\n        Some(self.cmp(other))\n    }\n}\n\nimpl BreakLinePointProperties {\n    pub fn new(\n        precedence: usize,\n        break_indentation: BreakLinePointIndentation,\n        is_optional: bool,\n        space_if_not_broken: bool,\n    ) -> Self {\n        Self {\n            precedence,\n            break_indentation,\n            is_optional,\n            space_if_not_broken,\n            is_empty_line_breakpoint: false,\n        }\n    }\n    pub fn new_empty_line() -> Self {\n        Self {\n            precedence: 0,\n            break_indentation: BreakLinePointIndentation::NotIndented,\n            is_optional: false,\n            space_if_not_broken: false,\n            is_empty_line_breakpoint: true,\n        }\n    }\n}\n\n/// The possible parts of line trees.\n#[derive(Clone, Debug)]\nenum LineComponent {\n    /// A simple string to be printed.\n    Token(String),\n    /// Any break line point inside a protected zone is ignored unless\n    /// it has no sibling break line points.\n    /// For example, in the expression let \"x = 1 * (2 + 3);\" everything inside the parentheses\n    /// is collected into a protected zone and is broken only if the line is too\n    /// long after the first break line point (the one before the '*' operator) is broken.\n    /// More generally, any break point inside a protected zone is ignored unless there\n    /// are no breakpoints which are direct children of the parent LineBuilder.\n    /// The precedence dictates the order of breaking the protected zones, among sibling protected\n    /// zones. For example, the body of a function should be broken into separate lines before\n    /// the function signature.\n    ProtectedZone { builder: LineBuilder, precedence: usize },\n    /// Represent a space in the code.\n    Space,\n    /// Represent a leading indent.\n    Indent(usize),\n    /// An optional break line point, that will be used if the line is too long.\n    BreakLinePoint(BreakLinePointProperties),\n    /// A component representing a comment in the code. Leading (not trailing) comments are\n    /// disregarded when computing line width as it belongs to another line.\n    Comment { content: String, is_trailing: bool },\n}\nimpl LineComponent {\n    pub fn width(&self) -> usize {\n        match self {\n            Self::Token(s) => s.len(),\n            Self::ProtectedZone { builder, .. } => builder.width(),\n            Self::Space => 1,\n            Self::Indent(n) => *n,\n            Self::BreakLinePoint(properties) => usize::from(properties.space_if_not_broken),\n            Self::Comment { content, is_trailing } => {\n                if *is_trailing {\n                    content.len()\n                } else {\n                    // Comments before a line are not accounted for the line width.\n                    0\n                }\n            }\n        }\n    }\n}\nimpl fmt::Display for LineComponent {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            Self::Token(s) => write!(f, \"{s}\"),\n            Self::ProtectedZone { builder, .. } => write!(f, \"{builder}\"),\n            Self::Space => write!(f, \" \"),\n            Self::Indent(n) => write!(f, \"{}\", \" \".repeat(*n)),\n            Self::BreakLinePoint(properties) => {\n                write!(f, \"{}\", if properties.space_if_not_broken { \" \" } else { \"\" })\n            }\n            Self::Comment { content, .. } => write!(f, \"{content}\"),\n        }\n    }\n}\n\n/// Represents a line in the code, separated by optional break line points.\n/// Used to break the line if too long.\n#[derive(Clone, Debug)]\nstruct LineBuilder {\n    children: Vec<LineComponent>,\n    /// Indicates whether this builder is open, which means any new child should\n    /// be (recursively) appended to it. Otherwise, new children will be appended as its sibling.\n    is_open: bool,\n    /// Added break line points are temporarly collected into this vector. The vector is flushed\n    /// into the children vector if any other LineComponent is pushed. This prevents break line\n    /// points being added to the end of a line.\n    pending_break_line_points: Vec<LineComponent>,\n}\nimpl fmt::Display for LineBuilder {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        if self.is_only_indents() {\n            write!(f, \"\")\n        } else {\n            write!(f, \"{}\", self.children.iter().map(|child| child.to_string()).join(\"\"))\n        }\n    }\n}\nimpl LineBuilder {\n    /// Creates a new intermediate line.\n    pub fn default() -> Self {\n        Self { children: vec![], is_open: true, pending_break_line_points: vec![] }\n    }\n    /// Creates a new line builder initialized with an indent component.\n    pub fn new(indent_size: usize) -> Self {\n        if indent_size > 0 {\n            Self {\n                children: vec![LineComponent::Indent(indent_size)],\n                is_open: true,\n                pending_break_line_points: vec![],\n            }\n        } else {\n            Self::default()\n        }\n    }\n    /// Adds a a sub-builder as the next child.\n    /// All subsequent children will be added to this sub builder until set as closed.\n    fn open_sub_builder(&mut self, precedence: usize) {\n        let active_builder = self.get_active_builder_mut();\n        active_builder.flush_pending_break_line_points();\n        active_builder.push_child(LineComponent::ProtectedZone {\n            builder: LineBuilder::default(),\n            precedence,\n        });\n    }\n    /// Sets the last child, which is assumed to be a LineBuilder, as close.\n    /// New children will be siblings of this subtree.\n    fn close_sub_builder(&mut self) {\n        let active_builder = self.get_active_builder_mut();\n        active_builder.flush_pending_break_line_points();\n        active_builder.is_open = false;\n    }\n    /// Adds a line component as the next child. If the last child is an open LineBuilder the child\n    /// is recursively appended to the sub builder.\n    fn push_child(&mut self, component: LineComponent) {\n        match &component {\n            LineComponent::BreakLinePoint(properties) if !properties.is_empty_line_breakpoint => {\n                if !self.is_only_indents() {\n                    self.get_active_builder_mut().pending_break_line_points.push(component);\n                }\n            }\n            _ => {\n                let active_builder = self.get_active_builder_mut();\n                active_builder.flush_pending_break_line_points();\n                active_builder.children.push(component);\n            }\n        }\n    }\n    /// Appends a string to the line.\n    pub fn push_str(&mut self, s: &str) {\n        self.push_child(LineComponent::Token(s.to_string()));\n    }\n    /// Appends a space to the line.\n    pub fn push_space(&mut self) {\n        self.push_child(LineComponent::Space);\n    }\n    /// Appends a user-inserted empty line to the line.\n    pub fn push_empty_line_break_line_point(&mut self) {\n        self.push_child(LineComponent::BreakLinePoint(BreakLinePointProperties::new_empty_line()));\n    }\n    /// Appends an optional break line point.\n    pub fn push_break_line_point(&mut self, properties: BreakLinePointProperties) {\n        self.push_child(LineComponent::BreakLinePoint(properties));\n    }\n    /// Appends a comment to the line.\n    pub fn push_comment(&mut self, content: &str, is_trailing: bool) {\n        self.push_child(LineComponent::Comment { content: content.to_string(), is_trailing });\n    }\n    /// Appends all the pending break line points to the builder. Should be called whenever a\n    /// component of another type (i.e. not a break line point) is appended.\n    fn flush_pending_break_line_points(&mut self) {\n        self.children.append(&mut self.pending_break_line_points);\n    }\n    /// The width, in number of chars, of the whole LineTree.\n    fn width(&self) -> usize {\n        self.width_between(0, self.children.len())\n    }\n    /// The width, in number of chars, between the `start`th (inclusive)\n    /// and `end`th (exclusive) children.\n    fn width_between(&self, start: usize, end: usize) -> usize {\n        // TODO(Gil): Optimize to O(1).\n        self.children[start..end].iter().fold(0, |sum, node| sum + node.width())\n    }\n    /// Returns the next break line point properties from within all the break line points\n    /// which are a direct child of this tree, or None if there are no such break line points.\n    fn get_next_break_properties(&self) -> Option<BreakLinePointProperties> {\n        self.children\n            .iter()\n            .filter_map(|child| {\n                if let LineComponent::BreakLinePoint(properties) = child {\n                    Some(properties.clone())\n                } else {\n                    None\n                }\n            })\n            .min()\n    }\n    /// Returns a vector of the positions of all the break line point children which have the\n    /// specified precedence.\n    fn get_break_point_indices_by_precedence(&self, precedence: usize) -> Vec<usize> {\n        self.children\n            .iter()\n            .enumerate()\n            .filter_map(|(i, child)| match child {\n                LineComponent::BreakLinePoint(properties)\n                    if properties.precedence == precedence =>\n                {\n                    Some(i)\n                }\n                _ => None,\n            })\n            .collect()\n    }\n    /// Recursively calls break_line_tree until no break_line_point or protected zone exists in the\n    /// tree. Returns a vec of strings, each one represents a line.\n    fn break_line_tree(&self, max_line_width: usize, tab_size: usize) -> Vec<String> {\n        // TODO(gil): improve the complexity of this function. Right now the line builder is\n        // entirely cloned for each protected zone, which results in a worst case complexity of\n        // O(n*m) where n is the line length and m is the number of protected zones. The actual\n        // complexity is lower since the line is broken into smaller pieces and each one is handeled\n        // separetly.\n        let mut sub_builders = self.break_line_tree_single_level(max_line_width, tab_size);\n        // If the line was not broken into several lines (i.e. only one sub_builder), open the\n        // highest precedence protected zone and try to break again.\n        while sub_builders.len() == 1 {\n            // Break the line according to the break_line_points.\n            // TODO(Gil): remove the \"contains_break_line_points\" and return from the breaking\n            // function whether it broke any break points.\n            if sub_builders[0].contains_break_line_points() {\n                sub_builders =\n                    sub_builders[0].break_line_tree_single_level(max_line_width, tab_size)\n            } else if sub_builders[0].contains_protected_zone() {\n                // No break_line_points, open the highest precedence protected zone.\n                sub_builders = vec![sub_builders[0].open_protected_zone()];\n            } else {\n                // All break line points were already broken or removed.\n                // TODO(Gil): Propagate error to user if line is still too long.\n                return vec![self.to_string()];\n            }\n        }\n        // Keep breaking recursively the new lines.\n        sub_builders\n            .iter()\n            .flat_map(|tree| tree.break_line_tree(max_line_width, tab_size))\n            .collect()\n    }\n    /// Breaks the LineTree once into a vector of LineTrees according to the highest precedence\n    /// (lowest precedence number) break line point found in the LineTree.\n    fn break_line_tree_single_level(\n        &self,\n        max_line_width: usize,\n        tab_size: usize,\n    ) -> Vec<LineBuilder> {\n        let Some(break_line_point_properties) = self.get_next_break_properties() else {\n            return vec![self.clone()];\n        };\n        let mut breaking_positions =\n            self.get_break_point_indices_by_precedence(break_line_point_properties.precedence);\n        if self.width() <= max_line_width && break_line_point_properties.is_optional {\n            return vec![self.remove_all_optional_break_line_points()];\n        }\n        let base_indent = self.get_leading_indent();\n        let mut trees: Vec<LineBuilder> = vec![];\n        let n_children = self.children.len();\n        // Dummy break line point, simplifies the loop.\n        breaking_positions.push(n_children);\n        let n_break_points = breaking_positions.len();\n\n        let mut current_line_start = 0;\n        // Iterate over the break line points and collect each part between them into one new\n        // LineBuilder.\n        for (i, current_line_end) in breaking_positions.iter().enumerate() {\n            let added_indent = match break_line_point_properties.break_indentation {\n                BreakLinePointIndentation::Indented if i != 0 => tab_size,\n                BreakLinePointIndentation::IndentedWithTail\n                    if i != 0 && i != n_break_points - 1 =>\n                {\n                    tab_size\n                }\n                _ => 0,\n            };\n            trees.push(LineBuilder::new(base_indent + added_indent));\n            for j in current_line_start..*current_line_end {\n                match &self.children[j] {\n                    LineComponent::Indent(_) => {}\n                    LineComponent::Space => {\n                        // Ignore spaces at the start of a line\n                        if !trees.last().unwrap().is_only_indents() {\n                            trees.last_mut().unwrap().push_space();\n                        }\n                    }\n                    _ => trees.last_mut().unwrap().push_child(self.children[j].clone()),\n                }\n            }\n            current_line_start = *current_line_end + 1;\n        }\n        trees\n    }\n    /// Returns a reference to the currently active builder.\n    fn get_active_builder_mut(&mut self) -> &mut LineBuilder {\n        // Splitted into two match statements since self is mutably borrowed in the second match,\n        // and thus a mutable ref to self can't be returned in it.\n        match self.children.last() {\n            Some(LineComponent::ProtectedZone { builder: sub_builder, .. })\n                if sub_builder.is_open => {}\n            _ => {\n                return self;\n            }\n        }\n        match self.children.last_mut() {\n            Some(LineComponent::ProtectedZone { builder: sub_builder, .. })\n                if sub_builder.is_open =>\n            {\n                sub_builder.get_active_builder_mut()\n            }\n            _ => {\n                unreachable!(\"This case is covered in the first match.\")\n            }\n        }\n    }\n    /// Creates a string of the code represented in the builder. The string may represent\n    /// several lines (separated by '\\n'), where each line length is\n    /// less than max_line_width (if possible).\n    /// Each line is prepended by the leading\n    pub fn build(&self, max_line_width: usize, tab_size: usize) -> String {\n        self.break_line_tree(max_line_width, tab_size).iter().join(\"\\n\") + \"\\n\"\n    }\n    /// Returns the highest protected zone precedence (minimum number) from within all the protected\n    /// zones which are direct children of this builder, or None if there are no protected zones\n    /// direct-children.\n    fn get_highest_protected_zone_precedence(&self) -> Option<usize> {\n        self.children\n            .iter()\n            .filter_map(|child| {\n                if let LineComponent::ProtectedZone { precedence, .. } = child {\n                    Some(*precedence)\n                } else {\n                    None\n                }\n            })\n            .min()\n    }\n    /// Creates a new LineBuilder where the first subchild which is a protected zone, is now\n    /// unprotected.\n    fn open_protected_zone(&self) -> LineBuilder {\n        let mut unprotected_builder = LineBuilder::default();\n        let mut first_protected_zone_found = false;\n        let highest_precedence = self\n            .get_highest_protected_zone_precedence()\n            .expect(\"Tried to unprotect a line builder with no protected zones.\");\n        for child in self.children.iter() {\n            match child {\n                LineComponent::ProtectedZone { builder: sub_tree, precedence }\n                    if *precedence == highest_precedence && !first_protected_zone_found =>\n                {\n                    first_protected_zone_found = true;\n                    for sub_child in sub_tree.children.iter() {\n                        unprotected_builder.push_child(sub_child.clone());\n                    }\n                }\n                _ => unprotected_builder.push_child(child.clone()),\n            }\n        }\n        unprotected_builder\n    }\n    /// Returns whether or not the line contains a protected zone.\n    fn contains_protected_zone(&self) -> bool {\n        self.children.iter().any(|child| matches!(child, LineComponent::ProtectedZone { .. }))\n    }\n    /// Returns whether the line contains only indents.\n    fn is_only_indents(&self) -> bool {\n        !self.children.iter().any(|child| !matches!(child, LineComponent::Indent { .. }))\n    }\n    fn get_leading_indent(&self) -> usize {\n        let mut leading_indent = 0;\n        let mut children_iter = self.children.iter();\n        while let Some(LineComponent::Indent(indent_size)) = children_iter.next() {\n            leading_indent += indent_size\n        }\n        leading_indent\n    }\n    /// Returns whether the line contains a break point.\n    fn contains_break_line_points(&self) -> bool {\n        self.children.iter().any(|child| matches!(child, LineComponent::BreakLinePoint(_)))\n    }\n    // Removes all the break line points.\n    fn remove_all_optional_break_line_points(&self) -> LineBuilder {\n        LineBuilder {\n            children: self\n                .children\n                .iter()\n                .map(|child| match child {\n                    LineComponent::BreakLinePoint(node_properties)\n                        if node_properties.is_optional =>\n                    {\n                        LineComponent::Token(child.to_string())\n                    }\n                    _ => child.clone(),\n                })\n                .collect_vec(),\n            is_open: true,\n            pending_break_line_points: vec![],\n        }\n    }\n}\n\n/// A struct holding all the data of the pending line to be emitted.\nstruct PendingLineState {\n    /// Intermidiate representation of the text to be emitted.\n    line_buffer: LineBuilder,\n    /// Should the next space between tokens be ignored.\n    force_no_space_after: bool,\n}\n\nimpl PendingLineState {\n    pub fn new() -> Self {\n        Self { line_buffer: LineBuilder::default(), force_no_space_after: true }\n    }\n}\n\n/// Represents the break line points before and after a syntax node.\npub struct WrappingBreakLinePoints {\n    pub leading: Option<BreakLinePointProperties>,\n    pub trailing: Option<BreakLinePointProperties>,\n}\n\n// TODO(spapini): Intorduce the correct types here, to reflect the \"applicable\" nodes types.\npub trait SyntaxNodeFormat {\n    /// Returns true if a token should never have a space before it.\n    /// Only applicable for token nodes.\n    fn force_no_space_before(&self, db: &dyn SyntaxGroup) -> bool;\n    /// Returns true if a token should never have a space after it.\n    /// Only applicable for token nodes.\n    fn force_no_space_after(&self, db: &dyn SyntaxGroup) -> bool;\n    /// Returns true if the line is allowed to break after the node.\n    /// Only applicable for terminal nodes.\n    fn allow_newline_after(&self, db: &dyn SyntaxGroup) -> bool;\n    /// Returns the number of allowed empty lines between two consecutive children of this node.\n    fn allowed_empty_between(&self, db: &dyn SyntaxGroup) -> usize;\n    /// Returns the break point properties before and after a specific node if a break point should\n    /// exist, otherwise returns None.\n    fn get_wrapping_break_line_point_properties(\n        &self,\n        db: &dyn SyntaxGroup,\n    ) -> WrappingBreakLinePoints;\n    /// If self is a protected zone, returns its precedence (highest precedence == lowest number).\n    /// Otherwise, returns None.\n    fn get_protected_zone_precedence(&self, db: &dyn SyntaxGroup) -> Option<usize>;\n}\n\npub struct FormatterImpl<'a> {\n    db: &'a dyn SyntaxGroup,\n    config: FormatterConfig,\n    /// A buffer for the current line.\n    line_state: PendingLineState,\n    /// The number of empty lines allowed after the current node.\n    empty_lines_allowance: usize,\n    /// Indicates whether the current line only consists of whitespace tokens (since the last\n    /// newline).\n    is_current_line_whitespaces: bool,\n}\n\nimpl<'a> FormatterImpl<'a> {\n    pub fn new(db: &'a dyn SyntaxGroup, config: FormatterConfig) -> Self {\n        Self {\n            db,\n            config,\n            line_state: PendingLineState::new(),\n            empty_lines_allowance: 0,\n            is_current_line_whitespaces: true,\n        }\n    }\n    /// Gets a root of a syntax tree and returns the formatted string of the code it represents.\n    pub fn get_formatted_string(&mut self, syntax_node: &SyntaxNode) -> String {\n        self.format_node(syntax_node, false);\n        self.line_state.line_buffer.build(self.config.max_line_length, self.config.tab_size)\n    }\n    /// Appends a formatted string, representing the syntax_node, to the result.\n    /// Should be called with a root syntax node to format a file.\n    pub fn format_node(&mut self, syntax_node: &SyntaxNode, no_space_after: bool) {\n        if syntax_node.text(self.db).is_some() {\n            panic!(\"Token reached before terminal.\");\n        }\n        let protected_zone_precedence = syntax_node.get_protected_zone_precedence(self.db);\n        let node_break_points = syntax_node.get_wrapping_break_line_point_properties(self.db);\n        self.append_break_line_point(node_break_points.leading);\n        if let Some(precedence) = protected_zone_precedence {\n            self.line_state.line_buffer.open_sub_builder(precedence);\n        }\n        if syntax_node.kind(self.db).is_terminal() {\n            self.format_terminal(syntax_node, no_space_after);\n        } else {\n            self.format_internal(syntax_node, no_space_after);\n        }\n        if protected_zone_precedence.is_some() {\n            self.line_state.line_buffer.close_sub_builder();\n        }\n        self.append_break_line_point(node_break_points.trailing);\n    }\n    /// Formats an internal node and appends the formatted string to the result.\n    fn format_internal(&mut self, syntax_node: &SyntaxNode, no_space_after: bool) {\n        let allowed_empty_between = syntax_node.allowed_empty_between(self.db);\n\n        let no_space_after = no_space_after || syntax_node.force_no_space_after(self.db);\n        let children = syntax_node.children(self.db);\n        let n_children = children.len();\n        for (i, child) in children.enumerate() {\n            if child.width(self.db) == TextWidth::default() {\n                continue;\n            }\n            self.format_node(&child, no_space_after && i == n_children - 1);\n\n            self.empty_lines_allowance = allowed_empty_between;\n        }\n    }\n    /// Formats a terminal node and appends the formatted string to the result.\n    fn format_terminal(&mut self, syntax_node: &SyntaxNode, no_space_after: bool) {\n        // TODO(spapini): Introduce a Terminal and a Token enum in ast.rs to make this cleaner.\n        let mut children = syntax_node.children(self.db);\n        let leading_trivia = ast::Trivia::from_syntax_node(self.db, children.next().unwrap());\n        let token = children.next().unwrap();\n        let trailing_trivia = ast::Trivia::from_syntax_node(self.db, children.next().unwrap());\n\n        // The first newlines is the leading trivia correspond exactly to empty lines.\n        self.format_trivia(leading_trivia, true);\n        self.format_token(&token, no_space_after || syntax_node.force_no_space_after(self.db));\n        self.format_trivia(trailing_trivia, false);\n    }\n    /// Appends a trivia node (if needed) to the result.\n    fn format_trivia(&mut self, trivia: syntax::node::ast::Trivia, is_leading: bool) {\n        for trivium in trivia.elements(self.db) {\n            match trivium {\n                ast::Trivium::SingleLineComment(_) => {\n                    if !is_leading {\n                        self.line_state.line_buffer.push_space();\n                    }\n                    self.line_state.line_buffer.push_comment(\n                        &trivium.as_syntax_node().text(self.db).unwrap(),\n                        !is_leading,\n                    );\n                    self.is_current_line_whitespaces = false;\n                    self.empty_lines_allowance = 1;\n\n                    self.line_state.line_buffer.push_break_line_point(\n                        BreakLinePointProperties::new(\n                            // Should be greater than any other precedence.\n                            usize::MAX,\n                            BreakLinePointIndentation::NotIndented,\n                            false,\n                            false,\n                        ),\n                    );\n                }\n                ast::Trivium::Whitespace(_) => {}\n                ast::Trivium::Newline(_) => {\n                    if self.empty_lines_allowance > 0 && self.is_current_line_whitespaces {\n                        self.empty_lines_allowance -= 1;\n                        self.line_state.line_buffer.push_empty_line_break_line_point();\n                    }\n                    self.is_current_line_whitespaces = true;\n                }\n                ast::Trivium::Skipped(_) => {\n                    self.format_token(&trivium.as_syntax_node(), false);\n                }\n            }\n        }\n    }\n    /// Formats a token node and appends it to the result.\n    /// Assumes the given SyntaxNode is a token.\n    fn format_token(&mut self, syntax_node: &SyntaxNode, no_space_after: bool) {\n        let no_space_after = no_space_after || syntax_node.force_no_space_after(self.db);\n        let text = syntax_node.text(self.db).unwrap();\n        if !syntax_node.force_no_space_before(self.db) && !self.line_state.force_no_space_after {\n            self.line_state.line_buffer.push_space();\n        }\n        self.line_state.force_no_space_after = no_space_after;\n\n        if syntax_node.kind(self.db) != SyntaxKind::TokenWhitespace {\n            self.is_current_line_whitespaces = false;\n        }\n        let node_break_points = syntax_node.get_wrapping_break_line_point_properties(self.db);\n        self.append_break_line_point(node_break_points.leading);\n        self.line_state.line_buffer.push_str(&text);\n        self.append_break_line_point(node_break_points.trailing);\n    }\n    fn append_break_line_point(&mut self, properties: Option<BreakLinePointProperties>) {\n        if let Some(properties) = properties {\n            self.line_state.line_buffer.push_break_line_point(properties);\n            self.line_state.force_no_space_after = true;\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Cairo formatter.\n//!\n//! This crate is responsible for formatting Cairo code.\npub mod cairo_formatter;\npub mod formatter_impl;\npub mod node_properties;\n\nuse std::sync::Arc;\n\nuse cairo_lang_diagnostics::DiagnosticsBuilder;\nuse cairo_lang_filesystem::ids::{FileLongId, VirtualFile};\nuse cairo_lang_parser::parser::Parser;\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::{SyntaxNode, TypedSyntaxNode};\n\npub use crate::cairo_formatter::{CairoFormatter, FormatOutcome, StdinFmt};\nuse crate::formatter_impl::FormatterImpl;\n\n#[cfg(test)]\nmod test;\n\npub const CAIRO_FMT_IGNORE: &str = \".cairofmtignore\";\n\n/// Returns the formatted syntax tree as a string.\n/// # Arguments\n/// * `db` - The syntax group.\n/// * `syntax_root` - The syntax root.\n/// * `config` - The formatter configuration.\n/// # Returns\n/// * `String` - The formatted file.\npub fn get_formatted_file(\n    db: &dyn SyntaxGroup,\n    syntax_root: &SyntaxNode,\n    config: FormatterConfig,\n) -> String {\n    let mut formatter = FormatterImpl::new(db, config);\n    formatter.get_formatted_string(syntax_root)\n}\n\n/// Formats Cairo code given as a string.\n/// # Arguments\n/// * `db` - The syntax group.\n/// * `content` - The code to format.\n/// # Returns\n/// * `String` - The formatted code.\npub fn format_string(db: &dyn SyntaxGroup, content: String) -> String {\n    let virtual_file = db.upcast().intern_file(FileLongId::Virtual(VirtualFile {\n        parent: None,\n        name: \"string_to_format\".into(),\n        content: Arc::new(content.clone()),\n    }));\n    let mut diagnostics = DiagnosticsBuilder::new();\n    let syntax_root =\n        Parser::parse_file(db, &mut diagnostics, virtual_file, content.as_str()).as_syntax_node();\n    get_formatted_file(db, &syntax_root, FormatterConfig::default())\n}\n\n#[derive(Debug, Clone)]\npub struct FormatterConfig {\n    tab_size: usize,\n    max_line_length: usize,\n}\n\n// Config params\n// TODO(Gil): export to file and load from file\nconst TAB_SIZE: usize = 4;\nconst MAX_LINE_LENGTH: usize = 100;\n\nimpl FormatterConfig {\n    pub fn new(tab_size: usize, max_line_length: usize) -> Self {\n        Self { tab_size, max_line_length }\n    }\n}\nimpl Default for FormatterConfig {\n    fn default() -> Self {\n        Self::new(TAB_SIZE, MAX_LINE_LENGTH)\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::kind::SyntaxKind;\nuse cairo_lang_syntax::node::utils::{grandparent_kind, parent_kind};\nuse cairo_lang_syntax::node::SyntaxNode;\n\nuse crate::formatter_impl::{\n    BreakLinePointIndentation, BreakLinePointProperties, SyntaxNodeFormat, WrappingBreakLinePoints,\n};\n\nimpl SyntaxNodeFormat for SyntaxNode {\n    fn force_no_space_before(&self, db: &dyn SyntaxGroup) -> bool {\n        match self.kind(db) {\n            SyntaxKind::TokenDot\n            | SyntaxKind::TokenColonColon\n            | SyntaxKind::TokenComma\n            | SyntaxKind::TokenSemicolon\n            | SyntaxKind::TokenQuestionMark\n            | SyntaxKind::TokenRParen\n            | SyntaxKind::TokenRBrack\n            | SyntaxKind::TokenLBrack\n            | SyntaxKind::TokenSingleLineComment => true,\n            SyntaxKind::TokenLParen\n                if matches!(\n                    grandparent_kind(db, self),\n                    Some(SyntaxKind::FunctionSignature | SyntaxKind::AttributeArgs)\n                ) =>\n            {\n                true\n            }\n            SyntaxKind::TokenColon\n                if grandparent_kind(db, self) != Some(SyntaxKind::ArgClauseFieldInitShorthand) =>\n            {\n                true\n            }\n            SyntaxKind::TokenLT | SyntaxKind::TokenGT\n                if matches!(\n                    grandparent_kind(db, self),\n                    Some(\n                        SyntaxKind::PathSegmentWithGenericArgs\n                            | SyntaxKind::GenericArgs\n                            | SyntaxKind::WrappedGenericParamList\n                    )\n                ) =>\n            {\n                true\n            }\n            _ => false,\n        }\n    }\n\n    fn force_no_space_after(&self, db: &dyn SyntaxGroup) -> bool {\n        match self.kind(db) {\n            SyntaxKind::TokenDot\n            | SyntaxKind::TokenNot\n            | SyntaxKind::TokenAt\n            | SyntaxKind::TokenColonColon\n            | SyntaxKind::TokenLParen\n            | SyntaxKind::TokenLBrack\n            | SyntaxKind::TokenLBrace\n            | SyntaxKind::TokenImplicits => true,\n            SyntaxKind::ExprPath | SyntaxKind::TerminalIdentifier\n                if matches!(\n                    parent_kind(db, self),\n                    Some(\n                        SyntaxKind::FunctionWithBody\n                            | SyntaxKind::ItemExternFunction\n                            | SyntaxKind::ExprFunctionCall\n                            | SyntaxKind::PatternEnum\n                            | SyntaxKind::PatternStruct\n                    )\n                ) =>\n            {\n                true\n            }\n            SyntaxKind::TokenMinus | SyntaxKind::TokenMul => {\n                matches!(grandparent_kind(db, self), Some(SyntaxKind::ExprUnary))\n            }\n            SyntaxKind::TokenLT\n                if matches!(\n                    grandparent_kind(db, self),\n                    Some(\n                        SyntaxKind::PathSegmentWithGenericArgs\n                            | SyntaxKind::GenericArgs\n                            | SyntaxKind::WrappedGenericParamList\n                    )\n                ) =>\n            {\n                true\n            }\n            SyntaxKind::TokenColon\n                if grandparent_kind(db, self) == Some(SyntaxKind::ArgClauseFieldInitShorthand) =>\n            {\n                true\n            }\n            _ => false,\n        }\n    }\n    // TODO(gil): consider removing this function as it is no longer used.\n    fn allow_newline_after(&self, _db: &dyn SyntaxGroup) -> bool {\n        false\n    }\n    fn allowed_empty_between(&self, db: &dyn SyntaxGroup) -> usize {\n        match self.kind(db) {\n            SyntaxKind::ItemList => 2,\n            SyntaxKind::StatementList => 1,\n            _ => 0,\n        }\n    }\n    // TODO(Gil): Add all protected zones and break points when the formatter is stable.\n    fn get_protected_zone_precedence(&self, db: &dyn SyntaxGroup) -> Option<usize> {\n        match parent_kind(db, self) {\n            // TODO(Gil): protected zone precefences should be local for each syntax node.\n            Some(SyntaxKind::ItemList | SyntaxKind::StatementList) => Some(0),\n            Some(SyntaxKind::FunctionWithBody) => match self.kind(db) {\n                SyntaxKind::AttributeList => Some(1),\n                SyntaxKind::ExprBlock => Some(2),\n                SyntaxKind::FunctionDeclaration => Some(3),\n                _ => None,\n            },\n            Some(SyntaxKind::ItemExternFunction) => match self.kind(db) {\n                SyntaxKind::AttributeList => Some(1),\n                SyntaxKind::FunctionDeclaration => Some(2),\n                _ => None,\n            },\n            Some(SyntaxKind::FunctionDeclaration) => match self.kind(db) {\n                SyntaxKind::FunctionSignature => Some(1),\n                SyntaxKind::WrappedGenericParamList => Some(2),\n                _ => None,\n            },\n            Some(SyntaxKind::ItemEnum) => match self.kind(db) {\n                SyntaxKind::AttributeList => Some(1),\n                SyntaxKind::MemberList => Some(2),\n                SyntaxKind::WrappedGenericParamList => Some(3),\n                _ => None,\n            },\n            Some(SyntaxKind::ExprMatch) => match self.kind(db) {\n                SyntaxKind::MatchArms => Some(1),\n                SyntaxKind::ExprBinary\n                | SyntaxKind::ExprBlock\n                | SyntaxKind::ExprErrorPropagate\n                | SyntaxKind::ExprFieldInitShorthand\n                | SyntaxKind::ExprFunctionCall\n                | SyntaxKind::ExprIf\n                | SyntaxKind::ExprList\n                | SyntaxKind::ExprMatch\n                | SyntaxKind::ExprMissing\n                | SyntaxKind::ExprParenthesized\n                | SyntaxKind::ExprPath\n                | SyntaxKind::ExprStructCtorCall\n                | SyntaxKind::ExprTuple\n                | SyntaxKind::ExprUnary => Some(10),\n                _ => None,\n            },\n            Some(SyntaxKind::StatementLet) => match self.kind(db) {\n                SyntaxKind::ExprBinary\n                | SyntaxKind::ExprBlock\n                | SyntaxKind::ExprErrorPropagate\n                | SyntaxKind::ExprFieldInitShorthand\n                | SyntaxKind::ExprFunctionCall\n                | SyntaxKind::ExprIf\n                | SyntaxKind::ExprList\n                | SyntaxKind::ExprMatch\n                | SyntaxKind::ExprMissing\n                | SyntaxKind::ExprParenthesized\n                | SyntaxKind::ExprPath\n                | SyntaxKind::ExprStructCtorCall\n                | SyntaxKind::ExprTuple\n                | SyntaxKind::ExprUnary => Some(1),\n                SyntaxKind::TerminalEq => Some(10),\n                SyntaxKind::PatternEnum | SyntaxKind::PatternTuple | SyntaxKind::PatternStruct => {\n                    Some(11)\n                }\n                SyntaxKind::TypeClause => Some(12),\n                _ => None,\n            },\n            _ => match self.kind(db) {\n                SyntaxKind::ExprParenthesized\n                | SyntaxKind::ExprList\n                | SyntaxKind::ExprBlock\n                | SyntaxKind::ExprTuple\n                | SyntaxKind::PatternTuple\n                | SyntaxKind::ModuleBody\n                | SyntaxKind::MatchArms\n                | SyntaxKind::MatchArm\n                | SyntaxKind::StructArgList\n                | SyntaxKind::TraitItemList\n                | SyntaxKind::PatternStructParamList\n                | SyntaxKind::PatternList\n                | SyntaxKind::ParamList\n                | SyntaxKind::ImplicitsList\n                | SyntaxKind::ImplicitsClause\n                | SyntaxKind::MemberList\n                | SyntaxKind::ArgList\n                | SyntaxKind::Arg\n                | SyntaxKind::AttributeArgList\n                | SyntaxKind::GenericArgList\n                | SyntaxKind::GenericParamList\n                | SyntaxKind::ArgListParenthesized\n                | SyntaxKind::StatementList\n                | SyntaxKind::ItemList\n                | SyntaxKind::ItemEnum => Some(5),\n                _ => None,\n            },\n        }\n    }\n    fn get_wrapping_break_line_point_properties(\n        &self,\n        db: &dyn SyntaxGroup,\n    ) -> WrappingBreakLinePoints {\n        match parent_kind(db, self) {\n            Some(SyntaxKind::ItemList) => WrappingBreakLinePoints {\n                leading: None,\n                trailing: Some(BreakLinePointProperties::new(\n                    1,\n                    BreakLinePointIndentation::NotIndented,\n                    false,\n                    false,\n                )),\n            },\n            Some(SyntaxKind::StatementList) => WrappingBreakLinePoints {\n                leading: None,\n                trailing: Some(BreakLinePointProperties::new(\n                    10,\n                    BreakLinePointIndentation::NotIndented,\n                    false,\n                    false,\n                )),\n            },\n            Some(SyntaxKind::TraitItemList) => WrappingBreakLinePoints {\n                leading: None,\n                trailing: Some(BreakLinePointProperties::new(\n                    12,\n                    BreakLinePointIndentation::NotIndented,\n                    false,\n                    false,\n                )),\n            },\n            Some(SyntaxKind::ModuleBody | SyntaxKind::ImplBody)\n                if self.kind(db) == SyntaxKind::ItemList =>\n            {\n                WrappingBreakLinePoints {\n                    leading: Some(BreakLinePointProperties::new(\n                        14,\n                        BreakLinePointIndentation::IndentedWithTail,\n                        false,\n                        true,\n                    )),\n                    trailing: Some(BreakLinePointProperties::new(\n                        14,\n                        BreakLinePointIndentation::IndentedWithTail,\n                        false,\n                        true,\n                    )),\n                }\n            }\n            Some(SyntaxKind::AttributeList) => WrappingBreakLinePoints {\n                leading: None,\n                trailing: Some(BreakLinePointProperties::new(\n                    20,\n                    BreakLinePointIndentation::NotIndented,\n                    false,\n                    false,\n                )),\n            },\n            _ => match self.kind(db) {\n                SyntaxKind::ParamList\n                | SyntaxKind::ExprList\n                | SyntaxKind::ImplicitsList\n                | SyntaxKind::PatternList => WrappingBreakLinePoints {\n                    leading: Some(BreakLinePointProperties::new(\n                        2,\n                        BreakLinePointIndentation::IndentedWithTail,\n                        true,\n                        false,\n                    )),\n                    trailing: Some(BreakLinePointProperties::new(\n                        2,\n                        BreakLinePointIndentation::IndentedWithTail,\n                        true,\n                        false,\n                    )),\n                },\n                SyntaxKind::StructArgList => WrappingBreakLinePoints {\n                    leading: Some(BreakLinePointProperties::new(\n                        3,\n                        BreakLinePointIndentation::IndentedWithTail,\n                        true,\n                        true,\n                    )),\n                    trailing: Some(BreakLinePointProperties::new(\n                        3,\n                        BreakLinePointIndentation::IndentedWithTail,\n                        true,\n                        true,\n                    )),\n                },\n                SyntaxKind::MemberList => WrappingBreakLinePoints {\n                    leading: Some(BreakLinePointProperties::new(\n                        3,\n                        BreakLinePointIndentation::IndentedWithTail,\n                        false,\n                        true,\n                    )),\n                    trailing: Some(BreakLinePointProperties::new(\n                        3,\n                        BreakLinePointIndentation::IndentedWithTail,\n                        false,\n                        true,\n                    )),\n                },\n                SyntaxKind::ArgList => WrappingBreakLinePoints {\n                    leading: Some(BreakLinePointProperties::new(\n                        3,\n                        BreakLinePointIndentation::IndentedWithTail,\n                        true,\n                        false,\n                    )),\n                    trailing: Some(BreakLinePointProperties::new(\n                        3,\n                        BreakLinePointIndentation::IndentedWithTail,\n                        true,\n                        false,\n                    )),\n                },\n                SyntaxKind::StatementList => WrappingBreakLinePoints {\n                    leading: Some(BreakLinePointProperties::new(\n                        4,\n                        BreakLinePointIndentation::IndentedWithTail,\n                        false,\n                        true,\n                    )),\n                    trailing: Some(BreakLinePointProperties::new(\n                        4,\n                        BreakLinePointIndentation::IndentedWithTail,\n                        false,\n                        true,\n                    )),\n                },\n                SyntaxKind::TraitItemList => WrappingBreakLinePoints {\n                    leading: Some(BreakLinePointProperties::new(\n                        5,\n                        BreakLinePointIndentation::IndentedWithTail,\n                        false,\n                        true,\n                    )),\n                    trailing: Some(BreakLinePointProperties::new(\n                        5,\n                        BreakLinePointIndentation::IndentedWithTail,\n                        false,\n                        true,\n                    )),\n                },\n                SyntaxKind::MatchArms => WrappingBreakLinePoints {\n                    leading: Some(BreakLinePointProperties::new(\n                        11,\n                        BreakLinePointIndentation::IndentedWithTail,\n                        false,\n                        true,\n                    )),\n                    trailing: Some(BreakLinePointProperties::new(\n                        11,\n                        BreakLinePointIndentation::IndentedWithTail,\n                        false,\n                        true,\n                    )),\n                },\n                SyntaxKind::TerminalComma\n                    if !matches!(\n                        parent_kind(db, self),\n                        Some(SyntaxKind::MatchArms) | Some(SyntaxKind::MemberList)\n                    ) =>\n                {\n                    WrappingBreakLinePoints {\n                        leading: None,\n                        trailing: Some(BreakLinePointProperties::new(\n                            5,\n                            BreakLinePointIndentation::NotIndented,\n                            true,\n                            true,\n                        )),\n                    }\n                }\n                SyntaxKind::TerminalComma => WrappingBreakLinePoints {\n                    leading: None,\n                    trailing: Some(BreakLinePointProperties::new(\n                        6,\n                        BreakLinePointIndentation::NotIndented,\n                        false,\n                        true,\n                    )),\n                },\n                SyntaxKind::TerminalPlus => WrappingBreakLinePoints {\n                    leading: Some(BreakLinePointProperties::new(\n                        7,\n                        BreakLinePointIndentation::Indented,\n                        true,\n                        true,\n                    )),\n                    trailing: None,\n                },\n                SyntaxKind::TerminalMinus\n                    if parent_kind(db, self) != Some(SyntaxKind::ExprUnary) =>\n                {\n                    WrappingBreakLinePoints {\n                        leading: Some(BreakLinePointProperties::new(\n                            7,\n                            BreakLinePointIndentation::Indented,\n                            true,\n                            true,\n                        )),\n                        trailing: None,\n                    }\n                }\n                SyntaxKind::TerminalMul if parent_kind(db, self) != Some(SyntaxKind::ExprUnary) => {\n                    WrappingBreakLinePoints {\n                        leading: Some(BreakLinePointProperties::new(\n                            9,\n                            BreakLinePointIndentation::Indented,\n                            true,\n                            true,\n                        )),\n                        trailing: None,\n                    }\n                }\n                SyntaxKind::TerminalDiv => WrappingBreakLinePoints {\n                    leading: Some(BreakLinePointProperties::new(\n                        9,\n                        BreakLinePointIndentation::Indented,\n                        true,\n                        true,\n                    )),\n                    trailing: None,\n                },\n                SyntaxKind::TokenEq\n                | SyntaxKind::TokenPlusEq\n                | SyntaxKind::TokenMinusEq\n                | SyntaxKind::TokenMulEq\n                | SyntaxKind::TokenDivEq\n                | SyntaxKind::TokenModEq => WrappingBreakLinePoints {\n                    leading: None,\n                    trailing: Some(BreakLinePointProperties::new(\n                        10,\n                        BreakLinePointIndentation::Indented,\n                        true,\n                        true,\n                    )),\n                },\n                _ => WrappingBreakLinePoints { leading: None, trailing: None },\n            },\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::fs;\n\nuse cairo_lang_filesystem::db::{FilesDatabase, FilesGroup};\nuse cairo_lang_parser::utils::{get_syntax_root_and_diagnostics_from_file, SimpleParserDatabase};\nuse cairo_lang_syntax::node::db::SyntaxDatabase;\nuse cairo_lang_utils::Upcast;\nuse pretty_assertions::assert_eq;\nuse test_case::test_case;\n\nuse crate::{get_formatted_file, FormatterConfig};\n\n#[salsa::database(SyntaxDatabase, FilesDatabase)]\n#[derive(Default)]\npub struct DatabaseImpl {\n    storage: salsa::Storage<DatabaseImpl>,\n}\nimpl salsa::Database for DatabaseImpl {}\nimpl Upcast<dyn FilesGroup> for DatabaseImpl {\n    fn upcast(&self) -> &(dyn FilesGroup + 'static) {\n        self\n    }\n}\n\n// TODO(Gil): Add tests\n#[test_case(\"test_data/cairo_files/test1.cairo\", \"test_data/expected_results/test1.cairo\")]\n#[test_case(\n    \"test_data/cairo_files/linebreaking.cairo\",\n    \"test_data/expected_results/linebreaking.cairo\"\n)]\nfn format_and_compare_file(unformatted_filename: &str, expected_filename: &str) {\n    let db_val = SimpleParserDatabase::default();\n    let db = &db_val;\n\n    let (syntax_root, diagnostics) =\n        get_syntax_root_and_diagnostics_from_file(db, unformatted_filename);\n    diagnostics.expect(&format!(\n        \"There were parsing errors while trying to format the code:\\n{}\",\n        diagnostics.format(db)\n    ));\n    let config = FormatterConfig::default();\n    let formatted_file = get_formatted_file(db, &syntax_root, config);\n    let expected_file =\n        fs::read_to_string(expected_filename).expect(\"Expected file does not exists.\");\n    assert_eq!(formatted_file, expected_file);\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_compiler::db::RootDatabase;\nuse cairo_lang_language_server::{Backend, State};\nuse cairo_lang_starknet::db::StarknetRootDatabaseBuilderEx;\nuse cairo_lang_utils::logging::init_logging;\nuse tower_lsp::{LspService, Server};\n\n#[tokio::main]\nasync fn main() {\n    init_logging(log::LevelFilter::Warn);\n\n    #[cfg(feature = \"runtime-agnostic\")]\n    use tokio_util::compat::{TokioAsyncReadCompatExt, TokioAsyncWriteCompatExt};\n\n    let (stdin, stdout) = (tokio::io::stdin(), tokio::io::stdout());\n    #[cfg(feature = \"runtime-agnostic\")]\n    let (stdin, stdout) = (stdin.compat(), stdout.compat_write());\n\n    let db = RootDatabase::builder()\n        .detect_corelib()\n        .with_starknet()\n        .build()\n        .expect(\"Failed to initialize Cairo compiler database.\");\n\n    let (service, socket) = LspService::build(|client| Backend {\n        client,\n        db_mutex: db.into(),\n        state_mutex: State::default().into(),\n    })\n    .custom_method(\"vfs/provide\", Backend::vfs_provide)\n    .finish();\n    Server::new(stdin, stdout, socket).serve(service).await;\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Cairo language server.\n//!\n//! Implements the LSP protocol over stdin/out.\n\nmod semantic_highlighting;\n\nuse std::collections::{HashMap, HashSet};\nuse std::io::BufRead;\nuse std::path::PathBuf;\nuse std::process::{Command, Stdio};\nuse std::sync::Arc;\n\nuse anyhow::anyhow;\nuse cairo_lang_compiler::db::RootDatabase;\nuse cairo_lang_compiler::project::{setup_project, update_crate_roots_from_project_config};\nuse cairo_lang_debug::DebugWithDb;\nuse cairo_lang_defs::db::DefsGroup;\nuse cairo_lang_defs::ids::{\n    ConstantLongId, EnumLongId, ExternFunctionLongId, ExternTypeLongId, FileIndex,\n    FreeFunctionLongId, FunctionTitleId, FunctionWithBodyId, ImplDefLongId, ImplFunctionLongId,\n    LanguageElementId, LookupItemId, ModuleFileId, ModuleId, ModuleItemId, StructLongId,\n    TraitLongId, UseLongId,\n};\nuse cairo_lang_diagnostics::{DiagnosticEntry, Diagnostics, ToOption};\nuse cairo_lang_filesystem::db::{\n    AsFilesGroupMut, FilesGroup, FilesGroupEx, PrivRawFileContentQuery,\n};\nuse cairo_lang_filesystem::ids::{CrateLongId, Directory, FileId, FileLongId};\nuse cairo_lang_filesystem::span::{TextPosition, TextWidth};\nuse cairo_lang_formatter::{get_formatted_file, FormatterConfig};\nuse cairo_lang_lowering::db::LoweringGroup;\nuse cairo_lang_lowering::diagnostic::LoweringDiagnostic;\nuse cairo_lang_parser::db::ParserGroup;\nuse cairo_lang_parser::ParserDiagnostic;\nuse cairo_lang_project::ProjectConfig;\nuse cairo_lang_semantic::db::SemanticGroup;\nuse cairo_lang_semantic::items::function_with_body::SemanticExprLookup;\nuse cairo_lang_semantic::items::functions::GenericFunctionId;\nuse cairo_lang_semantic::resolve_path::ResolvedGenericItem;\nuse cairo_lang_semantic::SemanticDiagnostic;\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::helpers::GetIdentifier;\nuse cairo_lang_syntax::node::kind::SyntaxKind;\nuse cairo_lang_syntax::node::stable_ptr::SyntaxStablePtr;\nuse cairo_lang_syntax::node::utils::is_grandparent_of_kind;\nuse cairo_lang_syntax::node::{ast, SyntaxNode, TypedSyntaxNode};\nuse cairo_lang_utils::ordered_hash_set::OrderedHashSet;\nuse cairo_lang_utils::{try_extract_matches, OptionHelper, Upcast};\nuse log::warn;\nuse salsa::InternKey;\nuse semantic_highlighting::token_kind::SemanticTokenKind;\nuse semantic_highlighting::SemanticTokensTraverser;\nuse serde::{Deserialize, Serialize};\nuse serde_json::Value;\nuse smol_str::SmolStr;\nuse tower_lsp::jsonrpc::Result;\nuse tower_lsp::lsp_types::*;\nuse tower_lsp::{Client, LanguageServer};\nuse vfs::{ProvideVirtualFileRequest, ProvideVirtualFileResponse};\npub mod vfs;\n\nconst MAX_CRATE_DETECTION_DEPTH: usize = 20;\nconst SCARB_PROJECT_FILE_NAME: &str = \"Scarb.toml\";\n\n#[derive(Default, PartialEq, Eq)]\npub struct FileDiagnostics {\n    pub parser: Diagnostics<ParserDiagnostic>,\n    pub semantic: Diagnostics<SemanticDiagnostic>,\n    pub lowering: Diagnostics<LoweringDiagnostic>,\n}\n#[derive(Default)]\npub struct State {\n    pub file_diagnostics: HashMap<FileId, FileDiagnostics>,\n    pub open_files: HashSet<FileId>,\n}\npub struct Backend {\n    pub client: Client,\n    // TODO(spapini): Remove this once we support ParallelDatabase.\n    pub db_mutex: tokio::sync::Mutex<RootDatabase>,\n    pub state_mutex: tokio::sync::Mutex<State>,\n}\nfn from_pos(pos: TextPosition) -> Position {\n    Position { line: pos.line as u32, character: pos.col as u32 }\n}\nimpl Backend {\n    /// Locks and gets a database instance.\n    async fn db(&self) -> tokio::sync::MutexGuard<'_, RootDatabase> {\n        self.db_mutex.lock().await\n    }\n    /// Gets a FileId from a URI.\n    fn file(&self, db: &RootDatabase, uri: Url) -> FileId {\n        match uri.scheme() {\n            \"file\" => {\n                let path = uri.to_file_path().unwrap();\n                FileId::new(db, path)\n            }\n            \"vfs\" => {\n                let id = uri.host_str().unwrap().parse::<usize>().unwrap();\n                FileId::from_intern_id(id.into())\n            }\n            _ => panic!(),\n        }\n    }\n\n    fn get_uri(&self, db: &RootDatabase, file_id: FileId) -> Url {\n        let virtual_file = match db.lookup_intern_file(file_id) {\n            FileLongId::OnDisk(path) => return Url::from_file_path(path).unwrap(),\n            FileLongId::Virtual(virtual_file) => virtual_file,\n        };\n        let uri = Url::parse(\n            format!(\"vfs://{}/{}.cairo\", file_id.as_intern_id().as_usize(), virtual_file.name)\n                .as_str(),\n        )\n        .unwrap();\n        uri\n    }\n\n    // TODO(spapini): Consider managing vfs in a different way, using the\n    // client.send_notification::<UpdateVirtualFile> call.\n\n    // Refresh diagnostics and send diffs to client.\n    async fn refresh_diagnostics(&self) {\n        let mut state = self.state_mutex.lock().await;\n\n        // Get all files. Try to go over open files first.\n        let mut files_set: OrderedHashSet<_> = state.open_files.iter().copied().collect();\n        let db = self.db().await;\n        for crate_id in db.crates() {\n            for module_id in db.crate_modules(crate_id).iter() {\n                for file_id in db.module_files(*module_id).unwrap_or_default() {\n                    files_set.insert(file_id);\n                }\n            }\n        }\n\n        // Get all diagnostics.\n        for file_id in files_set.iter().copied() {\n            let uri = self.get_uri(&db, file_id);\n            let new_file_diagnostics = FileDiagnostics {\n                parser: db.file_syntax_diagnostics(file_id),\n                semantic: db.file_semantic_diagnostics(file_id).unwrap_or_default(),\n                lowering: db.file_lowering_diagnostics(file_id).unwrap_or_default(),\n            };\n            // Since we are using Arcs, this comparison should be efficient.\n            if let Some(old_file_diagnostics) = state.file_diagnostics.get(&file_id) {\n                if old_file_diagnostics == &new_file_diagnostics {\n                    continue;\n                }\n            }\n            let mut diags = Vec::new();\n            self.get_diagnostics((*db).upcast(), &mut diags, &new_file_diagnostics.parser);\n            self.get_diagnostics((*db).upcast(), &mut diags, &new_file_diagnostics.semantic);\n            self.get_diagnostics((*db).upcast(), &mut diags, &new_file_diagnostics.lowering);\n            state.file_diagnostics.insert(file_id, new_file_diagnostics);\n\n            self.client.publish_diagnostics(uri, diags, None).await\n        }\n\n        // Clear old diagnostics.\n        let old_files: Vec<_> = state.file_diagnostics.keys().copied().collect();\n        for file_id in old_files {\n            if files_set.contains(&file_id) {\n                continue;\n            }\n            state.file_diagnostics.remove(&file_id);\n            let uri = self.get_uri(&db, file_id);\n            self.client.publish_diagnostics(uri, Vec::new(), None).await;\n        }\n    }\n\n    /// Converts internal format diagnostics to LSP format.\n    fn get_diagnostics<T: DiagnosticEntry>(\n        &self,\n        db: &T::DbType,\n        diags: &mut Vec<Diagnostic>,\n        diagnostics: &Diagnostics<T>,\n    ) {\n        for diagnostic in diagnostics.get_all() {\n            let location = diagnostic.location(db);\n            let message = diagnostic.format(db);\n            let start = from_pos(\n                location.span.start.position_in_file(db.upcast(), location.file_id).unwrap(),\n            );\n            let end = from_pos(\n                location.span.start.position_in_file(db.upcast(), location.file_id).unwrap(),\n            );\n            diags.push(Diagnostic {\n                range: Range { start, end },\n                message,\n                ..Diagnostic::default()\n            });\n        }\n    }\n\n    pub async fn vfs_provide(\n        &self,\n        params: ProvideVirtualFileRequest,\n    ) -> Result<ProvideVirtualFileResponse> {\n        let db = self.db().await;\n        let file_id = self.file(&db, params.uri);\n        Ok(ProvideVirtualFileResponse { content: db.file_content(file_id).map(|s| (*s).clone()) })\n    }\n}\n\n#[tower_lsp::async_trait]\nimpl LanguageServer for Backend {\n    async fn initialize(&self, _: InitializeParams) -> Result<InitializeResult> {\n        Ok(InitializeResult {\n            server_info: None,\n            capabilities: ServerCapabilities {\n                text_document_sync: Some(TextDocumentSyncCapability::Kind(\n                    TextDocumentSyncKind::FULL,\n                )),\n                completion_provider: Some(CompletionOptions {\n                    resolve_provider: Some(false),\n                    trigger_characters: Some(vec![\".\".to_string()]),\n                    work_done_progress_options: Default::default(),\n                    all_commit_characters: None,\n                }),\n                execute_command_provider: Some(ExecuteCommandOptions {\n                    commands: vec![\"dummy.do_something\".to_string()],\n                    work_done_progress_options: Default::default(),\n                }),\n                workspace: Some(WorkspaceServerCapabilities {\n                    workspace_folders: Some(WorkspaceFoldersServerCapabilities {\n                        supported: Some(true),\n                        change_notifications: Some(OneOf::Left(true)),\n                    }),\n                    file_operations: None,\n                }),\n                semantic_tokens_provider: Some(\n                    SemanticTokensOptions {\n                        legend: SemanticTokensLegend {\n                            token_types: SemanticTokenKind::legend(),\n                            token_modifiers: vec![],\n                        },\n                        full: Some(SemanticTokensFullOptions::Bool(true)),\n                        ..SemanticTokensOptions::default()\n                    }\n                    .into(),\n                ),\n                document_formatting_provider: Some(OneOf::Left(true)),\n                hover_provider: Some(HoverProviderCapability::Simple(true)),\n                definition_provider: Some(OneOf::Left(true)),\n                ..ServerCapabilities::default()\n            },\n        })\n    }\n\n    async fn initialized(&self, _: InitializedParams) {}\n\n    async fn shutdown(&self) -> Result<()> {\n        Ok(())\n    }\n\n    async fn did_change_workspace_folders(&self, _: DidChangeWorkspaceFoldersParams) {}\n\n    async fn did_change_configuration(&self, _: DidChangeConfigurationParams) {}\n\n    async fn did_change_watched_files(&self, params: DidChangeWatchedFilesParams) {\n        let mut db = self.db().await;\n        for change in params.changes {\n            let file = self.file(&db, change.uri);\n            PrivRawFileContentQuery.in_db_mut(db.as_files_group_mut()).invalidate(&file);\n        }\n    }\n\n    async fn execute_command(&self, _: ExecuteCommandParams) -> Result<Option<Value>> {\n        match self.client.apply_edit(WorkspaceEdit::default()).await {\n            Ok(res) if res.applied => self.client.log_message(MessageType::INFO, \"applied\").await,\n            Ok(_) => self.client.log_message(MessageType::INFO, \"rejected\").await,\n            Err(err) => self.client.log_message(MessageType::ERROR, err).await,\n        }\n\n        Ok(None)\n    }\n\n    async fn did_open(&self, params: DidOpenTextDocumentParams) {\n        let mut db = self.db().await;\n        let uri = params.text_document.uri;\n        let path = uri.path();\n        detect_crate_for(&mut db, path);\n\n        let file = self.file(&db, uri.clone());\n        self.state_mutex.lock().await.open_files.insert(file);\n        drop(db);\n        self.refresh_diagnostics().await;\n    }\n\n    async fn did_change(&self, params: DidChangeTextDocumentParams) {\n        let text =\n            if let [TextDocumentContentChangeEvent { text, .. }] = &params.content_changes[..] {\n                text\n            } else {\n                eprintln!(\"Unexpected format of document change.\");\n                return;\n            };\n        let mut db = self.db().await;\n        let uri = params.text_document.uri;\n        let file = self.file(&db, uri.clone());\n        db.override_file_content(file, Some(Arc::new(text.into())));\n        drop(db);\n        self.refresh_diagnostics().await;\n    }\n\n    async fn did_save(&self, params: DidSaveTextDocumentParams) {\n        let mut db = self.db().await;\n        let file = self.file(&db, params.text_document.uri);\n        PrivRawFileContentQuery.in_db_mut(db.as_files_group_mut()).invalidate(&file);\n        db.override_file_content(file, None);\n    }\n\n    async fn did_close(&self, params: DidCloseTextDocumentParams) {\n        let mut db = self.db().await;\n        let file = self.file(&db, params.text_document.uri);\n        self.state_mutex.lock().await.open_files.remove(&file);\n        db.override_file_content(file, None);\n        drop(db);\n        self.refresh_diagnostics().await;\n    }\n\n    async fn completion(&self, _: CompletionParams) -> Result<Option<CompletionResponse>> {\n        Ok(Some(CompletionResponse::Array(vec![\n            CompletionItem::new_simple(\"Hello\".to_string(), \"Some detail\".to_string()),\n            CompletionItem::new_simple(\"Bye\".to_string(), \"More detail\".to_string()),\n        ])))\n    }\n\n    async fn semantic_tokens_full(\n        &self,\n        params: SemanticTokensParams,\n    ) -> Result<Option<SemanticTokensResult>> {\n        let db = self.db().await;\n        let file_uri = params.text_document.uri;\n        let file = self.file(&db, file_uri.clone());\n        let syntax = if let Ok(syntax) = db.file_syntax(file) {\n            syntax\n        } else {\n            eprintln!(\"Semantic analysis failed. File '{file_uri}' does not exist.\");\n            return Ok(None);\n        };\n\n        let node = syntax.as_syntax_node();\n        let mut data: Vec<SemanticToken> = Vec::new();\n        SemanticTokensTraverser::default().find_semantic_tokens((*db).upcast(), &mut data, node);\n        Ok(Some(SemanticTokensResult::Tokens(SemanticTokens { result_id: None, data })))\n    }\n\n    async fn formatting(&self, params: DocumentFormattingParams) -> Result<Option<Vec<TextEdit>>> {\n        let db = self.db().await;\n        let file_uri = params.text_document.uri;\n        let file = self.file(&db, file_uri.clone());\n        let syntax = if let Ok(syntax) = db.file_syntax(file) {\n            syntax\n        } else {\n            eprintln!(\"Formatting failed. File '{file_uri}' does not exist.\");\n            return Ok(None);\n        };\n        let new_text = get_formatted_file(\n            (*db).upcast(),\n            &syntax.as_syntax_node(),\n            FormatterConfig::default(),\n        );\n\n        let file_summary = if let Some(summary) = db.file_summary(file) {\n            summary\n        } else {\n            eprintln!(\"Formatting failed. Cannot get summary for file '{file_uri}'.\");\n            return Ok(None);\n        };\n        let old_line_count = if let Ok(count) = file_summary.line_count().try_into() {\n            count\n        } else {\n            eprintln!(\"Formatting failed. Line count out of bound in file '{file_uri}'.\");\n            return Ok(None);\n        };\n\n        Ok(Some(vec![TextEdit {\n            range: Range {\n                start: Position { line: 0, character: 0 },\n                end: Position { line: old_line_count, character: 0 },\n            },\n            new_text,\n        }]))\n    }\n\n    async fn hover(&self, params: HoverParams) -> Result<Option<Hover>> {\n        let db = self.db().await;\n        let file_uri = params.text_document_position_params.text_document.uri;\n        eprintln!(\"Hover {file_uri}\");\n        let file = self.file(&db, file_uri);\n        let position = params.text_document_position_params.position;\n        let Some((node, lookup_items)) =\n            get_node_and_lookup_items(&*db, file, position) else { return Ok(None); };\n        let Some(lookup_item_id) = lookup_items.into_iter().next() else {\n                return Ok(None);\n            };\n        let function_id = match lookup_item_id {\n            LookupItemId::ModuleItem(ModuleItemId::FreeFunction(free_function_id)) => {\n                FunctionWithBodyId::Free(free_function_id)\n            }\n            LookupItemId::ImplFunction(impl_function_id) => {\n                FunctionWithBodyId::Impl(impl_function_id)\n            }\n            _ => {\n                return Ok(None);\n            }\n        };\n\n        // Build texts.\n        let mut hints = Vec::new();\n        if let Some(hint) = get_expr_hint(&*db, function_id, node.clone()) {\n            hints.push(MarkedString::String(hint));\n        };\n        if let Some(hint) = get_identifier_hint(&*db, lookup_item_id, node) {\n            hints.push(MarkedString::String(hint));\n        };\n\n        Ok(Some(Hover { contents: HoverContents::Array(hints), range: None }))\n    }\n    async fn goto_definition(\n        &self,\n        params: GotoDefinitionParams,\n    ) -> Result<Option<GotoDefinitionResponse>> {\n        let db = self.db().await;\n        let syntax_db = (*db).upcast();\n        let file_uri = params.text_document_position_params.text_document.uri;\n        let file = self.file(&db, file_uri.clone());\n        let position = params.text_document_position_params.position;\n        let Some((node, lookup_items)) = get_node_and_lookup_items(&*db, file, position) else {return Ok(None)};\n        for lookup_item_id in lookup_items {\n            if node.kind(syntax_db) != SyntaxKind::TokenIdentifier {\n                continue;\n            }\n            let identifier =\n                ast::TerminalIdentifier::from_syntax_node(syntax_db, node.parent().unwrap());\n            let Some(item) = db.lookup_resolved_generic_item_by_ptr(\n                lookup_item_id, identifier.stable_ptr())\n            else { continue; };\n\n            let defs_db = (*db).upcast();\n            let (module_id, file_index, stable_ptr) = match item {\n                ResolvedGenericItem::Constant(item) => (\n                    item.parent_module(defs_db),\n                    item.file_index(defs_db),\n                    item.untyped_stable_ptr(defs_db),\n                ),\n                ResolvedGenericItem::Module(item) => {\n                    (item, FileIndex(0), db.intern_stable_ptr(SyntaxStablePtr::Root))\n                }\n                ResolvedGenericItem::GenericFunction(item) => {\n                    let title = match item {\n                        GenericFunctionId::Free(id) => FunctionTitleId::Free(id),\n                        GenericFunctionId::Extern(id) => FunctionTitleId::Extern(id),\n                        GenericFunctionId::Impl(id) => {\n                            // Note: Only the trait title is returned.\n                            FunctionTitleId::Trait(id.function)\n                        }\n                    };\n                    (\n                        title.parent_module(defs_db),\n                        title.file_index(defs_db),\n                        title.untyped_stable_ptr(defs_db),\n                    )\n                }\n                ResolvedGenericItem::GenericType(generic_type) => (\n                    generic_type.parent_module(defs_db),\n                    generic_type.file_index(defs_db),\n                    generic_type.untyped_stable_ptr(defs_db),\n                ),\n                ResolvedGenericItem::GenericTypeAlias(type_alias) => (\n                    type_alias.parent_module(defs_db),\n                    type_alias.file_index(defs_db),\n                    type_alias.untyped_stable_ptr(defs_db),\n                ),\n                ResolvedGenericItem::Variant(variant) => (\n                    variant.id.parent_module(defs_db),\n                    variant.id.file_index(defs_db),\n                    variant.id.stable_ptr(defs_db).untyped(),\n                ),\n                ResolvedGenericItem::Trait(trt) => (\n                    trt.parent_module(defs_db),\n                    trt.file_index(defs_db),\n                    trt.stable_ptr(defs_db).untyped(),\n                ),\n                ResolvedGenericItem::Impl(imp) => (\n                    imp.parent_module(defs_db),\n                    imp.file_index(defs_db),\n                    imp.stable_ptr(defs_db).untyped(),\n                ),\n                ResolvedGenericItem::TraitFunction(trait_function) => (\n                    trait_function.parent_module(defs_db),\n                    trait_function.file_index(defs_db),\n                    trait_function.stable_ptr(defs_db).untyped(),\n                ),\n            };\n\n            let file = if let Ok(files) = db.module_files(module_id) {\n                files[file_index.0]\n            } else {\n                return Ok(None);\n            };\n\n            let uri = self.get_uri(&db, file);\n            let syntax = if let Ok(syntax) = db.file_syntax(file) {\n                syntax\n            } else {\n                eprintln!(\"Formatting failed. File '{file_uri}' does not exist.\");\n                return Ok(None);\n            };\n            let node = syntax.as_syntax_node().lookup_ptr(syntax_db, stable_ptr);\n            let span = node.span_without_trivia(syntax_db);\n\n            let start = from_pos(span.start.position_in_file((*db).upcast(), file).unwrap());\n            let end = from_pos(span.end.position_in_file((*db).upcast(), file).unwrap());\n\n            return Ok(Some(GotoDefinitionResponse::Scalar(Location {\n                uri,\n                range: Range { start, end },\n            })));\n        }\n        return Ok(None);\n    }\n}\n\n/// If the ast node is a lookup item, return the corresponding id. Otherwise, return None.\n/// See [LookupItemId].\nfn lookup_item_from_ast(\n    db: &dyn SemanticGroup,\n    module_file_id: ModuleFileId,\n    node: SyntaxNode,\n) -> Option<LookupItemId> {\n    let syntax_db = db.upcast();\n    // TODO(spapini): Handle trait items.\n    match node.kind(syntax_db) {\n        SyntaxKind::ItemConstant => Some(LookupItemId::ModuleItem(ModuleItemId::Constant(\n            db.intern_constant(ConstantLongId(\n                module_file_id,\n                ast::ItemConstant::from_syntax_node(syntax_db, node).stable_ptr(),\n            )),\n        ))),\n        SyntaxKind::FunctionWithBody => {\n            if is_grandparent_of_kind(syntax_db, &node, SyntaxKind::ImplBody) {\n                Some(LookupItemId::ImplFunction(db.intern_impl_function(ImplFunctionLongId(\n                    module_file_id,\n                    ast::FunctionWithBody::from_syntax_node(syntax_db, node).stable_ptr(),\n                ))))\n            } else {\n                Some(LookupItemId::ModuleItem(ModuleItemId::FreeFunction(db.intern_free_function(\n                    FreeFunctionLongId(\n                        module_file_id,\n                        ast::FunctionWithBody::from_syntax_node(syntax_db, node).stable_ptr(),\n                    ),\n                ))))\n            }\n        }\n        SyntaxKind::ItemExternFunction => Some(LookupItemId::ModuleItem(\n            ModuleItemId::ExternFunction(db.intern_extern_function(ExternFunctionLongId(\n                module_file_id,\n                ast::ItemExternFunction::from_syntax_node(syntax_db, node).stable_ptr(),\n            ))),\n        )),\n        SyntaxKind::ItemExternType => Some(LookupItemId::ModuleItem(ModuleItemId::ExternType(\n            db.intern_extern_type(ExternTypeLongId(\n                module_file_id,\n                ast::ItemExternType::from_syntax_node(syntax_db, node).stable_ptr(),\n            )),\n        ))),\n        SyntaxKind::ItemTrait => {\n            Some(LookupItemId::ModuleItem(ModuleItemId::Trait(db.intern_trait(TraitLongId(\n                module_file_id,\n                ast::ItemTrait::from_syntax_node(syntax_db, node).stable_ptr(),\n            )))))\n        }\n        SyntaxKind::ItemImpl => {\n            Some(LookupItemId::ModuleItem(ModuleItemId::Impl(db.intern_impl(ImplDefLongId(\n                module_file_id,\n                ast::ItemImpl::from_syntax_node(syntax_db, node).stable_ptr(),\n            )))))\n        }\n        SyntaxKind::ItemStruct => {\n            Some(LookupItemId::ModuleItem(ModuleItemId::Struct(db.intern_struct(StructLongId(\n                module_file_id,\n                ast::ItemStruct::from_syntax_node(syntax_db, node).stable_ptr(),\n            )))))\n        }\n        SyntaxKind::ItemEnum => {\n            Some(LookupItemId::ModuleItem(ModuleItemId::Enum(db.intern_enum(EnumLongId(\n                module_file_id,\n                ast::ItemEnum::from_syntax_node(syntax_db, node).stable_ptr(),\n            )))))\n        }\n        SyntaxKind::ItemUse => Some(LookupItemId::ModuleItem(ModuleItemId::Use(db.intern_use(\n            UseLongId(module_file_id, ast::ItemUse::from_syntax_node(syntax_db, node).stable_ptr()),\n        )))),\n        _ => None,\n    }\n}\n\n/// Given a position in a file, return the syntax node for the token at that position, and all the\n/// lookup items above this node.\nfn get_node_and_lookup_items(\n    db: &(dyn SemanticGroup + 'static),\n    file: FileId,\n    position: Position,\n) -> Option<(SyntaxNode, Vec<LookupItemId>)> {\n    let mut res = Vec::new();\n    let syntax_db = db.upcast();\n    let filename = file.file_name(db.upcast());\n\n    // Get syntax for file.\n    let syntax = db.file_syntax(file).to_option().on_none(|| {\n        eprintln!(\"Formatting failed. File '{filename}' does not exist.\");\n    })?;\n\n    // Get file summary and content.\n    let file_summary = db.file_summary(file).on_none(|| {\n        eprintln!(\"Hover failed. File '{filename}' does not exist.\");\n    })?;\n    let content = db.file_content(file).on_none(|| {\n        eprintln!(\"Hover failed. File '{filename}' does not exist.\");\n    })?;\n\n    // Find offset for position.\n    let mut offset = *file_summary.line_offsets.get(position.line as usize).on_none(|| {\n        eprintln!(\"Hover failed. Position out of bounds.\");\n    })?;\n    let mut chars_it = offset.take_from(&content).chars();\n    for _ in 0..position.character {\n        let c = chars_it.next().on_none(|| {\n            eprintln!(\"Position does not exist.\");\n        })?;\n        offset = offset.add_width(TextWidth::from_char(c));\n    }\n    let node = syntax.as_syntax_node().lookup_offset(syntax_db, offset);\n\n    // Find module.\n    let module_id = find_node_module(db, file, node.clone()).on_none(|| {\n        eprintln!(\"Hover failed. Failed to find module.\");\n    })?;\n    let file_index = FileIndex(0);\n    let module_file_id = ModuleFileId(module_id, file_index);\n\n    // Find containing function.\n    let mut item_node = node.clone();\n    loop {\n        if let Some(item) = lookup_item_from_ast(db, module_file_id, item_node.clone()) {\n            res.push(item);\n        }\n        match item_node.parent() {\n            Some(next_node) => {\n                item_node = next_node;\n            }\n            None => return Some((node, res)),\n        }\n    }\n}\n\nfn find_node_module(\n    db: &(dyn SemanticGroup + 'static),\n    main_file: FileId,\n    mut node: SyntaxNode,\n) -> Option<ModuleId> {\n    let modules: Vec<_> = db.file_modules(main_file).into_iter().flatten().collect();\n    let mut module = *modules.first()?;\n    let syntax_db = db.upcast();\n\n    let mut inner_module_names = vec![];\n    while let Some(parent) = node.parent() {\n        node = parent;\n        if node.kind(syntax_db) == SyntaxKind::ItemModule {\n            inner_module_names.push(\n                ast::ItemModule::from_syntax_node(syntax_db, node.clone())\n                    .stable_ptr()\n                    .name_green(syntax_db)\n                    .identifier(syntax_db),\n            );\n        }\n    }\n    for name in inner_module_names.into_iter().rev() {\n        let submodule = try_extract_matches!(\n            db.module_item_by_name(module, name).ok()??,\n            ModuleItemId::Submodule\n        )?;\n        module = ModuleId::Submodule(submodule);\n    }\n    Some(module)\n}\n\n/// If the node is an identifier, retrieves a hover hint for it.\nfn get_identifier_hint(\n    db: &(dyn SemanticGroup + 'static),\n    lookup_item_id: LookupItemId,\n    node: SyntaxNode,\n) -> Option<String> {\n    let syntax_db = db.upcast();\n    if node.kind(syntax_db) != SyntaxKind::TokenIdentifier {\n        return None;\n    }\n    let identifier = ast::TerminalIdentifier::from_syntax_node(syntax_db, node.parent().unwrap());\n    let item = db.lookup_resolved_generic_item_by_ptr(lookup_item_id, identifier.stable_ptr())?;\n\n    // TODO(spapini): Also include concrete item hints.\n    // TODO(spapini): Format this better.\n    Some(format!(\"`{:?}`\", item.debug(db)))\n}\n\n/// If the node is an expression, retrieves a hover hint for it.\nfn get_expr_hint(\n    db: &(dyn SemanticGroup + 'static),\n    function_id: FunctionWithBodyId,\n    mut node: SyntaxNode,\n) -> Option<String> {\n    let syntax_db = db.upcast();\n    // Add type info if exists.\n    while !is_expr(node.kind(syntax_db)) {\n        node = node.parent()?;\n    }\n    let expr_node = ast::Expr::from_syntax_node(syntax_db, node);\n    // Lookup semantic expression.\n    let expr_id =\n        db.lookup_expr_by_ptr(function_id, expr_node.stable_ptr()).to_option().on_none(|| {\n            eprintln!(\"Hover failed. Semantic model not found for expression.\");\n        })?;\n    let semantic_expr = db.expr_semantic(function_id, expr_id);\n    // Format the hover text.\n    Some(format!(\"Type: `{}`\", semantic_expr.ty().format(db)))\n}\n\n/// Returns true if the current ast node is an expression.\nfn is_expr(kind: SyntaxKind) -> bool {\n    matches!(\n        kind,\n        SyntaxKind::ExprBinary\n            | SyntaxKind::ExprBlock\n            | SyntaxKind::ExprParenthesized\n            | SyntaxKind::ExprFunctionCall\n            | SyntaxKind::ExprIf\n            | SyntaxKind::ExprMatch\n            | SyntaxKind::ExprMissing\n            | SyntaxKind::ExprStructCtorCall\n            | SyntaxKind::ExprUnary\n            | SyntaxKind::ExprTuple\n            | SyntaxKind::ExprPath\n    )\n}\n\n#[derive(Serialize, Deserialize, Debug)]\npub struct ScarbProjectMetadata {\n    pub packages: Vec<ScarbPackageMetadata>,\n    pub compilation_units: Vec<ScarbCompilationUnitMetadata>,\n}\n\n#[derive(Serialize, Deserialize, Debug)]\npub struct ScarbPackageMetadata {\n    pub id: String,\n    pub name: String,\n    pub root: PathBuf,\n    pub manifest_path: PathBuf,\n}\n\n#[derive(Serialize, Deserialize, Debug)]\npub struct ScarbCompilationUnitMetadata {\n    pub package: String,\n    pub components: Vec<String>,\n}\nuse indoc::indoc;\n\n/// Reads Scarb project metadata from manifest file.\nfn read_scarb_metadata(manifest_path: PathBuf) -> anyhow::Result<ScarbProjectMetadata> {\n    let mut cmd = Command::new(\"scarb\");\n    cmd.args([\"--json\", \"-vv\", \"metadata\", \"--format-version=1\"]);\n    cmd.stdout(Stdio::piped());\n    cmd.current_dir(manifest_path.parent().unwrap());\n    let output = cmd.output()?;\n\n    let slice = output.stdout.as_slice();\n    slice\n        .lines()\n        .flat_map(anyhow::Result::ok)\n        .flat_map(|line| serde_json::from_str::<ScarbProjectMetadata>(&line).ok())\n        .next()\n        .ok_or_else(|| {\n            anyhow!(\n                indoc! {r#\"\n                Scarb.toml not found. Calling `scarb metadata` failed.\n\n                stderr:\n                {}\"#},\n                String::from_utf8_lossy(&output.stderr)\n            )\n        })\n}\n\nfn update_crate_roots_from_metadata(\n    db: &mut dyn SemanticGroup,\n    project_metadata: ScarbProjectMetadata,\n) {\n    let packages: HashMap<String, ScarbPackageMetadata> = project_metadata\n        .packages\n        .into_iter()\n        .map(|package| (package.id.clone(), package))\n        .collect();\n\n    for unit in project_metadata.compilation_units {\n        for package_id in unit.components {\n            let package_metadata = packages.get(&package_id).unwrap();\n            let package_id = SmolStr::from(package_metadata.name.clone());\n            let src_path = package_metadata.root.clone().join(\"src\");\n            if src_path.exists() {\n                let crate_id = db.intern_crate(CrateLongId(package_id));\n                let root = Directory(src_path);\n                db.set_crate_root(crate_id, Some(root));\n            };\n        }\n    }\n}\n\n/// Tries to detect the crate root the config that contains a cairo file, and add it to the system.\nfn detect_crate_for(db: &mut RootDatabase, file_path: &str) {\n    let mut path = PathBuf::from(file_path);\n    for _ in 0..MAX_CRATE_DETECTION_DEPTH {\n        path.pop();\n\n        // Check for a Scarb manifest file.\n        let manifest_path = path.join(SCARB_PROJECT_FILE_NAME);\n        if manifest_path.exists() {\n            match read_scarb_metadata(manifest_path) {\n                Ok(metadata) => {\n                    update_crate_roots_from_metadata(db, metadata);\n                }\n                Err(err) => {\n                    warn!(\"Failed to obtain scarb metadata from manifest file. {err}\");\n                }\n            };\n            // Scarb manifest takes precedence over cairo project file.\n            return;\n        };\n\n        // Check for a cairo project file.\n        if let Ok(config) = ProjectConfig::from_directory(path.as_path()) {\n            update_crate_roots_from_project_config(db, config);\n            return;\n        };\n    }\n    // Fallback to a single file.\n    if let Err(err) = setup_project(&mut *db, PathBuf::from(file_path).as_path()) {\n        eprintln!(\"Error loading file {file_path} as a single crate: {err}\");\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "/// LSP protocol is using a differential position encoding to report the tokens.\n/// This encoder outputs this encoding.\n#[derive(Default)]\npub struct TokenEncoder {\n    /// Line number of the last encoded token.\n    last_line: u32,\n    /// Column number of the last encoded token.\n    last_col: u32,\n    /// Current line number.\n    line: u32,\n    /// Current column number.\n    col: u32,\n}\npub struct EncodedToken {\n    pub delta_line: u32,\n    pub delta_start: u32,\n}\nimpl TokenEncoder {\n    /// Skip a non newline token.\n    pub fn skip(&mut self, width: u32) {\n        self.col += width;\n    }\n\n    /// Moves to the next line.\n    pub fn next_line(&mut self) {\n        self.line += 1;\n        self.col = 0;\n    }\n    pub fn encode(&mut self, width: u32) -> EncodedToken {\n        let delta_line = self.line - self.last_line;\n        let prev_col = if delta_line > 0 { 0 } else { self.last_col };\n        let delta_start = self.col - prev_col;\n        self.last_line = self.line;\n        self.last_col = self.col;\n        self.skip(width);\n        EncodedToken { delta_line, delta_start }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_filesystem::span::TextOffset;\nuse cairo_lang_syntax as syntax;\nuse cairo_lang_syntax::node::ast::{self};\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::kind::SyntaxKind;\nuse cairo_lang_syntax::node::{SyntaxNode, TypedSyntaxNode};\nuse cairo_lang_utils::unordered_hash_map::UnorderedHashMap;\nuse tower_lsp::lsp_types::*;\n\nuse self::encoder::{EncodedToken, TokenEncoder};\nuse self::token_kind::SemanticTokenKind;\n\nmod encoder;\npub mod token_kind;\n\n#[derive(Default)]\npub struct SemanticTokensTraverser {\n    encoder: TokenEncoder,\n    /// A map from an offset in the file to semantic token kind.\n    /// This map is used to override future tokens based on the context.\n    /// For example: when we see the \"fn\" keyword, the name token is added\n    /// to the map, so that instead of marking it as an identifier, we will mark it\n    /// as a function name.\n    offset_to_kind_lookahead: UnorderedHashMap<TextOffset, SemanticTokenKind>,\n}\nimpl SemanticTokensTraverser {\n    pub fn find_semantic_tokens(\n        &mut self,\n        db: &dyn SyntaxGroup,\n        data: &mut Vec<SemanticToken>,\n        node: SyntaxNode,\n    ) {\n        let green_node = node.green_node(db);\n        match green_node.details {\n            syntax::node::green::GreenNodeDetails::Token(text) => {\n                if green_node.kind == SyntaxKind::TokenNewline {\n                    self.encoder.next_line();\n                    return;\n                }\n\n                let width = text.len() as u32;\n                let maybe_semantic_kind = self\n                    .offset_to_kind_lookahead\n                    .remove(&node.offset())\n                    .or_else(|| SemanticTokenKind::from_syntax_kind(green_node.kind));\n                if let Some(semantic_kind) = maybe_semantic_kind {\n                    let EncodedToken { delta_line, delta_start } = self.encoder.encode(width);\n                    data.push(SemanticToken {\n                        delta_line,\n                        delta_start,\n                        length: width,\n                        token_type: semantic_kind.as_u32(),\n                        token_modifiers_bitset: 0,\n                    });\n                } else {\n                    self.encoder.skip(width);\n                }\n            }\n            syntax::node::green::GreenNodeDetails::Node { .. } => {\n                let children = node.children(db);\n                match green_node.kind {\n                    SyntaxKind::Param => {\n                        self.mark_future_token(\n                            ast::Param::from_syntax_node(db, node)\n                                .name(db)\n                                .as_syntax_node()\n                                .offset(),\n                            SemanticTokenKind::Parameter,\n                        );\n                    }\n                    SyntaxKind::FunctionWithBody => {\n                        self.mark_future_token(\n                            ast::FunctionWithBody::from_syntax_node(db, node)\n                                .declaration(db)\n                                .name(db)\n                                .as_syntax_node()\n                                .offset(),\n                            SemanticTokenKind::Function,\n                        );\n                    }\n                    SyntaxKind::ItemStruct => self.mark_future_token(\n                        ast::ItemStruct::from_syntax_node(db, node)\n                            .name(db)\n                            .as_syntax_node()\n                            .offset(),\n                        SemanticTokenKind::Struct,\n                    ),\n                    SyntaxKind::ItemEnum => self.mark_future_token(\n                        ast::ItemEnum::from_syntax_node(db, node)\n                            .name(db)\n                            .as_syntax_node()\n                            .offset(),\n                        SemanticTokenKind::Enum,\n                    ),\n                    _ => {}\n                }\n                for child in children {\n                    self.find_semantic_tokens(db, data, child);\n                }\n            }\n        }\n    }\n\n    fn mark_future_token(&mut self, offset: TextOffset, semantic_kind: SemanticTokenKind) {\n        self.offset_to_kind_lookahead.insert(offset, semantic_kind);\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_syntax::node::kind::SyntaxKind;\nuse lsp::SemanticTokenType;\n\n#[allow(dead_code)]\npub enum SemanticTokenKind {\n    Namespace,\n    Class,\n    Enum,\n    Interface,\n    Struct,\n    TypeParameter,\n    Type,\n    Parameter,\n    Variable,\n    Property,\n    EnumMember,\n    Function,\n    Comment,\n    Keyword,\n    Operator,\n    Number,\n}\nimpl SemanticTokenKind {\n    pub fn from_syntax_kind(kind: SyntaxKind) -> Option<Self> {\n        Some(match kind {\n            _ if kind.is_keyword_token() => SemanticTokenKind::Keyword,\n            SyntaxKind::TokenIdentifier => SemanticTokenKind::Variable,\n            SyntaxKind::TokenLiteralNumber => SemanticTokenKind::Number,\n            SyntaxKind::TokenAnd\n            | SyntaxKind::TokenAndAnd\n            | SyntaxKind::TokenOr\n            | SyntaxKind::TokenOrOr\n            | SyntaxKind::TokenEqEq\n            | SyntaxKind::TokenNeq\n            | SyntaxKind::TokenGE\n            | SyntaxKind::TokenGT\n            | SyntaxKind::TokenLE\n            | SyntaxKind::TokenLT\n            | SyntaxKind::TokenNot\n            | SyntaxKind::TokenPlus\n            | SyntaxKind::TokenMinus\n            | SyntaxKind::TokenMul\n            | SyntaxKind::TokenDiv\n            | SyntaxKind::TokenMod => SemanticTokenKind::Operator,\n            SyntaxKind::TokenSingleLineComment => SemanticTokenKind::Comment,\n            _ => return None,\n        })\n    }\n    pub fn as_u32(&self) -> u32 {\n        match self {\n            SemanticTokenKind::Namespace => 0,\n            SemanticTokenKind::Class => 1,\n            SemanticTokenKind::Enum => 2,\n            SemanticTokenKind::Interface => 3,\n            SemanticTokenKind::Struct => 4,\n            SemanticTokenKind::TypeParameter => 5,\n            SemanticTokenKind::Type => 6,\n            SemanticTokenKind::Parameter => 7,\n            SemanticTokenKind::Variable => 8,\n            SemanticTokenKind::Property => 9,\n            SemanticTokenKind::EnumMember => 10,\n            SemanticTokenKind::Function => 11,\n            SemanticTokenKind::Comment => 12,\n            SemanticTokenKind::Keyword => 13,\n            SemanticTokenKind::Operator => 14,\n            SemanticTokenKind::Number => 15,\n        }\n    }\n    pub fn legend() -> Vec<SemanticTokenType> {\n        vec![\n            SemanticTokenType::NAMESPACE,\n            SemanticTokenType::CLASS,\n            SemanticTokenType::ENUM,\n            SemanticTokenType::INTERFACE,\n            SemanticTokenType::STRUCT,\n            SemanticTokenType::TYPE_PARAMETER,\n            SemanticTokenType::TYPE,\n            SemanticTokenType::PARAMETER,\n            SemanticTokenType::VARIABLE,\n            SemanticTokenType::PROPERTY,\n            SemanticTokenType::ENUM_MEMBER,\n            SemanticTokenType::FUNCTION,\n            SemanticTokenType::COMMENT,\n            SemanticTokenType::KEYWORD,\n            SemanticTokenType::OPERATOR,\n            SemanticTokenType::NUMBER,\n        ]\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use lsp::notification::Notification;\nuse lsp::Url;\nuse serde::{Deserialize, Serialize};\n\n#[derive(Debug)]\npub enum UpdateVirtualFile {}\n\nimpl Notification for UpdateVirtualFile {\n    type Params = UpdateVirtualFileParams;\n    const METHOD: &'static str = \"vfs/update\";\n}\n\n#[derive(Debug, Eq, PartialEq, Clone, Deserialize, Serialize)]\npub struct UpdateVirtualFileParams {\n    pub uri: Url,\n}\n\n#[derive(Debug, Eq, PartialEq, Clone, Deserialize, Serialize)]\npub struct ProvideVirtualFileRequest {\n    pub uri: Url,\n}\n\n#[derive(Debug, Eq, PartialEq, Clone, Deserialize, Serialize)]\npub struct ProvideVirtualFileResponse {\n    pub content: Option<String>,\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! This module introduced the BackAnalysis utility that allows writing analyzers that go backwards\n//! in the flow of the program, on a Lowered representation.\n\nuse std::collections::HashMap;\n\nuse itertools::Itertools;\n\nuse crate::{\n    BlockId, FlatBlock, FlatBlockEnd, FlatLowered, MatchInfo, Statement, VarRemapping, VariableId,\n};\n\n/// Location of a lowering statement inside a block.\npub type StatementLocation = (BlockId, usize);\n\n/// Analyzer trait to implement for each specific analysis.\n#[allow(unused_variables)]\npub trait Analyzer {\n    type Info: Clone;\n    fn visit_block_start(&mut self, info: &mut Self::Info, block_id: BlockId, block: &FlatBlock) {}\n    fn visit_stmt(\n        &mut self,\n        info: &mut Self::Info,\n        statement_location: StatementLocation,\n        stmt: &Statement,\n    ) {\n    }\n    fn visit_remapping(\n        &mut self,\n        info: &mut Self::Info,\n        block_id: BlockId,\n        target_block_id: BlockId,\n        remapping: &VarRemapping,\n    ) {\n    }\n    fn merge_match(\n        &mut self,\n        statement_location: StatementLocation,\n        match_info: &MatchInfo,\n        infos: &[Self::Info],\n    ) -> Self::Info;\n    fn info_from_return(\n        &mut self,\n        statement_location: StatementLocation,\n        vars: &[VariableId],\n    ) -> Self::Info;\n    fn info_from_panic(\n        &mut self,\n        statement_location: StatementLocation,\n        var: &VariableId,\n    ) -> Self::Info;\n}\n\n/// Main analysis type that allows traversing the flow backwards.\npub struct BackAnalysis<'a, TAnalyzer: Analyzer> {\n    pub lowered: &'a FlatLowered,\n    pub cache: HashMap<BlockId, TAnalyzer::Info>,\n    pub analyzer: TAnalyzer,\n}\nimpl<'a, TAnalyzer: Analyzer> BackAnalysis<'a, TAnalyzer> {\n    /// Gets the analysis info for the entire function.\n    pub fn get_root_info(&mut self) -> TAnalyzer::Info {\n        self.get_block_info(BlockId::root())\n    }\n\n    /// Gets the analysis info from the start of a block.\n    fn get_block_info(&mut self, block_id: BlockId) -> TAnalyzer::Info {\n        if let Some(cached_result) = self.cache.get(&block_id) {\n            return cached_result.clone();\n        }\n\n        let mut info = self.get_end_info(block_id, &self.lowered.blocks[block_id].end);\n        let block_end_offset = self.lowered.blocks[block_id].statements.len();\n\n        // Go through statements backwards, and update info.\n        for (i, stmt) in\n            self.lowered.blocks[block_id].statements[0..block_end_offset].iter().enumerate().rev()\n        {\n            let statement_location = (block_id, i);\n            self.analyzer.visit_stmt(&mut info, statement_location, stmt);\n        }\n\n        self.analyzer.visit_block_start(&mut info, block_id, &self.lowered.blocks[block_id]);\n\n        // Cache result.\n        self.cache.insert(block_id, info.clone());\n        info\n    }\n\n    /// Gets the analysis info from a [FlatBlockEnd] onwards.\n    fn get_end_info(&mut self, block_id: BlockId, block_end: &FlatBlockEnd) -> TAnalyzer::Info {\n        let statement_location = (block_id, self.lowered.blocks[block_id].statements.len());\n        match block_end {\n            FlatBlockEnd::NotSet => unreachable!(),\n            FlatBlockEnd::Goto(target_block_id, remapping) => {\n                let mut info = self.get_block_info(*target_block_id);\n                self.analyzer.visit_remapping(&mut info, block_id, *target_block_id, remapping);\n                info\n            }\n            FlatBlockEnd::Return(vars) => self.analyzer.info_from_return(statement_location, vars),\n            FlatBlockEnd::Panic(data) => self.analyzer.info_from_panic(statement_location, data),\n            FlatBlockEnd::Match { info } => {\n                let arm_infos = info\n                    .arms()\n                    .iter()\n                    .rev()\n                    .map(|arm| self.get_block_info(arm.block_id))\n                    .collect_vec()\n                    .into_iter()\n                    .rev()\n                    .collect_vec();\n                self.analyzer.merge_match(statement_location, info, &arm_infos[..])\n            }\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "/// ! This module provides the Demand utility struct used for analyzing usage of variables.\nuse cairo_lang_utils::ordered_hash_set::OrderedHashSet;\n\n/// A reporting trait that reports each variables dup, drop and last_use positions.\npub trait DemandReporter<Var> {\n    type UsePosition: Copy;\n    type IntroducePosition: Copy;\n    fn drop(&mut self, _position: Self::IntroducePosition, _var: Var) {}\n    fn dup(&mut self, _position: Self::UsePosition, _var: Var) {}\n    fn last_use(&mut self, _position: Self::UsePosition, _var_index: usize, _var: Var) {}\n    fn unused_mapped_var(&mut self, _var: Var) {}\n}\n\n/// Demanded variables from a certain point in the flow until the end of the function.\n/// Needs to be updates in backwards order.\n#[derive(Clone)]\npub struct Demand<Var: std::hash::Hash + Eq + Copy> {\n    pub vars: OrderedHashSet<Var>,\n}\nimpl<Var: std::hash::Hash + Eq + Copy> Default for Demand<Var> {\n    fn default() -> Self {\n        Self { vars: Default::default() }\n    }\n}\nimpl<Var: std::hash::Hash + Eq + Copy> Demand<Var> {\n    /// Finalizes a demand. Returns a boolean representing success - if all the variable demands\n    /// were satisfied.\n    pub fn finalize(self) -> bool {\n        self.vars.is_empty()\n    }\n\n    /// Updates the demand when a variable remapping occurs.\n    pub fn apply_remapping<V: Into<Var>, T: DemandReporter<Var>>(\n        &mut self,\n        reporter: &mut T,\n        remapping: impl Iterator<Item = (V, V)>,\n    ) {\n        for (dst, src) in remapping {\n            let src = src.into();\n            let dst = dst.into();\n            if self.vars.swap_remove(&dst) {\n                self.vars.insert(src);\n            } else {\n                reporter.unused_mapped_var(dst);\n            }\n        }\n    }\n\n    /// Updates the demand when some variables are used right before the current flow.\n    pub fn variables_used<V: Copy + Into<Var>, T: DemandReporter<Var>>(\n        &mut self,\n        reporter: &mut T,\n        vars: &[V],\n        position: T::UsePosition,\n    ) {\n        for (var_index, var) in vars.iter().enumerate().rev() {\n            if !self.vars.insert((*var).into()) {\n                // Variable already used. If it's not dup, that is an issue.\n                reporter.dup(position, (*var).into());\n            } else {\n                reporter.last_use(position, var_index, (*var).into());\n            }\n        }\n    }\n\n    /// Updates the demand when some variables are introduced right before the current flow.\n    pub fn variables_introduced<V: Copy + Into<Var>, T: DemandReporter<Var>>(\n        &mut self,\n        reporter: &mut T,\n        vars: &[V],\n        position: T::IntroducePosition,\n    ) {\n        for var in vars {\n            if !self.vars.swap_remove(&(*var).into()) {\n                // Variable introduced, but not demanded. If it's not drop, that is an issue.\n                reporter.drop(position, (*var).into());\n            }\n        }\n    }\n\n    /// Merges [Demand]s from multiple branches into one, reporting diagnostics in the way.\n    pub fn merge_demands<T: DemandReporter<Var>>(\n        demands: &[(Self, T::IntroducePosition)],\n        reporter: &mut T,\n    ) -> Self {\n        // Union demands.\n        let mut demand = Self::default();\n        for (arm_demand, _) in demands {\n            demand.vars.extend(arm_demand.vars.iter().copied());\n        }\n        // Check each var.\n        for var in demand.vars.iter() {\n            for (arm_demand, position) in demands {\n                if !arm_demand.vars.contains(var) {\n                    // Variable demanded only on some branches. It should be dropped in other.\n                    // If it's not drop, that is an issue.\n                    reporter.drop(*position, *var);\n                }\n            }\n        }\n        demand\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_defs::ids::ModuleFileId;\nuse cairo_lang_diagnostics::Maybe;\nuse itertools::{zip_eq, Itertools};\n\nuse self::analysis::{Analyzer, StatementLocation};\npub use self::demand::Demand;\nuse self::demand::DemandReporter;\nuse crate::blocks::Blocks;\nuse crate::borrow_check::analysis::BackAnalysis;\nuse crate::db::LoweringGroup;\nuse crate::diagnostic::LoweringDiagnosticKind::*;\nuse crate::diagnostic::LoweringDiagnostics;\nuse crate::{BlockId, FlatLowered, MatchInfo, Statement, VarRemapping, VariableId};\n\npub mod analysis;\npub mod demand;\n\npub type LoweredDemand = Demand<VariableId>;\npub struct BorrowChecker<'a> {\n    db: &'a dyn LoweringGroup,\n    diagnostics: &'a mut LoweringDiagnostics,\n    lowered: &'a FlatLowered,\n    success: Maybe<()>,\n}\n\nimpl<'a> DemandReporter<VariableId> for BorrowChecker<'a> {\n    type IntroducePosition = ();\n    type UsePosition = ();\n\n    fn drop(&mut self, _position: (), var_id: VariableId) {\n        let var = &self.lowered.variables[var_id];\n        let Err(drop_err) = var.droppable.clone() else { return; };\n        let Err(destruct_err) = var.destruct_impl.clone() else { return; };\n        self.success = Err(self\n            .diagnostics\n            .report_by_location(var.location, VariableNotDropped { drop_err, destruct_err }));\n    }\n\n    fn dup(&mut self, _position: (), var: VariableId) {\n        let var = &self.lowered.variables[var];\n        if let Err(inference_error) = var.duplicatable.clone() {\n            self.success = Err(self\n                .diagnostics\n                .report_by_location(var.location, VariableMoved { inference_error }));\n        }\n    }\n}\n\nimpl<'a> Analyzer for BorrowChecker<'a> {\n    type Info = LoweredDemand;\n\n    fn visit_stmt(\n        &mut self,\n        info: &mut Self::Info,\n        _statement_location: StatementLocation,\n        stmt: &Statement,\n    ) {\n        info.variables_introduced(self, &stmt.outputs(), ());\n        match stmt {\n            Statement::Call(stmt) => {\n                if let Ok(signature) = self.db.concrete_function_signature(stmt.function) {\n                    if signature.panicable {\n                        // Be prepared to panic here.\n                        let panic_demand = LoweredDemand::default();\n                        *info = LoweredDemand::merge_demands(\n                            &[(panic_demand, ()), (info.clone(), ())],\n                            self,\n                        );\n                    }\n                }\n            }\n            Statement::Desnap(stmt) => {\n                let var = &self.lowered.variables[stmt.output];\n                if let Err(inference_error) = var.duplicatable.clone() {\n                    self.success = Err(self.diagnostics.report_by_location(\n                        var.location,\n                        DesnappingANonCopyableType { inference_error },\n                    ));\n                }\n            }\n            _ => {}\n        }\n        info.variables_used(self, &stmt.inputs(), ());\n    }\n\n    fn visit_remapping(\n        &mut self,\n        info: &mut Self::Info,\n        _block_id: BlockId,\n        _target_block_id: BlockId,\n        remapping: &VarRemapping,\n    ) {\n        info.apply_remapping(self, remapping.iter().map(|(dst, src)| (*dst, *src)));\n    }\n\n    fn merge_match(\n        &mut self,\n        _statement_location: StatementLocation,\n        match_info: &MatchInfo,\n        infos: &[Self::Info],\n    ) -> Self::Info {\n        let arm_demands = zip_eq(match_info.arms(), infos)\n            .map(|(arm, demand)| {\n                let mut demand = demand.clone();\n                demand.variables_introduced(self, &arm.var_ids, ());\n                (demand, ())\n            })\n            .collect_vec();\n        let mut demand = LoweredDemand::merge_demands(&arm_demands, self);\n        demand.variables_used(self, &match_info.inputs(), ());\n        demand\n    }\n\n    fn info_from_return(\n        &mut self,\n        _statement_location: StatementLocation,\n        vars: &[VariableId],\n    ) -> Self::Info {\n        let mut info = LoweredDemand::default();\n        info.variables_used(self, vars, ());\n        info\n    }\n\n    fn info_from_panic(\n        &mut self,\n        _statement_location: StatementLocation,\n        data: &VariableId,\n    ) -> Self::Info {\n        let mut info = LoweredDemand::default();\n        info.variables_used(self, &[*data], ());\n        info\n    }\n}\n\n/// Report borrow checking diagnostics.\npub fn borrow_check(\n    db: &dyn LoweringGroup,\n    module_file_id: ModuleFileId,\n    lowered: &mut FlatLowered,\n) {\n    let mut diagnostics = LoweringDiagnostics::new(module_file_id);\n    diagnostics.diagnostics.extend(std::mem::take(&mut lowered.diagnostics));\n\n    if lowered.blocks.has_root().is_ok() {\n        let checker = BorrowChecker { db, diagnostics: &mut diagnostics, lowered, success: Ok(()) };\n        let mut analysis =\n            BackAnalysis { lowered: &*lowered, cache: Default::default(), analyzer: checker };\n        let mut root_demand = analysis.get_root_info();\n        root_demand.variables_introduced(&mut analysis.analyzer, &lowered.parameters, ());\n        let success = analysis.analyzer.success;\n        assert!(root_demand.finalize(), \"Undefined variable should not happen at this stage\");\n\n        if let Err(diag_added) = success {\n            lowered.blocks = Blocks::new_errored(diag_added);\n        }\n    }\n\n    lowered.diagnostics = diagnostics.build();\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_diagnostics::Maybe;\nuse cairo_lang_semantic::substitution::{\n    GenericSubstitution, SemanticRewriter, SubstitutionRewriter,\n};\n\nuse crate::db::LoweringGroup;\nuse crate::{FlatBlockEnd, FlatLowered, MatchArm, Statement};\n\n/// Concretizes a lowered generic function by applying a generic parameter substitution on its\n/// variable types, variants and called functions.\npub fn concretize_lowered(\n    db: &dyn LoweringGroup,\n    lowered: &mut FlatLowered,\n    substitution: &GenericSubstitution,\n) -> Maybe<()> {\n    let mut rewriter = SubstitutionRewriter { db: db.upcast(), substitution };\n    // Substitute all types.\n    for (_, var) in lowered.variables.iter_mut() {\n        var.ty = rewriter.rewrite(var.ty)?;\n        if let Ok(impl_id) = &mut var.destruct_impl {\n            *impl_id = rewriter.rewrite(*impl_id)?;\n        }\n    }\n    // Substitute all statements.\n    for block in lowered.blocks.iter_mut() {\n        for stmt in block.statements.iter_mut() {\n            match stmt {\n                Statement::Call(stmt) => {\n                    stmt.function = rewriter.rewrite(stmt.function)?;\n                }\n                Statement::EnumConstruct(stmt) => {\n                    stmt.variant = rewriter.rewrite(stmt.variant.clone())?;\n                }\n                Statement::Snapshot(_)\n                | Statement::Desnap(_)\n                | Statement::Literal(_)\n                | Statement::StructConstruct(_)\n                | Statement::StructDestructure(_) => {}\n            }\n        }\n        if let FlatBlockEnd::Match { info } = &mut block.end {\n            match info {\n                crate::MatchInfo::Enum(s) => {\n                    for MatchArm { variant_id, .. } in s.arms.iter_mut() {\n                        *variant_id = rewriter.rewrite(variant_id.clone())?;\n                    }\n                }\n                crate::MatchInfo::Extern(s) => {\n                    s.function = rewriter.rewrite(s.function)?;\n                    for MatchArm { variant_id, .. } in s.arms.iter_mut() {\n                        *variant_id = rewriter.rewrite(variant_id.clone())?;\n                    }\n                }\n            }\n        }\n    }\n\n    Ok(())\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashSet;\nuse std::ops::Deref;\nuse std::sync::Arc;\n\nuse cairo_lang_defs::ids::{FunctionWithBodyId, LanguageElementId, ModuleId, ModuleItemId};\nuse cairo_lang_diagnostics::{Diagnostics, DiagnosticsBuilder, Maybe};\nuse cairo_lang_filesystem::ids::FileId;\nuse cairo_lang_semantic as semantic;\nuse cairo_lang_semantic::db::SemanticGroup;\nuse cairo_lang_semantic::TypeId;\nuse cairo_lang_utils::Upcast;\nuse itertools::Itertools;\nuse semantic::items::functions::ConcreteFunctionWithBodyId;\nuse semantic::ConcreteFunction;\n\nuse crate::borrow_check::borrow_check;\nuse crate::concretize::concretize_lowered;\nuse crate::destructs::add_destructs;\nuse crate::diagnostic::LoweringDiagnostic;\nuse crate::implicits::lower_implicits;\nuse crate::inline::{apply_inlining, PrivInlineData};\nuse crate::lower::lower;\nuse crate::optimizations::match_optimizer::optimize_matches;\nuse crate::optimizations::remappings::optimize_remappings;\nuse crate::panic::lower_panics;\nuse crate::topological_sort::topological_sort;\nuse crate::{FlatBlockEnd, FlatLowered, MatchInfo, Statement};\n\n// Salsa database interface.\n#[salsa::query_group(LoweringDatabase)]\npub trait LoweringGroup: SemanticGroup + Upcast<dyn SemanticGroup> {\n    // Reports inlining diagnostics.\n    #[salsa::invoke(crate::inline::priv_inline_data)]\n    fn priv_inline_data(&self, function_id: FunctionWithBodyId) -> Maybe<Arc<PrivInlineData>>;\n\n    /// Computes the lowered representation of a function with a body.\n    fn priv_function_with_body_lowered_flat(\n        &self,\n        function_id: FunctionWithBodyId,\n    ) -> Maybe<Arc<FlatLowered>>;\n\n    /// A concrete version of priv_function_with_body_lowered_flat\n    fn priv_concrete_function_with_body_lowered_flat(\n        &self,\n        function_id: ConcreteFunctionWithBodyId,\n    ) -> Maybe<Arc<FlatLowered>>;\n\n    /// Computes the lowered representation after the panic phase.\n    fn concrete_function_with_body_postpanic_lowered(\n        &self,\n        function_id: ConcreteFunctionWithBodyId,\n    ) -> Maybe<Arc<FlatLowered>>;\n\n    /// Computes the final lowered representation (after all the internal transformations).\n    fn concrete_function_with_body_lowered(\n        &self,\n        function_id: ConcreteFunctionWithBodyId,\n    ) -> Maybe<Arc<FlatLowered>>;\n\n    /// Returns the set of direct callees of a concrete function with a body after the panic phase.\n    fn concrete_function_with_body_postpanic_direct_callees(\n        &self,\n        function_id: ConcreteFunctionWithBodyId,\n    ) -> Maybe<Vec<ConcreteFunction>>;\n\n    /// Returns the set of direct callees of a concrete function with a body.\n    fn concrete_function_with_body_direct_callees(\n        &self,\n        function_id: ConcreteFunctionWithBodyId,\n    ) -> Maybe<Vec<ConcreteFunction>>;\n\n    /// Returns the set of direct callees which are functions with body of a concrete function with\n    /// a body (i.e. excluding libfunc callees).\n    fn concrete_function_with_body_direct_callees_with_body(\n        &self,\n        function_id: ConcreteFunctionWithBodyId,\n    ) -> Maybe<Vec<ConcreteFunctionWithBodyId>>;\n\n    /// Returns the set of direct callees which are functions with body of a concrete function with\n    /// a body (i.e. excluding libfunc callees), after the panic phase.\n    fn concrete_function_with_body_postpanic_direct_callees_with_body(\n        &self,\n        function_id: ConcreteFunctionWithBodyId,\n    ) -> Maybe<Vec<ConcreteFunctionWithBodyId>>;\n\n    /// Aggregates function level semantic diagnostics.\n    fn function_with_body_lowering_diagnostics(\n        &self,\n        function_id: FunctionWithBodyId,\n    ) -> Maybe<Arc<Diagnostics<LoweringDiagnostic>>>;\n    /// Aggregates module level semantic diagnostics.\n    fn module_lowering_diagnostics(\n        &self,\n        module_id: ModuleId,\n    ) -> Maybe<Diagnostics<LoweringDiagnostic>>;\n\n    /// Aggregates file level lowering diagnostics.\n    fn file_lowering_diagnostics(&self, file_id: FileId) -> Maybe<Diagnostics<LoweringDiagnostic>>;\n\n    // ### Queries related to implicits ###\n\n    /// Returns the explicit implicits required by all the functions in the SCC of this function.\n    /// These are all the implicit parameters that are explicitly declared in the functions of\n    /// the given function's SCC.\n    ///\n    /// For better caching, this function should be called only with the representative of the SCC.\n    #[salsa::invoke(crate::implicits::function_scc_explicit_implicits)]\n    fn function_scc_explicit_implicits(\n        &self,\n        function: ConcreteSCCRepresentative,\n    ) -> Maybe<HashSet<TypeId>>;\n\n    /// Returns all the implicit parameters that the function requires (according to both its\n    /// signature and the functions it calls). The items in the returned vector are unique and the\n    /// order is consistent, but not necessarily related to the order of the explicit implicits in\n    /// the signature of the function.\n    #[salsa::invoke(crate::implicits::function_all_implicits)]\n    fn function_all_implicits(&self, function: semantic::FunctionId) -> Maybe<Vec<TypeId>>;\n\n    /// Returns all the implicit parameters that a concrete function with a body requires (according\n    /// to both its signature and the functions it calls).\n    #[salsa::invoke(crate::implicits::concrete_function_with_body_all_implicits)]\n    fn concrete_function_with_body_all_implicits(\n        &self,\n        function: ConcreteFunctionWithBodyId,\n    ) -> Maybe<HashSet<TypeId>>;\n\n    /// Returns all the implicit parameters that a function with a body requires (according to both\n    /// its signature and the functions it calls). The items in the returned vector are unique\n    /// and the order is consistent, but not necessarily related to the order of the explicit\n    /// implicits in the signature of the function.\n    #[salsa::invoke(crate::implicits::concrete_function_with_body_all_implicits_vec)]\n    fn concrete_function_with_body_all_implicits_vec(\n        &self,\n        function: ConcreteFunctionWithBodyId,\n    ) -> Maybe<Vec<TypeId>>;\n\n    /// An array that sets the precedence of implicit types.\n    #[salsa::input]\n    fn implicit_precedence(&self) -> Arc<Vec<TypeId>>;\n\n    // ### Queries related to panics ###\n\n    /// Returns whether the function may panic.\n    #[salsa::invoke(crate::panic::function_may_panic)]\n    fn function_may_panic(&self, function: semantic::FunctionId) -> Maybe<bool>;\n\n    /// Returns whether the concrete function may panic.\n    #[salsa::invoke(crate::panic::concrete_function_with_body_may_panic)]\n    fn concrete_function_with_body_may_panic(\n        &self,\n        function: ConcreteFunctionWithBodyId,\n    ) -> Maybe<bool>;\n\n    /// Checks if the function has a block that ends with panic.\n    #[salsa::invoke(crate::panic::has_direct_panic)]\n    fn has_direct_panic(&self, function_id: ConcreteFunctionWithBodyId) -> Maybe<bool>;\n\n    // ### cycles ###\n\n    /// Returns `true` if the function calls (possibly indirectly) itself, or if it calls (possibly\n    /// indirectly) such a function. For example, if f0 calls f1, f1 calls f2, f2 calls f3, and f3\n    /// calls f2, then [Self::contains_cycle] will return `true` for all of these functions.\n    #[salsa::invoke(crate::graph_algorithms::cycles::contains_cycle)]\n    #[salsa::cycle(crate::graph_algorithms::cycles::contains_cycle_handle_cycle)]\n    fn contains_cycle(&self, function_id: ConcreteFunctionWithBodyId) -> Maybe<bool>;\n\n    /// Returns `true` if the function calls (possibly indirectly) itself. For example, if f0 calls\n    /// f1, f1 calls f2, f2 calls f3, and f3 calls f2, then [Self::in_cycle] will return\n    /// `true` for f2 and f3, but false for f0 and f1.\n    #[salsa::invoke(crate::graph_algorithms::cycles::in_cycle)]\n    fn in_cycle(&self, function_id: FunctionWithBodyId) -> Maybe<bool>;\n\n    // ### Strongly connected components ###\n\n    /// Returns the representative of the concrete function's strongly connected component. The\n    /// representative is consistently chosen for all the concrete functions in the same SCC.\n    #[salsa::invoke(\n        crate::graph_algorithms::strongly_connected_components::concrete_function_with_body_scc_representative\n    )]\n    fn concrete_function_with_body_scc_representative(\n        &self,\n        function: ConcreteFunctionWithBodyId,\n    ) -> ConcreteSCCRepresentative;\n\n    /// Returns all the concrete functions in the same strongly connected component as the given\n    /// concrete function.\n    #[salsa::invoke(\n        crate::graph_algorithms::strongly_connected_components::concrete_function_with_body_scc\n    )]\n    fn concrete_function_with_body_scc(\n        &self,\n        function_id: ConcreteFunctionWithBodyId,\n    ) -> Vec<ConcreteFunctionWithBodyId>;\n\n    /// Returns the representative of the concrete function's strongly connected component. The\n    /// representative is consistently chosen for all the concrete functions in the same SCC.\n    /// This is using the representation after the panic phase.\n    #[salsa::invoke(\n        crate::graph_algorithms::strongly_connected_components::concrete_function_with_body_scc_postpanic_representative\n    )]\n    fn concrete_function_with_body_scc_postpanic_representative(\n        &self,\n        function: ConcreteFunctionWithBodyId,\n    ) -> ConcreteSCCRepresentative;\n\n    /// Returns all the concrete functions in the same strongly connected component as the given\n    /// concrete function.\n    /// This is using the representation after the panic phase.\n    #[salsa::invoke(\n        crate::graph_algorithms::strongly_connected_components::concrete_function_with_body_postpanic_scc\n    )]\n    fn concrete_function_with_body_postpanic_scc(\n        &self,\n        function_id: ConcreteFunctionWithBodyId,\n    ) -> Vec<ConcreteFunctionWithBodyId>;\n\n    /// Returns the representative of the function's strongly connected component. The\n    /// representative is consistently chosen for all the functions in the same SCC.\n    #[salsa::invoke(crate::scc::function_scc_representative)]\n    fn function_scc_representative(&self, function: FunctionWithBodyId)\n    -> GenericSCCRepresentative;\n\n    /// Returns all the functions in the same strongly connected component as the given function.\n    #[salsa::invoke(crate::scc::function_with_body_scc)]\n    fn function_with_body_scc(&self, function_id: FunctionWithBodyId) -> Vec<FunctionWithBodyId>;\n\n    // ### Feedback set ###\n\n    /// Returns the feedback-vertex-set of the given concrete function. A feedback-vertex-set is the\n    /// set of vertices whose removal leaves a graph without cycles.\n    #[salsa::invoke(crate::graph_algorithms::feedback_set::function_with_body_feedback_set)]\n    fn function_with_body_feedback_set(\n        &self,\n        function: ConcreteFunctionWithBodyId,\n    ) -> Maybe<HashSet<ConcreteFunctionWithBodyId>>;\n\n    /// Returns the feedback-vertex-set of the given concrete-function SCC-representative. A\n    /// feedback-vertex-set is the set of vertices whose removal leaves a graph without cycles.\n    #[salsa::invoke(crate::graph_algorithms::feedback_set::priv_function_with_body_feedback_set_of_representative)]\n    fn priv_function_with_body_feedback_set_of_representative(\n        &self,\n        function: ConcreteSCCRepresentative,\n    ) -> Maybe<HashSet<ConcreteFunctionWithBodyId>>;\n}\n\npub fn init_lowering_group(db: &mut (dyn LoweringGroup + 'static)) {\n    // Initialize inputs.\n    db.set_implicit_precedence(Arc::new(vec![]));\n}\n\n#[derive(Debug, Eq, PartialEq, Clone, Hash)]\npub struct GenericSCCRepresentative(pub FunctionWithBodyId);\n\n#[derive(Debug, Eq, PartialEq, Clone, Hash)]\npub struct ConcreteSCCRepresentative(pub ConcreteFunctionWithBodyId);\n\n// *** Main lowering phases in order.\n\n// * Borrow checking.\nfn priv_function_with_body_lowered_flat(\n    db: &dyn LoweringGroup,\n    function_id: FunctionWithBodyId,\n) -> Maybe<Arc<FlatLowered>> {\n    let mut lowered = lower(db.upcast(), function_id)?;\n    borrow_check(db, function_id.module_file_id(db.upcast()), &mut lowered);\n    Ok(Arc::new(lowered))\n}\n\n// * Concretizes lowered representation (monomorphization).\nfn priv_concrete_function_with_body_lowered_flat(\n    db: &dyn LoweringGroup,\n    function: ConcreteFunctionWithBodyId,\n) -> Maybe<Arc<FlatLowered>> {\n    let semantic_db = db.upcast();\n    let mut lowered = (*db\n        .priv_function_with_body_lowered_flat(function.function_with_body_id(semantic_db))?)\n    .clone();\n    concretize_lowered(db, &mut lowered, &function.substitution(semantic_db)?)?;\n    Ok(Arc::new(lowered))\n}\n\n// * Applies inlining.\n// * Adds panics.\n// * Adds destructor calls.\nfn concrete_function_with_body_postpanic_lowered(\n    db: &dyn LoweringGroup,\n    function: ConcreteFunctionWithBodyId,\n) -> Maybe<Arc<FlatLowered>> {\n    let semantic_db = db.upcast();\n    let mut lowered = (*db.priv_concrete_function_with_body_lowered_flat(function)?).clone();\n\n    // TODO(spapini): passing function.function_with_body_id might be weird here.\n    // It's not really needed for inlining, so try to remove.\n    apply_inlining(db, function.function_with_body_id(semantic_db), &mut lowered)?;\n    lowered = lower_panics(db, function, &lowered)?;\n    add_destructs(db, &mut lowered);\n    Ok(Arc::new(lowered))\n}\n\n// * Lowers implicits.\n// * Optimize_matches\n// * Topological sort.\n// * Optimizes remappings\nfn concrete_function_with_body_lowered(\n    db: &dyn LoweringGroup,\n    function: ConcreteFunctionWithBodyId,\n) -> Maybe<Arc<FlatLowered>> {\n    let mut lowered = (*db.concrete_function_with_body_postpanic_lowered(function)?).clone();\n    lower_implicits(db, function, &mut lowered);\n    optimize_matches(&mut lowered);\n    topological_sort(&mut lowered);\n    optimize_remappings(&mut lowered);\n    Ok(Arc::new(lowered))\n}\n\nfn concrete_function_with_body_direct_callees(\n    db: &dyn LoweringGroup,\n    function_id: ConcreteFunctionWithBodyId,\n) -> Maybe<Vec<ConcreteFunction>> {\n    let mut direct_callees = Vec::new();\n    let lowered_function =\n        (*db.priv_concrete_function_with_body_lowered_flat(function_id)?).clone();\n    for (_, block) in &lowered_function.blocks {\n        for statement in &block.statements {\n            if let Statement::Call(statement_call) = statement {\n                let concrete = db.lookup_intern_function(statement_call.function).function;\n                direct_callees.push(concrete);\n            }\n        }\n        if let FlatBlockEnd::Match { info: MatchInfo::Extern(s) } = &block.end {\n            direct_callees.push(s.function.get_concrete(db.upcast()));\n        }\n    }\n    Ok(direct_callees)\n}\n\nfn concrete_function_with_body_postpanic_direct_callees(\n    db: &dyn LoweringGroup,\n    function_id: ConcreteFunctionWithBodyId,\n) -> Maybe<Vec<ConcreteFunction>> {\n    let mut direct_callees = Vec::new();\n    let lowered_function =\n        (*db.concrete_function_with_body_postpanic_lowered(function_id)?).clone();\n    for (_, block) in &lowered_function.blocks {\n        for statement in &block.statements {\n            if let Statement::Call(statement_call) = statement {\n                let concrete = db.lookup_intern_function(statement_call.function).function;\n                direct_callees.push(concrete);\n            }\n        }\n        if let FlatBlockEnd::Match { info: MatchInfo::Extern(s) } = &block.end {\n            direct_callees.push(s.function.get_concrete(db.upcast()));\n        }\n    }\n    Ok(direct_callees)\n}\n\nfn concrete_function_with_body_direct_callees_with_body(\n    db: &dyn LoweringGroup,\n    function_id: ConcreteFunctionWithBodyId,\n) -> Maybe<Vec<ConcreteFunctionWithBodyId>> {\n    Ok(db\n        .concrete_function_with_body_direct_callees(function_id)?\n        .into_iter()\n        .map(|concrete| concrete.get_body(db.upcast()))\n        .collect::<Maybe<Vec<_>>>()?\n        .into_iter()\n        .flatten()\n        .collect_vec())\n}\n\nfn concrete_function_with_body_postpanic_direct_callees_with_body(\n    db: &dyn LoweringGroup,\n    function_id: ConcreteFunctionWithBodyId,\n) -> Maybe<Vec<ConcreteFunctionWithBodyId>> {\n    Ok(db\n        .concrete_function_with_body_postpanic_direct_callees(function_id)?\n        .into_iter()\n        .map(|concrete| concrete.get_body(db.upcast()))\n        .collect::<Maybe<Vec<_>>>()?\n        .into_iter()\n        .flatten()\n        .collect_vec())\n}\n\nfn function_with_body_lowering_diagnostics(\n    db: &dyn LoweringGroup,\n    function_id: FunctionWithBodyId,\n) -> Maybe<Arc<Diagnostics<LoweringDiagnostic>>> {\n    let mut diagnostics = DiagnosticsBuilder::default();\n\n    diagnostics.extend(\n        db.priv_function_with_body_lowered_flat(function_id)\n            .map(|lowered| lowered.diagnostics.clone())\n            .unwrap_or_default(),\n    );\n\n    diagnostics.extend(\n        db.priv_inline_data(function_id)\n            .map(|inline_data| inline_data.diagnostics.clone())\n            .unwrap_or_default(),\n    );\n\n    Ok(Arc::new(diagnostics.build()))\n}\n\nfn module_lowering_diagnostics(\n    db: &dyn LoweringGroup,\n    module_id: ModuleId,\n) -> Maybe<Diagnostics<LoweringDiagnostic>> {\n    let mut diagnostics = DiagnosticsBuilder::default();\n    for item in db.module_items(module_id)?.iter() {\n        match item {\n            ModuleItemId::FreeFunction(free_function) => {\n                let function_id = FunctionWithBodyId::Free(*free_function);\n                diagnostics.extend(\n                    db.function_with_body_lowering_diagnostics(function_id)?.deref().clone(),\n                );\n            }\n            ModuleItemId::Constant(_) => {}\n            ModuleItemId::Submodule(_) => {}\n            ModuleItemId::Use(_) => {}\n            ModuleItemId::Struct(_) => {}\n            ModuleItemId::Enum(_) => {}\n            ModuleItemId::TypeAlias(_) => {}\n            ModuleItemId::Trait(_) => {}\n            ModuleItemId::Impl(impl_def_id) => {\n                for impl_func in db.impl_functions(*impl_def_id)?.values() {\n                    let function_id = FunctionWithBodyId::Impl(*impl_func);\n                    diagnostics.extend(\n                        db.function_with_body_lowering_diagnostics(function_id)?.deref().clone(),\n                    );\n                }\n            }\n            ModuleItemId::ExternType(_) => {}\n            ModuleItemId::ExternFunction(_) => {}\n        }\n    }\n    Ok(diagnostics.build())\n}\n\nfn file_lowering_diagnostics(\n    db: &dyn LoweringGroup,\n    file_id: FileId,\n) -> Maybe<Diagnostics<LoweringDiagnostic>> {\n    let mut diagnostics = DiagnosticsBuilder::default();\n    for module_id in db.file_modules(file_id)? {\n        if let Ok(module_diagnostics) = db.module_lowering_diagnostics(module_id) {\n            diagnostics.extend(module_diagnostics)\n        }\n    }\n    Ok(diagnostics.build())\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! This module implements the destructor call addition. It is assumed to run after the panic phase.\n//! This is similar to the borrow checking algorithm, except we handle \"undroppable drops\" by adding\n//! destructor calls.\n\nuse cairo_lang_semantic::corelib::get_core_trait;\nuse cairo_lang_semantic::items::functions::{GenericFunctionId, ImplGenericFunctionId};\nuse cairo_lang_semantic::items::imp::ImplId;\nuse cairo_lang_semantic::{ConcreteFunction, FunctionLongId};\nuse itertools::{zip_eq, Itertools};\n\nuse crate::borrow_check::analysis::{Analyzer, BackAnalysis, StatementLocation};\nuse crate::borrow_check::demand::DemandReporter;\nuse crate::borrow_check::Demand;\nuse crate::db::LoweringGroup;\nuse crate::{BlockId, FlatLowered, MatchInfo, Statement, StatementCall, VarRemapping, VariableId};\n\npub type LoweredDemand = Demand<VariableId>;\n\n/// Context for the dectructor call addition phase,\npub struct DestructAdder<'a> {\n    lowered: &'a FlatLowered,\n    destructions: Vec<DestructionEntry>,\n}\n\n// A destructr call that needs to be added.\nstruct DestructionEntry {\n    position: StatementLocation,\n    var_id: VariableId,\n    impl_id: ImplId,\n}\n\nimpl<'a> DemandReporter<VariableId> for DestructAdder<'a> {\n    type IntroducePosition = StatementLocation;\n    type UsePosition = ();\n\n    fn drop(&mut self, position: StatementLocation, var_id: VariableId) {\n        let var = &self.lowered.variables[var_id];\n        if var.droppable.is_ok() {\n            return;\n        };\n        // If we a non droppable variable gets our of scope, add a destructor call for it.\n        if let Ok(impl_id) = var.destruct_impl.clone() {\n            self.destructions.push(DestructionEntry { position, var_id, impl_id });\n        }\n\n        // TODO(spapini): Panic here when everything works.\n    }\n\n    fn dup(&mut self, _position: (), _var: VariableId) {}\n}\n\nimpl<'a> Analyzer for DestructAdder<'a> {\n    type Info = LoweredDemand;\n\n    fn visit_stmt(\n        &mut self,\n        info: &mut Self::Info,\n        statement_location: StatementLocation,\n        stmt: &Statement,\n    ) {\n        info.variables_introduced(self, &stmt.outputs(), statement_location);\n        info.variables_used(self, &stmt.inputs(), ());\n    }\n\n    fn visit_remapping(\n        &mut self,\n        info: &mut Self::Info,\n        _block_id: BlockId,\n        _target_block_id: BlockId,\n        remapping: &VarRemapping,\n    ) {\n        info.apply_remapping(self, remapping.iter().map(|(dst, src)| (*dst, *src)));\n    }\n\n    fn merge_match(\n        &mut self,\n        _statement_location: StatementLocation,\n        match_info: &MatchInfo,\n        infos: &[Self::Info],\n    ) -> Self::Info {\n        let arm_demands = zip_eq(match_info.arms(), infos)\n            .map(|(arm, demand)| {\n                let mut demand = demand.clone();\n                let use_position = (arm.block_id, 0);\n                demand.variables_introduced(self, &arm.var_ids, use_position);\n                (demand, use_position)\n            })\n            .collect_vec();\n        let mut demand = LoweredDemand::merge_demands(&arm_demands, self);\n        demand.variables_used(self, &match_info.inputs(), ());\n        demand\n    }\n\n    fn info_from_return(\n        &mut self,\n        _statement_location: StatementLocation,\n        vars: &[VariableId],\n    ) -> Self::Info {\n        let mut info = LoweredDemand::default();\n        info.variables_used(self, vars, ());\n        info\n    }\n\n    fn info_from_panic(\n        &mut self,\n        _statement_location: StatementLocation,\n        data: &VariableId,\n    ) -> Self::Info {\n        let mut info = LoweredDemand::default();\n        info.variables_used(self, &[*data], ());\n        info\n    }\n}\n\n/// Report borrow checking diagnostics.\npub fn add_destructs(db: &dyn LoweringGroup, lowered: &mut FlatLowered) {\n    if lowered.blocks.has_root().is_ok() {\n        let checker = DestructAdder { lowered, destructions: vec![] };\n        let mut analysis =\n            BackAnalysis { lowered: &*lowered, cache: Default::default(), analyzer: checker };\n        let mut root_demand = analysis.get_root_info();\n        root_demand.variables_introduced(\n            &mut analysis.analyzer,\n            &lowered.parameters,\n            (BlockId::root(), 0),\n        );\n        assert!(root_demand.finalize(), \"Undefined variable should not happen at this stage\");\n\n        let trait_id = get_core_trait(db.upcast(), \"Destruct\".into());\n        let trait_function =\n            db.trait_function_by_name(trait_id, \"destruct\".into()).unwrap().unwrap();\n\n        // Add destructions.\n        for destruction in analysis.analyzer.destructions {\n            let DestructionEntry { position: (block_id, statement_offset), var_id, impl_id } =\n                destruction;\n            lowered.blocks[block_id].statements.insert(\n                statement_offset,\n                Statement::Call(StatementCall {\n                    function: db.intern_function(FunctionLongId {\n                        function: ConcreteFunction {\n                            generic_function: GenericFunctionId::Impl(ImplGenericFunctionId {\n                                impl_id,\n                                function: trait_function,\n                            }),\n                            generic_args: vec![],\n                        },\n                    }),\n                    inputs: vec![var_id],\n                    outputs: vec![],\n                    location: lowered.variables[var_id].location,\n                }),\n            )\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_defs::diagnostic_utils::{StableLocation, StableLocationOption};\nuse cairo_lang_defs::ids::ModuleFileId;\nuse cairo_lang_diagnostics::{\n    DiagnosticAdded, DiagnosticEntry, DiagnosticLocation, Diagnostics, DiagnosticsBuilder,\n};\nuse cairo_lang_semantic::db::SemanticGroup;\nuse cairo_lang_semantic::expr::inference::InferenceError;\nuse cairo_lang_syntax::node::ids::SyntaxStablePtrId;\n\npub struct LoweringDiagnostics {\n    pub diagnostics: DiagnosticsBuilder<LoweringDiagnostic>,\n    pub module_file_id: ModuleFileId,\n}\nimpl LoweringDiagnostics {\n    pub fn new(module_file_id: ModuleFileId) -> Self {\n        Self { module_file_id, diagnostics: DiagnosticsBuilder::default() }\n    }\n    pub fn build(self) -> Diagnostics<LoweringDiagnostic> {\n        self.diagnostics.build()\n    }\n    pub fn report(\n        &mut self,\n        stable_ptr: SyntaxStablePtrId,\n        kind: LoweringDiagnosticKind,\n    ) -> DiagnosticAdded {\n        self.report_by_location(StableLocationOption::new(self.module_file_id, stable_ptr), kind)\n    }\n    pub fn report_by_location(\n        &mut self,\n        stable_location: StableLocationOption,\n        kind: LoweringDiagnosticKind,\n    ) -> DiagnosticAdded {\n        self.diagnostics.add(LoweringDiagnostic { stable_location: stable_location.unwrap(), kind })\n    }\n}\n\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct LoweringDiagnostic {\n    pub stable_location: StableLocation,\n    pub kind: LoweringDiagnosticKind,\n}\nimpl DiagnosticEntry for LoweringDiagnostic {\n    type DbType = dyn SemanticGroup;\n\n    fn format(&self, db: &Self::DbType) -> String {\n        match &self.kind {\n            LoweringDiagnosticKind::Unreachable { .. } => \"Unreachable code\".into(),\n            LoweringDiagnosticKind::NonZeroValueInMatch => {\n                \"Match with a non-zero value is not supported.\".into()\n            }\n            LoweringDiagnosticKind::OnlyMatchZeroIsSupported => {\n                \"Only match zero (match ... { 0 => ..., _ => ... }) is currently supported.\".into()\n            }\n            LoweringDiagnosticKind::VariableMoved { inference_error } => {\n                format!(\"Variable was previously moved. {}\", inference_error.format(db))\n            }\n            LoweringDiagnosticKind::VariableNotDropped { drop_err, destruct_err } => {\n                format!(\n                    \"Variable not dropped. {}. {}.\",\n                    drop_err.format(db),\n                    destruct_err.format(db)\n                )\n            }\n            LoweringDiagnosticKind::DesnappingANonCopyableType { inference_error } => {\n                format!(\"Cannot desnap a non copyable type. {}\", inference_error.format(db))\n            }\n            LoweringDiagnosticKind::UnsupportedMatch => \"Unsupported match. Currently, matches \\\n                                                         require one arm per variant, in the \\\n                                                         order of variant definition.\"\n                .into(),\n            LoweringDiagnosticKind::UnsupportedMatchArmNotAVariant => {\n                \"Unsupported match arm - not a variant.\".into()\n            }\n            LoweringDiagnosticKind::UnsupportedMatchArmOutOfOrder => {\n                \"Unsupported match arm - variants must be the same order as enum declaration.\"\n                    .into()\n            }\n            LoweringDiagnosticKind::CannotInlineFunctionThatMightCallItself => {\n                \"Cannot inline a function that might call itself.\".into()\n            }\n            LoweringDiagnosticKind::UnsupportedMatchEmptyEnum => {\n                \"Unsupported match - match on empty enums is not supported.\".into()\n            }\n        }\n    }\n\n    #[allow(unreachable_patterns, clippy::single_match)]\n    fn location(&self, db: &Self::DbType) -> DiagnosticLocation {\n        match &self.kind {\n            LoweringDiagnosticKind::Unreachable { last_statement_ptr } => {\n                return self\n                    .stable_location\n                    .diagnostic_location_until(db.upcast(), *last_statement_ptr);\n            }\n            _ => {}\n        }\n        self.stable_location.diagnostic_location(db.upcast())\n    }\n}\n\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum LoweringDiagnosticKind {\n    Unreachable { last_statement_ptr: SyntaxStablePtrId },\n    // TODO(lior): Remove once supported.\n    NonZeroValueInMatch,\n    // TODO(lior): Remove once supported.\n    OnlyMatchZeroIsSupported,\n    VariableMoved { inference_error: InferenceError },\n    VariableNotDropped { drop_err: InferenceError, destruct_err: InferenceError },\n    DesnappingANonCopyableType { inference_error: InferenceError },\n    UnsupportedMatch,\n    UnsupportedMatchArmNotAVariant,\n    UnsupportedMatchArmOutOfOrder,\n    UnsupportedMatchEmptyEnum,\n    CannotInlineFunctionThatMightCallItself,\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_debug::DebugWithDb;\nuse cairo_lang_semantic::ConcreteVariant;\nuse id_arena::Arena;\n\nuse crate::db::LoweringGroup;\nuse crate::objects::{\n    BlockId, MatchExternInfo, Statement, StatementCall, StatementLiteral,\n    StatementStructDestructure, VariableId,\n};\nuse crate::{\n    FlatBlock, FlatBlockEnd, FlatLowered, MatchArm, MatchEnumInfo, MatchInfo, StatementDesnap,\n    StatementEnumConstruct, StatementSnapshot, StatementStructConstruct, VarRemapping, Variable,\n};\n\n/// Holds all the information needed for formatting lowered representations.\n/// Acts like a \"db\" for DebugWithDb.\npub struct LoweredFormatter<'db> {\n    pub db: &'db dyn LoweringGroup,\n    pub variables: &'db Arena<Variable>,\n}\n\nimpl DebugWithDb<LoweredFormatter<'_>> for VarRemapping {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, ctx: &LoweredFormatter<'_>) -> std::fmt::Result {\n        let mut remapping = self.iter().peekable();\n        write!(f, \"{{\")?;\n        while let Some((dst, src)) = remapping.next() {\n            src.fmt(f, ctx)?;\n            write!(f, \" -> \")?;\n            dst.fmt(f, ctx)?;\n            if remapping.peek().is_some() {\n                write!(f, \", \")?;\n            }\n        }\n        write!(f, \"}}\")?;\n        Ok(())\n    }\n}\nimpl DebugWithDb<LoweredFormatter<'_>> for FlatLowered {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, ctx: &LoweredFormatter<'_>) -> std::fmt::Result {\n        write!(f, \"Parameters:\")?;\n        let mut inputs = self.parameters.iter().peekable();\n        while let Some(var) = inputs.next() {\n            write!(f, \" \")?;\n            format_var_with_ty(*var, f, ctx)?;\n            if inputs.peek().is_some() {\n                write!(f, \",\")?;\n            }\n        }\n        writeln!(f)?;\n        let mut blocks = self.blocks.iter();\n        if let Some((root_block_id, root_block)) = blocks.next() {\n            root_block_id.fmt(f, ctx)?;\n            writeln!(f, \" (root):\")?;\n            root_block.fmt(f, ctx)?;\n            writeln!(f)?;\n        }\n        for (block_id, block) in blocks {\n            block_id.fmt(f, ctx)?;\n            writeln!(f, \":\")?;\n            block.fmt(f, ctx)?;\n            writeln!(f)?;\n        }\n        Ok(())\n    }\n}\n\nimpl DebugWithDb<LoweredFormatter<'_>> for FlatBlock {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, ctx: &LoweredFormatter<'_>) -> std::fmt::Result {\n        writeln!(f, \"Statements:\")?;\n        for stmt in &self.statements {\n            write!(f, \"  \")?;\n            stmt.fmt(f, ctx)?;\n            writeln!(f)?;\n        }\n\n        writeln!(f, \"End:\")?;\n        self.end.fmt(f, ctx)?;\n        writeln!(f)\n    }\n}\n\nimpl DebugWithDb<LoweredFormatter<'_>> for FlatBlockEnd {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, ctx: &LoweredFormatter<'_>) -> std::fmt::Result {\n        let outputs = match &self {\n            FlatBlockEnd::Return(returns) => {\n                write!(f, \"  Return(\")?;\n                returns.clone()\n            }\n            FlatBlockEnd::Panic(data) => {\n                write!(f, \"  Panic(\")?;\n                vec![*data]\n            }\n            FlatBlockEnd::Goto(block_id, remapping) => {\n                return write!(f, \"  Goto({:?}, {:?})\", block_id.debug(ctx), remapping.debug(ctx));\n            }\n            FlatBlockEnd::NotSet => unreachable!(),\n            FlatBlockEnd::Match { info } => {\n                return write!(f, \"  Match({:?})\", info.debug(ctx));\n            }\n        };\n        let mut outputs = outputs.iter().peekable();\n        while let Some(var) = outputs.next() {\n            var.fmt(f, ctx)?;\n            if outputs.peek().is_some() {\n                write!(f, \", \")?;\n            }\n        }\n        write!(f, \")\")\n    }\n}\n\nfn format_var_with_ty(\n    var_id: VariableId,\n    f: &mut std::fmt::Formatter<'_>,\n    ctx: &LoweredFormatter<'_>,\n) -> std::fmt::Result {\n    var_id.fmt(f, ctx)?;\n    let var = &ctx.variables[var_id];\n    write!(f, \": {}\", var.ty.format(ctx.db.upcast()))\n}\n\nimpl DebugWithDb<LoweredFormatter<'_>> for BlockId {\n    fn fmt(\n        &self,\n        f: &mut std::fmt::Formatter<'_>,\n        _lowered: &LoweredFormatter<'_>,\n    ) -> std::fmt::Result {\n        write!(f, \"blk{:?}\", self.0)\n    }\n}\n\nimpl DebugWithDb<LoweredFormatter<'_>> for VariableId {\n    fn fmt(\n        &self,\n        f: &mut std::fmt::Formatter<'_>,\n        _lowered: &LoweredFormatter<'_>,\n    ) -> std::fmt::Result {\n        write!(f, \"v{:?}\", self.index())\n    }\n}\n\nimpl DebugWithDb<LoweredFormatter<'_>> for Statement {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, ctx: &LoweredFormatter<'_>) -> std::fmt::Result {\n        write!(f, \"(\")?;\n        let mut outputs = self.outputs().into_iter().peekable();\n        while let Some(var) = outputs.next() {\n            format_var_with_ty(var, f, ctx)?;\n            if outputs.peek().is_some() {\n                write!(f, \", \")?;\n            }\n        }\n        write!(f, \") <- \")?;\n        match self {\n            Statement::Literal(stmt) => stmt.fmt(f, ctx),\n            Statement::Call(stmt) => stmt.fmt(f, ctx),\n            Statement::StructConstruct(stmt) => stmt.fmt(f, ctx),\n            Statement::StructDestructure(stmt) => stmt.fmt(f, ctx),\n            Statement::EnumConstruct(stmt) => stmt.fmt(f, ctx),\n            Statement::Snapshot(stmt) => stmt.fmt(f, ctx),\n            Statement::Desnap(stmt) => stmt.fmt(f, ctx),\n        }\n    }\n}\n\nimpl DebugWithDb<LoweredFormatter<'_>> for MatchInfo {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, ctx: &LoweredFormatter<'_>) -> std::fmt::Result {\n        match self {\n            MatchInfo::Extern(s) => s.fmt(f, ctx),\n            MatchInfo::Enum(s) => s.fmt(f, ctx),\n        }\n    }\n}\n\nimpl DebugWithDb<LoweredFormatter<'_>> for StatementLiteral {\n    fn fmt(\n        &self,\n        f: &mut std::fmt::Formatter<'_>,\n        _ctx: &LoweredFormatter<'_>,\n    ) -> std::fmt::Result {\n        write!(f, \"{}u\", self.value)\n    }\n}\n\nimpl DebugWithDb<LoweredFormatter<'_>> for StatementCall {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, ctx: &LoweredFormatter<'_>) -> std::fmt::Result {\n        write!(f, \"{:?}(\", self.function.debug(ctx.db))?;\n        let mut inputs = self.inputs.iter().peekable();\n        while let Some(var) = inputs.next() {\n            var.fmt(f, ctx)?;\n            if inputs.peek().is_some() {\n                write!(f, \", \")?;\n            }\n        }\n        write!(f, \")\")\n    }\n}\n\nimpl DebugWithDb<LoweredFormatter<'_>> for MatchExternInfo {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, ctx: &LoweredFormatter<'_>) -> std::fmt::Result {\n        write!(f, \"match {:?}(\", self.function.debug(ctx.db))?;\n        let mut inputs = self.inputs.iter().peekable();\n        while let Some(var) = inputs.next() {\n            var.fmt(f, ctx)?;\n            if inputs.peek().is_some() {\n                write!(f, \", \")?;\n            }\n        }\n        writeln!(f, \") {{\")?;\n        for arm in &self.arms {\n            arm.fmt(f, ctx)?;\n            writeln!(f)?;\n        }\n        write!(f, \"  }}\")\n    }\n}\n\nimpl DebugWithDb<LoweredFormatter<'_>> for ConcreteVariant {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, ctx: &LoweredFormatter<'_>) -> std::fmt::Result {\n        let enum_name = self.concrete_enum_id.enum_id(ctx.db.upcast()).name(ctx.db.upcast());\n        let variant_name = self.id.name(ctx.db.upcast());\n        write!(f, \"{enum_name}::{variant_name}\")\n    }\n}\n\nimpl DebugWithDb<LoweredFormatter<'_>> for MatchArm {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, ctx: &LoweredFormatter<'_>) -> std::fmt::Result {\n        write!(f, \"    {:?}\", self.variant_id.debug(ctx))?;\n\n        if !self.var_ids.is_empty() {\n            write!(f, \"(\")?;\n            let mut var_ids = self.var_ids.iter().peekable();\n            while let Some(var_id) = var_ids.next() {\n                var_id.fmt(f, ctx)?;\n                if var_ids.peek().is_some() {\n                    write!(f, \", \")?;\n                }\n            }\n            write!(f, \")\")?;\n        }\n\n        write!(f, \" => {:?},\", self.block_id.debug(ctx))\n    }\n}\n\nimpl DebugWithDb<LoweredFormatter<'_>> for MatchEnumInfo {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, ctx: &LoweredFormatter<'_>) -> std::fmt::Result {\n        write!(f, \"match_enum(\")?;\n        self.input.fmt(f, ctx)?;\n        writeln!(f, \") {{\")?;\n        for arm in &self.arms {\n            arm.fmt(f, ctx)?;\n            writeln!(f)?;\n        }\n        write!(f, \"  }}\")\n    }\n}\n\nimpl DebugWithDb<LoweredFormatter<'_>> for StatementEnumConstruct {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, ctx: &LoweredFormatter<'_>) -> std::fmt::Result {\n        let enum_name =\n            self.variant.concrete_enum_id.enum_id(ctx.db.upcast()).name(ctx.db.upcast());\n        let variant_name = self.variant.id.name(ctx.db.upcast());\n        write!(f, \"{enum_name}::{variant_name}(\",)?;\n        self.input.fmt(f, ctx)?;\n        write!(f, \")\")\n    }\n}\n\nimpl DebugWithDb<LoweredFormatter<'_>> for StatementStructConstruct {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, ctx: &LoweredFormatter<'_>) -> std::fmt::Result {\n        write!(f, \"struct_construct(\")?;\n        let mut inputs = self.inputs.iter().peekable();\n        while let Some(var) = inputs.next() {\n            var.fmt(f, ctx)?;\n            if inputs.peek().is_some() {\n                write!(f, \", \")?;\n            }\n        }\n        write!(f, \")\")\n    }\n}\n\nimpl DebugWithDb<LoweredFormatter<'_>> for StatementStructDestructure {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, ctx: &LoweredFormatter<'_>) -> std::fmt::Result {\n        write!(f, \"struct_destructure(\")?;\n        self.input.fmt(f, ctx)?;\n        write!(f, \")\")\n    }\n}\n\nimpl DebugWithDb<LoweredFormatter<'_>> for StatementSnapshot {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, ctx: &LoweredFormatter<'_>) -> std::fmt::Result {\n        write!(f, \"snapshot(\")?;\n        self.input.fmt(f, ctx)?;\n        write!(f, \")\")\n    }\n}\n\nimpl DebugWithDb<LoweredFormatter<'_>> for StatementDesnap {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, ctx: &LoweredFormatter<'_>) -> std::fmt::Result {\n        write!(f, \"desnap(\")?;\n        self.input.fmt(f, ctx)?;\n        write!(f, \")\")\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_semantic::ConcreteFunctionWithBodyId;\nuse cairo_lang_utils::graph_algos::graph_node::GraphNode;\nuse cairo_lang_utils::graph_algos::strongly_connected_components::ComputeScc;\n\nuse super::strongly_connected_components::concrete_function_with_body_scc;\nuse crate::db::LoweringGroup;\n\n/// A node to use in graph-algorithms.\n#[derive(Clone)]\npub struct ConcreteFunctionWithBodyNode<'a> {\n    pub function_id: ConcreteFunctionWithBodyId,\n    pub db: &'a dyn LoweringGroup,\n}\nimpl<'a> GraphNode for ConcreteFunctionWithBodyNode<'a> {\n    type NodeId = ConcreteFunctionWithBodyId;\n\n    fn get_neighbors(&self) -> Vec<Self> {\n        let Ok(direct_callees) = self.db.concrete_function_with_body_direct_callees_with_body(self.function_id)\n            else { return vec![] };\n        direct_callees\n            .into_iter()\n            .map(|callee| ConcreteFunctionWithBodyNode { function_id: callee, db: self.db })\n            .collect()\n    }\n\n    fn get_id(&self) -> Self::NodeId {\n        self.function_id\n    }\n}\nimpl<'a> ComputeScc for ConcreteFunctionWithBodyNode<'a> {\n    fn compute_scc(&self) -> Vec<Self::NodeId> {\n        concrete_function_with_body_scc(self.db, self.function_id)\n    }\n}\n\n#[derive(Clone)]\npub struct ConcreteFunctionWithBodyPostPanicNode<'a> {\n    pub function_id: ConcreteFunctionWithBodyId,\n    pub db: &'a dyn LoweringGroup,\n}\nimpl<'a> GraphNode for ConcreteFunctionWithBodyPostPanicNode<'a> {\n    type NodeId = ConcreteFunctionWithBodyId;\n\n    fn get_neighbors(&self) -> Vec<Self> {\n        let Ok(direct_callees) = self.db.concrete_function_with_body_postpanic_direct_callees_with_body(self.function_id)\n            else { return vec![] };\n        direct_callees\n            .into_iter()\n            .map(|callee| ConcreteFunctionWithBodyPostPanicNode {\n                function_id: callee,\n                db: self.db,\n            })\n            .collect()\n    }\n\n    fn get_id(&self) -> Self::NodeId {\n        self.function_id\n    }\n}\nimpl<'a> ComputeScc for ConcreteFunctionWithBodyPostPanicNode<'a> {\n    fn compute_scc(&self) -> Vec<Self::NodeId> {\n        concrete_function_with_body_scc(self.db, self.function_id)\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_defs::ids::FunctionWithBodyId;\nuse cairo_lang_diagnostics::Maybe;\nuse cairo_lang_semantic::ConcreteFunctionWithBodyId;\n\nuse crate::db::LoweringGroup;\n\n/// Query implementation of [LoweringGroup::contains_cycle].\npub fn contains_cycle(\n    db: &dyn LoweringGroup,\n    function_id: ConcreteFunctionWithBodyId,\n) -> Maybe<bool> {\n    let direct_callees = db.concrete_function_with_body_direct_callees_with_body(function_id)?;\n    for callee in direct_callees {\n        if db.contains_cycle(callee)? {\n            return Ok(true);\n        }\n    }\n\n    Ok(false)\n}\n\n/// Cycle handling for [LoweringGroup::contains_cycle].\npub fn contains_cycle_handle_cycle(\n    _db: &dyn LoweringGroup,\n    _cycle: &[String],\n    _function_id: &ConcreteFunctionWithBodyId,\n) -> Maybe<bool> {\n    Ok(true)\n}\n\n/// Query implementation of [LoweringGroup::in_cycle].\npub fn in_cycle(db: &dyn LoweringGroup, function_id: FunctionWithBodyId) -> Maybe<bool> {\n    if db.function_with_body_direct_function_with_body_callees(function_id)?.contains(&function_id)\n    {\n        return Ok(true);\n    }\n    Ok(db.function_with_body_scc(function_id).len() > 1)\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashSet;\n\nuse cairo_lang_diagnostics::Maybe;\nuse cairo_lang_semantic::ConcreteFunctionWithBodyId;\nuse cairo_lang_utils::graph_algos::feedback_set::calc_feedback_set;\n\nuse super::concrete_function_node::ConcreteFunctionWithBodyNode;\nuse crate::db::{ConcreteSCCRepresentative, LoweringGroup};\n\n/// Query implementation of [crate::db::LoweringGroup::function_with_body_feedback_set].\npub fn function_with_body_feedback_set(\n    db: &dyn LoweringGroup,\n    function: ConcreteFunctionWithBodyId,\n) -> Maybe<HashSet<ConcreteFunctionWithBodyId>> {\n    let r = db.concrete_function_with_body_scc_representative(function);\n    db.priv_function_with_body_feedback_set_of_representative(r)\n}\n\n/// Query implementation of\n/// [crate::db::LoweringGroup::priv_function_with_body_feedback_set_of_representative].\npub fn priv_function_with_body_feedback_set_of_representative(\n    db: &dyn LoweringGroup,\n    function: ConcreteSCCRepresentative,\n) -> Maybe<HashSet<ConcreteFunctionWithBodyId>> {\n    Ok(calc_feedback_set(&ConcreteFunctionWithBodyNode { function_id: function.0, db }.into()))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "pub mod concrete_function_node;\npub mod cycles;\npub mod feedback_set;\npub mod strongly_connected_components;\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_defs::ids::UnstableSalsaId;\nuse cairo_lang_semantic::ConcreteFunctionWithBodyId;\nuse cairo_lang_utils::graph_algos::strongly_connected_components::compute_scc;\n\nuse super::concrete_function_node::{\n    ConcreteFunctionWithBodyNode, ConcreteFunctionWithBodyPostPanicNode,\n};\nuse crate::db::{ConcreteSCCRepresentative, LoweringGroup};\n\n/// Query implementation of\n/// [crate::db::LoweringGroup::concrete_function_with_body_scc_representative].\npub fn concrete_function_with_body_scc_representative(\n    db: &dyn LoweringGroup,\n    function: ConcreteFunctionWithBodyId,\n) -> ConcreteSCCRepresentative {\n    ConcreteSCCRepresentative(\n        db.concrete_function_with_body_scc(function)\n            .into_iter()\n            .min_by(|x, y| x.get_internal_id().cmp(y.get_internal_id()))\n            .unwrap_or(function),\n    )\n}\n\n/// Query implementation of [crate::db::LoweringGroup::concrete_function_with_body_scc].\npub fn concrete_function_with_body_scc(\n    db: &dyn LoweringGroup,\n    function_id: ConcreteFunctionWithBodyId,\n) -> Vec<ConcreteFunctionWithBodyId> {\n    compute_scc(&ConcreteFunctionWithBodyNode { function_id, db: db.upcast() })\n}\n\n/// Query implementation of\n/// [crate::db::LoweringGroup::concrete_function_with_body_scc_postpanic_representative].\npub fn concrete_function_with_body_scc_postpanic_representative(\n    db: &dyn LoweringGroup,\n    function: ConcreteFunctionWithBodyId,\n) -> ConcreteSCCRepresentative {\n    ConcreteSCCRepresentative(\n        db.concrete_function_with_body_postpanic_scc(function)\n            .into_iter()\n            .min_by(|x, y| x.get_internal_id().cmp(y.get_internal_id()))\n            .unwrap_or(function),\n    )\n}\n\n/// Query implementation of [crate::db::LoweringGroup::concrete_function_with_body_postpanic_scc].\npub fn concrete_function_with_body_postpanic_scc(\n    db: &dyn LoweringGroup,\n    function_id: ConcreteFunctionWithBodyId,\n) -> Vec<ConcreteFunctionWithBodyId> {\n    compute_scc(&ConcreteFunctionWithBodyPostPanicNode { function_id, db: db.upcast() })\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::{HashMap, HashSet};\n\nuse cairo_lang_defs::diagnostic_utils::StableLocationOption;\nuse cairo_lang_defs::ids::LanguageElementId;\nuse cairo_lang_diagnostics::Maybe;\nuse cairo_lang_semantic as semantic;\nuse itertools::{chain, zip_eq, Itertools};\nuse semantic::items::functions::{\n    ConcreteFunctionWithBody, GenericFunctionId, GenericFunctionWithBodyId,\n};\nuse semantic::{ConcreteFunctionWithBodyId, TypeId};\n\nuse crate::blocks::Blocks;\nuse crate::db::{ConcreteSCCRepresentative, LoweringGroup};\nuse crate::graph_algorithms::strongly_connected_components::concrete_function_with_body_scc;\nuse crate::lower::context::{LoweringContext, LoweringContextBuilder, VarRequest};\nuse crate::{BlockId, FlatBlockEnd, FlatLowered, MatchArm, MatchInfo, Statement, VariableId};\n\nstruct Context<'a> {\n    db: &'a dyn LoweringGroup,\n    ctx: &'a mut LoweringContext<'a>,\n    lowered: &'a mut FlatLowered,\n    implicit_index: HashMap<TypeId, usize>,\n    implicits_tys: Vec<TypeId>,\n    implicit_vars_for_block: HashMap<BlockId, Vec<VariableId>>,\n    visited: HashSet<BlockId>,\n    location: StableLocationOption,\n}\n\n/// Lowering phase that adds implicits.\npub fn lower_implicits(\n    db: &dyn LoweringGroup,\n    function_id: ConcreteFunctionWithBodyId,\n    lowered: &mut FlatLowered,\n) {\n    if let Err(diag_added) = inner_lower_implicits(db, function_id, lowered) {\n        lowered.blocks = Blocks::new_errored(diag_added);\n    }\n}\n\n/// Similar to lower_implicits, but uses Maybe<> for convenience.\npub fn inner_lower_implicits(\n    db: &dyn LoweringGroup,\n    function_id: ConcreteFunctionWithBodyId,\n    lowered: &mut FlatLowered,\n) -> Maybe<()> {\n    let generic_function_id = function_id.function_with_body_id(db.upcast());\n    let function_signature = db.function_with_body_signature(generic_function_id)?;\n    let location = StableLocationOption::new(\n        generic_function_id.module_file_id(db.upcast()),\n        function_signature.stable_ptr.untyped(),\n    );\n    lowered.blocks.has_root()?;\n    let root_block_id = BlockId::root();\n\n    let lowering_info = LoweringContextBuilder::new(db, generic_function_id)?;\n    let mut lowering_ctx = lowering_info.ctx()?;\n    lowering_ctx.variables = lowered.variables.clone();\n\n    let implicits_tys = db.concrete_function_with_body_all_implicits_vec(function_id)?;\n\n    let implicit_index =\n        HashMap::from_iter(implicits_tys.iter().enumerate().map(|(i, ty)| (*ty, i)));\n    let mut ctx = Context {\n        db,\n        ctx: &mut lowering_ctx,\n        lowered,\n        implicit_index,\n        implicits_tys,\n        implicit_vars_for_block: Default::default(),\n        visited: Default::default(),\n        location,\n    };\n\n    // Start form root block.\n    lower_block_implicits(&mut ctx, root_block_id)?;\n\n    // Introduce new input variables in the root block.\n    let implicit_vars = &ctx.implicit_vars_for_block[&root_block_id];\n    ctx.lowered.parameters.splice(0..0, implicit_vars.iter().cloned());\n\n    lowered.variables = std::mem::take(&mut ctx.ctx.variables);\n\n    Ok(())\n}\n\n/// Allocates and returns new variables for each of the current function's implicits.\nfn alloc_implicits(\n    ctx: &mut LoweringContext<'_>,\n    implicits_tys: &[TypeId],\n    location: StableLocationOption,\n) -> Vec<VariableId> {\n    implicits_tys.iter().copied().map(|ty| ctx.new_var(VarRequest { ty, location })).collect_vec()\n}\n\n/// Adds implicits in a block.\nfn lower_block_implicits(ctx: &mut Context<'_>, block_id: BlockId) -> Maybe<()> {\n    if !ctx.visited.insert(block_id) {\n        return Ok(());\n    }\n    let mut implicits = ctx\n        .implicit_vars_for_block\n        .entry(block_id)\n        .or_insert_with(|| alloc_implicits(ctx.ctx, &ctx.implicits_tys, ctx.location))\n        .clone();\n    for statement in &mut ctx.lowered.blocks[block_id].statements {\n        if let Statement::Call(stmt) = statement {\n            let callee_implicits = ctx.db.function_all_implicits(stmt.function)?;\n            let indices = callee_implicits.iter().map(|ty| ctx.implicit_index[ty]).collect_vec();\n            let implicit_input_vars = indices.iter().map(|i| implicits[*i]);\n            stmt.inputs.splice(0..0, implicit_input_vars);\n            let implicit_output_vars = callee_implicits\n                .iter()\n                .copied()\n                .map(|ty| ctx.ctx.new_var(VarRequest { ty, location: stmt.location }))\n                .collect_vec();\n            for (i, var) in zip_eq(indices, implicit_output_vars.iter()) {\n                implicits[i] = *var;\n            }\n            stmt.outputs.splice(0..0, implicit_output_vars);\n        }\n    }\n    // End.\n    let mut blocks_to_visit = vec![];\n    match &mut ctx.lowered.blocks[block_id].end {\n        FlatBlockEnd::Return(rets) => {\n            rets.splice(0..0, implicits);\n        }\n        FlatBlockEnd::Panic(_) => {\n            unreachable!(\"Panics should have been stripped in a previous phase.\")\n        }\n        FlatBlockEnd::Goto(block_id, remapping) => {\n            let target_implicits = ctx\n                .implicit_vars_for_block\n                .entry(*block_id)\n                .or_insert_with(|| alloc_implicits(ctx.ctx, &ctx.implicits_tys, ctx.location))\n                .clone();\n            let old_remapping = std::mem::take(&mut remapping.remapping);\n            remapping.remapping =\n                chain!(zip_eq(target_implicits, implicits), old_remapping).collect();\n            blocks_to_visit.push(*block_id);\n        }\n        FlatBlockEnd::Match { info } => match info {\n            MatchInfo::Enum(stmt) => {\n                for MatchArm { variant_id: _, block_id, var_ids: _ } in &stmt.arms {\n                    assert!(\n                        ctx.implicit_vars_for_block.insert(*block_id, implicits.clone()).is_none(),\n                        \"Multiple jumps to arm blocks are not allowed.\"\n                    );\n                    blocks_to_visit.push(*block_id);\n                }\n            }\n            MatchInfo::Extern(stmt) => {\n                let callee_implicits = ctx.db.function_all_implicits(stmt.function)?;\n                let indices =\n                    callee_implicits.iter().map(|ty| ctx.implicit_index[ty]).collect_vec();\n                let implicit_input_vars = indices.iter().map(|i| implicits[*i]);\n                stmt.inputs.splice(0..0, implicit_input_vars);\n                let location = stmt.location;\n\n                for MatchArm { variant_id: _, block_id, var_ids } in stmt.arms.iter_mut() {\n                    let mut arm_implicits = implicits.clone();\n                    let mut implicit_input_vars = vec![];\n                    for ty in callee_implicits.iter().copied() {\n                        let var = ctx.ctx.new_var(VarRequest { ty, location });\n                        implicit_input_vars.push(var);\n                        let implicit_index = ctx.implicit_index[&ty];\n                        arm_implicits[implicit_index] = var;\n                    }\n                    assert!(\n                        ctx.implicit_vars_for_block.insert(*block_id, arm_implicits).is_none(),\n                        \"Multiple jumps to arm blocks are not allowed.\"\n                    );\n\n                    var_ids.splice(0..0, implicit_input_vars);\n                    blocks_to_visit.push(*block_id);\n                }\n            }\n        },\n        FlatBlockEnd::NotSet => unreachable!(),\n    }\n    for block_id in blocks_to_visit {\n        lower_block_implicits(ctx, block_id)?;\n    }\n    Ok(())\n}\n\n// =========== Query implementations ===========\n\n/// Query implementation of [crate::db::LoweringGroup::function_scc_explicit_implicits].\npub fn function_scc_explicit_implicits(\n    db: &dyn LoweringGroup,\n    function: ConcreteSCCRepresentative,\n) -> Maybe<HashSet<TypeId>> {\n    let scc = concrete_function_with_body_scc(db, function.0);\n    let mut explicit_implicits = HashSet::new();\n    for func in scc {\n        let current_implicits: HashSet<TypeId> = match func.generic_function(db.upcast()) {\n            GenericFunctionWithBodyId::Free(free_function) => {\n                db.free_function_declaration_implicits(free_function)?.into_iter().collect()\n            }\n            GenericFunctionWithBodyId::Impl(concrete_impl_generic_function) => db\n                .impl_function_declaration_implicits(concrete_impl_generic_function.function)?\n                .into_iter()\n                .collect(),\n        };\n        explicit_implicits.extend(current_implicits);\n    }\n    Ok(explicit_implicits)\n}\n\n/// Query implementation of [crate::db::LoweringGroup::function_all_implicits].\npub fn function_all_implicits(\n    db: &dyn LoweringGroup,\n    function: semantic::FunctionId,\n) -> Maybe<Vec<TypeId>> {\n    let concrete_function = function.get_concrete(db.upcast());\n    match concrete_function.generic_function {\n        GenericFunctionId::Free(free_function) => {\n            let concrete_with_body =\n                db.intern_concrete_function_with_body(ConcreteFunctionWithBody {\n                    generic_function: GenericFunctionWithBodyId::Free(free_function),\n                    generic_args: concrete_function.generic_args,\n                });\n            db.concrete_function_with_body_all_implicits_vec(concrete_with_body)\n        }\n        GenericFunctionId::Impl(impl_generic_function) => {\n            let Some(generic_with_body) =\n                impl_generic_function.to_generic_with_body(db.upcast())?\n                else {\n                    unreachable!();\n                };\n            let concrete_with_body =\n                db.intern_concrete_function_with_body(ConcreteFunctionWithBody {\n                    generic_function: generic_with_body,\n                    generic_args: concrete_function.generic_args,\n                });\n            db.concrete_function_with_body_all_implicits_vec(concrete_with_body)\n        }\n        GenericFunctionId::Extern(extern_function) => {\n            db.extern_function_declaration_implicits(extern_function)\n        }\n    }\n}\n\n/// Query implementation of [crate::db::LoweringGroup::concrete_function_with_body_all_implicits].\npub fn concrete_function_with_body_all_implicits(\n    db: &dyn LoweringGroup,\n    function: ConcreteFunctionWithBodyId,\n) -> Maybe<HashSet<TypeId>> {\n    // Find the SCC representative.\n    let scc_representative = db.concrete_function_with_body_scc_postpanic_representative(function);\n\n    // Start with the explicit implicits of the SCC.\n    let mut all_implicits = db.function_scc_explicit_implicits(scc_representative.clone())?;\n\n    let direct_callees = db.concrete_function_with_body_postpanic_direct_callees(function)?;\n    // For each direct callee, add its implicits.\n    for direct_callee in direct_callees {\n        let generic_function = direct_callee.generic_function;\n        let current_implicits = match generic_function {\n            GenericFunctionId::Free(free_function) => {\n                // For a free function, call this method recursively. To avoid cycles, first\n                // check that the callee is not in this function's SCC.\n                let concrete_with_body =\n                    db.intern_concrete_function_with_body(ConcreteFunctionWithBody {\n                        generic_function: GenericFunctionWithBodyId::Free(free_function),\n                        generic_args: direct_callee.generic_args,\n                    });\n                let direct_callee_representative =\n                    db.concrete_function_with_body_scc_postpanic_representative(concrete_with_body);\n                if direct_callee_representative == scc_representative {\n                    // We already have the implicits of this SCC - do nothing.\n                    continue;\n                }\n                db.concrete_function_with_body_all_implicits(direct_callee_representative.0)?\n            }\n            GenericFunctionId::Impl(impl_generic_function) => {\n                let Some(generic_with_body) =\n                    impl_generic_function.to_generic_with_body(db.upcast())?\n                    else {\n                        unreachable!();\n                    };\n                // For an impl function, call this method recursively. To avoid cycles, first\n                // check that the callee is not in this function's SCC.\n                let concrete_with_body =\n                    db.intern_concrete_function_with_body(ConcreteFunctionWithBody {\n                        generic_function: generic_with_body,\n                        generic_args: direct_callee.generic_args,\n                    });\n                let direct_callee_representative =\n                    db.concrete_function_with_body_scc_postpanic_representative(concrete_with_body);\n                if direct_callee_representative == scc_representative {\n                    // We already have the implicits of this SCC - do nothing.\n                    continue;\n                }\n                db.concrete_function_with_body_all_implicits(direct_callee_representative.0)?\n            }\n            GenericFunctionId::Extern(extern_function) => {\n                // All implicits of a libfunc are explicit implicits.\n                db.extern_function_declaration_implicits(extern_function)?.into_iter().collect()\n            }\n        };\n        all_implicits.extend(&current_implicits);\n    }\n    Ok(all_implicits)\n}\n\n/// Query implementation of\n/// [crate::db::LoweringGroup::concrete_function_with_body_all_implicits_vec].\npub fn concrete_function_with_body_all_implicits_vec(\n    db: &dyn LoweringGroup,\n    function: ConcreteFunctionWithBodyId,\n) -> Maybe<Vec<TypeId>> {\n    let implicits_set = db.concrete_function_with_body_all_implicits(function)?;\n    let mut implicits_vec = implicits_set.into_iter().collect_vec();\n\n    let semantic_db = db.upcast();\n    let precedence = db.implicit_precedence();\n    implicits_vec.sort_by_cached_key(|type_id| {\n        if let Some(idx) = precedence.iter().position(|item| item == type_id) {\n            return (idx, \"\".to_string());\n        }\n\n        (precedence.len(), type_id.format(semantic_db))\n    });\n\n    Ok(implicits_vec)\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "#[cfg(test)]\nmod test;\n\nuse std::collections::{HashMap, VecDeque};\nuse std::sync::Arc;\n\nuse cairo_lang_defs::ids::{FunctionWithBodyId, LanguageElementId};\nuse cairo_lang_diagnostics::{Diagnostics, Maybe};\nuse cairo_lang_semantic::items::functions::InlineConfiguration;\nuse cairo_lang_semantic::ConcreteFunctionWithBodyId;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse itertools::{izip, Itertools};\n\nuse crate::blocks::{FlatBlocks, FlatBlocksBuilder};\nuse crate::db::LoweringGroup;\nuse crate::diagnostic::{LoweringDiagnostic, LoweringDiagnosticKind, LoweringDiagnostics};\nuse crate::lower::context::{LoweringContext, LoweringContextBuilder, VarRequest};\nuse crate::utils::{Rebuilder, RebuilderEx};\nuse crate::{BlockId, FlatBlock, FlatBlockEnd, FlatLowered, Statement, VarRemapping, VariableId};\n\n/// data about inlining.\n#[derive(Debug, PartialEq, Eq)]\npub struct PrivInlineData {\n    /// Diagnostics produced while collecting inlining Info.\n    pub diagnostics: Diagnostics<LoweringDiagnostic>,\n    pub config: InlineConfiguration,\n    pub info: InlineInfo,\n}\n\n/// Per function information for the inlining phase.\n#[derive(Debug, PartialEq, Eq)]\npub struct InlineInfo {\n    /// Indicates that the function can be inlined.\n    pub is_inlinable: bool,\n    /// Indicates that the function should be inlined.\n    pub should_inline: bool,\n}\n\npub fn priv_inline_data(\n    db: &dyn LoweringGroup,\n    function_id: FunctionWithBodyId,\n) -> Maybe<Arc<PrivInlineData>> {\n    let mut diagnostics = LoweringDiagnostics::new(function_id.module_file_id(db.upcast()));\n    let config = db.function_declaration_inline_config(function_id)?;\n\n    let info = if matches!(config, InlineConfiguration::Never(_)) {\n        InlineInfo { is_inlinable: false, should_inline: false }\n    } else {\n        // If the the function is marked as #[inline(always)], we need to report inlining problems.\n        let report_diagnostics = matches!(config, InlineConfiguration::Always(_));\n        gather_inlining_info(db, &mut diagnostics, report_diagnostics, function_id)?\n    };\n\n    Ok(Arc::new(PrivInlineData { diagnostics: diagnostics.build(), config, info }))\n}\n\n/// Gathers inlining information for the given function.\n/// If report_diagnostics is true, adds a diagnostics with the reason that prevents inlining.\nfn gather_inlining_info(\n    db: &dyn LoweringGroup,\n    diagnostics: &mut LoweringDiagnostics,\n    report_diagnostics: bool,\n    function_id: FunctionWithBodyId,\n) -> Maybe<InlineInfo> {\n    let defs_db = db.upcast();\n    // TODO(ilya): Relax requirement, if one of the functions does not have `#[inline(always)]` then\n    // we can inline it.\n    if db.in_cycle(function_id)? {\n        if report_diagnostics {\n            diagnostics.report(\n                function_id.untyped_stable_ptr(defs_db),\n                LoweringDiagnosticKind::CannotInlineFunctionThatMightCallItself,\n            );\n        }\n        return Ok(InlineInfo { is_inlinable: false, should_inline: false });\n    }\n\n    let lowered = db.priv_function_with_body_lowered_flat(function_id)?;\n\n    Ok(InlineInfo { is_inlinable: true, should_inline: should_inline(db, &lowered)? })\n}\n\n// A heuristic to decide if a function should be inlined.\nfn should_inline(_db: &dyn LoweringGroup, lowered: &FlatLowered) -> Maybe<bool> {\n    let root_block = lowered.blocks.root_block()?;\n\n    Ok(match &root_block.end {\n        FlatBlockEnd::Return(_) => {\n            // Inline a function that only calls another function or returns a literal.\n            matches!(root_block.statements.as_slice(), [Statement::Call(_) | Statement::Literal(_)])\n        }\n        FlatBlockEnd::Goto(..) | FlatBlockEnd::Match { .. } | FlatBlockEnd::Panic(_) => false,\n        FlatBlockEnd::NotSet => {\n            panic!(\"Unexpected block end.\");\n        }\n    })\n}\n\n// TODO(ilya): Add Rewriter trait.\n\n/// A rewriter that inlines functions annotated with #[inline(always)].\npub struct FunctionInlinerRewriter<'db> {\n    /// The LoweringContext were we are building the new blocks.\n    ctx: LoweringContext<'db>,\n    /// A Queue of blocks on which we want to apply the FunctionInlinerRewriter.\n    block_queue: BlockQueue,\n    /// rewritten statements.\n    statements: Vec<Statement>,\n\n    /// The end of the current block.\n    block_end: FlatBlockEnd,\n    /// stack for statements that require rewriting.\n    statement_rewrite_stack: StatementStack,\n    /// Indicates that the inlining process was successful.\n    inlining_success: Maybe<()>,\n}\n\n#[derive(Default)]\npub struct StatementStack {\n    stack: Vec<Statement>,\n}\n\nimpl StatementStack {\n    /// Pushes multiple statement into the stack.\n    ///\n    /// Note that to keep the order of the statements when they are popped from the stack\n    /// they need to be pushed in reverse order.\n    fn push_statements(&mut self, statements: impl DoubleEndedIterator<Item = Statement>) {\n        self.stack.extend(statements.rev());\n    }\n\n    // Consumes all the statements in the stack.\n    fn consume(&mut self) -> Vec<Statement> {\n        self.stack.drain(..).rev().collect_vec()\n    }\n\n    fn pop_statement(&mut self) -> Option<Statement> {\n        self.stack.pop()\n    }\n}\n\npub struct BlockQueue {\n    /// A Queue of blocks that require processing.\n    block_queue: VecDeque<FlatBlock>,\n    /// The new blocks that were created during the inlining.\n    flat_blocks: FlatBlocksBuilder,\n}\nimpl BlockQueue {\n    /// Enqueues the block for processing and returns the block_id that this\n    /// block is going to get in self.flat_blocks.\n    fn enqueue_block(&mut self, block: FlatBlock) -> BlockId {\n        self.block_queue.push_back(block);\n        BlockId(self.flat_blocks.len() + self.block_queue.len())\n    }\n    // Pops a block from the queue.\n    fn dequeue(&mut self) -> Option<FlatBlock> {\n        self.block_queue.pop_front()\n    }\n    /// Finalizes a block.\n    fn finalize(&mut self, block: FlatBlock) -> BlockId {\n        self.flat_blocks.alloc(block)\n    }\n}\nimpl Default for BlockQueue {\n    fn default() -> Self {\n        Self { block_queue: Default::default(), flat_blocks: FlatBlocksBuilder::new() }\n    }\n}\n\n/// Context for mapping ids from `lowered` to a new `FlatLowered` object.\npub struct Mapper<'a, 'b> {\n    ctx: &'a mut LoweringContext<'b>,\n    lowered: &'a FlatLowered,\n    renamed_vars: HashMap<VariableId, VariableId>,\n    return_block_id: BlockId,\n    outputs: &'a [id_arena::Id<crate::Variable>],\n\n    /// An offset that is added to all the block IDs in order to translate them into the new\n    /// lowering representation.\n    block_id_offset: BlockId,\n}\n\nimpl<'a, 'b> Rebuilder for Mapper<'a, 'b> {\n    /// Maps a var id from the original lowering representation to the equivalent id in the\n    /// new lowering representation.\n    /// If the variable wasn't assigned an id yet, a new id is assigned.\n    fn map_var_id(&mut self, orig_var_id: VariableId) -> VariableId {\n        *self.renamed_vars.entry(orig_var_id).or_insert_with(|| {\n            self.ctx.new_var(VarRequest {\n                ty: self.lowered.variables[orig_var_id].ty,\n                location: self.lowered.variables[orig_var_id].location,\n            })\n        })\n    }\n\n    /// Maps a block id from the original lowering representation to the equivalent id in the\n    /// new lowering representation.\n    fn map_block_id(&mut self, orig_block_id: BlockId) -> BlockId {\n        BlockId(self.block_id_offset.0 + orig_block_id.0)\n    }\n\n    fn transform_end(&mut self, end: &mut FlatBlockEnd) {\n        match end {\n            FlatBlockEnd::Return(returns) => {\n                let remapping = VarRemapping {\n                    remapping: OrderedHashMap::from_iter(izip!(\n                        self.outputs.iter().cloned(),\n                        returns.iter().copied()\n                    )),\n                };\n                *end = FlatBlockEnd::Goto(self.return_block_id, remapping);\n            }\n            FlatBlockEnd::Panic(_) | FlatBlockEnd::Goto(_, _) | FlatBlockEnd::Match { .. } => {}\n            FlatBlockEnd::NotSet => unreachable!(),\n        }\n    }\n}\n\nimpl<'db> FunctionInlinerRewriter<'db> {\n    fn apply(ctx: LoweringContext<'db>, flat_lower: &FlatLowered) -> Maybe<FlatLowered> {\n        let mut rewriter = Self {\n            ctx,\n            block_queue: BlockQueue {\n                block_queue: VecDeque::from(flat_lower.blocks.get().clone()),\n                flat_blocks: FlatBlocksBuilder::new(),\n            },\n            statements: vec![],\n            block_end: FlatBlockEnd::NotSet,\n            statement_rewrite_stack: StatementStack::default(),\n            inlining_success: flat_lower.blocks.has_root(),\n        };\n\n        rewriter.ctx.variables = flat_lower.variables.clone();\n        while let Some(block) = rewriter.block_queue.dequeue() {\n            rewriter.block_end = block.end;\n            rewriter.statement_rewrite_stack.push_statements(block.statements.into_iter());\n\n            while let Some(statement) = rewriter.statement_rewrite_stack.pop_statement() {\n                rewriter.rewrite(statement)?;\n            }\n\n            rewriter.block_queue.finalize(FlatBlock {\n                statements: std::mem::take(&mut rewriter.statements),\n                end: rewriter.block_end,\n            });\n        }\n\n        let blocks = rewriter\n            .inlining_success\n            .map(|()| rewriter.block_queue.flat_blocks.build().unwrap())\n            .unwrap_or_else(FlatBlocks::new_errored);\n\n        assert!(rewriter.ctx.diagnostics.build().is_empty());\n        Ok(FlatLowered {\n            diagnostics: flat_lower.diagnostics.clone(),\n            variables: rewriter.ctx.variables,\n            blocks,\n            parameters: flat_lower.parameters.clone(),\n        })\n    }\n\n    /// Rewrites a statement and either appends it to self.statements or adds new statements to\n    /// self.statements_rewrite_stack.\n    fn rewrite(&mut self, statement: Statement) -> Maybe<()> {\n        if let Statement::Call(ref stmt) = statement {\n            let concrete_function = self.ctx.db.lookup_intern_function(stmt.function).function;\n            let semantic_db = self.ctx.db.upcast();\n            if let Some(function_id) = concrete_function.get_body(semantic_db)? {\n                let inline_data =\n                    self.ctx.db.priv_inline_data(function_id.function_with_body_id(semantic_db))?;\n\n                self.inlining_success = self\n                    .inlining_success\n                    .and_then(|()| inline_data.diagnostics.is_diagnostic_free());\n\n                if inline_data.info.is_inlinable\n                    && (inline_data.info.should_inline\n                        || matches!(inline_data.config, InlineConfiguration::Always(_)))\n                {\n                    return self.inline_function(function_id, &stmt.inputs, &stmt.outputs);\n                }\n            }\n        }\n\n        self.statements.push(statement);\n        Ok(())\n    }\n\n    /// Inlines the given function, with the given input and output variables.\n    /// The statements that need to replace the call statement in the original block\n    /// are pushed into the `statement_rewrite_stack`.\n    /// May also push additional blocks to the block queue.\n    /// The function takes an optional return block id to handle early returns.\n    pub fn inline_function(\n        &mut self,\n        function_id: ConcreteFunctionWithBodyId,\n        inputs: &[VariableId],\n        outputs: &[VariableId],\n    ) -> Maybe<()> {\n        let lowered = self.ctx.db.priv_concrete_function_with_body_lowered_flat(function_id)?;\n\n        lowered.blocks.has_root()?;\n\n        // Create a new block with all the statements that follow the call statement.\n        let return_block_id = self.block_queue.enqueue_block(FlatBlock {\n            statements: self.statement_rewrite_stack.consume(),\n            end: self.block_end.clone(),\n        });\n\n        // As the block_ids and variable_ids are per function, we need to rename all\n        // the blocks and variables before we enqueue the blocks from the function that\n        // we are inlining.\n\n        // The input variables need to be renamed to match the inputs to the function call.\n        let renamed_vars = HashMap::<VariableId, VariableId>::from_iter(izip!(\n            lowered.parameters.iter().cloned(),\n            inputs.iter().cloned()\n        ));\n\n        let mut mapper = Mapper {\n            ctx: &mut self.ctx,\n            lowered: &lowered,\n            renamed_vars,\n            block_id_offset: BlockId(return_block_id.0 + 1),\n            return_block_id,\n            outputs,\n        };\n\n        // The current block should Goto to the root block of the inlined function.\n        // Note that we can't remap the inputs as they might be used after we return\n        // from the inlined function.\n        // TODO(ilya): Try to use var remapping instead of renaming for the inputs to\n        // keep track of the correct Variable.location.\n        self.block_end =\n            FlatBlockEnd::Goto(mapper.map_block_id(BlockId::root()), VarRemapping::default());\n\n        for (block_id, block) in lowered.blocks.iter() {\n            let block = mapper.rebuild_block(block);\n\n            assert_eq!(\n                mapper.map_block_id(block_id),\n                self.block_queue.enqueue_block(block),\n                \"Unexpected block_id.\"\n            );\n        }\n\n        Ok(())\n    }\n}\n\npub fn apply_inlining(\n    db: &dyn LoweringGroup,\n    function_id: FunctionWithBodyId,\n    flat_lowered: &mut FlatLowered,\n) -> Maybe<()> {\n    let lowering_builder = LoweringContextBuilder::new(db, function_id)?;\n    if let Ok(new_flat_lowered) =\n        FunctionInlinerRewriter::apply(lowering_builder.ctx()?, flat_lowered)\n    {\n        *flat_lowered = new_flat_lowered;\n    }\n    Ok(())\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::ops::Deref;\n\nuse cairo_lang_debug::DebugWithDb;\nuse cairo_lang_plugins::get_default_plugins;\nuse cairo_lang_semantic::db::SemanticGroup;\nuse cairo_lang_semantic::test_utils::setup_test_function;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\n\nuse crate::db::LoweringGroup;\nuse crate::fmt::LoweredFormatter;\nuse crate::inline::apply_inlining;\nuse crate::test_utils::LoweringDatabaseForTesting;\n\ncairo_lang_test_utils::test_file_test!(\n    inlining,\n    \"src/inline/test_data\",\n    {\n\n        inline :\"inline\",\n        inline_diagnostics :\"inline_diagnostics\",\n    },\n    test_function_inlining\n);\n\nfn test_function_inlining(\n    inputs: &OrderedHashMap<String, String>,\n) -> OrderedHashMap<String, String> {\n    let db = &mut LoweringDatabaseForTesting::default();\n    db.set_semantic_plugins(get_default_plugins());\n    let (test_function, semantic_diagnostics) = setup_test_function(\n        db,\n        inputs[\"function\"].as_str(),\n        inputs[\"function_name\"].as_str(),\n        inputs[\"module_code\"].as_str(),\n    )\n    .split();\n    let before = db\n        .priv_concrete_function_with_body_lowered_flat(test_function.concrete_function_id)\n        .unwrap();\n\n    let lowering_diagnostics = db.module_lowering_diagnostics(test_function.module_id).unwrap();\n\n    let mut after = before.deref().clone();\n    apply_inlining(db, test_function.function_id, &mut after).unwrap();\n\n    OrderedHashMap::from([\n        (\"semantic_diagnostics\".into(), semantic_diagnostics),\n        (\n            \"before\".into(),\n            format!(\"{:?}\", before.debug(&LoweredFormatter { db, variables: &before.variables })),\n        ),\n        (\n            \"after\".into(),\n            format!(\"{:?}\", after.debug(&LoweredFormatter { db, variables: &after.variables })),\n        ),\n        (\"lowering_diagnostics\".into(), lowering_diagnostics.format(db)),\n    ])\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Cairo lowering.\n//!\n//! This crate is responsible for handling the lowering phase.\npub mod borrow_check;\npub mod concretize;\npub mod db;\npub mod destructs;\npub mod diagnostic;\npub mod fmt;\npub mod graph_algorithms;\npub mod implicits;\npub mod inline;\npub mod lower;\npub mod objects;\npub mod optimizations;\npub mod panic;\npub mod scc;\npub mod topological_sort;\npub mod utils;\n\n#[cfg(test)]\nmod test;\n\npub use self::objects::*;\n\n#[cfg(any(feature = \"testing\", test))]\npub mod test_utils;\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse cairo_lang_defs::diagnostic_utils::StableLocationOption;\nuse cairo_lang_defs::ids::{FunctionWithBodyId, LanguageElementId};\nuse cairo_lang_diagnostics::{DiagnosticAdded, Maybe};\nuse cairo_lang_semantic as semantic;\nuse cairo_lang_semantic::expr::fmt::ExprFormatter;\nuse cairo_lang_semantic::items::enm::SemanticEnumEx;\nuse cairo_lang_semantic::items::imp::ImplLookupContext;\nuse cairo_lang_semantic::{Mutability, VarId};\nuse cairo_lang_syntax::node::ids::SyntaxStablePtrId;\nuse cairo_lang_utils::unordered_hash_map::UnorderedHashMap;\nuse id_arena::Arena;\nuse itertools::{zip_eq, Itertools};\nuse semantic::expr::inference::InferenceError;\nuse semantic::types::wrap_in_snapshots;\nuse semantic::ConcreteFunctionWithBodyId;\n\nuse super::generators;\nuse super::scope::{BlockBuilder, SealedBlockBuilder};\nuse crate::blocks::FlatBlocksBuilder;\nuse crate::db::LoweringGroup;\nuse crate::diagnostic::LoweringDiagnostics;\nuse crate::lower::external::{extern_facade_expr, extern_facade_return_tys};\nuse crate::objects::Variable;\nuse crate::{MatchArm, MatchExternInfo, MatchInfo, VariableId};\n\n/// Builds a Lowering context.\npub struct LoweringContextBuilder<'db> {\n    pub db: &'db dyn LoweringGroup,\n    pub function_id: FunctionWithBodyId,\n    pub function_body: Arc<semantic::items::function_with_body::FunctionBody>,\n    /// Semantic signature for current function.\n    pub signature: semantic::Signature,\n    /// The `ref` parameters of the current function.\n    pub ref_params: Vec<semantic::VarId>,\n}\nimpl<'db> LoweringContextBuilder<'db> {\n    /// Constructs a new LoweringContextBuilder with the generic signature of the given generic\n    /// function.\n    pub fn new(db: &'db dyn LoweringGroup, function_id: FunctionWithBodyId) -> Maybe<Self> {\n        let signature = db.function_with_body_signature(function_id)?;\n        Self::new_inner(db, function_id, signature)\n    }\n    /// Constructs a new LoweringContextBuilder with a concrete signature of the given concrete\n    /// function.\n    pub fn new_concrete(\n        db: &'db dyn LoweringGroup,\n        concrete_function_with_body_id: ConcreteFunctionWithBodyId,\n    ) -> Maybe<Self> {\n        let function_id = concrete_function_with_body_id.function_with_body_id(db.upcast());\n\n        let signature = db.concrete_function_signature(\n            concrete_function_with_body_id.function_id(db.upcast())?,\n        )?;\n        Self::new_inner(db, function_id, signature)\n    }\n    fn new_inner(\n        db: &'db dyn LoweringGroup,\n        function_id: FunctionWithBodyId,\n        signature: semantic::Signature,\n    ) -> Maybe<Self> {\n        let ref_params = signature\n            .params\n            .iter()\n            .filter(|param| param.mutability == Mutability::Reference)\n            .map(|param| VarId::Param(param.id))\n            .collect();\n        Ok(LoweringContextBuilder {\n            db,\n            function_id,\n            function_body: db.function_body(function_id)?,\n            signature,\n            ref_params,\n        })\n    }\n    pub fn ctx<'a: 'db>(&'a self) -> Maybe<LoweringContext<'db>> {\n        let generic_params = self.db.function_with_body_generic_params(self.function_id)?;\n        Ok(LoweringContext {\n            db: self.db,\n            function_id: self.function_id,\n            function_body: &self.function_body,\n            signature: &self.signature,\n            diagnostics: LoweringDiagnostics::new(\n                self.function_id.module_file_id(self.db.upcast()),\n            ),\n            variables: Arena::default(),\n            blocks: FlatBlocksBuilder::new(),\n            semantic_defs: UnorderedHashMap::default(),\n            ref_params: &self.ref_params,\n            lookup_context: ImplLookupContext {\n                module_id: self.function_id.parent_module(self.db.upcast()),\n                extra_modules: vec![],\n                generic_params,\n            },\n            expr_formatter: ExprFormatter { db: self.db.upcast(), function_id: self.function_id },\n        })\n    }\n}\n\n/// Context for the lowering phase of a free function.\npub struct LoweringContext<'db> {\n    pub db: &'db dyn LoweringGroup,\n    /// Id for the current function being lowered.\n    pub function_id: FunctionWithBodyId,\n    /// Semantic model for current function body.\n    pub function_body: &'db semantic::FunctionBody,\n    /// Semantic signature for current function.\n    pub signature: &'db semantic::Signature,\n    /// Current emitted diagnostics.\n    pub diagnostics: LoweringDiagnostics,\n    /// Arena of allocated lowered variables.\n    pub variables: Arena<Variable>,\n    /// Lowered blocks of the function.\n    pub blocks: FlatBlocksBuilder,\n    /// Definitions encountered for semantic variables.\n    // TODO(spapini): consider moving to semantic model.\n    pub semantic_defs: UnorderedHashMap<semantic::VarId, semantic::Variable>,\n    /// The `ref` parameters of the current function.\n    pub ref_params: &'db [semantic::VarId],\n    // Lookup context for impls.\n    pub lookup_context: ImplLookupContext,\n    // Expression formatter of the free function.\n    pub expr_formatter: ExprFormatter<'db>,\n}\nimpl<'db> LoweringContext<'db> {\n    pub fn new_var(&mut self, req: VarRequest) -> VariableId {\n        let ty_info = self.db.type_info(self.lookup_context.clone(), req.ty);\n        self.variables.alloc(Variable {\n            duplicatable: ty_info\n                .clone()\n                .map_err(InferenceError::Failed)\n                .and_then(|info| info.duplicatable),\n            droppable: ty_info\n                .clone()\n                .map_err(InferenceError::Failed)\n                .and_then(|info| info.droppable),\n            destruct_impl: ty_info\n                .map_err(InferenceError::Failed)\n                .and_then(|info| info.destruct_impl),\n            ty: req.ty,\n            location: req.location,\n        })\n    }\n\n    /// Retrieves the StableLocation of a stable syntax pointer in the current function file.\n    pub fn get_location(&self, stable_ptr: SyntaxStablePtrId) -> StableLocationOption {\n        StableLocationOption::new(self.function_id.module_file_id(self.db.upcast()), stable_ptr)\n    }\n}\n\n/// Request for a lowered variable allocation.\npub struct VarRequest {\n    pub ty: semantic::TypeId,\n    pub location: StableLocationOption,\n}\n\n/// Representation of the value of a computed expression.\n#[derive(Clone, Debug)]\npub enum LoweredExpr {\n    /// The expression value lies in a variable.\n    AtVariable(VariableId),\n    /// The expression value is a tuple.\n    Tuple {\n        exprs: Vec<LoweredExpr>,\n        location: StableLocationOption,\n    },\n    /// The expression value is an enum result from an extern call.\n    ExternEnum(LoweredExprExternEnum),\n    SemanticVar(semantic::VarId, StableLocationOption),\n    Snapshot {\n        expr: Box<LoweredExpr>,\n        location: StableLocationOption,\n    },\n}\nimpl LoweredExpr {\n    pub fn var(\n        self,\n        ctx: &mut LoweringContext<'_>,\n        scope: &mut BlockBuilder,\n    ) -> Result<VariableId, LoweringFlowError> {\n        match self {\n            LoweredExpr::AtVariable(var_id) => Ok(var_id),\n            LoweredExpr::Tuple { exprs, location } => {\n                let inputs: Vec<_> = exprs\n                    .into_iter()\n                    .map(|expr| expr.var(ctx, scope))\n                    .collect::<Result<Vec<_>, _>>()?;\n                let tys = inputs.iter().map(|var| ctx.variables[*var].ty).collect();\n                let ty = ctx.db.intern_type(semantic::TypeLongId::Tuple(tys));\n                Ok(generators::StructConstruct { inputs, ty, location }\n                    .add(ctx, &mut scope.statements))\n            }\n            LoweredExpr::ExternEnum(extern_enum) => extern_enum.var(ctx, scope),\n            LoweredExpr::SemanticVar(semantic_var_id, location) => {\n                Ok(scope.get_semantic(ctx, semantic_var_id, location))\n            }\n            LoweredExpr::Snapshot { expr, location } => {\n                let (original, snapshot) =\n                    generators::Snapshot { input: expr.clone().var(ctx, scope)?, location }\n                        .add(ctx, &mut scope.statements);\n                if let LoweredExpr::SemanticVar(semantic_var_id, _location) = &*expr {\n                    scope.put_semantic(*semantic_var_id, original);\n                }\n\n                Ok(snapshot)\n            }\n        }\n    }\n    pub fn ty(&self, ctx: &mut LoweringContext<'_>) -> semantic::TypeId {\n        match self {\n            LoweredExpr::AtVariable(var) => ctx.variables[*var].ty,\n            LoweredExpr::Tuple { exprs, .. } => ctx.db.intern_type(semantic::TypeLongId::Tuple(\n                exprs.iter().map(|expr| expr.ty(ctx)).collect(),\n            )),\n            LoweredExpr::ExternEnum(extern_enum) => {\n                ctx.db.intern_type(semantic::TypeLongId::Concrete(semantic::ConcreteTypeId::Enum(\n                    extern_enum.concrete_enum_id,\n                )))\n            }\n            LoweredExpr::SemanticVar(semantic_var_id, _) => {\n                ctx.semantic_defs[*semantic_var_id].ty()\n            }\n            LoweredExpr::Snapshot { expr, .. } => {\n                wrap_in_snapshots(ctx.db.upcast(), expr.ty(ctx), 1)\n            }\n        }\n    }\n}\n\n/// Lazy expression value of an extern call returning an enum.\n#[derive(Clone, Debug)]\npub struct LoweredExprExternEnum {\n    pub function: semantic::FunctionId,\n    pub concrete_enum_id: semantic::ConcreteEnumId,\n    pub inputs: Vec<VariableId>,\n    pub member_paths: Vec<semantic::VarMemberPath>,\n    pub location: StableLocationOption,\n}\nimpl LoweredExprExternEnum {\n    pub fn var(\n        self,\n        ctx: &mut LoweringContext<'_>,\n        scope: &mut BlockBuilder,\n    ) -> LoweringResult<VariableId> {\n        let concrete_variants = ctx\n            .db\n            .concrete_enum_variants(self.concrete_enum_id)\n            .map_err(LoweringFlowError::Failed)?;\n\n        let mut arm_var_ids = vec![];\n        let (sealed_blocks, block_ids): (Vec<_>, Vec<_>) = concrete_variants\n            .clone()\n            .into_iter()\n            .map(|concrete_variant| {\n                let mut subscope = scope.subscope(ctx.blocks.alloc_empty());\n                let block_id = subscope.block_id;\n\n                let mut var_ids = vec![];\n                // Bind the ref parameters.\n                for member_path in &self.member_paths {\n                    let var =\n                        ctx.new_var(VarRequest { ty: member_path.ty(), location: self.location });\n                    var_ids.push(var);\n\n                    subscope.update_ref(ctx, member_path, var);\n                }\n\n                let variant_vars = extern_facade_return_tys(ctx, concrete_variant.ty)\n                    .into_iter()\n                    .map(|ty| ctx.new_var(VarRequest { ty, location: self.location }))\n                    .collect_vec();\n                var_ids.extend(variant_vars.iter());\n\n                arm_var_ids.push(var_ids);\n                let maybe_input =\n                    extern_facade_expr(ctx, concrete_variant.ty, variant_vars, self.location)\n                        .var(ctx, &mut subscope);\n                let input = match maybe_input {\n                    Ok(var) => var,\n                    Err(err) => {\n                        return lowering_flow_error_to_sealed_block(ctx, subscope, err)\n                            .map(|sb| (sb, block_id));\n                    }\n                };\n                let result = generators::EnumConstruct {\n                    input,\n                    variant: concrete_variant,\n                    location: self.location,\n                }\n                .add(ctx, &mut subscope.statements);\n                Ok((subscope.goto_callsite(Some(result)), block_id))\n            })\n            .collect::<Result<Vec<_>, _>>()\n            .map_err(LoweringFlowError::Failed)?\n            .into_iter()\n            .unzip();\n\n        let match_info = MatchInfo::Extern(MatchExternInfo {\n            function: self.function,\n            inputs: self.inputs,\n            arms: zip_eq(zip_eq(concrete_variants, block_ids), arm_var_ids)\n                .map(|((variant_id, block_id), var_ids)| MatchArm { variant_id, block_id, var_ids })\n                .collect(),\n            location: self.location,\n        });\n        scope\n            .merge_and_end_with_match(ctx, match_info, sealed_blocks, self.location)?\n            .var(ctx, scope)\n    }\n}\n\npub type LoweringResult<T> = Result<T, LoweringFlowError>;\n\n/// Cases where the flow of lowering an expression should halt.\n#[derive(Debug)]\npub enum LoweringFlowError {\n    /// Computation failure. A corresponding diagnostic should be emitted.\n    Failed(DiagnosticAdded),\n    Panic(VariableId),\n    Return(VariableId, StableLocationOption),\n    Match(MatchInfo),\n}\nimpl LoweringFlowError {\n    pub fn is_unreachable(&self) -> bool {\n        match self {\n            LoweringFlowError::Failed(_) => false,\n            LoweringFlowError::Panic(_)\n            | LoweringFlowError::Return(_, _)\n            | LoweringFlowError::Match(_) => true,\n        }\n    }\n}\n\n/// Converts a lowering flow error to the appropriate block scope end, if possible.\npub fn lowering_flow_error_to_sealed_block(\n    ctx: &mut LoweringContext<'_>,\n    scope: BlockBuilder,\n    err: LoweringFlowError,\n) -> Maybe<SealedBlockBuilder> {\n    let block_id = scope.block_id;\n    match err {\n        LoweringFlowError::Failed(diag_added) => return Err(diag_added),\n        LoweringFlowError::Return(return_var, location) => {\n            scope.ret(ctx, return_var, location)?;\n        }\n        LoweringFlowError::Panic(data_var) => {\n            scope.panic(ctx, data_var)?;\n        }\n        LoweringFlowError::Match(info) => {\n            scope.unreachable_match(ctx, info);\n        }\n    }\n    Ok(SealedBlockBuilder::Ends(block_id))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_defs::diagnostic_utils::StableLocationOption;\nuse cairo_lang_semantic as semantic;\n\nuse super::context::LoweringContext;\nuse super::LoweredExpr;\nuse crate::VariableId;\n\n/// Given a return type of an external function, gets the real output variable types for that call.\n/// For example, an external function that returns a tuple, has an output variable for each tuple\n/// entry.\npub fn extern_facade_return_tys(\n    ctx: &mut LoweringContext<'_>,\n    ret_ty: semantic::TypeId,\n) -> Vec<semantic::TypeId> {\n    if let semantic::TypeLongId::Tuple(tys) = ctx.db.lookup_intern_type(ret_ty) {\n        tys\n    } else {\n        vec![ret_ty]\n    }\n}\n\n/// Given the returned output variables from an external function call, creates a LoweredExpr\n/// representing the return expression of the type that was declared in the signature.\n/// For example, for an external function that returns a tuple, even though it will have an output\n/// variable for each entry, the return expression is a single value of type tuple.\npub fn extern_facade_expr(\n    ctx: &mut LoweringContext<'_>,\n    ty: semantic::TypeId,\n    returns: Vec<VariableId>,\n    location: StableLocationOption,\n) -> LoweredExpr {\n    if let semantic::TypeLongId::Tuple(subtypes) = ctx.db.lookup_intern_type(ty) {\n        assert_eq!(returns.len(), subtypes.len());\n        LoweredExpr::Tuple {\n            exprs: returns.into_iter().map(LoweredExpr::AtVariable).collect(),\n            location,\n        }\n    } else {\n        assert_eq!(returns.len(), 1);\n        LoweredExpr::AtVariable(returns.into_iter().next().unwrap())\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Statement generators. Add statements to BlockBuilder while respecting variable liveness and\n//! ownership of OwnedVariable.\n\nuse cairo_lang_defs::diagnostic_utils::StableLocationOption;\nuse cairo_lang_semantic as semantic;\nuse cairo_lang_semantic::ConcreteVariant;\nuse cairo_lang_utils::extract_matches;\nuse itertools::chain;\nuse num_bigint::BigInt;\n\nuse super::context::VarRequest;\nuse super::VariableId;\nuse crate::lower::context::LoweringContext;\nuse crate::objects::{\n    Statement, StatementCall, StatementLiteral, StatementStructConstruct,\n    StatementStructDestructure,\n};\nuse crate::{StatementDesnap, StatementEnumConstruct, StatementSnapshot};\n\n#[derive(Clone, Default)]\npub struct StatementsBuilder {\n    pub statements: Vec<Statement>,\n}\nimpl StatementsBuilder {\n    /// Adds a statement to the block.\n    pub fn push_statement(&mut self, statement: Statement) {\n        self.statements.push(statement);\n    }\n}\n\n/// Generator for [StatementLiteral].\npub struct Literal {\n    pub value: BigInt,\n    pub location: StableLocationOption,\n    pub ty: semantic::TypeId,\n}\nimpl Literal {\n    pub fn add(self, ctx: &mut LoweringContext<'_>, scope: &mut StatementsBuilder) -> VariableId {\n        let output = ctx.new_var(VarRequest { ty: self.ty, location: self.location });\n        scope.push_statement(Statement::Literal(StatementLiteral { value: self.value, output }));\n        output\n    }\n}\n\n/// Generator for [StatementCall].\n/// Note that scope.finalize_statement() must be called manually after ref bindings.\npub struct Call {\n    /// Called function.\n    pub function: semantic::FunctionId,\n    /// Inputs to function.\n    pub inputs: Vec<VariableId>,\n    /// Types for `ref` parameters of the function. An output variable will be introduced for each.\n    pub ref_tys: Vec<semantic::TypeId>,\n    /// Types for the returns of the function. An output variable will be introduced for each.\n    pub ret_tys: Vec<semantic::TypeId>,\n    /// Location associated with this statement.\n    pub location: StableLocationOption,\n}\nimpl Call {\n    /// Adds a call statement to the scope.\n    pub fn add(self, ctx: &mut LoweringContext<'_>, scope: &mut StatementsBuilder) -> CallResult {\n        let returns = self\n            .ret_tys\n            .into_iter()\n            .map(|ty| ctx.new_var(VarRequest { ty, location: self.location }))\n            .collect();\n        let ref_outputs = self\n            .ref_tys\n            .into_iter()\n            .map(|ty| ctx.new_var(VarRequest { ty, location: self.location }))\n            .collect();\n        let outputs = chain!(&ref_outputs, &returns).copied().collect();\n\n        scope.push_statement(Statement::Call(StatementCall {\n            function: self.function,\n            inputs: self.inputs,\n            outputs,\n            location: self.location,\n        }));\n\n        CallResult { returns, ref_outputs }\n    }\n}\n/// Result of adding a Call statement.\npub struct CallResult {\n    /// Output variables for function's return value.\n    pub returns: Vec<VariableId>,\n    /// Output variables for function's `ref` parameters.\n    pub ref_outputs: Vec<VariableId>,\n}\n\n/// Generator for [StatementEnumConstruct].\npub struct EnumConstruct {\n    pub input: VariableId,\n    pub variant: ConcreteVariant,\n    pub location: StableLocationOption,\n}\nimpl EnumConstruct {\n    pub fn add(self, ctx: &mut LoweringContext<'_>, scope: &mut StatementsBuilder) -> VariableId {\n        let ty = ctx.db.intern_type(semantic::TypeLongId::Concrete(\n            semantic::ConcreteTypeId::Enum(self.variant.concrete_enum_id),\n        ));\n        let output = ctx.new_var(VarRequest { ty, location: self.location });\n        scope.push_statement(Statement::EnumConstruct(StatementEnumConstruct {\n            variant: self.variant,\n            input: self.input,\n            output,\n        }));\n        output\n    }\n}\n\n/// Generator for [StatementSnapshot].\npub struct Snapshot {\n    pub input: VariableId,\n    pub location: StableLocationOption,\n}\nimpl Snapshot {\n    pub fn add(\n        self,\n        ctx: &mut LoweringContext<'_>,\n        scope: &mut StatementsBuilder,\n    ) -> (VariableId, VariableId) {\n        let input_ty = ctx.variables[self.input].ty;\n        let ty = ctx.db.intern_type(semantic::TypeLongId::Snapshot(input_ty));\n        let output_original = ctx.new_var(VarRequest { ty: input_ty, location: self.location });\n        let output_snapshot = ctx.new_var(VarRequest { ty, location: self.location });\n        scope.push_statement(Statement::Snapshot(StatementSnapshot {\n            input: self.input,\n            output_original,\n            output_snapshot,\n        }));\n        (output_original, output_snapshot)\n    }\n}\n\n/// Generator for [StatementDesnap].\npub struct Desnap {\n    pub input: VariableId,\n    pub location: StableLocationOption,\n}\nimpl Desnap {\n    pub fn add(self, ctx: &mut LoweringContext<'_>, scope: &mut StatementsBuilder) -> VariableId {\n        let ty = extract_matches!(\n            ctx.db.lookup_intern_type(ctx.variables[self.input].ty),\n            semantic::TypeLongId::Snapshot\n        );\n        let output = ctx.new_var(VarRequest { ty, location: self.location });\n        scope.push_statement(Statement::Desnap(StatementDesnap { input: self.input, output }));\n        output\n    }\n}\n\n/// Generator for [StatementStructDestructure].\npub struct StructDestructure {\n    /// Variable that holds the struct value.\n    pub input: VariableId,\n    /// Variable requests for the newly generated member values.\n    pub var_reqs: Vec<VarRequest>,\n}\nimpl StructDestructure {\n    pub fn add(\n        self,\n        ctx: &mut LoweringContext<'_>,\n        scope: &mut StatementsBuilder,\n    ) -> Vec<VariableId> {\n        let outputs: Vec<_> = self.var_reqs.into_iter().map(|req| ctx.new_var(req)).collect();\n        scope.push_statement(Statement::StructDestructure(StatementStructDestructure {\n            input: self.input,\n            outputs: outputs.clone(),\n        }));\n        outputs\n    }\n}\n\n/// Generator for [StatementStructDestructure] as member access.\npub struct StructMemberAccess {\n    pub input: VariableId,\n    pub member_tys: Vec<semantic::TypeId>,\n    pub member_idx: usize,\n    pub location: StableLocationOption,\n}\nimpl StructMemberAccess {\n    pub fn add(self, ctx: &mut LoweringContext<'_>, scope: &mut StatementsBuilder) -> VariableId {\n        StructDestructure {\n            input: self.input,\n            var_reqs: self\n                .member_tys\n                .into_iter()\n                .map(|ty| VarRequest { ty, location: self.location })\n                .collect(),\n        }\n        .add(ctx, scope)\n        .remove(self.member_idx)\n    }\n}\n\n/// Generator for [StatementStructConstruct].\npub struct StructConstruct {\n    pub inputs: Vec<VariableId>,\n    pub ty: semantic::TypeId,\n    pub location: StableLocationOption,\n}\nimpl StructConstruct {\n    pub fn add(self, ctx: &mut LoweringContext<'_>, scope: &mut StatementsBuilder) -> VariableId {\n        let output = ctx.new_var(VarRequest { ty: self.ty, location: self.location });\n        scope.push_statement(Statement::StructConstruct(StatementStructConstruct {\n            inputs: self.inputs,\n            output,\n        }));\n        output\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_debug::DebugWithDb;\nuse cairo_lang_defs::diagnostic_utils::StableLocationOption;\nuse cairo_lang_diagnostics::Maybe;\nuse cairo_lang_semantic as semantic;\nuse cairo_lang_semantic::corelib;\nuse cairo_lang_utils::extract_matches;\nuse num_traits::Zero;\nuse semantic::ExprFunctionCallArg;\n\nuse super::context::{LoweredExpr, LoweringContext, LoweringFlowError, LoweringResult};\nuse super::scope::{BlockBuilder, SealedBlockBuilder};\nuse super::{lower_expr, lowered_expr_to_block_scope_end};\nuse crate::lower::context::VarRequest;\nuse crate::lower::{create_subscope_with_bound_refs, generators, lower_block};\nuse crate::{MatchArm, MatchEnumInfo, MatchExternInfo, MatchInfo};\n\n#[allow(dead_code)]\nenum IfCondition {\n    BoolExpr(semantic::ExprId),\n    Eq(semantic::ExprId, semantic::ExprId),\n}\n\n/// Analyzes the condition of an if statement into an [IfCondition] tree, to allow different\n/// optimizations.\n// TODO(lior): Make it an actual tree (handling && and ||).\nfn analyze_condition(ctx: &LoweringContext<'_>, expr_id: semantic::ExprId) -> IfCondition {\n    let expr = &ctx.function_body.exprs[expr_id];\n    if let semantic::Expr::FunctionCall(function_call) = expr {\n        if function_call.function == corelib::felt252_eq(ctx.db.upcast())\n            && function_call.args.len() == 2\n        {\n            return IfCondition::Eq(\n                extract_matches!(function_call.args[0], ExprFunctionCallArg::Value),\n                extract_matches!(function_call.args[1], ExprFunctionCallArg::Value),\n            );\n        };\n    };\n\n    IfCondition::BoolExpr(expr_id)\n}\n\nfn is_zero(ctx: &LoweringContext<'_>, expr_id: semantic::ExprId) -> bool {\n    let expr = &ctx.function_body.exprs[expr_id];\n    matches!(expr, semantic::Expr::Literal(literal) if literal.value.is_zero())\n}\n\n/// Lowers an expression of type [semantic::ExprIf].\npub fn lower_expr_if(\n    ctx: &mut LoweringContext<'_>,\n    scope: &mut BlockBuilder,\n    expr: &semantic::ExprIf,\n) -> LoweringResult<LoweredExpr> {\n    match analyze_condition(ctx, expr.condition) {\n        IfCondition::BoolExpr(_) => lower_expr_if_bool(ctx, scope, expr),\n        IfCondition::Eq(expr_a, expr_b) => lower_expr_if_eq(ctx, scope, expr, expr_a, expr_b),\n    }\n}\n\n/// Lowers an expression of type [semantic::ExprIf], for the case of [IfCondition::BoolExpr].\npub fn lower_expr_if_bool(\n    ctx: &mut LoweringContext<'_>,\n    scope: &mut BlockBuilder,\n    expr: &semantic::ExprIf,\n) -> LoweringResult<LoweredExpr> {\n    log::trace!(\"Lowering a boolean if expression: {:?}\", expr.debug(&ctx.expr_formatter));\n    // The condition cannot be unit.\n    let condition_var = lower_expr(ctx, scope, expr.condition)?.var(ctx, scope)?;\n    let semantic_db = ctx.db.upcast();\n    let unit_ty = corelib::unit_ty(semantic_db);\n    let if_location = ctx.get_location(expr.stable_ptr.untyped());\n\n    // Main block.\n    let subscope_main = create_subscope_with_bound_refs(ctx, scope);\n    let block_main_id = subscope_main.block_id;\n    let main_block =\n        extract_matches!(&ctx.function_body.exprs[expr.if_block], semantic::Expr::Block);\n    let main_block_var_id = ctx.new_var(VarRequest {\n        ty: unit_ty,\n        location: ctx.get_location(main_block.stable_ptr.untyped()),\n    });\n    let block_main =\n        lower_block(ctx, subscope_main, main_block).map_err(LoweringFlowError::Failed)?;\n\n    // Else block.\n    let subscope_else = create_subscope_with_bound_refs(ctx, scope);\n    let block_else_id = subscope_else.block_id;\n\n    let else_block_input_var_id = ctx.new_var(VarRequest { ty: unit_ty, location: if_location });\n    let block_else = lower_optional_else_block(ctx, subscope_else, expr.else_block, if_location)\n        .map_err(LoweringFlowError::Failed)?;\n\n    let match_info = MatchInfo::Enum(MatchEnumInfo {\n        concrete_enum_id: corelib::core_bool_enum(semantic_db),\n        input: condition_var,\n        arms: vec![\n            MatchArm {\n                variant_id: corelib::false_variant(semantic_db),\n                block_id: block_else_id,\n                var_ids: vec![else_block_input_var_id],\n            },\n            MatchArm {\n                variant_id: corelib::true_variant(semantic_db),\n                block_id: block_main_id,\n                var_ids: vec![main_block_var_id],\n            },\n        ],\n    });\n    scope.merge_and_end_with_match(ctx, match_info, vec![block_main, block_else], if_location)\n}\n\n/// Lowers an expression of type [semantic::ExprIf], for the case of [IfCondition::Eq].\npub fn lower_expr_if_eq(\n    ctx: &mut LoweringContext<'_>,\n    scope: &mut BlockBuilder,\n    expr: &semantic::ExprIf,\n    expr_a: semantic::ExprId,\n    expr_b: semantic::ExprId,\n) -> LoweringResult<LoweredExpr> {\n    log::trace!(\n        \"Started lowering of an if-eq-zero expression: {:?}\",\n        expr.debug(&ctx.expr_formatter)\n    );\n    let if_location = ctx.get_location(expr.stable_ptr.untyped());\n    let condition_var = if is_zero(ctx, expr_b) {\n        lower_expr(ctx, scope, expr_a)?.var(ctx, scope)?\n    } else if is_zero(ctx, expr_a) {\n        lower_expr(ctx, scope, expr_b)?.var(ctx, scope)?\n    } else {\n        let lowered_a = lower_expr(ctx, scope, expr_a)?.var(ctx, scope)?;\n        let lowered_b = lower_expr(ctx, scope, expr_b)?.var(ctx, scope)?;\n        let ret_ty = corelib::core_felt252_ty(ctx.db.upcast());\n        let call_result = generators::Call {\n            function: corelib::felt252_sub(ctx.db.upcast()),\n            inputs: vec![lowered_a, lowered_b],\n            ref_tys: vec![],\n            ret_tys: vec![ret_ty],\n            location: ctx\n                .get_location(ctx.function_body.exprs[expr.condition].stable_ptr().untyped()),\n        }\n        .add(ctx, &mut scope.statements);\n        call_result.returns.into_iter().next().unwrap()\n    };\n\n    let semantic_db = ctx.db.upcast();\n\n    // Main block.\n    let subscope_main = create_subscope_with_bound_refs(ctx, scope);\n    let block_main_id = subscope_main.block_id;\n    let block_main = lower_block(\n        ctx,\n        subscope_main,\n        extract_matches!(&ctx.function_body.exprs[expr.if_block], semantic::Expr::Block),\n    )\n    .map_err(LoweringFlowError::Failed)?;\n\n    // Else block.\n    let non_zero_type =\n        corelib::core_nonzero_ty(semantic_db, corelib::core_felt252_ty(semantic_db));\n    let subscope_else = create_subscope_with_bound_refs(ctx, scope);\n    let block_else_id = subscope_else.block_id;\n\n    let else_block_input_var_id =\n        ctx.new_var(VarRequest { ty: non_zero_type, location: if_location });\n    let block_else = lower_optional_else_block(ctx, subscope_else, expr.else_block, if_location)\n        .map_err(LoweringFlowError::Failed)?;\n\n    let match_info = MatchInfo::Extern(MatchExternInfo {\n        function: corelib::core_felt252_is_zero(semantic_db),\n        inputs: vec![condition_var],\n        arms: vec![\n            MatchArm {\n                variant_id: corelib::jump_nz_zero_variant(semantic_db),\n                block_id: block_main_id,\n                var_ids: vec![],\n            },\n            MatchArm {\n                variant_id: corelib::jump_nz_nonzero_variant(semantic_db),\n                block_id: block_else_id,\n                var_ids: vec![else_block_input_var_id],\n            },\n        ],\n        location: if_location,\n    });\n    scope.merge_and_end_with_match(ctx, match_info, vec![block_main, block_else], if_location)\n}\n\n/// Lowers an optional else block. If the else block is missing it is replaced with a block\n/// returning a unit.\n/// Returns the sealed block builder of the else block.\nfn lower_optional_else_block(\n    ctx: &mut LoweringContext<'_>,\n    mut scope: BlockBuilder,\n    else_expr_opt: Option<semantic::ExprId>,\n    if_location: StableLocationOption,\n) -> Maybe<SealedBlockBuilder> {\n    log::trace!(\"Started lowering of an optional else block.\");\n    match else_expr_opt {\n        Some(else_expr) => {\n            let expr = &ctx.function_body.exprs[else_expr];\n            match expr {\n                semantic::Expr::Block(block) => lower_block(ctx, scope, block),\n                semantic::Expr::If(if_expr) => {\n                    let lowered_if = lower_expr_if(ctx, &mut scope, if_expr);\n                    lowered_expr_to_block_scope_end(ctx, scope, lowered_if)\n                }\n                _ => unreachable!(),\n            }\n        }\n        None => lowered_expr_to_block_scope_end(\n            ctx,\n            scope,\n            Ok(LoweredExpr::Tuple { exprs: vec![], location: if_location }),\n        ),\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_debug::DebugWithDb;\nuse cairo_lang_defs::diagnostic_utils::StableLocationOption;\nuse cairo_lang_defs::ids::FunctionWithBodyId;\nuse cairo_lang_diagnostics::Maybe;\nuse cairo_lang_semantic as semantic;\nuse cairo_lang_utils::unordered_hash_map::UnorderedHashMap;\nuse cairo_lang_utils::{extract_matches, try_extract_matches};\nuse itertools::{chain, zip_eq, Itertools};\nuse num_traits::Zero;\nuse scope::BlockBuilder;\nuse semantic::corelib::{\n    core_felt252_is_zero, core_felt252_ty, core_nonzero_ty, get_core_function_id,\n    jump_nz_nonzero_variant, jump_nz_zero_variant, unit_ty,\n};\nuse semantic::items::enm::SemanticEnumEx;\nuse semantic::items::structure::SemanticStructEx;\nuse semantic::types::{peel_snapshots, wrap_in_snapshots};\nuse semantic::{ConcreteTypeId, ExprFunctionCallArg, ExprPropagateError, TypeLongId};\n\nuse self::context::{\n    lowering_flow_error_to_sealed_block, LoweredExpr, LoweredExprExternEnum, LoweringContext,\n    LoweringFlowError,\n};\nuse self::external::{extern_facade_expr, extern_facade_return_tys};\nuse self::lower_if::lower_expr_if;\nuse self::scope::SealedBlockBuilder;\nuse crate::blocks::FlatBlocks;\nuse crate::db::LoweringGroup;\nuse crate::diagnostic::LoweringDiagnosticKind::*;\nuse crate::lower::context::{LoweringContextBuilder, LoweringResult, VarRequest};\nuse crate::{\n    BlockId, FlatLowered, MatchArm, MatchEnumInfo, MatchExternInfo, MatchInfo, VariableId,\n};\npub mod generators;\n\npub mod context;\nmod external;\nmod lower_if;\npub mod refs;\nmod scope;\n\n/// Lowers a semantic free function.\npub fn lower(db: &dyn LoweringGroup, function_id: FunctionWithBodyId) -> Maybe<FlatLowered> {\n    log::trace!(\"Lowering a free function.\");\n    let semantic_diagnostics_free = db\n        .function_declaration_diagnostics(function_id)\n        .is_diagnostic_free()\n        .and_then(|()| db.function_body_diagnostics(function_id).is_diagnostic_free());\n    let function_def = db.function_body(function_id)?;\n    let signature = db.function_with_body_signature(function_id)?;\n\n    // Params.\n    let input_semantic_vars: Vec<semantic::Variable> =\n        signature.params.iter().cloned().map(semantic::Variable::Param).collect();\n\n    let lowering_builder = LoweringContextBuilder::new(db, function_id)?;\n    let mut ctx = lowering_builder.ctx()?;\n\n    // TODO(spapini): Build semantic_defs in semantic model.\n    for semantic_var in input_semantic_vars {\n        ctx.semantic_defs.insert(semantic_var.id(), semantic_var);\n    }\n\n    // Fetch body block expr.\n    let semantic_block =\n        extract_matches!(&function_def.exprs[function_def.body_expr], semantic::Expr::Block);\n\n    // Initialize scope.\n    let root_block_id = alloc_empty_block(&mut ctx);\n    let mut scope = BlockBuilder::root(&ctx, root_block_id);\n\n    let parameters = ctx\n        .signature\n        .params\n        .iter()\n        .cloned()\n        .map(|param| {\n            let location = ctx.get_location(param.stable_ptr.untyped());\n            let semantic = semantic::Variable::Param(param);\n            let var = ctx.new_var(VarRequest { ty: semantic.ty(), location });\n            scope.put_semantic(semantic.id(), var);\n            var\n        })\n        .collect_vec();\n\n    let root_ok = semantic_diagnostics_free.and_then(|()| {\n        let maybe_sealed_block = lower_block(&mut ctx, scope, semantic_block);\n        maybe_sealed_block.and_then(|block_sealed| {\n            match block_sealed {\n                SealedBlockBuilder::GotoCallsite { mut scope, expr } => {\n                    // Convert to a return.\n                    let var = expr.unwrap_or_else(|| {\n                        generators::StructConstruct {\n                            inputs: vec![],\n                            ty: unit_ty(ctx.db.upcast()),\n                            location: ctx.get_location(semantic_block.stable_ptr.untyped()),\n                        }\n                        .add(&mut ctx, &mut scope.statements)\n                    });\n                    let location = ctx.get_location(semantic_block.stable_ptr.untyped());\n                    scope.ret(&mut ctx, var, location)?;\n                }\n                SealedBlockBuilder::Ends(_) => {}\n            }\n            Ok(root_block_id)\n        })\n    });\n    let blocks = root_ok\n        .map(|_| ctx.blocks.build().expect(\"Root block must exist.\"))\n        .unwrap_or_else(FlatBlocks::new_errored);\n    Ok(FlatLowered {\n        diagnostics: ctx.diagnostics.build(),\n        variables: ctx.variables,\n        blocks,\n        parameters,\n    })\n}\n\n/// Lowers a semantic block.\nfn lower_block(\n    ctx: &mut LoweringContext<'_>,\n    mut scope: BlockBuilder,\n    semantic_block: &semantic::ExprBlock,\n) -> Maybe<SealedBlockBuilder> {\n    let block_expr = lower_expr_block(ctx, &mut scope, semantic_block);\n    lowered_expr_to_block_scope_end(ctx, scope, block_expr)\n}\n\n/// Lowers a semantic block.\nfn lower_expr_block(\n    ctx: &mut LoweringContext<'_>,\n    scope: &mut BlockBuilder,\n    expr_block: &semantic::ExprBlock,\n) -> LoweringResult<LoweredExpr> {\n    log::trace!(\"Lowering a block.\");\n    for (i, stmt_id) in expr_block.statements.iter().enumerate() {\n        let stmt = &ctx.function_body.statements[*stmt_id];\n        let Err(err) = lower_statement(ctx, scope, stmt) else { continue; };\n        if err.is_unreachable() {\n            // If flow is not reachable anymore, no need to continue emitting statements.\n            // TODO(spapini): We might want to report unreachable for expr that abruptly\n            // ends, e.g. `5 + {return; 6}`.\n            if i + 1 < expr_block.statements.len() {\n                let start_stmt = &ctx.function_body.statements[expr_block.statements[i + 1]];\n                let end_stmt =\n                    &ctx.function_body.statements[*expr_block.statements.last().unwrap()];\n                // Emit diagnostic fo the rest of the statements with unreachable.\n                ctx.diagnostics.report(\n                    start_stmt.stable_ptr().untyped(),\n                    Unreachable { last_statement_ptr: end_stmt.stable_ptr().untyped() },\n                );\n            }\n        }\n        return Err(err);\n    }\n    // Determine correct block end.\n    let location = ctx.get_location(expr_block.stable_ptr.untyped());\n    expr_block\n        .tail\n        .map(|expr| lower_expr(ctx, scope, expr))\n        .unwrap_or_else(|| Ok(LoweredExpr::Tuple { exprs: vec![], location }))\n}\n\n/// Lowers an expression that is either a complete block, or the end (tail expression) of a\n/// block.\npub fn lower_tail_expr(\n    ctx: &mut LoweringContext<'_>,\n    mut scope: BlockBuilder,\n    expr: semantic::ExprId,\n) -> Maybe<SealedBlockBuilder> {\n    log::trace!(\"Lowering a tail expression.\");\n    let lowered_expr = lower_expr(ctx, &mut scope, expr);\n    lowered_expr_to_block_scope_end(ctx, scope, lowered_expr)\n}\n\n/// Converts [`LoweringResult<LoweredExpr>`] into `BlockScopeEnd`.\npub fn lowered_expr_to_block_scope_end(\n    ctx: &mut LoweringContext<'_>,\n    mut scope: BlockBuilder,\n    lowered_expr: LoweringResult<LoweredExpr>,\n) -> Maybe<SealedBlockBuilder> {\n    Ok(match lowered_expr {\n        Ok(LoweredExpr::Tuple { exprs, .. }) if exprs.is_empty() => scope.goto_callsite(None),\n        Ok(lowered_expr) => match lowered_expr.var(ctx, &mut scope) {\n            Ok(var) => scope.goto_callsite(Some(var)),\n            Err(err) => lowering_flow_error_to_sealed_block(ctx, scope, err)?,\n        },\n        Err(err) => lowering_flow_error_to_sealed_block(ctx, scope, err)?,\n    })\n}\n\n/// Lowers a semantic statement.\npub fn lower_statement(\n    ctx: &mut LoweringContext<'_>,\n    scope: &mut BlockBuilder,\n    stmt: &semantic::Statement,\n) -> Result<(), LoweringFlowError> {\n    match stmt {\n        semantic::Statement::Expr(semantic::StatementExpr { expr, stable_ptr: _ }) => {\n            log::trace!(\"Lowering an expression statement.\");\n            let lowered_expr = lower_expr(ctx, scope, *expr)?;\n            // The LoweredExpr must be evaluated now to push/bring back variables in case it is\n            // LoweredExpr::ExternEnum.\n            if let LoweredExpr::ExternEnum(x) = lowered_expr {\n                x.var(ctx, scope)?;\n            }\n        }\n        semantic::Statement::Let(semantic::StatementLet { pattern, expr, stable_ptr: _ }) => {\n            log::trace!(\"Lowering a let statement.\");\n            let lowered_expr = lower_expr(ctx, scope, *expr)?;\n            lower_single_pattern(ctx, scope, pattern, lowered_expr)?\n        }\n        semantic::Statement::Return(semantic::StatementReturn { expr, stable_ptr }) => {\n            log::trace!(\"Lowering a return statement.\");\n            let ret_var = lower_expr(ctx, scope, *expr)?.var(ctx, scope)?;\n            return Err(LoweringFlowError::Return(ret_var, ctx.get_location(stable_ptr.untyped())));\n        }\n    }\n    Ok(())\n}\n\n// TODO(spapini): Separate match pattern from non-match (single) patterns in the semantic\n// model.\n/// Lowers a single-pattern (pattern that does not appear in a match. This includes structs,\n/// tuples, variables, etc...\n/// Adds the bound variables to the scope.\n/// Note that single patterns are the only way to bind new local variables in the semantic\n/// model.\nfn lower_single_pattern(\n    ctx: &mut LoweringContext<'_>,\n    scope: &mut BlockBuilder,\n    pattern: &semantic::Pattern,\n    lowered_expr: LoweredExpr,\n) -> Result<(), LoweringFlowError> {\n    log::trace!(\"Lowering a single pattern.\");\n    match pattern {\n        semantic::Pattern::Literal(_) => unreachable!(),\n        semantic::Pattern::Variable(semantic::PatternVariable {\n            name: _,\n            var: sem_var,\n            stable_ptr,\n        }) => {\n            let sem_var = semantic::Variable::Local(sem_var.clone());\n            // Deposit the owned variable in the semantic variables store.\n            let var = lowered_expr.var(ctx, scope)?;\n            // Override variable location.\n            ctx.variables[var].location = ctx.get_location(stable_ptr.untyped());\n            scope.put_semantic(sem_var.id(), var);\n            // TODO(spapini): Build semantic_defs in semantic model.\n            ctx.semantic_defs.insert(sem_var.id(), sem_var);\n        }\n        semantic::Pattern::Struct(structure) => {\n            let members = ctx\n                .db\n                .concrete_struct_members(structure.concrete_struct_id)\n                .map_err(LoweringFlowError::Failed)?;\n            let mut required_members = UnorderedHashMap::from_iter(\n                structure.field_patterns.iter().map(|(member, pattern)| (member.id, pattern)),\n            );\n            let generator = generators::StructDestructure {\n                input: lowered_expr.var(ctx, scope)?,\n                var_reqs: members\n                    .iter()\n                    .map(|(_, member)| VarRequest {\n                        ty: wrap_in_snapshots(ctx.db.upcast(), member.ty, structure.n_snapshots),\n                        location: ctx.get_location(\n                            required_members\n                                .get(&member.id)\n                                .map(|pattern| pattern.stable_ptr().untyped())\n                                .unwrap_or_else(|| structure.stable_ptr.untyped()),\n                        ),\n                    })\n                    .collect(),\n            };\n            for (var, (_, member)) in\n                generator.add(ctx, &mut scope.statements).into_iter().zip(members.into_iter())\n            {\n                if let Some(member_pattern) = required_members.remove(&member.id) {\n                    lower_single_pattern(ctx, scope, member_pattern, LoweredExpr::AtVariable(var))?;\n                }\n            }\n        }\n        semantic::Pattern::Tuple(semantic::PatternTuple { field_patterns, ty, stable_ptr }) => {\n            let location = ctx.get_location(stable_ptr.untyped());\n            let outputs = if let LoweredExpr::Tuple { exprs, .. } = lowered_expr {\n                exprs\n            } else {\n                let (n_snapshots, long_type_id) = peel_snapshots(ctx.db.upcast(), *ty);\n                let reqs = extract_matches!(long_type_id, TypeLongId::Tuple)\n                    .into_iter()\n                    .map(|ty| VarRequest {\n                        ty: wrap_in_snapshots(ctx.db.upcast(), ty, n_snapshots),\n                        location,\n                    })\n                    .collect();\n                generators::StructDestructure {\n                    input: lowered_expr.var(ctx, scope)?,\n                    var_reqs: reqs,\n                }\n                .add(ctx, &mut scope.statements)\n                .into_iter()\n                .map(LoweredExpr::AtVariable)\n                .collect()\n            };\n            for (var, pattern) in zip_eq(outputs, field_patterns) {\n                lower_single_pattern(ctx, scope, pattern, var)?;\n            }\n        }\n        semantic::Pattern::EnumVariant(_) => unreachable!(),\n        semantic::Pattern::Otherwise(_) => {}\n    }\n    Ok(())\n}\n\n/// Lowers a semantic expression.\nfn lower_expr(\n    ctx: &mut LoweringContext<'_>,\n    scope: &mut BlockBuilder,\n    expr_id: semantic::ExprId,\n) -> LoweringResult<LoweredExpr> {\n    let expr = &ctx.function_body.exprs[expr_id];\n    match expr {\n        semantic::Expr::Constant(expr) => lower_expr_constant(ctx, expr, scope),\n        semantic::Expr::Tuple(expr) => lower_expr_tuple(ctx, expr, scope),\n        semantic::Expr::Snapshot(expr) => lower_expr_snapshot(ctx, expr, scope),\n        semantic::Expr::Desnap(expr) => lower_expr_desnap(ctx, expr, scope),\n        semantic::Expr::Assignment(expr) => lower_expr_assignment(ctx, expr, scope),\n        semantic::Expr::Block(expr) => lower_expr_block(ctx, scope, expr),\n        semantic::Expr::FunctionCall(expr) => lower_expr_function_call(ctx, expr, scope),\n        semantic::Expr::Match(expr) => lower_expr_match(ctx, expr, scope),\n        semantic::Expr::If(expr) => lower_expr_if(ctx, scope, expr),\n        semantic::Expr::Var(expr) => {\n            log::trace!(\"Lowering a variable: {:?}\", expr.debug(&ctx.expr_formatter));\n            Ok(LoweredExpr::SemanticVar(expr.var, ctx.get_location(expr.stable_ptr.untyped())))\n        }\n        semantic::Expr::Literal(expr) => lower_expr_literal(ctx, expr, scope),\n        semantic::Expr::MemberAccess(expr) => lower_expr_member_access(ctx, expr, scope),\n        semantic::Expr::StructCtor(expr) => lower_expr_struct_ctor(ctx, expr, scope),\n        semantic::Expr::EnumVariantCtor(expr) => lower_expr_enum_ctor(ctx, expr, scope),\n        semantic::Expr::PropagateError(expr) => lower_expr_error_propagate(ctx, expr, scope),\n        semantic::Expr::Missing(semantic::ExprMissing { diag_added, .. }) => {\n            Err(LoweringFlowError::Failed(*diag_added))\n        }\n    }\n}\n\nfn lower_expr_literal(\n    ctx: &mut LoweringContext<'_>,\n    expr: &semantic::ExprLiteral,\n    scope: &mut BlockBuilder,\n) -> LoweringResult<LoweredExpr> {\n    log::trace!(\"Lowering a literal: {:?}\", expr.debug(&ctx.expr_formatter));\n    let location = ctx.get_location(expr.stable_ptr.untyped());\n    Ok(LoweredExpr::AtVariable(\n        generators::Literal { value: expr.value.clone(), ty: expr.ty, location }\n            .add(ctx, &mut scope.statements),\n    ))\n}\n\nfn lower_expr_constant(\n    ctx: &mut LoweringContext<'_>,\n    expr: &semantic::ExprConstant,\n    scope: &mut BlockBuilder,\n) -> LoweringResult<LoweredExpr> {\n    log::trace!(\"Lowering a constant: {:?}\", expr.debug(&ctx.expr_formatter));\n    let const_expr =\n        &ctx.db.constant_semantic_data(expr.constant_id).map_err(LoweringFlowError::Failed)?.value;\n    let semantic::Expr::Literal(const_expr_literal) = const_expr else {\n        panic!(\"Only literal constants are supported.\");\n    };\n    lower_expr_literal(ctx, const_expr_literal, scope)\n}\n\n/// Lowers an expression of type [semantic::ExprTuple].\nfn lower_expr_tuple(\n    ctx: &mut LoweringContext<'_>,\n    expr: &semantic::ExprTuple,\n    scope: &mut BlockBuilder,\n) -> LoweringResult<LoweredExpr> {\n    log::trace!(\"Lowering a tuple: {:?}\", expr.debug(&ctx.expr_formatter));\n    let location = ctx.get_location(expr.stable_ptr.untyped());\n    let inputs = expr\n        .items\n        .iter()\n        .map(|arg_expr_id| lower_expr(ctx, scope, *arg_expr_id))\n        .collect::<Result<Vec<_>, _>>()?;\n    Ok(LoweredExpr::Tuple { exprs: inputs, location })\n}\n\n/// Lowers an expression of type [semantic::ExprSnapshot].\nfn lower_expr_snapshot(\n    ctx: &mut LoweringContext<'_>,\n    expr: &semantic::ExprSnapshot,\n    scope: &mut BlockBuilder,\n) -> LoweringResult<LoweredExpr> {\n    log::trace!(\"Lowering a snapshot: {:?}\", expr.debug(&ctx.expr_formatter));\n    let location = ctx.get_location(expr.stable_ptr.untyped());\n    let expr = Box::new(lower_expr(ctx, scope, expr.inner)?);\n    Ok(LoweredExpr::Snapshot { expr, location })\n}\n\n/// Lowers an expression of type [semantic::ExprDesnap].\nfn lower_expr_desnap(\n    ctx: &mut LoweringContext<'_>,\n    expr: &semantic::ExprDesnap,\n    scope: &mut BlockBuilder,\n) -> LoweringResult<LoweredExpr> {\n    log::trace!(\"Lowering a desnap: {:?}\", expr.debug(&ctx.expr_formatter));\n    let location = ctx.get_location(expr.stable_ptr.untyped());\n    let input = lower_expr(ctx, scope, expr.inner)?.var(ctx, scope)?;\n\n    Ok(LoweredExpr::AtVariable(\n        generators::Desnap { input, location }.add(ctx, &mut scope.statements),\n    ))\n}\n\n/// Lowers an expression of type [semantic::ExprFunctionCall].\nfn lower_expr_function_call(\n    ctx: &mut LoweringContext<'_>,\n    expr: &semantic::ExprFunctionCall,\n    scope: &mut BlockBuilder,\n) -> LoweringResult<LoweredExpr> {\n    log::trace!(\"Lowering a function call expression: {:?}\", expr.debug(&ctx.expr_formatter));\n    let location = ctx.get_location(expr.stable_ptr.untyped());\n\n    // TODO(spapini): Use the correct stable pointer.\n    let arg_inputs = lower_exprs_as_vars(ctx, &expr.args, scope)?;\n    let ref_args_iter = expr\n        .args\n        .iter()\n        .filter_map(|arg| try_extract_matches!(arg, ExprFunctionCallArg::Reference));\n    let ref_tys = ref_args_iter.clone().map(|ref_arg| ref_arg.ty()).collect();\n\n    // If the function is panic(), do something special.\n    if expr.function == get_core_function_id(ctx.db.upcast(), \"panic\".into(), vec![]) {\n        let [input] = <[_; 1]>::try_from(arg_inputs).ok().unwrap();\n        return Err(LoweringFlowError::Panic(input));\n    }\n\n    // The following is relevant only to extern functions.\n    if expr.function.try_get_extern_function_id(ctx.db.upcast()).is_some() {\n        if let semantic::TypeLongId::Concrete(semantic::ConcreteTypeId::Enum(concrete_enum_id)) =\n            ctx.db.lookup_intern_type(expr.ty)\n        {\n            let lowered_expr = LoweredExprExternEnum {\n                function: expr.function,\n                concrete_enum_id,\n                inputs: arg_inputs,\n                member_paths: ref_args_iter.cloned().collect(),\n                location,\n            };\n\n            // It is still unknown whether we directly match on this enum result, or store it to a\n            // variable. Thus we can't perform the call. Performing it and pushing/bringing-back\n            // variables are done on the 2 places where this result is used:\n            // 1. [lower_optimized_extern_match]\n            // 2. [context::LoweredExprExternEnum::var]\n            return Ok(LoweredExpr::ExternEnum(lowered_expr));\n        }\n    }\n\n    let (ref_outputs, res) =\n        perform_function_call(ctx, scope, expr.function, arg_inputs, ref_tys, expr.ty, location)?;\n\n    // Rebind the ref variables.\n    for (ref_arg, output_var) in zip_eq(ref_args_iter, ref_outputs) {\n        scope.update_ref(ctx, ref_arg, output_var);\n    }\n\n    Ok(res)\n}\n\n/// Creates a LoweredExpr for a function call, taking into consideration external function facades:\n/// For external functions, sometimes the high level signature doesn't exactly correspond to the\n/// external function returned variables / branches.\nfn perform_function_call(\n    ctx: &mut LoweringContext<'_>,\n    scope: &mut BlockBuilder,\n    function: semantic::FunctionId,\n    inputs: Vec<VariableId>,\n    ref_tys: Vec<semantic::TypeId>,\n    ret_ty: semantic::TypeId,\n    location: StableLocationOption,\n) -> Result<(Vec<VariableId>, LoweredExpr), LoweringFlowError> {\n    // If the function is not extern, simply call it.\n    if function.try_get_extern_function_id(ctx.db.upcast()).is_none() {\n        let call_result =\n            generators::Call { function, inputs, ref_tys, ret_tys: vec![ret_ty], location }\n                .add(ctx, &mut scope.statements);\n        let res = LoweredExpr::AtVariable(call_result.returns.into_iter().next().unwrap());\n        return Ok((call_result.ref_outputs, res));\n    };\n\n    // Extern function.\n    let ret_tys = extern_facade_return_tys(ctx, ret_ty);\n    let call_result = generators::Call { function, inputs, ref_tys, ret_tys, location }\n        .add(ctx, &mut scope.statements);\n    Ok((call_result.ref_outputs, extern_facade_expr(ctx, ret_ty, call_result.returns, location)))\n}\n\n/// Lowers an expression of type [semantic::ExprMatch].\nfn lower_expr_match(\n    ctx: &mut LoweringContext<'_>,\n    expr: &semantic::ExprMatch,\n    scope: &mut BlockBuilder,\n) -> LoweringResult<LoweredExpr> {\n    log::trace!(\"Lowering a match expression: {:?}\", expr.debug(&ctx.expr_formatter));\n    let location = ctx.get_location(expr.stable_ptr.untyped());\n    let lowered_expr = lower_expr(ctx, scope, expr.matched_expr)?;\n\n    if ctx.function_body.exprs[expr.matched_expr].ty() == ctx.db.core_felt252_ty() {\n        let var = lowered_expr.var(ctx, scope)?;\n        return lower_expr_match_felt252(ctx, expr, var, scope);\n    }\n\n    // TODO(spapini): Use diagnostics.\n    // TODO(spapini): Handle more than just enums.\n    if let LoweredExpr::ExternEnum(extern_enum) = lowered_expr {\n        return lower_optimized_extern_match(ctx, scope, extern_enum, &expr.arms);\n    }\n\n    let ExtractedEnumDetails { concrete_enum_id, concrete_variants, n_snapshots } =\n        extract_concrete_enum(ctx, expr)?;\n    let expr_var = lowered_expr.var(ctx, scope)?;\n\n    // Merge arm blocks.\n\n    let mut arm_var_ids = vec![];\n    let (sealed_blocks, block_ids): (Vec<_>, Vec<_>) = zip_eq(&concrete_variants, &expr.arms)\n        .map(|(concrete_variant, arm)| {\n            let mut subscope = create_subscope_with_bound_refs(ctx, scope);\n            let block_id = subscope.block_id;\n\n            let enum_pattern = try_extract_matches!(&arm.pattern, semantic::Pattern::EnumVariant)\n                .ok_or_else(|| {\n                LoweringFlowError::Failed(\n                    ctx.diagnostics\n                        .report(arm.pattern.stable_ptr().untyped(), UnsupportedMatchArmNotAVariant),\n                )\n            })?;\n            if &enum_pattern.variant != concrete_variant {\n                return Err(LoweringFlowError::Failed(\n                    ctx.diagnostics\n                        .report(arm.pattern.stable_ptr().untyped(), UnsupportedMatchArmOutOfOrder),\n                ));\n            }\n\n            let pattern_location =\n                ctx.get_location(enum_pattern.inner_pattern.stable_ptr().untyped());\n\n            let var_id = ctx.new_var(VarRequest {\n                ty: wrap_in_snapshots(ctx.db.upcast(), concrete_variant.ty, n_snapshots),\n                location: pattern_location,\n            });\n            arm_var_ids.push(vec![var_id]);\n            let variant_expr = LoweredExpr::AtVariable(var_id);\n\n            match lower_single_pattern(\n                ctx,\n                &mut subscope,\n                &enum_pattern.inner_pattern,\n                variant_expr,\n            ) {\n                Ok(_) => {\n                    // Lower the arm expression.\n                    lower_tail_expr(ctx, subscope, arm.expression)\n                }\n                Err(err) => lowering_flow_error_to_sealed_block(ctx, subscope, err),\n            }\n            .map_err(LoweringFlowError::Failed)\n            .map(|sb| (sb, block_id))\n        })\n        .collect::<LoweringResult<Vec<_>>>()?\n        .into_iter()\n        .unzip();\n\n    let match_info = MatchInfo::Enum(MatchEnumInfo {\n        concrete_enum_id,\n        input: expr_var,\n        arms: zip_eq(zip_eq(concrete_variants, block_ids), arm_var_ids.into_iter())\n            .map(|((variant_id, block_id), var_ids)| MatchArm { variant_id, block_id, var_ids })\n            .collect(),\n    });\n    scope.merge_and_end_with_match(ctx, match_info, sealed_blocks, location)\n}\n\n/// Lowers a match expression on a LoweredExpr::ExternEnum lowered expression.\nfn lower_optimized_extern_match(\n    ctx: &mut LoweringContext<'_>,\n    scope: &mut BlockBuilder,\n    extern_enum: LoweredExprExternEnum,\n    match_arms: &[semantic::MatchArm],\n) -> LoweringResult<LoweredExpr> {\n    log::trace!(\"Started lowering of an optimized extern match.\");\n    let location = extern_enum.location;\n    let concrete_variants = ctx\n        .db\n        .concrete_enum_variants(extern_enum.concrete_enum_id)\n        .map_err(LoweringFlowError::Failed)?;\n    if match_arms.len() != concrete_variants.len() {\n        return Err(LoweringFlowError::Failed(\n            ctx.diagnostics.report_by_location(location, UnsupportedMatch),\n        ));\n    }\n    // Merge arm blocks.\n    let mut arm_var_ids = vec![];\n\n    let (sealed_blocks, block_ids): (Vec<_>, Vec<_>) = zip_eq(&concrete_variants, match_arms)\n        .map(|(concrete_variant, arm)| {\n            let mut subscope = create_subscope(ctx, scope);\n            let block_id = subscope.block_id;\n\n            let input_tys =\n                match_extern_variant_arm_input_types(ctx, concrete_variant.ty, &extern_enum);\n            let mut input_vars = input_tys\n                .into_iter()\n                .map(|ty| ctx.new_var(VarRequest { ty, location }))\n                .collect_vec();\n            arm_var_ids.push(input_vars.clone());\n\n            let enum_pattern = try_extract_matches!(&arm.pattern, semantic::Pattern::EnumVariant)\n                .ok_or_else(|| {\n                LoweringFlowError::Failed(\n                    ctx.diagnostics\n                        .report(arm.pattern.stable_ptr().untyped(), UnsupportedMatchArmNotAVariant),\n                )\n            })?;\n            if &enum_pattern.variant != concrete_variant {\n                return Err(LoweringFlowError::Failed(\n                    ctx.diagnostics\n                        .report(arm.pattern.stable_ptr().untyped(), UnsupportedMatchArmOutOfOrder),\n                ));\n            }\n\n            // Bind the arm inputs to implicits and semantic variables.\n            match_extern_arm_ref_args_bind(ctx, &mut input_vars, &extern_enum, &mut subscope);\n\n            let variant_expr = extern_facade_expr(ctx, concrete_variant.ty, input_vars, location);\n            match lower_single_pattern(\n                ctx,\n                &mut subscope,\n                &enum_pattern.inner_pattern,\n                variant_expr,\n            ) {\n                Ok(_) => {\n                    // Lower the arm expression.\n                    lower_tail_expr(ctx, subscope, arm.expression)\n                }\n                Err(err) => lowering_flow_error_to_sealed_block(ctx, subscope, err),\n            }\n            .map_err(LoweringFlowError::Failed)\n            .map(|sb| (sb, block_id))\n        })\n        .collect::<LoweringResult<Vec<_>>>()?\n        .into_iter()\n        .unzip();\n\n    let match_info = MatchInfo::Extern(MatchExternInfo {\n        function: extern_enum.function,\n        inputs: extern_enum.inputs,\n        arms: zip_eq(zip_eq(concrete_variants, block_ids), arm_var_ids.into_iter())\n            .map(|((variant_id, block_id), var_ids)| MatchArm { variant_id, block_id, var_ids })\n            .collect(),\n        location,\n    });\n    scope.merge_and_end_with_match(ctx, match_info, sealed_blocks, location)\n}\n\n/// Lowers an expression of type [semantic::ExprMatch] where the matched expression is a felt252.\n/// Currently only a simple match-zero is supported.\nfn lower_expr_match_felt252(\n    ctx: &mut LoweringContext<'_>,\n    expr: &semantic::ExprMatch,\n    expr_var: VariableId,\n    scope: &mut BlockBuilder,\n) -> LoweringResult<LoweredExpr> {\n    log::trace!(\"Lowering a match-felt252 expression.\");\n    let location = ctx.get_location(expr.stable_ptr.untyped());\n    // Check that the match has the expected form.\n    let (literal, block0, block_otherwise) = if let [\n        semantic::MatchArm {\n            pattern: semantic::Pattern::Literal(semantic::PatternLiteral { literal, .. }),\n            expression: block0,\n        },\n        semantic::MatchArm {\n            pattern: semantic::Pattern::Otherwise(_),\n            expression: block_otherwise,\n        },\n    ] = &expr.arms[..]\n    {\n        (literal, block0, block_otherwise)\n    } else {\n        return Err(LoweringFlowError::Failed(\n            ctx.diagnostics.report(expr.stable_ptr.untyped(), OnlyMatchZeroIsSupported),\n        ));\n    };\n\n    // Make sure literal is 0.\n    if !literal.value.is_zero() {\n        return Err(LoweringFlowError::Failed(\n            ctx.diagnostics.report(literal.stable_ptr.untyped(), NonZeroValueInMatch),\n        ));\n    }\n\n    let semantic_db = ctx.db.upcast();\n\n    // Lower both blocks.\n    let zero_block_id = alloc_empty_block(ctx);\n    let nonzero_block_id = alloc_empty_block(ctx);\n\n    let subscope_nz = scope.subscope_with_bound_refs(nonzero_block_id);\n    let var_nz = ctx.new_var(VarRequest {\n        ty: core_nonzero_ty(semantic_db, core_felt252_ty(semantic_db)),\n        location,\n    });\n\n    let sealed_blocks = vec![\n        lower_tail_expr(ctx, scope.subscope_with_bound_refs(zero_block_id), *block0)\n            .map_err(LoweringFlowError::Failed)?,\n        lower_tail_expr(ctx, subscope_nz, *block_otherwise).map_err(LoweringFlowError::Failed)?,\n    ];\n\n    let match_info = MatchInfo::Extern(MatchExternInfo {\n        function: core_felt252_is_zero(semantic_db),\n        inputs: vec![expr_var],\n        arms: vec![\n            MatchArm {\n                variant_id: jump_nz_zero_variant(semantic_db),\n                block_id: zero_block_id,\n                var_ids: vec![],\n            },\n            MatchArm {\n                variant_id: jump_nz_nonzero_variant(semantic_db),\n                block_id: nonzero_block_id,\n                var_ids: vec![var_nz],\n            },\n        ],\n        location,\n    });\n    scope.merge_and_end_with_match(ctx, match_info, sealed_blocks, location)\n}\n\n/// Information about the enum of a match statement. See [extract_concrete_enum].\nstruct ExtractedEnumDetails {\n    concrete_enum_id: semantic::ConcreteEnumId,\n    concrete_variants: Vec<semantic::ConcreteVariant>,\n    n_snapshots: usize,\n}\n\n/// Extracts concrete enum and variants from a match expression. Assumes it is indeed a concrete\n/// enum.\nfn extract_concrete_enum(\n    ctx: &mut LoweringContext<'_>,\n    expr: &semantic::ExprMatch,\n) -> Result<ExtractedEnumDetails, LoweringFlowError> {\n    let ty = ctx.function_body.exprs[expr.matched_expr].ty();\n    let (n_snapshots, long_ty) = peel_snapshots(ctx.db.upcast(), ty);\n\n    // Semantic model should have made sure the type is an enum.\n    let concrete_ty = extract_matches!(long_ty, TypeLongId::Concrete);\n    let concrete_enum_id = extract_matches!(concrete_ty, ConcreteTypeId::Enum);\n    let enum_id = concrete_enum_id.enum_id(ctx.db.upcast());\n    let variants = ctx.db.enum_variants(enum_id).map_err(LoweringFlowError::Failed)?;\n    let concrete_variants = variants\n        .values()\n        .map(|variant_id| {\n            let variant =\n                ctx.db.variant_semantic(enum_id, *variant_id).map_err(LoweringFlowError::Failed)?;\n\n            ctx.db\n                .concrete_enum_variant(concrete_enum_id, &variant)\n                .map_err(LoweringFlowError::Failed)\n        })\n        .collect::<Result<Vec<_>, _>>()?;\n\n    if expr.arms.len() != concrete_variants.len() {\n        return Err(LoweringFlowError::Failed(\n            ctx.diagnostics.report(expr.stable_ptr.untyped(), UnsupportedMatch),\n        ));\n    }\n    if concrete_variants.is_empty() {\n        return Err(LoweringFlowError::Failed(\n            ctx.diagnostics.report(expr.stable_ptr.untyped(), UnsupportedMatchEmptyEnum),\n        ));\n    }\n\n    Ok(ExtractedEnumDetails { concrete_enum_id, concrete_variants, n_snapshots })\n}\n\n/// Lowers a sequence of expressions and return them all. If the flow ended in the middle,\n/// propagates that flow error without returning any variable.\nfn lower_exprs_as_vars(\n    ctx: &mut LoweringContext<'_>,\n    args: &[semantic::ExprFunctionCallArg],\n    scope: &mut BlockBuilder,\n) -> Result<Vec<VariableId>, LoweringFlowError> {\n    // Since value expressions may depends on the same variables as the references, which must be\n    // variables, all expressions must be evaluated before using the references for binding into the\n    // call.\n    // TODO(orizi): Consider changing this to disallow taking a reference and then using the\n    // variable, while still allowing `arr.append(arr.len())`.\n    let mut value_iter = args\n        .iter()\n        .filter_map(|arg| try_extract_matches!(arg, ExprFunctionCallArg::Value))\n        .map(|arg_expr_id| lower_expr(ctx, scope, *arg_expr_id)?.var(ctx, scope))\n        .collect::<Result<Vec<_>, _>>()?\n        .into_iter();\n    Ok(args\n        .iter()\n        .map(|arg| match arg {\n            semantic::ExprFunctionCallArg::Reference(ref_arg) => {\n                scope.get_ref(ctx, ref_arg).unwrap()\n            }\n            semantic::ExprFunctionCallArg::Value(_) => value_iter.next().unwrap(),\n        })\n        .collect())\n}\n\n/// Lowers an expression of type [semantic::ExprEnumVariantCtor].\nfn lower_expr_enum_ctor(\n    ctx: &mut LoweringContext<'_>,\n    expr: &semantic::ExprEnumVariantCtor,\n    scope: &mut BlockBuilder,\n) -> LoweringResult<LoweredExpr> {\n    log::trace!(\n        \"Started lowering of an enum c'tor expression: {:?}\",\n        expr.debug(&ctx.expr_formatter)\n    );\n    let location = ctx.get_location(expr.stable_ptr.untyped());\n    Ok(LoweredExpr::AtVariable(\n        generators::EnumConstruct {\n            input: lower_expr(ctx, scope, expr.value_expr)?.var(ctx, scope)?,\n            variant: expr.variant.clone(),\n            location,\n        }\n        .add(ctx, &mut scope.statements),\n    ))\n}\n\n/// Lowers an expression of type [semantic::ExprMemberAccess].\nfn lower_expr_member_access(\n    ctx: &mut LoweringContext<'_>,\n    expr: &semantic::ExprMemberAccess,\n    scope: &mut BlockBuilder,\n) -> LoweringResult<LoweredExpr> {\n    log::trace!(\"Lowering a member-access expression: {:?}\", expr.debug(&ctx.expr_formatter));\n    let location = ctx.get_location(expr.stable_ptr.untyped());\n    let members = ctx\n        .db\n        .concrete_struct_members(expr.concrete_struct_id)\n        .map_err(LoweringFlowError::Failed)?;\n    let member_idx =\n        members.iter().position(|(_, member)| member.id == expr.member).ok_or_else(|| {\n            LoweringFlowError::Failed(\n                ctx.diagnostics.report(expr.stable_ptr.untyped(), UnsupportedMatch),\n            )\n        })?;\n    if let Some(member_path) = &expr.member_path {\n        if let Some(var) = scope.get_ref(ctx, member_path) {\n            return Ok(LoweredExpr::AtVariable(var));\n        }\n    }\n    Ok(LoweredExpr::AtVariable(\n        generators::StructMemberAccess {\n            input: lower_expr(ctx, scope, expr.expr)?.var(ctx, scope)?,\n            member_tys: members\n                .into_iter()\n                .map(|(_, member)| wrap_in_snapshots(ctx.db.upcast(), member.ty, expr.n_snapshots))\n                .collect(),\n            member_idx,\n            location,\n        }\n        .add(ctx, &mut scope.statements),\n    ))\n}\n\n/// Lowers an expression of type [semantic::ExprStructCtor].\nfn lower_expr_struct_ctor(\n    ctx: &mut LoweringContext<'_>,\n    expr: &semantic::ExprStructCtor,\n    scope: &mut BlockBuilder,\n) -> LoweringResult<LoweredExpr> {\n    log::trace!(\"Lowering a struct c'tor expression: {:?}\", expr.debug(&ctx.expr_formatter));\n    let location = ctx.get_location(expr.stable_ptr.untyped());\n    let members = ctx\n        .db\n        .concrete_struct_members(expr.concrete_struct_id)\n        .map_err(LoweringFlowError::Failed)?;\n    let member_expr = UnorderedHashMap::from_iter(expr.members.iter().cloned());\n    Ok(LoweredExpr::AtVariable(\n        generators::StructConstruct {\n            inputs: members\n                .into_iter()\n                .map(|(_, member)| lower_expr(ctx, scope, member_expr[member.id])?.var(ctx, scope))\n                .collect::<Result<Vec<_>, _>>()?,\n            ty: expr.ty,\n            location,\n        }\n        .add(ctx, &mut scope.statements),\n    ))\n}\n\n/// Lowers an expression of type [semantic::ExprPropagateError].\nfn lower_expr_error_propagate(\n    ctx: &mut LoweringContext<'_>,\n    expr: &semantic::ExprPropagateError,\n    scope: &mut BlockBuilder,\n) -> LoweringResult<LoweredExpr> {\n    log::trace!(\n        \"Started lowering of an error-propagate expression: {:?}\",\n        expr.debug(&ctx.expr_formatter)\n    );\n    let location = ctx.get_location(expr.stable_ptr.untyped());\n    let lowered_expr = lower_expr(ctx, scope, expr.inner)?;\n    let ExprPropagateError { ok_variant, err_variant, func_err_variant, .. } = expr;\n    if let LoweredExpr::ExternEnum(extern_enum) = lowered_expr {\n        return lower_optimized_extern_error_propagate(\n            ctx,\n            scope,\n            extern_enum,\n            ok_variant,\n            err_variant,\n            func_err_variant,\n            location,\n        );\n    }\n\n    let var = lowered_expr.var(ctx, scope)?;\n    // Ok arm.\n    let subscope_ok = create_subscope_with_bound_refs(ctx, scope);\n    let block_ok_id = subscope_ok.block_id;\n    let expr_var = ctx.new_var(VarRequest { ty: ok_variant.ty, location });\n    let sealed_block_ok = subscope_ok.goto_callsite(Some(expr_var));\n\n    // Err arm.\n    let mut subscope_err = create_subscope_with_bound_refs(ctx, scope);\n    let block_err_id = subscope_err.block_id;\n    let err_value = ctx.new_var(VarRequest { ty: err_variant.ty, location });\n    let err_res =\n        generators::EnumConstruct { input: err_value, variant: func_err_variant.clone(), location }\n            .add(ctx, &mut subscope_err.statements);\n    subscope_err.ret(ctx, err_res, location).map_err(LoweringFlowError::Failed)?;\n    let sealed_block_err = SealedBlockBuilder::Ends(block_err_id);\n\n    // Merge blocks.\n    let match_info = MatchInfo::Enum(MatchEnumInfo {\n        concrete_enum_id: ok_variant.concrete_enum_id,\n        input: var,\n        arms: vec![\n            MatchArm {\n                variant_id: ok_variant.clone(),\n                block_id: block_ok_id,\n                var_ids: vec![expr_var],\n            },\n            MatchArm {\n                variant_id: err_variant.clone(),\n                block_id: block_err_id,\n                var_ids: vec![err_value],\n            },\n        ],\n    });\n    scope.merge_and_end_with_match(\n        ctx,\n        match_info,\n        vec![sealed_block_ok, sealed_block_err],\n        location,\n    )\n}\n\n/// Lowers an error propagation expression on a LoweredExpr::ExternEnum lowered expression.\nfn lower_optimized_extern_error_propagate(\n    ctx: &mut LoweringContext<'_>,\n    scope: &mut BlockBuilder,\n    extern_enum: LoweredExprExternEnum,\n    ok_variant: &semantic::ConcreteVariant,\n    err_variant: &semantic::ConcreteVariant,\n    func_err_variant: &semantic::ConcreteVariant,\n    location: StableLocationOption,\n) -> LoweringResult<LoweredExpr> {\n    log::trace!(\"Started lowering of an optimized error-propagate expression.\");\n\n    // Ok arm.\n    let mut subscope_ok = create_subscope(ctx, scope);\n    let block_ok_id = subscope_ok.block_id;\n    let input_tys = match_extern_variant_arm_input_types(ctx, ok_variant.ty, &extern_enum);\n    let mut input_vars: Vec<VariableId> =\n        input_tys.into_iter().map(|ty| ctx.new_var(VarRequest { ty, location })).collect();\n    let block_ok_input_vars = input_vars.clone();\n    match_extern_arm_ref_args_bind(ctx, &mut input_vars, &extern_enum, &mut subscope_ok);\n    let expr =\n        extern_facade_expr(ctx, ok_variant.ty, input_vars, location).var(ctx, &mut subscope_ok)?;\n    let sealed_block_ok = subscope_ok.goto_callsite(Some(expr));\n\n    // Err arm.\n    let mut subscope_err = create_subscope(ctx, scope);\n    let block_err_id = subscope_err.block_id;\n    let input_tys = match_extern_variant_arm_input_types(ctx, err_variant.ty, &extern_enum);\n    let mut input_vars: Vec<VariableId> =\n        input_tys.into_iter().map(|ty| ctx.new_var(VarRequest { ty, location })).collect();\n    let block_err_input_vars = input_vars.clone();\n\n    match_extern_arm_ref_args_bind(ctx, &mut input_vars, &extern_enum, &mut subscope_err);\n    let expr = extern_facade_expr(ctx, err_variant.ty, input_vars, location);\n    let input = expr.var(ctx, &mut subscope_err)?;\n    let err_res = generators::EnumConstruct { input, variant: func_err_variant.clone(), location }\n        .add(ctx, &mut subscope_err.statements);\n    subscope_err.ret(ctx, err_res, location).map_err(LoweringFlowError::Failed)?;\n    let sealed_block_err = SealedBlockBuilder::Ends(block_err_id);\n\n    // Merge.\n    let match_info = MatchInfo::Extern(MatchExternInfo {\n        function: extern_enum.function,\n        inputs: extern_enum.inputs,\n        arms: vec![\n            MatchArm {\n                variant_id: ok_variant.clone(),\n                block_id: block_ok_id,\n                var_ids: block_ok_input_vars,\n            },\n            MatchArm {\n                variant_id: err_variant.clone(),\n                block_id: block_err_id,\n                var_ids: block_err_input_vars,\n            },\n        ],\n        location,\n    });\n    scope.merge_and_end_with_match(\n        ctx,\n        match_info,\n        vec![sealed_block_ok, sealed_block_err],\n        location,\n    )\n}\n\n/// Returns the input types for an extern match variant arm.\nfn match_extern_variant_arm_input_types(\n    ctx: &mut LoweringContext<'_>,\n    ty: semantic::TypeId,\n    extern_enum: &LoweredExprExternEnum,\n) -> Vec<semantic::TypeId> {\n    let variant_input_tys = extern_facade_return_tys(ctx, ty);\n    let ref_tys = extern_enum.member_paths.iter().map(|ref_arg| ref_arg.ty());\n    chain!(ref_tys, variant_input_tys.into_iter()).collect()\n}\n\n/// Binds input references and implicits when matching on extern functions.\nfn match_extern_arm_ref_args_bind(\n    ctx: &mut LoweringContext<'_>,\n    arm_inputs: &mut Vec<VariableId>,\n    extern_enum: &LoweredExprExternEnum,\n    subscope: &mut BlockBuilder,\n) {\n    let ref_outputs: Vec<_> = arm_inputs.drain(0..extern_enum.member_paths.len()).collect();\n    // Bind the ref parameters.\n    for (ref_arg, output_var) in zip_eq(&extern_enum.member_paths, ref_outputs) {\n        subscope.update_ref(ctx, ref_arg, output_var);\n    }\n}\n\n/// Lowers an expression of type [semantic::ExprAssignment].\nfn lower_expr_assignment(\n    ctx: &mut LoweringContext<'_>,\n    expr: &semantic::ExprAssignment,\n    scope: &mut BlockBuilder,\n) -> LoweringResult<LoweredExpr> {\n    log::trace!(\n        \"Started lowering of an assignment expression: {:?}\",\n        expr.debug(&ctx.expr_formatter)\n    );\n    let location = ctx.get_location(expr.stable_ptr.untyped());\n    let var = lower_expr(ctx, scope, expr.rhs)?.var(ctx, scope)?;\n    scope.update_ref(ctx, &expr.ref_arg, var);\n    Ok(LoweredExpr::Tuple { exprs: vec![], location })\n}\n\n/// Allocates and empty block in `ctx`.\nfn alloc_empty_block(ctx: &mut LoweringContext<'_>) -> BlockId {\n    ctx.blocks.alloc_empty()\n}\n\n/// Creates a new subscope of the given scope, with an empty block.\nfn create_subscope_with_bound_refs(\n    ctx: &mut LoweringContext<'_>,\n    scope: &BlockBuilder,\n) -> BlockBuilder {\n    scope.subscope_with_bound_refs(alloc_empty_block(ctx))\n}\n\n/// Creates a new subscope of the given scope, with unchanged refs and with an empty block.\nfn create_subscope(ctx: &mut LoweringContext<'_>, scope: &BlockBuilder) -> BlockBuilder {\n    scope.subscope(alloc_empty_block(ctx))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_defs::ids::MemberId;\nuse cairo_lang_semantic as semantic;\nuse cairo_lang_utils::extract_matches;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse semantic::VarMemberPath;\n\nuse crate::VariableId;\n\n/// Maps member paths ([VarMemberPath]) to lowered variable ids.\n#[derive(Clone, Default, Debug)]\npub struct SemanticLoweringMapping {\n    scattered: OrderedHashMap<semantic::VarId, Value>,\n}\nimpl SemanticLoweringMapping {\n    pub fn contains_semantic_var(&mut self, semantic_var: &semantic::VarId) -> bool {\n        self.scattered.contains_key(semantic_var)\n    }\n\n    pub fn get_semantic_var<TContext: StructRecomposer>(\n        &mut self,\n        mut ctx: TContext,\n        semantic_var: &semantic::VarId,\n    ) -> Option<VariableId> {\n        let value = self.scattered.get_mut(semantic_var)?;\n        Self::assemble_value(&mut ctx, value)\n    }\n\n    pub fn get_member_path<TContext: StructRecomposer>(\n        &mut self,\n        mut ctx: TContext,\n        member_path: &VarMemberPath,\n    ) -> Option<VariableId> {\n        let value = self.break_into_value(&mut ctx, member_path)?;\n        Self::assemble_value(&mut ctx, value)\n    }\n\n    pub fn insert_semantic_var(&mut self, semantic_var: semantic::VarId, var: VariableId) {\n        self.scattered.insert(semantic_var, Value::Var(var));\n    }\n\n    pub fn update_member_path<TContext: StructRecomposer>(\n        &mut self,\n        mut ctx: TContext,\n        member_path: &VarMemberPath,\n        var: VariableId,\n    ) -> Option<()> {\n        let value = self.break_into_value(&mut ctx, member_path)?;\n        *value = Value::Var(var);\n        Some(())\n    }\n\n    fn assemble_value<TContext: StructRecomposer>(\n        ctx: &mut TContext,\n        value: &mut Value,\n    ) -> Option<VariableId> {\n        Some(match value {\n            Value::Var(var) => *var,\n            Value::Scattered(scattered) => {\n                let members = scattered\n                    .members\n                    .iter_mut()\n                    .map(|(_, value)| Self::assemble_value(ctx, value))\n                    .collect::<Option<_>>()?;\n                let var = ctx.reconstruct(scattered.concrete_struct_id, members);\n                *value = Value::Var(var);\n                var\n            }\n        })\n    }\n\n    fn break_into_value<TContext: StructRecomposer>(\n        &mut self,\n        ctx: &mut TContext,\n        member_path: &VarMemberPath,\n    ) -> Option<&mut Value> {\n        match member_path {\n            VarMemberPath::Var(expr) => self.scattered.get_mut(&expr.var),\n            VarMemberPath::Member { parent, member_id, concrete_struct_id, .. } => {\n                let parent_value = self.break_into_value(ctx, parent)?;\n                match parent_value {\n                    Value::Var(var) => {\n                        // TODO: Emit destruct statement.\n                        let members = ctx.deconstruct(*concrete_struct_id, *var);\n                        let members = OrderedHashMap::from_iter(\n                            members\n                                .into_iter()\n                                .map(|(member_id, var)| (member_id, Value::Var(var))),\n                        );\n                        let scattered =\n                            Scattered { concrete_struct_id: *concrete_struct_id, members };\n                        *parent_value = Value::Scattered(Box::new(scattered));\n\n                        extract_matches!(parent_value, Value::Scattered).members.get_mut(member_id)\n                    }\n                    Value::Scattered(scattered) => scattered.members.get_mut(member_id),\n                }\n            }\n        }\n    }\n}\n\n/// A trait for deconstructing and constructing structs.\npub trait StructRecomposer {\n    fn deconstruct(\n        &mut self,\n        concrete_struct_id: semantic::ConcreteStructId,\n        value: VariableId,\n    ) -> OrderedHashMap<MemberId, VariableId>;\n    fn reconstruct(\n        &mut self,\n        concrete_struct_id: semantic::ConcreteStructId,\n        members: Vec<VariableId>,\n    ) -> VariableId;\n    fn var_ty(&self, var: VariableId) -> semantic::TypeId;\n}\n\n/// An intermediate value for a member path.\n#[derive(Clone, Debug)]\nenum Value {\n    /// The value of member path is stored in a lowered variable.\n    Var(VariableId),\n    /// The value of the member path is not stored. It should be reconstructed from the member\n    /// values.\n    Scattered(Box<Scattered>),\n}\n\n/// A value for an non-stored member path. Recursively holds the [Value] for the members.\n#[derive(Clone, Debug)]\nstruct Scattered {\n    concrete_struct_id: semantic::ConcreteStructId,\n    members: OrderedHashMap<MemberId, Value>,\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_defs::diagnostic_utils::StableLocationOption;\nuse cairo_lang_defs::ids::MemberId;\nuse cairo_lang_diagnostics::Maybe;\nuse cairo_lang_semantic as semantic;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse cairo_lang_utils::ordered_hash_set::OrderedHashSet;\nuse itertools::{chain, zip_eq, Itertools};\nuse semantic::items::structure::SemanticStructEx;\nuse semantic::{ConcreteTypeId, TypeLongId, VarMemberPath};\n\nuse super::context::{LoweredExpr, LoweringContext, LoweringFlowError, LoweringResult, VarRequest};\nuse super::generators;\nuse super::generators::StatementsBuilder;\nuse super::refs::{SemanticLoweringMapping, StructRecomposer};\nuse crate::diagnostic::LoweringDiagnosticKind;\nuse crate::{BlockId, FlatBlock, FlatBlockEnd, MatchInfo, Statement, VarRemapping, VariableId};\n\n/// FlatBlock builder, describing its current state.\n#[derive(Clone)]\npub struct BlockBuilder {\n    /// A store for semantic variables, owning their OwnedVariable instances.\n    semantics: SemanticLoweringMapping,\n    /// The semantic variables that are added/changed in this block.\n    changed_semantics: OrderedHashSet<semantic::VarId>,\n    /// Current sequence of lowered statements emitted.\n    pub statements: StatementsBuilder,\n    /// The block id to use for this block when it's finalized.\n    pub block_id: BlockId,\n}\nimpl BlockBuilder {\n    /// Creates a new [BlockBuilder] for the root block of a function body.\n    pub fn root(_ctx: &LoweringContext<'_>, block_id: BlockId) -> Self {\n        BlockBuilder {\n            semantics: Default::default(),\n            changed_semantics: Default::default(),\n            statements: Default::default(),\n            block_id,\n        }\n    }\n\n    /// Creates a [BlockBuilder] for a subscope.\n    pub fn subscope(&self, block_id: BlockId) -> BlockBuilder {\n        BlockBuilder {\n            semantics: self.semantics.clone(),\n            changed_semantics: Default::default(),\n            statements: Default::default(),\n            block_id,\n        }\n    }\n\n    /// Creates a [BlockBuilder] for a subscope with unchanged refs.\n    pub fn subscope_with_bound_refs(&self, block_id: BlockId) -> BlockBuilder {\n        self.subscope(block_id)\n    }\n\n    /// Creates a [BlockBuilder] for a sibling scope. This is used when an original block is split\n    /// (e.g. after a match statement) to add the ability to 'goto' to after-the-block.\n    pub fn sibling_scope(&self, block_id: BlockId) -> BlockBuilder {\n        BlockBuilder {\n            semantics: self.semantics.clone(),\n            changed_semantics: self.changed_semantics.clone(),\n            statements: Default::default(),\n            block_id,\n        }\n    }\n\n    /// Binds a semantic variable to a lowered variable.\n    pub fn put_semantic(&mut self, semantic_var_id: semantic::VarId, var: VariableId) {\n        self.semantics.insert_semantic_var(semantic_var_id, var);\n        self.changed_semantics.insert(semantic_var_id);\n    }\n\n    pub fn update_ref(\n        &mut self,\n        ctx: &mut LoweringContext<'_>,\n        member_path: &VarMemberPath,\n        var: VariableId,\n    ) {\n        let location = ctx.get_location(member_path.stable_ptr().untyped());\n        self.semantics.update_member_path(\n            BlockStructRecomposer { statements: &mut self.statements, ctx, location },\n            member_path,\n            var,\n        );\n        self.changed_semantics.insert(member_path.base_var());\n    }\n\n    pub fn get_ref(\n        &mut self,\n        ctx: &mut LoweringContext<'_>,\n        member_path: &VarMemberPath,\n    ) -> Option<VariableId> {\n        let location = ctx.get_location(member_path.stable_ptr().untyped());\n        self.semantics.get_member_path(\n            BlockStructRecomposer { statements: &mut self.statements, ctx, location },\n            member_path,\n        )\n    }\n\n    /// Gets the current lowered variable bound to a semantic variable.\n    pub fn get_semantic(\n        &mut self,\n        ctx: &mut LoweringContext<'_>,\n        semantic_var_id: semantic::VarId,\n        location: StableLocationOption,\n    ) -> VariableId {\n        self.semantics\n            .get_semantic_var(\n                BlockStructRecomposer { statements: &mut self.statements, ctx, location },\n                &semantic_var_id,\n            )\n            .expect(\"Use of undefined variable cannot happen after semantic phase.\")\n    }\n\n    /// Adds a statement to the block.\n    pub fn push_statement(&mut self, statement: Statement) {\n        self.statements.push_statement(statement);\n    }\n\n    /// Ends a block with an unreachable match.\n    pub fn unreachable_match(self, ctx: &mut LoweringContext<'_>, match_info: MatchInfo) {\n        self.finalize(ctx, FlatBlockEnd::Match { info: match_info });\n    }\n\n    /// Ends a block with Panic.\n    pub fn panic(self, ctx: &mut LoweringContext<'_>, data: VariableId) -> Maybe<()> {\n        self.finalize(ctx, FlatBlockEnd::Panic(data));\n        Ok(())\n    }\n\n    /// Ends a block with Callsite.\n    pub fn goto_callsite(self, expr: Option<VariableId>) -> SealedBlockBuilder {\n        SealedBlockBuilder::GotoCallsite { scope: self, expr }\n    }\n\n    /// Ends a block with Return.\n    pub fn ret(\n        mut self,\n        ctx: &mut LoweringContext<'_>,\n        expr: VariableId,\n        location: StableLocationOption,\n    ) -> Maybe<()> {\n        let ref_vars = ctx\n            .ref_params\n            .iter()\n            .map(|semantic_var_id| {\n                self.semantics.get_semantic_var(\n                    BlockStructRecomposer { statements: &mut self.statements, ctx, location },\n                    semantic_var_id,\n                )\n            })\n            .collect::<Option<Vec<_>>>()\n            .ok_or_else(|| {\n                ctx.diagnostics\n                    .report_by_location(location, LoweringDiagnosticKind::UnsupportedMatch)\n            })?;\n\n        self.finalize(ctx, FlatBlockEnd::Return(chain!(ref_vars, [expr]).collect()));\n        Ok(())\n    }\n\n    /// Ends a block with known ending information. Used by [SealedBlockBuilder].\n    fn finalize(self, ctx: &mut LoweringContext<'_>, end: FlatBlockEnd) {\n        let block = FlatBlock { statements: self.statements.statements, end };\n        ctx.blocks.set_block(self.block_id, block);\n    }\n\n    /// Merges the sealed blocks and ends the block with a match-end.\n    /// Replaces `self` with a sibling scope.\n    pub fn merge_and_end_with_match(\n        &mut self,\n        ctx: &mut LoweringContext<'_>,\n        match_info: MatchInfo,\n        sealed_blocks: Vec<SealedBlockBuilder>,\n        location: StableLocationOption,\n    ) -> LoweringResult<LoweredExpr> {\n        let Some((merged_expr, following_block)) = self.merge_sealed(ctx, sealed_blocks, location) else {\n            return Err(LoweringFlowError::Match(match_info));\n        };\n\n        let new_scope = self.sibling_scope(following_block);\n        let prev_scope = std::mem::replace(self, new_scope);\n        prev_scope.finalize(ctx, FlatBlockEnd::Match { info: match_info });\n        Ok(merged_expr)\n    }\n\n    /// Merges sibling sealed blocks.\n    /// If there are reachable blocks, returns the converged expression of the blocks, usable at the\n    /// calling scope, and the following block ID.\n    /// Otherwise, returns None.\n    fn merge_sealed(\n        &mut self,\n        ctx: &mut LoweringContext<'_>,\n        sealed_blocks: Vec<SealedBlockBuilder>,\n        location: StableLocationOption,\n    ) -> Option<(LoweredExpr, BlockId)> {\n        // TODO(spapini): When adding Gotos, include the callsite target in the required information\n        // to merge.\n        // TODO(spapini): Don't remap if we have a single reachable branch.\n\n        let mut semantic_remapping = SemanticRemapping::default();\n        let mut n_reachable_blocks = 0;\n\n        // Remap Variables from all blocks.\n        for sealed_block in &sealed_blocks {\n            let SealedBlockBuilder::GotoCallsite { scope: subscope, expr } = sealed_block else {\n            continue;\n        };\n            n_reachable_blocks += 1;\n            if let Some(var) = expr {\n                semantic_remapping.expr.get_or_insert_with(|| {\n                    let var = ctx.variables[*var].clone();\n                    ctx.variables.alloc(var)\n                });\n            }\n            for semantic in subscope.changed_semantics.iter() {\n                if !self.semantics.contains_semantic_var(semantic) {\n                    // This variable is local to the subscope.\n                    continue;\n                }\n                // This variable belongs to an outer scope, and it is changed in at least one\n                // branch. It should be remapped.\n                semantic_remapping.semantics.entry(*semantic).or_insert_with(|| {\n                    let var = self.get_semantic(ctx, *semantic, location);\n                    let var = ctx.variables[var].clone();\n                    ctx.variables.alloc(var)\n                });\n            }\n        }\n\n        if n_reachable_blocks == 0 {\n            return None;\n        }\n\n        // If there are reachable blocks, create a new empty block for the code after this match.\n        let following_block = ctx.blocks.alloc_empty();\n\n        for sealed_block in sealed_blocks {\n            sealed_block.finalize(ctx, following_block, &semantic_remapping, location);\n        }\n\n        // Apply remapping on scope.\n        for (semantic, var) in semantic_remapping.semantics {\n            self.put_semantic(semantic, var);\n        }\n\n        let expr = match semantic_remapping.expr {\n            Some(var) => LoweredExpr::AtVariable(var),\n            None => LoweredExpr::Tuple { exprs: vec![], location },\n        };\n        Some((expr, following_block))\n    }\n}\n\n/// Remapping of lowered variables with more semantic information regarding what is the semantic\n/// role of the lowered variables.\n#[derive(Debug, Default)]\npub struct SemanticRemapping {\n    expr: Option<VariableId>,\n    semantics: OrderedHashMap<semantic::VarId, VariableId>,\n}\n\n/// A sealed BlockBuilder, ready to be merged with sibling blocks to end the block.\n#[allow(clippy::large_enum_variant)]\npub enum SealedBlockBuilder {\n    /// Block should end by goto callsite. `expr` may be None for blocks that return the unit type.\n    GotoCallsite { scope: BlockBuilder, expr: Option<VariableId> },\n    /// Block end is already known.\n    Ends(BlockId),\n}\nimpl SealedBlockBuilder {\n    /// Finalizes a non-finalized block, given the semantic remapping of variables and the target\n    /// block to jump to.\n    fn finalize(\n        self,\n        ctx: &mut LoweringContext<'_>,\n        target: BlockId,\n        semantic_remapping: &SemanticRemapping,\n        location: StableLocationOption,\n    ) {\n        if let SealedBlockBuilder::GotoCallsite { mut scope, expr } = self {\n            let mut remapping = VarRemapping::default();\n            // Since SemanticRemapping should have unique variable ids, these asserts will pass.\n            for (semantic, remapped_var) in semantic_remapping.semantics.iter() {\n                assert!(\n                    remapping\n                        .insert(*remapped_var, scope.get_semantic(ctx, *semantic, location))\n                        .is_none()\n                );\n            }\n            if let Some(remapped_var) = semantic_remapping.expr {\n                let expr = expr.unwrap_or_else(|| {\n                    LoweredExpr::Tuple {\n                        exprs: vec![],\n                        location: ctx.variables[remapped_var].location,\n                    }\n                    .var(ctx, &mut scope)\n                    .unwrap()\n                });\n                assert!(remapping.insert(remapped_var, expr).is_none());\n            }\n\n            scope.finalize(ctx, FlatBlockEnd::Goto(target, remapping));\n        }\n    }\n}\n\nstruct BlockStructRecomposer<'a, 'b> {\n    statements: &'a mut StatementsBuilder,\n    ctx: &'a mut LoweringContext<'b>,\n    location: StableLocationOption,\n}\nimpl<'a, 'b> StructRecomposer for BlockStructRecomposer<'a, 'b> {\n    fn deconstruct(\n        &mut self,\n        concrete_struct_id: semantic::ConcreteStructId,\n        value: VariableId,\n    ) -> OrderedHashMap<MemberId, VariableId> {\n        let members = self.ctx.db.concrete_struct_members(concrete_struct_id).unwrap();\n        let members = members.values().collect_vec();\n        let member_ids = members.iter().map(|m| m.id);\n        let var_reqs = members\n            .iter()\n            .map(|member| VarRequest { ty: member.ty, location: self.location })\n            .collect();\n        let member_values =\n            generators::StructDestructure { input: value, var_reqs }.add(self.ctx, self.statements);\n        OrderedHashMap::from_iter(zip_eq(member_ids, member_values))\n    }\n\n    fn reconstruct(\n        &mut self,\n        concrete_struct_id: semantic::ConcreteStructId,\n        members: Vec<VariableId>,\n    ) -> VariableId {\n        let ty = self\n            .ctx\n            .db\n            .intern_type(TypeLongId::Concrete(ConcreteTypeId::Struct(concrete_struct_id)));\n        generators::StructConstruct { inputs: members, ty, location: self.location }\n            .add(self.ctx, self.statements)\n    }\n\n    fn var_ty(&self, var: VariableId) -> semantic::TypeId {\n        self.ctx.variables[var].ty\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::ops::{Index, IndexMut};\n\nuse cairo_lang_diagnostics::{DiagnosticAdded, Maybe};\n\nuse crate::FlatBlock;\n\n#[derive(Copy, Clone, Debug, PartialEq, Eq, Hash)]\npub struct BlockId(pub usize);\nimpl BlockId {\n    pub fn root() -> Self {\n        Self(0)\n    }\n\n    pub fn is_root(&self) -> bool {\n        self.0 == 0\n    }\n\n    pub fn next_block_id(&self) -> BlockId {\n        BlockId(self.0 + 1)\n    }\n}\n\n/// A convenient wrapper around a vector of blocks.\n/// This is used instead of id_arena, since the latter is harder to clone and modify.\n#[derive(Clone, Debug, Default, PartialEq, Eq)]\npub struct BlocksBuilder<T>(pub Vec<T>);\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct Blocks<T>(Vec<T>);\n\nimpl<T: Default> BlocksBuilder<T> {\n    pub fn new() -> Self {\n        Self(vec![])\n    }\n    pub fn alloc(&mut self, block: T) -> BlockId {\n        let id = BlockId(self.0.len());\n        self.0.push(block);\n        id\n    }\n    /// Allocate a new block ID. The block itself should be populated later.\n    pub fn alloc_empty(&mut self) -> BlockId {\n        let id = BlockId(self.0.len());\n        self.0.push(T::default());\n        id\n    }\n    /// Sets an already-allocated block.\n    pub fn set_block(&mut self, id: BlockId, block: T) {\n        self.0[id.0] = block;\n    }\n\n    pub fn len(&self) -> usize {\n        self.0.len()\n    }\n\n    pub fn is_empty(&self) -> bool {\n        self.0.is_empty()\n    }\n\n    pub fn build(self) -> Option<Blocks<T>> {\n        if self.is_empty() {\n            return None;\n        }\n        Some(Blocks(self.0))\n    }\n}\nimpl<T: Default> Blocks<T> {\n    pub fn new_errored(_diag_added: DiagnosticAdded) -> Self {\n        Self(vec![])\n    }\n\n    pub fn get(&self) -> &Vec<T> {\n        &self.0\n    }\n\n    pub fn len(&self) -> usize {\n        self.0.len()\n    }\n\n    pub fn is_empty(&self) -> bool {\n        self.0.is_empty()\n    }\n\n    pub fn iter(&self) -> BlocksIter<'_, T> {\n        self.into_iter()\n    }\n\n    // Note: It is safe to create DiagnosticAdded here, since BlocksBuilder::build() guarantees to\n    // build a non empty Blocks. The only way to create an empty Blocks is using\n    // `new_errored(DiagnosticAdded)`.\n    pub fn root_block(&self) -> Maybe<&T> {\n        if self.is_empty() { Err(DiagnosticAdded) } else { Ok(&self.0[0]) }\n    }\n\n    pub fn has_root(&self) -> Maybe<()> {\n        if self.is_empty() { Err(DiagnosticAdded) } else { Ok(()) }\n    }\n\n    pub fn iter_mut(&mut self) -> std::slice::IterMut<'_, T> {\n        self.0.iter_mut()\n    }\n}\nimpl<T> Index<BlockId> for Blocks<T> {\n    type Output = T;\n\n    fn index(&self, index: BlockId) -> &Self::Output {\n        &self.0[index.0]\n    }\n}\nimpl<T> IndexMut<BlockId> for Blocks<T> {\n    fn index_mut(&mut self, index: BlockId) -> &mut Self::Output {\n        &mut self.0[index.0]\n    }\n}\nimpl<'a, T> IntoIterator for &'a Blocks<T> {\n    type Item = (BlockId, &'a T);\n    type IntoIter = BlocksIter<'a, T>;\n\n    fn into_iter(self) -> Self::IntoIter {\n        BlocksIter { blocks: self, index: 0 }\n    }\n}\npub struct BlocksIter<'a, T> {\n    pub blocks: &'a Blocks<T>,\n    pub index: usize,\n}\nimpl<'a, T> Iterator for BlocksIter<'a, T> {\n    type Item = (BlockId, &'a T);\n\n    fn next(&mut self) -> Option<Self::Item> {\n        self.blocks.0.get(self.index).map(|b| {\n            let res = (BlockId(self.index), b);\n            self.index += 1;\n            res\n        })\n    }\n}\n\npub type FlatBlocksBuilder = BlocksBuilder<FlatBlock>;\npub type FlatBlocks = Blocks<FlatBlock>;\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Intermediate representation objects after lowering from semantic.\n//! This representation is SSA (static single-assignment): each variable is defined before usage and\n//! assigned once. It is also normal form: each function argument is a variable, rather than a\n//! compound expression.\n\nuse std::ops::{Deref, DerefMut};\n\nuse cairo_lang_defs::diagnostic_utils::StableLocationOption;\nuse cairo_lang_diagnostics::Diagnostics;\nuse cairo_lang_semantic as semantic;\nuse cairo_lang_semantic::{ConcreteEnumId, ConcreteVariant};\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse id_arena::{Arena, Id};\nuse num_bigint::BigInt;\npub mod blocks;\npub use blocks::BlockId;\nuse semantic::expr::inference::InferenceResult;\nuse semantic::items::imp::ImplId;\n\nuse self::blocks::FlatBlocks;\nuse crate::diagnostic::LoweringDiagnostic;\n\npub type VariableId = Id<Variable>;\n\n/// A lowered function code using flat blocks.\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct FlatLowered {\n    /// Diagnostics produced while lowering.\n    pub diagnostics: Diagnostics<LoweringDiagnostic>,\n    /// Arena of allocated lowered variables.\n    pub variables: Arena<Variable>,\n    /// Arena of allocated lowered blocks.\n    pub blocks: FlatBlocks,\n    /// function paramaters, including implicits.\n    pub parameters: Vec<VariableId>,\n}\n\n/// Remapping of lowered variable ids. Useful for convergence of branches.\n#[derive(Clone, Debug, Default, PartialEq, Eq)]\npub struct VarRemapping {\n    /// Map from new_var to old_var (since new_var cannot appear twice, but old_var can).\n    pub remapping: OrderedHashMap<VariableId, VariableId>,\n}\nimpl Deref for VarRemapping {\n    type Target = OrderedHashMap<VariableId, VariableId>;\n\n    fn deref(&self) -> &Self::Target {\n        &self.remapping\n    }\n}\nimpl DerefMut for VarRemapping {\n    fn deref_mut(&mut self) -> &mut Self::Target {\n        &mut self.remapping\n    }\n}\n\n/// A block of statements. Unlike [`FlatBlock`], this has no reference information,\n/// and no panic ending.\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct FlatBlock {\n    /// Statements sequence running one after the other in the block, in a linear flow.\n    /// Note: Inner blocks might end with a `return`, which will exit the function in the middle.\n    /// Note: Match is a possible statement, which means it has control flow logic inside, but\n    /// after its execution is completed, the flow returns to the following statement of the block.\n    pub statements: Vec<Statement>,\n    /// Describes how this block ends: returns to the caller or exits the function.\n    pub end: FlatBlockEnd,\n}\nimpl Default for FlatBlock {\n    fn default() -> Self {\n        Self { statements: Default::default(), end: FlatBlockEnd::NotSet }\n    }\n}\nimpl FlatBlock {\n    pub fn is_set(&self) -> bool {\n        !matches!(self.end, FlatBlockEnd::NotSet)\n    }\n}\n\n/// Describes what happens to the program flow at the end of a [`FlatBlock`].\n#[derive(Clone, Debug, PartialEq, Eq)]\npub enum FlatBlockEnd {\n    /// The block was created but still needs to be populated. Block must not be in this state in\n    /// the end of the lowering phase.\n    NotSet,\n    /// This block ends with a `return` statement, exiting the function.\n    Return(Vec<VariableId>),\n    /// This block ends with a panic.\n    Panic(VariableId),\n    /// This block ends with a jump to a different block.\n    Goto(BlockId, VarRemapping),\n    Match {\n        info: MatchInfo,\n    },\n}\n\n/// Lowered variable representation.\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct Variable {\n    /// Can the type be (trivially) dropped.\n    pub droppable: InferenceResult<()>,\n    /// Can the type be (trivially) duplicated.\n    pub duplicatable: InferenceResult<()>,\n    /// A Destruct impl for the type, if found.\n    pub destruct_impl: InferenceResult<ImplId>,\n    /// Semantic type of the variable.\n    pub ty: semantic::TypeId,\n    /// Location of the variable.\n    pub location: StableLocationOption,\n}\n\n/// Lowered statement.\n#[derive(Clone, Debug, PartialEq, Eq)]\npub enum Statement {\n    // Values.\n    // TODO(spapini): Consts.\n    Literal(StatementLiteral),\n\n    // Flow control.\n    Call(StatementCall),\n\n    // Structs (including tuples).\n    StructConstruct(StatementStructConstruct),\n    StructDestructure(StatementStructDestructure),\n\n    // Enums.\n    EnumConstruct(StatementEnumConstruct),\n\n    Snapshot(StatementSnapshot),\n    Desnap(StatementDesnap),\n}\nimpl Statement {\n    pub fn inputs(&self) -> Vec<VariableId> {\n        match &self {\n            Statement::Literal(_stmt) => vec![],\n            Statement::Call(stmt) => stmt.inputs.clone(),\n            Statement::StructConstruct(stmt) => stmt.inputs.clone(),\n            Statement::StructDestructure(stmt) => vec![stmt.input],\n            Statement::EnumConstruct(stmt) => vec![stmt.input],\n            Statement::Snapshot(stmt) => vec![stmt.input],\n            Statement::Desnap(stmt) => vec![stmt.input],\n        }\n    }\n    pub fn outputs(&self) -> Vec<VariableId> {\n        match &self {\n            Statement::Literal(stmt) => vec![stmt.output],\n            Statement::Call(stmt) => stmt.outputs.clone(),\n            Statement::StructConstruct(stmt) => vec![stmt.output],\n            Statement::StructDestructure(stmt) => stmt.outputs.clone(),\n            Statement::EnumConstruct(stmt) => vec![stmt.output],\n            Statement::Snapshot(stmt) => vec![stmt.output_original, stmt.output_snapshot],\n            Statement::Desnap(stmt) => vec![stmt.output],\n        }\n    }\n}\n\n/// A statement that binds a literal value to a variable.\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct StatementLiteral {\n    /// The value of the literal.\n    pub value: BigInt,\n    /// The variable to bind the value to.\n    pub output: VariableId,\n}\n\n/// A statement that calls a user function.\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct StatementCall {\n    /// A function to \"call\".\n    pub function: semantic::FunctionId,\n    /// Living variables in current scope to move to the function, as arguments.\n    pub inputs: Vec<VariableId>,\n    /// New variables to be introduced into the current scope from the function outputs.\n    pub outputs: Vec<VariableId>,\n    /// Location for the call.\n    pub location: StableLocationOption,\n}\n\n/// A statement that construct a variant of an enum with a single argument, and binds it to a\n/// variable.\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct StatementEnumConstruct {\n    pub variant: ConcreteVariant,\n    /// A living variable in current scope to wrap with the variant.\n    pub input: VariableId,\n    /// The variable to bind the value to.\n    pub output: VariableId,\n}\n\n/// A statement that constructs a struct (tuple included) into a new variable.\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct StatementStructConstruct {\n    pub inputs: Vec<VariableId>,\n    /// The variable to bind the value to.\n    pub output: VariableId,\n}\n\n/// A statement that destructures a struct (tuple included), introducing its elements as new\n/// variables.\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct StatementStructDestructure {\n    /// A living variable in current scope to destructure.\n    pub input: VariableId,\n    /// The variables to bind values to.\n    pub outputs: Vec<VariableId>,\n}\n\n/// A statement that takes a snapshot of a variable.\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct StatementSnapshot {\n    pub input: VariableId,\n    pub output_original: VariableId,\n    pub output_snapshot: VariableId,\n}\n\n/// A statement that desnaps a variable.\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct StatementDesnap {\n    pub input: VariableId,\n    /// The variable to bind the value to.\n    pub output: VariableId,\n}\n\n/// An arm of a match statement.\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct MatchArm {\n    /// The id of the arm variant.\n    pub variant_id: ConcreteVariant,\n\n    /// The block_id where the relevent arm is implemented.\n    pub block_id: BlockId,\n\n    /// The list of variable ids introduced in this arm.\n    pub var_ids: Vec<VariableId>,\n}\n\n/// A statement that calls an extern function with branches, and \"calls\" a possibly different block\n/// for each branch.\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct MatchExternInfo {\n    // TODO(spapini): ConcreteExternFunctionId once it exists.\n    /// A concrete external function to call.\n    pub function: semantic::FunctionId,\n    /// Living variables in current scope to move to the function, as arguments.\n    pub inputs: Vec<VariableId>,\n    /// Match arms. All blocks should have the same rets.\n    /// Order must be identical to the order in the definition of the enum.\n    pub arms: Vec<MatchArm>,\n    /// Location for the call.\n    pub location: StableLocationOption,\n}\n\n/// A statement that matches an enum, and \"calls\" a possibly different block for each branch.\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct MatchEnumInfo {\n    pub concrete_enum_id: ConcreteEnumId,\n    /// A living variable in current scope to match on.\n    pub input: VariableId,\n    /// Match arms. All blocks should have the same rets.\n    /// Order must be identical to the order in the definition of the enum.\n    pub arms: Vec<MatchArm>,\n}\n\n#[derive(Clone, Debug, PartialEq, Eq)]\npub enum MatchInfo {\n    Enum(MatchEnumInfo),\n    Extern(MatchExternInfo),\n}\nimpl MatchInfo {\n    pub fn inputs(&self) -> Vec<VariableId> {\n        match self {\n            MatchInfo::Enum(s) => vec![s.input],\n            MatchInfo::Extern(s) => s.inputs.clone(),\n        }\n    }\n    pub fn arms(&self) -> &Vec<MatchArm> {\n        match self {\n            MatchInfo::Enum(s) => &s.arms,\n            MatchInfo::Extern(s) => &s.arms,\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "#[cfg(test)]\n#[path = \"match_optimizer_test.rs\"]\nmod test;\n\nuse itertools::{zip_eq, Itertools};\n\nuse crate::borrow_check::analysis::{Analyzer, BackAnalysis, StatementLocation};\nuse crate::borrow_check::demand::DemandReporter;\nuse crate::borrow_check::LoweredDemand;\nuse crate::{\n    BlockId, FlatBlockEnd, FlatLowered, MatchArm, MatchEnumInfo, MatchInfo, Statement,\n    StatementEnumConstruct, VarRemapping, VariableId,\n};\n\n/// Optimizes Statement::EnumConstruct that is follwed by a match to jump to the target of the\n/// relevent match arm.\npub fn optimize_matches(lowered: &mut FlatLowered) {\n    if !lowered.blocks.is_empty() {\n        let ctx = MatchOptimizerContext { fixes: vec![] };\n        let mut analysis =\n            BackAnalysis { lowered: &*lowered, cache: Default::default(), analyzer: ctx };\n        analysis.get_root_info();\n        let ctx = analysis.analyzer;\n\n        for FixInfo { statement_location, target_block, remapping } in ctx.fixes.into_iter() {\n            let block = &mut lowered.blocks[statement_location.0];\n\n            assert_eq!(\n                block.statements.len() - 1,\n                statement_location.1,\n                \"The optimization can only be applied to the last statment in the block.\"\n            );\n            block.statements.pop();\n\n            block.end = FlatBlockEnd::Goto(target_block, remapping)\n        }\n    }\n}\n\npub struct MatchOptimizerContext {\n    fixes: Vec<FixInfo>,\n}\n\nimpl MatchOptimizerContext {\n    /// Returns true if the statement can be optimized out and false otherwise.\n    /// If the statement can be optimized a fix info is added to `self.fixes`.\n    fn statement_can_be_optimized_out(\n        &mut self,\n        stmt: &Statement,\n        info: &mut AnalysisInfo,\n        statement_location: (BlockId, usize),\n    ) -> bool {\n        let Statement::EnumConstruct(StatementEnumConstruct {\n            variant, input, output }) = stmt else { return false;};\n        let Some(ref mut candidate) = &mut info.candidate else {return false;};\n        if *output != candidate.match_variable {\n            return false;\n        }\n        let (arm_idx, arm) = candidate\n            .match_arms\n            .iter()\n            .find_position(|arm| arm.variant_id == *variant)\n            .expect(\"arm not found.\");\n\n        let [var_id] = arm.var_ids.as_slice() else {\n            panic!(\"An arm of an EnumMatch should produce a single variable.\");\n        };\n\n        let mut demand = candidate.arm_demands[arm_idx].clone();\n\n        let mut remapping = VarRemapping::default();\n        if demand.vars.contains(var_id) {\n            // The input to EnumConstruct should be available as `var_id`\n            // in `arm.block_id`\n            remapping.insert(*var_id, *input);\n        }\n\n        demand.apply_remapping(self, remapping.iter().map(|(dst, src)| (*dst, *src)));\n        info.demand = demand;\n\n        self.fixes.push(FixInfo { statement_location, target_block: arm.block_id, remapping });\n        true\n    }\n}\n\nimpl DemandReporter<VariableId> for MatchOptimizerContext {\n    type IntroducePosition = ();\n    type UsePosition = ();\n}\n\npub struct FixInfo {\n    /// The location that needs to be fixed,\n    statement_location: (BlockId, usize),\n    /// The block That we want to jump to.\n    target_block: BlockId,\n    /// The variable remapping that should be applied.\n    remapping: VarRemapping,\n}\n\n#[derive(Clone)]\nstruct OptimizationCandidate {\n    /// The variable that is match.\n    match_variable: VariableId,\n\n    /// The match arms of the extern match that we are optimizing.\n    match_arms: Vec<MatchArm>,\n\n    /// The demands at the arms.\n    arm_demands: Vec<LoweredDemand>,\n}\n\n#[derive(Clone)]\npub struct AnalysisInfo {\n    candidate: Option<OptimizationCandidate>,\n    demand: LoweredDemand,\n}\nimpl Analyzer for MatchOptimizerContext {\n    type Info = AnalysisInfo;\n\n    fn visit_stmt(\n        &mut self,\n        info: &mut Self::Info,\n        statement_location: StatementLocation,\n        stmt: &Statement,\n    ) {\n        if !self.statement_can_be_optimized_out(stmt, info, statement_location) {\n            info.demand.variables_introduced(self, &stmt.outputs(), ());\n            info.demand.variables_used(self, &stmt.inputs(), ());\n        }\n\n        info.candidate = None;\n    }\n\n    fn visit_remapping(\n        &mut self,\n        info: &mut Self::Info,\n        _block_id: BlockId,\n        _target_block_id: BlockId,\n        remapping: &VarRemapping,\n    ) {\n        if !remapping.is_empty() {\n            info.demand.apply_remapping(self, remapping.iter().map(|(dst, src)| (*dst, *src)));\n\n            if let Some(ref mut candidate) = &mut info.candidate {\n                let expected_remappings =\n                    if let Some(var_id) = remapping.get(&candidate.match_variable) {\n                        candidate.match_variable = *var_id;\n                        1\n                    } else {\n                        0\n                    };\n\n                if remapping.len() != expected_remappings {\n                    // Remapping is currently not supported as it breaks SSA when we use the same\n                    // remapping with diffrent destantation blocks.\n\n                    // TODO(ilya): Support multiple remappings.\n                    info.candidate = None;\n                }\n            }\n        }\n    }\n\n    fn merge_match(\n        &mut self,\n        _statement_location: StatementLocation,\n        match_info: &MatchInfo,\n        infos: &[Self::Info],\n    ) -> Self::Info {\n        let arm_demands = zip_eq(match_info.arms(), infos)\n            .map(|(arm, info)| {\n                let mut demand = info.demand.clone();\n                demand.variables_introduced(self, &arm.var_ids, ());\n\n                (demand, ())\n            })\n            .collect_vec();\n        let mut demand = LoweredDemand::merge_demands(&arm_demands, self);\n\n        let candidate = match match_info {\n            // A match is a candidate for the optimization if it is a match on an Enum\n            // and its input is unused after the match.\n            MatchInfo::Enum(MatchEnumInfo { concrete_enum_id: _, input, arms })\n                if !demand.vars.contains(input) =>\n            {\n                Some(OptimizationCandidate {\n                    match_variable: *input,\n                    match_arms: arms.to_vec(),\n                    arm_demands: infos.iter().map(|info| info.demand.clone()).collect(),\n                })\n            }\n\n            _ => None,\n        };\n\n        demand.variables_used(self, &match_info.inputs(), ());\n\n        Self::Info { candidate, demand }\n    }\n\n    fn info_from_return(\n        &mut self,\n        _statement_location: StatementLocation,\n        vars: &[VariableId],\n    ) -> Self::Info {\n        let mut demand = LoweredDemand::default();\n        demand.variables_used(self, vars, ());\n        Self::Info { candidate: None, demand }\n    }\n\n    fn info_from_panic(\n        &mut self,\n        _statement_location: StatementLocation,\n        data: &VariableId,\n    ) -> Self::Info {\n        let mut demand = LoweredDemand::default();\n        demand.variables_used(self, &[*data], ());\n        Self::Info { candidate: None, demand }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::ops::Deref;\n\nuse cairo_lang_debug::DebugWithDb;\nuse cairo_lang_plugins::get_default_plugins;\nuse cairo_lang_semantic::db::SemanticGroup;\nuse cairo_lang_semantic::test_utils::setup_test_function;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\n\nuse super::optimize_matches;\nuse crate::db::LoweringGroup;\nuse crate::fmt::LoweredFormatter;\nuse crate::inline::apply_inlining;\nuse crate::optimizations::remappings::optimize_remappings;\nuse crate::panic::lower_panics;\nuse crate::test_utils::LoweringDatabaseForTesting;\nuse crate::topological_sort::topological_sort;\n\ncairo_lang_test_utils::test_file_test!(\n    match_optimizer,\n    \"src/optimizations/test_data\",\n    {\n        option :\"option\",\n    },\n    test_match_optimizer\n);\n\nfn test_match_optimizer(inputs: &OrderedHashMap<String, String>) -> OrderedHashMap<String, String> {\n    let db = &mut LoweringDatabaseForTesting::default();\n    db.set_semantic_plugins(get_default_plugins());\n    let (test_function, semantic_diagnostics) = setup_test_function(\n        db,\n        inputs[\"function\"].as_str(),\n        inputs[\"function_name\"].as_str(),\n        inputs[\"module_code\"].as_str(),\n    )\n    .split();\n\n    let mut before = db\n        .priv_concrete_function_with_body_lowered_flat(test_function.concrete_function_id)\n        .unwrap()\n        .deref()\n        .clone();\n\n    let lowering_diagnostics = db.module_lowering_diagnostics(test_function.module_id).unwrap();\n\n    apply_inlining(db, test_function.function_id, &mut before).unwrap();\n    before = lower_panics(db, test_function.concrete_function_id, &before).unwrap();\n    topological_sort(&mut before);\n    optimize_remappings(&mut before);\n\n    let mut after = before.clone();\n    optimize_matches(&mut after);\n\n    OrderedHashMap::from([\n        (\"semantic_diagnostics\".into(), semantic_diagnostics),\n        (\n            \"before\".into(),\n            format!(\"{:?}\", before.debug(&LoweredFormatter { db, variables: &before.variables })),\n        ),\n        (\n            \"after\".into(),\n            format!(\"{:?}\", after.debug(&LoweredFormatter { db, variables: &after.variables })),\n        ),\n        (\"lowering_diagnostics\".into(), lowering_diagnostics.format(db)),\n    ])\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "pub mod match_optimizer;\npub mod remappings;\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Remove unnecessary remapping of variables optimization.\n//! At each convergence, we have one or more branches with remappings of variables.\n//! A destination variable `dest` introduced by the remappings must be remapped at every branch\n//! `b_i` by mapping a source variable `src_i->dest`.\n//! We require that every use of `dest` refers to the correct `src_i`.\n//! This means that the remappings to `dest` are not necessary in these cases:\n//! 1. There is no flow that uses the \"value\" of `dest` after the convergence.\n//! 2. All the `src_i` variables get the same \"value\".\n\nuse std::collections::{HashMap, HashSet};\n\nuse itertools::Itertools;\n\nuse crate::utils::{Rebuilder, RebuilderEx};\nuse crate::{BlockId, FlatBlockEnd, FlatLowered, VarRemapping, VariableId};\n\nfn visit_remappings<F: FnMut(&VarRemapping)>(lowered: &mut FlatLowered, mut f: F) {\n    let mut stack = vec![BlockId::root()];\n    let mut visited = vec![false; lowered.blocks.len()];\n    while let Some(block_id) = stack.pop() {\n        if visited[block_id.0] {\n            continue;\n        }\n        visited[block_id.0] = true;\n        match &lowered.blocks[block_id].end {\n            FlatBlockEnd::Goto(target_block_id, remapping) => {\n                stack.push(*target_block_id);\n                f(remapping)\n            }\n            FlatBlockEnd::Match { info } => {\n                stack.extend(info.arms().iter().map(|arm| arm.block_id));\n            }\n            FlatBlockEnd::Return(_) | FlatBlockEnd::Panic(_) => {}\n            FlatBlockEnd::NotSet => unreachable!(),\n        }\n    }\n}\n\n#[derive(Default)]\nstruct Context {\n    dest_to_srcs: HashMap<VariableId, Vec<VariableId>>,\n    var_representatives: HashMap<VariableId, VariableId>,\n    variable_used: HashSet<VariableId>,\n}\nimpl Context {\n    fn set_used(&mut self, var: VariableId) {\n        if self.variable_used.insert(var) {\n            for src in self.dest_to_srcs.get(&var).cloned().unwrap_or_default() {\n                self.set_used(src);\n            }\n        }\n    }\n}\n\nimpl Rebuilder for Context {\n    fn map_var_id(&mut self, var: VariableId) -> VariableId {\n        if let Some(res) = self.var_representatives.get(&var) {\n            *res\n        } else {\n            let srcs = self.dest_to_srcs.get(&var).cloned().unwrap_or_default();\n            let src_representatives: HashSet<_> =\n                srcs.iter().map(|src| self.map_var_id(*src)).collect();\n            let src_representatives = src_representatives.into_iter().collect_vec();\n            let new_var =\n                if let [single_var] = &src_representatives[..] { *single_var } else { var };\n            self.var_representatives.insert(var, new_var);\n            new_var\n        }\n    }\n\n    fn map_block_id(&mut self, block: BlockId) -> BlockId {\n        block\n    }\n\n    fn transform_remapping(&mut self, remapping: &mut VarRemapping) {\n        let mut new_remapping = VarRemapping::default();\n        for (dst, src) in remapping.iter() {\n            if dst != src && self.variable_used.contains(dst) {\n                new_remapping.insert(*dst, *src);\n            }\n        }\n        *remapping = new_remapping;\n    }\n}\n\npub fn optimize_remappings(lowered: &mut FlatLowered) {\n    if lowered.blocks.has_root().is_err() {\n        return;\n    }\n\n    // Find condition 1 (see module doc).\n    let mut ctx = Context::default();\n    visit_remappings(lowered, |remapping| {\n        for (dst, src) in remapping.iter() {\n            ctx.dest_to_srcs.entry(*dst).or_default().push(*src);\n        }\n    });\n\n    // Find condition 2 (see module doc).\n    for (_, block) in lowered.blocks.iter() {\n        for stmt in &block.statements {\n            for var in stmt.inputs() {\n                let var = ctx.map_var_id(var);\n                ctx.set_used(var);\n            }\n        }\n        match &block.end {\n            FlatBlockEnd::Return(returns) => {\n                for var in returns {\n                    let var = ctx.map_var_id(*var);\n                    ctx.set_used(var);\n                }\n            }\n            FlatBlockEnd::Panic(data) => {\n                let var = ctx.map_var_id(*data);\n                ctx.set_used(var);\n            }\n            FlatBlockEnd::Goto(_, _) => {}\n            FlatBlockEnd::Match { info } => {\n                for var in info.inputs() {\n                    let var = ctx.map_var_id(var);\n                    ctx.set_used(var);\n                }\n            }\n            FlatBlockEnd::NotSet => unreachable!(),\n        }\n    }\n\n    // Rebuild the blocks without unnecessary remappings.\n    for block in lowered.blocks.iter_mut() {\n        *block = ctx.rebuild_block(block);\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::VecDeque;\n\nuse cairo_lang_diagnostics::Maybe;\nuse cairo_lang_semantic as semantic;\nuse cairo_lang_semantic::corelib::{get_core_enum_concrete_variant, get_panic_ty};\nuse cairo_lang_semantic::GenericArgumentId;\nuse itertools::{chain, zip_eq, Itertools};\nuse semantic::items::functions::{\n    ConcreteFunctionWithBody, GenericFunctionId, GenericFunctionWithBodyId,\n};\nuse semantic::{ConcreteFunctionWithBodyId, ConcreteVariant, Mutability, Signature, TypeId};\n\nuse crate::blocks::FlatBlocksBuilder;\nuse crate::db::LoweringGroup;\nuse crate::lower::context::{LoweringContext, LoweringContextBuilder, VarRequest};\nuse crate::{\n    BlockId, FlatBlock, FlatBlockEnd, FlatLowered, MatchArm, MatchEnumInfo, MatchInfo, Statement,\n    StatementCall, StatementEnumConstruct, StatementStructConstruct, StatementStructDestructure,\n    VarRemapping, VariableId,\n};\n\n// TODO(spapini): Remove tuple in the Ok() variant of the panic, by supporting multiple values in\n// the Sierra type.\n\n/// Lowering phase that converts BlockEnd::Panic into BlockEnd::Return, and wraps necessary types\n/// with PanicResult<>.\npub fn lower_panics(\n    db: &dyn LoweringGroup,\n    function_id: ConcreteFunctionWithBodyId,\n    lowered: &FlatLowered,\n) -> Maybe<FlatLowered> {\n    let lowering_info = LoweringContextBuilder::new_concrete(db, function_id)?;\n    let mut ctx = lowering_info.ctx()?;\n    ctx.variables = lowered.variables.clone();\n\n    // Skip this phase for non panicable functions.\n    if !db.concrete_function_with_body_may_panic(function_id)? {\n        return Ok(FlatLowered {\n            diagnostics: Default::default(),\n            variables: ctx.variables,\n            blocks: lowered.blocks.clone(),\n            parameters: lowered.parameters.clone(),\n        });\n    }\n\n    let panic_info = PanicSignatureInfo::new(db, ctx.signature);\n    let mut ctx = PanicLoweringContext {\n        ctx,\n        block_queue: VecDeque::from(lowered.blocks.get().clone()),\n        flat_blocks: FlatBlocksBuilder::new(),\n        panic_info,\n    };\n\n    // Iterate block queue (old and new blocks).\n    while let Some(block) = ctx.block_queue.pop_front() {\n        ctx = handle_block(ctx, block)?;\n    }\n\n    Ok(FlatLowered {\n        diagnostics: Default::default(),\n        variables: ctx.ctx.variables,\n        blocks: ctx.flat_blocks.build().unwrap(),\n        parameters: lowered.parameters.clone(),\n    })\n}\n\n/// Handles the lowering of panics in a single block.\nfn handle_block(\n    mut ctx: PanicLoweringContext<'_>,\n    mut block: FlatBlock,\n) -> Maybe<PanicLoweringContext<'_>> {\n    let mut block_ctx = PanicBlockLoweringContext { ctx, statements: Vec::new() };\n    for (i, stmt) in block.statements.iter().cloned().enumerate() {\n        if let Some((continuation_block, cur_block_end)) = block_ctx.handle_statement(&stmt)? {\n            // This case means that the lowering should split the block here.\n\n            // Block ended with a match.\n            ctx = block_ctx.handle_end(cur_block_end);\n\n            // The rest of the statements in this block have not been handled yet, and should be\n            // handled as a part of the continuation block - the second block in the \"split\".\n            let block_to_edit = &mut ctx.block_queue[continuation_block.0 - ctx.flat_blocks.len()];\n            block_to_edit.statements.extend(block.statements.drain(i + 1..));\n            block_to_edit.end = block.end;\n            return Ok(ctx);\n        }\n    }\n    ctx = block_ctx.handle_end(block.end);\n    Ok(ctx)\n}\n\npub struct PanicSignatureInfo {\n    /// The types of all the variables returned on OK: Reference variables and the original result.\n    ok_ret_tys: Vec<TypeId>,\n    /// The type of the Ok() variant.\n    ok_ty: TypeId,\n    /// The Ok() variant.\n    ok_variant: ConcreteVariant,\n    /// The Err() variant.\n    err_variant: ConcreteVariant,\n    /// The PanicResult concrete type - the new return type of the function.\n    pub panic_ty: TypeId,\n}\nimpl PanicSignatureInfo {\n    pub fn new(db: &dyn LoweringGroup, signature: &Signature) -> Self {\n        let refs = signature\n            .params\n            .iter()\n            .filter(|param| matches!(param.mutability, Mutability::Reference))\n            .map(|param| param.ty);\n        let original_return_ty = signature.return_type;\n\n        let ok_ret_tys = chain!(refs, [original_return_ty]).collect_vec();\n        let ok_ty = db.intern_type(semantic::TypeLongId::Tuple(ok_ret_tys.clone()));\n        let ok_variant = get_core_enum_concrete_variant(\n            db.upcast(),\n            \"PanicResult\",\n            vec![GenericArgumentId::Type(ok_ty)],\n            \"Ok\",\n        );\n        let err_variant = get_core_enum_concrete_variant(\n            db.upcast(),\n            \"PanicResult\",\n            vec![GenericArgumentId::Type(ok_ty)],\n            \"Err\",\n        );\n        let panic_ty = get_panic_ty(db.upcast(), ok_ty);\n        Self { ok_ret_tys, ok_ty, ok_variant, err_variant, panic_ty }\n    }\n}\n\nstruct PanicLoweringContext<'a> {\n    ctx: LoweringContext<'a>,\n    block_queue: VecDeque<FlatBlock>,\n    flat_blocks: FlatBlocksBuilder,\n    panic_info: PanicSignatureInfo,\n}\nimpl<'a> PanicLoweringContext<'a> {\n    pub fn db(&self) -> &dyn LoweringGroup {\n        self.ctx.db\n    }\n\n    fn enqueue_block(&mut self, block: FlatBlock) -> BlockId {\n        self.block_queue.push_back(block);\n        BlockId(self.flat_blocks.len() + self.block_queue.len())\n    }\n}\n\nstruct PanicBlockLoweringContext<'a> {\n    ctx: PanicLoweringContext<'a>,\n    statements: Vec<Statement>,\n}\nimpl<'a> PanicBlockLoweringContext<'a> {\n    pub fn db(&self) -> &dyn LoweringGroup {\n        self.ctx.db()\n    }\n\n    fn new_var(&mut self, req: VarRequest) -> VariableId {\n        self.ctx.ctx.new_var(req)\n    }\n\n    /// Handles a statement. If needed, returns the continuation block and the block end for this\n    /// block.\n    /// The continuation block happens when a panic match is added, and the block needs to be split.\n    /// The continuation block is the second block in the \"split\". This function already partially\n    /// creates this second block, and returns it.\n    fn handle_statement(&mut self, stmt: &Statement) -> Maybe<Option<(BlockId, FlatBlockEnd)>> {\n        if let Statement::Call(call) = &stmt {\n            let concrete_function = self.db().lookup_intern_function(call.function).function;\n            if let Some(with_body) = concrete_function.get_body(self.db().upcast())? {\n                if self.db().concrete_function_with_body_may_panic(with_body)? {\n                    return Ok(Some(self.handle_call_panic(call)?));\n                }\n            }\n        }\n        self.statements.push(stmt.clone());\n        Ok(None)\n    }\n\n    /// Handles a call statement to a panicking function.\n    /// Returns the continuation block ID for the caller to complete it, and the block end to set\n    /// for the current block.\n    fn handle_call_panic(&mut self, call: &StatementCall) -> Maybe<(BlockId, FlatBlockEnd)> {\n        // Extract return variable.\n        let mut original_outputs = call.outputs.clone();\n        let location = self.ctx.ctx.variables[original_outputs[0]].location;\n\n        // Get callee info.\n        let callee_signature = self.ctx.ctx.db.concrete_function_signature(call.function)?;\n        let callee_info = PanicSignatureInfo::new(self.ctx.ctx.db, &callee_signature);\n\n        // Allocate 2 new variables.\n        // panic_result_var - for the new return variable, with is actually of type PanicResult<ty>.\n        let panic_result_var = self.new_var(VarRequest { ty: callee_info.panic_ty, location });\n        let n_callee_implicits = original_outputs.len() - callee_info.ok_ret_tys.len();\n        let mut call_outputs = original_outputs.drain(..n_callee_implicits).collect_vec();\n        call_outputs.push(panic_result_var);\n        // inner_ok_value - for the Ok() match arm input.\n        let inner_ok_value = self.new_var(VarRequest { ty: callee_info.ok_ty, location });\n        // inner_ok_values - for the destructure.\n        let inner_ok_values = callee_info\n            .ok_ret_tys\n            .iter()\n            .copied()\n            .map(|ty| self.new_var(VarRequest { ty, location }))\n            .collect_vec();\n\n        // Emit the new statement.\n        self.statements.push(Statement::Call(StatementCall {\n            function: call.function,\n            inputs: call.inputs.clone(),\n            outputs: call_outputs,\n            location,\n        }));\n\n        // Start constructing a match on the result.\n        let block_continuation =\n            self.ctx.enqueue_block(FlatBlock { statements: vec![], end: FlatBlockEnd::NotSet });\n\n        // Prepare Ok() match arm block. This block will be the continuation block.\n        // This block is only partially created. It is returned at this function to let the caller\n        // complete it.\n        let block_ok = self.ctx.enqueue_block(FlatBlock {\n            statements: vec![Statement::StructDestructure(StatementStructDestructure {\n                input: inner_ok_value,\n                outputs: inner_ok_values.clone(),\n            })],\n            end: FlatBlockEnd::Goto(\n                block_continuation,\n                VarRemapping { remapping: zip_eq(original_outputs, inner_ok_values).collect() },\n            ),\n        });\n\n        // Prepare Err() match arm block.\n        let data_var =\n            self.new_var(VarRequest { ty: self.ctx.panic_info.err_variant.ty, location });\n        let block_err = self\n            .ctx\n            .enqueue_block(FlatBlock { statements: vec![], end: FlatBlockEnd::Panic(data_var) });\n\n        let cur_block_end = FlatBlockEnd::Match {\n            info: MatchInfo::Enum(MatchEnumInfo {\n                concrete_enum_id: callee_info.ok_variant.concrete_enum_id,\n                input: panic_result_var,\n                arms: vec![\n                    MatchArm {\n                        variant_id: callee_info.ok_variant,\n                        block_id: block_ok,\n                        var_ids: vec![inner_ok_value],\n                    },\n                    MatchArm {\n                        variant_id: callee_info.err_variant,\n                        block_id: block_err,\n                        var_ids: vec![data_var],\n                    },\n                ],\n            }),\n        };\n\n        Ok((block_continuation, cur_block_end))\n    }\n\n    fn handle_end(mut self, end: FlatBlockEnd) -> PanicLoweringContext<'a> {\n        let end = match end {\n            FlatBlockEnd::Goto(target, remapping) => FlatBlockEnd::Goto(target, remapping),\n            FlatBlockEnd::Panic(data) => {\n                // Wrap with PanicResult::Err.\n                let ty = self.ctx.panic_info.panic_ty;\n                let location = self.ctx.ctx.variables[data].location;\n                let output = self.new_var(VarRequest { ty, location });\n                self.statements.push(Statement::EnumConstruct(StatementEnumConstruct {\n                    variant: self.ctx.panic_info.err_variant.clone(),\n                    input: data,\n                    output,\n                }));\n                FlatBlockEnd::Return(vec![output])\n            }\n            FlatBlockEnd::Return(returns) => {\n                let location = self.ctx.ctx.variables[returns[0]].location;\n\n                // Tuple construction.\n                let tupled_res =\n                    self.new_var(VarRequest { ty: self.ctx.panic_info.ok_ty, location });\n                self.statements.push(Statement::StructConstruct(StatementStructConstruct {\n                    inputs: returns,\n                    output: tupled_res,\n                }));\n\n                // Wrap with PanicResult::Ok.\n                let ty = self.ctx.panic_info.panic_ty;\n                let output = self.new_var(VarRequest { ty, location });\n                self.statements.push(Statement::EnumConstruct(StatementEnumConstruct {\n                    variant: self.ctx.panic_info.ok_variant.clone(),\n                    input: tupled_res,\n                    output,\n                }));\n                FlatBlockEnd::Return(vec![output])\n            }\n            FlatBlockEnd::NotSet => unreachable!(),\n            FlatBlockEnd::Match { info } => FlatBlockEnd::Match { info },\n        };\n        self.ctx.flat_blocks.alloc(FlatBlock { statements: self.statements, end });\n        self.ctx\n    }\n}\n\n// ============= Query implementations =============\n\n/// Query implementation of [crate::db::LoweringGroup::function_may_panic].\npub fn function_may_panic(db: &dyn LoweringGroup, function: semantic::FunctionId) -> Maybe<bool> {\n    let concrete_function = function.get_concrete(db.upcast());\n    match concrete_function.generic_function {\n        GenericFunctionId::Free(free_function) => {\n            let concrete_with_body =\n                db.intern_concrete_function_with_body(ConcreteFunctionWithBody {\n                    generic_function: GenericFunctionWithBodyId::Free(free_function),\n                    generic_args: concrete_function.generic_args,\n                });\n            db.concrete_function_with_body_may_panic(concrete_with_body)\n        }\n        GenericFunctionId::Impl(impl_generic_function) => {\n            let Some(generic_with_body) =\n            impl_generic_function.to_generic_with_body(db.upcast())?\n            else {\n                unreachable!();\n            };\n            let concrete_with_body =\n                db.intern_concrete_function_with_body(ConcreteFunctionWithBody {\n                    generic_function: generic_with_body,\n                    generic_args: concrete_function.generic_args,\n                });\n            db.concrete_function_with_body_may_panic(concrete_with_body)\n        }\n        GenericFunctionId::Extern(extern_function) => {\n            Ok(db.extern_function_signature(extern_function)?.panicable)\n        }\n    }\n}\n\n/// Query implementation of [crate::db::LoweringGroup::concrete_function_with_body_may_panic].\npub fn concrete_function_with_body_may_panic(\n    db: &dyn LoweringGroup,\n    function: ConcreteFunctionWithBodyId,\n) -> Maybe<bool> {\n    // Find the SCC representative.\n    let scc_representative = db.concrete_function_with_body_scc_representative(function);\n\n    if db.has_direct_panic(function)? {\n        return Ok(true);\n    }\n\n    // For each direct callee, find if it may panic.\n    let direct_callees = db.concrete_function_with_body_direct_callees(function)?;\n    for direct_callee in direct_callees {\n        let generic_function = direct_callee.generic_function;\n        // For a function with a body, call this method recursively. To avoid cycles, first\n        // check that the callee is not in this function's SCC.\n        let generic_with_body = match generic_function {\n            GenericFunctionId::Free(free_function) => {\n                GenericFunctionWithBodyId::Free(free_function)\n            }\n            GenericFunctionId::Impl(impl_generic_function) => {\n                if let Some(generic_with_body) =\n                    impl_generic_function.to_generic_with_body(db.upcast())?\n                {\n                    generic_with_body\n                } else {\n                    unreachable!()\n                }\n            }\n            GenericFunctionId::Extern(extern_function) => {\n                if db.extern_function_signature(extern_function)?.panicable {\n                    return Ok(true);\n                }\n                continue;\n            }\n        };\n        let concrete_with_body = db.intern_concrete_function_with_body(ConcreteFunctionWithBody {\n            generic_function: generic_with_body,\n            generic_args: direct_callee.generic_args,\n        });\n        let direct_callee_representative =\n            db.concrete_function_with_body_scc_representative(concrete_with_body);\n        if direct_callee_representative == scc_representative {\n            // We already know this SCC may not panic - do nothing.\n            continue;\n        }\n        if db.concrete_function_with_body_may_panic(direct_callee_representative.0)? {\n            return Ok(true);\n        }\n    }\n    Ok(false)\n}\n\n/// Query implementation of [crate::db::LoweringGroup::has_direct_panic].\npub fn has_direct_panic(\n    db: &dyn LoweringGroup,\n    function_id: ConcreteFunctionWithBodyId,\n) -> Maybe<bool> {\n    let lowered_function = db.priv_concrete_function_with_body_lowered_flat(function_id)?;\n    Ok(itertools::any(&lowered_function.blocks, |(_, block)| {\n        matches!(&block.end, FlatBlockEnd::Panic(..))\n    }))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::cmp::Ordering;\n\nuse cairo_lang_defs::ids::{FunctionWithBodyId, UnstableSalsaId};\nuse cairo_lang_utils::graph_algos::graph_node::GraphNode;\nuse cairo_lang_utils::graph_algos::strongly_connected_components::compute_scc;\n\nuse crate::db::{GenericSCCRepresentative, LoweringGroup};\n\n/// Query implementation of [crate::db::LoweringGroup::function_scc_representative].\npub fn function_scc_representative(\n    db: &dyn LoweringGroup,\n    function: FunctionWithBodyId,\n) -> GenericSCCRepresentative {\n    GenericSCCRepresentative(\n        db.function_with_body_scc(function)\n            .into_iter()\n            .min_by(|x, y| match (x, y) {\n                (FunctionWithBodyId::Free(x), FunctionWithBodyId::Free(y)) => {\n                    x.get_internal_id().cmp(y.get_internal_id())\n                }\n                (FunctionWithBodyId::Impl(x), FunctionWithBodyId::Impl(y)) => {\n                    x.get_internal_id().cmp(y.get_internal_id())\n                }\n                (FunctionWithBodyId::Free(_), FunctionWithBodyId::Impl(_)) => Ordering::Less,\n                (FunctionWithBodyId::Impl(_), FunctionWithBodyId::Free(_)) => Ordering::Greater,\n            })\n            .unwrap_or(function),\n    )\n}\n\n/// Query implementation of [crate::db::LoweringGroup::function_with_body_scc].\npub fn function_with_body_scc(\n    db: &dyn LoweringGroup,\n    function_id: FunctionWithBodyId,\n) -> Vec<FunctionWithBodyId> {\n    compute_scc(&FunctionWithBodyNode { function_with_body_id: function_id, db: db.upcast() })\n}\n\n/// A node to use in the SCC computation.\n#[derive(Clone)]\nstruct FunctionWithBodyNode<'a> {\n    function_with_body_id: FunctionWithBodyId,\n    db: &'a dyn LoweringGroup,\n}\nimpl<'a> GraphNode for FunctionWithBodyNode<'a> {\n    type NodeId = FunctionWithBodyId;\n\n    fn get_neighbors(&self) -> Vec<Self> {\n        self.db\n            .function_with_body_direct_function_with_body_callees(self.function_with_body_id)\n            .unwrap_or_default()\n            .into_iter()\n            .map(|function_with_body_id| FunctionWithBodyNode {\n                function_with_body_id,\n                db: self.db,\n            })\n            .collect()\n    }\n\n    fn get_id(&self) -> Self::NodeId {\n        self.function_with_body_id\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::ops::Deref;\n\nuse cairo_lang_debug::DebugWithDb;\nuse cairo_lang_plugins::get_default_plugins;\nuse cairo_lang_semantic::db::SemanticGroup;\nuse cairo_lang_semantic::test_utils::setup_test_function;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\n\nuse crate::db::LoweringGroup;\nuse crate::fmt::LoweredFormatter;\nuse crate::implicits::lower_implicits;\nuse crate::inline::apply_inlining;\nuse crate::optimizations::match_optimizer::optimize_matches;\nuse crate::optimizations::remappings::optimize_remappings;\nuse crate::panic::lower_panics;\nuse crate::test_utils::LoweringDatabaseForTesting;\nuse crate::topological_sort::topological_sort;\nuse crate::FlatLowered;\n\ncairo_lang_test_utils::test_file_test!(\n    lowering,\n    \"src/test_data\",\n    {\n        assignment :\"assignment\",\n        borrow_check :\"borrow_check\",\n        call :\"call\",\n        constant :\"constant\",\n        destruct :\"destruct\",\n        enums :\"enums\",\n        error_propagate :\"error_propagate\",\n        generics :\"generics\",\n        extern_ :\"extern\",\n        arm_pattern_destructure :\"arm_pattern_destructure\",\n        if_ :\"if\",\n        match_ :\"match\",\n        members :\"members\",\n        panic :\"panic\",\n        rebindings :\"rebindings\",\n        snapshot :\"snapshot\",\n        struct_ :\"struct\",\n        tests :\"tests\",\n        tuple :\"tuple\",\n    },\n    test_function_lowering\n);\n\ncairo_lang_test_utils::test_file_test!(\n    lowering_phases,\n    \"src/test_data\",\n    {\n        tests :\"lowering_phases\",\n    },\n    test_function_lowering_phases\n);\n\nfn test_function_lowering(\n    inputs: &OrderedHashMap<String, String>,\n) -> OrderedHashMap<String, String> {\n    let db = &mut LoweringDatabaseForTesting::default();\n    db.set_semantic_plugins(get_default_plugins());\n    let (test_function, semantic_diagnostics) = setup_test_function(\n        db,\n        inputs[\"function\"].as_str(),\n        inputs[\"function_name\"].as_str(),\n        inputs[\"module_code\"].as_str(),\n    )\n    .split();\n    let lowered =\n        db.concrete_function_with_body_lowered(test_function.concrete_function_id).unwrap();\n    assert!(\n        lowered.blocks.iter().all(|(_, b)| b.is_set()),\n        \"There should not be any unset flat blocks\"\n    );\n    let diagnostics = db.module_lowering_diagnostics(test_function.module_id).unwrap();\n\n    let lowered_formatter = LoweredFormatter { db, variables: &lowered.variables };\n    OrderedHashMap::from([\n        (\"semantic_diagnostics\".into(), semantic_diagnostics),\n        (\"lowering_diagnostics\".into(), diagnostics.format(db)),\n        (\"lowering_flat\".into(), format!(\"{:?}\", lowered.debug(&lowered_formatter))),\n    ])\n}\n\n/// Tests all the lowering phases of a function (tracking logic in\n/// `concrete_function_with_body_lowered`).\n/// Can be used to debug cases where the transition of a specific lowering phase fails.\nfn test_function_lowering_phases(\n    inputs: &OrderedHashMap<String, String>,\n) -> OrderedHashMap<String, String> {\n    let db = &mut LoweringDatabaseForTesting::default();\n    db.set_semantic_plugins(get_default_plugins());\n    let (test_function, semantic_diagnostics) = setup_test_function(\n        db,\n        inputs[\"function\"].as_str(),\n        inputs[\"function_name\"].as_str(),\n        inputs[\"module_code\"].as_str(),\n    )\n    .split();\n    let concrete_function = test_function.concrete_function_id;\n\n    let before_all = db.priv_concrete_function_with_body_lowered_flat(concrete_function).unwrap();\n    assert!(\n        before_all.blocks.iter().all(|(_, b)| b.is_set()),\n        \"There should not be any unset blocks\"\n    );\n\n    let mut after_inlining = before_all.deref().clone();\n    apply_inlining(db, test_function.function_id, &mut after_inlining).unwrap();\n\n    let after_lower_panics = lower_panics(db, concrete_function, &after_inlining).unwrap();\n\n    let mut after_lower_implicits = after_lower_panics.clone();\n    lower_implicits(db, concrete_function, &mut after_lower_implicits);\n\n    let mut after_optimize_matches = after_lower_implicits.clone();\n    optimize_matches(&mut after_optimize_matches);\n\n    let mut after_topological_sort = after_optimize_matches.clone();\n    topological_sort(&mut after_topological_sort);\n\n    let mut after_optimize_remappings = after_topological_sort.clone();\n    optimize_remappings(&mut after_optimize_remappings);\n\n    let after_all = db.concrete_function_with_body_lowered(concrete_function).unwrap();\n\n    // This asserts that we indeed follow the logic of `concrete_function_with_body_lowered`.\n    // If something is changed there, it should be changed here too.\n    assert_eq!(*after_all, after_optimize_remappings);\n\n    let diagnostics = db.module_lowering_diagnostics(test_function.module_id).unwrap();\n\n    OrderedHashMap::from([\n        (\"semantic_diagnostics\".into(), semantic_diagnostics),\n        (\"lowering_diagnostics\".into(), diagnostics.format(db)),\n        (\"before_all\".into(), formatted_lowered(db, &before_all)),\n        (\"after_inlining\".into(), formatted_lowered(db, &after_inlining)),\n        (\"after_lower_panics\".into(), formatted_lowered(db, &after_lower_panics)),\n        (\"after_lower_implicits\".into(), formatted_lowered(db, &after_lower_implicits)),\n        (\"after_optimize_matches\".into(), formatted_lowered(db, &after_optimize_matches)),\n        (\"after_topological_sort\".into(), formatted_lowered(db, &after_topological_sort)),\n        (\n            \"after_optimize_remappings (final)\".into(),\n            formatted_lowered(db, &after_optimize_remappings),\n        ),\n    ])\n}\n\nfn formatted_lowered(db: &dyn LoweringGroup, lowered: &FlatLowered) -> String {\n    let lowered_formatter = LoweredFormatter { db, variables: &lowered.variables };\n    format!(\"{:?}\", lowered.debug(&lowered_formatter))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse cairo_lang_defs::db::{DefsDatabase, DefsGroup, HasMacroPlugins};\nuse cairo_lang_defs::plugin::MacroPlugin;\nuse cairo_lang_filesystem::db::{\n    init_dev_corelib, init_files_group, AsFilesGroupMut, FilesDatabase, FilesGroup,\n};\nuse cairo_lang_filesystem::detect::detect_corelib;\nuse cairo_lang_parser::db::ParserDatabase;\nuse cairo_lang_plugins::get_default_plugins;\nuse cairo_lang_semantic::db::{SemanticDatabase, SemanticGroup, SemanticGroupEx};\nuse cairo_lang_syntax::node::db::{SyntaxDatabase, SyntaxGroup};\nuse cairo_lang_utils::Upcast;\n\nuse crate::db::{init_lowering_group, LoweringDatabase, LoweringGroup};\n\n#[salsa::database(\n    LoweringDatabase,\n    SemanticDatabase,\n    DefsDatabase,\n    ParserDatabase,\n    SyntaxDatabase,\n    FilesDatabase\n)]\npub struct LoweringDatabaseForTesting {\n    storage: salsa::Storage<LoweringDatabaseForTesting>,\n}\nimpl salsa::Database for LoweringDatabaseForTesting {}\nimpl Default for LoweringDatabaseForTesting {\n    fn default() -> Self {\n        let mut res = Self { storage: Default::default() };\n        init_files_group(&mut res);\n        init_lowering_group(&mut res);\n        res.set_semantic_plugins(get_default_plugins());\n        let corelib_path = detect_corelib().expect(\"Corelib not found in default location.\");\n        init_dev_corelib(&mut res, corelib_path);\n        res\n    }\n}\nimpl AsFilesGroupMut for LoweringDatabaseForTesting {\n    fn as_files_group_mut(&mut self) -> &mut (dyn FilesGroup + 'static) {\n        self\n    }\n}\nimpl Upcast<dyn FilesGroup> for LoweringDatabaseForTesting {\n    fn upcast(&self) -> &(dyn FilesGroup + 'static) {\n        self\n    }\n}\nimpl Upcast<dyn SyntaxGroup> for LoweringDatabaseForTesting {\n    fn upcast(&self) -> &(dyn SyntaxGroup + 'static) {\n        self\n    }\n}\nimpl Upcast<dyn DefsGroup> for LoweringDatabaseForTesting {\n    fn upcast(&self) -> &(dyn DefsGroup + 'static) {\n        self\n    }\n}\nimpl Upcast<dyn SemanticGroup> for LoweringDatabaseForTesting {\n    fn upcast(&self) -> &(dyn SemanticGroup + 'static) {\n        self\n    }\n}\nimpl Upcast<dyn LoweringGroup> for LoweringDatabaseForTesting {\n    fn upcast(&self) -> &(dyn LoweringGroup + 'static) {\n        self\n    }\n}\nimpl HasMacroPlugins for LoweringDatabaseForTesting {\n    fn macro_plugins(&self) -> Vec<Arc<dyn MacroPlugin>> {\n        self.get_macro_plugins()\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashMap;\n\nuse crate::blocks::FlatBlocksBuilder;\nuse crate::borrow_check::analysis::{Analyzer, BackAnalysis, StatementLocation};\nuse crate::utils::{Rebuilder, RebuilderEx};\nuse crate::{BlockId, FlatBlock, FlatLowered, MatchInfo, VariableId};\n\n/// Order the blocks in a lowered function topologically.\npub fn topological_sort(lowered: &mut FlatLowered) {\n    if !lowered.blocks.is_empty() {\n        let ctx = TopSortContext { old_block_rev_order: Default::default() };\n        let mut analysis =\n            BackAnalysis { lowered: &*lowered, cache: Default::default(), analyzer: ctx };\n        analysis.get_root_info();\n        let mut ctx = analysis.analyzer;\n\n        // Rebuild the blocks in the correct order.\n        let mut new_blocks = FlatBlocksBuilder::default();\n        let old_block_rev_order = std::mem::take(&mut ctx.old_block_rev_order);\n\n        let n_visited_blocks = old_block_rev_order.len();\n        let mut rebuilder = RebuildContext {\n            block_remapping: HashMap::from_iter(\n                old_block_rev_order\n                    .iter()\n                    .enumerate()\n                    .map(|(idx, block_id)| (*block_id, BlockId(n_visited_blocks - idx - 1))),\n            ),\n        };\n        for block_id in old_block_rev_order.into_iter().rev() {\n            new_blocks.alloc(rebuilder.rebuild_block(&lowered.blocks[block_id]));\n        }\n\n        lowered.blocks = new_blocks.build().unwrap();\n    }\n}\n\npub struct TopSortContext {\n    old_block_rev_order: Vec<BlockId>,\n}\n\nimpl Analyzer for TopSortContext {\n    type Info = ();\n\n    fn visit_block_start(&mut self, _info: &mut Self::Info, block_id: BlockId, _block: &FlatBlock) {\n        self.old_block_rev_order.push(block_id);\n    }\n\n    fn merge_match(\n        &mut self,\n        _statement_location: StatementLocation,\n        _match_info: &MatchInfo,\n        _infos: &[Self::Info],\n    ) -> Self::Info {\n    }\n\n    fn info_from_return(\n        &mut self,\n        _statement_location: StatementLocation,\n        _vars: &[VariableId],\n    ) -> Self::Info {\n    }\n\n    fn info_from_panic(\n        &mut self,\n        _statement_location: StatementLocation,\n        _data: &VariableId,\n    ) -> Self::Info {\n    }\n}\n\npub struct RebuildContext {\n    block_remapping: HashMap<BlockId, BlockId>,\n}\nimpl Rebuilder for RebuildContext {\n    fn map_var_id(&mut self, var: VariableId) -> VariableId {\n        var\n    }\n\n    fn map_block_id(&mut self, block: BlockId) -> BlockId {\n        self.block_remapping[&block]\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_utils::ordered_hash_map::OrderedHashMap;\n\nuse crate::{\n    BlockId, FlatBlock, FlatBlockEnd, MatchArm, MatchEnumInfo, MatchExternInfo, MatchInfo,\n    Statement, StatementCall, StatementDesnap, StatementEnumConstruct, StatementLiteral,\n    StatementSnapshot, StatementStructConstruct, StatementStructDestructure, VarRemapping,\n    VariableId,\n};\n\n/// A rebuilder trait for rebuilding lowered representation.\npub trait Rebuilder {\n    fn map_var_id(&mut self, var: VariableId) -> VariableId;\n    fn map_block_id(&mut self, block: BlockId) -> BlockId;\n    fn transform_statement(&mut self, _statement: &mut Statement) {}\n    fn transform_remapping(&mut self, _remapping: &mut VarRemapping) {}\n    fn transform_end(&mut self, _end: &mut FlatBlockEnd) {}\n    fn transform_block(&mut self, _block: &mut FlatBlock) {}\n}\n\npub trait RebuilderEx: Rebuilder {\n    /// Rebuilds the statement with renamed var and block ids.\n    fn rebuild_statement(&mut self, statement: &Statement) -> Statement {\n        let mut statement = match statement {\n            Statement::Literal(stmt) => Statement::Literal(StatementLiteral {\n                value: stmt.value.clone(),\n                output: self.map_var_id(stmt.output),\n            }),\n            Statement::Call(stmt) => Statement::Call(StatementCall {\n                function: stmt.function,\n                inputs: stmt.inputs.iter().map(|v| self.map_var_id(*v)).collect(),\n                outputs: stmt.outputs.iter().map(|v| self.map_var_id(*v)).collect(),\n                location: stmt.location,\n            }),\n            Statement::StructConstruct(stmt) => {\n                Statement::StructConstruct(StatementStructConstruct {\n                    inputs: stmt.inputs.iter().map(|v| self.map_var_id(*v)).collect(),\n                    output: self.map_var_id(stmt.output),\n                })\n            }\n            Statement::StructDestructure(stmt) => {\n                Statement::StructDestructure(StatementStructDestructure {\n                    input: self.map_var_id(stmt.input),\n                    outputs: stmt.outputs.iter().map(|v| self.map_var_id(*v)).collect(),\n                })\n            }\n            Statement::EnumConstruct(stmt) => Statement::EnumConstruct(StatementEnumConstruct {\n                variant: stmt.variant.clone(),\n                input: self.map_var_id(stmt.input),\n                output: self.map_var_id(stmt.output),\n            }),\n            Statement::Snapshot(stmt) => Statement::Snapshot(StatementSnapshot {\n                input: self.map_var_id(stmt.input),\n                output_original: self.map_var_id(stmt.output_original),\n                output_snapshot: self.map_var_id(stmt.output_snapshot),\n            }),\n            Statement::Desnap(stmt) => Statement::Desnap(StatementDesnap {\n                input: self.map_var_id(stmt.input),\n                output: self.map_var_id(stmt.output),\n            }),\n        };\n        self.transform_statement(&mut statement);\n        statement\n    }\n\n    /// Apply map_var_id to all the variable in the `remapping`.\n    fn rebuild_remapping(&mut self, remapping: &VarRemapping) -> VarRemapping {\n        let mut remapping = VarRemapping {\n            remapping: OrderedHashMap::from_iter(\n                remapping.iter().map(|(dst, src)| (self.map_var_id(*dst), self.map_var_id(*src))),\n            ),\n        };\n        self.transform_remapping(&mut remapping);\n        remapping\n    }\n\n    /// Rebuilds the block end with renamed var and block ids.\n    fn rebuild_end(&mut self, end: &FlatBlockEnd) -> FlatBlockEnd {\n        let mut end = match end {\n            FlatBlockEnd::Return(returns) => FlatBlockEnd::Return(\n                returns.iter().map(|var_id| self.map_var_id(*var_id)).collect(),\n            ),\n            FlatBlockEnd::Panic(data) => FlatBlockEnd::Panic(self.map_var_id(*data)),\n            FlatBlockEnd::Goto(block_id, remapping) => {\n                FlatBlockEnd::Goto(self.map_block_id(*block_id), self.rebuild_remapping(remapping))\n            }\n            FlatBlockEnd::NotSet => unreachable!(),\n            FlatBlockEnd::Match { info } => FlatBlockEnd::Match {\n                info: match info {\n                    MatchInfo::Extern(stmt) => MatchInfo::Extern(MatchExternInfo {\n                        function: stmt.function,\n                        inputs: stmt.inputs.iter().map(|v| self.map_var_id(*v)).collect(),\n                        arms: stmt\n                            .arms\n                            .iter()\n                            .map(|arm| MatchArm {\n                                variant_id: arm.variant_id.clone(),\n                                block_id: self.map_block_id(arm.block_id),\n                                var_ids: arm\n                                    .var_ids\n                                    .iter()\n                                    .map(|var_id| self.map_var_id(*var_id))\n                                    .collect(),\n                            })\n                            .collect(),\n                        location: stmt.location,\n                    }),\n                    MatchInfo::Enum(stmt) => MatchInfo::Enum(MatchEnumInfo {\n                        concrete_enum_id: stmt.concrete_enum_id,\n                        input: self.map_var_id(stmt.input),\n                        arms: stmt\n                            .arms\n                            .iter()\n                            .map(|arm| MatchArm {\n                                variant_id: arm.variant_id.clone(),\n                                block_id: self.map_block_id(arm.block_id),\n                                var_ids: arm\n                                    .var_ids\n                                    .iter()\n                                    .map(|var_id| self.map_var_id(*var_id))\n                                    .collect(),\n                            })\n                            .collect(),\n                    }),\n                },\n            },\n        };\n        self.transform_end(&mut end);\n        end\n    }\n\n    /// Rebuilds the block with renamed var and block ids.\n    fn rebuild_block(&mut self, block: &FlatBlock) -> FlatBlock {\n        let mut statements = vec![];\n        for stmt in &block.statements {\n            statements.push(self.rebuild_statement(stmt));\n        }\n        let end = self.rebuild_end(&block.end);\n        let mut block = FlatBlock { statements, end };\n        self.transform_block(&mut block);\n        block\n    }\n}\n\nimpl<T: Rebuilder> RebuilderEx for T {}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::green::GreenNodeDetails;\nuse cairo_lang_syntax::node::kind::SyntaxKind;\nuse cairo_lang_syntax::node::SyntaxNode;\nuse colored::{ColoredString, Colorize};\nuse smol_str::SmolStr;\n\nstruct ColoredPrinter<'a> {\n    db: &'a dyn SyntaxGroup,\n    /// Whether to also print empty and missing tokens/nodes\n    verbose: bool,\n    result: String,\n}\nimpl<'a> ColoredPrinter<'a> {\n    fn print(&mut self, syntax_node: &SyntaxNode) {\n        let node = syntax_node.green_node(self.db);\n        match node.details {\n            GreenNodeDetails::Token(text) => {\n                if self.verbose && node.kind == SyntaxKind::TokenMissing {\n                    self.result.push_str(format!(\"{}\", \"<m>\".red()).as_str());\n                } else {\n                    self.result.push_str(set_color(text, node.kind).to_string().as_str());\n                }\n            }\n            GreenNodeDetails::Node { .. } => {\n                if self.verbose && is_missing_kind(node.kind) {\n                    self.result.push_str(format!(\"{}\", \"<m>\".red()).as_str());\n                } else if self.verbose && is_empty_kind(node.kind) {\n                    self.result.push_str(format!(\"{}\", \"<e>\".red()).as_str());\n                } else {\n                    for child in syntax_node.children(self.db) {\n                        self.print(&child);\n                    }\n                }\n            }\n        }\n    }\n}\n\n// TODO(yuval): autogenerate both.\nfn is_missing_kind(kind: SyntaxKind) -> bool {\n    matches!(kind, SyntaxKind::ExprMissing | SyntaxKind::StatementMissing)\n}\n\n// TODO(yuval): Move to SyntaxKind.\npub fn is_empty_kind(kind: SyntaxKind) -> bool {\n    matches!(\n        kind,\n        SyntaxKind::OptionStructArgExprEmpty\n            | SyntaxKind::OptionTypeClauseEmpty\n            | SyntaxKind::OptionReturnTypeClauseEmpty\n            | SyntaxKind::OptionTerminalSemicolonEmpty\n            | SyntaxKind::OptionTerminalColonColonEmpty\n            | SyntaxKind::OptionWrappedGenericParamListEmpty\n    )\n}\n\nfn set_color(text: SmolStr, kind: SyntaxKind) -> ColoredString {\n    // TODO(yuval): use tags on SyntaxKind\n    match kind {\n        SyntaxKind::TokenIdentifier => text.truecolor(255, 255, 100), // Yellow\n        SyntaxKind::TokenPlus\n        | SyntaxKind::TokenMinus\n        | SyntaxKind::TokenMul\n        | SyntaxKind::TokenDiv\n        | SyntaxKind::TokenMod\n        | SyntaxKind::TokenDot => text.bright_magenta(),\n        SyntaxKind::TokenLiteralNumber\n        | SyntaxKind::TokenFalse\n        | SyntaxKind::TokenTrue\n        | SyntaxKind::TokenShortString => text.bright_cyan(),\n        SyntaxKind::TokenExtern\n        | SyntaxKind::TokenType\n        | SyntaxKind::TokenFunction\n        | SyntaxKind::TokenModule\n        | SyntaxKind::TokenEnum\n        | SyntaxKind::TokenStruct\n        | SyntaxKind::TokenTrait\n        | SyntaxKind::TokenImpl => text.bright_blue(),\n        SyntaxKind::TokenOf\n        | SyntaxKind::TokenLet\n        | SyntaxKind::TokenReturn\n        | SyntaxKind::TokenMatch\n        | SyntaxKind::TokenIf\n        | SyntaxKind::TokenElse\n        | SyntaxKind::TokenUse\n        | SyntaxKind::TokenImplicits\n        | SyntaxKind::TokenRef\n        | SyntaxKind::TokenMut\n        | SyntaxKind::TokenNoPanic => text.bright_blue(),\n        SyntaxKind::TokenArrow\n        | SyntaxKind::TokenMatchArrow\n        | SyntaxKind::TokenColon\n        | SyntaxKind::TokenColonColon\n        | SyntaxKind::TokenDotDot\n        | SyntaxKind::TokenSemicolon\n        | SyntaxKind::TokenAnd\n        | SyntaxKind::TokenAndAnd\n        | SyntaxKind::TokenOr\n        | SyntaxKind::TokenOrOr\n        | SyntaxKind::TokenXor\n        | SyntaxKind::TokenNot\n        | SyntaxKind::TokenQuestionMark\n        | SyntaxKind::TokenUnderscore\n        | SyntaxKind::TokenHash => text.truecolor(255, 180, 255), // Pink\n        SyntaxKind::TokenEq\n        | SyntaxKind::TokenEqEq\n        | SyntaxKind::TokenGE\n        | SyntaxKind::TokenGT\n        | SyntaxKind::TokenLE\n        | SyntaxKind::TokenLT\n        | SyntaxKind::TokenNeq => {\n            text.truecolor(255, 165, 0) // Orange\n        }\n        SyntaxKind::TokenLBrace\n        | SyntaxKind::TokenRBrace\n        | SyntaxKind::TokenLBrack\n        | SyntaxKind::TokenRBrack\n        | SyntaxKind::TokenLParen\n        | SyntaxKind::TokenRParen\n        | SyntaxKind::TokenComma => text.clear(),\n        SyntaxKind::TokenEndOfFile => text.clear(),\n        SyntaxKind::TokenBadCharacters => text.red(),\n        SyntaxKind::TokenMissing => text.clear(),\n        SyntaxKind::TokenSkipped => text.on_red(), // red background\n        SyntaxKind::TokenSingleLineComment\n        | SyntaxKind::TokenWhitespace\n        | SyntaxKind::TokenNewline => text.clear(),\n        // TODO(yuval): Can this be made exhaustive?\n        _ => panic!(\"Unexpected syntax kind: {kind:?}\"),\n    }\n}\n\npub fn print_colored(db: &dyn SyntaxGroup, syntax_root: &SyntaxNode, verbose: bool) -> String {\n    let mut printer = ColoredPrinter { db, verbose, result: \"\".to_string() };\n    printer.print(syntax_root);\n    printer.result\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse cairo_lang_diagnostics::{Diagnostics, DiagnosticsBuilder, Maybe, ToMaybe};\nuse cairo_lang_filesystem::db::FilesGroup;\nuse cairo_lang_filesystem::ids::FileId;\nuse cairo_lang_syntax::node::ast::SyntaxFile;\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_utils::Upcast;\n\nuse crate::diagnostic::ParserDiagnostic;\nuse crate::parser::Parser;\n\n#[cfg(test)]\n#[path = \"db_test.rs\"]\nmod db_test;\n\n// Salsa database interface.\n#[salsa::query_group(ParserDatabase)]\npub trait ParserGroup: SyntaxGroup + Upcast<dyn SyntaxGroup> + FilesGroup {\n    /// Should only be used internally.\n    /// Parses a file and returns the result and the generated [ParserDiagnostic].\n    fn priv_file_syntax_data(&self, file_id: FileId) -> SyntaxData;\n    /// Parses a file and returns its AST.\n    fn file_syntax(&self, file_id: FileId) -> Maybe<Arc<SyntaxFile>>;\n    /// Returns the parser diagnostics for this file.\n    fn file_syntax_diagnostics(&self, file_id: FileId) -> Diagnostics<ParserDiagnostic>;\n}\n\n#[derive(Clone, PartialEq, Eq, Debug)]\npub struct SyntaxData {\n    diagnostics: Diagnostics<ParserDiagnostic>,\n    syntax: Maybe<Arc<SyntaxFile>>,\n}\n\npub fn priv_file_syntax_data(db: &dyn ParserGroup, file_id: FileId) -> SyntaxData {\n    let mut diagnostics = DiagnosticsBuilder::default();\n    let syntax = db\n        .file_content(file_id)\n        .to_maybe()\n        .map(|s| Arc::new(Parser::parse_file(db.upcast(), &mut diagnostics, file_id, s.as_str())));\n    SyntaxData { diagnostics: diagnostics.build(), syntax }\n}\n\npub fn file_syntax(db: &dyn ParserGroup, file_id: FileId) -> Maybe<Arc<SyntaxFile>> {\n    db.priv_file_syntax_data(file_id).syntax\n}\n\npub fn file_syntax_diagnostics(\n    db: &dyn ParserGroup,\n    file_id: FileId,\n) -> Diagnostics<ParserDiagnostic> {\n    db.priv_file_syntax_data(file_id).diagnostics\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_syntax::node::ast::{\n    ItemList, SyntaxFile, TerminalEndOfFile, TokenEndOfFile, Trivia,\n};\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::{SyntaxNode, Terminal, Token, TypedSyntaxNode};\nuse cairo_lang_utils::Upcast;\nuse pretty_assertions::assert_eq;\nuse smol_str::SmolStr;\nuse test_log::test;\n\nuse crate::db::ParserGroup;\nuse crate::test_utils::create_virtual_file;\nuse crate::utils::SimpleParserDatabase;\n\nfn build_empty_file_green_tree(db: &dyn SyntaxGroup) -> SyntaxFile {\n    let eof_token = TokenEndOfFile::new_green(db, SmolStr::from(\"\"));\n    let eof_terminal = TerminalEndOfFile::new_green(\n        db,\n        Trivia::new_green(db, vec![]),\n        eof_token,\n        Trivia::new_green(db, vec![]),\n    );\n    SyntaxFile::from_syntax_node(\n        db,\n        SyntaxNode::new_root(\n            db,\n            SyntaxFile::new_green(db, ItemList::new_green(db, vec![]), eof_terminal),\n        ),\n    )\n}\n\n#[test]\nfn test_parser() {\n    let db = SimpleParserDatabase::default();\n\n    // Parse empty cairo file.\n    let file_id = create_virtual_file(&db, \"file.cairo\", \"\");\n    let syntax_file = db.file_syntax(file_id).unwrap();\n    let diagnostics = db.file_syntax_diagnostics(file_id);\n    assert_eq!(diagnostics.format(&db), \"\");\n\n    let expected_syntax_file = build_empty_file_green_tree(db.upcast());\n\n    assert_eq!(*syntax_file, expected_syntax_file);\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_diagnostics::DiagnosticEntry;\nuse cairo_lang_filesystem::db::FilesGroup;\nuse cairo_lang_filesystem::ids::FileId;\nuse cairo_lang_filesystem::span::TextSpan;\nuse cairo_lang_syntax::node::kind::SyntaxKind;\nuse smol_str::SmolStr;\n\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ParserDiagnostic {\n    pub file_id: FileId,\n    pub span: TextSpan,\n    pub kind: ParserDiagnosticKind,\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum ParserDiagnosticKind {\n    // TODO(spapini): Add tokens from the recovery set to the message.\n    SkippedElement { element_name: SmolStr },\n    MissingToken(SyntaxKind),\n    MissingExpression,\n    MissingPathSegment,\n    MissingTypeClause,\n    MissingTypeExpression,\n    ReservedIdentifier { identifier: SmolStr },\n    UnderscoreNotAllowedAsIdentifier,\n}\nimpl DiagnosticEntry for ParserDiagnostic {\n    type DbType = dyn FilesGroup;\n\n    fn format(&self, _db: &dyn FilesGroup) -> String {\n        match self.kind {\n            ParserDiagnosticKind::SkippedElement { ref element_name } => {\n                format!(\"Skipped tokens. Expected: {element_name}.\")\n            }\n            ParserDiagnosticKind::MissingToken(kind) => {\n                format!(\"Missing token {kind:?}.\")\n            }\n            ParserDiagnosticKind::MissingExpression => {\n                \"Missing tokens. Expected an expression.\".to_string()\n            }\n            ParserDiagnosticKind::MissingPathSegment => {\n                \"Missing tokens. Expected a path segment.\".to_string()\n            }\n            ParserDiagnosticKind::MissingTypeClause => {\n                \"Unexpected token, expected ':' followed by a type.\".to_string()\n            }\n            ParserDiagnosticKind::MissingTypeExpression => {\n                \"Missing tokens. Expected a type expression.\".to_string()\n            }\n            ParserDiagnosticKind::ReservedIdentifier { ref identifier } => {\n                format!(\"'{identifier}' is a reserved identifier.\")\n            }\n            ParserDiagnosticKind::UnderscoreNotAllowedAsIdentifier => {\n                \"An underscore ('_') is not allowed as an identifier in this context.\".to_string()\n            }\n        }\n    }\n\n    fn location(&self, _db: &dyn FilesGroup) -> cairo_lang_diagnostics::DiagnosticLocation {\n        cairo_lang_diagnostics::DiagnosticLocation { file_id: self.file_id, span: self.span }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "#[cfg(test)]\n#[path = \"lexer_test.rs\"]\nmod test;\n\nuse cairo_lang_filesystem::ids::FileId;\nuse cairo_lang_filesystem::span::{TextOffset, TextSpan, TextWidth};\nuse cairo_lang_syntax::node::ast::{\n    TokenNewline, TokenSingleLineComment, TokenWhitespace, TriviumGreen,\n};\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::kind::SyntaxKind;\nuse cairo_lang_syntax::node::Token;\nuse smol_str::SmolStr;\n\npub struct Lexer<'a> {\n    db: &'a dyn SyntaxGroup,\n    text: &'a str,\n    previous_position: TextOffset,\n    current_position: TextOffset,\n    done: bool,\n}\n\nimpl<'a> Lexer<'a> {\n    // Ctors.\n    pub fn from_text(db: &'a dyn SyntaxGroup, _source: FileId, text: &'a str) -> Lexer<'a> {\n        Lexer {\n            db,\n            text,\n            previous_position: TextOffset::default(),\n            current_position: TextOffset::default(),\n            done: false,\n        }\n    }\n\n    pub fn position(&self) -> TextOffset {\n        self.current_position\n    }\n\n    // Helpers.\n    fn peek(&self) -> Option<char> {\n        self.current_position.take_from(self.text).chars().next()\n    }\n\n    fn peek_nth(&self, n: usize) -> Option<char> {\n        self.current_position.take_from(self.text).chars().nth(n)\n    }\n\n    fn take(&mut self) -> Option<char> {\n        let res = self.peek()?;\n        self.current_position = self.current_position.add_width(TextWidth::from_char(res));\n        Some(res)\n    }\n\n    /// Takes a character while the given function returns true.\n    fn take_while<F>(&mut self, f: F)\n    where\n        F: Fn(char) -> bool,\n    {\n        while self.peek().map(&f).unwrap_or(false) {\n            self.take();\n        }\n    }\n\n    fn peek_span_text(&self) -> &'a str {\n        let span = TextSpan { start: self.previous_position, end: self.current_position };\n        span.take(self.text)\n    }\n\n    fn consume_span(&mut self) -> &str {\n        let val = self.peek_span_text();\n        self.previous_position = self.current_position;\n        val\n    }\n\n    // Trivia matchers.\n    fn match_trivia(&mut self, leading: bool) -> Vec<TriviumGreen> {\n        let mut res: Vec<TriviumGreen> = Vec::new();\n        while let Some(current) = self.peek() {\n            let trivium = match current {\n                ' ' | '\\r' | '\\t' => self.match_trivium_whitespace(),\n                '\\n' => self.match_trivium_newline(),\n                '/' if self.peek_nth(1) == Some('/') => self.match_trivium_single_line_comment(),\n                _ => break,\n            };\n            res.push(trivium);\n            if current == '\\n' && !leading {\n                break;\n            }\n        }\n        res\n    }\n\n    /// Assumes the next character is one of [' ', '\\r', '\\t'].\n    fn match_trivium_whitespace(&mut self) -> TriviumGreen {\n        self.take_while(|s| matches!(s, ' ' | '\\r' | '\\t'));\n        TokenWhitespace::new_green(self.db, SmolStr::from(self.consume_span())).into()\n    }\n\n    /// Assumes the next character '/n'.\n    fn match_trivium_newline(&mut self) -> TriviumGreen {\n        self.take();\n        TokenNewline::new_green(self.db, SmolStr::from(self.consume_span())).into()\n    }\n\n    /// Assumes the next 2 characters are \"//\".\n    fn match_trivium_single_line_comment(&mut self) -> TriviumGreen {\n        self.take_while(|c| c != '\\n');\n        TokenSingleLineComment::new_green(self.db, SmolStr::from(self.consume_span())).into()\n    }\n\n    /// Token matchers.\n    /// =================================================================================\n\n    /// Takes a hex or decimal number.\n    fn take_token_literal_number(&mut self) -> TokenKind {\n        if self.peek() == Some('0') {\n            self.take();\n            if self.peek() == Some('x') {\n                self.take();\n                self.take_while(|c| c.is_ascii_hexdigit());\n            }\n        }\n\n        // If the token does not start with \"0x\", parse the token as a decimal number.\n        // Does nothing if the token starts with \"0x\" as it is already fully taken.\n        self.take_while(|c| c.is_ascii_digit());\n\n        // Parse _type suffix.\n        if self.peek() == Some('_') {\n            self.take_while(|c| c.is_ascii_alphanumeric() || c == '_');\n        }\n        TokenKind::LiteralNumber\n    }\n\n    /// Takes a short string.\n    fn take_token_short_string(&mut self) -> TokenKind {\n        self.take();\n        let mut escaped = false;\n        while let Some(token) = self.peek() {\n            self.take();\n            match token {\n                _ if escaped => escaped = false,\n                '\\\\' => escaped = true,\n                '\\'' => {\n                    break;\n                }\n                _ => {}\n            };\n        }\n\n        // Parse _type suffix.\n        if self.peek() == Some('_') {\n            self.take_while(|c| c.is_ascii_alphanumeric() || c == '_');\n        }\n        TokenKind::ShortString\n    }\n\n    /// Assumes the next character is [a-zA-Z_].\n    fn take_token_identifier(&mut self) -> TokenKind {\n        // TODO(spapini): Support or explicitly report general unicode characters.\n        self.take_while(|c| c.is_ascii_alphanumeric() || c == '_');\n\n        match self.peek_span_text() {\n            \"const\" => TokenKind::Const,\n            \"false\" => TokenKind::False,\n            \"true\" => TokenKind::True,\n            \"extern\" => TokenKind::Extern,\n            \"type\" => TokenKind::Type,\n            \"fn\" => TokenKind::Function,\n            \"trait\" => TokenKind::Trait,\n            \"impl\" => TokenKind::Impl,\n            \"of\" => TokenKind::Of,\n            \"mod\" => TokenKind::Module,\n            \"struct\" => TokenKind::Struct,\n            \"enum\" => TokenKind::Enum,\n            \"let\" => TokenKind::Let,\n            \"return\" => TokenKind::Return,\n            \"match\" => TokenKind::Match,\n            \"if\" => TokenKind::If,\n            \"else\" => TokenKind::Else,\n            \"use\" => TokenKind::Use,\n            \"implicits\" => TokenKind::Implicits,\n            \"ref\" => TokenKind::Ref,\n            \"mut\" => TokenKind::Mut,\n            \"nopanic\" => TokenKind::NoPanic,\n            \"_\" => TokenKind::Underscore,\n            _ => TokenKind::Identifier,\n        }\n    }\n\n    /// Takes a single character and returns the given kind.\n    fn take_token_of_kind(&mut self, kind: TokenKind) -> TokenKind {\n        self.take();\n        kind\n    }\n\n    /// If the next character is `second_char`, returns `long_kind`, otherwise returns `short_kind`.\n    fn pick_kind(\n        &mut self,\n        second_char: char,\n        long_kind: TokenKind,\n        short_kind: TokenKind,\n    ) -> TokenKind {\n        self.take();\n        if self.peek() == Some(second_char) {\n            self.take();\n            long_kind\n        } else {\n            short_kind\n        }\n    }\n\n    fn match_terminal(&mut self) -> LexerTerminal {\n        let leading_trivia = self.match_trivia(true);\n\n        let kind = if let Some(current) = self.peek() {\n            match current {\n                '0'..='9' => self.take_token_literal_number(),\n                '\\'' => self.take_token_short_string(),\n                ',' => self.take_token_of_kind(TokenKind::Comma),\n                ';' => self.take_token_of_kind(TokenKind::Semicolon),\n                '?' => self.take_token_of_kind(TokenKind::QuestionMark),\n                '{' => self.take_token_of_kind(TokenKind::LBrace),\n                '}' => self.take_token_of_kind(TokenKind::RBrace),\n                '[' => self.take_token_of_kind(TokenKind::LBrack),\n                ']' => self.take_token_of_kind(TokenKind::RBrack),\n                '(' => self.take_token_of_kind(TokenKind::LParen),\n                ')' => self.take_token_of_kind(TokenKind::RParen),\n                '.' => self.pick_kind('.', TokenKind::DotDot, TokenKind::Dot),\n                '*' => self.pick_kind('=', TokenKind::MulEq, TokenKind::Mul),\n                '/' => self.pick_kind('=', TokenKind::DivEq, TokenKind::Div),\n                '%' => self.pick_kind('=', TokenKind::ModEq, TokenKind::Mod),\n                '+' => self.pick_kind('=', TokenKind::PlusEq, TokenKind::Plus),\n                '#' => self.take_token_of_kind(TokenKind::Hash),\n                '-' => {\n                    self.take();\n                    match self.peek() {\n                        Some('>') => self.take_token_of_kind(TokenKind::Arrow),\n                        Some('=') => self.take_token_of_kind(TokenKind::MinusEq),\n                        _ => TokenKind::Minus,\n                    }\n                }\n                '<' => self.pick_kind('=', TokenKind::LE, TokenKind::LT),\n                '>' => self.pick_kind('=', TokenKind::GE, TokenKind::GT),\n                'a'..='z' | 'A'..='Z' | '_' => self.take_token_identifier(),\n                ':' => self.pick_kind(':', TokenKind::ColonColon, TokenKind::Colon),\n                '!' => self.pick_kind('=', TokenKind::Neq, TokenKind::Not),\n                '=' => {\n                    self.take();\n                    match self.peek() {\n                        Some('=') => self.take_token_of_kind(TokenKind::EqEq),\n                        Some('>') => self.take_token_of_kind(TokenKind::MatchArrow),\n                        _ => TokenKind::Eq,\n                    }\n                }\n                '&' => self.pick_kind('&', TokenKind::AndAnd, TokenKind::And),\n                '|' => self.pick_kind('|', TokenKind::OrOr, TokenKind::Or),\n                '^' => self.take_token_of_kind(TokenKind::Xor),\n                '@' => self.take_token_of_kind(TokenKind::At),\n                _ => self.take_token_of_kind(TokenKind::BadCharacters),\n            }\n        } else {\n            TokenKind::EndOfFile\n        };\n\n        let text = SmolStr::from(self.consume_span());\n        let trailing_trivia = self.match_trivia(false);\n        let terminal_kind = token_kind_to_terminal_syntax_kind(kind);\n\n        // TODO(yuval): log(verbose) \"consumed text: ...\"\n        LexerTerminal { text, kind: terminal_kind, leading_trivia, trailing_trivia }\n    }\n}\n\n/// Output terminal emitted by the lexer.\n#[derive(Clone, PartialEq, Eq, Debug)]\npub struct LexerTerminal {\n    pub text: SmolStr,\n    /// The kind of the inner token of this terminal.\n    pub kind: SyntaxKind,\n    pub leading_trivia: Vec<TriviumGreen>,\n    pub trailing_trivia: Vec<TriviumGreen>,\n}\nimpl LexerTerminal {\n    pub fn width(&self, db: &dyn SyntaxGroup) -> TextWidth {\n        self.leading_trivia.iter().map(|t| t.0.width(db)).sum::<TextWidth>()\n            + TextWidth::from_str(&self.text)\n            + self.trailing_trivia.iter().map(|t| t.0.width(db)).sum::<TextWidth>()\n    }\n}\n\nimpl Iterator for Lexer<'_> {\n    type Item = LexerTerminal;\n\n    /// Returns the next token. Once there are no more tokens left, returns token EOF.\n    /// One should not call this after EOF was returned. If one does, None is returned.\n    fn next(&mut self) -> Option<Self::Item> {\n        if self.done {\n            return None;\n        }\n        let lexer_terminal = self.match_terminal();\n        if lexer_terminal.kind == SyntaxKind::TerminalEndOfFile {\n            self.done = true;\n        };\n        Some(lexer_terminal)\n    }\n}\n\n#[derive(Clone, Copy, PartialEq, Debug, Eq, Hash)]\nenum TokenKind {\n    Identifier,\n\n    // Literals.\n    LiteralNumber,\n    ShortString,\n\n    // Keywords.\n    Const,\n    False,\n    True,\n    Extern,\n    Type,\n    Function,\n    Trait,\n    Impl,\n    Of,\n    Module,\n    Struct,\n    Enum,\n    Let,\n    Return,\n    Match,\n    If,\n    Else,\n    Use,\n    Implicits,\n    NoPanic,\n\n    // Modifiers.\n    Ref,\n    Mut,\n\n    // Punctuation.\n    And,\n    AndAnd,\n    At,\n    Or,\n    OrOr,\n    Xor,\n    EqEq,\n    Neq,\n    GE,\n    GT,\n    LE,\n    LT,\n    Not,\n    Plus,\n    PlusEq,\n    Minus,\n    MinusEq,\n    Mul,\n    MulEq,\n    Div,\n    DivEq,\n    Mod,\n    ModEq,\n\n    Colon,\n    ColonColon,\n    Comma,\n    Dot,\n    DotDot,\n    Eq,\n    Hash,\n    Semicolon,\n    QuestionMark,\n    Underscore,\n    LBrace,\n    RBrace,\n    LBrack,\n    RBrack,\n    LParen,\n    RParen,\n    Arrow,\n    MatchArrow,\n\n    // Meta.\n    EndOfFile,\n    BadCharacters,\n}\n\nfn token_kind_to_terminal_syntax_kind(kind: TokenKind) -> SyntaxKind {\n    match kind {\n        TokenKind::Const => SyntaxKind::TerminalConst,\n        TokenKind::Identifier => SyntaxKind::TerminalIdentifier,\n        TokenKind::LiteralNumber => SyntaxKind::TerminalLiteralNumber,\n        TokenKind::ShortString => SyntaxKind::TerminalShortString,\n        TokenKind::False => SyntaxKind::TerminalFalse,\n        TokenKind::True => SyntaxKind::TerminalTrue,\n        TokenKind::Extern => SyntaxKind::TerminalExtern,\n        TokenKind::Type => SyntaxKind::TerminalType,\n        TokenKind::Function => SyntaxKind::TerminalFunction,\n        TokenKind::Trait => SyntaxKind::TerminalTrait,\n        TokenKind::Impl => SyntaxKind::TerminalImpl,\n        TokenKind::Of => SyntaxKind::TerminalOf,\n        TokenKind::Module => SyntaxKind::TerminalModule,\n        TokenKind::Struct => SyntaxKind::TerminalStruct,\n        TokenKind::Enum => SyntaxKind::TerminalEnum,\n        TokenKind::Let => SyntaxKind::TerminalLet,\n        TokenKind::Return => SyntaxKind::TerminalReturn,\n        TokenKind::Match => SyntaxKind::TerminalMatch,\n        TokenKind::If => SyntaxKind::TerminalIf,\n        TokenKind::Else => SyntaxKind::TerminalElse,\n        TokenKind::Use => SyntaxKind::TerminalUse,\n        TokenKind::Implicits => SyntaxKind::TerminalImplicits,\n        TokenKind::NoPanic => SyntaxKind::TerminalNoPanic,\n        TokenKind::And => SyntaxKind::TerminalAnd,\n        TokenKind::AndAnd => SyntaxKind::TerminalAndAnd,\n        TokenKind::At => SyntaxKind::TerminalAt,\n        TokenKind::Or => SyntaxKind::TerminalOr,\n        TokenKind::OrOr => SyntaxKind::TerminalOrOr,\n        TokenKind::Xor => SyntaxKind::TerminalXor,\n        TokenKind::EqEq => SyntaxKind::TerminalEqEq,\n        TokenKind::Neq => SyntaxKind::TerminalNeq,\n        TokenKind::GE => SyntaxKind::TerminalGE,\n        TokenKind::GT => SyntaxKind::TerminalGT,\n        TokenKind::LE => SyntaxKind::TerminalLE,\n        TokenKind::LT => SyntaxKind::TerminalLT,\n        TokenKind::Not => SyntaxKind::TerminalNot,\n        TokenKind::Plus => SyntaxKind::TerminalPlus,\n        TokenKind::PlusEq => SyntaxKind::TerminalPlusEq,\n        TokenKind::Minus => SyntaxKind::TerminalMinus,\n        TokenKind::MinusEq => SyntaxKind::TerminalMinusEq,\n        TokenKind::Mul => SyntaxKind::TerminalMul,\n        TokenKind::MulEq => SyntaxKind::TerminalMulEq,\n        TokenKind::Div => SyntaxKind::TerminalDiv,\n        TokenKind::DivEq => SyntaxKind::TerminalDivEq,\n        TokenKind::Mod => SyntaxKind::TerminalMod,\n        TokenKind::ModEq => SyntaxKind::TerminalModEq,\n        TokenKind::Colon => SyntaxKind::TerminalColon,\n        TokenKind::ColonColon => SyntaxKind::TerminalColonColon,\n        TokenKind::Comma => SyntaxKind::TerminalComma,\n        TokenKind::Dot => SyntaxKind::TerminalDot,\n        TokenKind::DotDot => SyntaxKind::TerminalDotDot,\n        TokenKind::Eq => SyntaxKind::TerminalEq,\n        TokenKind::Hash => SyntaxKind::TerminalHash,\n        TokenKind::Semicolon => SyntaxKind::TerminalSemicolon,\n        TokenKind::QuestionMark => SyntaxKind::TerminalQuestionMark,\n        TokenKind::Underscore => SyntaxKind::TerminalUnderscore,\n        TokenKind::LBrace => SyntaxKind::TerminalLBrace,\n        TokenKind::RBrace => SyntaxKind::TerminalRBrace,\n        TokenKind::LBrack => SyntaxKind::TerminalLBrack,\n        TokenKind::RBrack => SyntaxKind::TerminalRBrack,\n        TokenKind::LParen => SyntaxKind::TerminalLParen,\n        TokenKind::RParen => SyntaxKind::TerminalRParen,\n        TokenKind::Ref => SyntaxKind::TerminalRef,\n        TokenKind::Mut => SyntaxKind::TerminalMut,\n        TokenKind::Arrow => SyntaxKind::TerminalArrow,\n        TokenKind::MatchArrow => SyntaxKind::TerminalMatchArrow,\n        TokenKind::BadCharacters => SyntaxKind::TerminalBadCharacters,\n        TokenKind::EndOfFile => SyntaxKind::TerminalEndOfFile,\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_filesystem::ids::FileId;\nuse cairo_lang_syntax::node::ast::{TokenSingleLineComment, TokenWhitespace};\nuse cairo_lang_syntax::node::kind::SyntaxKind;\nuse cairo_lang_syntax::node::Token;\nuse salsa::{InternId, InternKey};\nuse test_log::test;\n\nuse super::Lexer;\nuse crate::lexer::LexerTerminal;\nuse crate::utils::SimpleParserDatabase;\n\n// TODO(spapini): Use snapshot/regression tests.\n\nfn terminal_kind_to_text(kind: SyntaxKind) -> Vec<&'static str> {\n    match kind {\n        SyntaxKind::TerminalIdentifier => vec![\"abc\", \"_az12f\", \"A90g5__\"],\n        SyntaxKind::TerminalLiteralNumber => {\n            vec![\n                \"0\",\n                \"0xA2\",\n                \"9\",\n                \"00\",\n                \"1234567890123456789012345678901234567890\",\n                \"11_u128\",\n                \"0xA2_u128\",\n            ]\n        }\n        SyntaxKind::TerminalFalse => vec![\"false\"],\n        SyntaxKind::TerminalExtern => vec![\"extern\"],\n        SyntaxKind::TerminalType => vec![\"type\"],\n        SyntaxKind::TerminalFunction => vec![\"fn\"],\n        SyntaxKind::TerminalTrait => vec![\"trait\"],\n        SyntaxKind::TerminalImpl => vec![\"impl\"],\n        SyntaxKind::TerminalOf => vec![\"of\"],\n        SyntaxKind::TerminalLet => vec![\"let\"],\n        SyntaxKind::TerminalMut => vec![\"mut\"],\n        SyntaxKind::TerminalRef => vec![\"ref\"],\n        SyntaxKind::TerminalNoPanic => vec![\"nopanic\"],\n        SyntaxKind::TerminalModule => vec![\"mod\"],\n        SyntaxKind::TerminalStruct => vec![\"struct\"],\n        SyntaxKind::TerminalEnum => vec![\"enum\"],\n        SyntaxKind::TerminalTrue => vec![\"true\"],\n        SyntaxKind::TerminalReturn => vec![\"return\"],\n        SyntaxKind::TerminalMatch => vec![\"match\"],\n        SyntaxKind::TerminalIf => vec![\"if\"],\n        SyntaxKind::TerminalElse => vec![\"else\"],\n        SyntaxKind::TerminalUse => vec![\"use\"],\n        SyntaxKind::TerminalAnd => vec![\"&\"],\n        SyntaxKind::TerminalAndAnd => vec![\"&&\"],\n        SyntaxKind::TerminalAt => vec![\"@\"],\n        SyntaxKind::TerminalColon => vec![\":\"],\n        SyntaxKind::TerminalColonColon => vec![\"::\"],\n        SyntaxKind::TerminalComma => vec![\",\"],\n        SyntaxKind::TerminalDiv => vec![\"/\"],\n        SyntaxKind::TerminalDivEq => vec![\"/=\"],\n        SyntaxKind::TerminalMod => vec![\"%\"],\n        SyntaxKind::TerminalModEq => vec![\"%=\"],\n        SyntaxKind::TerminalDot => vec![\".\"],\n        SyntaxKind::TerminalDotDot => vec![\"..\"],\n        SyntaxKind::TerminalEq => vec![\"=\"],\n        SyntaxKind::TerminalEqEq => vec![\"==\"],\n        SyntaxKind::TerminalGE => vec![\">=\"],\n        SyntaxKind::TerminalGT => vec![\">\"],\n        SyntaxKind::TerminalLE => vec![\"<=\"],\n        SyntaxKind::TerminalLT => vec![\"<\"],\n        SyntaxKind::TerminalMinus => vec![\"-\"],\n        SyntaxKind::TerminalMinusEq => vec![\"-=\"],\n        SyntaxKind::TerminalMul => vec![\"*\"],\n        SyntaxKind::TerminalMulEq => vec![\"*=\"],\n        SyntaxKind::TerminalNeq => vec![\"!=\"],\n        SyntaxKind::TerminalNot => vec![\"!\"],\n        SyntaxKind::TerminalOr => vec![\"|\"],\n        SyntaxKind::TerminalOrOr => vec![\"||\"],\n        SyntaxKind::TerminalXor => vec![\"^\"],\n        SyntaxKind::TerminalPlus => vec![\"+\"],\n        SyntaxKind::TerminalPlusEq => vec![\"+=\"],\n        SyntaxKind::TerminalSemicolon => vec![\";\"],\n        SyntaxKind::TerminalQuestionMark => vec![\"?\"],\n        SyntaxKind::TerminalUnderscore => vec![\"_\"],\n        SyntaxKind::TerminalLBrace => vec![\"{\"],\n        SyntaxKind::TerminalRBrace => vec![\"}\"],\n        SyntaxKind::TerminalLBrack => vec![\"[\"],\n        SyntaxKind::TerminalRBrack => vec![\"]\"],\n        SyntaxKind::TerminalLParen => vec![\"(\"],\n        SyntaxKind::TerminalRParen => vec![\")\"],\n        SyntaxKind::TerminalArrow => vec![\"->\"],\n        SyntaxKind::TerminalMatchArrow => vec![\"=>\"],\n        SyntaxKind::TerminalEndOfFile => vec![],\n        _ => {\n            assert!(!kind.is_terminal());\n            vec![]\n        }\n    }\n}\n\nfn terminal_kinds() -> Vec<SyntaxKind> {\n    vec![\n        SyntaxKind::TerminalIdentifier,\n        SyntaxKind::TerminalLiteralNumber,\n        SyntaxKind::TerminalFalse,\n        SyntaxKind::TerminalTrue,\n        SyntaxKind::TerminalExtern,\n        SyntaxKind::TerminalType,\n        SyntaxKind::TerminalFunction,\n        SyntaxKind::TerminalTrait,\n        SyntaxKind::TerminalImpl,\n        SyntaxKind::TerminalOf,\n        SyntaxKind::TerminalModule,\n        SyntaxKind::TerminalStruct,\n        SyntaxKind::TerminalEnum,\n        SyntaxKind::TerminalLet,\n        SyntaxKind::TerminalMut,\n        SyntaxKind::TerminalRef,\n        SyntaxKind::TerminalNoPanic,\n        SyntaxKind::TerminalReturn,\n        SyntaxKind::TerminalMatch,\n        SyntaxKind::TerminalIf,\n        SyntaxKind::TerminalElse,\n        SyntaxKind::TerminalUse,\n        SyntaxKind::TerminalAnd,\n        SyntaxKind::TerminalAndAnd,\n        SyntaxKind::TerminalAt,\n        SyntaxKind::TerminalOr,\n        SyntaxKind::TerminalOrOr,\n        SyntaxKind::TerminalXor,\n        SyntaxKind::TerminalEqEq,\n        SyntaxKind::TerminalNeq,\n        SyntaxKind::TerminalGE,\n        SyntaxKind::TerminalGT,\n        SyntaxKind::TerminalLE,\n        SyntaxKind::TerminalLT,\n        SyntaxKind::TerminalNot,\n        SyntaxKind::TerminalPlus,\n        SyntaxKind::TerminalPlusEq,\n        SyntaxKind::TerminalMinus,\n        SyntaxKind::TerminalMinusEq,\n        SyntaxKind::TerminalMul,\n        SyntaxKind::TerminalMulEq,\n        SyntaxKind::TerminalDiv,\n        SyntaxKind::TerminalDivEq,\n        SyntaxKind::TerminalMod,\n        SyntaxKind::TerminalModEq,\n        SyntaxKind::TerminalColon,\n        SyntaxKind::TerminalColonColon,\n        SyntaxKind::TerminalComma,\n        SyntaxKind::TerminalDot,\n        SyntaxKind::TerminalDotDot,\n        SyntaxKind::TerminalEq,\n        SyntaxKind::TerminalSemicolon,\n        SyntaxKind::TerminalQuestionMark,\n        SyntaxKind::TerminalUnderscore,\n        SyntaxKind::TerminalLBrace,\n        SyntaxKind::TerminalRBrace,\n        SyntaxKind::TerminalLBrack,\n        SyntaxKind::TerminalRBrack,\n        SyntaxKind::TerminalLParen,\n        SyntaxKind::TerminalRParen,\n        SyntaxKind::TerminalArrow,\n        SyntaxKind::TerminalMatchArrow,\n        SyntaxKind::TerminalEndOfFile,\n    ]\n}\n\nfn token_separators() -> Vec<&'static str> {\n    vec![\" \", \"\\t\", \"\\n\", \" // Comment with unicode \\n\"]\n}\n\nfn need_separator(\n    kind0: SyntaxKind,\n    text0: &'static str,\n    kind1: SyntaxKind,\n    text1: &'static str,\n) -> bool {\n    if is_identifier_like(kind0)\n        && (is_identifier_like(kind1) || matches!(kind1, SyntaxKind::TerminalLiteralNumber))\n    {\n        return true;\n    }\n    if kind0 == SyntaxKind::TerminalLiteralNumber && (kind0 == kind1 || is_identifier_like(kind1)) {\n        return true;\n    }\n    if (text0 == \"&\" && text1.starts_with('&'))\n        || (text0 == \"|\" && text1.starts_with('|'))\n        || (text0 == \"/\" && text1.starts_with('/'))\n        || ((text0 == \"=\" || text0 == \"!\") && text1.starts_with('='))\n        || ((text0 == \"=\") && text1.starts_with('>'))\n        || ((text0 == \"<\" || text0 == \">\") && text1.starts_with('='))\n        || (text0 == \":\" && text1.starts_with(':'))\n        || (text0 == \".\" && text1.starts_with('.'))\n        || (text0 == \"-\" && (text1.starts_with('>') || text1.starts_with('=')))\n        || ((text0 == \"+\" || text0 == \"*\" || text0 == \"/\" || text0 == \"%\")\n            && text1.starts_with('='))\n        || (kind0 == SyntaxKind::TerminalLiteralNumber && kind0 == kind1)\n    {\n        return true;\n    }\n    false\n}\n\nfn is_identifier_like(kind: SyntaxKind) -> bool {\n    matches!(kind, SyntaxKind::TerminalIdentifier | SyntaxKind::TerminalUnderscore)\n        || kind.is_keyword_terminal()\n}\n\nfn terminal_kind_and_text() -> Vec<(SyntaxKind, &'static str)> {\n    let mut res: Vec<(SyntaxKind, &'static str)> = Vec::new();\n    for kind in terminal_kinds() {\n        for text in terminal_kind_to_text(kind) {\n            res.push((kind, text));\n        }\n    }\n    res\n}\n\nfn trivia_kinds() -> Vec<SyntaxKind> {\n    vec![SyntaxKind::TokenWhitespace, SyntaxKind::TokenNewline, SyntaxKind::TokenSingleLineComment]\n}\nfn trivia_kind_to_text(kind: SyntaxKind) -> Vec<&'static str> {\n    match kind {\n        SyntaxKind::TokenSingleLineComment => vec![\"// abc def\\n\", \"///\\n\", \"//=\\n\"],\n        SyntaxKind::TokenWhitespace => vec![\" \", \"\\t\", \"\\r\"],\n        SyntaxKind::TokenNewline => vec![\"\\n\"],\n        _ => vec![],\n    }\n}\nfn trivia_texts() -> Vec<&'static str> {\n    let mut res: Vec<&'static str> = Vec::new();\n    for kind in trivia_kinds() {\n        for text in trivia_kind_to_text(kind) {\n            res.push(text);\n        }\n    }\n    res\n}\n\nfn test_source() -> FileId {\n    FileId::from_intern_id(InternId::from(100u32))\n}\n\n#[test]\nfn test_lex_single_token() {\n    let db_val = SimpleParserDatabase::default();\n    let db = &db_val;\n    for (kind, text) in terminal_kind_and_text() {\n        let mut lexer = Lexer::from_text(db, test_source(), text);\n        let terminal = lexer.next().unwrap();\n        // TODO(spapini): Remove calling new_root on non root elements.\n        assert_eq!(terminal.kind, kind, \"Wrong token kind, with text: \\\"{text}\\\".\");\n        assert_eq!(terminal.text, text, \"Wrong token text.\");\n\n        assert_eq!(\n            lexer.next().unwrap().kind,\n            SyntaxKind::TerminalEndOfFile,\n            \"Wrong eof token, with text: \\\"{text}\\\".\"\n        );\n        assert!(lexer.next().is_none(), \"Expected end of lexer stream.\");\n    }\n}\n\n#[test]\nfn test_lex_double_token() {\n    let db_val = SimpleParserDatabase::default();\n    let db = &db_val;\n    for (kind0, text0) in terminal_kind_and_text() {\n        for (kind1, text1) in terminal_kind_and_text() {\n            let mut separators = token_separators();\n            if !need_separator(kind0, text0, kind1, text1) {\n                separators.push(\"\");\n            }\n            for separator in separators {\n                let text = format!(\"{text0}{separator}{text1}\");\n                let mut lexer = Lexer::from_text(db, test_source(), text.as_str());\n\n                let terminal = lexer.next().unwrap();\n                let token_text = terminal.text;\n                assert_eq!(\n                    terminal.kind, kind0,\n                    \"Wrong first token kind: {}, expected: {kind0}. Text: \\\"{token_text}\\\".\",\n                    terminal.kind\n                );\n                assert_eq!(\n                    token_text, text0,\n                    \"Wrong first token text, with total text: \\\"{token_text}\\\".\",\n                );\n\n                let terminal = lexer.next().unwrap();\n                let token_text = terminal.text;\n                assert_eq!(\n                    terminal.kind, kind1,\n                    \"Wrong second token kind {}, expected: {kind1}. Text: \\\"{token_text}\\\".\",\n                    terminal.kind\n                );\n                assert_eq!(\n                    token_text, text1,\n                    \"Wrong second token text, with total text: \\\"{token_text}\\\".\",\n                );\n\n                assert_eq!(\n                    lexer.next().unwrap().kind,\n                    SyntaxKind::TerminalEndOfFile,\n                    \"Wrong eof token, with text: \\\"{text}\\\".\",\n                );\n                assert!(lexer.next().is_none(), \"Expected end of lexer stream.\");\n            }\n        }\n    }\n}\n\n#[test]\nfn test_lex_token_with_trivia() {\n    let db_val = SimpleParserDatabase::default();\n    let db = &db_val;\n    for (kind, expected_token_text) in terminal_kind_and_text() {\n        for leading_trivia in trivia_texts() {\n            for trailing_trivia in trivia_texts() {\n                let text = format!(\"{leading_trivia}{expected_token_text} {trailing_trivia}\");\n                let mut lexer = Lexer::from_text(db, test_source(), text.as_str());\n                let terminal = lexer.next().unwrap();\n                let token_text = terminal.text;\n                assert_eq!(terminal.kind, kind, \"Wrong token kind, with text: \\\"{text}\\\".\");\n                assert_eq!(token_text, expected_token_text, \"Wrong token text.\");\n                // TODO: verify trivia kinds and texts\n\n                assert_eq!(\n                    lexer.next().unwrap().kind,\n                    SyntaxKind::TerminalEndOfFile,\n                    \"Wrong eof token, with text: \\\"{text}\\\".\"\n                );\n                assert!(lexer.next().is_none(), \"Expected end of lexer stream.\");\n            }\n        }\n    }\n}\n\n#[test]\nfn test_cases() {\n    let db_val = SimpleParserDatabase::default();\n    let db = &db_val;\n    let res: Vec<LexerTerminal> =\n        Lexer::from_text(db, test_source(), \"let x: &T = ` 6; //  5+ 3;\").collect();\n    assert_eq!(\n        res,\n        vec![\n            LexerTerminal {\n                text: \"let\".into(),\n                kind: SyntaxKind::TerminalLet,\n                leading_trivia: vec![],\n                trailing_trivia: vec![TokenWhitespace::new_green(db, \" \".into()).into()]\n            },\n            LexerTerminal {\n                text: \"x\".into(),\n                kind: SyntaxKind::TerminalIdentifier,\n                leading_trivia: vec![],\n                trailing_trivia: vec![]\n            },\n            LexerTerminal {\n                text: \":\".into(),\n                kind: SyntaxKind::TerminalColon,\n                leading_trivia: vec![],\n                trailing_trivia: vec![TokenWhitespace::new_green(db, \" \".into()).into()]\n            },\n            LexerTerminal {\n                text: \"&\".into(),\n                kind: SyntaxKind::TerminalAnd,\n                leading_trivia: vec![],\n                trailing_trivia: vec![]\n            },\n            LexerTerminal {\n                text: \"T\".into(),\n                kind: SyntaxKind::TerminalIdentifier,\n                leading_trivia: vec![],\n                trailing_trivia: vec![TokenWhitespace::new_green(db, \" \".into()).into()]\n            },\n            LexerTerminal {\n                text: \"=\".into(),\n                kind: SyntaxKind::TerminalEq,\n                leading_trivia: vec![],\n                trailing_trivia: vec![TokenWhitespace::new_green(db, \" \".into()).into()]\n            },\n            LexerTerminal {\n                text: \"`\".into(),\n                kind: SyntaxKind::TerminalBadCharacters,\n                leading_trivia: vec![],\n                trailing_trivia: vec![TokenWhitespace::new_green(db, \" \".into()).into()]\n            },\n            LexerTerminal {\n                text: \"6\".into(),\n                kind: SyntaxKind::TerminalLiteralNumber,\n                leading_trivia: vec![],\n                trailing_trivia: vec![]\n            },\n            LexerTerminal {\n                text: \";\".into(),\n                kind: SyntaxKind::TerminalSemicolon,\n                leading_trivia: vec![],\n                trailing_trivia: vec![\n                    TokenWhitespace::new_green(db, \" \".into()).into(),\n                    TokenSingleLineComment::new_green(db, \"//  5+ 3;\".into()).into()\n                ]\n            },\n            LexerTerminal {\n                text: \"\".into(),\n                kind: SyntaxKind::TerminalEndOfFile,\n                leading_trivia: vec![],\n                trailing_trivia: vec![]\n            }\n        ]\n    );\n}\n\n#[test]\nfn test_bad_character() {\n    let db_val = SimpleParserDatabase::default();\n    let db = &db_val;\n\n    let text = \"`\";\n    let mut lexer = Lexer::from_text(db, test_source(), text);\n    let terminal = lexer.next().unwrap();\n    let token_text = terminal.text;\n    assert_eq!(\n        terminal.kind,\n        SyntaxKind::TerminalBadCharacters,\n        \"Wrong token kind, with text: \\\"{text}\\\".\",\n    );\n    assert_eq!(token_text, text, \"Wrong token text.\");\n\n    assert_eq!(\n        lexer.next().unwrap().kind,\n        SyntaxKind::TerminalEndOfFile,\n        \"Wrong eof token, with text: \\\"{text}\\\".\"\n    );\n    assert!(lexer.next().is_none(), \"Expected end of lexer stream.\");\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Cairo parser.\n//!\n//! This crate is responsible for parsing Cairo code.\npub mod colored_printer;\npub mod db;\npub mod diagnostic;\npub mod lexer;\npub mod operators;\npub mod parser;\npub mod printer;\npub mod recovery;\npub mod test_utils;\npub mod utils;\n\npub use diagnostic::ParserDiagnostic;\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_syntax::node::kind::SyntaxKind;\n\npub fn get_unary_operator_precedence(kind: SyntaxKind) -> Option<usize> {\n    match kind {\n        SyntaxKind::TerminalAt | SyntaxKind::TerminalNot | SyntaxKind::TerminalMul => Some(2),\n        SyntaxKind::TerminalMinus => Some(4),\n        _ => None,\n    }\n}\npub fn get_post_operator_precedence(kind: SyntaxKind) -> Option<usize> {\n    match kind {\n        SyntaxKind::TerminalDot => Some(0),\n        SyntaxKind::TerminalQuestionMark\n        // [] Operator.\n        | SyntaxKind::TerminalLBrack => Some(1),\n        SyntaxKind::TerminalAt | SyntaxKind::TerminalNot => Some(2),\n        SyntaxKind::TerminalMul | SyntaxKind::TerminalDiv | SyntaxKind::TerminalMod => Some(3),\n        SyntaxKind::TerminalPlus | SyntaxKind::TerminalMinus => Some(4),\n        SyntaxKind::TerminalEqEq\n        | SyntaxKind::TerminalNeq\n        | SyntaxKind::TerminalLT\n        | SyntaxKind::TerminalGT\n        | SyntaxKind::TerminalLE\n        | SyntaxKind::TerminalGE => Some(5),\n        SyntaxKind::TerminalAnd => Some(6),\n        SyntaxKind::TerminalOr => Some(7),\n        SyntaxKind::TerminalXor => Some(8),\n        SyntaxKind::TerminalEq\n        | SyntaxKind::TerminalPlusEq\n        | SyntaxKind::TerminalMinusEq\n        | SyntaxKind::TerminalMulEq\n        | SyntaxKind::TerminalDivEq\n        | SyntaxKind::TerminalModEq => Some(9),\n        _ => None,\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "#[cfg(test)]\n#[path = \"parser_test.rs\"]\nmod test;\n\nuse std::mem;\n\nuse cairo_lang_diagnostics::DiagnosticsBuilder;\nuse cairo_lang_filesystem::ids::FileId;\nuse cairo_lang_filesystem::span::{TextOffset, TextSpan, TextWidth};\nuse cairo_lang_syntax as syntax;\nuse cairo_lang_syntax::node::ast::*;\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::kind::SyntaxKind;\nuse cairo_lang_syntax::node::{SyntaxNode, Token, TypedSyntaxNode};\nuse syntax::node::green::{GreenNode, GreenNodeDetails};\n\nuse crate::diagnostic::ParserDiagnosticKind;\nuse crate::lexer::{Lexer, LexerTerminal};\nuse crate::operators::{get_post_operator_precedence, get_unary_operator_precedence};\nuse crate::recovery::is_of_kind;\nuse crate::ParserDiagnostic;\n\npub struct Parser<'a> {\n    db: &'a dyn SyntaxGroup,\n    file_id: FileId,\n    lexer: Lexer<'a>,\n    /// The next terminal to handle.\n    next_terminal: LexerTerminal,\n    /// A vector of pending trivia to be added as leading trivia to the next valid terminal.\n    pending_trivia: Vec<TriviumGreen>,\n    /// The current offset, excluding the current terminal.\n    offset: TextOffset,\n    /// The width of the current terminal being handled.\n    current_width: TextWidth,\n    /// The length of the trailing trivia following the last read token.\n    last_trivia_length: TextWidth,\n    diagnostics: &'a mut DiagnosticsBuilder<ParserDiagnostic>,\n}\n\n// try_parse_<something>: returns a green ID with a kind that represents 'something' or None if\n// 'something' can't be parsed.\n// If None is returned, the current token is not consumed, otherwise it is (taken or skipped).\n// Used when something may or may not be there and we can act differently according to each case.\n//\n// parse_option_<something>: returns a green ID with a kind that represents 'something'. If\n// 'something' can't be parsed, returns a green ID with the relevant empty kind. Used for an\n// optional child. Always returns some green ID.\n//\n// parse_<something>: returns a green ID with a kind that represents 'something'. If\n// 'something' can't be parsed, returns a green ID with the relevant missing kind. Used when we\n// expect 'something' to be there. Always returns some green ID.\n//\n// expect_<something>: similar to parse_<something>, but assumes the current token is as expected.\n// Therefore, it always returns a GreenId of a node with a kind that represents 'something' and\n// never a missing kind.\n// Should only be called after checking the current token.\n\nconst MAX_PRECEDENCE: usize = 10;\nimpl<'a> Parser<'a> {\n    /// Parses a file.\n    pub fn parse_file(\n        db: &'a dyn SyntaxGroup,\n        diagnostics: &mut DiagnosticsBuilder<ParserDiagnostic>,\n        file_id: FileId,\n        text: &'a str,\n    ) -> SyntaxFile {\n        let mut lexer = Lexer::from_text(db, file_id, text);\n        let next_terminal = lexer.next().unwrap();\n        let parser = Parser {\n            db,\n            file_id,\n            lexer,\n            next_terminal,\n            pending_trivia: Vec::new(),\n            offset: Default::default(),\n            current_width: Default::default(),\n            last_trivia_length: Default::default(),\n            diagnostics,\n        };\n        let green = parser.parse_syntax_file();\n        SyntaxFile::from_syntax_node(db, SyntaxNode::new_root(db, green))\n    }\n\n    /// Returns a GreenId of an ExprMissing and adds a diagnostic describing it.\n    fn create_and_report_missing<T: TypedSyntaxNode>(\n        &mut self,\n        missing_kind: ParserDiagnosticKind,\n    ) -> T::Green {\n        let next_offset = self.offset.add_width(self.current_width - self.last_trivia_length);\n        self.diagnostics.add(ParserDiagnostic {\n            file_id: self.file_id,\n            kind: missing_kind,\n            span: TextSpan { start: next_offset, end: next_offset },\n        });\n        T::missing(self.db)\n    }\n\n    /// Returns the missing terminal and adds the corresponding missing token\n    /// diagnostic report.\n    fn create_and_report_missing_terminal<Terminal: syntax::node::Terminal>(\n        &mut self,\n    ) -> Terminal::Green {\n        self.create_and_report_missing::<Terminal>(ParserDiagnosticKind::MissingToken(\n            Terminal::KIND,\n        ))\n    }\n\n    pub fn parse_syntax_file(mut self) -> SyntaxFileGreen {\n        let items = ItemList::new_green(\n            self.db,\n            self.parse_attributed_list(Self::try_parse_top_level_item, is_of_kind!(), \"item\"),\n        );\n        // This will not panic since the above parsing only stops when reaches EOF.\n        assert_eq!(self.peek().kind, SyntaxKind::TerminalEndOfFile);\n\n        // Fix offset in case there are skipped tokens before EOF. This is usually done in\n        // self.take_raw() but here we don't call self.take_raw as it tries to read the next\n        // token, which doesn't exist.\n        self.offset = self.offset.add_width(self.current_width);\n\n        let eof = self.add_trivia_to_terminal::<TerminalEndOfFile>(self.next_terminal.clone());\n        SyntaxFile::new_green(self.db, items, eof)\n    }\n\n    // ------------------------------- Top level items -------------------------------\n\n    /// Returns a GreenId of a node with an Item.* kind (see [syntax::node::ast::Item]).\n    /// If can't parse as a top level item, keeps skipping tokens until it can.\n    /// Returns None only when it reaches EOF.\n    pub fn try_parse_top_level_item(&mut self) -> Option<ItemGreen> {\n        let attributes = self.parse_attribute_list(\n            \"Module/Use/FreeFunction/ExternFunction/ExternType/Trait/Impl/Struct/Enum\",\n        );\n\n        match self.peek().kind {\n            SyntaxKind::TerminalConst => Some(self.expect_const(attributes).into()),\n            SyntaxKind::TerminalModule => Some(self.expect_module(attributes).into()),\n            SyntaxKind::TerminalStruct => Some(self.expect_struct(attributes).into()),\n            SyntaxKind::TerminalEnum => Some(self.expect_enum(attributes).into()),\n            SyntaxKind::TerminalType => Some(self.expect_type_alias(attributes).into()),\n            SyntaxKind::TerminalExtern => Some(self.expect_extern_item(attributes)),\n            SyntaxKind::TerminalFunction => Some(self.expect_free_function(attributes).into()),\n            SyntaxKind::TerminalUse => Some(self.expect_use(attributes).into()),\n            SyntaxKind::TerminalTrait => Some(self.expect_trait(attributes).into()),\n            SyntaxKind::TerminalImpl => Some(self.expect_impl(attributes).into()),\n            _ => None,\n        }\n    }\n\n    /// Assumes the current token is Module.\n    /// Expected pattern: `mod <Identifier> \\{<ItemList>\\}` or `mod <Identifier>;`.\n    fn expect_module(&mut self, attributes: AttributeListGreen) -> ItemModuleGreen {\n        let module_kw = self.take::<TerminalModule>();\n        let name = self.parse_identifier();\n\n        let body = match self.peek().kind {\n            SyntaxKind::TerminalLBrace => {\n                let lbrace = self.take::<TerminalLBrace>();\n                let items = ItemList::new_green(\n                    self.db,\n                    self.parse_attributed_list(\n                        Self::try_parse_top_level_item,\n                        is_of_kind!(rbrace),\n                        \"item\",\n                    ),\n                );\n                let rbrace = self.parse_token::<TerminalRBrace>();\n                ModuleBody::new_green(self.db, lbrace, items, rbrace).into()\n            }\n            // TODO: Improve diagnostic to indicate semicolon or a body were expected.\n            _ => self.parse_token::<TerminalSemicolon>().into(),\n        };\n\n        ItemModule::new_green(self.db, attributes, module_kw, name, body)\n    }\n\n    /// Assumes the current token is Struct.\n    /// Expected pattern: `struct<Identifier>{<ParamList>}`\n    fn expect_struct(&mut self, attributes: AttributeListGreen) -> ItemStructGreen {\n        let struct_kw = self.take::<TerminalStruct>();\n        let name = self.parse_identifier();\n        let generic_params = self.parse_optional_generic_params();\n        let lbrace = self.parse_token::<TerminalLBrace>();\n        let members = self.parse_member_list();\n        let rbrace = self.parse_token::<TerminalRBrace>();\n        ItemStruct::new_green(\n            self.db,\n            attributes,\n            struct_kw,\n            name,\n            generic_params,\n            lbrace,\n            members,\n            rbrace,\n        )\n    }\n\n    /// Assumes the current token is Enum.\n    /// Expected pattern: `enum<Identifier>{<ParamList>}`\n    fn expect_enum(&mut self, attributes: AttributeListGreen) -> ItemEnumGreen {\n        let enum_kw = self.take::<TerminalEnum>();\n        let name = self.parse_identifier();\n        let generic_params = self.parse_optional_generic_params();\n        let lbrace = self.parse_token::<TerminalLBrace>();\n        let variants = self.parse_member_list();\n        let rbrace = self.parse_token::<TerminalRBrace>();\n        ItemEnum::new_green(\n            self.db,\n            attributes,\n            enum_kw,\n            name,\n            generic_params,\n            lbrace,\n            variants,\n            rbrace,\n        )\n    }\n\n    /// Assumes the current token is type.\n    /// Expected pattern: `type <Identifier>{<ParamList>} = <TypeExpression>`\n    fn expect_type_alias(&mut self, attributes: AttributeListGreen) -> ItemTypeAliasGreen {\n        let type_kw = self.take::<TerminalType>();\n        let name = self.parse_identifier();\n        let generic_params = self.parse_optional_generic_params();\n        let eq = self.parse_token::<TerminalEq>();\n        let ty = self.try_parse_type_expr().unwrap_or_else(|| {\n            self.create_and_report_missing::<Expr>(ParserDiagnosticKind::MissingTypeExpression)\n        });\n        let semicolon = self.parse_token::<TerminalSemicolon>();\n        ItemTypeAlias::new_green(\n            self.db,\n            attributes,\n            type_kw,\n            name,\n            generic_params,\n            eq,\n            ty,\n            semicolon,\n        )\n    }\n\n    /// Expected pattern: `<ParenthesizedParamList><ReturnTypeClause>`\n    fn expect_function_signature(&mut self) -> FunctionSignatureGreen {\n        let lparen = self.parse_token::<TerminalLParen>();\n        let params = self.parse_param_list();\n        let rparen = self.parse_token::<TerminalRParen>();\n        let return_type_clause = self.parse_option_return_type_clause();\n        let implicits_clause = self.parse_option_implicits_clause();\n        let optional_no_panic = if self.peek().kind == SyntaxKind::TerminalNoPanic {\n            self.take::<TerminalNoPanic>().into()\n        } else {\n            OptionTerminalNoPanicEmpty::new_green(self.db).into()\n        };\n\n        FunctionSignature::new_green(\n            self.db,\n            lparen,\n            params,\n            rparen,\n            return_type_clause,\n            implicits_clause,\n            optional_no_panic,\n        )\n    }\n\n    /// Assumes the current token is [TerminalConst].\n    /// Expected pattern: `const <Identifier> = <Expr>;`\n    fn expect_const(&mut self, attributes: AttributeListGreen) -> ItemConstantGreen {\n        let const_kw = self.take::<TerminalConst>();\n        let name = self.parse_identifier();\n        let type_clause = self.parse_type_clause(ErrorRecovery {\n            should_stop: is_of_kind!(eq, semicolon, top_level),\n        });\n        let eq = self.parse_token::<TerminalEq>();\n        let expr = self.parse_expr();\n        let semicolon = self.parse_token::<TerminalSemicolon>();\n\n        ItemConstant::new_green(\n            self.db,\n            attributes,\n            const_kw,\n            name,\n            type_clause,\n            eq,\n            expr,\n            semicolon,\n        )\n    }\n\n    /// Assumes the current token is Extern.\n    /// Expected pattern: `extern(<FunctionDeclaration>|type<Identifier>);`\n    fn expect_extern_item(&mut self, attributes: AttributeListGreen) -> ItemGreen {\n        let extern_kw = self.take::<TerminalExtern>();\n        match self.peek().kind {\n            SyntaxKind::TerminalFunction => {\n                let declaration = self.expect_function_declaration();\n                let semicolon = self.parse_token::<TerminalSemicolon>();\n                ItemExternFunction::new_green(\n                    self.db,\n                    attributes,\n                    extern_kw,\n                    declaration,\n                    semicolon,\n                )\n                .into()\n            }\n            _ => {\n                // TODO(spapini): Do'nt return ItemExternType if we don't see a type.\n                let type_kw = self.parse_token::<TerminalType>();\n\n                let name = self.parse_identifier();\n                let generic_params = self.parse_optional_generic_params();\n                let semicolon = self.parse_token::<TerminalSemicolon>();\n                // If the next token is not type, assume it is missing.\n                ItemExternType::new_green(\n                    self.db,\n                    attributes,\n                    extern_kw,\n                    type_kw,\n                    name,\n                    generic_params,\n                    semicolon,\n                )\n                .into()\n            }\n        }\n    }\n\n    /// Assumes the current token is Use.\n    /// Expected pattern: `use<Path>;`\n    fn expect_use(&mut self, attributes: AttributeListGreen) -> ItemUseGreen {\n        let use_kw = self.take::<TerminalUse>();\n        let path = self.parse_path();\n        let semicolon = self.parse_token::<TerminalSemicolon>();\n        ItemUse::new_green(self.db, attributes, use_kw, path, semicolon)\n    }\n\n    /// Returns a GreenId of a node with an identifier kind or None if an identifier can't be\n    /// parsed.\n    /// Note that if the terminal is a keyword or an underscore, it is skipped, and\n    /// Some(missing-identifier) is returned.\n    fn try_parse_identifier(&mut self) -> Option<TerminalIdentifierGreen> {\n        if self.peek().kind.is_keyword_terminal() {\n            // TODO(spapini): don't skip every keyword. Instead, pass a recovery set.\n            Some(self.skip_token_and_return_missing::<TerminalIdentifier>(\n                ParserDiagnosticKind::ReservedIdentifier { identifier: self.peek().text.clone() },\n            ))\n        } else if self.peek().kind == SyntaxKind::TerminalUnderscore {\n            Some(self.skip_token_and_return_missing::<TerminalIdentifier>(\n                ParserDiagnosticKind::UnderscoreNotAllowedAsIdentifier,\n            ))\n        } else {\n            self.try_parse_token::<TerminalIdentifier>()\n        }\n    }\n    /// Returns whether the current token is an identifier, a keyword or an underscore ('_'),\n    /// without consuming it. This should be used mostly, instead of checking whether the current\n    /// token is an identifier, because in many cases we'd want to consume the keyword/underscore as\n    /// the identifier and raise a relevant diagnostic\n    /// (ReservedIdentifier/UnderscoreNotAllowedAsIdentifier).\n    fn is_peek_identifier_like(&self) -> bool {\n        let kind = self.peek().kind;\n        kind.is_keyword_terminal()\n            || matches!(kind, SyntaxKind::TerminalUnderscore | SyntaxKind::TerminalIdentifier)\n    }\n\n    /// Returns a GreenId of a node with an identifier kind.\n    fn parse_identifier(&mut self) -> TerminalIdentifierGreen {\n        match self.try_parse_identifier() {\n            Some(identifier) => identifier,\n            None => self.create_and_report_missing_terminal::<TerminalIdentifier>(),\n        }\n    }\n\n    /// Parses the arguments of an attributes if exists.\n    /// Expected pattern: `\\(<ExprList>\\)`\n    fn try_attribute_arg_list_parenthesized(&mut self) -> OptionAttributeArgsGreen {\n        if self.peek().kind != SyntaxKind::TerminalLParen {\n            return OptionAttributeArgsEmpty::new_green(self.db).into();\n        }\n        let lparen = self.take::<TerminalLParen>();\n        let args = self\n            .parse_separated_list::<Expr, TerminalComma, AttributeArgListElementOrSeparatorGreen>(\n                Self::try_parse_expr,\n                is_of_kind!(rparen, block, rbrace, top_level),\n                \"expression\",\n            );\n        let arg_list = AttributeArgList::new_green(self.db, args);\n        let rparen = self.parse_token::<TerminalRParen>();\n        AttributeArgs::new_green(self.db, lparen, arg_list, rparen).into()\n    }\n\n    /// Returns a GreenId of a node with an attribute kind or None if an attribute can't be parsed.\n    fn try_parse_attribute(&mut self) -> Option<AttributeGreen> {\n        match self.peek().kind {\n            SyntaxKind::TerminalHash => {\n                let hash = self.take::<TerminalHash>();\n                let lbrack = self.parse_token::<TerminalLBrack>();\n\n                let attr = self.parse_identifier();\n                let args = self.try_attribute_arg_list_parenthesized();\n                let rbrack = self.parse_token::<TerminalRBrack>();\n\n                Some(Attribute::new_green(self.db, hash, lbrack, attr, args, rbrack))\n            }\n            _ => None,\n        }\n    }\n\n    /// Parses an attribute list.\n    /// `expected_elements_str` are the expected elements that these attributes are parsed for.\n    /// Note: it should not include \"attribute\".\n    fn parse_attribute_list(&mut self, expected_elements_str: &str) -> AttributeListGreen {\n        AttributeList::new_green(\n            self.db,\n            self.parse_list(\n                Self::try_parse_attribute,\n                is_of_kind!(rbrace, top_level),\n                format!(\"{expected_elements_str} or an attribute\").as_str(),\n            ),\n        )\n    }\n\n    /// Assumes the current token is Function.\n    /// Expected pattern: `<FunctionDeclaration>`\n    fn expect_function_declaration(&mut self) -> FunctionDeclarationGreen {\n        let function_kw = self.take::<TerminalFunction>();\n        let name = self.parse_identifier();\n        let generic_params = self.parse_optional_generic_params();\n        let signature = self.expect_function_signature();\n\n        FunctionDeclaration::new_green(self.db, function_kw, name, generic_params, signature)\n    }\n\n    /// Assumes the current token is Function.\n    /// Expected pattern: `<FunctionDeclaration><Block>`\n    fn expect_free_function(&mut self, attributes: AttributeListGreen) -> FunctionWithBodyGreen {\n        let declaration = self.expect_function_declaration();\n        let function_body = self.parse_block();\n        FunctionWithBody::new_green(self.db, attributes, declaration, function_body)\n    }\n\n    /// Assumes the current token is Trait.\n    fn expect_trait(&mut self, attributes: AttributeListGreen) -> ItemTraitGreen {\n        let trait_kw = self.take::<TerminalTrait>();\n        let name = self.parse_identifier();\n        let generic_params = self.parse_optional_generic_params();\n        let body = if self.peek().kind == SyntaxKind::TerminalLBrace {\n            let lbrace = self.take::<TerminalLBrace>();\n            let items = TraitItemList::new_green(\n                self.db,\n                self.parse_attributed_list(\n                    Self::try_parse_trait_item,\n                    is_of_kind!(rbrace, top_level),\n                    \"trait item\",\n                ),\n            );\n            let rbrace = self.parse_token::<TerminalRBrace>();\n            TraitBody::new_green(self.db, lbrace, items, rbrace).into()\n        } else {\n            self.parse_token::<TerminalSemicolon>().into()\n        };\n\n        ItemTrait::new_green(self.db, attributes, trait_kw, name, generic_params, body)\n    }\n\n    /// Returns a GreenId of a node with a TraitItem.* kind (see\n    /// [syntax::node::ast::TraitItem]).\n    pub fn try_parse_trait_item(&mut self) -> Option<TraitItemGreen> {\n        let attributes = self.parse_attribute_list(\"trait item\");\n\n        match self.peek().kind {\n            SyntaxKind::TerminalFunction => Some(self.expect_trait_function(attributes).into()),\n            _ => None,\n        }\n    }\n\n    /// Assumes the current token is Function.\n    /// Expected pattern: `<FunctionDeclaration><SemiColon>`\n    fn expect_trait_function(&mut self, attributes: AttributeListGreen) -> TraitItemFunctionGreen {\n        let declaration = self.expect_function_declaration();\n        let body = if self.peek().kind == SyntaxKind::TerminalLBrace {\n            self.parse_block().into()\n        } else {\n            self.parse_token::<TerminalSemicolon>().into()\n        };\n        TraitItemFunction::new_green(self.db, attributes, declaration, body)\n    }\n\n    /// Assumes the current token is Impl.\n    fn expect_impl(&mut self, attributes: AttributeListGreen) -> ItemImplGreen {\n        let impl_kw = self.take::<TerminalImpl>();\n        let name = self.parse_identifier();\n        let generic_params = self.parse_optional_generic_params();\n        let of_kw = self.parse_token::<TerminalOf>();\n        let trait_path = self.parse_path();\n        let body = if self.peek().kind == SyntaxKind::TerminalLBrace {\n            let lbrace = self.take::<TerminalLBrace>();\n            let items = ItemList::new_green(\n                self.db,\n                self.parse_attributed_list(\n                    Self::try_parse_top_level_item,\n                    is_of_kind!(rbrace),\n                    \"item\",\n                ),\n            );\n            let rbrace = self.parse_token::<TerminalRBrace>();\n            ImplBody::new_green(self.db, lbrace, items, rbrace).into()\n        } else {\n            self.parse_token::<TerminalSemicolon>().into()\n        };\n\n        ItemImpl::new_green(\n            self.db,\n            attributes,\n            impl_kw,\n            name,\n            generic_params,\n            of_kw,\n            trait_path,\n            body,\n        )\n    }\n\n    // ------------------------------- Expressions -------------------------------\n\n    /// Returns a GreenId of a node with an Expr.* kind (see [syntax::node::ast::Expr])\n    /// or None if an expression can't be parsed.\n    fn try_parse_expr(&mut self) -> Option<ExprGreen> {\n        self.try_parse_expr_limited(MAX_PRECEDENCE, LbraceAllowed::Allow)\n    }\n    /// Returns a GreenId of a node with an Expr.* kind (see [syntax::node::ast::Expr])\n    /// or a node with kind ExprMissing if an expression can't be parsed.\n    pub fn parse_expr(&mut self) -> ExprGreen {\n        match self.try_parse_expr() {\n            Some(green) => green,\n            None => self.create_and_report_missing::<Expr>(ParserDiagnosticKind::MissingExpression),\n        }\n    }\n\n    /// Assumes the current token is an operator (binary or unary).\n    /// Returns a GreenId of the operator or None if the operator is a unary-only operator.\n    fn try_parse_binary_operator(&mut self) -> Option<BinaryOperatorGreen> {\n        if matches!(self.peek().kind, SyntaxKind::TerminalNot | SyntaxKind::TerminalAt) {\n            None\n        } else {\n            Some(match self.peek().kind {\n                SyntaxKind::TerminalDot => self.take::<TerminalDot>().into(),\n                SyntaxKind::TerminalMul => self.take::<TerminalMul>().into(),\n                SyntaxKind::TerminalMulEq => self.take::<TerminalMulEq>().into(),\n                SyntaxKind::TerminalDiv => self.take::<TerminalDiv>().into(),\n                SyntaxKind::TerminalDivEq => self.take::<TerminalDivEq>().into(),\n                SyntaxKind::TerminalMod => self.take::<TerminalMod>().into(),\n                SyntaxKind::TerminalModEq => self.take::<TerminalModEq>().into(),\n                SyntaxKind::TerminalPlus => self.take::<TerminalPlus>().into(),\n                SyntaxKind::TerminalPlusEq => self.take::<TerminalPlusEq>().into(),\n                SyntaxKind::TerminalMinus => self.take::<TerminalMinus>().into(),\n                SyntaxKind::TerminalMinusEq => self.take::<TerminalMinusEq>().into(),\n                SyntaxKind::TerminalEq => self.take::<TerminalEq>().into(),\n                SyntaxKind::TerminalEqEq => self.take::<TerminalEqEq>().into(),\n                SyntaxKind::TerminalNeq => self.take::<TerminalNeq>().into(),\n                SyntaxKind::TerminalLT => self.take::<TerminalLT>().into(),\n                SyntaxKind::TerminalGT => self.take::<TerminalGT>().into(),\n                SyntaxKind::TerminalLE => self.take::<TerminalLE>().into(),\n                SyntaxKind::TerminalGE => self.take::<TerminalGE>().into(),\n                SyntaxKind::TerminalAnd => self.take::<TerminalAnd>().into(),\n                SyntaxKind::TerminalOr => self.take::<TerminalOr>().into(),\n                SyntaxKind::TerminalXor => self.take::<TerminalXor>().into(),\n                _ => unreachable!(),\n            })\n        }\n    }\n    /// Assumes the current token is a unary operator, and returns a GreenId of the operator.\n    fn expect_unary_operator(&mut self) -> UnaryOperatorGreen {\n        match self.peek().kind {\n            SyntaxKind::TerminalAt => self.take::<TerminalAt>().into(),\n            SyntaxKind::TerminalNot => self.take::<TerminalNot>().into(),\n            SyntaxKind::TerminalMinus => self.take::<TerminalMinus>().into(),\n            SyntaxKind::TerminalMul => self.take::<TerminalMul>().into(),\n            _ => unreachable!(),\n        }\n    }\n\n    /// Returns a GreenId of a node with an Expr.* kind (see [syntax::node::ast::Expr])\n    /// or None if such an expression can't be parsed.\n    ///\n    /// Parsing will be limited by:\n    /// `parent_precedence` - parsing of boolean operators limited to this.\n    /// `lbrace_allowed` - See [LbraceAllowed].\n    fn try_parse_expr_limited(\n        &mut self,\n        parent_precedence: usize,\n        lbrace_allowed: LbraceAllowed,\n    ) -> Option<ExprGreen> {\n        let mut expr = if let Some(precedence) = get_unary_operator_precedence(self.peek().kind) {\n            let op = self.expect_unary_operator();\n            let expr = self.parse_expr_limited(precedence, lbrace_allowed);\n            ExprUnary::new_green(self.db, op, expr).into()\n        } else {\n            self.try_parse_atom(lbrace_allowed)?\n        };\n\n        while let Some(precedence) = get_post_operator_precedence(self.peek().kind) {\n            if precedence >= parent_precedence {\n                return Some(expr);\n            }\n            if self.peek().kind == SyntaxKind::TerminalQuestionMark {\n                expr = ExprErrorPropagate::new_green(\n                    self.db,\n                    expr,\n                    self.take::<TerminalQuestionMark>(),\n                )\n                .into();\n            } else if self.peek().kind == SyntaxKind::TerminalLBrack {\n                let lbrack = self.take::<TerminalLBrack>();\n                let index_expr = self.parse_expr();\n                let rbrack = self.parse_token::<TerminalRBrack>();\n                expr = ExprIndexed::new_green(self.db, expr, lbrack, index_expr, rbrack).into();\n            } else if let Some(op) = self.try_parse_binary_operator() {\n                let rhs = self.parse_expr_limited(precedence, lbrace_allowed);\n                expr = ExprBinary::new_green(self.db, expr, op, rhs).into();\n            } else {\n                return Some(expr);\n            }\n        }\n        Some(expr)\n    }\n    /// Returns a GreenId of a node with an Expr.* kind (see [syntax::node::ast::Expr]),\n    /// excluding ExprBlock, or ExprMissing if such an expression can't be parsed.\n    ///\n    /// `lbrace_allowed` - See [LbraceAllowed].\n    fn parse_expr_limited(\n        &mut self,\n        parent_precedence: usize,\n        lbrace_allowed: LbraceAllowed,\n    ) -> ExprGreen {\n        match self.try_parse_expr_limited(parent_precedence, lbrace_allowed) {\n            Some(green) => green,\n            None => self.create_and_report_missing::<Expr>(ParserDiagnosticKind::MissingExpression),\n        }\n    }\n\n    /// Returns a GreenId of a node with an\n    /// ExprPath|ExprFunctionCall|ExprStructCtorCall|ExprParenthesized|ExprTuple kind, or None if\n    /// such an expression can't be parsed.\n    ///\n    /// `lbrace_allowed` - See [LbraceAllowed].\n    fn try_parse_atom(&mut self, lbrace_allowed: LbraceAllowed) -> Option<ExprGreen> {\n        // TODO(yuval): support paths starting with \"::\".\n        match self.peek().kind {\n            SyntaxKind::TerminalIdentifier => {\n                // Call parse_path() and not expect_path(), because it's cheap.\n                let path = self.parse_path();\n                match self.peek().kind {\n                    SyntaxKind::TerminalLParen => Some(self.expect_function_call(path).into()),\n                    SyntaxKind::TerminalLBrace if lbrace_allowed == LbraceAllowed::Allow => {\n                        Some(self.expect_constructor_call(path).into())\n                    }\n                    _ => Some(path.into()),\n                }\n            }\n            SyntaxKind::TerminalFalse => Some(self.take::<TerminalFalse>().into()),\n            SyntaxKind::TerminalTrue => Some(self.take::<TerminalTrue>().into()),\n            SyntaxKind::TerminalLiteralNumber => Some(self.take::<TerminalLiteralNumber>().into()),\n            SyntaxKind::TerminalShortString => Some(self.take::<TerminalShortString>().into()),\n            SyntaxKind::TerminalLParen => {\n                // Note that LBrace is allowed inside parenthesis, even if `lbrace_allowed` is\n                // [LbraceAllowed::Forbid].\n                Some(self.expect_parenthesized_expr())\n            }\n            SyntaxKind::TerminalLBrace if lbrace_allowed == LbraceAllowed::Allow => {\n                Some(self.parse_block().into())\n            }\n            SyntaxKind::TerminalMatch if lbrace_allowed == LbraceAllowed::Allow => {\n                Some(self.expect_match_expr().into())\n            }\n            SyntaxKind::TerminalIf if lbrace_allowed == LbraceAllowed::Allow => {\n                Some(self.expect_if_expr().into())\n            }\n            _ => {\n                // TODO(yuval): report to diagnostics.\n                None\n            }\n        }\n    }\n\n    /// Returns a GreenId of a node with an ExprPath|ExprParenthesized|ExprTuple kind, or None if\n    /// such an expression can't be parsed.\n    fn try_parse_type_expr(&mut self) -> Option<ExprGreen> {\n        // TODO(yuval): support paths starting with \"::\".\n        match self.peek().kind {\n            SyntaxKind::TerminalAt => {\n                let op = self.take::<TerminalAt>().into();\n                let expr = self.try_parse_type_expr().unwrap_or_else(|| {\n                    self.create_and_report_missing::<Expr>(\n                        ParserDiagnosticKind::MissingTypeExpression,\n                    )\n                });\n                Some(ExprUnary::new_green(self.db, op, expr).into())\n            }\n            SyntaxKind::TerminalIdentifier => Some(self.parse_type_path().into()),\n            SyntaxKind::TerminalLParen => Some(self.expect_parenthesized_expr()),\n            _ => {\n                // TODO(yuval): report to diagnostics.\n                None\n            }\n        }\n    }\n\n    /// Assumes the current token is LBrace.\n    /// Expected pattern: `\\{<StructArgList>\\}`\n    fn expect_struct_ctor_argument_list_braced(&mut self) -> ArgListBracedGreen {\n        let lbrace = self.take::<TerminalLBrace>();\n        let arg_list = StructArgList::new_green(\n            self.db,\n            self.parse_separated_list::<StructArg, TerminalComma, StructArgListElementOrSeparatorGreen>(\n                Self::try_parse_struct_ctor_argument,\n                is_of_kind!(rparen, block, rbrace, top_level),\n                \"struct constructor argument\",\n            ),\n        );\n        let rbrace = self.parse_token::<TerminalRBrace>();\n\n        ArgListBraced::new_green(self.db, lbrace, arg_list, rbrace)\n    }\n\n    /// Assumes the current token is LParen.\n    /// Expected pattern: `<ArgListParenthesized>`\n    fn expect_function_call(&mut self, path: ExprPathGreen) -> ExprFunctionCallGreen {\n        let func_name = path;\n        let parenthesized_args = self.expect_parenthesized_argument_list();\n        ExprFunctionCall::new_green(self.db, func_name, parenthesized_args)\n    }\n\n    /// Assumes the current token is LParen.\n    /// Expected pattern: `\\(<ArgList>\\)`\n    fn expect_parenthesized_argument_list(&mut self) -> ArgListParenthesizedGreen {\n        let lparen = self.take::<TerminalLParen>();\n        let arg_list = ArgList::new_green(\n            self.db,\n            self.parse_separated_list::<Arg, TerminalComma, ArgListElementOrSeparatorGreen>(\n                Self::try_parse_function_argument,\n                is_of_kind!(rparen, block, rbrace, top_level),\n                \"argument\",\n            ),\n        );\n        let rparen = self.parse_token::<TerminalRParen>();\n        ArgListParenthesized::new_green(self.db, lparen, arg_list, rparen)\n    }\n\n    /// Parses a function call's argument, which contains possibly modifiers, and a argument clause.\n    fn try_parse_function_argument(&mut self) -> Option<ArgGreen> {\n        let modifiers_list = self.parse_modifier_list();\n        let arg_clause = self.try_parse_argument_clause();\n        if !modifiers_list.is_empty() && arg_clause.is_none() {\n            let modifiers = ModifierList::new_green(self.db, modifiers_list);\n            let arg_clause = ArgClauseUnnamed::new_green(self.db, self.parse_expr()).into();\n            return Some(Arg::new_green(self.db, modifiers, arg_clause));\n        }\n        let modifiers = ModifierList::new_green(self.db, modifiers_list);\n        Some(Arg::new_green(self.db, modifiers, arg_clause?))\n    }\n\n    /// Parses a function call's argument, which is an expression with or without the name\n    /// of the argument.\n    ///\n    /// Possible patterns:\n    /// * `<Expr>` (unnamed).\n    /// * `<Identifier>: <Expr>` (named).\n    /// * `:<Identifier>` (Field init shorthand - syntactic sugar for `a: a`).\n    fn try_parse_argument_clause(&mut self) -> Option<ArgClauseGreen> {\n        if self.peek().kind == SyntaxKind::TerminalColon {\n            let colon = self.take::<TerminalColon>();\n            let argname = self.parse_identifier();\n            return Some(\n                ArgClauseFieldInitShorthand::new_green(\n                    self.db,\n                    colon,\n                    ExprFieldInitShorthand::new_green(self.db, argname),\n                )\n                .into(),\n            );\n        }\n\n        // Read an expression.\n        let expr_or_argname = self.try_parse_expr()?;\n\n        // If the next token is `:` and the expression is an identifier, this is the argument's\n        // name.\n        if self.peek().kind == SyntaxKind::TerminalColon {\n            if let Some(argname) = self.try_extract_identifier(expr_or_argname) {\n                let colon = self.take::<TerminalColon>();\n                let expr = self.parse_expr();\n                return Some(ArgClauseNamed::new_green(self.db, argname, colon, expr).into());\n            }\n        }\n\n        Some(ArgClauseUnnamed::new_green(self.db, expr_or_argname).into())\n    }\n\n    /// If the given `expr` is a simple identifier, returns the corresponding green node.\n    /// Otherwise, returns `None`.\n    fn try_extract_identifier(&self, expr: ExprGreen) -> Option<TerminalIdentifierGreen> {\n        // Check that `expr` is `ExprPath`.\n        let GreenNode {\n            kind: SyntaxKind::ExprPath,\n            details: GreenNodeDetails::Node { children: children0, .. },\n        } = &self.db.lookup_intern_green(expr.0) else {return None;};\n\n        // Check that it has one child.\n        let [path_segment] = children0[..] else {return None;};\n\n        // Check that `path_segment` is `PathSegmentSimple`.\n        let GreenNode {\n            kind: SyntaxKind::PathSegmentSimple,\n            details: GreenNodeDetails::Node { children: children1, .. },\n        } = self.db.lookup_intern_green(path_segment) else {return None;};\n\n        // Check that it has one child.\n        let [ident] = children1[..] else {return None;};\n\n        // Check that it is indeed `TerminalIdentifier`.\n        let GreenNode {\n            kind: SyntaxKind::TerminalIdentifier,\n            ..\n        } = self.db.lookup_intern_green(ident) else {return None;};\n\n        Some(TerminalIdentifierGreen(ident))\n    }\n\n    /// Assumes the current token is LBrace.\n    /// Expected pattern: `<ExprListBraced>`\n    fn expect_constructor_call(&mut self, path: ExprPathGreen) -> ExprStructCtorCallGreen {\n        let ctor_name = path;\n        let args = self.expect_struct_ctor_argument_list_braced();\n        ExprStructCtorCall::new_green(self.db, ctor_name, args)\n    }\n\n    /// Assumes the current token is LParen.\n    /// Expected pattern: `\\((<expr>,)*<expr>?\\)`\n    /// Returns a GreenId of a node with kind ExprParenthesized|ExprTuple.\n    fn expect_parenthesized_expr(&mut self) -> ExprGreen {\n        let lparen = self.take::<TerminalLParen>();\n        let exprs: Vec<ExprListElementOrSeparatorGreen> = self\n            .parse_separated_list::<Expr, TerminalComma, ExprListElementOrSeparatorGreen>(\n                Self::try_parse_expr,\n                is_of_kind!(rparen, block, rbrace, top_level),\n                \"expression\",\n            );\n        let rparen = self.parse_token::<TerminalRParen>();\n\n        if let [ExprListElementOrSeparatorGreen::Element(expr)] = &exprs[..] {\n            // We have exactly one item and no separator --> This is not a tuple.\n            ExprParenthesized::new_green(self.db, lparen, *expr, rparen).into()\n        } else {\n            ExprTuple::new_green(self.db, lparen, ExprList::new_green(self.db, exprs), rparen)\n                .into()\n        }\n    }\n\n    /// Assumes the current token is DotDot.\n    /// Expected pattern: `\\.\\.<Expr>`\n    fn expect_struct_argument_tail(&mut self) -> StructArgTailGreen {\n        let dotdot = self.take::<TerminalDotDot>(); // ..\n        // TODO(yuval): consider changing this to SimpleExpr once it exists.\n        let expr = self.parse_expr();\n        StructArgTail::new_green(self.db, dotdot, expr)\n    }\n\n    // For the similar syntax in Rust, see\n    // https://doc.rust-lang.org/book/ch05-01-defining-structs.html#creating-instances-from-other-instances-with-struct-update-syntax.\n    /// Like parse_argument, but also allows a struct-arg-tail, e.g. 'let s2 = S{\"s2\", ..s1};'\n    /// Returns a GreenId of a node with kind StructArgSingle|StructArgTail.\n    fn try_parse_struct_ctor_argument(&mut self) -> Option<StructArgGreen> {\n        match self.peek().kind {\n            SyntaxKind::TerminalDotDot => Some(self.expect_struct_argument_tail().into()),\n            _ => Some(self.try_parse_argument_single()?.into()),\n        }\n    }\n\n    /// Returns a GreenId of a node with kind StructArgExpr or OptionStructArgExprEmpty if an\n    /// argument expression `(\":<value>\")` can't be parsed.\n    fn parse_option_struct_arg_expression(&mut self) -> OptionStructArgExprGreen {\n        if self.peek().kind == SyntaxKind::TerminalColon {\n            let colon = self.take::<TerminalColon>();\n            let value = self.parse_expr();\n            StructArgExpr::new_green(self.db, colon, value).into()\n        } else {\n            OptionStructArgExprEmpty::new_green(self.db).into()\n        }\n    }\n\n    /// Returns a GreenId of a node with kind StructArgSingle.\n    fn try_parse_argument_single(&mut self) -> Option<StructArgSingleGreen> {\n        let identifier = self.try_parse_identifier()?;\n        let struct_arg_expr = self.parse_option_struct_arg_expression(); // :<expr>\n        Some(StructArgSingle::new_green(self.db, identifier, struct_arg_expr))\n    }\n\n    /// Returns a GreenId of a node with kind ExprBlock.\n    fn parse_block(&mut self) -> ExprBlockGreen {\n        let skipped_tokens = self.skip_until(is_of_kind!(lbrace, top_level, block));\n\n        if let Err(SkippedError(span)) = skipped_tokens {\n            self.diagnostics.add(ParserDiagnostic {\n                file_id: self.file_id,\n                kind: ParserDiagnosticKind::SkippedElement { element_name: \"'{'\".into() },\n                span,\n            });\n        }\n\n        // Don't report diagnostic if one has already been reported.\n        let lbrace = self.parse_token_ex::<TerminalLBrace>(skipped_tokens.is_ok());\n        let statements = StatementList::new_green(\n            self.db,\n            self.parse_list(Self::try_parse_statement, is_of_kind!(rbrace, top_level), \"statement\"),\n        );\n        let rbrace = self.parse_token::<TerminalRBrace>();\n        ExprBlock::new_green(self.db, lbrace, statements, rbrace)\n    }\n\n    /// Assumes the current token is `Match`.\n    /// Expected pattern: `match <expr> \\{<MatchArm>*\\}`\n    fn expect_match_expr(&mut self) -> ExprMatchGreen {\n        let match_kw = self.take::<TerminalMatch>();\n        let expr = self.parse_expr_limited(MAX_PRECEDENCE, LbraceAllowed::Forbid);\n        let lbrace = self.parse_token::<TerminalLBrace>();\n        let arms = MatchArms::new_green(\n            self.db,\n            self.parse_separated_list::<MatchArm, TerminalComma, MatchArmsElementOrSeparatorGreen>(\n                Self::try_parse_match_arm,\n                is_of_kind!(block, rbrace, top_level),\n                \"match arm\",\n            ),\n        );\n        let rbrace = self.parse_token::<TerminalRBrace>();\n        ExprMatch::new_green(self.db, match_kw, expr, lbrace, arms, rbrace)\n    }\n\n    /// Assumes the current token is `If`.\n    /// Expected pattern: `if <expr> <block> [else <block>]`.\n    fn expect_if_expr(&mut self) -> ExprIfGreen {\n        let if_kw = self.take::<TerminalIf>();\n        let condition = self.parse_expr_limited(MAX_PRECEDENCE, LbraceAllowed::Forbid);\n        let if_block = self.parse_block();\n\n        let else_clause: OptionElseClauseGreen = if self.peek().kind == SyntaxKind::TerminalElse {\n            let else_kw = self.take::<TerminalElse>();\n            let else_block_or_if = if self.peek().kind == SyntaxKind::TerminalIf {\n                BlockOrIfGreen::from(self.expect_if_expr())\n            } else {\n                BlockOrIfGreen::from(self.parse_block())\n            };\n            ElseClause::new_green(self.db, else_kw, else_block_or_if).into()\n        } else {\n            OptionElseClauseEmpty::new_green(self.db).into()\n        };\n\n        ExprIf::new_green(self.db, if_kw, condition, if_block, else_clause)\n    }\n\n    /// Returns a GreenId of a node with a MatchArm kind or None if a match arm can't be parsed.\n    pub fn try_parse_match_arm(&mut self) -> Option<MatchArmGreen> {\n        let pattern = self.try_parse_pattern()?;\n        let arrow = self.parse_token::<TerminalMatchArrow>();\n        let expr = self.parse_expr();\n        Some(MatchArm::new_green(self.db, pattern, arrow, expr))\n    }\n\n    /// Returns a GreenId of a node with some Pattern kind (see\n    /// [syntax::node::ast::Pattern]) or None if a pattern can't be parsed.\n    fn try_parse_pattern(&mut self) -> Option<PatternGreen> {\n        let modifier_list = self.parse_modifier_list();\n        if !modifier_list.is_empty() {\n            let modifiers = ModifierList::new_green(self.db, modifier_list);\n            let name = self.parse_identifier();\n            return Some(PatternIdentifier::new_green(self.db, modifiers, name).into());\n        };\n\n        // TODO(yuval): Support \"Or\" patterns.\n        Some(match self.peek().kind {\n            SyntaxKind::TerminalLiteralNumber => self.take::<TerminalLiteralNumber>().into(),\n            SyntaxKind::TerminalShortString => self.take::<TerminalShortString>().into(),\n            SyntaxKind::TerminalUnderscore => self.take::<TerminalUnderscore>().into(),\n            SyntaxKind::TerminalIdentifier => {\n                // TODO(ilya): Consider parsing a single identifier as PatternIdentifier rather\n                // then ExprPath.\n                let path = self.parse_path();\n                match self.peek().kind {\n                    SyntaxKind::TerminalLBrace => {\n                        let lbrace = self.take::<TerminalLBrace>();\n                        let params = PatternStructParamList::new_green(\n                            self.db,\n                            self.parse_separated_list::<\n                                PatternStructParam,\n                                TerminalComma,\n                                PatternStructParamListElementOrSeparatorGreen>\n                            (\n                                Self::try_parse_pattern_struct_param,\n                                is_of_kind!(rparen, block, rbrace, top_level),\n                                \"struct pattern parameter\",\n                            ),\n                        );\n                        let rbrace = self.take::<TerminalRBrace>();\n                        PatternStruct::new_green(self.db, path, lbrace, params, rbrace).into()\n                    }\n                    SyntaxKind::TerminalLParen => {\n                        // Enum pattern.\n                        let lparen = self.take::<TerminalLParen>();\n                        let pattern = self.parse_pattern();\n                        let rparen = self.parse_token::<TerminalRParen>();\n                        PatternEnum::new_green(self.db, path, lparen, pattern, rparen).into()\n                    }\n                    _ => path.into(),\n                }\n            }\n            SyntaxKind::TerminalLParen => {\n                let lparen = self.take::<TerminalLParen>();\n                let patterns = PatternList::new_green(self.db,  self.parse_separated_list::<\n                    Pattern,\n                    TerminalComma,\n                    PatternListElementOrSeparatorGreen>\n                (\n                    Self::try_parse_pattern,\n                    is_of_kind!(rparen, block, rbrace, top_level),\n                    \"pattern\",\n                ));\n                let rparen = self.parse_token::<TerminalRParen>();\n                PatternTuple::new_green(self.db, lparen, patterns, rparen).into()\n            }\n            _ => return None,\n        })\n    }\n    /// Returns a GreenId of a node with some Pattern kind (see\n    /// [syntax::node::ast::Pattern]).\n    fn parse_pattern(&mut self) -> PatternGreen {\n        // If not found, return a missing underscore pattern.\n        self.try_parse_pattern().unwrap_or_else(|| {\n            self.create_and_report_missing_terminal::<TerminalUnderscore>().into()\n        })\n    }\n\n    /// Returns a GreenId of a syntax in side a struct pattern. Example:\n    /// `MyStruct { param0, param1: _, .. }`.\n    fn try_parse_pattern_struct_param(&mut self) -> Option<PatternStructParamGreen> {\n        Some(match self.peek().kind {\n            SyntaxKind::TerminalDotDot => self.take::<TerminalDotDot>().into(),\n            _ => {\n                let modifier_list = self.parse_modifier_list();\n                let name = if modifier_list.is_empty() {\n                    self.try_parse_identifier()?\n                } else {\n                    self.parse_identifier()\n                };\n                let modifiers = ModifierList::new_green(self.db, modifier_list);\n                if self.peek().kind == SyntaxKind::TerminalColon {\n                    let colon = self.take::<TerminalColon>();\n                    let pattern = self.parse_pattern();\n                    PatternStructParamWithExpr::new_green(self.db, modifiers, name, colon, pattern)\n                        .into()\n                } else {\n                    PatternIdentifier::new_green(self.db, modifiers, name).into()\n                }\n            }\n        })\n    }\n\n    // ------------------------------- Statements -------------------------------\n\n    /// Returns a GreenId of a node with a Statement.* kind (see\n    /// [syntax::node::ast::Statement]) or None if a statement can't be parsed.\n    pub fn try_parse_statement(&mut self) -> Option<StatementGreen> {\n        match self.peek().kind {\n            SyntaxKind::TerminalLet => {\n                let let_kw = self.take::<TerminalLet>();\n                let pattern = self.parse_pattern();\n                let type_clause = self.parse_option_type_clause();\n                let eq = self.parse_token::<TerminalEq>();\n                let rhs = self.parse_expr();\n                let semicolon = self.parse_token::<TerminalSemicolon>();\n                Some(\n                    StatementLet::new_green(\n                        self.db,\n                        let_kw,\n                        pattern,\n                        type_clause,\n                        eq,\n                        rhs,\n                        semicolon,\n                    )\n                    .into(),\n                )\n            }\n            SyntaxKind::TerminalReturn => {\n                let return_kw = self.take::<TerminalReturn>();\n                let expr = self.parse_expr();\n                let semicolon = self.parse_token::<TerminalSemicolon>();\n                Some(StatementReturn::new_green(self.db, return_kw, expr, semicolon).into())\n            }\n            _ => match self.try_parse_expr() {\n                None => None,\n                Some(expr) => {\n                    let optional_semicolon = if self.peek().kind == SyntaxKind::TerminalSemicolon {\n                        self.take::<TerminalSemicolon>().into()\n                    } else {\n                        OptionTerminalSemicolonEmpty::new_green(self.db).into()\n                    };\n                    Some(StatementExpr::new_green(self.db, expr, optional_semicolon).into())\n                }\n            },\n        }\n    }\n\n    /// Returns a GreenId of a node with kind TypeClause or OptionTypeClauseEmpty if a type clause\n    /// can't be parsed.\n    fn parse_option_type_clause(&mut self) -> OptionTypeClauseGreen {\n        match self.try_parse_type_clause() {\n            Some(green) => green.into(),\n            None => OptionTypeClauseEmpty::new_green(self.db).into(),\n        }\n    }\n\n    /// Parses a type clause of the form: `: <type>`.\n    fn parse_type_clause(&mut self, error_recovery: ErrorRecovery) -> TypeClauseGreen {\n        match self.try_parse_type_clause() {\n            Some(green) => green,\n            None => {\n                let res = self.create_and_report_missing::<TypeClause>(\n                    ParserDiagnosticKind::MissingTypeClause,\n                );\n                self.skip_until(error_recovery.should_stop).ok();\n                res\n            }\n        }\n    }\n    fn try_parse_type_clause(&mut self) -> Option<TypeClauseGreen> {\n        if self.peek().kind == SyntaxKind::TerminalColon {\n            let colon = self.take::<TerminalColon>();\n            let ty = self.try_parse_type_expr().unwrap_or_else(|| {\n                self.create_and_report_missing::<Expr>(ParserDiagnosticKind::MissingTypeExpression)\n            });\n            Some(TypeClause::new_green(self.db, colon, ty))\n        } else {\n            None\n        }\n    }\n\n    /// Returns a GreenId of a node with kind ReturnTypeClause or OptionReturnTypeClauseEmpty if a\n    /// return type clause can't be parsed.\n    fn parse_option_return_type_clause(&mut self) -> OptionReturnTypeClauseGreen {\n        if self.peek().kind == SyntaxKind::TerminalArrow {\n            let arrow = self.take::<TerminalArrow>();\n            let return_type = self.try_parse_type_expr().unwrap_or_else(|| {\n                self.create_and_report_missing::<Expr>(ParserDiagnosticKind::MissingTypeExpression)\n            });\n            ReturnTypeClause::new_green(self.db, arrow, return_type).into()\n        } else {\n            OptionReturnTypeClauseEmpty::new_green(self.db).into()\n        }\n    }\n\n    /// Returns a GreenId of a node with kind ImplicitsClause or OptionImplicitsClauseEmpty if a\n    /// implicits-clause can't be parsed.\n    fn parse_option_implicits_clause(&mut self) -> OptionImplicitsClauseGreen {\n        if self.peek().kind == SyntaxKind::TerminalImplicits {\n            let implicits_kw = self.take::<TerminalImplicits>();\n            let lparen = self.parse_token::<TerminalLParen>();\n            let implicits = ImplicitsList::new_green(\n                self.db,\n                self.parse_separated_list::<ExprPath, TerminalComma, ImplicitsListElementOrSeparatorGreen>(\n                    Self::try_parse_path,\n                    // Don't stop at keywords as try_parse_path handles keywords inside it. Otherwise the diagnostic is less accurate.\n                    is_of_kind!(rparen, lbrace, rbrace),\n                    \"implicit type\",\n                ),\n            );\n            let rparen = self.parse_token::<TerminalRParen>();\n            ImplicitsClause::new_green(self.db, implicits_kw, lparen, implicits, rparen).into()\n        } else {\n            OptionImplicitsClauseEmpty::new_green(self.db).into()\n        }\n    }\n\n    /// Returns a GreenId of a node with kind ParamList.\n    fn parse_param_list(&mut self) -> ParamListGreen {\n        ParamList::new_green(\n            self.db,\n            self.parse_separated_list::<Param, TerminalComma, ParamListElementOrSeparatorGreen>(\n                Self::try_parse_param,\n                is_of_kind!(rparen, block, lbrace, rbrace, top_level),\n                \"parameter\",\n            ),\n        )\n    }\n\n    /// Returns a GreenId of a node with kind Modifier or None if a modifier can't be parsed.\n    fn try_parse_modifier(&mut self) -> Option<ModifierGreen> {\n        match self.peek().kind {\n            SyntaxKind::TerminalRef => Some(self.take::<TerminalRef>().into()),\n            SyntaxKind::TerminalMut => Some(self.take::<TerminalMut>().into()),\n            _ => None,\n        }\n    }\n\n    /// Returns a vector of GreenIds with kind Modifier.\n    fn parse_modifier_list(&mut self) -> Vec<ModifierGreen> {\n        let mut modifier_list = vec![];\n\n        while let Some(modifier) = self.try_parse_modifier() {\n            modifier_list.push(modifier);\n        }\n        modifier_list\n    }\n\n    /// Returns a GreenId of a node with kind Param or None if a parameter can't be parsed.\n    fn try_parse_param(&mut self) -> Option<ParamGreen> {\n        let modifier_list = self.parse_modifier_list();\n        let name = if modifier_list.is_empty() {\n            self.try_parse_identifier()?\n        } else {\n            // If we had modifiers then the identifier is not optional and can't be '_'.\n            self.parse_identifier()\n        };\n\n        let type_clause = self.parse_type_clause(ErrorRecovery {\n            should_stop: is_of_kind!(comma, rparen, top_level),\n        });\n        Some(Param::new_green(\n            self.db,\n            ModifierList::new_green(self.db, modifier_list),\n            name,\n            type_clause,\n        ))\n    }\n\n    /// Returns a GreenId of a node with kind MemberList.\n    fn parse_member_list(&mut self) -> MemberListGreen {\n        MemberList::new_green(\n            self.db,\n            self.parse_separated_list::<Member, TerminalComma, MemberListElementOrSeparatorGreen>(\n                Self::try_parse_member,\n                is_of_kind!(rparen, block, lbrace, rbrace, top_level),\n                \"member or variant\",\n            ),\n        )\n    }\n\n    /// Returns a GreenId of a node with kind Member or None if a struct member/enum variant can't\n    /// be parsed.\n    fn try_parse_member(&mut self) -> Option<MemberGreen> {\n        let name = self.try_parse_identifier()?;\n        let type_clause = self.parse_type_clause(ErrorRecovery {\n            should_stop: is_of_kind!(comma, rbrace, top_level),\n        });\n        Some(Member::new_green(self.db, name, type_clause))\n    }\n\n    /// Expected pattern: `<PathSegment>(::<PathSegment>)*`\n    /// Returns a GreenId of a node with kind ExprPath.\n    fn parse_path(&mut self) -> ExprPathGreen {\n        let mut children: Vec<ExprPathElementOrSeparatorGreen> = vec![];\n        loop {\n            let (segment, optional_separator) = self.parse_path_segment();\n            children.push(segment.into());\n\n            if let Some(separator) = optional_separator {\n                children.push(separator.into());\n                continue;\n            }\n            break;\n        }\n\n        ExprPath::new_green(self.db, children)\n    }\n    /// Returns a GreenId of a node with kind ExprPath or None if a path can't be parsed.\n    fn try_parse_path(&mut self) -> Option<ExprPathGreen> {\n        if self.is_peek_identifier_like() { Some(self.parse_path()) } else { None }\n    }\n\n    /// Expected pattern: `(<PathSegment>::)*<PathSegment>(::){0,1}<GenericArgs>`.\n    ///\n    /// Returns a GreenId of a node with kind ExprPath.\n    fn parse_type_path(&mut self) -> ExprPathGreen {\n        let mut children: Vec<ExprPathElementOrSeparatorGreen> = vec![];\n        loop {\n            let (segment, optional_separator) = self.parse_type_path_segment();\n            children.push(segment.into());\n\n            if let Some(separator) = optional_separator {\n                children.push(separator.into());\n                continue;\n            }\n            break;\n        }\n\n        ExprPath::new_green(self.db, children)\n    }\n\n    /// Returns a PathSegment and an optional separator.\n    fn parse_path_segment(&mut self) -> (PathSegmentGreen, Option<TerminalColonColonGreen>) {\n        let identifier = match self.try_parse_identifier() {\n            Some(identifier) => identifier,\n            None => {\n                return (\n                    self.create_and_report_missing::<PathSegment>(\n                        ParserDiagnosticKind::MissingPathSegment,\n                    ),\n                    // TODO(ilya, 10/10/2022): Should we continue parsing the path here?\n                    None,\n                );\n            }\n        };\n        match self.try_parse_token::<TerminalColonColon>() {\n            Some(separator) if self.peek().kind == SyntaxKind::TerminalLT => (\n                PathSegmentWithGenericArgs::new_green(\n                    self.db,\n                    identifier,\n                    separator.into(),\n                    self.expect_generic_args(),\n                )\n                .into(),\n                self.try_parse_token::<TerminalColonColon>(),\n            ),\n            optional_separator => {\n                (PathSegmentSimple::new_green(self.db, identifier).into(), optional_separator)\n            }\n        }\n    }\n\n    /// Returns a Typed PathSegment or a normal PathSegment.\n    /// Additionally returns an optional separators.\n    fn parse_type_path_segment(&mut self) -> (PathSegmentGreen, Option<TerminalColonColonGreen>) {\n        let identifier = match self.try_parse_identifier() {\n            Some(identifier) => identifier,\n            None => {\n                return (\n                    self.create_and_report_missing::<PathSegment>(\n                        ParserDiagnosticKind::MissingPathSegment,\n                    ),\n                    // TODO(ilya, 10/10/2022): Should we continue parsing the path here?\n                    None,\n                );\n            }\n        };\n        match self.try_parse_token::<TerminalColonColon>() {\n            None if self.peek().kind == SyntaxKind::TerminalLT => (\n                PathSegmentWithGenericArgs::new_green(\n                    self.db,\n                    identifier,\n                    OptionTerminalColonColonEmpty::new_green(self.db).into(),\n                    self.expect_generic_args(),\n                )\n                .into(),\n                None,\n            ),\n            // This is here to preserve backwards compatibility.\n            // This allows Option::<T> to still work after this change.\n            Some(separator) if self.peek().kind == SyntaxKind::TerminalLT => (\n                PathSegmentWithGenericArgs::new_green(\n                    self.db,\n                    identifier,\n                    separator.into(),\n                    self.expect_generic_args(),\n                )\n                .into(),\n                self.try_parse_token::<TerminalColonColon>(),\n            ),\n            optional_separator => {\n                (PathSegmentSimple::new_green(self.db, identifier).into(), optional_separator)\n            }\n        }\n    }\n\n    /// Returns a GreenId of a node with an\n    /// ExprLiteral|ExprPath|ExprParenthesized|ExprTuple|ExprUnderscore kind, or None if such an\n    /// expression can't be parsed.\n    fn try_parse_generic_arg(&mut self) -> Option<GenericArgGreen> {\n        if self.peek().kind == SyntaxKind::TerminalUnderscore {\n            return Some(self.take::<TerminalUnderscore>().into());\n        }\n\n        let expr = if self.peek().kind == SyntaxKind::TerminalLiteralNumber {\n            self.take::<TerminalLiteralNumber>().into()\n        } else if self.peek().kind == SyntaxKind::TerminalMinus {\n            let minus = self.take::<TerminalMinus>().into();\n            let literal = self.parse_token::<TerminalLiteralNumber>().into();\n            ExprUnary::new_green(self.db, minus, literal).into()\n        } else if self.peek().kind == SyntaxKind::TerminalShortString {\n            self.take::<TerminalShortString>().into()\n        } else {\n            self.try_parse_type_expr()?\n        };\n\n        Some(GenericArgExpr::new_green(self.db, expr).into())\n    }\n\n    /// Assumes the current token is LT.\n    /// Expected pattern: `\\< <GenericArgList> \\>`\n    fn expect_generic_args(&mut self) -> GenericArgsGreen {\n        let langle = self.take::<TerminalLT>();\n        let generic_args = GenericArgList::new_green(\n            self.db,\n            self.parse_separated_list::<GenericArg, TerminalComma, GenericArgListElementOrSeparatorGreen>(\n                Self::try_parse_generic_arg,\n                is_of_kind!(rangle, rparen, block, lbrace, rbrace, top_level),\n                \"generic arg\",\n            ),\n        );\n        let rangle = self.parse_token::<TerminalGT>();\n        GenericArgs::new_green(self.db, langle, generic_args, rangle)\n    }\n\n    /// Assumes the current token is LT.\n    /// Expected pattern: `\\< <GenericParamList> \\>`\n    fn expect_generic_params(&mut self) -> WrappedGenericParamListGreen {\n        let langle = self.take::<TerminalLT>();\n        let generic_params = GenericParamList::new_green(\n            self.db,\n            self.parse_separated_list::<GenericParam, TerminalComma, GenericParamListElementOrSeparatorGreen>(\n                Self::try_parse_generic_param,\n                is_of_kind!(rangle, rparen, block, lbrace, rbrace, top_level),\n                \"generic param\",\n            ),\n        );\n        let rangle = self.parse_token::<TerminalGT>();\n        WrappedGenericParamList::new_green(self.db, langle, generic_params, rangle)\n    }\n\n    fn parse_optional_generic_params(&mut self) -> OptionWrappedGenericParamListGreen {\n        if self.peek().kind != SyntaxKind::TerminalLT {\n            return OptionWrappedGenericParamListEmpty::new_green(self.db).into();\n        }\n        self.expect_generic_params().into()\n    }\n\n    fn try_parse_generic_param(&mut self) -> Option<GenericParamGreen> {\n        match self.peek().kind {\n            SyntaxKind::TerminalConst => {\n                let const_kw = self.take::<TerminalConst>();\n                let name = self.parse_identifier();\n                Some(GenericParamConst::new_green(self.db, const_kw, name).into())\n            }\n            SyntaxKind::TerminalImpl => {\n                let impl_kw = self.take::<TerminalImpl>();\n                let name = self.parse_identifier();\n                let colon = self.parse_token::<TerminalColon>();\n                let trait_path = self.parse_path();\n                Some(GenericParamImpl::new_green(self.db, impl_kw, name, colon, trait_path).into())\n            }\n            _ => Some(GenericParamType::new_green(self.db, self.try_parse_identifier()?).into()),\n        }\n    }\n\n    // ------------------------------- Helpers -------------------------------\n\n    /// Parses a list of elements (without separators), where the elements are parsed using\n    /// `try_parse_list_element`.\n    /// Returns the list of green ids of the elements.\n    ///\n    /// `should_stop` is a predicate to decide how to proceed in case an element can't be parsed,\n    /// according to the current token. If it returns true, the parsing of the list stops. If it\n    /// returns false, the current token is skipped and we try to parse an element again.\n    ///\n    /// `expected_element` is a description of the expected element.\n    fn parse_list<ElementGreen>(\n        &mut self,\n        try_parse_list_element: fn(&mut Self) -> Option<ElementGreen>,\n        should_stop: fn(SyntaxKind) -> bool,\n        expected_element: &str,\n    ) -> Vec<ElementGreen> {\n        let mut children: Vec<ElementGreen> = Vec::new();\n        loop {\n            let element = try_parse_list_element(self);\n            if let Some(green) = element {\n                children.push(green);\n            } else {\n                if should_stop(self.peek().kind) {\n                    break;\n                }\n                self.skip_token(ParserDiagnosticKind::SkippedElement {\n                    element_name: expected_element.into(),\n                });\n            }\n        }\n        children\n    }\n\n    /// Parses a list of elements (without separators) that can be prefixed with attributes\n    /// (#[...]), where the elements are parsed using `try_parse_list_element`.\n    /// Returns the list of green ids of the elements.\n    ///\n    /// `should_stop` is a predicate to decide how to proceed in case an element can't be parsed,\n    /// according to the current token. If it returns true, the parsing of the list stops. If it\n    /// returns false, the current token is skipped and we try to parse an element again.\n    ///\n    /// `expected_element` is a description of the expected element. Note: it should not include\n    /// \"attribute\".\n    fn parse_attributed_list<ElementGreen>(\n        &mut self,\n        try_parse_list_element: fn(&mut Self) -> Option<ElementGreen>,\n        should_stop: fn(SyntaxKind) -> bool,\n        expected_element: &str,\n    ) -> Vec<ElementGreen> {\n        self.parse_list::<ElementGreen>(\n            try_parse_list_element,\n            should_stop,\n            &format!(\"{expected_element} or an attribute\"),\n        )\n    }\n\n    /// Parses a list of elements with `separator`s, where the elements are parsed using\n    /// `try_parse_list_element`. The separator may or may not appear in the end of the list.\n    /// Returns the list of elements and separators. This list contains alternating children:\n    /// [element, separator, element, separator, ...]. Separators may be missing.\n    /// The length of the list is either 2 * #elements - 1 or 2 * #elements (a separator for each\n    /// element or for each element but the last one).\n    ///\n    /// `should_stop` is a predicate to decide how to proceed in case an element or a separator\n    /// can't be parsed, according to the current token.\n    /// When parsing an element:\n    /// If it returns true, the parsing of the list stops. If it returns false, the current token\n    /// is skipped and we try to parse an element again.\n    /// When parsing a separator:\n    /// If it returns true, the parsing of the list stops. If it returns false, a missing separator\n    /// is added and we continue to try to parse another element (with the same token).\n    fn parse_separated_list<\n        Element: TypedSyntaxNode,\n        Separator: syntax::node::Terminal,\n        ElementOrSeparatorGreen,\n    >(\n        &mut self,\n        try_parse_list_element: fn(&mut Self) -> Option<Element::Green>,\n        should_stop: fn(SyntaxKind) -> bool,\n        expected_element: &'static str,\n    ) -> Vec<ElementOrSeparatorGreen>\n    where\n        ElementOrSeparatorGreen: From<Separator::Green> + From<Element::Green>,\n    {\n        let mut children: Vec<ElementOrSeparatorGreen> = Vec::new();\n        loop {\n            match try_parse_list_element(self) {\n                None if should_stop(self.peek().kind) => {\n                    break;\n                }\n                None => {\n                    self.skip_token(ParserDiagnosticKind::SkippedElement {\n                        element_name: expected_element.into(),\n                    });\n                    continue;\n                }\n                Some(element) => {\n                    children.push(element.into());\n                }\n            };\n\n            let separator = match self.try_parse_token::<Separator>() {\n                None if should_stop(self.peek().kind) => {\n                    break;\n                }\n                None => self.create_and_report_missing::<Separator>(\n                    ParserDiagnosticKind::MissingToken(Separator::KIND),\n                ),\n                Some(separator) => separator,\n            };\n            children.push(separator.into());\n        }\n        children\n    }\n\n    /// Peeks at the next terminal from the Lexer without taking it.\n    fn peek(&self) -> &LexerTerminal {\n        &self.next_terminal\n    }\n\n    /// Takes a terminal from the Lexer and places it in self.next_terminal.\n    fn take_raw(&mut self) -> LexerTerminal {\n        self.offset = self.offset.add_width(self.current_width);\n        self.current_width = self.next_terminal.width(self.db);\n        self.last_trivia_length =\n            self.next_terminal.trailing_trivia.iter().map(|y| y.0.width(self.db)).sum();\n        let next_terminal = self.lexer.next().unwrap();\n        std::mem::replace(&mut self.next_terminal, next_terminal)\n    }\n\n    /// Skips a token. A skipped token is a token which is not expected where it is found. Skipping\n    /// this token means reporting an error and ignoring it and continuing the compilation as if it\n    /// wasn't there.\n    fn skip_token(&mut self, diagnostic_kind: ParserDiagnosticKind) {\n        let terminal = self.take_raw();\n\n        let diag_start = self.offset.add_width(\n            terminal\n                .leading_trivia\n                .iter()\n                .map(|trivium| trivium.0.width(self.db))\n                .sum::<TextWidth>(),\n        );\n        let diag_end = diag_start.add_width(TextWidth::from_str(&terminal.text));\n\n        // Add to pending trivia.\n        self.pending_trivia.extend(terminal.leading_trivia);\n        self.pending_trivia.push(TokenSkipped::new_green(self.db, terminal.text).into());\n        self.pending_trivia.extend(terminal.trailing_trivia);\n        self.diagnostics.add(ParserDiagnostic {\n            file_id: self.file_id,\n            kind: diagnostic_kind,\n            span: TextSpan { start: diag_start, end: diag_end },\n        });\n    }\n\n    /// Skips the current token, reports the given diagnostic and returns missing kind of the\n    /// expected terminal.\n    fn skip_token_and_return_missing<ExpectedTerminal: syntax::node::Terminal>(\n        &mut self,\n        diagnostic: ParserDiagnosticKind,\n    ) -> ExpectedTerminal::Green {\n        self.skip_token(diagnostic);\n        ExpectedTerminal::missing(self.db)\n    }\n\n    /// Skips terminals until `should_stop` returns `true`.\n    ///\n    /// Returns the span of the skipped terminals, if any.\n    fn skip_until(&mut self, should_stop: fn(SyntaxKind) -> bool) -> Result<(), SkippedError> {\n        let mut diag_start = None;\n        let mut diag_end = None;\n        while !should_stop(self.peek().kind) {\n            let terminal = self.take_raw();\n            diag_start.get_or_insert(self.offset);\n            diag_end = Some(self.offset.add_width(TextWidth::from_str(&terminal.text)));\n\n            self.pending_trivia.extend(terminal.leading_trivia);\n            self.pending_trivia.push(TokenSkipped::new_green(self.db, terminal.text).into());\n            self.pending_trivia.extend(terminal.trailing_trivia);\n        }\n        if let (Some(diag_start), Some(diag_end)) = (diag_start, diag_end) {\n            Err(SkippedError(TextSpan { start: diag_start, end: diag_end }))\n        } else {\n            Ok(())\n        }\n    }\n\n    /// Builds a new terminal to replace the given terminal by gluing the recently skipped terminals\n    /// to the given terminal as extra leading trivia.\n    fn add_trivia_to_terminal<Terminal: syntax::node::Terminal>(\n        &mut self,\n        lexer_terminal: LexerTerminal,\n    ) -> Terminal::Green {\n        let LexerTerminal { text, kind: _, leading_trivia, trailing_trivia } = lexer_terminal;\n        let token = Terminal::TokenType::new_green(self.db, text);\n        let mut new_leading_trivia = mem::take(&mut self.pending_trivia);\n        new_leading_trivia.extend(leading_trivia);\n        Terminal::new_green(\n            self.db,\n            Trivia::new_green(self.db, new_leading_trivia),\n            token,\n            Trivia::new_green(self.db, trailing_trivia),\n        )\n    }\n\n    /// Takes a token from the Lexer and place it in self.current. If tokens were skipped, glue them\n    /// to this token as leading trivia.\n    fn take<Terminal: syntax::node::Terminal>(&mut self) -> Terminal::Green {\n        let token = self.take_raw();\n        assert_eq!(token.kind, Terminal::KIND);\n        self.add_trivia_to_terminal::<Terminal>(token)\n    }\n\n    /// If the current terminal is of kind `Terminal`, returns its Green wrapper. Otherwise, returns\n    /// None.\n    /// Note that this function should not be called for 'TerminalIdentifier' -\n    /// try_parse_identifier() should be used instead.\n    fn try_parse_token<Terminal: syntax::node::Terminal>(&mut self) -> Option<Terminal::Green> {\n        if Terminal::KIND == self.peek().kind { Some(self.take::<Terminal>()) } else { None }\n    }\n\n    /// If the current token is of kind `token_kind`, returns a GreenId of a node with this kind.\n    /// Otherwise, returns Token::Missing.\n    ///\n    /// Note that this function should not be called for 'TerminalIdentifier' - parse_identifier()\n    /// should be used instead.\n    fn parse_token<Terminal: syntax::node::Terminal>(&mut self) -> Terminal::Green {\n        self.parse_token_ex::<Terminal>(true)\n    }\n\n    /// Same as [Self::parse_token], except that the diagnostic may be omitted.\n    fn parse_token_ex<Terminal: syntax::node::Terminal>(\n        &mut self,\n        report_diagnostic: bool,\n    ) -> Terminal::Green {\n        match self.try_parse_token::<Terminal>() {\n            Some(green) => green,\n            None => {\n                if report_diagnostic {\n                    self.create_and_report_missing_terminal::<Terminal>()\n                } else {\n                    Terminal::missing(self.db)\n                }\n            }\n        }\n    }\n}\n\n/// Controls whether Lbrace (`{`) is allowed in the expression.\n///\n/// Lbrace is always allowed in sub-expressions (e.g. in parenthesized expression). For example,\n/// while `1 + MyStruct { ... }` may not be valid, `1 + (MyStruct { ... })` is always ok.\n///\n/// This can be used to parse the argument of a `match` statement,\n/// so that the `{` that opens the `match` body is not confused with other potential uses of\n/// `{`.\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\nenum LbraceAllowed {\n    Forbid,\n    Allow,\n}\n\n/// Indicates that [Parser::skip_until] skipped some terminals.\nstruct SkippedError(TextSpan);\n\n/// Defines the parser behavior in the case of a parsing error.\nstruct ErrorRecovery {\n    /// In the case of a parsing error, tokens will be skipped until `should_stop`\n    /// returns `true`. For example, one can stop at tokens such as `,` and `}`.\n    should_stop: fn(SyntaxKind) -> bool,\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "#![allow(non_upper_case_globals)]\nuse std::fmt::Write;\n\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse test_case::test_case;\n\nuse crate::colored_printer::print_colored;\nuse crate::printer::{print_partial_tree, print_tree};\nuse crate::test_utils::{create_virtual_file, get_diagnostics, read_file};\nuse crate::utils::{\n    get_syntax_root_and_diagnostics, get_syntax_root_and_diagnostics_from_file,\n    SimpleParserDatabase,\n};\n\nstruct ParserTreeTestParams {\n    cairo_filename: &'static str,\n    expected_output_filename: &'static str,\n    print_diagnostics: bool,\n    print_colors: bool,\n    print_trivia: bool,\n}\n\nconst TEST_short_tree_uncolored: ParserTreeTestParams = ParserTreeTestParams {\n    cairo_filename: \"test_data/cairo_files/short.cairo\",\n    expected_output_filename: \"test_data/expected_results/short_tree\",\n    print_diagnostics: true,\n    print_colors: false,\n    print_trivia: false,\n};\nconst TEST_short_tree_colored: ParserTreeTestParams = ParserTreeTestParams {\n    cairo_filename: \"test_data/cairo_files/short.cairo\",\n    expected_output_filename: \"test_data/expected_results/short_tree_colored\",\n    print_diagnostics: false,\n    print_colors: true,\n    print_trivia: false,\n};\nconst TEST_test1_tree_no_trivia: ParserTreeTestParams = ParserTreeTestParams {\n    cairo_filename: \"test_data/cairo_files/test1.cairo\",\n    expected_output_filename: \"test_data/expected_results/test1_tree_no_trivia\",\n    print_diagnostics: true,\n    print_colors: false,\n    print_trivia: false,\n};\nconst TEST_test1_tree_with_trivia: ParserTreeTestParams = ParserTreeTestParams {\n    cairo_filename: \"test_data/cairo_files/test1.cairo\",\n    expected_output_filename: \"test_data/expected_results/test1_tree_with_trivia\",\n    print_diagnostics: false,\n    print_colors: false,\n    print_trivia: true,\n};\nconst TEST_test2_tree_no_trivia: ParserTreeTestParams = ParserTreeTestParams {\n    cairo_filename: \"test_data/cairo_files/test2.cairo\",\n    expected_output_filename: \"test_data/expected_results/test2_tree_no_trivia\",\n    print_diagnostics: true,\n    print_colors: false,\n    print_trivia: false,\n};\nconst TEST_test2_tree_with_trivia: ParserTreeTestParams = ParserTreeTestParams {\n    cairo_filename: \"test_data/cairo_files/test2.cairo\",\n    expected_output_filename: \"test_data/expected_results/test2_tree_with_trivia\",\n    print_diagnostics: false,\n    print_colors: false,\n    print_trivia: true,\n};\nconst TEST_test3_tree_no_trivia: ParserTreeTestParams = ParserTreeTestParams {\n    cairo_filename: \"test_data/cairo_files/test3.cairo\",\n    expected_output_filename: \"test_data/expected_results/test3_tree_no_trivia\",\n    print_diagnostics: true,\n    print_colors: false,\n    print_trivia: false,\n};\nconst TEST_test3_tree_with_trivia: ParserTreeTestParams = ParserTreeTestParams {\n    cairo_filename: \"test_data/cairo_files/test3.cairo\",\n    expected_output_filename: \"test_data/expected_results/test3_tree_with_trivia\",\n    print_diagnostics: false,\n    print_colors: false,\n    print_trivia: true,\n};\n#[cfg(feature = \"fix_parser_tests\")]\nstatic TREE_TEST_CASES: [&ParserTreeTestParams; 8] = [\n    &TEST_short_tree_uncolored,\n    &TEST_short_tree_colored,\n    &TEST_test1_tree_no_trivia,\n    &TEST_test1_tree_with_trivia,\n    &TEST_test2_tree_no_trivia,\n    &TEST_test2_tree_with_trivia,\n    &TEST_test3_tree_no_trivia,\n    &TEST_test3_tree_with_trivia,\n];\n\n/// Parse the cairo file, print it, and compare with the expected result.\n#[test_case(&TEST_short_tree_uncolored; \"short_tree_uncolored\")]\n#[test_case(&TEST_short_tree_colored; \"short_tree_colored\")]\n#[test_case(&TEST_test1_tree_no_trivia; \"test1_tree_no_trivia\")]\n#[test_case(&TEST_test1_tree_with_trivia; \"test1_tree_with_trivia\")]\n#[test_case(&TEST_test2_tree_no_trivia; \"test2_tree_no_trivia\")]\n#[test_case(&TEST_test2_tree_with_trivia; \"test2_tree_with_trivia\")]\n#[test_case(&TEST_test3_tree_no_trivia; \"test3_tree_no_trivia\")]\n#[test_case(&TEST_test3_tree_with_trivia; \"test3_tree_with_trivia\")]\nfn parse_and_compare_tree(test_params: &ParserTreeTestParams) {\n    parse_and_compare_tree_maybe_fix(test_params, false);\n}\n\nfn parse_and_compare_tree_maybe_fix(test_params: &ParserTreeTestParams, fix: bool) {\n    // Make sure the colors are printed, even if the test doesn't run in a terminal.\n    colored::control::set_override(true);\n\n    let db_val = SimpleParserDatabase::default();\n    let db = &db_val;\n\n    let (syntax_root, diagnostics) =\n        get_syntax_root_and_diagnostics_from_file(db, test_params.cairo_filename);\n    let diagnostics_str = diagnostics.format(db);\n\n    let mut printed_tree =\n        print_tree(db, &syntax_root, test_params.print_colors, test_params.print_trivia);\n    if test_params.print_diagnostics {\n        write!(printed_tree, \"--------------------\\n{diagnostics_str}\").unwrap();\n    }\n\n    let expected_tree = read_file(test_params.expected_output_filename);\n    compare_printed_and_expected_maybe_fix(\n        printed_tree,\n        expected_tree,\n        test_params.expected_output_filename,\n        fix,\n    );\n}\n\nstruct ParserColoredTestParams {\n    cairo_filename: &'static str,\n    expected_colored_filename: &'static str,\n    verbose: bool,\n}\n\nconst TEST_colored: ParserColoredTestParams = ParserColoredTestParams {\n    cairo_filename: \"test_data/cairo_files/colored.cairo\",\n    expected_colored_filename: \"test_data/expected_results/colored\",\n    verbose: false,\n};\nconst TEST_colored_verbose: ParserColoredTestParams = ParserColoredTestParams {\n    cairo_filename: \"test_data/cairo_files/colored.cairo\",\n    expected_colored_filename: \"test_data/expected_results/colored_verbose\",\n    verbose: true,\n};\n#[cfg(feature = \"fix_parser_tests\")]\nstatic COLORED_TEST_CASES: [&ParserColoredTestParams; 2] = [&TEST_colored, &TEST_colored_verbose];\n\n#[test_case(&TEST_colored;\"colored\")]\n#[test_case(&TEST_colored_verbose; \"colored_verbose\")]\nfn parse_and_compare_colored(test_params: &ParserColoredTestParams) {\n    parse_and_compare_colored_maybe_fix(test_params, false);\n}\nfn parse_and_compare_colored_maybe_fix(test_params: &ParserColoredTestParams, fix: bool) {\n    // Make sure the colors are printed, even if the test doesn't run in a terminal.\n    colored::control::set_override(true);\n\n    let db_val = SimpleParserDatabase::default();\n    let db = &db_val;\n\n    let (syntax_root, _diagnostics) =\n        get_syntax_root_and_diagnostics_from_file(db, test_params.cairo_filename);\n    let printed = print_colored(db, &syntax_root, test_params.verbose);\n    let expected = read_file(test_params.expected_colored_filename);\n    compare_printed_and_expected_maybe_fix(\n        printed,\n        expected,\n        test_params.expected_colored_filename,\n        fix,\n    );\n}\n\n/// Compares the printed output with the expected one. If `fix` is true, overwrites the output file\n/// to fix the test.\nfn compare_printed_and_expected_maybe_fix(\n    printed: String,\n    expected: String,\n    expected_output_filename: &str,\n    fix: bool,\n) {\n    if printed != expected {\n        if fix {\n            println!(\n                \"Test failed, fixing expected output file: {expected_output_filename}. Please \\\n                 make sure that the result is correct.\"\n            );\n            std::fs::write(expected_output_filename, printed)\n                .expect(\"Failed writing to the expected output file\");\n        } else {\n            panic!(\n                \"assertion failed: printed != expected.\\nTo automatically fix this, run:\\n  cargo \\\n                 test -p cairo-lang-parser -F fix_parser_tests --tests \\\n                 parser::test::fix_parser_tests -- --nocapture\\nNote to carefully review it and \\\n                 not to blindly paste it there, as this loses the whole point of the test.\\nTo \\\n                 debug this without fixing, use _debug_failure().\"\n            );\n        }\n    }\n}\n\nfn _debug_failure(printed: String, expected: String) {\n    println!(\"Printed:\\n{printed}\");\n\n    let printed_bytes = printed.as_bytes();\n    let expected_bytes = expected.as_bytes();\n\n    if printed == expected {\n        println!(\"Printed is as expected.\");\n        return;\n    }\n    for (i, printed_byte) in printed_bytes.iter().enumerate() {\n        let expected_byte = expected_bytes[i];\n        if *printed_byte != expected_byte {\n            println!(\"printed is different than expected! First different byte index: {i}\");\n            println!(\"Printed byte: {printed_byte:02x}, Expected byte: {expected_byte:02x}\");\n\n            let initial_index = if i < 5000 { 0 } else { i - 5000 };\n            let last_50_printed = &printed_bytes[initial_index..(i + 1)];\n            let last_50_expected = &expected_bytes[initial_index..(i + 1)];\n\n            _print_bytes(\"Printed hex:\", last_50_printed, true);\n            _print_bytes(\"Expected hex:\", last_50_expected, true);\n            _print_bytes(\"Printed raw:\", last_50_printed, false);\n            _print_bytes(\"Expected raw:\", last_50_expected, false);\n            break;\n        }\n    }\n}\n\n// `hex`: print hex if true, raw if false.\nfn _print_bytes(title: &str, bytes: &[u8], hex: bool) {\n    println!(\"{title}\");\n    let mut bytes_str = String::new();\n    if hex {\n        for c in bytes {\n            bytes_str.push_str(format!(\"{c:02x} \").as_str());\n        }\n    } else {\n        for c in bytes {\n            bytes_str.push_str(format!(\"{}\", *c as char).as_str());\n        }\n    }\n    println!(\"{bytes_str}\");\n}\n\n// Fixes the parser tests expected output files to the content of the parsed files.\n// !!! Use this with caution! Review the changed output files carefully !!!\n#[test]\n#[cfg(feature = \"fix_parser_tests\")]\npub fn fix_parser_tests() {\n    for test_params in TREE_TEST_CASES {\n        parse_and_compare_tree_maybe_fix(test_params, true);\n    }\n    for test_params in COLORED_TEST_CASES {\n        parse_and_compare_colored_maybe_fix(test_params, true);\n    }\n    println!(\"All Parser tests should be fixed now!\");\n}\n\n/// Inputs:\n/// - cairo_code\n/// - top_level_kind - the highest SyntaxKind that is interesting. All other kinds, if not under it,\n///   are ignored.\n/// - ignored_kinds: Syntax kinds to ignore when printing. In this context, \"ignore\" means printing\n///   the nodes themselves, but not their children.\n/// Outputs:\n/// - expected_tree - the printed syntax tree of the given cairo_code, with/without trivia, ignoring\n///   the irrelevant kinds.\npub fn test_partial_parser_tree(\n    inputs: &OrderedHashMap<String, String>,\n) -> OrderedHashMap<String, String> {\n    test_partial_parser_tree_inner(inputs, false)\n}\npub fn test_partial_parser_tree_with_trivia(\n    inputs: &OrderedHashMap<String, String>,\n) -> OrderedHashMap<String, String> {\n    test_partial_parser_tree_inner(inputs, true)\n}\nfn test_partial_parser_tree_inner(\n    inputs: &OrderedHashMap<String, String>,\n    print_trivia: bool,\n) -> OrderedHashMap<String, String> {\n    // TODO(yuval): allow pointing to a code in another file.\n    let db = &SimpleParserDatabase::default();\n    let file_id = create_virtual_file(db, \"dummy_file.cairo\", &inputs[\"cairo_code\"]);\n    let (syntax_root, diagnostics) =\n        get_syntax_root_and_diagnostics(db, file_id, &inputs[\"cairo_code\"]);\n\n    let ignored_kinds: Vec<&str> = inputs[\"ignored_kinds\"].split('\\n').collect();\n    OrderedHashMap::from([\n        (\n            \"expected_tree\".into(),\n            print_partial_tree(\n                db,\n                &syntax_root,\n                &inputs[\"top_level_kind\"],\n                ignored_kinds,\n                print_trivia,\n            ),\n        ),\n        (\"expected_diagnostics\".into(), diagnostics.format(db)),\n    ])\n}\n\ncairo_lang_test_utils::test_file_test!(\n    diagnostic,\n    \"src/parser_test_data\",\n    {\n        module_diagnostics: \"module_diagnostics\",\n        exprs: \"exprs\",\n        fn_: \"fn\",\n        if_: \"if\",\n        match_: \"match\",\n        pattern: \"pattern\",\n        unterminated_string: \"unterminated_string\",\n        question_mark: \"question_mark\",\n        semicolon: \"semicolon\",\n        reserved_identifier: \"reserved_identifier\",\n        underscore_not_supported: \"underscore_not_supported\",\n    },\n    get_diagnostics\n);\n\ncairo_lang_test_utils::test_file_test!(\n    partial_parser_tree,\n    \"src/parser_test_data\",\n    {\n        constant: \"constant\",\n        enum_: \"enum\",\n        item_free_function: \"item_free_function\",\n        function_signature: \"function_signature\",\n        function_call: \"function_call\",\n        unary_only_operators: \"unary_only_operators\",\n        item_trait: \"item_trait\",\n        let_statement: \"let_statement\",\n        if_else: \"if_else\",\n        literal: \"literal\",\n        module: \"module\",\n        op_eq: \"op_eq\",\n        array: \"array\",\n    },\n    test_partial_parser_tree\n);\n\ncairo_lang_test_utils::test_file_test!(\n    partial_parser_tree_with_trivia,\n    \"src/parser_test_data\",\n    {\n        path: \"path_with_trivia\",\n        path_compat: \"path_with_trivia_compat\",\n    },\n    test_partial_parser_tree_with_trivia\n);\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_syntax as syntax;\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::kind::SyntaxKind;\nuse cairo_lang_syntax::node::SyntaxNode;\nuse cairo_lang_syntax_codegen::cairo_spec::get_spec;\nuse cairo_lang_syntax_codegen::spec::{Member, Node, NodeKind};\nuse colored::{ColoredString, Colorize};\nuse itertools::zip_eq;\nuse smol_str::SmolStr;\n\npub fn print_tree(\n    db: &dyn SyntaxGroup,\n    syntax_root: &SyntaxNode,\n    print_colors: bool,\n    print_trivia: bool,\n) -> String {\n    let mut printer = Printer::new(db, print_colors, print_trivia);\n    printer.print_tree(\"root\", syntax_root, \"\", true, true);\n    printer.result\n}\n\npub fn print_partial_tree(\n    db: &dyn SyntaxGroup,\n    syntax_root: &SyntaxNode,\n    top_level_kind: &str,\n    ignored_kinds: Vec<&str>,\n    print_trivia: bool,\n) -> String {\n    let mut printer = Printer::new_partial(db, top_level_kind, ignored_kinds, print_trivia);\n    printer.print_tree(\"root\", syntax_root, \"\", true, false);\n    printer.result\n}\n\nstruct Printer<'a> {\n    db: &'a dyn SyntaxGroup,\n    spec: Vec<Node>,\n    print_colors: bool,\n    print_trivia: bool,\n    /// The highest SyntaxKind that is interesting. All other kinds, if not under it, are ignored.\n    top_level_kind: Option<String>,\n    /// Syntax kinds to ignore when printing. In this context, \"ignore\" means printing the nodes\n    /// themselves, but not their children.\n    ignored_kinds: Vec<String>,\n    result: String,\n}\nimpl<'a> Printer<'a> {\n    fn new(db: &'a dyn SyntaxGroup, print_colors: bool, print_trivia: bool) -> Self {\n        Self {\n            db,\n            spec: get_spec(),\n            print_colors,\n            print_trivia,\n            top_level_kind: None,\n            ignored_kinds: Vec::new(),\n            result: String::new(),\n        }\n    }\n\n    /// Create a new printer that is capable of partial printing of the syntax tree.\n    fn new_partial(\n        db: &'a dyn SyntaxGroup,\n        top_level_kind: &str,\n        ignored_kinds: Vec<&str>,\n        print_trivia: bool,\n    ) -> Self {\n        Self {\n            db,\n            spec: get_spec(),\n            print_colors: false,\n            print_trivia,\n            top_level_kind: Some(top_level_kind.to_string()),\n            ignored_kinds: ignored_kinds.into_iter().map(|x| x.to_string()).collect(),\n            result: String::new(),\n        }\n    }\n\n    /// `under_top_level`: whether we are in a subtree of the top-level kind.\n    fn print_tree(\n        &mut self,\n        field_description: &str,\n        syntax_node: &SyntaxNode,\n        indent: &str,\n        is_last: bool,\n        under_top_level: bool,\n    ) {\n        let extra_head_indent = if is_last { \" \" } else { \" \" };\n        let green_node = syntax_node.green_node(self.db);\n        match green_node.details {\n            syntax::node::green::GreenNodeDetails::Token(text) => {\n                if under_top_level {\n                    self.print_token_node(\n                        field_description,\n                        indent,\n                        extra_head_indent,\n                        text,\n                        green_node.kind,\n                    )\n                }\n            }\n            syntax::node::green::GreenNodeDetails::Node { .. } => {\n                self.print_internal_node(\n                    field_description,\n                    indent,\n                    extra_head_indent,\n                    is_last,\n                    syntax_node,\n                    green_node.kind,\n                    under_top_level,\n                );\n            }\n        }\n    }\n\n    fn print_token_node(\n        &mut self,\n        field_description: &str,\n        indent: &str,\n        extra_head_indent: &str,\n        text: SmolStr,\n        kind: SyntaxKind,\n    ) {\n        let text = if kind == SyntaxKind::TokenMissing {\n            format!(\"{}: {}\", self.blue(field_description.into()), self.red(\"Missing\".into()))\n        } else {\n            let token_text = match kind {\n                SyntaxKind::TokenWhitespace\n                | SyntaxKind::TokenNewline\n                | SyntaxKind::TokenEndOfFile => \".\".to_string(),\n                _ => format!(\": '{}'\", self.green(self.bold(text.as_str().into()))),\n            };\n            format!(\"{} (kind: {:?}){token_text}\", self.blue(field_description.into()), kind)\n        };\n        self.result.push_str(format!(\"{indent}{extra_head_indent}{text}\\n\").as_str());\n    }\n\n    /// `under_top_level`: whether we are in a subtree of the top-level kind.\n    #[allow(clippy::too_many_arguments)]\n    fn print_internal_node(\n        &mut self,\n        field_description: &str,\n        indent: &str,\n        extra_head_indent: &str,\n        is_last: bool,\n        syntax_node: &SyntaxNode,\n        kind: SyntaxKind,\n        under_top_level: bool,\n    ) {\n        let current_is_top_level =\n            !under_top_level && self.top_level_kind == Some(format!(\"{kind:?}\"));\n        // Update under_top_level and indent as needed.\n        let (under_top_level, indent) =\n            if current_is_top_level { (true, \"\") } else { (under_top_level, indent) };\n\n        if !self.print_trivia {\n            if let Some(token_node) = syntax_node.get_terminal_token(self.db) {\n                self.print_tree(field_description, &token_node, indent, is_last, under_top_level);\n                return;\n            }\n        }\n\n        let extra_info = if is_missing_kind(kind) {\n            format!(\": {}\", self.red(\"Missing\".into()))\n        } else {\n            format!(\" (kind: {kind:?})\")\n        };\n\n        let children: Vec<_> = syntax_node.children(self.db).collect();\n        let num_children = children.len();\n        let suffix = if self.ignored_kinds.contains(&format!(\"{kind:?}\")) {\n            \" <ignored>\".to_string()\n        } else if num_children == 0 {\n            self.bright_purple(\" []\".into()).to_string()\n        } else {\n            String::new()\n        };\n\n        // Append to string only if we are under the top level kind.\n        if under_top_level {\n            if current_is_top_level {\n                self.result.push_str(format!(\" Top level kind: {kind:?}{suffix}\\n\").as_str());\n            } else {\n                self.result.push_str(\n                    format!(\n                        \"{indent}{extra_head_indent}{}{extra_info}{suffix}\\n\",\n                        self.cyan(field_description.into())\n                    )\n                    .as_str(),\n                );\n            }\n        }\n\n        if under_top_level && self.ignored_kinds.contains(&format!(\"{kind:?}\")) {\n            return;\n        }\n\n        if num_children == 0 {\n            return;\n        }\n\n        let extra_indent = if is_last || current_is_top_level { \"    \" } else { \"   \" };\n        let indent = String::from(indent) + extra_indent;\n        let node_kind = self.get_node_kind(kind.to_string());\n        match node_kind {\n            NodeKind::Struct { members: expected_children }\n            | NodeKind::Terminal { members: expected_children, .. } => {\n                self.print_internal_struct(\n                    &children,\n                    &expected_children,\n                    indent.as_str(),\n                    under_top_level,\n                );\n            }\n            NodeKind::List { .. } => {\n                for (i, child) in children.iter().enumerate() {\n                    self.print_tree(\n                        format!(\"child #{i}\").as_str(),\n                        child,\n                        indent.as_str(),\n                        i == num_children - 1,\n                        under_top_level,\n                    );\n                }\n            }\n            NodeKind::SeparatedList { .. } => {\n                for (i, child) in children.iter().enumerate() {\n                    let description = if i % 2 == 0 { \"item\" } else { \"separator\" };\n                    self.print_tree(\n                        format!(\"{description} #{}\", i / 2).as_str(),\n                        child,\n                        indent.as_str(),\n                        i == num_children - 1,\n                        under_top_level,\n                    );\n                }\n            }\n            _ => panic!(\"This should never happen\"),\n        }\n    }\n\n    /// Assumes children and expected children are non-empty of the same length.\n    /// `under_top_level`: whether we are in a subtree of the top-level kind.\n    fn print_internal_struct(\n        &mut self,\n        children: &[SyntaxNode],\n        expected_children: &[Member],\n        indent: &str,\n        under_top_level: bool,\n    ) {\n        let (last_child, non_last_children) = children.split_last().unwrap();\n        let (last_expected_child, non_last_expected_children) =\n            expected_children.split_last().unwrap();\n        for (child, expected_child) in zip_eq(non_last_children, non_last_expected_children) {\n            self.print_tree(&expected_child.name, child, indent, false, under_top_level);\n        }\n        self.print_tree(&last_expected_child.name, last_child, indent, true, under_top_level);\n    }\n\n    fn get_node_kind(&self, name: String) -> NodeKind {\n        if let Some(node) = self.spec.iter().find(|x| x.name == name) {\n            node.kind.clone()\n        } else {\n            panic!(\"Could not find spec for {name}\")\n        }\n    }\n\n    // Color helpers.\n    fn bold(&self, text: ColoredString) -> ColoredString {\n        if self.print_colors { text.bold() } else { text }\n    }\n    fn green(&self, text: ColoredString) -> ColoredString {\n        if self.print_colors { text.green() } else { text }\n    }\n    fn red(&self, text: ColoredString) -> ColoredString {\n        if self.print_colors { text.red() } else { text }\n    }\n    fn cyan(&self, text: ColoredString) -> ColoredString {\n        if self.print_colors { text.cyan() } else { text }\n    }\n    fn blue(&self, text: ColoredString) -> ColoredString {\n        if self.print_colors { text.blue() } else { text }\n    }\n    fn bright_purple(&self, text: ColoredString) -> ColoredString {\n        if self.print_colors { text.bright_purple() } else { text }\n    }\n}\n\n// TODO(yuval): autogenerate.\nfn is_missing_kind(kind: SyntaxKind) -> bool {\n    matches!(kind, SyntaxKind::ExprMissing | SyntaxKind::StatementMissing)\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "/// Macro that produces an inline function that gets a token kind and returns true iff it is in one\n/// of the supplied groups.\nmacro_rules! is_of_kind {\n    ($($element:ident),*) => {\n        |kind: SyntaxKind| {\n            match kind{\n                $($crate::recovery::$element!() => true,)*\n                SyntaxKind::TerminalEndOfFile => true,\n                _ => false\n            }\n        }\n    };\n}\npub(crate) use is_of_kind;\n\nmacro_rules! lbrace {\n    () => {\n        SyntaxKind::TerminalLBrace\n    };\n}\npub(crate) use lbrace;\n\nmacro_rules! rbrace {\n    () => {\n        SyntaxKind::TerminalRBrace\n    };\n}\npub(crate) use rbrace;\n\nmacro_rules! rparen {\n    () => {\n        SyntaxKind::TerminalRParen\n    };\n}\npub(crate) use rparen;\n\nmacro_rules! rangle {\n    () => {\n        SyntaxKind::TerminalGT\n    };\n}\npub(crate) use rangle;\n\nmacro_rules! comma {\n    () => {\n        SyntaxKind::TerminalComma\n    };\n}\npub(crate) use comma;\n\nmacro_rules! semicolon {\n    () => {\n        SyntaxKind::TerminalSemicolon\n    };\n}\npub(crate) use semicolon;\n\nmacro_rules! eq {\n    () => {\n        SyntaxKind::TerminalEq\n    };\n}\npub(crate) use eq;\n\nmacro_rules! top_level {\n    () => {\n        SyntaxKind::TerminalConst\n            | SyntaxKind::TerminalEnum\n            | SyntaxKind::TerminalExtern\n            | SyntaxKind::TerminalFunction\n            | SyntaxKind::TerminalImpl\n            | SyntaxKind::TerminalModule\n            | SyntaxKind::TerminalStruct\n            | SyntaxKind::TerminalTrait\n            | SyntaxKind::TerminalType\n            | SyntaxKind::TerminalUse\n    };\n}\npub(crate) use top_level;\n\nmacro_rules! block {\n    () => {\n        SyntaxKind::TerminalLet | SyntaxKind::TerminalMatch | SyntaxKind::TerminalReturn\n    };\n}\npub(crate) use block;\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::fs;\nuse std::sync::Arc;\n\nuse cairo_lang_filesystem::db::FilesGroup;\nuse cairo_lang_filesystem::ids::{FileId, FileLongId, VirtualFile};\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse smol_str::SmolStr;\n\nuse crate::utils::{get_syntax_root_and_diagnostics, SimpleParserDatabase};\n\npub fn read_file(filename: &str) -> String {\n    fs::read_to_string(filename)\n        .unwrap_or_else(|_| panic!(\"Something went wrong reading file {filename}\"))\n}\n\npub fn get_diagnostics(inputs: &OrderedHashMap<String, String>) -> OrderedHashMap<String, String> {\n    let db = &SimpleParserDatabase::default();\n    let code = &inputs[\"cairo_code\"];\n\n    let file_id = create_virtual_file(db, \"dummy_file.cairo\", code);\n    let (_, diagnostics) = get_syntax_root_and_diagnostics(db, file_id, code);\n    OrderedHashMap::from([(\"expected_diagnostics\".into(), diagnostics.format(db))])\n}\n\n// TODO(yuval): stop virtual files for tests anymore. See semantic tests.\n/// Creates a virtual file with the given content and returns its ID.\npub fn create_virtual_file(\n    db: &SimpleParserDatabase,\n    file_name: impl Into<SmolStr>,\n    content: &str,\n) -> FileId {\n    db.intern_file(FileLongId::Virtual(VirtualFile {\n        parent: None,\n        name: file_name.into(),\n        content: Arc::new(content.into()),\n    }))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::path::PathBuf;\n\nuse cairo_lang_diagnostics::{Diagnostics, DiagnosticsBuilder};\nuse cairo_lang_filesystem::db::{init_files_group, FilesDatabase, FilesGroup};\nuse cairo_lang_filesystem::ids::FileId;\nuse cairo_lang_syntax::node::ast::SyntaxFile;\nuse cairo_lang_syntax::node::db::{SyntaxDatabase, SyntaxGroup};\nuse cairo_lang_syntax::node::{SyntaxNode, TypedSyntaxNode};\nuse cairo_lang_utils::Upcast;\n\nuse crate::db::ParserDatabase;\nuse crate::parser::Parser;\nuse crate::ParserDiagnostic;\n\n/// A salsa database for parsing only.\n#[salsa::database(ParserDatabase, SyntaxDatabase, FilesDatabase)]\npub struct SimpleParserDatabase {\n    storage: salsa::Storage<SimpleParserDatabase>,\n}\nimpl salsa::Database for SimpleParserDatabase {}\nimpl Default for SimpleParserDatabase {\n    fn default() -> Self {\n        let mut res = Self { storage: Default::default() };\n        init_files_group(&mut res);\n        res\n    }\n}\n\nimpl Upcast<dyn SyntaxGroup> for SimpleParserDatabase {\n    fn upcast(&self) -> &(dyn SyntaxGroup + 'static) {\n        self\n    }\n}\nimpl Upcast<dyn FilesGroup> for SimpleParserDatabase {\n    fn upcast(&self) -> &(dyn FilesGroup + 'static) {\n        self\n    }\n}\n\n/// Reads a cairo file to the db and return the syntax_root and diagnostic of its parsing.\npub fn get_syntax_root_and_diagnostics_from_file(\n    db: &SimpleParserDatabase,\n    cairo_filename: &str,\n) -> (SyntaxNode, Diagnostics<ParserDiagnostic>) {\n    let file_id = FileId::new(db, PathBuf::from(cairo_filename));\n    let contents = db.file_content(file_id).unwrap();\n    get_syntax_root_and_diagnostics(db, file_id, contents.as_str())\n}\n\n/// Returns the syntax_root and diagnostic of a file in the db.\npub fn get_syntax_root_and_diagnostics(\n    db: &SimpleParserDatabase,\n    file_id: FileId,\n    contents: &str,\n) -> (SyntaxNode, Diagnostics<ParserDiagnostic>) {\n    let (syntax_file, diagnostics) = get_syntax_file_and_diagnostics(db, file_id, contents);\n    (syntax_file.as_syntax_node(), diagnostics)\n}\n\n/// Returns the syntax_file and diagnostic of a file in the db.\npub fn get_syntax_file_and_diagnostics(\n    db: &SimpleParserDatabase,\n    file_id: FileId,\n    contents: &str,\n) -> (SyntaxFile, Diagnostics<ParserDiagnostic>) {\n    let mut diagnostics = DiagnosticsBuilder::new();\n    let syntax_file = Parser::parse_file(db, &mut diagnostics, file_id, contents);\n    (syntax_file, diagnostics.build())\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashSet;\nuse std::sync::Arc;\n\nuse cairo_lang_defs::plugin::{MacroPlugin, PluginResult};\nuse cairo_lang_semantic::plugin::{AsDynMacroPlugin, SemanticPlugin};\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::{ast, Terminal, TypedSyntaxNode};\n\n/// Plugin that enables ignoring modules not involved in the current config.\n/// Mostly usefull for marking test modules to prevent usage of their functionality out of tests,\n/// and reduce compilation time when the tests data isn't required.\n#[derive(Debug)]\npub struct ConfigPlugin {\n    pub configs: HashSet<String>,\n}\n\nimpl MacroPlugin for ConfigPlugin {\n    fn generate_code(&self, db: &dyn SyntaxGroup, item_ast: ast::Item) -> PluginResult {\n        let item_attributes = match item_ast {\n            ast::Item::Constant(ast_node) => ast_node.attributes(db),\n            ast::Item::Module(ast_node) => ast_node.attributes(db),\n            ast::Item::Use(ast_node) => ast_node.attributes(db),\n            ast::Item::FreeFunction(ast_node) => ast_node.attributes(db),\n            ast::Item::ExternFunction(ast_node) => ast_node.attributes(db),\n            ast::Item::ExternType(ast_node) => ast_node.attributes(db),\n            ast::Item::Trait(ast_node) => ast_node.attributes(db),\n            ast::Item::Impl(ast_node) => ast_node.attributes(db),\n            ast::Item::Struct(ast_node) => ast_node.attributes(db),\n            ast::Item::Enum(ast_node) => ast_node.attributes(db),\n            ast::Item::TypeAlias(ast_node) => ast_node.attributes(db),\n        };\n        for attr in item_attributes.elements(db) {\n            if attr.attr(db).text(db) == \"cfg\" {\n                if let ast::OptionAttributeArgs::AttributeArgs(args) = attr.args(db) {\n                    if !self\n                        .configs\n                        .contains(args.arg_list(db).as_syntax_node().get_text(db).trim())\n                    {\n                        return PluginResult {\n                            code: None,\n                            diagnostics: vec![],\n                            remove_original_item: true,\n                        };\n                    }\n                }\n            }\n        }\n        PluginResult::default()\n    }\n}\nimpl AsDynMacroPlugin for ConfigPlugin {\n    fn as_dyn_macro_plugin<'a>(self: Arc<Self>) -> Arc<dyn MacroPlugin + 'a>\n    where\n        Self: 'a,\n    {\n        self\n    }\n}\nimpl SemanticPlugin for ConfigPlugin {}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse cairo_lang_defs::plugin::{\n    DynGeneratedFileAuxData, MacroPlugin, PluginDiagnostic, PluginGeneratedFile, PluginResult,\n};\nuse cairo_lang_semantic::plugin::{AsDynMacroPlugin, SemanticPlugin, TrivialPluginAuxData};\nuse cairo_lang_syntax::node::ast::AttributeList;\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::{ast, Terminal, TypedSyntaxNode};\n\n#[derive(Debug)]\npub struct DerivePlugin {}\n\nimpl MacroPlugin for DerivePlugin {\n    fn generate_code(&self, db: &dyn SyntaxGroup, item_ast: ast::Item) -> PluginResult {\n        match item_ast {\n            ast::Item::Struct(struct_ast) => {\n                generate_derive_code_for_type(db, struct_ast.name(db), struct_ast.attributes(db))\n            }\n            ast::Item::Enum(enum_ast) => {\n                generate_derive_code_for_type(db, enum_ast.name(db), enum_ast.attributes(db))\n            }\n            ast::Item::ExternType(extern_type_ast) => generate_derive_code_for_type(\n                db,\n                extern_type_ast.name(db),\n                extern_type_ast.attributes(db),\n            ),\n            _ => PluginResult::default(),\n        }\n    }\n}\nimpl AsDynMacroPlugin for DerivePlugin {\n    fn as_dyn_macro_plugin<'a>(self: Arc<Self>) -> Arc<dyn MacroPlugin + 'a>\n    where\n        Self: 'a,\n    {\n        self\n    }\n}\nimpl SemanticPlugin for DerivePlugin {}\n\n/// Adds an implementation for all requested derives for the type.\nfn generate_derive_code_for_type(\n    db: &dyn SyntaxGroup,\n    ident: ast::TerminalIdentifier,\n    attributes: AttributeList,\n) -> PluginResult {\n    let mut diagnostics = vec![];\n    let mut impls = vec![];\n    for attr in attributes.elements(db) {\n        if attr.attr(db).text(db) == \"derive\" {\n            if let ast::OptionAttributeArgs::AttributeArgs(args) = attr.args(db) {\n                for arg in args.arg_list(db).elements(db) {\n                    if let ast::Expr::Path(expr) = arg {\n                        if let [ast::PathSegment::Simple(segment)] = &expr.elements(db)[..] {\n                            let name = ident.text(db);\n                            let derived = segment.ident(db).text(db);\n                            if matches!(derived.as_str(), \"Copy\" | \"Drop\") {\n                                impls.push(format!(\n                                    \"impl {name}{derived} of {derived}::<{name}>;\\n\"\n                                ));\n                            }\n                        } else {\n                            diagnostics.push(PluginDiagnostic {\n                                stable_ptr: expr.stable_ptr().untyped(),\n                                message: \"Expected a single segment.\".into(),\n                            });\n                        }\n                    } else {\n                        diagnostics.push(PluginDiagnostic {\n                            stable_ptr: arg.stable_ptr().untyped(),\n                            message: \"Expected path.\".into(),\n                        });\n                    }\n                }\n            } else {\n                diagnostics.push(PluginDiagnostic {\n                    stable_ptr: attr.args(db).stable_ptr().untyped(),\n                    message: \"Expected args.\".into(),\n                });\n            }\n        }\n    }\n    PluginResult {\n        code: if impls.is_empty() {\n            None\n        } else {\n            Some(PluginGeneratedFile {\n                name: \"impls\".into(),\n                content: impls.join(\"\"),\n                aux_data: DynGeneratedFileAuxData(Arc::new(TrivialPluginAuxData {})),\n            })\n        },\n        diagnostics,\n        remove_original_item: false,\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Cairo core plugin implementations.\nuse std::collections::HashSet;\nuse std::sync::Arc;\n\nuse cairo_lang_semantic::plugin::SemanticPlugin;\n\nuse crate::config::ConfigPlugin;\nuse crate::derive::DerivePlugin;\nuse crate::panicable::PanicablePlugin;\n\npub mod config;\npub mod derive;\npub mod panicable;\n\n#[cfg(test)]\nmod test;\n\n/// Gets the list of default plugins to load into the Cairo compiler.\npub fn get_default_plugins() -> Vec<Arc<dyn SemanticPlugin>> {\n    vec![\n        Arc::new(DerivePlugin {}),\n        Arc::new(PanicablePlugin {}),\n        Arc::new(ConfigPlugin { configs: HashSet::default() }),\n    ]\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse cairo_lang_defs::plugin::{\n    DynGeneratedFileAuxData, MacroPlugin, PluginDiagnostic, PluginGeneratedFile, PluginResult,\n};\nuse cairo_lang_semantic::plugin::{AsDynMacroPlugin, SemanticPlugin, TrivialPluginAuxData};\nuse cairo_lang_syntax::node::ast::AttributeList;\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::{ast, Terminal, TypedSyntaxNode};\nuse cairo_lang_utils::try_extract_matches;\nuse itertools::Itertools;\n\n#[derive(Debug)]\npub struct PanicablePlugin {}\n\nimpl MacroPlugin for PanicablePlugin {\n    fn generate_code(&self, db: &dyn SyntaxGroup, item_ast: ast::Item) -> PluginResult {\n        let (declaration, attributes) = match item_ast {\n            ast::Item::ExternFunction(extern_func_ast) => {\n                (extern_func_ast.declaration(db), extern_func_ast.attributes(db))\n            }\n            ast::Item::FreeFunction(free_func_ast) => {\n                (free_func_ast.declaration(db), free_func_ast.attributes(db))\n            }\n            _ => return PluginResult::default(),\n        };\n\n        generate_panicable_code(db, declaration, attributes)\n    }\n}\nimpl AsDynMacroPlugin for PanicablePlugin {\n    fn as_dyn_macro_plugin<'a>(self: Arc<Self>) -> Arc<dyn MacroPlugin + 'a>\n    where\n        Self: 'a,\n    {\n        self\n    }\n}\nimpl SemanticPlugin for PanicablePlugin {}\n\n/// Adds an implementation for all requested derives for the type.\nfn generate_panicable_code(\n    db: &dyn SyntaxGroup,\n    declaration: ast::FunctionDeclaration,\n    attributes: AttributeList,\n) -> PluginResult {\n    let remove_original_item = false;\n    for attr in attributes.elements(db) {\n        if attr.attr(db).text(db) != \"panic_with\" {\n            continue;\n        }\n        let signature = declaration.signature(db);\n        let Some((inner_ty_text, success_variant, failure_variant)) =\n            extract_success_ty_and_variants(db, &signature) else {\n            return PluginResult {\n                code: None,\n                diagnostics: vec![PluginDiagnostic {\n                    stable_ptr: signature.ret_ty(db).stable_ptr().untyped(),\n                    message: \"Currently only wrapping functions returning an Option<T> or \\\n                                Result<T, E>\"\n                        .into(),\n                }],\n                remove_original_item,\n            };\n        };\n\n        let Some((err_value, panicable_name)) = try_extract_matches!(attr.args(db), ast::OptionAttributeArgs::AttributeArgs).and_then(\n            |args| {\n            if let [ast::Expr::ShortString(err_value), ast::Expr::Path(name)] = &args.arg_list(db).elements(db)[..] {\n                if let [ast::PathSegment::Simple(segment)] = &name.elements(db)[..] {\n                    Some((err_value.text(db), segment.ident(db).text(db)))\n                } else {\n                    None\n                }\n            } else {\n                None\n            }\n        }) else {\n            return PluginResult {\n                code: None,\n                diagnostics: vec![PluginDiagnostic {\n                    stable_ptr: attr.stable_ptr().untyped(),\n                    message: \"Failed to extract panic data attribute\".into(),\n                }],\n                remove_original_item,\n            };\n        };\n        let generics_params = declaration.generic_params(db).as_syntax_node().get_text(db);\n\n        let function_name = declaration.name(db).text(db);\n        let params = signature.parameters(db).as_syntax_node().get_text(db);\n        let args = signature\n            .parameters(db)\n            .elements(db)\n            .into_iter()\n            .map(|param| {\n                format!(\n                    \"{}{}\",\n                    if matches!(&param.modifiers(db).elements(db)[..], [ast::Modifier::Ref(_)]) {\n                        \"ref \"\n                    } else {\n                        \"\"\n                    },\n                    param.name(db).as_syntax_node().get_text(db)\n                )\n            })\n            .join(\", \");\n        return PluginResult {\n            code: Some(PluginGeneratedFile {\n                name: \"panicable\".into(),\n                content: indoc::formatdoc!(\n                    r#\"\n                    fn {panicable_name}{generics_params}({params}) -> {inner_ty_text} {{\n                        match {function_name}({args}) {{\n                            {success_variant} (v) => {{\n                                v\n                            }},\n                            {failure_variant} (v) => {{\n                                let mut data = array::array_new::<felt252>();\n                                array::array_append::<felt252>(ref data, {err_value});\n                                panic(data)\n                            }},\n                        }}\n                    }}\n                \"#\n                ),\n                aux_data: DynGeneratedFileAuxData(Arc::new(TrivialPluginAuxData {})),\n            }),\n            diagnostics: vec![],\n            remove_original_item,\n        };\n    }\n    PluginResult::default()\n}\n\n/// Given a function signature, if it returns `Option::<T>` or `Result::<T, E>`, returns T and the\n/// variant match strings. Otherwise, returns None.\nfn extract_success_ty_and_variants(\n    db: &dyn SyntaxGroup,\n    signature: &ast::FunctionSignature,\n) -> Option<(String, String, String)> {\n    let ret_ty_expr =\n        try_extract_matches!(signature.ret_ty(db), ast::OptionReturnTypeClause::ReturnTypeClause)?\n            .ty(db);\n    let ret_ty_path = try_extract_matches!(ret_ty_expr, ast::Expr::Path)?;\n\n    // Currently only wrapping functions returning an Option<T>.\n    let [ast::PathSegment::WithGenericArgs(segment)] = &ret_ty_path.elements(db)[..] else {\n        return None;\n    };\n    let ty = segment.ident(db).text(db);\n    if ty == \"Option\" {\n        let [inner] = &segment.generic_args(db).generic_args(db).elements(db)[..] else { return None; };\n        Some((\n            inner.as_syntax_node().get_text(db),\n            \"Option::Some\".to_owned(),\n            \"Option::None\".to_owned(),\n        ))\n    } else if ty == \"Result\" {\n        let [inner, _err] = &segment.generic_args(db).generic_args(db).elements(db)[..] else { return None; };\n        Some((\n            inner.as_syntax_node().get_text(db),\n            \"Result::Ok\".to_owned(),\n            \"Result::Err\".to_owned(),\n        ))\n    } else {\n        None\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_defs::plugin::{PluginGeneratedFile, PluginResult};\nuse cairo_lang_diagnostics::{format_diagnostics, DiagnosticLocation};\nuse cairo_lang_parser::test_utils::create_virtual_file;\nuse cairo_lang_parser::utils::{get_syntax_file_and_diagnostics, SimpleParserDatabase};\nuse cairo_lang_syntax::node::TypedSyntaxNode;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse pretty_assertions::assert_eq;\n\nuse crate::get_default_plugins;\n\ncairo_lang_test_utils::test_file_test!(\n    expand_plugin,\n    \"src/test_data\",\n    {\n        config: \"config\",\n        derive: \"derive\",\n        panicable: \"panicable\",\n    },\n    test_expand_plugin\n);\n\npub fn test_expand_plugin(\n    inputs: &OrderedHashMap<String, String>,\n) -> OrderedHashMap<String, String> {\n    let db = &mut SimpleParserDatabase::default();\n    let cairo_code = &inputs[\"cairo_code\"];\n    let file_id = create_virtual_file(db, \"dummy_file.cairo\", cairo_code);\n\n    let (syntax_file, diagnostics) = get_syntax_file_and_diagnostics(db, file_id, cairo_code);\n    assert_eq!(diagnostics.format(db), \"\");\n    let file_syntax_node = syntax_file.as_syntax_node();\n    let plugins = get_default_plugins();\n    let mut generated_items: Vec<String> = Vec::new();\n    let mut diagnostic_items: Vec<String> = Vec::new();\n    for item in syntax_file.items(db).elements(db).into_iter() {\n        for plugin in &plugins {\n            let PluginResult { code, diagnostics, remove_original_item } =\n                plugin.clone().as_dyn_macro_plugin().generate_code(db, item.clone());\n\n            diagnostic_items.extend(diagnostics.iter().map(|diag| {\n                let syntax_node = file_syntax_node.lookup_ptr(db, diag.stable_ptr);\n\n                let location =\n                    DiagnosticLocation { file_id, span: syntax_node.span_without_trivia(db) };\n                format_diagnostics(db, &diag.message, location)\n            }));\n\n            let content = match code {\n                Some(PluginGeneratedFile { content, .. }) => content,\n                None => continue,\n            };\n            if !remove_original_item {\n                generated_items.push(item.as_syntax_node().get_text(db));\n            }\n            generated_items.push(content);\n        }\n    }\n\n    OrderedHashMap::from([\n        (\"generated_cairo_code\".into(), generated_items.join(\"\\n\")),\n        (\"expected_diagnostics\".into(), diagnostic_items.join(\"\\n\")),\n    ])\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Procedural macros.\nuse proc_macro::TokenStream;\nuse quote::__private::{Span, TokenStream as TokenStream2};\nuse quote::quote;\nuse syn::{parse_macro_input, DeriveInput};\n\n/// Derives a [`cairo_lang_debug::DebugWithDb`] implementation for structs and enums.\npub fn derive_debug_with_db(input: TokenStream) -> TokenStream {\n    // Parse the input tokens into a syntax tree.\n    let input = parse_macro_input!(input as DeriveInput);\n    let attribute = input\n        .attrs\n        .iter()\n        .find(|a| a.path.segments.len() == 1 && a.path.segments[0].ident == \"debug_db\")\n        .expect(\"debug_db attribute required for deriving DebugWithDB.\");\n    let db: syn::Type = syn::parse2(attribute.tokens.clone()).expect(\"Invalid debug_db attribute!\");\n    let db = if let syn::Type::Paren(db) = db { db } else { panic!(\"Expected parenthesis\") };\n    let db = quote! {(#db)};\n    let name = input.ident;\n    // TODO(yuval/shahar): extract the lifetime here and use it instead of `'a` below.\n    let body = match input.data {\n        syn::Data::Struct(structure) => emit_struct_debug(name, db, structure),\n        syn::Data::Enum(enm) => emit_enum_debug(name, db, enm),\n        syn::Data::Union(_) => panic!(\"Unions are not supported\"),\n    };\n    quote! {\n        #[allow(unused_parens)]\n        #body\n    }\n    .into()\n}\n\n/// Emits a DebugWithDb implementation for a struct.\nfn emit_struct_debug(\n    name: syn::Ident,\n    db: TokenStream2,\n    structure: syn::DataStruct,\n) -> TokenStream2 {\n    let (pattern, field_prints) = emit_fields_debug(db.clone(), name.to_string(), structure.fields);\n    let crt = debug_crate();\n    quote! {\n        impl<'a, T: ?Sized + cairo_lang_utils::Upcast<#db>> #crt::debug::DebugWithDb<T> for #name {\n            fn fmt(&self, f: &mut std::fmt::Formatter<'_>, other_db: &T) -> std::fmt::Result {\n                use #crt::debug::DebugWithDb;\n                use #crt::debug::helper::Fallback;\n                let #name #pattern = self;\n                let db: &#db = other_db.upcast();\n                #field_prints\n            }\n        }\n    }\n}\n\n/// Emits a DebugWithDb implementation for an enum.\nfn emit_enum_debug(name: syn::Ident, db: TokenStream2, enm: syn::DataEnum) -> TokenStream2 {\n    let mut variant_prints = quote! {};\n    for variant in enm.variants {\n        let variant_name = variant.ident;\n        let (pattern, field_prints) =\n            emit_fields_debug(db.clone(), variant_name.to_string(), variant.fields);\n        variant_prints = quote! {\n            #variant_prints\n            #name :: #variant_name #pattern => {\n                #field_prints\n            }\n        }\n    }\n    let crt = debug_crate();\n    quote! {\n        impl<'a, T: ?Sized + cairo_lang_utils::Upcast<#db>> #crt::debug::DebugWithDb<T> for #name {\n            fn fmt(&self, f: &mut std::fmt::Formatter<'_>, other_db: &T) -> std::fmt::Result {\n                use #crt::debug::DebugWithDb;\n                use #crt::debug::helper::Fallback;\n                let db: &#db = other_db.upcast();\n                match self {\n                    #variant_prints\n                }\n            }\n        }\n    }\n}\n\n/// Helper function for emit_struct_debug and emit_enum_debug. Both struct, and a variant use\n/// a type called [syn::Fields].\n/// This function builds and returns an unpacking pattern and code for `fmt()` on these fields.\nfn emit_fields_debug(\n    db: TokenStream2,\n    name: String,\n    fields: syn::Fields,\n) -> (TokenStream2, TokenStream2) {\n    let crt = debug_crate();\n    let mut pattern = quote! {};\n    let mut field_prints = quote! {};\n    for (i, field) in fields.iter().enumerate() {\n        let has_hide_attr = field.attrs.iter().any(|a| {\n            a.path.segments.len() == 1 && a.path.segments[0].ident == \"hide_field_debug_with_db\"\n        });\n\n        let ty = &field.ty;\n\n        if has_hide_attr {\n            if let Some(field_ident) = &field.ident {\n                let ignore_name = syn::Ident::new(&format!(\"_{field_ident}\"), Span::call_site());\n                pattern = quote! { #pattern #field_ident: #ignore_name, };\n            } else {\n                panic!(\"Hiding unnamed fields is not implemented.\");\n            }\n        } else {\n            let field_ident = field\n                .ident\n                .clone()\n                .unwrap_or_else(|| syn::Ident::new(&format!(\"v{i}\"), Span::call_site()));\n            pattern = quote! { #pattern #field_ident, };\n            let func_call = quote! {\n                &#crt::debug::helper::HelperDebug::<#ty, #db>::helper_debug(#field_ident, db)\n            };\n            if let Some(field_ident) = &field.ident {\n                field_prints = quote! {\n                    #field_prints\n                    .field(stringify!(#field_ident), #func_call)\n                }\n            } else {\n                field_prints = quote! {\n                    #field_prints\n                    .field(#func_call)\n                }\n            }\n        }\n    }\n    match fields {\n        syn::Fields::Named(_) => {\n            pattern = quote! { { #pattern } };\n            field_prints = quote! { f.debug_struct(#name) #field_prints .finish() };\n        }\n        syn::Fields::Unnamed(_) => {\n            pattern = quote! { ( #pattern ) };\n            field_prints = quote! { f.debug_tuple(#name) #field_prints .finish() };\n        }\n        syn::Fields::Unit => {\n            pattern = quote! {};\n            field_prints = quote! { f.debug_tuple(#name).finish() };\n        }\n    };\n    (pattern, field_prints)\n}\n\n/// Returns the identifier of the debug crate. This is needed, since inside the debug\n/// crate, it needs to be referred to as `crate` and no `debug`.\nfn debug_crate() -> syn::Ident {\n    let crate_name = std::env::var(\"CARGO_PKG_NAME\").unwrap();\n    let res = if crate_name == \"cairo-lang-debug\" { \"crate\" } else { \"cairo_lang_debug\" };\n    syn::Ident::new(res, Span::call_site())\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use proc_macro::TokenStream;\n\nmod debug;\nmod rewriter;\n\n#[proc_macro_derive(DebugWithDb, attributes(debug_db, hide_field_debug_with_db))]\npub fn derive_debug_with_db(input: TokenStream) -> TokenStream {\n    debug::derive_debug_with_db(input)\n}\n\n#[proc_macro_derive(SemanticObject, attributes(dont_rewrite))]\npub fn derive_semantic_object(input: TokenStream) -> TokenStream {\n    rewriter::derive_semantic_object(input)\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Procedural macros.\nuse proc_macro::TokenStream;\nuse quote::__private::{Span, TokenStream as TokenStream2};\nuse quote::quote;\nuse syn::{parse_macro_input, DeriveInput};\n\n/// Derives a SemanticObject implementation for structs and enums.\npub fn derive_semantic_object(input: TokenStream) -> TokenStream {\n    // Parse the input tokens into a syntax tree.\n    let input = parse_macro_input!(input as DeriveInput);\n    let name = input.ident;\n    // TODO(yuval/shahar): extract the lifetime here and use it instead of `'a` below.\n    let body = match input.data {\n        syn::Data::Struct(structure) => emit_struct_semantic_object(name, structure),\n        syn::Data::Enum(enm) => emit_enum_semantic_object(name, enm),\n        syn::Data::Union(_) => panic!(\"Unions are not supported\"),\n    };\n    quote! {\n        #[allow(unused_parens)]\n        #body\n    }\n    .into()\n}\n\n/// Emits a SemanticObject implementation for a struct.\nfn emit_struct_semantic_object(name: syn::Ident, structure: syn::DataStruct) -> TokenStream2 {\n    let (deps, pattern, field_rewrites) = emit_fields_semantic_object(structure.fields);\n    let crt = semantic_crate();\n    quote! {\n        impl<T:#deps, Error> #crt::SemanticObject<T, Error> for #name {\n            fn default_rewrite(self, rewriter: &mut T) -> Result<Self, Error> {\n                let #name #pattern = self;\n                Ok(#name #field_rewrites)\n            }\n        }\n    }\n}\n\n/// Emits a SemanticObject implementation for an enum.\nfn emit_enum_semantic_object(name: syn::Ident, enm: syn::DataEnum) -> TokenStream2 {\n    let mut variant_rewrites = quote! {};\n    let mut deps = quote! {};\n    for variant in enm.variants {\n        let variant_name = variant.ident;\n        let (current_deps, pattern, field_rewrites) = emit_fields_semantic_object(variant.fields);\n        deps = quote! {#deps #current_deps};\n        variant_rewrites = quote! {\n            #variant_rewrites\n            #name :: #variant_name #pattern => {\n                #name :: #variant_name #field_rewrites\n            }\n        }\n    }\n    let crt = semantic_crate();\n    quote! {\n        impl<T:#deps, Error> #crt::SemanticObject<T, Error> for #name {\n            fn default_rewrite(self, rewriter: &mut T) -> Result<Self, Error> {\n                Ok(match self {\n                    #variant_rewrites\n                })\n            }\n        }\n    }\n}\n\n/// Helper function for emit_struct_semantic_object and emit_enum_semantic_object. Both struct, and\n/// a variant use a type called [syn::Fields].\n/// This function builds and returns an unpacking pattern and code for `fmt()` on these fields.\nfn emit_fields_semantic_object(fields: syn::Fields) -> (TokenStream2, TokenStream2, TokenStream2) {\n    let mut pattern = quote! {};\n    let mut field_rewrites = quote! {};\n    let mut deps = quote! {};\n    for (i, field) in fields.iter().enumerate() {\n        let field_ident = field\n            .ident\n            .clone()\n            .unwrap_or_else(|| syn::Ident::new(&format!(\"v{i}\"), Span::call_site()));\n        pattern = quote! { #pattern #field_ident, };\n\n        let has_dont_rewrite_attr = field\n            .attrs\n            .iter()\n            .any(|a| a.path.segments.len() == 1 && a.path.segments[0].ident == \"dont_rewrite\");\n        let rewrite_expr = if has_dont_rewrite_attr {\n            quote! { #field_ident }\n        } else {\n            emit_expr_for_ty(&mut deps, quote! {#field_ident}, &field.ty)\n        };\n        if let Some(field_ident) = &field.ident {\n            field_rewrites = quote! {\n                #field_rewrites\n                #field_ident: #rewrite_expr,\n            }\n        } else {\n            field_rewrites = quote! {\n                #field_rewrites\n                #rewrite_expr,\n            }\n        }\n    }\n    match fields {\n        syn::Fields::Named(_) => {\n            pattern = quote! { { #pattern } };\n            field_rewrites = quote! { { #field_rewrites } };\n        }\n        syn::Fields::Unnamed(_) => {\n            pattern = quote! { ( #pattern ) };\n            field_rewrites = quote! { ( #field_rewrites ) };\n        }\n        syn::Fields::Unit => {\n            pattern = quote! {};\n            field_rewrites = quote! {};\n        }\n    };\n    (deps, pattern, field_rewrites)\n}\n\nfn emit_expr_for_ty(deps: &mut TokenStream2, item: TokenStream2, ty: &syn::Type) -> TokenStream2 {\n    let crt = semantic_crate();\n    *deps = quote! { #deps #crt::substitution::SemanticRewriter<#ty, Error> + };\n    quote! {\n        #crt::substitution::SemanticRewriter::<#ty, Error>::rewrite(rewriter, #item)?\n    }\n}\n\n/// Returns the identifier of the semantic crate. This is needed, since inside the semantic\n/// crate, it needs to be referred to as `crate` and no `semantic`.\nfn semantic_crate() -> syn::Ident {\n    let crate_name = std::env::var(\"CARGO_PKG_NAME\").unwrap();\n    let res = if crate_name == \"cairo-lang-semantic\" { \"crate\" } else { \"cairo_lang_semantic\" };\n    syn::Ident::new(res, Span::call_site())\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Cairo project specification. For example, crates and flags used for compilation.\n#[cfg(test)]\nmod test;\n\nuse std::collections::HashMap;\nuse std::path::{Path, PathBuf};\n\nuse cairo_lang_filesystem::ids::Directory;\nuse serde::{Deserialize, Serialize};\nuse smol_str::SmolStr;\n\n#[derive(thiserror::Error, Debug)]\npub enum DeserializationError {\n    #[error(transparent)]\n    TomlError(#[from] toml::de::Error),\n    #[error(transparent)]\n    IoError(#[from] std::io::Error),\n    #[error(\"PathError\")]\n    PathError,\n}\nconst PROJECT_FILE_NAME: &str = \"cairo_project.toml\";\n\n/// Cairo project config, including its file content and metadata about the file.\n/// This file is expected to be at a root of a crate and specify the crate name and location and\n/// of its dependency crates.\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct ProjectConfig {\n    pub base_path: PathBuf,\n    pub corelib: Option<Directory>,\n    pub content: ProjectConfigContent,\n}\n/// Contents of a Cairo project config file.\n#[derive(Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]\npub struct ProjectConfigContent {\n    pub crate_roots: HashMap<SmolStr, PathBuf>,\n}\n\nimpl ProjectConfig {\n    pub fn from_directory(directory: &Path) -> Result<Self, DeserializationError> {\n        Self::from_file(&directory.join(PROJECT_FILE_NAME))\n    }\n    pub fn from_file(filename: &Path) -> Result<Self, DeserializationError> {\n        let base_path = filename\n            .parent()\n            .and_then(|p| p.to_str())\n            .ok_or(DeserializationError::PathError)?\n            .into();\n        let content = toml::from_str(&std::fs::read_to_string(filename)?)?;\n        Ok(ProjectConfig { base_path, content, corelib: None })\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use indoc::indoc;\n\nuse crate::ProjectConfigContent;\n\n#[test]\nfn test_serde() {\n    let config = ProjectConfigContent {\n        crate_roots: [(\"crate\".into(), \"dir\".into())].into_iter().collect(),\n    };\n    let serialized = toml::to_string(&config).unwrap();\n    assert_eq!(\n        serialized,\n        indoc! { r#\"\n            [crate_roots]\n            crate = \"dir\"\n        \"# }\n    );\n    assert_eq!(config, toml::from_str(&serialized).unwrap());\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashMap;\n\nuse cairo_felt::Felt as Felt252;\nuse cairo_vm::types::relocatable::Relocatable;\nuse cairo_vm::vm::vm_core::VirtualMachine;\n\n/// Stores the data of a specific dictionary.\npub struct DictTrackerExecScope {\n    /// The data of the dictionary.\n    data: HashMap<Felt252, Felt252>,\n    /// The index of the dictionary in the dict_infos segment.\n    #[allow(dead_code)]\n    idx: usize,\n}\n\n/// Helper object to allocate, track and destruct all dictionaries in the run.\n#[derive(Default)]\npub struct DictManagerExecScope {\n    /// Maps between a segment index and the DictTrackerExecScope associated with it.\n    trackers: HashMap<isize, DictTrackerExecScope>,\n}\n\nimpl DictTrackerExecScope {\n    /// Creates a new tracker placed in index `idx` in the dict_infos segment.\n    pub fn new(idx: usize) -> Self {\n        Self { data: HashMap::default(), idx }\n    }\n}\n\nimpl DictManagerExecScope {\n    pub const DICT_DEFAULT_VALUE: usize = 0;\n\n    /// Allocates a new segment for a new dictionary and return the start of the segment.\n    pub fn new_default_dict(&mut self, vm: &mut VirtualMachine) -> Relocatable {\n        let dict_segment = vm.add_memory_segment();\n        assert!(\n            self.trackers\n                .insert(dict_segment.segment_index, DictTrackerExecScope::new(self.trackers.len()))\n                .is_none(),\n            \"Segment index already in use.\"\n        );\n        dict_segment\n    }\n\n    /// Returns a reference for a dict tracker corresponding to a given pointer to a dict segment.\n    fn get_dict_tracker(&self, dict_end: Relocatable) -> &DictTrackerExecScope {\n        self.trackers\n            .get(&dict_end.segment_index)\n            .expect(\"The given value does not point to a known dictionary.\")\n    }\n\n    /// Returns a mut reference for a dict tracker corresponding to a given pointer to a dict\n    /// segment.\n    fn get_dict_tracker_mut(&mut self, dict_end: Relocatable) -> &mut DictTrackerExecScope {\n        self.trackers\n            .get_mut(&dict_end.segment_index)\n            .expect(\"The given value does not point to a known dictionary.\")\n    }\n\n    /// Returns the index of the dict tracker corresponding to a given pointer to a dict segment.\n    pub fn get_dict_infos_index(&self, dict_end: Relocatable) -> usize {\n        self.get_dict_tracker(dict_end).idx\n    }\n\n    /// Inserts a value to the dict tracker corresponding to a given pointer to a dict segment.\n    pub fn insert_to_tracker(&mut self, dict_end: Relocatable, key: Felt252, value: Felt252) {\n        self.get_dict_tracker_mut(dict_end).data.insert(key, value);\n    }\n\n    /// Gets a value from the dict tracker corresponding to a given pointer to a dict segment.\n    /// None if the key does not exist in the tracker data.\n    pub fn get_from_tracker(&self, dict_end: Relocatable, key: &Felt252) -> Option<Felt252> {\n        self.get_dict_tracker(dict_end).data.get(key).cloned()\n    }\n}\n\n/// Helper object for the managment of dict_squash hints.\n#[derive(Default, Debug)]\npub struct DictSquashExecScope {\n    /// A map from key to the list of indices accessing it, each list in reverse order.\n    pub access_indices: HashMap<Felt252, Vec<Felt252>>,\n    /// Descending list of keys.\n    pub keys: Vec<Felt252>,\n}\n\nimpl DictSquashExecScope {\n    /// Returns the current key to process.\n    pub fn current_key(&self) -> Option<Felt252> {\n        self.keys.last().cloned()\n    }\n\n    /// Returns and removes the current key, and its access indices. Should be called when only the\n    /// last key access is in the corresponding indices list.\n    pub fn pop_current_key(&mut self) -> Option<Felt252> {\n        let key_accesses = self.access_indices.remove(&self.current_key().unwrap());\n        assert!(\n            key_accesses.unwrap().len() == 1,\n            \"Key popped but not all accesses were processed.\"\n        );\n        self.keys.pop()\n    }\n\n    /// Returns a reference to the access indices list of the current key.\n    pub fn current_access_indices(&mut self) -> Option<&mut Vec<Felt252>> {\n        let current_key = self.current_key()?;\n        self.access_indices.get_mut(&current_key)\n    }\n\n    /// Returns a reference to the last index in the current access indices list.\n    pub fn current_access_index(&mut self) -> Option<&Felt252> {\n        self.current_access_indices()?.last()\n    }\n\n    /// Returns and removes the current access index.\n    pub fn pop_current_access_index(&mut self) -> Option<Felt252> {\n        self.current_access_indices()?.pop()\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::any::Any;\nuse std::collections::HashMap;\n\nuse ark_ff::fields::{Fp256, MontBackend, MontConfig};\nuse ark_ff::{Field, PrimeField};\nuse ark_std::UniformRand;\nuse cairo_felt::{self as felt, felt_str as felt252_str, Felt as Felt252, PRIME_STR};\nuse cairo_lang_casm::hints::Hint;\nuse cairo_lang_casm::instructions::Instruction;\nuse cairo_lang_casm::operand::{\n    BinOpOperand, CellRef, DerefOrImmediate, Operation, Register, ResOperand,\n};\nuse cairo_lang_utils::extract_matches;\nuse cairo_vm::hint_processor::hint_processor_definition::{HintProcessor, HintReference};\nuse cairo_vm::serde::deserialize_program::{\n    ApTracking, FlowTrackingData, HintParams, ReferenceManager,\n};\nuse cairo_vm::types::exec_scope::ExecutionScopes;\nuse cairo_vm::types::program::Program;\nuse cairo_vm::types::relocatable::{MaybeRelocatable, Relocatable};\nuse cairo_vm::vm::errors::hint_errors::HintError;\nuse cairo_vm::vm::errors::vm_errors::VirtualMachineError;\nuse cairo_vm::vm::runners::cairo_runner::CairoRunner;\nuse cairo_vm::vm::vm_core::VirtualMachine;\nuse dict_manager::DictManagerExecScope;\nuse num_bigint::BigUint;\nuse num_traits::{FromPrimitive, ToPrimitive, Zero};\n\nuse self::dict_manager::DictSquashExecScope;\nuse crate::short_string::as_cairo_short_string;\n\n#[cfg(test)]\nmod test;\n\nmod dict_manager;\n\n// TODO(orizi): This def is duplicated.\n/// Returns the Beta value of the Starkware elliptic curve.\nfn get_beta() -> Felt252 {\n    felt252_str!(\"3141592653589793238462643383279502884197169399375105820974944592307816406665\")\n}\n\n#[derive(MontConfig)]\n#[modulus = \"3618502788666131213697322783095070105623107215331596699973092056135872020481\"]\n#[generator = \"3\"]\nstruct FqConfig;\ntype Fq = Fp256<MontBackend<FqConfig, 4>>;\n\n/// Convert a Hint to the cairo-vm class HintParams by canonically serializing it to a string.\nfn hint_to_hint_params(hint: &Hint) -> HintParams {\n    HintParams {\n        code: hint.to_string(),\n        accessible_scopes: vec![],\n        flow_tracking_data: FlowTrackingData {\n            ap_tracking: ApTracking::new(),\n            reference_ids: HashMap::new(),\n        },\n    }\n}\n\n/// HintProcessor for Cairo compiler hints.\nstruct CairoHintProcessor {\n    // A dict from instruction offset to hint vector.\n    pub hints_dict: HashMap<usize, Vec<HintParams>>,\n    // A mapping from a string that represents a hint to the hint object.\n    pub string_to_hint: HashMap<String, Hint>,\n}\n\nimpl CairoHintProcessor {\n    pub fn new<'a, Instructions: Iterator<Item = &'a Instruction> + Clone>(\n        instructions: Instructions,\n    ) -> Self {\n        let mut hints_dict: HashMap<usize, Vec<HintParams>> = HashMap::new();\n        let mut string_to_hint: HashMap<String, Hint> = HashMap::new();\n\n        let mut hint_offset = 0;\n\n        for instruction in instructions {\n            if !instruction.hints.is_empty() {\n                // Register hint with string for the hint processor.\n                for hint in instruction.hints.iter() {\n                    string_to_hint.insert(hint.to_string(), hint.clone());\n                }\n                // Add hint, associated with the instruction offset.\n                hints_dict.insert(\n                    hint_offset,\n                    instruction.hints.iter().map(hint_to_hint_params).collect(),\n                );\n            }\n            hint_offset += instruction.body.op_size();\n        }\n        CairoHintProcessor { hints_dict, string_to_hint }\n    }\n}\n\nfn cell_ref_to_relocatable(cell_ref: &CellRef, vm: &VirtualMachine) -> Relocatable {\n    let base = match cell_ref.register {\n        Register::AP => vm.get_ap(),\n        Register::FP => vm.get_fp(),\n    };\n    base + (cell_ref.offset as i32)\n}\n\n/// Inserts a value into the vm memory cell represented by the cellref.\nmacro_rules! insert_value_to_cellref {\n    ($vm:ident, $cell_ref:ident, $value:expr) => {\n        $vm.insert_value(&cell_ref_to_relocatable($cell_ref, $vm), $value)\n    };\n}\n\n/// Execution scope for starknet related data.\n/// All values will be 0 and by default if not setup by the test.\nstruct StarknetExecScope {\n    /// The values of addresses in the simulated storage per contract.\n    storage: HashMap<Felt252, HashMap<Felt252, Felt252>>,\n    /// The simulated execution info.\n    exec_info: ExecutionInfo,\n}\n\n/// Copy of the cairo `ExecutionInfo` struct.\n#[derive(Default)]\nstruct ExecutionInfo {\n    block_info: BlockInfo,\n    tx_info: TxInfo,\n    caller_address: Felt252,\n    contract_address: Felt252,\n}\n\n/// Copy of the cairo `BlockInfo` struct.\n#[derive(Default)]\nstruct BlockInfo {\n    block_number: Felt252,\n    block_timestamp: Felt252,\n    sequencer_address: Felt252,\n}\n\n/// Copy of the cairo `TxInfo` struct.\n#[derive(Default)]\nstruct TxInfo {\n    version: Felt252,\n    account_contract_address: Felt252,\n    max_fee: Felt252,\n    signature: Vec<Felt252>,\n    transaction_hash: Felt252,\n    chain_id: Felt252,\n    nonce: Felt252,\n}\n/// Execution scope for constant memory allocation.\nstruct MemoryExecScope {\n    /// The first free address in the segment.\n    next_address: Relocatable,\n}\n\n/// Fetches the value of a cell from the vm.\nfn get_cell_val(vm: &VirtualMachine, cell: &CellRef) -> Result<Felt252, VirtualMachineError> {\n    Ok(vm.get_integer(&cell_ref_to_relocatable(cell, vm))?.as_ref().clone())\n}\n\n/// Fetches the value of a cell plus an offset from the vm, useful for pointers.\nfn get_ptr(\n    vm: &VirtualMachine,\n    cell: &CellRef,\n    offset: &Felt252,\n) -> Result<Relocatable, VirtualMachineError> {\n    let base_ptr = vm.get_relocatable(&cell_ref_to_relocatable(cell, vm))?;\n    base_ptr.add_int(offset)\n}\n\n/// Fetches the value of a pointer described by the value at `cell` plus an offset from the vm.\nfn get_double_deref_val(\n    vm: &VirtualMachine,\n    cell: &CellRef,\n    offset: &Felt252,\n) -> Result<Felt252, VirtualMachineError> {\n    Ok(vm.get_integer(&get_ptr(vm, cell, offset)?)?.as_ref().clone())\n}\n\n/// Fetches the value of `res_operand` from the vm.\nfn get_val(vm: &VirtualMachine, res_operand: &ResOperand) -> Result<Felt252, VirtualMachineError> {\n    match res_operand {\n        ResOperand::Deref(cell) => get_cell_val(vm, cell),\n        ResOperand::DoubleDeref(cell, offset) => get_double_deref_val(vm, cell, &(*offset).into()),\n        ResOperand::Immediate(x) => Ok(Felt252::from(x.value.clone())),\n        ResOperand::BinOp(op) => {\n            let a = get_cell_val(vm, &op.a)?;\n            let b = match &op.b {\n                DerefOrImmediate::Deref(cell) => get_cell_val(vm, cell)?,\n                DerefOrImmediate::Immediate(x) => Felt252::from(x.value.clone()),\n            };\n            match op.op {\n                Operation::Add => Ok(a + b),\n                Operation::Mul => Ok(a * b),\n            }\n        }\n    }\n}\n\nimpl HintProcessor for CairoHintProcessor {\n    /// Trait function to execute a given hint in the hint processor.\n    fn execute_hint(\n        &mut self,\n        vm: &mut VirtualMachine,\n        exec_scopes: &mut ExecutionScopes,\n        hint_data: &Box<dyn Any>,\n        _constants: &HashMap<String, Felt252>,\n    ) -> Result<(), HintError> {\n        let hint = hint_data.downcast_ref::<Hint>().unwrap();\n        match hint {\n            Hint::AllocSegment { dst } => {\n                let segment = vm.add_memory_segment();\n                insert_value_to_cellref!(vm, dst, segment)?;\n            }\n            Hint::TestLessThan { lhs, rhs, dst } => {\n                let lhs_val = get_val(vm, lhs)?;\n                let rhs_val = get_val(vm, rhs)?;\n                insert_value_to_cellref!(\n                    vm,\n                    dst,\n                    if lhs_val < rhs_val { Felt252::from(1) } else { Felt252::from(0) }\n                )?;\n            }\n            Hint::TestLessThanOrEqual { lhs, rhs, dst } => {\n                let lhs_val = get_val(vm, lhs)?;\n                let rhs_val = get_val(vm, rhs)?;\n                insert_value_to_cellref!(\n                    vm,\n                    dst,\n                    if lhs_val <= rhs_val { Felt252::from(1) } else { Felt252::from(0) }\n                )?;\n            }\n            Hint::DivMod { lhs, rhs, quotient, remainder } => {\n                let lhs_val = get_val(vm, lhs)?.to_biguint();\n                let rhs_val = get_val(vm, rhs)?.to_biguint();\n                insert_value_to_cellref!(\n                    vm,\n                    quotient,\n                    Felt252::from(lhs_val.clone() / rhs_val.clone())\n                )?;\n                insert_value_to_cellref!(vm, remainder, Felt252::from(lhs_val % rhs_val))?;\n            }\n            Hint::SquareRoot { value, dst } => {\n                let val = get_val(vm, value)?.to_biguint();\n                insert_value_to_cellref!(vm, dst, Felt252::from(val.sqrt()))?;\n            }\n            Hint::LinearSplit { value, scalar, max_x, x, y } => {\n                let value = get_val(vm, value)?.to_biguint();\n                let scalar = get_val(vm, scalar)?.to_biguint();\n                let max_x = get_val(vm, max_x)?.to_biguint();\n                let x_value = (value.clone() / scalar.clone()).min(max_x);\n                let y_value = value - x_value.clone() * scalar;\n                insert_value_to_cellref!(vm, x, Felt252::from(x_value))?;\n                insert_value_to_cellref!(vm, y, Felt252::from(y_value))?;\n            }\n            Hint::RandomEcPoint { x, y } => {\n                // Keep sampling a random field element `X` until `X^3 + X + beta` is a quadratic\n                // residue.\n                let beta = Fq::from(get_beta().to_biguint());\n                let mut rng = ark_std::test_rng();\n                let (random_x, random_y_squared) = loop {\n                    let random_x = Fq::rand(&mut rng);\n                    let random_y_squared = random_x * random_x * random_x + random_x + beta;\n                    if random_y_squared.legendre().is_qr() {\n                        break (random_x, random_y_squared);\n                    }\n                };\n                let x_bigint: BigUint = random_x.into_bigint().into();\n                let y_bigint: BigUint = random_y_squared.sqrt().unwrap().into_bigint().into();\n                insert_value_to_cellref!(vm, x, Felt252::from(x_bigint))?;\n                insert_value_to_cellref!(vm, y, Felt252::from(y_bigint))?;\n            }\n            Hint::FieldSqrt { val, sqrt } => {\n                let val = Fq::from(get_val(vm, val)?.to_biguint());\n                insert_value_to_cellref!(vm, sqrt, {\n                    let three_fq = Fq::from(BigUint::from_usize(3).unwrap());\n                    let res = (if val.legendre().is_qr() { val } else { val * three_fq }).sqrt();\n                    let res_big_uint: BigUint = res.unwrap().into_bigint().into();\n                    Felt252::from(res_big_uint)\n                })?;\n            }\n            Hint::SystemCall { system } => {\n                let starknet_exec_scope = starknet_execution_scope(exec_scopes)?;\n                let (cell, base_offset) = extract_buffer(system);\n                let selector = get_double_deref_val(vm, cell, &base_offset)?.to_bytes_be();\n                // Given `res_offset` as the offset in the system ptr where the result begins,\n                // `cost` as the cost of the function and a `handler` which actually implements the\n                // syscall, changes the vm status and writes the system buffer in case of success\n                // and may also return a revert reason if additional checks failed. Runs the\n                // simulation including gas checks and revert reasons.\n                let mut check_handle_oog =\n                    |res_offset: u32,\n                     cost: usize,\n                     handler: &mut dyn FnMut(\n                        &mut VirtualMachine,\n                    )\n                        -> Result<Option<Felt252>, HintError>|\n                     -> Result<(), HintError> {\n                        let gas_counter =\n                            get_double_deref_val(vm, cell, &(base_offset.clone() + 1u32))?;\n                        let gas_counter_updated_ptr =\n                            get_ptr(vm, cell, &(base_offset.clone() + res_offset))?;\n                        let failure_flag_ptr =\n                            get_ptr(vm, cell, &(base_offset.clone() + (res_offset + 1)))?;\n                        let revert_reason = if gas_counter < cost.into() {\n                            Felt252::from_bytes_be(b\"Syscall out of gas\")\n                        } else if let Some(revert_reason) = handler(vm)? {\n                            revert_reason\n                        } else {\n                            vm.insert_value(&gas_counter_updated_ptr, gas_counter - cost)?;\n                            vm.insert_value(&failure_flag_ptr, Felt252::from(0))?;\n                            return Ok(());\n                        };\n                        vm.insert_value(&gas_counter_updated_ptr, gas_counter)?;\n                        vm.insert_value(&failure_flag_ptr, Felt252::from(1))?;\n                        let revert_reason_start = vm.add_memory_segment();\n                        vm.insert_value(&revert_reason_start, revert_reason)?;\n                        let revert_reason_end = revert_reason_start + 1;\n                        let revert_reason_start_ptr =\n                            get_ptr(vm, cell, &(base_offset.clone() + (res_offset + 2)))?;\n                        vm.insert_value(&revert_reason_start_ptr, revert_reason_start)?;\n                        let revert_reason_end_ptr =\n                            get_ptr(vm, cell, &(base_offset.clone() + (res_offset + 3)))?;\n                        vm.insert_value(&revert_reason_end_ptr, revert_reason_end)?;\n                        Ok(())\n                    };\n                if selector == \"StorageWrite\".as_bytes() {\n                    check_handle_oog(5, 1000, &mut |vm| {\n                        let addr_domain =\n                            get_double_deref_val(vm, cell, &(base_offset.clone() + 2u32))?;\n                        if !addr_domain.is_zero() {\n                            // Only address_domain 0 is currently supported.\n                            return Ok(Some(Felt252::from_bytes_be(b\"Unsupported address domain\")));\n                        }\n                        let addr = get_double_deref_val(vm, cell, &(base_offset.clone() + 3u32))?;\n                        let value = get_double_deref_val(vm, cell, &(base_offset.clone() + 4u32))?;\n                        let contract = starknet_exec_scope.exec_info.contract_address.clone();\n                        starknet_exec_scope\n                            .storage\n                            .entry(contract)\n                            .or_default()\n                            .insert(addr, value);\n                        Ok(None)\n                    })?;\n                } else if selector == \"StorageRead\".as_bytes() {\n                    check_handle_oog(4, 100, &mut |vm| {\n                        let addr_domain =\n                            get_double_deref_val(vm, cell, &(base_offset.clone() + 2u32))?;\n                        if !addr_domain.is_zero() {\n                            // Only address_domain 0 is currently supported.\n                            return Ok(Some(Felt252::from_bytes_be(b\"Unsupported address domain\")));\n                        }\n                        let addr = get_double_deref_val(vm, cell, &(base_offset.clone() + 3u32))?;\n                        let value = starknet_exec_scope\n                            .storage\n                            .get(&starknet_exec_scope.exec_info.contract_address)\n                            .and_then(|contract_storage| contract_storage.get(&addr))\n                            .cloned()\n                            .unwrap_or_else(|| Felt252::from(0));\n                        let result_ptr = get_ptr(vm, cell, &(base_offset.clone() + 6u32))?;\n                        vm.insert_value(&result_ptr, value)?;\n                        Ok(None)\n                    })?;\n                } else if selector == \"GetExecutionInfo\".as_bytes() {\n                    check_handle_oog(2, 50, &mut |vm| {\n                        let result_ptr = get_ptr(vm, cell, &(base_offset.clone() + 4u32))?;\n                        let exec_info = &starknet_exec_scope.exec_info;\n                        let block_info = &exec_info.block_info;\n                        let tx_info = &exec_info.tx_info;\n                        let mut res_segment = vm.add_memory_segment();\n                        let signature_start = res_segment;\n                        for val in &tx_info.signature {\n                            vm.insert_value(&res_segment, val)?;\n                            res_segment.offset += 1;\n                        }\n                        let signature_end = res_segment;\n                        let tx_info_ptr = res_segment;\n                        vm.insert_value(&(tx_info_ptr + 0), &tx_info.version)?;\n                        vm.insert_value(&(tx_info_ptr + 1), &tx_info.account_contract_address)?;\n                        vm.insert_value(&(tx_info_ptr + 2), &tx_info.max_fee)?;\n                        vm.insert_value(&(tx_info_ptr + 3), signature_start)?;\n                        vm.insert_value(&(tx_info_ptr + 4), signature_end)?;\n                        vm.insert_value(&(tx_info_ptr + 5), &tx_info.transaction_hash)?;\n                        vm.insert_value(&(tx_info_ptr + 6), &tx_info.chain_id)?;\n                        vm.insert_value(&(tx_info_ptr + 7), &tx_info.nonce)?;\n                        res_segment.offset += 8;\n                        let block_info_ptr = res_segment;\n                        vm.insert_value(&(block_info_ptr + 0), &block_info.block_number)?;\n                        vm.insert_value(&(block_info_ptr + 1), &block_info.block_timestamp)?;\n                        vm.insert_value(&(block_info_ptr + 2), &block_info.sequencer_address)?;\n                        res_segment.offset += 3;\n                        let exec_info_ptr = res_segment;\n                        vm.insert_value(&(exec_info_ptr + 0), block_info_ptr)?;\n                        vm.insert_value(&(exec_info_ptr + 1), tx_info_ptr)?;\n                        vm.insert_value(&(exec_info_ptr + 2), &exec_info.caller_address)?;\n                        vm.insert_value(&(exec_info_ptr + 3), &exec_info.contract_address)?;\n                        res_segment.offset += 4;\n                        vm.insert_value(&result_ptr, exec_info_ptr)?;\n                        Ok(None)\n                    })?;\n                } else if selector == \"EmitEvent\".as_bytes() {\n                    check_handle_oog(6, 50, &mut |vm| {\n                        let _keys_start_ptr = get_ptr(vm, cell, &(base_offset.clone() + 2u32))?;\n                        let _keys_end_ptr = get_ptr(vm, cell, &(base_offset.clone() + 3u32))?;\n                        let _values_start_ptr = get_ptr(vm, cell, &(base_offset.clone() + 4u32))?;\n                        let _values_end_ptr = get_ptr(vm, cell, &(base_offset.clone() + 5u32))?;\n                        Ok(None)\n                    })?;\n                } else if selector == \"CallContract\".as_bytes() {\n                    todo!()\n                } else {\n                    panic!(\"Unknown selector for system call!\");\n                }\n            }\n            Hint::SetBlockNumber { value } => {\n                starknet_execution_scope(exec_scopes)?.exec_info.block_info.block_number =\n                    get_val(vm, value)?;\n            }\n            Hint::SetSequencerAddress { value } => {\n                starknet_execution_scope(exec_scopes)?.exec_info.block_info.sequencer_address =\n                    get_val(vm, value)?;\n            }\n            Hint::SetBlockTimestamp { value } => {\n                starknet_execution_scope(exec_scopes)?.exec_info.block_info.block_timestamp =\n                    get_val(vm, value)?;\n            }\n            Hint::SetCallerAddress { value } => {\n                starknet_execution_scope(exec_scopes)?.exec_info.caller_address =\n                    get_val(vm, value)?;\n            }\n            Hint::SetContractAddress { value } => {\n                starknet_execution_scope(exec_scopes)?.exec_info.contract_address =\n                    get_val(vm, value)?;\n            }\n            Hint::AllocFelt252Dict { segment_arena_ptr } => {\n                let (cell, base_offset) = extract_buffer(segment_arena_ptr);\n                let dict_manager_address = get_ptr(vm, cell, &base_offset)?;\n                let n_dicts = vm\n                    .get_integer(&(dict_manager_address + (-2)))?\n                    .into_owned()\n                    .to_usize()\n                    .expect(\"Number of dictionaries too large.\");\n                let dict_infos_base = vm.get_relocatable(&(dict_manager_address + (-3)))?;\n\n                let dict_manager_exec_scope = match exec_scopes\n                    .get_mut_ref::<DictManagerExecScope>(\"dict_manager_exec_scope\")\n                {\n                    Ok(dict_manager_exec_scope) => dict_manager_exec_scope,\n                    Err(_) => {\n                        exec_scopes.assign_or_update_variable(\n                            \"dict_manager_exec_scope\",\n                            Box::<DictManagerExecScope>::default(),\n                        );\n                        exec_scopes\n                            .get_mut_ref::<DictManagerExecScope>(\"dict_manager_exec_scope\")?\n                    }\n                };\n                let new_dict_segment = dict_manager_exec_scope.new_default_dict(vm);\n                vm.insert_value(&(dict_infos_base + 3 * n_dicts), new_dict_segment)?;\n            }\n            Hint::Felt252DictRead { dict_ptr, key, value_dst } => {\n                let (dict_base, dict_offset) = extract_buffer(dict_ptr);\n                let dict_address = get_ptr(vm, dict_base, &dict_offset)?;\n                let key = get_val(vm, key)?;\n                let dict_manager_exec_scope = exec_scopes\n                    .get_mut_ref::<DictManagerExecScope>(\"dict_manager_exec_scope\")\n                    .expect(\"Trying to read from a dict while dict manager was not initialized.\");\n                let value = dict_manager_exec_scope\n                    .get_from_tracker(dict_address, &key)\n                    .unwrap_or_else(|| DictManagerExecScope::DICT_DEFAULT_VALUE.into());\n                insert_value_to_cellref!(vm, value_dst, value)?;\n            }\n            Hint::Felt252DictWrite { dict_ptr, key, value } => {\n                let (dict_base, dict_offset) = extract_buffer(dict_ptr);\n                let dict_address = get_ptr(vm, dict_base, &dict_offset)?;\n                let key = get_val(vm, key)?;\n                let value = get_val(vm, value)?;\n                let dict_manager_exec_scope = exec_scopes\n                    .get_mut_ref::<DictManagerExecScope>(\"dict_manager_exec_scope\")\n                    .expect(\"Trying to write to a dict while dict manager was not initialized.\");\n                let prev_value = dict_manager_exec_scope\n                    .get_from_tracker(dict_address, &key)\n                    .unwrap_or_else(|| DictManagerExecScope::DICT_DEFAULT_VALUE.into());\n                vm.insert_value(&(dict_address + 1), prev_value)?;\n                dict_manager_exec_scope.insert_to_tracker(dict_address, key, value);\n            }\n            Hint::GetSegmentArenaIndex { dict_end_ptr, dict_index, .. } => {\n                let (dict_base, dict_offset) = extract_buffer(dict_end_ptr);\n                let dict_address = get_ptr(vm, dict_base, &dict_offset)?;\n                let dict_manager_exec_scope = exec_scopes\n                    .get_ref::<DictManagerExecScope>(\"dict_manager_exec_scope\")\n                    .expect(\"Trying to read from a dict while dict manager was not initialized.\");\n                let dict_infos_index = dict_manager_exec_scope.get_dict_infos_index(dict_address);\n                insert_value_to_cellref!(vm, dict_index, Felt252::from(dict_infos_index))?;\n            }\n            Hint::InitSquashData { dict_accesses, n_accesses, first_key, big_keys, .. } => {\n                let dict_access_size = 3;\n                let rangecheck_bound = Felt252::from(u128::MAX) + 1u32;\n\n                exec_scopes.assign_or_update_variable(\n                    \"dict_squash_exec_scope\",\n                    Box::<DictSquashExecScope>::default(),\n                );\n                let dict_squash_exec_scope =\n                    exec_scopes.get_mut_ref::<DictSquashExecScope>(\"dict_squash_exec_scope\")?;\n                let (dict_accesses_base, dict_accesses_offset) = extract_buffer(dict_accesses);\n                let dict_accesses_address = get_ptr(vm, dict_accesses_base, &dict_accesses_offset)?;\n                let n_accesses = get_val(vm, n_accesses)?\n                    .to_usize()\n                    .expect(\"Number of accesses is too large or negative.\");\n                for i in 0..n_accesses {\n                    let current_key =\n                        vm.get_integer(&(dict_accesses_address + i * dict_access_size))?;\n                    dict_squash_exec_scope\n                        .access_indices\n                        .entry(current_key.into_owned())\n                        .and_modify(|indices| indices.push(Felt252::from(i)))\n                        .or_insert_with(|| vec![Felt252::from(i)]);\n                }\n                // Reverse the accesses in order to pop them in order later.\n                for (_, accesses) in dict_squash_exec_scope.access_indices.iter_mut() {\n                    accesses.reverse();\n                }\n                dict_squash_exec_scope.keys =\n                    dict_squash_exec_scope.access_indices.keys().cloned().collect();\n                dict_squash_exec_scope.keys.sort_by(|a, b| b.cmp(a));\n                // big_keys indicates if the keys are greater than rangecheck_bound. If they are not\n                // a simple range check is used instead of assert_le_felt252.\n                insert_value_to_cellref!(\n                    vm,\n                    big_keys,\n                    if dict_squash_exec_scope.keys[0] < rangecheck_bound {\n                        Felt252::from(0)\n                    } else {\n                        Felt252::from(1)\n                    }\n                )?;\n                insert_value_to_cellref!(\n                    vm,\n                    first_key,\n                    dict_squash_exec_scope.current_key().unwrap()\n                )?;\n            }\n            Hint::GetCurrentAccessIndex { range_check_ptr } => {\n                let dict_squash_exec_scope: &mut DictSquashExecScope =\n                    exec_scopes.get_mut_ref(\"dict_squash_exec_scope\")?;\n                let (range_check_base, range_check_offset) = extract_buffer(range_check_ptr);\n                let range_check_ptr = get_ptr(vm, range_check_base, &range_check_offset)?;\n                let current_access_index = dict_squash_exec_scope.current_access_index().unwrap();\n                vm.insert_value(&range_check_ptr, current_access_index)?;\n            }\n            Hint::ShouldSkipSquashLoop { should_skip_loop } => {\n                let dict_squash_exec_scope: &mut DictSquashExecScope =\n                    exec_scopes.get_mut_ref(\"dict_squash_exec_scope\")?;\n                insert_value_to_cellref!(\n                    vm,\n                    should_skip_loop,\n                    // The loop verifies that each two consecutive accesses are valid, thus we\n                    // break when there is only one remaining access.\n                    if dict_squash_exec_scope.current_access_indices().unwrap().len() > 1 {\n                        Felt252::from(0)\n                    } else {\n                        Felt252::from(1)\n                    }\n                )?;\n            }\n            Hint::GetCurrentAccessDelta { index_delta_minus1 } => {\n                let dict_squash_exec_scope: &mut DictSquashExecScope =\n                    exec_scopes.get_mut_ref(\"dict_squash_exec_scope\")?;\n                let prev_access_index = dict_squash_exec_scope.pop_current_access_index().unwrap();\n                let index_delta_minus_1_val =\n                    dict_squash_exec_scope.current_access_index().unwrap().clone()\n                        - prev_access_index\n                        - 1_u32;\n                insert_value_to_cellref!(vm, index_delta_minus1, index_delta_minus_1_val)?;\n            }\n            Hint::ShouldContinueSquashLoop { should_continue } => {\n                let dict_squash_exec_scope: &mut DictSquashExecScope =\n                    exec_scopes.get_mut_ref(\"dict_squash_exec_scope\")?;\n                insert_value_to_cellref!(\n                    vm,\n                    should_continue,\n                    // The loop verifies that each two consecutive accesses are valid, thus we\n                    // break when there is only one remaining access.\n                    if dict_squash_exec_scope.current_access_indices().unwrap().len() > 1 {\n                        Felt252::from(1)\n                    } else {\n                        Felt252::from(0)\n                    }\n                )?;\n            }\n            Hint::AssertCurrentAccessIndicesIsEmpty => {}\n            Hint::AssertAllAccessesUsed { .. } => {}\n            Hint::AssertAllKeysUsed => {}\n            Hint::GetNextDictKey { next_key } => {\n                let dict_squash_exec_scope: &mut DictSquashExecScope =\n                    exec_scopes.get_mut_ref(\"dict_squash_exec_scope\")?;\n                dict_squash_exec_scope.pop_current_key();\n                insert_value_to_cellref!(\n                    vm,\n                    next_key,\n                    dict_squash_exec_scope.current_key().unwrap()\n                )?;\n            }\n            Hint::AssertLtAssertValidInput { .. } => {}\n            Hint::AssertLeFindSmallArcs { a, b, range_check_ptr } => {\n                let a_val = get_val(vm, a)?;\n                let b_val = get_val(vm, b)?;\n                let mut lengths_and_indices = vec![\n                    (a_val.clone(), 0),\n                    (b_val.clone() - a_val, 1),\n                    (Felt252::from(-1) - b_val, 2),\n                ];\n                lengths_and_indices.sort();\n                exec_scopes\n                    .assign_or_update_variable(\"excluded_arc\", Box::new(lengths_and_indices[2].1));\n                // ceil((PRIME / 2) / 2 ** 128).\n                let prime_over_2_high = 3544607988759775765608368578435044694_u128;\n                // ceil((PRIME / 3) / 2 ** 128).\n                let prime_over_3_high = 5316911983139663648412552867652567041_u128;\n                let (range_check_base, range_check_offset) = extract_buffer(range_check_ptr);\n                let range_check_ptr = get_ptr(vm, range_check_base, &range_check_offset)?;\n                vm.insert_value(\n                    &range_check_ptr,\n                    Felt252::from(lengths_and_indices[0].0.to_biguint() % prime_over_3_high),\n                )?;\n                vm.insert_value(\n                    &(range_check_ptr + 1),\n                    Felt252::from(lengths_and_indices[0].0.to_biguint() / prime_over_3_high),\n                )?;\n                vm.insert_value(\n                    &(range_check_ptr + 2),\n                    Felt252::from(lengths_and_indices[1].0.to_biguint() % prime_over_2_high),\n                )?;\n                vm.insert_value(\n                    &(range_check_ptr + 3),\n                    Felt252::from(lengths_and_indices[1].0.to_biguint() / prime_over_2_high),\n                )?;\n            }\n            Hint::AssertLeIsFirstArcExcluded { skip_exclude_a_flag } => {\n                let excluded_arc: i32 = exec_scopes.get(\"excluded_arc\")?;\n                insert_value_to_cellref!(\n                    vm,\n                    skip_exclude_a_flag,\n                    if excluded_arc != 0 { Felt252::from(1) } else { Felt252::from(0) }\n                )?;\n            }\n            Hint::AssertLeIsSecondArcExcluded { skip_exclude_b_minus_a } => {\n                let excluded_arc: i32 = exec_scopes.get(\"excluded_arc\")?;\n                insert_value_to_cellref!(\n                    vm,\n                    skip_exclude_b_minus_a,\n                    if excluded_arc != 1 { Felt252::from(1) } else { Felt252::from(0) }\n                )?;\n            }\n            Hint::AssertLeAssertThirdArcExcluded => {}\n            Hint::DebugPrint { start, end } => {\n                let as_relocatable = |vm, value| {\n                    let (base, offset) = extract_buffer(value);\n                    get_ptr(vm, base, &offset)\n                };\n                let mut curr = as_relocatable(vm, start)?;\n                let end = as_relocatable(vm, end)?;\n                while curr != end {\n                    let value = vm.get_integer(&curr)?;\n                    if let Some(shortstring) = as_cairo_short_string(&value) {\n                        println!(\"[DEBUG]\\t{shortstring: <31}\\t(raw: {value: <31})\");\n                    } else {\n                        println!(\"[DEBUG]\\t{0: <31}\\t(raw: {value: <31}) \", ' ');\n                    }\n                    curr = curr.add_int(&1.into())?;\n                }\n                println!();\n            }\n            Hint::AllocConstantSize { size, dst } => {\n                let object_size = get_val(vm, size)?.to_usize().expect(\"Object size too large.\");\n                let memory_exec_scope =\n                    match exec_scopes.get_mut_ref::<MemoryExecScope>(\"memory_exec_scope\") {\n                        Ok(memory_exec_scope) => memory_exec_scope,\n                        Err(_) => {\n                            exec_scopes.assign_or_update_variable(\n                                \"memory_exec_scope\",\n                                Box::new(MemoryExecScope { next_address: vm.add_memory_segment() }),\n                            );\n                            exec_scopes.get_mut_ref::<MemoryExecScope>(\"memory_exec_scope\")?\n                        }\n                    };\n                insert_value_to_cellref!(vm, dst, memory_exec_scope.next_address)?;\n                memory_exec_scope.next_address.offset += object_size;\n            }\n        };\n        Ok(())\n    }\n\n    /// Trait function to store hint in the hint processor by string.\n    fn compile_hint(\n        &self,\n        hint_code: &str,\n        _ap_tracking_data: &ApTracking,\n        _reference_ids: &HashMap<String, usize>,\n        _references: &HashMap<usize, HintReference>,\n    ) -> Result<Box<dyn Any>, VirtualMachineError> {\n        Ok(Box::new(self.string_to_hint[hint_code].clone()))\n    }\n}\n\n/// Returns the starknet execution scope.\nfn starknet_execution_scope(\n    exec_scopes: &mut ExecutionScopes,\n) -> Result<&mut StarknetExecScope, HintError> {\n    Ok(exec_scopes\n        .get_local_variables_mut()?\n        .entry(\"starknet_exec_scope\".to_string())\n        .or_insert_with(|| {\n            Box::new(StarknetExecScope {\n                storage: HashMap::default(),\n                exec_info: ExecutionInfo::default(),\n            })\n        })\n        .downcast_mut::<StarknetExecScope>()\n        .unwrap())\n}\n\n/// Extracts a parameter assumed to be a buffer.\nfn extract_buffer(buffer: &ResOperand) -> (&CellRef, Felt252) {\n    let (cell, base_offset) = match buffer {\n        ResOperand::Deref(cell) => (cell, 0.into()),\n        ResOperand::BinOp(BinOpOperand { op: Operation::Add, a, b }) => {\n            (a, extract_matches!(b, DerefOrImmediate::Immediate).clone().value.into())\n        }\n        _ => panic!(\"Illegal argument for a buffer.\"),\n    };\n    (cell, base_offset)\n}\n\n/// Provides context for the `additional_initialization` callback function of [run_function].\npub struct RunFunctionContext<'a> {\n    pub vm: &'a mut VirtualMachine,\n    pub data_len: usize,\n}\n\n/// Runs `program` on layout with prime, and returns the memory layout and ap value.\npub fn run_function<'a, Instructions: Iterator<Item = &'a Instruction> + Clone>(\n    instructions: Instructions,\n    builtins: Vec<String>,\n    additional_initialization: fn(\n        context: RunFunctionContext<'_>,\n    ) -> Result<(), Box<VirtualMachineError>>,\n) -> Result<(Vec<Option<Felt252>>, usize), Box<VirtualMachineError>> {\n    let data: Vec<MaybeRelocatable> = instructions\n        .clone()\n        .flat_map(|inst| inst.assemble().encode())\n        .map(Felt252::from)\n        .map(MaybeRelocatable::from)\n        .collect();\n\n    let mut hint_processor = CairoHintProcessor::new(instructions);\n\n    let data_len = data.len();\n    let program = Program {\n        builtins,\n        prime: PRIME_STR.to_string(),\n        data,\n        constants: HashMap::new(),\n        main: Some(0),\n        start: None,\n        end: None,\n        hints: hint_processor.hints_dict.clone(),\n        reference_manager: ReferenceManager { references: Vec::new() },\n        identifiers: HashMap::new(),\n        error_message_attributes: vec![],\n        instruction_locations: None,\n    };\n    let mut runner = CairoRunner::new(&program, \"all\", false)\n        .map_err(VirtualMachineError::from)\n        .map_err(Box::new)?;\n    let mut vm = VirtualMachine::new(true);\n\n    let end = runner.initialize(&mut vm).map_err(VirtualMachineError::from).map_err(Box::new)?;\n\n    additional_initialization(RunFunctionContext { vm: &mut vm, data_len })?;\n\n    runner.run_until_pc(end, &mut vm, &mut hint_processor)?;\n    runner.end_run(true, false, &mut vm, &mut hint_processor).map_err(Box::new)?;\n    runner.relocate(&mut vm).map_err(VirtualMachineError::from).map_err(Box::new)?;\n    Ok((runner.relocated_memory, runner.relocated_trace.unwrap().last().unwrap().ap))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_felt::Felt as Felt252;\nuse cairo_lang_casm::inline::CasmContext;\nuse cairo_lang_casm::{casm, deref};\nuse itertools::Itertools;\nuse num_traits::ToPrimitive;\nuse test_case::test_case;\n\nuse crate::casm_run::run_function;\n\n#[test_case(\n    casm! {\n        [ap] = (-5), ap++;\n        [ap] = 7, ap++;\n        ret;\n    },\n    2,\n    &[-5, 7];\n    \"simple ap sets\"\n)]\n#[test_case(\n    casm! {\n        ap += 1;\n        [ap] = 123, ap++;\n        [ap] = 456, ap++;\n        [fp] = [ap - 2] + [ap - 1];\n        ret;\n    },\n    3,\n    &[579, 123, 456];\n    \"sum ap into fp\"\n)]\n#[test_case(\n    casm! {\n        [ap] = 1, ap++;\n        jmp rel 2 if [ap - 1] != 0;\n        [ap] = 5, ap++;\n        [ap] = 0, ap++;\n        jmp rel 2 if [ap - 1] != 0;\n        [ap] = 3, ap++;\n        [ap] = 4, ap++;\n        ret;\n    },\n    5,\n    &[1, 5, 0, 3, 4];\n    \"jumps\"\n)]\n#[test_case(\n    casm! {\n        [ap] = 39, ap++;\n        %{ memory[ap] = 13 < memory[ap - 1] %}\n        ap += 1;\n        [ap] = [ap - 1] + 83, ap++;\n        ret;\n    },\n    3,\n    &[39, 1, 84];\n    \"less than hint\"\n)]\n#[test_case(\n    casm! {\n        [ap] = 5, ap++;\n        [ap] = 39, ap++;\n        %{ (memory[ap], memory[ap + 1]) = divmod(memory[ap - 1], memory[ap - 2]) %}\n        ap += 2;\n        ret;\n    },\n    4,\n    &[5, 39, 7, 4];\n    \"divmod hint\"\n)]\n#[test_case(\n    casm! {\n        [ap + 0] = 1, ap++;\n        [ap + 0] = 1, ap++;\n        [ap + 0] = 13, ap++;\n        call rel 3;\n        ret;\n        jmp rel 5 if [fp + -3] != 0;\n        [ap + 0] = [fp + -5], ap++;\n        jmp rel 8;\n        [ap + 0] = [fp + -4], ap++;\n        [ap + 0] = [fp + -5] + [fp + -4], ap++;\n        [fp + -3] = [ap + 0] + 1, ap++;\n        call rel (-9);\n        ret;\n    },\n    1,\n    &[377];\n    \"fib(1, 1, 13)\"\n)]\n#[test_case(\n    casm! {\n        [ap + 0] = 2, ap++;\n        [ap + 0] = 1, ap++;\n        [ap - 1] = [ap + 0] * [ap - 2], ap++; // Caclulates.\n        [ap - 2] = [ap - 1] * [ap - 3]; // Validates the calculation.\n        ret;\n    },\n    0,\n    &[];\n    \"simple_division\"\n)]\nfn test_runner(function: CasmContext, n_returns: usize, expected: &[i128]) {\n    let (cells, ap) = run_function(function.instructions.iter(), vec![], |_| Ok(()))\n        .expect(\"Running code failed.\");\n    let cells = cells.into_iter().skip(ap - n_returns);\n    assert_eq!(\n        cells.take(n_returns).map(|cell| cell.unwrap()).collect_vec(),\n        expected.iter().copied().map(Felt252::from).collect_vec()\n    );\n}\n\n#[test]\nfn test_allocate_segment() {\n    let (memory, ap) = run_function(\n        casm! {\n            [ap] = 1337, ap++;\n            %{ memory[ap] = segments.add() %}\n            [ap - 1] = [[&deref!([ap])]];\n            ret;\n        }\n        .instructions\n        .iter(),\n        vec![],\n        |_| Ok(()),\n    )\n    .expect(\"Running code failed.\");\n    let ptr = memory[ap]\n        .as_ref()\n        .expect(\"Uninitialized value.\")\n        .to_usize()\n        .expect(\"Number not in index range.\");\n    assert_eq!(memory[ptr], Some(Felt252::from(1337)));\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Compiles and runs a Cairo program.\n\nuse std::path::Path;\n\nuse anyhow::{Context, Ok};\nuse cairo_lang_compiler::db::RootDatabase;\nuse cairo_lang_compiler::diagnostics::DiagnosticsReporter;\nuse cairo_lang_compiler::project::setup_project;\nuse cairo_lang_diagnostics::ToOption;\nuse cairo_lang_runner::SierraCasmRunner;\nuse cairo_lang_sierra_generator::db::SierraGenGroup;\nuse cairo_lang_sierra_generator::replace_ids::replace_sierra_ids_in_program;\nuse clap::Parser;\n\n/// Command line args parser.\n/// Exits with 0/1 if the input is formatted correctly/incorrectly.\n#[derive(Parser, Debug)]\n#[clap(version, verbatim_doc_comment)]\nstruct Args {\n    /// The file to compile and run.\n    #[arg(short, long)]\n    path: String,\n    /// In cases where gas is available, the amount of provided gas.\n    #[arg(long)]\n    available_gas: Option<usize>,\n    /// Whether to print the memory.\n    #[arg(long, default_value_t = false)]\n    print_full_memory: bool,\n}\n\nfn main() -> anyhow::Result<()> {\n    let args = Args::parse();\n\n    let db = &mut RootDatabase::builder().detect_corelib().build()?;\n\n    let main_crate_ids = setup_project(db, Path::new(&args.path))?;\n\n    if DiagnosticsReporter::stderr().check(db) {\n        anyhow::bail!(\"failed to compile: {}\", args.path);\n    }\n\n    let sierra_program = db\n        .get_sierra_program(main_crate_ids)\n        .to_option()\n        .with_context(|| \"Compilation failed without any diagnostics.\")?;\n    let runner = SierraCasmRunner::new(\n        replace_sierra_ids_in_program(db, &sierra_program),\n        args.available_gas.is_some(),\n    )\n    .with_context(|| \"Failed setting up runner.\")?;\n    let result = runner\n        .run_function(\"::main\", &[], args.available_gas)\n        .with_context(|| \"Failed to run the function.\")?;\n    match result.value {\n        cairo_lang_runner::RunResultValue::Success(values) => {\n            println!(\"Run completed successfully, returning {values:?}\")\n        }\n        cairo_lang_runner::RunResultValue::Panic(values) => {\n            println!(\"Run panicked with err values: {values:?}\")\n        }\n    }\n    if let Some(gas) = result.gas_counter {\n        println!(\"Remaining gas: {gas}\");\n    }\n    if args.print_full_memory {\n        print!(\"Full memory: [\");\n        for cell in &result.memory {\n            match cell {\n                None => print!(\"_, \"),\n                Some(value) => print!(\"{value}, \"),\n            }\n        }\n        println!(\"]\");\n    }\n    Ok(())\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Basic runner for running a Sierra program on the vm.\nuse std::collections::HashMap;\n\nuse cairo_felt::Felt as Felt252;\nuse cairo_lang_casm::instructions::Instruction;\nuse cairo_lang_casm::{casm, casm_extend};\nuse cairo_lang_sierra::extensions::bitwise::BitwiseType;\nuse cairo_lang_sierra::extensions::builtin_cost::CostTokenType;\nuse cairo_lang_sierra::extensions::core::{CoreLibfunc, CoreType};\nuse cairo_lang_sierra::extensions::ec::EcOpType;\nuse cairo_lang_sierra::extensions::enm::EnumType;\nuse cairo_lang_sierra::extensions::gas::GasBuiltinType;\nuse cairo_lang_sierra::extensions::pedersen::PedersenType;\nuse cairo_lang_sierra::extensions::range_check::RangeCheckType;\nuse cairo_lang_sierra::extensions::segment_arena::SegmentArenaType;\nuse cairo_lang_sierra::extensions::starknet::syscalls::SystemType;\nuse cairo_lang_sierra::extensions::{ConcreteType, NamedType};\nuse cairo_lang_sierra::program::{Function, GenericArg};\nuse cairo_lang_sierra::program_registry::{ProgramRegistry, ProgramRegistryError};\nuse cairo_lang_sierra_ap_change::{calc_ap_changes, ApChangeError};\nuse cairo_lang_sierra_gas::gas_info::GasInfo;\nuse cairo_lang_sierra_to_casm::compiler::{CairoProgram, CompilationError};\nuse cairo_lang_sierra_to_casm::metadata::{calc_metadata, Metadata, MetadataError};\nuse cairo_lang_utils::extract_matches;\nuse cairo_vm::vm::errors::vm_errors::VirtualMachineError;\nuse itertools::chain;\nuse num_traits::ToPrimitive;\nuse thiserror::Error;\n\nmod casm_run;\npub mod short_string;\n\n#[derive(Debug, Error)]\npub enum RunnerError {\n    #[error(\"Not enough gas to call function.\")]\n    NotEnoughGasToCall,\n    #[error(\"GasBuiltin is required while `available_gas` value is provided.\")]\n    GasBuiltinRequired,\n    #[error(\n        \"Failed calculating gas usage, it is likely a call for `gas::withdraw_gas` is missing.\"\n    )]\n    FailedGasCalculation,\n    #[error(\"Function with suffix `{suffix}` to run not found.\")]\n    MissingFunction { suffix: String },\n    #[error(\"Function expects arguments of size {expected} and received {actual} instead.\")]\n    ArgumentsSizeMismatch { expected: usize, actual: usize },\n    #[error(transparent)]\n    ProgramRegistryError(#[from] Box<ProgramRegistryError>),\n    #[error(transparent)]\n    SierraCompilationError(#[from] Box<CompilationError>),\n    #[error(transparent)]\n    ApChangeError(#[from] ApChangeError),\n    #[error(transparent)]\n    VirtualMachineError(#[from] Box<VirtualMachineError>),\n}\n\n/// The full result of a run.\npub struct RunResult {\n    pub gas_counter: Option<Felt252>,\n    pub memory: Vec<Option<Felt252>>,\n    pub value: RunResultValue,\n}\n\n/// The ran function return value.\n#[derive(Debug, Eq, PartialEq)]\npub enum RunResultValue {\n    /// Run ended successfully, returning the memory of the non-implicit returns.\n    Success(Vec<Felt252>),\n    /// Run panicked, returning the carried error data.\n    Panic(Vec<Felt252>),\n}\n\n// Dummy cost of a builtin invocation.\npub const DUMMY_BUILTIN_GAS_COST: usize = 10000;\n\n/// Runner enabling running a Sierra program on the vm.\npub struct SierraCasmRunner {\n    /// The sierra program.\n    sierra_program: cairo_lang_sierra::program::Program,\n    /// Metadata for the Sierra program.\n    metadata: Metadata,\n    /// Program registry for the Sierra program.\n    sierra_program_registry: ProgramRegistry<CoreType, CoreLibfunc>,\n    /// The casm program matching the Sierra code.\n    casm_program: CairoProgram,\n}\nimpl SierraCasmRunner {\n    pub fn new(\n        sierra_program: cairo_lang_sierra::program::Program,\n        calc_gas: bool,\n    ) -> Result<Self, RunnerError> {\n        let metadata = create_metadata(&sierra_program, calc_gas)?;\n        let sierra_program_registry =\n            ProgramRegistry::<CoreType, CoreLibfunc>::new(&sierra_program)?;\n        let casm_program =\n            cairo_lang_sierra_to_casm::compiler::compile(&sierra_program, &metadata, calc_gas)?;\n        Ok(Self { sierra_program, metadata, sierra_program_registry, casm_program })\n    }\n\n    /// Runs the vm starting from a function. Function may have implicits, but no other ref params.\n    /// The cost of the function is deducted from available_gas before the execution begins.\n    pub fn run_function(\n        &self,\n        name_suffix: &str,\n        args: &[Felt252],\n        available_gas: Option<usize>,\n    ) -> Result<RunResult, RunnerError> {\n        let func = self.find_function(name_suffix)?;\n        let initial_gas = self.get_initial_available_gas(func, available_gas)?;\n        let (entry_code, builtins) = self.create_entry_code(func, args, initial_gas)?;\n        let footer = self.create_code_footer();\n        let (cells, ap) = casm_run::run_function(\n            chain!(entry_code.iter(), self.casm_program.instructions.iter(), footer.iter()),\n            builtins,\n            |context| {\n                let vm = context.vm;\n                // Create the builtin cost segment, with dummy values.\n                let builtin_cost_segment = vm.add_memory_segment();\n                for token_type in CostTokenType::iter_precost() {\n                    vm.insert_value(\n                        &(builtin_cost_segment + (token_type.offset_in_builtin_costs() as usize)),\n                        Felt252::from(DUMMY_BUILTIN_GAS_COST),\n                    )?;\n                }\n                // Put a pointer to the builtin cost segment at the end of the program (after the\n                // additional `ret` statement).\n                vm.insert_value(&(vm.get_pc() + context.data_len), builtin_cost_segment)?;\n                Ok(())\n            },\n        )?;\n        let mut results_data = self.get_results_data(func, &cells, ap)?;\n        // Handling implicits.\n        let mut gas_counter = None;\n        results_data.retain_mut(|(ty, values)| {\n            let info = self.get_info(ty);\n            let generic_ty = &info.long_id.generic_id;\n            if *generic_ty == GasBuiltinType::ID {\n                gas_counter = Some(values.remove(0));\n                assert!(values.is_empty());\n                false\n            } else {\n                *generic_ty != RangeCheckType::ID\n                    && *generic_ty != BitwiseType::ID\n                    && *generic_ty != EcOpType::ID\n                    && *generic_ty != PedersenType::ID\n                    && *generic_ty != SystemType::ID\n                    && *generic_ty != SegmentArenaType::ID\n            }\n        });\n        assert!(results_data.len() <= 1);\n        let value = if results_data.is_empty() {\n            // No result type - no panic.\n            RunResultValue::Success(vec![])\n        } else {\n            let [(ty, values)] = <[_; 1]>::try_from(results_data).ok().unwrap();\n            self.handle_main_return_value(ty, values, &cells)?\n        };\n        Ok(RunResult { gas_counter, memory: cells, value })\n    }\n\n    /// Handling the main return value to create a `RunResultValue`.\n    fn handle_main_return_value(\n        &self,\n        ty: cairo_lang_sierra::ids::ConcreteTypeId,\n        values: Vec<Felt252>,\n        cells: &[Option<Felt252>],\n    ) -> Result<RunResultValue, RunnerError> {\n        let info = self.get_info(&ty);\n        let long_id = &info.long_id;\n        Ok(\n            if long_id.generic_id == EnumType::ID\n                && matches!(&long_id.generic_args[0], GenericArg::UserType(ut) if ut.debug_name.as_ref().unwrap().starts_with(\"core::PanicResult::\"))\n            {\n                // The function includes a panic wrapper.\n                if values[0] != Felt252::from(0) {\n                    // The run resulted in a panic, returning the error data.\n                    let err_data_start = values[values.len() - 2].to_usize().unwrap();\n                    let err_data_end = values[values.len() - 1].to_usize().unwrap();\n                    RunResultValue::Panic(\n                        cells[err_data_start..err_data_end]\n                            .iter()\n                            .cloned()\n                            .map(|cell| cell.unwrap())\n                            .collect(),\n                    )\n                } else {\n                    // The run resulted successfully, returning the inner value.\n                    let inner_ty = extract_matches!(&long_id.generic_args[1], GenericArg::Type);\n                    let inner_ty_size =\n                        self.sierra_program_registry.get_type(inner_ty)?.info().size as usize;\n                    let skip_size = values.len() - inner_ty_size;\n                    RunResultValue::Success(values.into_iter().skip(skip_size).collect())\n                }\n            } else {\n                // No panic wrap - so always successful.\n                RunResultValue::Success(values)\n            },\n        )\n    }\n\n    /// Returns the final values and type of all `func`s returning variables.\n    fn get_results_data(\n        &self,\n        func: &Function,\n        cells: &[Option<Felt252>],\n        mut ap: usize,\n    ) -> Result<Vec<(cairo_lang_sierra::ids::ConcreteTypeId, Vec<Felt252>)>, RunnerError> {\n        let mut results_data = vec![];\n        for ty in func.signature.ret_types.iter().rev() {\n            let size = self.sierra_program_registry.get_type(ty)?.info().size as usize;\n            let values: Vec<Felt252> =\n                ((ap - size)..ap).map(|index| cells[index].clone().unwrap()).collect();\n            ap -= size;\n            results_data.push((ty.clone(), values));\n        }\n        Ok(results_data)\n    }\n\n    /// Finds first function ending with `name_suffix`.\n    fn find_function(&self, name_suffix: &str) -> Result<&Function, RunnerError> {\n        self.sierra_program\n            .funcs\n            .iter()\n            .find(|f| {\n                if let Some(name) = &f.id.debug_name { name.ends_with(name_suffix) } else { false }\n            })\n            .ok_or_else(|| RunnerError::MissingFunction { suffix: name_suffix.to_owned() })\n    }\n\n    fn get_info(\n        &self,\n        ty: &cairo_lang_sierra::ids::ConcreteTypeId,\n    ) -> &cairo_lang_sierra::extensions::types::TypeInfo {\n        self.sierra_program_registry.get_type(ty).unwrap().info()\n    }\n\n    /// Returns the instructions to add to the beginning of the code to successfully call the main\n    /// function, as well as the builtins required to execute the program.\n    fn create_entry_code(\n        &self,\n        func: &Function,\n        args: &[Felt252],\n        initial_gas: usize,\n    ) -> Result<(Vec<Instruction>, Vec<String>), RunnerError> {\n        let mut arg_iter = args.iter();\n        let mut expected_arguments_size = 0;\n        let mut ctx = casm! {};\n        // The builtins in the formatting expected by the runner.\n        let builtins: Vec<_> = [\"pedersen\", \"range_check\", \"bitwise\", \"ec_op\"]\n            .map(&str::to_string)\n            .into_iter()\n            .collect();\n        // The offset [fp - i] for each of this builtins in this configuration.\n        let builtin_offset: HashMap<cairo_lang_sierra::ids::GenericTypeId, i16> = HashMap::from([\n            (PedersenType::ID, 6),\n            (RangeCheckType::ID, 5),\n            (BitwiseType::ID, 4),\n            (EcOpType::ID, 3),\n        ]);\n        if func\n            .signature\n            .param_types\n            .iter()\n            .any(|ty| self.get_info(ty).long_id.generic_id == SegmentArenaType::ID)\n        {\n            casm_extend! {ctx,\n                // SegmentArena segment.\n                %{ memory[ap + 0] = segments.add() %}\n                // Infos segment.\n                %{ memory[ap + 1] = segments.add() %}\n                ap += 2;\n                [ap + 0] = 0, ap++;\n                // Write Infos segment, n_constructed (0), and n_destructed (0) to the segment.\n                [ap - 2] = [[ap - 3]];\n                [ap - 1] = [[ap - 3] + 1];\n                [ap - 1] = [[ap - 3] + 2];\n            }\n        }\n        for (i, ty) in func.signature.param_types.iter().enumerate() {\n            let info = self.get_info(ty);\n            let generic_ty = &info.long_id.generic_id;\n            if let Some(offset) = builtin_offset.get(generic_ty) {\n                casm_extend! {ctx,\n                    [ap + 0] = [fp - offset], ap++;\n                }\n            } else if generic_ty == &SystemType::ID {\n                casm_extend! {ctx,\n                    %{ memory[ap + 0] = segments.add() %}\n                    ap += 1;\n                }\n            } else if generic_ty == &GasBuiltinType::ID {\n                casm_extend! {ctx,\n                    [ap + 0] = initial_gas, ap++;\n                }\n            } else if generic_ty == &SegmentArenaType::ID {\n                let offset = -(i as i16) - 3;\n                casm_extend! {ctx,\n                    [ap + 0] = [ap + offset] + 3, ap++;\n                }\n            } else {\n                let arg_size = info.size;\n                expected_arguments_size += arg_size as usize;\n                for _ in 0..arg_size {\n                    if let Some(value) = arg_iter.next() {\n                        casm_extend! {ctx,\n                            [ap + 0] = (value.to_bigint()), ap++;\n                        }\n                    }\n                }\n            }\n        }\n        if expected_arguments_size != args.len() {\n            return Err(RunnerError::ArgumentsSizeMismatch {\n                expected: expected_arguments_size,\n                actual: args.len(),\n            });\n        }\n        let before_final_call = ctx.current_code_offset;\n        let final_call_size = 3;\n        let offset = final_call_size\n            + self.casm_program.debug_info.sierra_statement_info[func.entry_point.0].code_offset;\n        casm_extend! {ctx,\n            call rel offset;\n            ret;\n        }\n        assert_eq!(before_final_call + final_call_size, ctx.current_code_offset);\n        Ok((ctx.instructions, builtins))\n    }\n\n    /// Returns the initial value for the gas counter.\n    /// If available_gas is None returns 0.\n    fn get_initial_available_gas(\n        &self,\n        func: &Function,\n        available_gas: Option<usize>,\n    ) -> Result<usize, RunnerError> {\n        // In case we don't have any costs - it means no equations were solved - so the gas builtin\n        // is irrelevant, and we can return any value.\n        if self.metadata.gas_info.function_costs.is_empty() {\n            return Ok(0);\n        }\n        let Some(available_gas) = available_gas else { return Ok(0); };\n\n        // Compute the initial gas required by the function.\n        let required_gas = self.metadata.gas_info.function_costs[func.id.clone()]\n            .iter()\n            .map(|(cost_token_type, val)| {\n                let val_usize: usize = (*val).try_into().unwrap();\n                let token_cost = if *cost_token_type == CostTokenType::Const {\n                    1\n                } else {\n                    DUMMY_BUILTIN_GAS_COST\n                };\n                val_usize * token_cost\n            })\n            .sum();\n\n        available_gas.checked_sub(required_gas).ok_or(RunnerError::NotEnoughGasToCall)\n    }\n\n    /// Creates a list of instructions that will be appended to the program's bytecode.\n    pub fn create_code_footer(&self) -> Vec<Instruction> {\n        casm! {\n            // Add a `ret` instruction used in libfuncs that retrieve the current value of the `fp`\n            // and `pc` registers.\n            ret;\n        }\n        .instructions\n    }\n}\n\n/// Creates the metadata required for a Sierra program lowering to casm.\nfn create_metadata(\n    sierra_program: &cairo_lang_sierra::program::Program,\n    calc_gas: bool,\n) -> Result<Metadata, RunnerError> {\n    if calc_gas {\n        calc_metadata(sierra_program, Default::default()).map_err(|err| match err {\n            MetadataError::ApChangeError(err) => RunnerError::ApChangeError(err),\n            MetadataError::CostError(_) => RunnerError::FailedGasCalculation,\n        })\n    } else {\n        Ok(Metadata {\n            ap_change_info: calc_ap_changes(sierra_program, |_, _| 0)?,\n            gas_info: GasInfo {\n                variable_values: Default::default(),\n                function_costs: Default::default(),\n            },\n        })\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_felt::Felt as Felt252;\n\n/// Converts a bigint representing a felt252 to a Cairo short-string.\npub fn as_cairo_short_string(value: &Felt252) -> Option<String> {\n    let mut as_string = String::default();\n    let mut is_end = false;\n    for byte in value.to_bytes_be() {\n        if byte == 0 {\n            is_end = true;\n        } else if is_end || !byte.is_ascii() {\n            return None;\n        } else {\n            as_string.push(byte as char);\n        }\n    }\n    Some(as_string)\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_defs::ids::{EnumId, GenericTypeId, ImplDefId, ModuleId, ModuleItemId, TraitId};\nuse cairo_lang_diagnostics::{Maybe, ToOption};\nuse cairo_lang_filesystem::ids::{CrateId, CrateLongId};\nuse cairo_lang_syntax::node::ast::{self, BinaryOperator, UnaryOperator};\nuse cairo_lang_syntax::node::ids::SyntaxStablePtrId;\nuse cairo_lang_syntax::node::Terminal;\nuse cairo_lang_utils::{extract_matches, try_extract_matches, OptionFrom};\nuse num_bigint::BigInt;\nuse num_traits::{Num, Signed};\nuse smol_str::SmolStr;\n\nuse crate::db::SemanticGroup;\nuse crate::diagnostic::SemanticDiagnosticKind;\nuse crate::expr::compute::ComputationContext;\nuse crate::expr::inference::Inference;\nuse crate::items::enm::SemanticEnumEx;\nuse crate::items::functions::{GenericFunctionId, ImplGenericFunctionId};\nuse crate::items::imp::ImplId;\nuse crate::items::trt::{\n    ConcreteTraitGenericFunctionId, ConcreteTraitGenericFunctionLongId, ConcreteTraitId,\n};\nuse crate::items::us::SemanticUseEx;\nuse crate::resolve_path::ResolvedGenericItem;\nuse crate::types::ConcreteEnumLongId;\nuse crate::{\n    semantic, ConcreteEnumId, ConcreteFunction, ConcreteImplLongId, ConcreteVariant, Expr, ExprId,\n    ExprTuple, FunctionId, FunctionLongId, GenericArgumentId, TypeId, TypeLongId,\n};\n\npub fn core_module(db: &dyn SemanticGroup) -> ModuleId {\n    let core_crate = db.core_crate();\n    ModuleId::CrateRoot(core_crate)\n}\n\npub fn core_submodule(db: &dyn SemanticGroup, submodule_name: &str) -> ModuleId {\n    let core_module = core_module(db);\n    let submodules = db.module_submodules(core_module).unwrap();\n    let syntax_db = db.upcast();\n    for (submodule_id, submodule) in submodules {\n        if submodule.name(syntax_db).text(syntax_db) == submodule_name {\n            return ModuleId::Submodule(submodule_id);\n        }\n    }\n    unreachable!(\"Requested core submodule not found\");\n}\n\npub fn core_crate(db: &dyn SemanticGroup) -> CrateId {\n    db.intern_crate(CrateLongId(\"core\".into()))\n}\n\npub fn core_felt252_ty(db: &dyn SemanticGroup) -> TypeId {\n    get_core_ty_by_name(db, \"felt252\".into(), vec![])\n}\n\npub fn core_nonzero_ty(db: &dyn SemanticGroup, inner_type: TypeId) -> TypeId {\n    get_core_ty_by_name(db, \"NonZero\".into(), vec![GenericArgumentId::Type(inner_type)])\n}\n\npub fn core_array_felt_ty(db: &dyn SemanticGroup) -> TypeId {\n    get_core_ty_by_name(db, \"Array\".into(), vec![GenericArgumentId::Type(core_felt252_ty(db))])\n}\n\npub fn try_get_core_ty_by_name(\n    db: &dyn SemanticGroup,\n    name: SmolStr,\n    generic_args: Vec<GenericArgumentId>,\n) -> Result<TypeId, SemanticDiagnosticKind> {\n    let core_module = db.core_module();\n    // This should not fail if the corelib is present.\n    let module_item_id = db\n        .module_item_by_name(core_module, name.clone())\n        .map_err(|_| SemanticDiagnosticKind::UnknownType)?\n        .ok_or(SemanticDiagnosticKind::UnknownType)?;\n    let generic_type = match module_item_id {\n        ModuleItemId::Use(use_id) => {\n            db.use_resolved_item(use_id).to_option().and_then(|resolved_generic_item| {\n                try_extract_matches!(resolved_generic_item, ResolvedGenericItem::GenericType)\n            })\n        }\n        ModuleItemId::TypeAlias(type_alias_id) => {\n            let ty =\n                db.type_alias_resolved_type(type_alias_id).expect(\"Could not find type alias.\");\n            assert!(\n                db.type_alias_generic_params(type_alias_id).unwrap().is_empty(),\n                \"Cannot get type aliases with params from corelib.\"\n            );\n            return Ok(ty);\n        }\n        _ => GenericTypeId::option_from(module_item_id),\n    }\n    .unwrap_or_else(|| panic!(\"{name} is not a type.\"));\n\n    Ok(db.intern_type(semantic::TypeLongId::Concrete(semantic::ConcreteTypeId::new(\n        db,\n        generic_type,\n        generic_args,\n    ))))\n}\n\npub fn get_core_ty_by_name(\n    db: &dyn SemanticGroup,\n    name: SmolStr,\n    generic_args: Vec<GenericArgumentId>,\n) -> TypeId {\n    try_get_core_ty_by_name(db, name, generic_args).unwrap()\n}\n\npub fn core_bool_ty(db: &dyn SemanticGroup) -> TypeId {\n    let core_module = db.core_module();\n    // This should not fail if the corelib is present.\n    let generic_type = db\n        .module_item_by_name(core_module, \"bool\".into())\n        .expect(\"Failed to load core lib.\")\n        .and_then(GenericTypeId::option_from)\n        .expect(\"Type bool was not found in core lib.\");\n    db.intern_type(semantic::TypeLongId::Concrete(semantic::ConcreteTypeId::new(\n        db,\n        generic_type,\n        vec![],\n    )))\n}\n\n// TODO(spapini): Consider making all these queries for better caching.\n/// Generates a ConcreteEnumId instance for `bool`.\npub fn core_bool_enum(db: &dyn SemanticGroup) -> ConcreteEnumId {\n    let core_module = db.core_module();\n    // This should not fail if the corelib is present.\n    let enum_id = db\n        .module_item_by_name(core_module, \"bool\".into())\n        .expect(\"Failed to load core lib.\")\n        .and_then(EnumId::option_from)\n        .expect(\"Type bool was not found in core lib.\");\n    db.intern_concrete_enum(ConcreteEnumLongId { enum_id, generic_args: vec![] })\n}\n\n/// Generates a ConcreteVariant instance for `false`.\npub fn false_variant(db: &dyn SemanticGroup) -> ConcreteVariant {\n    get_core_enum_concrete_variant(db, \"bool\", vec![], \"False\")\n}\n\n/// Generates a ConcreteVariant instance for `true`.\npub fn true_variant(db: &dyn SemanticGroup) -> ConcreteVariant {\n    get_core_enum_concrete_variant(db, \"bool\", vec![], \"True\")\n}\n\n/// Generates a ConcreteVariant instance for `IsZeroResult::<felt252>::Zero`.\npub fn jump_nz_zero_variant(db: &dyn SemanticGroup) -> ConcreteVariant {\n    get_core_enum_concrete_variant(\n        db,\n        \"IsZeroResult\",\n        vec![GenericArgumentId::Type(core_felt252_ty(db))],\n        \"Zero\",\n    )\n}\n\n/// Generates a ConcreteVariant instance for `IsZeroResult::<felt252>::NonZero`.\npub fn jump_nz_nonzero_variant(db: &dyn SemanticGroup) -> ConcreteVariant {\n    get_core_enum_concrete_variant(\n        db,\n        \"IsZeroResult\",\n        vec![GenericArgumentId::Type(core_felt252_ty(db))],\n        \"NonZero\",\n    )\n}\n\n/// Generates a ConcreteVariant instance for `Option::Some`.\npub fn option_some_variant(\n    db: &dyn SemanticGroup,\n    generic_arg: GenericArgumentId,\n) -> ConcreteVariant {\n    get_enum_concrete_variant(db, core_submodule(db, \"option\"), \"Option\", vec![generic_arg], \"Some\")\n}\n\n/// Generates a ConcreteVariant instance for `Option::None`.\npub fn option_none_variant(\n    db: &dyn SemanticGroup,\n    generic_arg: GenericArgumentId,\n) -> ConcreteVariant {\n    get_enum_concrete_variant(db, core_submodule(db, \"option\"), \"Option\", vec![generic_arg], \"None\")\n}\n\n/// Gets a semantic expression of the literal `false`. Uses the given `stable_ptr` in the returned\n/// semantic expression.\npub fn false_literal_expr(\n    ctx: &mut ComputationContext<'_>,\n    stable_ptr: ast::ExprPtr,\n) -> semantic::Expr {\n    get_bool_variant_expr(ctx, \"bool\", \"False\", stable_ptr)\n}\n\n/// Gets a semantic expression of the literal `true`. Uses the given `stable_ptr` in the returned\n/// semantic expression.\npub fn true_literal_expr(\n    ctx: &mut ComputationContext<'_>,\n    stable_ptr: ast::ExprPtr,\n) -> semantic::Expr {\n    get_bool_variant_expr(ctx, \"bool\", \"True\", stable_ptr)\n}\n\n/// Gets a semantic expression of the specified bool enum variant. Uses the given `stable_ptr` in\n/// the returned semantic expression.\nfn get_bool_variant_expr(\n    ctx: &mut ComputationContext<'_>,\n    enum_name: &str,\n    variant_name: &str,\n    stable_ptr: ast::ExprPtr,\n) -> semantic::Expr {\n    let concrete_variant = get_core_enum_concrete_variant(ctx.db, enum_name, vec![], variant_name);\n    semantic::Expr::EnumVariantCtor(semantic::ExprEnumVariantCtor {\n        variant: concrete_variant,\n        value_expr: unit_expr(ctx, stable_ptr),\n        ty: core_bool_ty(ctx.db),\n        stable_ptr,\n    })\n}\n\n/// Gets a [ConcreteVariant] instance for an enum variant, by module and name.\n/// Assumes the variant exists.\npub fn get_enum_concrete_variant(\n    db: &dyn SemanticGroup,\n    module_id: ModuleId,\n    enum_name: &str,\n    generic_args: Vec<GenericArgumentId>,\n    variant_name: &str,\n) -> ConcreteVariant {\n    let enum_item = db.module_item_by_name(module_id, enum_name.into()).unwrap().unwrap();\n    let enum_id = extract_matches!(enum_item, ModuleItemId::Enum);\n    let concrete_enum_id = db.intern_concrete_enum(ConcreteEnumLongId { enum_id, generic_args });\n    let variant_id = db.enum_variants(enum_id).unwrap()[variant_name];\n    let variant = db.variant_semantic(enum_id, variant_id).unwrap();\n    db.concrete_enum_variant(concrete_enum_id, &variant).unwrap()\n}\n\n/// Gets a [ConcreteVariant] instance for an enum variant from the core module, by name.\n/// Assumes the variant exists.\npub fn get_core_enum_concrete_variant(\n    db: &dyn SemanticGroup,\n    enum_name: &str,\n    generic_args: Vec<GenericArgumentId>,\n    variant_name: &str,\n) -> ConcreteVariant {\n    get_enum_concrete_variant(db, core_module(db), enum_name, generic_args, variant_name)\n}\n\n/// Gets the unit type ().\npub fn unit_ty(db: &dyn SemanticGroup) -> TypeId {\n    db.intern_type(semantic::TypeLongId::Tuple(vec![]))\n}\n\n/// Gets the never type ().\npub fn never_ty(db: &dyn SemanticGroup) -> TypeId {\n    let core_module = db.core_module();\n    // This should not fail if the corelib is present.\n    let generic_type = db\n        .module_item_by_name(core_module, \"never\".into())\n        .expect(\"Failed to load core lib.\")\n        .and_then(GenericTypeId::option_from)\n        .expect(\"Type bool was not found in core lib.\");\n    db.intern_type(semantic::TypeLongId::Concrete(semantic::ConcreteTypeId::new(\n        db,\n        generic_type,\n        vec![],\n    )))\n}\n\n/// Attempts to unwrap error propagation types (Option, Result).\n/// Returns None if not one of these types.\npub fn unwrap_error_propagation_type(\n    db: &dyn SemanticGroup,\n    ty: TypeId,\n) -> Option<(ConcreteVariant, ConcreteVariant)> {\n    match db.lookup_intern_type(ty) {\n        // Only enums may be `Result` and `Option` types.\n        TypeLongId::Concrete(semantic::ConcreteTypeId::Enum(enm)) => {\n            let name = enm.enum_id(db.upcast()).name(db.upcast());\n            if name == \"Option\" || name == \"Result\" {\n                if let [ok_variant, err_variant] =\n                    db.concrete_enum_variants(enm).to_option()?.as_slice()\n                {\n                    Some((ok_variant.clone(), err_variant.clone()))\n                } else {\n                    None\n                }\n            } else {\n                None\n            }\n        }\n        TypeLongId::GenericParameter(_) => todo!(\n            \"When generic types are supported, if type is of matching type, allow unwrapping it \\\n             to type.\"\n        ),\n        TypeLongId::Concrete(\n            semantic::ConcreteTypeId::Struct(_) | semantic::ConcreteTypeId::Extern(_),\n        )\n        | TypeLongId::Tuple(_)\n        | TypeLongId::Snapshot(_)\n        | TypeLongId::Var(_)\n        | TypeLongId::Missing(_) => None,\n    }\n}\n\n/// builds a semantic unit expression. This is not necessarily located in the AST, so it is received\n/// as a param.\npub fn unit_expr(ctx: &mut ComputationContext<'_>, stable_ptr: ast::ExprPtr) -> ExprId {\n    ctx.exprs.alloc(Expr::Tuple(ExprTuple {\n        items: Vec::new(),\n        ty: ctx.db.intern_type(TypeLongId::Tuple(Vec::new())),\n        stable_ptr,\n    }))\n}\n\npub fn core_unary_operator(\n    db: &dyn SemanticGroup,\n    inference: &mut Inference<'_>,\n    unary_op: &UnaryOperator,\n    stable_ptr: SyntaxStablePtrId,\n) -> Maybe<Result<ConcreteTraitGenericFunctionId, SemanticDiagnosticKind>> {\n    let (trait_name, function_name) = match unary_op {\n        UnaryOperator::Minus(_) => (\"Neg\", \"neg\"),\n        UnaryOperator::Not(_) => (\"Not\", \"not\"),\n        UnaryOperator::At(_) => unreachable!(\"@ is not an unary operator.\"),\n        UnaryOperator::Desnap(_) => unreachable!(\"* is not an unary operator.\"),\n    };\n    Ok(Ok(get_core_trait_function_infer(\n        db,\n        inference,\n        trait_name.into(),\n        function_name.into(),\n        stable_ptr,\n    )))\n}\n\npub fn core_binary_operator(\n    db: &dyn SemanticGroup,\n    inference: &mut Inference<'_>,\n    binary_op: &BinaryOperator,\n    stable_ptr: SyntaxStablePtrId,\n) -> Maybe<Result<ConcreteTraitGenericFunctionId, SemanticDiagnosticKind>> {\n    let (trait_name, function_name) = match binary_op {\n        BinaryOperator::Plus(_) => (\"Add\", \"add\"),\n        BinaryOperator::PlusEq(_) => (\"AddEq\", \"add_eq\"),\n        BinaryOperator::Minus(_) => (\"Sub\", \"sub\"),\n        BinaryOperator::MinusEq(_) => (\"SubEq\", \"sub_eq\"),\n        BinaryOperator::Mul(_) => (\"Mul\", \"mul\"),\n        BinaryOperator::MulEq(_) => (\"MulEq\", \"mul_eq\"),\n        BinaryOperator::Div(_) => (\"Div\", \"div\"),\n        BinaryOperator::DivEq(_) => (\"DivEq\", \"div_eq\"),\n        BinaryOperator::Mod(_) => (\"Rem\", \"rem\"),\n        BinaryOperator::ModEq(_) => (\"RemEq\", \"rem_eq\"),\n        BinaryOperator::EqEq(_) => (\"PartialEq\", \"eq\"),\n        BinaryOperator::Neq(_) => (\"PartialEq\", \"ne\"),\n        BinaryOperator::LE(_) => (\"PartialOrd\", \"le\"),\n        BinaryOperator::GE(_) => (\"PartialOrd\", \"ge\"),\n        BinaryOperator::LT(_) => (\"PartialOrd\", \"lt\"),\n        BinaryOperator::GT(_) => (\"PartialOrd\", \"gt\"),\n        BinaryOperator::And(_) => (\"BitAnd\", \"bitand\"),\n        BinaryOperator::Or(_) => (\"BitOr\", \"bitor\"),\n        BinaryOperator::Xor(_) => (\"BitXor\", \"bitxor\"),\n        _ => return Ok(Err(SemanticDiagnosticKind::UnknownBinaryOperator)),\n    };\n    Ok(Ok(get_core_trait_function_infer(\n        db,\n        inference,\n        trait_name.into(),\n        function_name.into(),\n        stable_ptr,\n    )))\n}\n\npub fn felt252_eq(db: &dyn SemanticGroup) -> FunctionId {\n    get_core_function_impl_method(db, \"Felt252PartialEq\".into(), \"eq\".into())\n}\n\npub fn felt252_sub(db: &dyn SemanticGroup) -> FunctionId {\n    get_core_function_impl_method(db, \"Felt252Sub\".into(), \"sub\".into())\n}\n\n/// Given a core library impl name and a method name, returns [FunctionId].\nfn get_core_function_impl_method(\n    db: &dyn SemanticGroup,\n    impl_name: SmolStr,\n    method_name: SmolStr,\n) -> FunctionId {\n    let core_module = db.core_module();\n    let module_item_id = db\n        .module_item_by_name(core_module, impl_name.clone())\n        .expect(\"Failed to load core lib.\")\n        .unwrap_or_else(|| panic!(\"Impl '{impl_name}' was not found in core lib.\"));\n    let impl_def_id = match module_item_id {\n        ModuleItemId::Use(use_id) => {\n            db.use_resolved_item(use_id).to_option().and_then(|resolved_generic_item| {\n                try_extract_matches!(resolved_generic_item, ResolvedGenericItem::Impl)\n            })\n        }\n        _ => ImplDefId::option_from(module_item_id),\n    }\n    .unwrap_or_else(|| panic!(\"{impl_name} is not an impl.\"));\n    let impl_id = ImplId::Concrete(\n        db.intern_concrete_impl(ConcreteImplLongId { impl_def_id, generic_args: vec![] }),\n    );\n    let concrete_trait_id = db.impl_concrete_trait(impl_id).unwrap();\n    let function = db\n        .trait_functions(concrete_trait_id.trait_id(db))\n        .ok()\n        .and_then(|functions| functions.get(&method_name).cloned())\n        .unwrap_or_else(|| {\n            panic!(\"no {method_name} in {}.\", concrete_trait_id.trait_id(db).name(db.upcast()))\n        });\n    db.intern_function(FunctionLongId {\n        function: ConcreteFunction {\n            generic_function: GenericFunctionId::Impl(ImplGenericFunctionId { impl_id, function }),\n            generic_args: vec![],\n        },\n    })\n}\n\npub fn core_felt252_is_zero(db: &dyn SemanticGroup) -> FunctionId {\n    get_core_function_id(db, \"felt252_is_zero\".into(), vec![])\n}\n\n/// Given a core library function name and its generic arguments, returns [FunctionId].\npub fn get_core_function_id(\n    db: &dyn SemanticGroup,\n    name: SmolStr,\n    generic_args: Vec<GenericArgumentId>,\n) -> FunctionId {\n    let generic_function = get_core_generic_function_id(db, name);\n\n    db.intern_function(FunctionLongId {\n        function: ConcreteFunction { generic_function, generic_args },\n    })\n}\n\n/// Given a core library function name, returns [GenericFunctionId].\npub fn get_core_generic_function_id(db: &dyn SemanticGroup, name: SmolStr) -> GenericFunctionId {\n    let core_module = db.core_module();\n    let module_item_id = db\n        .module_item_by_name(core_module, name.clone())\n        .expect(\"Failed to load core lib.\")\n        .unwrap_or_else(|| panic!(\"Function '{name}' was not found in core lib.\"));\n    match module_item_id {\n        ModuleItemId::Use(use_id) => {\n            db.use_resolved_item(use_id).to_option().and_then(|resolved_generic_item| {\n                try_extract_matches!(resolved_generic_item, ResolvedGenericItem::GenericFunction)\n            })\n        }\n        _ => GenericFunctionId::option_from(module_item_id),\n    }\n    .unwrap_or_else(|| panic!(\"{name} is not a function.\"))\n}\n\npub fn concrete_copy_trait(db: &dyn SemanticGroup, ty: TypeId) -> ConcreteTraitId {\n    get_core_concrete_trait(db, \"Copy\".into(), vec![GenericArgumentId::Type(ty)])\n}\n\npub fn concrete_drop_trait(db: &dyn SemanticGroup, ty: TypeId) -> ConcreteTraitId {\n    get_core_concrete_trait(db, \"Drop\".into(), vec![GenericArgumentId::Type(ty)])\n}\n\npub fn concrete_destruct_trait(db: &dyn SemanticGroup, ty: TypeId) -> ConcreteTraitId {\n    get_core_concrete_trait(db, \"Destruct\".into(), vec![GenericArgumentId::Type(ty)])\n}\n\npub fn copy_trait(db: &dyn SemanticGroup) -> TraitId {\n    get_core_trait(db, \"Copy\".into())\n}\n\npub fn drop_trait(db: &dyn SemanticGroup) -> TraitId {\n    get_core_trait(db, \"Drop\".into())\n}\n\npub fn destruct_trait(db: &dyn SemanticGroup) -> TraitId {\n    get_core_trait(db, \"Destruct\".into())\n}\n\n/// Given a core library trait name and its generic arguments, returns [ConcreteTraitId].\nfn get_core_concrete_trait(\n    db: &dyn SemanticGroup,\n    name: SmolStr,\n    generic_args: Vec<GenericArgumentId>,\n) -> ConcreteTraitId {\n    let trait_id = get_core_trait(db, name);\n    db.intern_concrete_trait(semantic::ConcreteTraitLongId { trait_id, generic_args })\n}\n\n/// Given a core library trait name, returns [TraitId].\npub fn get_core_trait(db: &dyn SemanticGroup, name: SmolStr) -> TraitId {\n    let core_module = db.core_module();\n    // This should not fail if the corelib is present.\n    let use_id = extract_matches!(\n        db.module_item_by_name(core_module, name).unwrap().unwrap(),\n        ModuleItemId::Use\n    );\n    let trait_id =\n        extract_matches!(db.use_resolved_item(use_id).unwrap(), ResolvedGenericItem::Trait);\n    trait_id\n}\n\n/// Retrieves a trait function from the core library with type variables as generic arguments, to\n/// be inferred later.\nfn get_core_trait_function_infer(\n    db: &dyn SemanticGroup,\n    inference: &mut Inference<'_>,\n    trait_name: SmolStr,\n    function_name: SmolStr,\n    stable_ptr: SyntaxStablePtrId,\n) -> ConcreteTraitGenericFunctionId {\n    let trait_id = get_core_trait(db, trait_name);\n    let generic_params = db.trait_generic_params(trait_id);\n    let generic_args = generic_params\n        .iter()\n        .map(|_| GenericArgumentId::Type(inference.new_type_var(stable_ptr)))\n        .collect();\n    let concrete_trait_id =\n        db.intern_concrete_trait(semantic::ConcreteTraitLongId { trait_id, generic_args });\n    let trait_function = db.trait_function_by_name(trait_id, function_name).unwrap().unwrap();\n    db.intern_concrete_trait_function(ConcreteTraitGenericFunctionLongId::new(\n        db,\n        concrete_trait_id,\n        trait_function,\n    ))\n}\n\npub fn get_panic_ty(db: &dyn SemanticGroup, inner_ty: TypeId) -> TypeId {\n    get_core_ty_by_name(db.upcast(), \"PanicResult\".into(), vec![GenericArgumentId::Type(inner_ty)])\n}\n\n/// Returns the name of the libfunc that creates a constant of type `ty`;\npub fn get_const_libfunc_name_by_type(db: &dyn SemanticGroup, ty: TypeId) -> String {\n    if ty == core_felt252_ty(db) {\n        \"felt252_const\".into()\n    } else if ty == get_core_ty_by_name(db, \"u8\".into(), vec![]) {\n        \"u8_const\".into()\n    } else if ty == get_core_ty_by_name(db, \"u16\".into(), vec![]) {\n        \"u16_const\".into()\n    } else if ty == get_core_ty_by_name(db, \"u32\".into(), vec![]) {\n        \"u32_const\".into()\n    } else if ty == get_core_ty_by_name(db, \"u64\".into(), vec![]) {\n        \"u64_const\".into()\n    } else if ty == get_core_ty_by_name(db, \"u128\".into(), vec![]) {\n        \"u128_const\".into()\n    } else {\n        panic!(\"No const libfunc for type {}.\", ty.format(db))\n    }\n}\n\n/// Validates that a given type is valid for a literal and that the value fits the range of the\n/// specific type.\npub fn validate_literal(\n    db: &dyn SemanticGroup,\n    ty: TypeId,\n    value: BigInt,\n) -> Result<(), SemanticDiagnosticKind> {\n    let is_out_of_range = if ty == core_felt252_ty(db) {\n        value.is_negative()\n            || value\n                > BigInt::from_str_radix(\n                    \"800000000000011000000000000000000000000000000000000000000000000\",\n                    16,\n                )\n                .unwrap()\n    } else if ty == get_core_ty_by_name(db, \"u8\".into(), vec![]) {\n        value.is_negative() || value.bits() > 8\n    } else if ty == get_core_ty_by_name(db, \"u16\".into(), vec![]) {\n        value.is_negative() || value.bits() > 16\n    } else if ty == get_core_ty_by_name(db, \"u32\".into(), vec![]) {\n        value.is_negative() || value.bits() > 32\n    } else if ty == get_core_ty_by_name(db, \"u64\".into(), vec![]) {\n        value.is_negative() || value.bits() > 64\n    } else if ty == get_core_ty_by_name(db, \"u128\".into(), vec![]) {\n        value.is_negative() || value.bits() > 128\n    } else {\n        return Err(SemanticDiagnosticKind::NoLiteralFunctionFound);\n    };\n    if is_out_of_range { Err(SemanticDiagnosticKind::LiteralOutOfRange { ty }) } else { Ok(()) }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashSet;\nuse std::sync::Arc;\n\nuse cairo_lang_defs::db::{DefsGroup, GeneratedFileInfo};\nuse cairo_lang_defs::diagnostic_utils::StableLocation;\nuse cairo_lang_defs::ids::{\n    ConstantId, EnumId, ExternFunctionId, ExternTypeId, FreeFunctionId, FunctionTitleId,\n    FunctionWithBodyId, GenericParamId, GenericTypeId, ImplDefId, ImplFunctionId,\n    LanguageElementId, LookupItemId, ModuleId, ModuleItemId, StructId, TraitFunctionId, TraitId,\n    TypeAliasId, UseId, VariantId,\n};\nuse cairo_lang_defs::plugin::MacroPlugin;\nuse cairo_lang_diagnostics::{Diagnostics, DiagnosticsBuilder, Maybe};\nuse cairo_lang_filesystem::db::{AsFilesGroupMut, FilesGroup};\nuse cairo_lang_filesystem::ids::{CrateId, FileId, FileLongId};\nuse cairo_lang_parser::db::ParserGroup;\nuse cairo_lang_syntax::node::ast;\nuse cairo_lang_syntax::node::stable_ptr::SyntaxStablePtr;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse cairo_lang_utils::Upcast;\nuse smol_str::SmolStr;\n\nuse crate::diagnostic::SemanticDiagnosticKind;\nuse crate::items::attribute::Attribute;\nuse crate::items::constant::Constant;\nuse crate::items::function_with_body::FunctionBody;\nuse crate::items::functions::InlineConfiguration;\nuse crate::items::generics::GenericParam;\nuse crate::items::imp::{ImplId, ImplLookupContext};\nuse crate::items::module::ModuleSemanticData;\nuse crate::items::trt::{ConcreteTraitGenericFunctionId, ConcreteTraitId};\nuse crate::plugin::{DynPluginAuxData, SemanticPlugin};\nuse crate::resolve_path::{ResolvedConcreteItem, ResolvedGenericItem, ResolvedLookback};\nuse crate::{\n    corelib, items, literals, semantic, types, FunctionId, Parameter, SemanticDiagnostic, TypeId,\n};\n\n/// Helper trait to make sure we can always get a `dyn SemanticGroup + 'static` from a\n/// SemanticGroup.\npub trait Elongate {\n    fn elongate(&self) -> &(dyn SemanticGroup + 'static);\n}\n\n// Salsa database interface.\n// All queries starting with priv_ are for internal use only by this crate.\n// They appear in the public API because of salsa limitations.\n// We differentiate between the declaration and the definition of each item:\n// Declarations and definitions must not depend on other definitions, only other declarations.\n// This prevents cycles where there shouldn't be any.\n#[salsa::query_group(SemanticDatabase)]\npub trait SemanticGroup:\n    DefsGroup\n    + Upcast<dyn DefsGroup>\n    + ParserGroup\n    + Upcast<dyn FilesGroup>\n    + AsFilesGroupMut\n    + Elongate\n{\n    #[salsa::interned]\n    fn intern_function(&self, id: items::functions::FunctionLongId) -> semantic::FunctionId;\n    #[salsa::interned]\n    fn intern_concrete_function_with_body(\n        &self,\n        id: items::functions::ConcreteFunctionWithBody,\n    ) -> semantic::ConcreteFunctionWithBodyId;\n    #[salsa::interned]\n    fn intern_concrete_struct(&self, id: types::ConcreteStructLongId) -> types::ConcreteStructId;\n    #[salsa::interned]\n    fn intern_concrete_enum(&self, id: types::ConcreteEnumLongId) -> types::ConcreteEnumId;\n    #[salsa::interned]\n    fn intern_concrete_extern_type(\n        &self,\n        id: types::ConcreteExternTypeLongId,\n    ) -> types::ConcreteExternTypeId;\n    #[salsa::interned]\n    fn intern_concrete_trait(\n        &self,\n        id: items::trt::ConcreteTraitLongId,\n    ) -> items::trt::ConcreteTraitId;\n    #[salsa::interned]\n    fn intern_concrete_trait_function(\n        &self,\n        id: items::trt::ConcreteTraitGenericFunctionLongId,\n    ) -> items::trt::ConcreteTraitGenericFunctionId;\n    #[salsa::interned]\n    fn intern_concrete_impl(\n        &self,\n        id: items::imp::ConcreteImplLongId,\n    ) -> items::imp::ConcreteImplId;\n    #[salsa::interned]\n    fn intern_type(&self, id: types::TypeLongId) -> semantic::TypeId;\n    #[salsa::interned]\n    fn intern_literal(&self, id: literals::LiteralLongId) -> literals::LiteralId;\n\n    // Const.\n    // ====\n    /// Private query to compute data about a constant definition.\n    #[salsa::invoke(items::constant::priv_constant_semantic_data)]\n    fn priv_constant_semantic_data(\n        &self,\n        const_id: ConstantId,\n    ) -> Maybe<items::constant::ConstantData>;\n    /// Returns the semantic diagnostics of a constant definition.\n    #[salsa::invoke(items::constant::constant_semantic_diagnostics)]\n    fn constant_semantic_diagnostics(\n        &self,\n        const_id: ConstantId,\n    ) -> Diagnostics<SemanticDiagnostic>;\n    /// Returns the semantic data of a constant definition.\n    #[salsa::invoke(items::constant::constant_semantic_data)]\n    fn constant_semantic_data(&self, use_id: ConstantId) -> Maybe<Constant>;\n    #[salsa::invoke(items::constant::constant_resolved_lookback)]\n    fn constant_resolved_lookback(&self, use_id: ConstantId) -> Maybe<Arc<ResolvedLookback>>;\n\n    // Use.\n    // ====\n    /// Private query to compute data about a use.\n    #[salsa::invoke(items::us::priv_use_semantic_data)]\n    #[salsa::cycle(items::us::priv_use_semantic_data_cycle)]\n    fn priv_use_semantic_data(&self, use_id: UseId) -> Maybe<items::us::UseData>;\n    /// Returns the semantic diagnostics of a use.\n    #[salsa::invoke(items::us::use_semantic_diagnostics)]\n    fn use_semantic_diagnostics(&self, use_id: UseId) -> Diagnostics<SemanticDiagnostic>;\n    #[salsa::invoke(items::us::use_resolved_lookback)]\n    fn use_resolved_lookback(&self, use_id: UseId) -> Maybe<Arc<ResolvedLookback>>;\n\n    // Module.\n    // ====\n\n    /// Private query to compute data about the module.\n    #[salsa::invoke(items::module::priv_module_items_data)]\n    fn priv_module_items_data(&self, module_id: ModuleId) -> Maybe<Arc<ModuleSemanticData>>;\n\n    /// Returns [Maybe::Err] if the module was not properly resolved.\n    /// Returns [Maybe::Ok(Option::None)] if the item does not exist.\n    #[salsa::invoke(items::module::module_item_by_name)]\n    fn module_item_by_name(\n        &self,\n        module_id: ModuleId,\n        name: SmolStr,\n    ) -> Maybe<Option<ModuleItemId>>;\n\n    /// Returns the attributes of a module\n    // TODO(ilya): Move impl to module.rs.\n    #[salsa::invoke(items::attribute::module_attributes)]\n    fn module_attributes(&self, module_id: ModuleId) -> Maybe<Vec<Attribute>>;\n\n    // Struct.\n    // =======\n    /// Private query to compute data about a struct declaration.\n    #[salsa::invoke(items::structure::priv_struct_declaration_data)]\n    fn priv_struct_declaration_data(\n        &self,\n        struct_id: StructId,\n    ) -> Maybe<items::structure::StructDeclarationData>;\n    /// Returns the declaration diagnostics of a struct.\n    #[salsa::invoke(items::structure::struct_declaration_diagnostics)]\n    fn struct_declaration_diagnostics(\n        &self,\n        struct_id: StructId,\n    ) -> Diagnostics<SemanticDiagnostic>;\n    /// Returns the attributes of a struct.\n    #[salsa::invoke(items::structure::struct_attributes)]\n    fn struct_attributes(&self, struct_id: StructId) -> Maybe<Vec<Attribute>>;\n    /// Returns the generic parameters of an enum.\n    #[salsa::invoke(items::structure::struct_generic_params)]\n    fn struct_generic_params(&self, struct_id: StructId) -> Maybe<Vec<GenericParam>>;\n    /// Returns the resolution lookback of a struct declaration.\n    #[salsa::invoke(items::structure::struct_declaration_resolved_lookback)]\n    fn struct_declaration_resolved_lookback(\n        &self,\n        structure_id: StructId,\n    ) -> Maybe<Arc<ResolvedLookback>>;\n\n    /// Private query to compute data about a struct definition.\n    #[salsa::invoke(items::structure::priv_struct_definition_data)]\n    fn priv_struct_definition_data(\n        &self,\n        struct_id: StructId,\n    ) -> Maybe<items::structure::StructDefinitionData>;\n    /// Returns the semantic diagnostics of a struct definition.\n    #[salsa::invoke(items::structure::struct_definition_diagnostics)]\n    fn struct_definition_diagnostics(&self, struct_id: StructId)\n    -> Diagnostics<SemanticDiagnostic>;\n    /// Returns the members of a struct.\n    #[salsa::invoke(items::structure::struct_members)]\n    fn struct_members(\n        &self,\n        struct_id: StructId,\n    ) -> Maybe<OrderedHashMap<SmolStr, semantic::Member>>;\n    /// Returns the resolution lookback of a struct definition.\n    #[salsa::invoke(items::structure::struct_definition_resolved_lookback)]\n    fn struct_definition_resolved_lookback(\n        &self,\n        structure_id: StructId,\n    ) -> Maybe<Arc<ResolvedLookback>>;\n\n    // Enum.\n    // =======\n    /// Private query to compute data about an enum declaration.\n    #[salsa::invoke(items::enm::priv_enum_declaration_data)]\n    fn priv_enum_declaration_data(&self, enum_id: EnumId)\n    -> Maybe<items::enm::EnumDeclarationData>;\n    /// Returns the diagnostics of an enum declaration.\n    #[salsa::invoke(items::enm::enum_declaration_diagnostics)]\n    fn enum_declaration_diagnostics(&self, enum_id: EnumId) -> Diagnostics<SemanticDiagnostic>;\n    /// Returns the generic parameters of an enum.\n    #[salsa::invoke(items::enm::enum_generic_params)]\n    fn enum_generic_params(&self, enum_id: EnumId) -> Maybe<Vec<GenericParam>>;\n    /// Returns the resolution lookback of an enum declaration.\n    #[salsa::invoke(items::enm::enum_declaration_resolved_lookback)]\n    fn enum_declaration_resolved_lookback(&self, enum_id: EnumId) -> Maybe<Arc<ResolvedLookback>>;\n\n    /// Private query to compute data about an enum definition.\n    #[salsa::invoke(items::enm::priv_enum_definition_data)]\n    fn priv_enum_definition_data(&self, enum_id: EnumId) -> Maybe<items::enm::EnumDefinitionData>;\n    /// Returns the definition diagnostics of an enum definition.\n    #[salsa::invoke(items::enm::enum_definition_diagnostics)]\n    fn enum_definition_diagnostics(&self, enum_id: EnumId) -> Diagnostics<SemanticDiagnostic>;\n    /// Returns the members of an enum.\n    #[salsa::invoke(items::enm::enum_variants)]\n    fn enum_variants(&self, enum_id: EnumId) -> Maybe<OrderedHashMap<SmolStr, VariantId>>;\n    /// Returns the semantic model of a variant.\n    #[salsa::invoke(items::enm::variant_semantic)]\n    fn variant_semantic(&self, enum_id: EnumId, variant_id: VariantId) -> Maybe<semantic::Variant>;\n    /// Returns the resolution lookback of an enum definition.\n    #[salsa::invoke(items::enm::enum_definition_resolved_lookback)]\n    fn enum_definition_resolved_lookback(&self, enum_id: EnumId) -> Maybe<Arc<ResolvedLookback>>;\n\n    // Type Alias.\n    // ====\n    /// Private query to compute data about a type alias.\n    #[salsa::invoke(items::type_alias::priv_type_alias_semantic_data)]\n    #[salsa::cycle(items::type_alias::priv_type_alias_semantic_data_cycle)]\n    fn priv_type_alias_semantic_data(\n        &self,\n        type_alias_id: TypeAliasId,\n    ) -> Maybe<items::type_alias::TypeAliasData>;\n    /// Returns the semantic diagnostics of a type alias.\n    #[salsa::invoke(items::type_alias::type_alias_semantic_diagnostics)]\n    fn type_alias_semantic_diagnostics(\n        &self,\n        type_alias_id: TypeAliasId,\n    ) -> Diagnostics<SemanticDiagnostic>;\n    /// Returns the resolved type of a type alias.\n    #[salsa::invoke(items::type_alias::type_alias_resolved_type)]\n    fn type_alias_resolved_type(&self, type_alias_id: TypeAliasId) -> Maybe<TypeId>;\n    /// Returns the generic parameters of a type alias.\n    #[salsa::invoke(items::type_alias::type_alias_generic_params)]\n    fn type_alias_generic_params(&self, enum_id: TypeAliasId) -> Maybe<Vec<GenericParam>>;\n    /// Returns the resolution lookback of a type alias.\n    #[salsa::invoke(items::type_alias::type_alias_resolved_lookback)]\n    fn type_alias_resolved_lookback(\n        &self,\n        type_alias_id: TypeAliasId,\n    ) -> Maybe<Arc<ResolvedLookback>>;\n\n    // Trait.\n    // =======\n    /// Private query to compute data about a trait.\n    #[salsa::invoke(items::trt::priv_trait_semantic_data)]\n    fn priv_trait_semantic_data(&self, trait_id: TraitId) -> Maybe<items::trt::TraitData>;\n    /// Returns the semantic diagnostics of a trait.\n    #[salsa::invoke(items::trt::trait_semantic_diagnostics)]\n    fn trait_semantic_diagnostics(&self, trait_id: TraitId) -> Diagnostics<SemanticDiagnostic>;\n    /// Returns the generic parameters of a trait.\n    #[salsa::invoke(items::trt::trait_generic_params)]\n    fn trait_generic_params(&self, trait_id: TraitId) -> Maybe<Vec<GenericParam>>;\n    /// Returns the attributes of a trait.\n    #[salsa::invoke(items::trt::trait_attributes)]\n    fn trait_attributes(&self, trait_id: TraitId) -> Maybe<Vec<Attribute>>;\n    /// Returns the functions of a trait.\n    #[salsa::invoke(items::trt::trait_functions)]\n    fn trait_functions(&self, trait_id: TraitId)\n    -> Maybe<OrderedHashMap<SmolStr, TraitFunctionId>>;\n    /// Returns the function with the given name of the given trait, if exists.\n    #[salsa::invoke(items::trt::trait_function_by_name)]\n    fn trait_function_by_name(\n        &self,\n        trait_id: TraitId,\n        name: SmolStr,\n    ) -> Maybe<Option<TraitFunctionId>>;\n\n    // Trait function.\n    // ================\n    /// Private query to compute data about a trait function.\n    #[salsa::invoke(items::trt::priv_trait_function_data)]\n    fn priv_trait_function_data(\n        &self,\n        function_id: TraitFunctionId,\n    ) -> Maybe<items::trt::TraitFunctionData>;\n    /// Returns the semantic diagnostics of a trait function.\n    #[salsa::invoke(items::trt::trait_function_diagnostics)]\n    fn trait_function_diagnostics(\n        &self,\n        trait_function_id: TraitFunctionId,\n    ) -> Diagnostics<SemanticDiagnostic>;\n    /// Returns the signature of a trait function.\n    #[salsa::invoke(items::trt::trait_function_signature)]\n    fn trait_function_signature(\n        &self,\n        trait_function_id: TraitFunctionId,\n    ) -> Maybe<semantic::Signature>;\n    /// Returns the attributes of a trait function.\n    #[salsa::invoke(items::trt::trait_function_attributes)]\n    fn trait_function_attributes(\n        &self,\n        trait_function_id: TraitFunctionId,\n    ) -> Maybe<Vec<Attribute>>;\n    /// Returns the generic params of a trait function.\n    #[salsa::invoke(items::trt::trait_function_generic_params)]\n    fn trait_function_generic_params(\n        &self,\n        trait_function_id: TraitFunctionId,\n    ) -> Maybe<Vec<GenericParam>>;\n    /// Returns the resolution lookback of a trait function.\n    #[salsa::invoke(items::trt::trait_function_resolved_lookback)]\n    fn trait_function_resolved_lookback(\n        &self,\n        trait_function_id: TraitFunctionId,\n    ) -> Maybe<Arc<ResolvedLookback>>;\n    /// Returns the generic params of a concrete trait function.\n    #[salsa::invoke(items::trt::concrete_trait_function_generic_params)]\n    fn concrete_trait_function_generic_params(\n        &self,\n        concrete_trait_function_id: ConcreteTraitGenericFunctionId,\n    ) -> Maybe<Vec<GenericParam>>;\n    /// Returns the signature of a concrete trait function.\n    #[salsa::invoke(items::trt::concrete_trait_function_signature)]\n    fn concrete_trait_function_signature(\n        &self,\n        concrete_trait_function_id: ConcreteTraitGenericFunctionId,\n    ) -> Maybe<semantic::Signature>;\n\n    // Impl.\n    // =======\n    /// Private query to compute declaration data about an impl.\n    #[salsa::invoke(items::imp::priv_impl_declaration_data)]\n    #[salsa::cycle(items::imp::priv_impl_declaration_data_cycle)]\n    fn priv_impl_declaration_data(\n        &self,\n        impl_def_id: ImplDefId,\n    ) -> Maybe<items::imp::ImplDeclarationData>;\n    /// Returns the semantic declaration diagnostics of an impl.\n    #[salsa::invoke(items::imp::impl_semantic_declaration_diagnostics)]\n    fn impl_semantic_declaration_diagnostics(\n        &self,\n        impl_def_id: ImplDefId,\n    ) -> Diagnostics<SemanticDiagnostic>;\n    /// Returns the generic parameters of an impl.\n    #[salsa::invoke(items::imp::impl_def_generic_params)]\n    fn impl_def_generic_params(&self, impl_def_id: ImplDefId) -> Maybe<Vec<GenericParam>>;\n    /// Returns the resolution lookback of an impl.\n    #[salsa::invoke(items::imp::impl_def_resolved_lookback)]\n    fn impl_def_resolved_lookback(&self, impl_def_id: ImplDefId) -> Maybe<Arc<ResolvedLookback>>;\n    /// Returns the concrete trait that is implemented by the impl.\n    #[salsa::invoke(items::imp::impl_def_concrete_trait)]\n    fn impl_def_concrete_trait(&self, impl_def_id: ImplDefId) -> Maybe<ConcreteTraitId>;\n    /// Returns the concrete trait that is implemented by the concrete impl.\n    #[salsa::invoke(items::imp::impl_concrete_trait)]\n    fn impl_concrete_trait(&self, impl_id: ImplId) -> Maybe<ConcreteTraitId>;\n    /// Private query to compute data about an impl.\n    #[salsa::invoke(items::imp::priv_impl_definition_data)]\n    fn priv_impl_definition_data(\n        &self,\n        impl_def_id: ImplDefId,\n    ) -> Maybe<items::imp::ImplDefinitionData>;\n    /// Returns the semantic definition diagnostics of an impl.\n    #[salsa::invoke(items::imp::impl_semantic_definition_diagnostics)]\n    fn impl_semantic_definition_diagnostics(\n        &self,\n        impl_def_id: ImplDefId,\n    ) -> Diagnostics<SemanticDiagnostic>;\n    /// Returns the functions in the impl.\n    #[salsa::invoke(items::imp::impl_functions)]\n    fn impl_functions(\n        &self,\n        impl_def_id: ImplDefId,\n    ) -> Maybe<OrderedHashMap<SmolStr, ImplFunctionId>>;\n    /// Returns the impl function that matches the given trait function, if exists.\n    /// Note that a function that doesn't exist in the impl doesn't necessarily indicate an error,\n    /// as, e.g., a trait function that has a default implementation doesn't have to be\n    /// implemented in the impl.\n    #[salsa::invoke(items::imp::impl_function_by_trait_function)]\n    fn impl_function_by_trait_function(\n        &self,\n        impl_def_id: ImplDefId,\n        trait_function_id: TraitFunctionId,\n    ) -> Maybe<Option<ImplFunctionId>>;\n    /// Returns candidate [ImplDefId]s for a specific trait lookup constraint.\n    #[salsa::invoke(items::imp::module_impl_ids_for_trait_info)]\n    fn module_impl_ids_for_trait_info(\n        &self,\n        module_id: ModuleId,\n        trait_lookup_constraint: items::imp::TraitFilter,\n    ) -> Maybe<Vec<ImplDefId>>;\n\n    // Impl function.\n    // ================\n    /// Returns the signature of an impl function.\n    #[salsa::invoke(items::imp::impl_function_signature)]\n    fn impl_function_signature(\n        &self,\n        impl_function_id: ImplFunctionId,\n    ) -> Maybe<semantic::Signature>;\n    /// Returns the explicit implicits of a signature of an impl function.\n    #[salsa::invoke(items::imp::impl_function_declaration_implicits)]\n    fn impl_function_declaration_implicits(\n        &self,\n        impl_function_id: ImplFunctionId,\n    ) -> Maybe<Vec<TypeId>>;\n    /// Returns the generic params of an impl function.\n    #[salsa::invoke(items::imp::impl_function_generic_params)]\n    fn impl_function_generic_params(\n        &self,\n        impl_function_id: ImplFunctionId,\n    ) -> Maybe<Vec<GenericParam>>;\n    /// Returns the semantic diagnostics of an impl function's declaration (signature).\n    #[salsa::invoke(items::imp::impl_function_declaration_diagnostics)]\n    fn impl_function_declaration_diagnostics(\n        &self,\n        impl_function_id: ImplFunctionId,\n    ) -> Diagnostics<SemanticDiagnostic>;\n    /// Returns the resolution lookback of an impl function's declaration.\n    #[salsa::invoke(items::imp::impl_function_resolved_lookback)]\n    fn impl_function_resolved_lookback(\n        &self,\n        impl_function_id: ImplFunctionId,\n    ) -> Maybe<Arc<ResolvedLookback>>;\n    /// Returns the inline configuration of an impl function's declaration.\n    #[salsa::invoke(items::imp::impl_function_declaration_inline_config)]\n    fn impl_function_declaration_inline_config(\n        &self,\n        impl_function_id: ImplFunctionId,\n    ) -> Maybe<InlineConfiguration>;\n    /// Returns the trait function of an impl function.\n    #[salsa::invoke(items::imp::impl_function_trait_function)]\n    fn impl_function_trait_function(\n        &self,\n        impl_function_id: ImplFunctionId,\n    ) -> Maybe<TraitFunctionId>;\n    /// Private query to compute data about an impl function declaration.\n    #[salsa::invoke(items::imp::priv_impl_function_declaration_data)]\n    fn priv_impl_function_declaration_data(\n        &self,\n        impl_function_id: ImplFunctionId,\n    ) -> Maybe<items::imp::ImplFunctionDeclarationData>;\n\n    /// Returns the semantic diagnostics of an impl function definition (declaration + body).\n    #[salsa::invoke(items::imp::impl_function_body_diagnostics)]\n    fn impl_function_body_diagnostics(\n        &self,\n        impl_function_id: ImplFunctionId,\n    ) -> Diagnostics<SemanticDiagnostic>;\n    /// Returns the definition of an impl function.\n    #[salsa::invoke(items::imp::impl_function_body)]\n    fn impl_function_body(&self, impl_function_id: ImplFunctionId) -> Maybe<Arc<FunctionBody>>;\n    /// Returns the resolution lookback of an impl function's definition.\n    #[salsa::invoke(items::imp::impl_function_body_resolved_lookback)]\n    fn impl_function_body_resolved_lookback(\n        &self,\n        impl_function_id: ImplFunctionId,\n    ) -> Maybe<Arc<ResolvedLookback>>;\n    /// Private query to compute data about an impl function definition (declaration + body)\n    #[salsa::invoke(items::imp::priv_impl_function_body_data)]\n    fn priv_impl_function_body_data(\n        &self,\n        impl_function_id: ImplFunctionId,\n    ) -> Maybe<items::function_with_body::FunctionBodyData>;\n\n    // Free function.\n    // ==============\n    /// Returns the semantic diagnostics of a free function's declaration (signature).\n    #[salsa::invoke(items::free_function::free_function_declaration_diagnostics)]\n    fn free_function_declaration_diagnostics(\n        &self,\n        free_function_id: FreeFunctionId,\n    ) -> Diagnostics<SemanticDiagnostic>;\n    /// Returns the signature of a free function.\n    #[salsa::invoke(items::free_function::free_function_signature)]\n    fn free_function_signature(\n        &self,\n        free_function_id: FreeFunctionId,\n    ) -> Maybe<semantic::Signature>;\n    /// Returns the explicit implicits of a signature of a free function.\n    #[salsa::invoke(items::free_function::free_function_declaration_implicits)]\n    fn free_function_declaration_implicits(\n        &self,\n        free_function_id: FreeFunctionId,\n    ) -> Maybe<Vec<TypeId>>;\n    /// Returns the generic params of a free function.\n    #[salsa::invoke(items::free_function::free_function_generic_params)]\n    fn free_function_generic_params(\n        &self,\n        free_function_id: FreeFunctionId,\n    ) -> Maybe<Vec<GenericParam>>;\n    /// Returns the resolution lookback of a free function's declaration.\n    #[salsa::invoke(items::free_function::free_function_declaration_resolved_lookback)]\n    fn free_function_declaration_resolved_lookback(\n        &self,\n        free_function_id: FreeFunctionId,\n    ) -> Maybe<Arc<ResolvedLookback>>;\n    /// Returns the inline configuration of a free function's declaration.\n    #[salsa::invoke(items::free_function::free_function_declaration_inline_config)]\n    fn free_function_declaration_inline_config(\n        &self,\n        free_function_id: FreeFunctionId,\n    ) -> Maybe<InlineConfiguration>;\n    /// Private query to compute data about a free function declaration - its signature excluding\n    /// its body.\n    #[salsa::invoke(items::free_function::priv_free_function_declaration_data)]\n    fn priv_free_function_declaration_data(\n        &self,\n        function_id: FreeFunctionId,\n    ) -> Maybe<items::functions::FunctionDeclarationData>;\n\n    /// Returns the semantic diagnostics of a free function's body.\n    #[salsa::invoke(items::free_function::free_function_body_diagnostics)]\n    fn free_function_body_diagnostics(\n        &self,\n        free_function_id: FreeFunctionId,\n    ) -> Diagnostics<SemanticDiagnostic>;\n    /// Returns the resolution lookback of a free function's body.\n    #[salsa::invoke(items::free_function::free_function_body_resolved_lookback)]\n    fn free_function_body_resolved_lookback(\n        &self,\n        free_function_id: FreeFunctionId,\n    ) -> Maybe<Arc<ResolvedLookback>>;\n    /// Private query to compute data about a free function's body.\n    #[salsa::invoke(items::free_function::priv_free_function_body_data)]\n    fn priv_free_function_body_data(\n        &self,\n        free_function_id: FreeFunctionId,\n    ) -> Maybe<items::function_with_body::FunctionBodyData>;\n\n    // Function with body.\n    // ===================\n    /// Returns the semantic diagnostics of a declaration (signature) of a function with a body.\n    #[salsa::invoke(items::function_with_body::function_declaration_diagnostics)]\n    fn function_declaration_diagnostics(\n        &self,\n        function_id: FunctionWithBodyId,\n    ) -> Diagnostics<SemanticDiagnostic>;\n    /// Returns the inline configuration of a declaration (signature) of a function with a body.\n    #[salsa::invoke(items::function_with_body::function_declaration_inline_config)]\n    fn function_declaration_inline_config(\n        &self,\n        function_id: FunctionWithBodyId,\n    ) -> Maybe<InlineConfiguration>;\n    /// Returns the signature of a function with a body.\n    #[salsa::invoke(items::function_with_body::function_with_body_signature)]\n    fn function_with_body_signature(\n        &self,\n        function_id: FunctionWithBodyId,\n    ) -> Maybe<semantic::Signature>;\n    /// Returns all the available generic params inside a function body.\n    #[salsa::invoke(items::function_with_body::function_with_body_generic_params)]\n    fn function_with_body_generic_params(\n        &self,\n        function_id: FunctionWithBodyId,\n    ) -> Maybe<Vec<GenericParam>>;\n    /// Returns the attributes of a function with a body.\n    #[salsa::invoke(items::function_with_body::function_with_body_attributes)]\n    fn function_with_body_attributes(\n        &self,\n        function_id: FunctionWithBodyId,\n    ) -> Maybe<Vec<Attribute>>;\n\n    /// Returns the semantic diagnostics of a body of a function (with a body).\n    #[salsa::invoke(items::function_with_body::function_body_diagnostics)]\n    fn function_body_diagnostics(\n        &self,\n        function_id: FunctionWithBodyId,\n    ) -> Diagnostics<SemanticDiagnostic>;\n    /// Returns the body expr of a function (with a body).\n    #[salsa::invoke(items::function_with_body::function_body_expr)]\n    fn function_body_expr(&self, function_id: FunctionWithBodyId) -> Maybe<semantic::ExprId>;\n    /// Returns the body of a function (with a body).\n    #[salsa::invoke(items::function_with_body::function_body)]\n    fn function_body(&self, function_id: FunctionWithBodyId) -> Maybe<Arc<FunctionBody>>;\n    /// Returns the set of direct callees of a function with a body.\n    #[salsa::invoke(items::function_with_body::function_with_body_direct_callees)]\n    fn function_with_body_direct_callees(\n        &self,\n        function_id: FunctionWithBodyId,\n    ) -> Maybe<HashSet<FunctionId>>;\n    /// Returns the set of direct callees which are functions with body of a function with a body\n    /// (i.e. excluding libfunc callees).\n    #[salsa::invoke(\n        items::function_with_body::function_with_body_direct_function_with_body_callees\n    )]\n    fn function_with_body_direct_function_with_body_callees(\n        &self,\n        function_id: FunctionWithBodyId,\n    ) -> Maybe<HashSet<FunctionWithBodyId>>;\n\n    // Extern function.\n    // ================\n    /// Private query to compute data about an extern function declaration. An extern function has\n    /// no body, and thus only has a declaration.\n    #[salsa::invoke(items::extern_function::priv_extern_function_declaration_data)]\n    fn priv_extern_function_declaration_data(\n        &self,\n        function_id: ExternFunctionId,\n    ) -> Maybe<items::functions::FunctionDeclarationData>;\n    /// Returns the inline configuration of an extern function's declaration.\n    #[salsa::invoke(items::extern_function::extern_function_declaration_inline_config)]\n    fn extern_function_declaration_inline_config(\n        &self,\n        extern_function_id: ExternFunctionId,\n    ) -> Maybe<InlineConfiguration>;\n    /// Returns the semantic diagnostics of an extern function declaration. An extern function has\n    /// no body, and thus only has a declaration.\n    #[salsa::invoke(items::extern_function::extern_function_declaration_diagnostics)]\n    fn extern_function_declaration_diagnostics(\n        &self,\n        extern_function_id: ExternFunctionId,\n    ) -> Diagnostics<SemanticDiagnostic>;\n    /// Returns the signature of an extern function.\n    #[salsa::invoke(items::extern_function::extern_function_signature)]\n    fn extern_function_signature(\n        &self,\n        extern_function_id: ExternFunctionId,\n    ) -> Maybe<semantic::Signature>;\n    /// Returns the generic params of an extern function.\n    #[salsa::invoke(items::extern_function::extern_function_declaration_generic_params)]\n    fn extern_function_declaration_generic_params(\n        &self,\n        extern_function_id: ExternFunctionId,\n    ) -> Maybe<Vec<GenericParam>>;\n    /// Returns the explicit implicits of an extern function declaration.\n    #[salsa::invoke(items::extern_function::extern_function_declaration_implicits)]\n    fn extern_function_declaration_implicits(\n        &self,\n        extern_function_id: ExternFunctionId,\n    ) -> Maybe<Vec<TypeId>>;\n    /// Returns the ref parameters of an extern function declaration.\n    #[salsa::invoke(items::extern_function::extern_function_declaration_refs)]\n    fn extern_function_declaration_refs(\n        &self,\n        extern_function_id: ExternFunctionId,\n    ) -> Maybe<Vec<Parameter>>;\n    /// Returns the resolution lookback of an extern function.\n    #[salsa::invoke(items::extern_function::extern_function_declaration_resolved_lookback)]\n    fn extern_function_declaration_resolved_lookback(\n        &self,\n        extern_function_id: ExternFunctionId,\n    ) -> Maybe<Arc<ResolvedLookback>>;\n\n    // Extern type.\n    // ============\n    /// Private query to compute data about an extern type declaration. An extern type has\n    /// no body, and thus only has a declaration.\n    #[salsa::invoke(items::extern_type::priv_extern_type_declaration_data)]\n    fn priv_extern_type_declaration_data(\n        &self,\n        type_id: ExternTypeId,\n    ) -> Maybe<items::extern_type::ExternTypeDeclarationData>;\n    /// Returns the semantic diagnostics of an extern type declaration. An extern type has\n    /// no body, and thus only has a declaration.\n    #[salsa::invoke(items::extern_type::extern_type_declaration_diagnostics)]\n    fn extern_type_declaration_diagnostics(\n        &self,\n        extern_type_id: ExternTypeId,\n    ) -> Diagnostics<SemanticDiagnostic>;\n    /// Returns the generic params of an extern type.\n    #[salsa::invoke(items::extern_type::extern_type_declaration_generic_params)]\n    fn extern_type_declaration_generic_params(\n        &self,\n        extern_type_id: ExternTypeId,\n    ) -> Maybe<Vec<GenericParam>>;\n\n    // Function Signature.\n    // =================\n    /// Returns the signature of the given FunctionTitleId. This include free functions, extern\n    /// functions, etc...\n    #[salsa::invoke(items::functions::function_title_signature)]\n    fn function_title_signature(\n        &self,\n        function_title_id: FunctionTitleId,\n    ) -> Maybe<semantic::Signature>;\n\n    /// Returns the generic parameters of the given FunctionTitleId. This include free\n    /// functions, extern functions, etc...\n    #[salsa::invoke(items::functions::function_title_generic_params)]\n    fn function_title_generic_params(\n        &self,\n        function_title_id: FunctionTitleId,\n    ) -> Maybe<Vec<GenericParam>>;\n\n    // Concrete function.\n    // =================\n    /// Returns the signature of a concrete function. This include free functions, extern functions,\n    /// etc...\n    #[salsa::invoke(items::functions::concrete_function_signature)]\n    fn concrete_function_signature(&self, function_id: FunctionId) -> Maybe<semantic::Signature>;\n\n    // Generic type.\n    // =============\n    /// Returns the generic params of a generic type.\n    #[salsa::invoke(types::generic_type_generic_params)]\n    fn generic_type_generic_params(&self, generic_type: GenericTypeId) -> Maybe<Vec<GenericParam>>;\n\n    // Generic param.\n    // ==============\n    #[salsa::invoke(items::generics::generic_param_semantic)]\n    fn generic_param_semantic(&self, generic_param: GenericParamId) -> Maybe<GenericParam>;\n\n    // Concrete type.\n    // ==============\n    /// Returns the generic_type of a generic function. This include free types, extern\n    /// types, etc...\n    #[salsa::invoke(types::type_info)]\n    fn type_info(\n        &self,\n        lookup_context: ImplLookupContext,\n        ty: types::TypeId,\n    ) -> Maybe<types::TypeInfo>;\n\n    // Expression.\n    // ===========\n    /// Assumes function and expression are present.\n    #[salsa::invoke(items::function_with_body::expr_semantic)]\n    fn expr_semantic(\n        &self,\n        function_id: FunctionWithBodyId,\n        id: semantic::ExprId,\n    ) -> semantic::Expr;\n    /// Assumes function and statement are valid.\n    #[salsa::invoke(items::function_with_body::statement_semantic)]\n    fn statement_semantic(\n        &self,\n        function_id: FunctionWithBodyId,\n        id: semantic::StatementId,\n    ) -> semantic::Statement;\n\n    // Lookups.\n    // ========\n    fn lookup_resolved_generic_item_by_ptr(\n        &self,\n        id: LookupItemId,\n        ptr: ast::TerminalIdentifierPtr,\n    ) -> Option<ResolvedGenericItem>;\n    fn lookup_resolved_concrete_item_by_ptr(\n        &self,\n        id: LookupItemId,\n        ptr: ast::TerminalIdentifierPtr,\n    ) -> Option<ResolvedConcreteItem>;\n\n    // Diagnostics.\n    // ============\n    /// Aggregates module level semantic diagnostics.\n    fn module_semantic_diagnostics(\n        &self,\n        module_id: ModuleId,\n    ) -> Maybe<Diagnostics<SemanticDiagnostic>>;\n\n    /// Aggregates file level semantic diagnostics.\n    fn file_semantic_diagnostics(&self, file_id: FileId) -> Maybe<Diagnostics<SemanticDiagnostic>>;\n\n    // Corelib.\n    // ========\n    #[salsa::invoke(corelib::core_crate)]\n    fn core_crate(&self) -> CrateId;\n    #[salsa::invoke(corelib::core_module)]\n    fn core_module(&self) -> ModuleId;\n    #[salsa::invoke(corelib::core_felt252_ty)]\n    fn core_felt252_ty(&self) -> semantic::TypeId;\n\n    // Plugins.\n    // ========\n    #[salsa::input]\n    fn semantic_plugins(&self) -> Vec<Arc<dyn SemanticPlugin>>;\n}\n\nimpl<T: Upcast<dyn SemanticGroup + 'static>> Elongate for T {\n    fn elongate(&self) -> &(dyn SemanticGroup + 'static) {\n        self.upcast()\n    }\n}\n\n/// Initializes a database with DefsGroup.\npub fn init_semantic_group(db: &mut (dyn SemanticGroup + 'static)) {\n    // Initialize inputs.\n    db.set_semantic_plugins(Vec::new());\n}\n\npub trait SemanticGroupEx: Upcast<dyn SemanticGroup> {\n    fn get_macro_plugins(&self) -> Vec<Arc<dyn MacroPlugin>> {\n        self.upcast()\n            .semantic_plugins()\n            .into_iter()\n            .map(|plugin| plugin.as_dyn_macro_plugin())\n            .collect()\n    }\n}\nimpl<T: Upcast<dyn SemanticGroup> + ?Sized> SemanticGroupEx for T {}\n\nfn module_semantic_diagnostics(\n    db: &dyn SemanticGroup,\n    module_id: ModuleId,\n) -> Maybe<Diagnostics<SemanticDiagnostic>> {\n    let mut diagnostics = DiagnosticsBuilder::default();\n    for (module_file_id, plugin_diag) in db.module_plugin_diagnostics(module_id)? {\n        diagnostics.add(SemanticDiagnostic::new(\n            StableLocation::new(module_file_id, plugin_diag.stable_ptr),\n            SemanticDiagnosticKind::PluginDiagnostic(plugin_diag),\n        ));\n    }\n\n    diagnostics.extend(db.priv_module_items_data(module_id)?.diagnostics.clone());\n\n    for item in db.module_items(module_id)?.iter() {\n        match item {\n            ModuleItemId::Constant(const_id) => {\n                diagnostics.extend(db.constant_semantic_diagnostics(*const_id));\n            }\n            // Add signature diagnostics.\n            ModuleItemId::Use(use_id) => {\n                diagnostics.extend(db.use_semantic_diagnostics(*use_id));\n            }\n            ModuleItemId::FreeFunction(free_function) => {\n                diagnostics.extend(db.free_function_declaration_diagnostics(*free_function));\n                diagnostics.extend(db.free_function_body_diagnostics(*free_function));\n            }\n            ModuleItemId::Struct(struct_id) => {\n                diagnostics.extend(db.struct_declaration_diagnostics(*struct_id));\n                diagnostics.extend(db.struct_definition_diagnostics(*struct_id));\n            }\n            ModuleItemId::Enum(enum_id) => {\n                diagnostics.extend(db.enum_definition_diagnostics(*enum_id));\n                diagnostics.extend(db.enum_declaration_diagnostics(*enum_id));\n            }\n            ModuleItemId::Trait(trait_id) => {\n                diagnostics.extend(db.trait_semantic_diagnostics(*trait_id));\n            }\n            ModuleItemId::Impl(impl_def_id) => {\n                diagnostics.extend(db.impl_semantic_declaration_diagnostics(*impl_def_id));\n                diagnostics.extend(db.impl_semantic_definition_diagnostics(*impl_def_id));\n            }\n            ModuleItemId::Submodule(submodule_id) => {\n                // Note that the parent module does not report the diagnostics of its submodules.\n                if let Ok(file_id) = db.module_main_file(ModuleId::Submodule(*submodule_id)) {\n                    if db.file_content(file_id).is_none() {\n                        // Note that the error location is in the parent module, not the\n                        // submodule.\n\n                        let path = match db.lookup_intern_file(file_id) {\n                            FileLongId::OnDisk(path) => path.display().to_string(),\n                            FileLongId::Virtual(_) => panic!(\"Expected OnDisk file.\"),\n                        };\n\n                        let stable_location = StableLocation::new(\n                            submodule_id.module_file_id(db.upcast()),\n                            submodule_id.stable_ptr(db.upcast()).untyped(),\n                        );\n                        diagnostics.add(SemanticDiagnostic::new(\n                            stable_location,\n                            SemanticDiagnosticKind::ModuleFileNotFound { path },\n                        ));\n                    }\n                }\n            }\n            ModuleItemId::ExternType(extern_type) => {\n                diagnostics.extend(db.extern_type_declaration_diagnostics(*extern_type));\n            }\n            ModuleItemId::ExternFunction(extern_function) => {\n                diagnostics.extend(db.extern_function_declaration_diagnostics(*extern_function));\n            }\n            ModuleItemId::TypeAlias(type_alias) => {\n                diagnostics.extend(db.type_alias_semantic_diagnostics(*type_alias));\n            }\n        }\n    }\n\n    Ok(map_diagnostics(\n        db.elongate(),\n        module_id,\n        &db.module_generated_file_infos(module_id)?,\n        diagnostics.build(),\n    )\n    .1)\n}\n\n/// Transforms diagnostics that originate from plugin generated files. Uses the plugin's diagnostic\n/// mapper.\nfn map_diagnostics(\n    db: &(dyn SemanticGroup + 'static),\n    module_id: ModuleId,\n    generated_file_info: &[Option<GeneratedFileInfo>],\n    original_diagnostics: Diagnostics<SemanticDiagnostic>,\n) -> (bool, Diagnostics<SemanticDiagnostic>) {\n    let mut diagnostics = DiagnosticsBuilder::default();\n    let mut has_change: bool = false;\n\n    for tree in &original_diagnostics.0.subtrees {\n        let (changed, new_diags) =\n            map_diagnostics(db, module_id, generated_file_info, tree.clone());\n        diagnostics.extend(new_diags);\n        has_change |= changed;\n    }\n\n    for diag in &original_diagnostics.0.leaves {\n        assert_eq!(diag.stable_location.module_file_id.0, module_id, \"Unexpected module id.\");\n        let file_index = diag.stable_location.module_file_id.1;\n        if let Some(file_info) = &generated_file_info[file_index.0] {\n            let opt_diag = file_info\n                .aux_data\n                .0\n                .as_any()\n                .downcast_ref::<DynPluginAuxData>()\n                .and_then(|mapper| mapper.map_diag(db.upcast(), diag));\n            if let Some(plugin_diag) = opt_diag {\n                // We don't have a real location, so we give a dummy location in the correct file.\n                // SemanticDiagnostic struct knowns to give the proper span for\n                // WrappedPluginDiagnostic.\n                let stable_location = StableLocation::new(\n                    file_info.origin,\n                    db.intern_stable_ptr(SyntaxStablePtr::Root),\n                );\n                let kind = SemanticDiagnosticKind::WrappedPluginDiagnostic {\n                    diagnostic: plugin_diag,\n                    original_diag: Box::new(diag.clone()),\n                };\n                diagnostics.add(SemanticDiagnostic::new(stable_location, kind));\n                has_change = true;\n                continue;\n            }\n        }\n        diagnostics.add(diag.clone());\n    }\n\n    if !has_change {\n        return (false, original_diagnostics);\n    }\n\n    (has_change, diagnostics.build())\n}\n\nfn file_semantic_diagnostics(\n    db: &dyn SemanticGroup,\n    file_id: FileId,\n) -> Maybe<Diagnostics<SemanticDiagnostic>> {\n    let mut diagnostics = DiagnosticsBuilder::default();\n    for module_id in db.file_modules(file_id)? {\n        if let Ok(module_diagnostics) = db.module_semantic_diagnostics(module_id) {\n            diagnostics.extend(module_diagnostics)\n        }\n    }\n    Ok(diagnostics.build())\n}\n\npub fn lookup_resolved_generic_item_by_ptr(\n    db: &dyn SemanticGroup,\n    id: LookupItemId,\n    ptr: ast::TerminalIdentifierPtr,\n) -> Option<ResolvedGenericItem> {\n    get_resolver_lookbacks(id, db)\n        .into_iter()\n        .find_map(|resolver_lookback| resolver_lookback.generic.get(&ptr).cloned())\n}\n\npub fn lookup_resolved_concrete_item_by_ptr(\n    db: &dyn SemanticGroup,\n    id: LookupItemId,\n    ptr: ast::TerminalIdentifierPtr,\n) -> Option<ResolvedConcreteItem> {\n    get_resolver_lookbacks(id, db)\n        .into_iter()\n        .find_map(|resolver_lookback| resolver_lookback.concrete.get(&ptr).cloned())\n}\n\nfn get_resolver_lookbacks(id: LookupItemId, db: &dyn SemanticGroup) -> Vec<Arc<ResolvedLookback>> {\n    match id {\n        LookupItemId::ModuleItem(module_item) => match module_item {\n            ModuleItemId::Constant(id) => vec![db.constant_resolved_lookback(id)],\n            ModuleItemId::Submodule(_) => vec![],\n            ModuleItemId::Use(id) => vec![db.use_resolved_lookback(id)],\n            ModuleItemId::FreeFunction(id) => vec![\n                db.free_function_declaration_resolved_lookback(id),\n                db.free_function_body_resolved_lookback(id),\n            ],\n            ModuleItemId::Struct(id) => vec![\n                db.struct_declaration_resolved_lookback(id),\n                db.struct_definition_resolved_lookback(id),\n            ],\n            ModuleItemId::Enum(id) => vec![\n                db.enum_definition_resolved_lookback(id),\n                db.enum_declaration_resolved_lookback(id),\n            ],\n            ModuleItemId::TypeAlias(id) => vec![db.type_alias_resolved_lookback(id)],\n            ModuleItemId::Trait(_) => vec![],\n            ModuleItemId::Impl(id) => vec![db.impl_def_resolved_lookback(id)],\n            ModuleItemId::ExternType(_) => vec![],\n            ModuleItemId::ExternFunction(id) => {\n                vec![db.extern_function_declaration_resolved_lookback(id)]\n            }\n        },\n        LookupItemId::ImplFunction(id) => vec![db.impl_function_resolved_lookback(id)],\n    }\n    .into_iter()\n    .flatten()\n    .collect()\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "#[cfg(test)]\n#[path = \"diagnostic_test.rs\"]\nmod test;\n\nuse std::fmt::Display;\n\nuse cairo_lang_debug::DebugWithDb;\nuse cairo_lang_defs::diagnostic_utils::StableLocation;\nuse cairo_lang_defs::ids::{\n    EnumId, FunctionTitleId, ImplDefId, ImplFunctionId, ModuleFileId, StructId,\n    TopLevelLanguageElementId, TraitFunctionId, TraitId,\n};\nuse cairo_lang_defs::plugin::PluginDiagnostic;\nuse cairo_lang_diagnostics::{\n    DiagnosticAdded, DiagnosticEntry, DiagnosticLocation, Diagnostics, DiagnosticsBuilder,\n};\nuse cairo_lang_syntax::node::ids::SyntaxStablePtrId;\nuse cairo_lang_syntax::node::TypedSyntaxNode;\nuse itertools::Itertools;\nuse smol_str::SmolStr;\n\nuse crate::db::SemanticGroup;\nuse crate::expr::inference::InferenceError;\nuse crate::items::imp::UninferredImpl;\nuse crate::plugin::PluginMappedDiagnostic;\nuse crate::resolve_path::ResolvedConcreteItem;\nuse crate::{semantic, ConcreteTraitId, GenericArgumentId};\n\npub struct SemanticDiagnostics {\n    pub diagnostics: DiagnosticsBuilder<SemanticDiagnostic>,\n    pub module_file_id: ModuleFileId,\n}\nimpl SemanticDiagnostics {\n    pub fn new(module_file_id: ModuleFileId) -> Self {\n        Self { module_file_id, diagnostics: DiagnosticsBuilder::default() }\n    }\n    pub fn build(self) -> Diagnostics<SemanticDiagnostic> {\n        self.diagnostics.build()\n    }\n    /// Report a diagnostic in the location of the given node.\n    pub fn report<TNode: TypedSyntaxNode>(\n        &mut self,\n        node: &TNode,\n        kind: SemanticDiagnosticKind,\n    ) -> DiagnosticAdded {\n        self.diagnostics\n            .add(SemanticDiagnostic::new(StableLocation::from_ast(self.module_file_id, node), kind))\n    }\n    /// Report a diagnostic in the location after the given node (with width 0).\n    pub fn report_after<TNode: TypedSyntaxNode>(\n        &mut self,\n        node: &TNode,\n        kind: SemanticDiagnosticKind,\n    ) -> DiagnosticAdded {\n        self.diagnostics.add(SemanticDiagnostic::new_after(\n            StableLocation::from_ast(self.module_file_id, node),\n            kind,\n        ))\n    }\n    pub fn report_by_ptr(\n        &mut self,\n        stable_ptr: SyntaxStablePtrId,\n        kind: SemanticDiagnosticKind,\n    ) -> DiagnosticAdded {\n        self.diagnostics.add(SemanticDiagnostic::new(\n            StableLocation::new(self.module_file_id, stable_ptr),\n            kind,\n        ))\n    }\n}\n\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct SemanticDiagnostic {\n    pub stable_location: StableLocation,\n    pub kind: SemanticDiagnosticKind,\n    /// true if the diagnostic should be reported *after* the given location. Normally false, in\n    /// which case the diagnostic points to the given location (as-is).\n    pub after: bool,\n}\nimpl SemanticDiagnostic {\n    /// Create a diagnostic in the given location.\n    pub fn new(stable_location: StableLocation, kind: SemanticDiagnosticKind) -> Self {\n        SemanticDiagnostic { stable_location, kind, after: false }\n    }\n    /// Create a diagnostic in the location after the given location (with width 0).\n    pub fn new_after(stable_location: StableLocation, kind: SemanticDiagnosticKind) -> Self {\n        SemanticDiagnostic { stable_location, kind, after: true }\n    }\n}\nimpl DiagnosticEntry for SemanticDiagnostic {\n    type DbType = dyn SemanticGroup;\n\n    fn format(&self, db: &Self::DbType) -> String {\n        match &self.kind {\n            SemanticDiagnosticKind::ModuleFileNotFound { path } => {\n                format!(\"Module file not found. Expected path: {path}\")\n            }\n            SemanticDiagnosticKind::Unsupported => \"Unsupported feature.\".into(),\n            SemanticDiagnosticKind::UnknownLiteral => \"Unknown literal.\".into(),\n            SemanticDiagnosticKind::UnsupportedUnaryOperator { op, ty } => {\n                format!(\"Unary operator '{op}' is not supported for type '{}'.\", ty.format(db),)\n            }\n            SemanticDiagnosticKind::UnknownBinaryOperator => \"Unknown binary operator.\".into(),\n            SemanticDiagnosticKind::UnsupportedBinaryOperator { op, type1, type2 } => {\n                format!(\n                    \"Binary operator '{op}' is not supported for types '{}' and '{}'.\",\n                    type1.format(db),\n                    type2.format(db)\n                )\n            }\n            SemanticDiagnosticKind::UnknownTrait => \"Unknown trait.\".into(),\n            SemanticDiagnosticKind::UnknownImpl => \"Unknown impl.\".into(),\n            SemanticDiagnosticKind::UnexpectedElement { expected, actual } => {\n                let expected_str = expected.iter().map(|kind| kind.to_string()).join(\" or \");\n                format!(\"Expected {expected_str}, found {actual}.\")\n            }\n            SemanticDiagnosticKind::UnknownType => \"Unknown type.\".into(),\n            SemanticDiagnosticKind::UnknownStruct => \"Unknown struct.\".into(),\n            SemanticDiagnosticKind::UnknownEnum => \"Unknown enum.\".into(),\n            SemanticDiagnosticKind::NoLiteralFunctionFound => {\n                \"A literal with this type cannot be created.\".into()\n            }\n            SemanticDiagnosticKind::LiteralOutOfRange { ty } => {\n                format!(\"The value does not fit within the range of type {}.\", ty.format(db))\n            }\n            SemanticDiagnosticKind::NotAVariant => {\n                \"Not a variant. Use the full name Enum::Variant.\".into()\n            }\n            SemanticDiagnosticKind::NotAStruct => \"Not a struct.\".into(),\n            SemanticDiagnosticKind::NotAType => \"Not a type.\".into(),\n            SemanticDiagnosticKind::NotATrait => \"Not a trait.\".into(),\n            SemanticDiagnosticKind::FunctionNotMemberOfTrait {\n                impl_def_id,\n                impl_function_id,\n                trait_id,\n            } => {\n                let defs_db = db.upcast();\n                format!(\n                    \"Impl function `{}::{}` is not a member of trait `{}`.\",\n                    impl_def_id.name(defs_db),\n                    impl_function_id.name(defs_db),\n                    trait_id.name(defs_db)\n                )\n            }\n            SemanticDiagnosticKind::UnexpectedGenericArgs => \"Unexpected generic arguments\".into(),\n            SemanticDiagnosticKind::UnknownMember => \"Unknown member.\".into(),\n            SemanticDiagnosticKind::MemberSpecifiedMoreThanOnce => {\n                \"Member specified more than once.\".into()\n            }\n            SemanticDiagnosticKind::UseCycle => {\n                \"Cycle detected while resolving 'use' items.\".into()\n            }\n            SemanticDiagnosticKind::TypeAliasCycle => {\n                \"Cycle detected while resolving 'type alias' items.\".into()\n            }\n            SemanticDiagnosticKind::ExpectedConcreteVariant => {\n                \"Expected a concrete variant. Use `::<>` syntax.\".to_string()\n            }\n            SemanticDiagnosticKind::MissingMember { member_name } => {\n                format!(r#\"Missing member \"{member_name}\".\"#)\n            }\n            SemanticDiagnosticKind::WrongNumberOfParameters {\n                impl_def_id,\n                impl_function_id,\n                trait_id,\n                expected,\n                actual,\n            } => {\n                let defs_db = db.upcast();\n                let function_name = impl_function_id.name(defs_db);\n                format!(\n                    \"The number of parameters in the impl function `{}::{}` is incompatible with \\\n                     `{}::{}`. Expected: {}, actual: {}.\",\n                    impl_def_id.name(defs_db),\n                    function_name,\n                    trait_id.name(defs_db),\n                    function_name,\n                    expected,\n                    actual,\n                )\n            }\n            SemanticDiagnosticKind::WrongNumberOfArguments { expected, actual } => {\n                format!(\"Wrong number of arguments. Expected {expected}, found: {actual}\")\n            }\n            SemanticDiagnosticKind::WrongNumberOfGenericArguments { expected, actual } => {\n                format!(\"Wrong number of generic arguments. Expected {expected}, found: {actual}\")\n            }\n            SemanticDiagnosticKind::WrongParameterType {\n                impl_def_id,\n                impl_function_id,\n                trait_id,\n                expected_ty,\n                actual_ty,\n            } => {\n                let defs_db = db.upcast();\n                let function_name = impl_function_id.name(defs_db);\n                format!(\n                    \"Parameter type of impl function `{}::{}` is incompatible with `{}::{}`. \\\n                     Expected: `{}`, actual: `{}`.\",\n                    impl_def_id.name(defs_db),\n                    function_name,\n                    trait_id.name(defs_db),\n                    function_name,\n                    expected_ty.format(db),\n                    actual_ty.format(db)\n                )\n            }\n            SemanticDiagnosticKind::VariantCtorNotImmutable => {\n                \"Variant constructor argument must be immutable.\".to_string()\n            }\n            SemanticDiagnosticKind::TraitParamMutable { trait_id, function_id } => {\n                let defs_db = db.upcast();\n                format!(\n                    \"Parameter of trait function `{}::{}` can't be defined as mutable.\",\n                    trait_id.name(defs_db),\n                    function_id.name(defs_db),\n                )\n            }\n            SemanticDiagnosticKind::TraitFunctionWithBody { trait_id, function_id } => {\n                let defs_db = db.upcast();\n                format!(\n                    \"Trait function `{}::{}` has a body. Trait functions with body are not \\\n                     supported.\",\n                    trait_id.name(defs_db),\n                    function_id.name(defs_db),\n                )\n            }\n            SemanticDiagnosticKind::ParamaterShouldBeReference {\n                impl_def_id,\n                impl_function_id,\n                trait_id,\n            } => {\n                let defs_db = db.upcast();\n                let function_name = impl_function_id.name(defs_db);\n                format!(\n                    \"Parameter of impl function {}::{} is incompatible with {}::{}. It should be \\\n                     a reference.\",\n                    impl_def_id.name(defs_db),\n                    function_name,\n                    trait_id.name(defs_db),\n                    function_name,\n                )\n            }\n            SemanticDiagnosticKind::ParameterShouldNotBeReference {\n                impl_def_id,\n                impl_function_id,\n                trait_id,\n            } => {\n                let defs_db = db.upcast();\n                let function_name = impl_function_id.name(defs_db);\n                format!(\n                    \"Parameter of impl function {}::{} is incompatible with {}::{}. It should not \\\n                     be a reference.\",\n                    impl_def_id.name(defs_db),\n                    function_name,\n                    trait_id.name(defs_db),\n                    function_name,\n                )\n            }\n            SemanticDiagnosticKind::WrongType { expected_ty, actual_ty } => {\n                format!(\n                    r#\"Expected type \"{}\", found: \"{}\".\"#,\n                    expected_ty.format(db),\n                    actual_ty.format(db)\n                )\n            }\n            SemanticDiagnosticKind::WrongArgumentType { expected_ty, actual_ty } => {\n                format!(\n                    r#\"Unexpected argument type. Expected: \"{}\", found: \"{}\".\"#,\n                    expected_ty.format(db),\n                    actual_ty.format(db)\n                )\n            }\n            SemanticDiagnosticKind::WrongReturnType { expected_ty, actual_ty } => {\n                format!(\n                    r#\"Unexpected return type. Expected: \"{}\", found: \"{}\".\"#,\n                    expected_ty.format(db),\n                    actual_ty.format(db)\n                )\n            }\n            SemanticDiagnosticKind::WrongReturnTypeForImpl {\n                impl_def_id,\n                impl_function_id,\n                trait_id,\n                expected_ty,\n                actual_ty,\n            } => {\n                let defs_db = db.upcast();\n                let function_name = impl_function_id.name(defs_db);\n                format!(\n                    \"Return type of impl function `{}::{}` is incompatible with `{}::{}`. \\\n                     Expected: `{}`, actual: `{}`.\",\n                    impl_def_id.name(defs_db),\n                    function_name,\n                    trait_id.name(defs_db),\n                    function_name,\n                    expected_ty.format(db),\n                    actual_ty.format(db)\n                )\n            }\n            SemanticDiagnosticKind::NoImplementationOfTrait { concrete_trait_id, generic_args } => {\n                let long_concrete_trait = db.lookup_intern_concrete_trait(*concrete_trait_id);\n                let trait_path = long_concrete_trait.trait_id.full_path(db.upcast());\n                format!(\n                    \"Trait `{trait_path}::<{}>` has no implementation in the context.\",\n                    generic_args.iter().map(|arg| arg.format(db)).join(\", \")\n                )\n            }\n            SemanticDiagnosticKind::AmbiguousTrait { trait_function_id0, trait_function_id1 } => {\n                format!(\n                    \"Ambiguous method call. More than one applicable trait function with a \\\n                     suitable self type was found: {} and {}. Consider adding type annotations or \\\n                     explicitly refer to the impl function.\",\n                    trait_function_id0.full_path(db.upcast()),\n                    trait_function_id1.full_path(db.upcast())\n                )\n            }\n            SemanticDiagnosticKind::MultipleImplementationOfTrait { trait_id, all_impl_ids } => {\n                let trait_path = trait_id.full_path(db.upcast());\n                let impls_str = all_impl_ids\n                    .iter()\n                    .map(|imp| format!(\"{:?}\", imp.debug(db.upcast())))\n                    .join(\", \");\n                format!(\"Trait `{trait_path}` has multiple implementations, in: {impls_str}\",)\n            }\n            SemanticDiagnosticKind::VariableNotFound { name } => {\n                format!(r#\"Variable \"{name}\" not found.\"#)\n            }\n            SemanticDiagnosticKind::StructMemberRedefinition { struct_id, member_name } => {\n                format!(\n                    r#\"Redefinition of member \"{member_name}\" on struct \"{}\".\"#,\n                    struct_id.full_path(db.upcast())\n                )\n            }\n            SemanticDiagnosticKind::EnumVariantRedefinition { enum_id, variant_name } => {\n                format!(\n                    r#\"Redefinition of variant \"{variant_name}\" on enum \"{}\".\"#,\n                    enum_id.full_path(db.upcast())\n                )\n            }\n            SemanticDiagnosticKind::ParamNameRedefinition { function_title_id, param_name } => {\n                format!(\n                    r#\"Redefinition of parameter name \"{param_name}\" in function \"{}\".\"#,\n                    function_title_id.full_path(db.upcast())\n                )\n            }\n            SemanticDiagnosticKind::IncompatibleMatchArms { match_ty, arm_ty } => format!(\n                r#\"Match arms have incompatible types: \"{}\" and \"{}\"\"#,\n                match_ty.format(db),\n                arm_ty.format(db)\n            ),\n            SemanticDiagnosticKind::IncompatibleIfBlockTypes { block_if_ty, block_else_ty } => {\n                format!(\n                    r#\"If blocks have incompatible types: \"{}\" and \"{}\"\"#,\n                    block_if_ty.format(db),\n                    block_else_ty.format(db),\n                )\n            }\n            SemanticDiagnosticKind::TypeHasNoMembers { ty, member_name: _ } => {\n                format!(r#\"Type \"{}\" has no members.\"#, ty.format(db))\n            }\n            SemanticDiagnosticKind::NoSuchMember { struct_id, member_name } => {\n                format!(\n                    r#\"Struct \"{}\" has no member \"{member_name}\"\"#,\n                    struct_id.full_path(db.upcast())\n                )\n            }\n            SemanticDiagnosticKind::NoSuchVariant { enum_id, variant_name } => {\n                format!(\n                    r#\"Enum \"{}\" has no variant \"{variant_name}\"\"#,\n                    enum_id.full_path(db.upcast())\n                )\n            }\n            SemanticDiagnosticKind::IncompatibleErrorPropagateType { return_ty, err_ty } => {\n                format!(\n                    r#\"Return type \"{}\" does not wrap error \"{}\"\"#,\n                    return_ty.format(db),\n                    err_ty.format(db)\n                )\n            }\n            SemanticDiagnosticKind::ErrorPropagateOnNonErrorType { ty } => {\n                format!(r#\"Type \"{}\" can not error propagate\"#, ty.format(db))\n            }\n            SemanticDiagnosticKind::InvalidMemberExpression => \"Invalid member expression.\".into(),\n            SemanticDiagnosticKind::InvalidPath => \"Invalid path.\".into(),\n            SemanticDiagnosticKind::RefArgNotAVariable => \"ref argument must be a variable.\".into(),\n            SemanticDiagnosticKind::RefArgNotMutable => {\n                \"ref argument must be a mutable variable.\".into()\n            }\n            SemanticDiagnosticKind::RefArgNotExplicit => {\n                \"ref argument must be passed with a preceding 'ref'.\".into()\n            }\n            SemanticDiagnosticKind::ImmutableArgWithModifiers => {\n                \"Argument to immutable parameter cannot have modifiers.\".into()\n            }\n            SemanticDiagnosticKind::AssignmentToImmutableVar => {\n                \"Cannot assign to an immutable variable.\".into()\n            }\n            SemanticDiagnosticKind::InvalidLhsForAssignment => {\n                \"Invalid left-hand side of assignment.\".into()\n            }\n            SemanticDiagnosticKind::PathNotFound(item_type) => match item_type {\n                NotFoundItemType::Identifier => \"Identifier not found.\".into(),\n                NotFoundItemType::Function => \"Function not found.\".into(),\n                NotFoundItemType::Type => \"Type not found.\".into(),\n                NotFoundItemType::Trait => \"Trait not found.\".into(),\n                NotFoundItemType::Impl => \"Impl not found.\".into(),\n            },\n            SemanticDiagnosticKind::SuperUsedInRootModule => {\n                \"'super' cannot be used for the crate's root module.\".into()\n            }\n            SemanticDiagnosticKind::UnexpectedLiteralPattern { ty } => format!(\n                r#\"Unexpected type for literal pattern. Expected: felt252. Got: \"{}\"\"#,\n                ty.format(db),\n            ),\n            SemanticDiagnosticKind::UnexpectedEnumPattern { ty } => {\n                format!(r#\"Unexpected type for enum pattern. \"{}\" is not an enum.\"#, ty.format(db),)\n            }\n            SemanticDiagnosticKind::UnexpectedStructPattern { ty } => {\n                format!(\n                    r#\"Unexpected type for struct pattern. \"{}\" is not a struct.\"#,\n                    ty.format(db),\n                )\n            }\n            SemanticDiagnosticKind::UnexpectedTuplePattern { ty } => {\n                format!(r#\"Unexpected type for tuple pattern. \"{}\" is not a tuple.\"#, ty.format(db),)\n            }\n            SemanticDiagnosticKind::WrongEnum { expected_enum, actual_enum } => {\n                format!(\n                    r#\"Wrong enum in pattern. Expected: \"{}\". Got: \"{}\".\"#,\n                    expected_enum.full_path(db.upcast()),\n                    actual_enum.full_path(db.upcast())\n                )\n            }\n            SemanticDiagnosticKind::RedundantModifier { current_modifier, previous_modifier } => {\n                format!(\n                    \"`{current_modifier}` modifier was specified after another modifier \\\n                     (`{previous_modifier}`). Only a single modifier is allowed.\"\n                )\n            }\n            SemanticDiagnosticKind::ReferenceLocalVariable => {\n                \"`ref` is only allowed for function parameters, not for local variables.\"\n                    .to_string()\n            }\n            SemanticDiagnosticKind::ShortStringMustBeAscii => {\n                \"Short strings can only include ASCII characters.\".into()\n            }\n            SemanticDiagnosticKind::IllegalStringEscaping(err) => {\n                format!(\"Invalid string escaping:\\n{err}\")\n            }\n            SemanticDiagnosticKind::InvalidCopyTraitImpl { inference_error } => {\n                format!(\"Invalid copy trait implementation, {}\", inference_error.format(db))\n            }\n            SemanticDiagnosticKind::InvalidDropTraitImpl { inference_error } => {\n                format!(\"Invalid drop trait implementation, {}\", inference_error.format(db))\n            }\n            SemanticDiagnosticKind::InvalidImplItem { item_kw } => {\n                format!(\"`{item_kw}` is not allowed inside impl.\")\n            }\n            SemanticDiagnosticKind::MissingItemsInImpl { item_names } => {\n                format!(\n                    \"Not all trait items are implemented. Missing: {}.\",\n                    item_names.iter().map(|name| format!(\"'{name}'\")).join(\", \")\n                )\n            }\n            SemanticDiagnosticKind::PassPanicAsNopanic { impl_function_id, trait_id } => {\n                let name = impl_function_id.name(db.upcast());\n                let trait_name = trait_id.name(db.upcast());\n                format!(\n                    \"The signature of function `{name}` is incompatible with trait \\\n                     `{trait_name}`. The trait function is declared as nopanic.\"\n                )\n            }\n            SemanticDiagnosticKind::PanicableFromNonPanicable => {\n                \"Function is declared as nopanic but calls a function that may panic.\".into()\n            }\n            SemanticDiagnosticKind::PanicableExternFunction => {\n                \"An extern function must be marked as nopanic.\".into()\n            }\n            SemanticDiagnosticKind::PluginDiagnostic(diagnostic) => {\n                format!(\"Plugin diagnostic: {}\", diagnostic.message)\n            }\n            SemanticDiagnosticKind::WrappedPluginDiagnostic { diagnostic, original_diag: _ } => {\n                // TODO(spapini): Support nested diagnostics.\n                format!(\"Plugin diagnostic: {}\", diagnostic.message)\n            }\n            SemanticDiagnosticKind::NameDefinedMultipleTimes { name } => {\n                format!(\"The name `{name}` is defined multiple times.\")\n            }\n            SemanticDiagnosticKind::NamedArgumentsAreNotSupported => {\n                \"Named arguments are not supported in this context.\".into()\n            }\n            SemanticDiagnosticKind::UnnamedArgumentFollowsNamed => {\n                \"Unnamed arguments cannot follow named arguments.\".into()\n            }\n            SemanticDiagnosticKind::NamedArgumentMismatch { expected, found } => {\n                format!(\"Unexpected argument name. Expected: '{expected}', found '{found}'.\")\n            }\n            SemanticDiagnosticKind::UnsupportedOutsideOfFunction { feature_name } => {\n                let feature_name_str = match feature_name {\n                    UnsupportedOutsideOfFunctionFeatureName::FunctionCall => \"Function call\",\n                    UnsupportedOutsideOfFunctionFeatureName::ReturnStatement => \"Return statement\",\n                    UnsupportedOutsideOfFunctionFeatureName::ErrorPropagate => \"The '?' operator\",\n                };\n                format!(\"{feature_name_str} is not supported outside of functions.\")\n            }\n            SemanticDiagnosticKind::OnlyLiteralConstants => {\n                \"Only literal constants are currently supported.\".into()\n            }\n            SemanticDiagnosticKind::ExternItemWithImplGenericsNotSupported => {\n                \"Extern items with impl generics are not supported\".into()\n            }\n            SemanticDiagnosticKind::MissingSemicolon => \"Missing semicolon\".into(),\n            SemanticDiagnosticKind::TraitMismatch => {\n                \"Supplied impl does not match the required trait\".into()\n            }\n            SemanticDiagnosticKind::InternalInferenceError(err) => err.format(db),\n            SemanticDiagnosticKind::DesnapNonSnapshot => {\n                \"Desnap operator can only be applied on snapshots\".into()\n            }\n            SemanticDiagnosticKind::UnsupportedInlineArguments => {\n                \"Unsupported `inline` arguments.\".into()\n            }\n            SemanticDiagnosticKind::RedundantInlineAttribute => {\n                \"Redundant `inline` attribute.\".into()\n            }\n            SemanticDiagnosticKind::InlineWithoutArgumentNotSupported => {\n                \"`inline` without arguments is not supported.\".into()\n            }\n            SemanticDiagnosticKind::InlineAttrForExternFunctionNotAllowed => {\n                \"`inline` attribute is not allowed for extern functions.\".into()\n            }\n            SemanticDiagnosticKind::InlineAlwaysWithImplGenericArgNotAllowed => {\n                \"`#[inline(always)]` is not allowed for functions with impl generic parameters.\"\n                    .into()\n            }\n            SemanticDiagnosticKind::NoSuchMethod { ty, method_name } => format!(\n                \"Method `{}` not found on type {:?}. Did you import the correct trait and impl?\",\n                method_name,\n                ty.format(db)\n            ),\n        }\n    }\n\n    fn location(&self, db: &Self::DbType) -> DiagnosticLocation {\n        let mut location = self.stable_location.diagnostic_location(db.upcast());\n        if self.after {\n            location = location.after();\n        }\n        match &self.kind {\n            SemanticDiagnosticKind::WrappedPluginDiagnostic { diagnostic, .. } => {\n                DiagnosticLocation { span: diagnostic.span, ..location }\n            }\n            _ => location,\n        }\n    }\n}\n\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum SemanticDiagnosticKind {\n    ModuleFileNotFound {\n        path: String,\n    },\n    Unsupported,\n    UnknownLiteral,\n    UnsupportedUnaryOperator {\n        op: SmolStr,\n        ty: semantic::TypeId,\n    },\n    UnknownBinaryOperator,\n    UnsupportedBinaryOperator {\n        op: SmolStr,\n        type1: semantic::TypeId,\n        type2: semantic::TypeId,\n    },\n    UnknownTrait,\n    UnknownImpl,\n    UnexpectedElement {\n        expected: Vec<ElementKind>,\n        actual: ElementKind,\n    },\n    UnknownType,\n    UnknownStruct,\n    UnknownEnum,\n    NoLiteralFunctionFound,\n    LiteralOutOfRange {\n        ty: semantic::TypeId,\n    },\n    NotAVariant,\n    NotAStruct,\n    NotAType,\n    NotATrait,\n    FunctionNotMemberOfTrait {\n        impl_def_id: ImplDefId,\n        impl_function_id: ImplFunctionId,\n        trait_id: TraitId,\n    },\n    UnexpectedGenericArgs,\n    UnknownMember,\n    MemberSpecifiedMoreThanOnce,\n    UseCycle,\n    TypeAliasCycle,\n    ExpectedConcreteVariant,\n    MissingMember {\n        member_name: SmolStr,\n    },\n    WrongNumberOfParameters {\n        impl_def_id: ImplDefId,\n        impl_function_id: ImplFunctionId,\n        trait_id: TraitId,\n        expected: usize,\n        actual: usize,\n    },\n    WrongNumberOfArguments {\n        expected: usize,\n        actual: usize,\n    },\n    WrongNumberOfGenericArguments {\n        expected: usize,\n        actual: usize,\n    },\n    WrongParameterType {\n        impl_def_id: ImplDefId,\n        impl_function_id: ImplFunctionId,\n        trait_id: TraitId,\n        expected_ty: semantic::TypeId,\n        actual_ty: semantic::TypeId,\n    },\n    VariantCtorNotImmutable,\n    TraitParamMutable {\n        trait_id: TraitId,\n        function_id: TraitFunctionId,\n    },\n    TraitFunctionWithBody {\n        trait_id: TraitId,\n        function_id: TraitFunctionId,\n    },\n    ParamaterShouldBeReference {\n        impl_def_id: ImplDefId,\n        impl_function_id: ImplFunctionId,\n        trait_id: TraitId,\n    },\n    ParameterShouldNotBeReference {\n        impl_def_id: ImplDefId,\n        impl_function_id: ImplFunctionId,\n        trait_id: TraitId,\n    },\n    WrongType {\n        expected_ty: semantic::TypeId,\n        actual_ty: semantic::TypeId,\n    },\n    WrongArgumentType {\n        expected_ty: semantic::TypeId,\n        actual_ty: semantic::TypeId,\n    },\n    WrongReturnType {\n        expected_ty: semantic::TypeId,\n        actual_ty: semantic::TypeId,\n    },\n    WrongReturnTypeForImpl {\n        impl_def_id: ImplDefId,\n        impl_function_id: ImplFunctionId,\n        trait_id: TraitId,\n        expected_ty: semantic::TypeId,\n        actual_ty: semantic::TypeId,\n    },\n    NoImplementationOfTrait {\n        concrete_trait_id: ConcreteTraitId,\n        generic_args: Vec<GenericArgumentId>,\n    },\n    AmbiguousTrait {\n        trait_function_id0: TraitFunctionId,\n        trait_function_id1: TraitFunctionId,\n    },\n    MultipleImplementationOfTrait {\n        trait_id: TraitId,\n        all_impl_ids: Vec<UninferredImpl>,\n    },\n    VariableNotFound {\n        name: SmolStr,\n    },\n    StructMemberRedefinition {\n        struct_id: StructId,\n        member_name: SmolStr,\n    },\n    EnumVariantRedefinition {\n        enum_id: EnumId,\n        variant_name: SmolStr,\n    },\n    ParamNameRedefinition {\n        function_title_id: FunctionTitleId,\n        param_name: SmolStr,\n    },\n    IncompatibleMatchArms {\n        match_ty: semantic::TypeId,\n        arm_ty: semantic::TypeId,\n    },\n    IncompatibleIfBlockTypes {\n        block_if_ty: semantic::TypeId,\n        block_else_ty: semantic::TypeId,\n    },\n    TypeHasNoMembers {\n        ty: semantic::TypeId,\n        member_name: SmolStr,\n    },\n    NoSuchMethod {\n        ty: semantic::TypeId,\n        method_name: SmolStr,\n    },\n    NoSuchMember {\n        struct_id: StructId,\n        member_name: SmolStr,\n    },\n    NoSuchVariant {\n        enum_id: EnumId,\n        variant_name: SmolStr,\n    },\n    IncompatibleErrorPropagateType {\n        return_ty: semantic::TypeId,\n        err_ty: semantic::TypeId,\n    },\n    ErrorPropagateOnNonErrorType {\n        ty: semantic::TypeId,\n    },\n    RefArgNotAVariable,\n    RefArgNotMutable,\n    RefArgNotExplicit,\n    ImmutableArgWithModifiers,\n    AssignmentToImmutableVar,\n    InvalidLhsForAssignment,\n    InvalidMemberExpression,\n    InvalidPath,\n    PathNotFound(NotFoundItemType),\n    SuperUsedInRootModule,\n    RedundantModifier {\n        current_modifier: SmolStr,\n        previous_modifier: SmolStr,\n    },\n    ReferenceLocalVariable,\n    UnexpectedLiteralPattern {\n        ty: semantic::TypeId,\n    },\n    UnexpectedEnumPattern {\n        ty: semantic::TypeId,\n    },\n    UnexpectedStructPattern {\n        ty: semantic::TypeId,\n    },\n    UnexpectedTuplePattern {\n        ty: semantic::TypeId,\n    },\n    WrongEnum {\n        expected_enum: EnumId,\n        actual_enum: EnumId,\n    },\n    ShortStringMustBeAscii,\n    IllegalStringEscaping(String),\n    InvalidCopyTraitImpl {\n        inference_error: InferenceError,\n    },\n    InvalidDropTraitImpl {\n        inference_error: InferenceError,\n    },\n    InvalidImplItem {\n        item_kw: SmolStr,\n    },\n    MissingItemsInImpl {\n        item_names: Vec<SmolStr>,\n    },\n    PassPanicAsNopanic {\n        impl_function_id: ImplFunctionId,\n        trait_id: TraitId,\n    },\n    PanicableFromNonPanicable,\n    PanicableExternFunction,\n    PluginDiagnostic(PluginDiagnostic),\n    WrappedPluginDiagnostic {\n        diagnostic: PluginMappedDiagnostic,\n        original_diag: Box<SemanticDiagnostic>,\n    },\n    NameDefinedMultipleTimes {\n        name: SmolStr,\n    },\n    NamedArgumentsAreNotSupported,\n    UnnamedArgumentFollowsNamed,\n    NamedArgumentMismatch {\n        expected: SmolStr,\n        found: SmolStr,\n    },\n    UnsupportedOutsideOfFunction {\n        feature_name: UnsupportedOutsideOfFunctionFeatureName,\n    },\n    OnlyLiteralConstants,\n    ExternItemWithImplGenericsNotSupported,\n    MissingSemicolon,\n    TraitMismatch,\n    DesnapNonSnapshot,\n    InternalInferenceError(InferenceError),\n    UnsupportedInlineArguments,\n    RedundantInlineAttribute,\n    InlineWithoutArgumentNotSupported,\n    InlineAttrForExternFunctionNotAllowed,\n    InlineAlwaysWithImplGenericArgNotAllowed,\n}\n\n#[derive(Clone, Copy, Debug, Eq, Hash, PartialEq)]\npub enum NotFoundItemType {\n    Identifier,\n    Function,\n    Type,\n    Trait,\n    Impl,\n}\n\n#[derive(Clone, Copy, Debug, Eq, Hash, PartialEq)]\npub enum UnsupportedOutsideOfFunctionFeatureName {\n    FunctionCall,\n    ReturnStatement,\n    ErrorPropagate,\n}\n\n#[derive(Clone, Copy, Debug, Eq, Hash, PartialEq)]\npub enum ElementKind {\n    Constant,\n    Variable,\n    Module,\n    Function,\n    TraitFunction,\n    Type,\n    Variant,\n    Trait,\n    Impl,\n}\nimpl From<&ResolvedConcreteItem> for ElementKind {\n    fn from(val: &ResolvedConcreteItem) -> Self {\n        match val {\n            ResolvedConcreteItem::Constant(_) => ElementKind::Constant,\n            ResolvedConcreteItem::Module(_) => ElementKind::Module,\n            ResolvedConcreteItem::Function(_) => ElementKind::Function,\n            ResolvedConcreteItem::TraitFunction(_) => ElementKind::TraitFunction,\n            ResolvedConcreteItem::Type(_) => ElementKind::Type,\n            ResolvedConcreteItem::Variant(_) => ElementKind::Variant,\n            ResolvedConcreteItem::Trait(_) => ElementKind::Trait,\n            ResolvedConcreteItem::Impl(_) => ElementKind::Impl,\n        }\n    }\n}\nimpl Display for ElementKind {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        let res = match self {\n            ElementKind::Constant => \"constant\",\n            ElementKind::Variable => \"variable\",\n            ElementKind::Module => \"module\",\n            ElementKind::Function => \"function\",\n            ElementKind::TraitFunction => \"function\",\n            ElementKind::Type => \"type\",\n            ElementKind::Variant => \"variant\",\n            ElementKind::Trait => \"trait\",\n            ElementKind::Impl => \"impl\",\n        };\n        write!(f, \"{res}\")\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse cairo_lang_defs::db::DefsGroup;\nuse cairo_lang_defs::ids::ModuleId;\nuse cairo_lang_defs::plugin::{\n    DynGeneratedFileAuxData, GeneratedFileAuxData, MacroPlugin, PluginGeneratedFile, PluginResult,\n};\nuse cairo_lang_diagnostics::DiagnosticEntry;\nuse cairo_lang_syntax as syntax;\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::{ast, Terminal};\nuse indoc::indoc;\nuse pretty_assertions::assert_eq;\nuse test_log::test;\n\nuse crate::db::SemanticGroup;\nuse crate::patcher::{PatchBuilder, Patches, RewriteNode};\nuse crate::plugin::{\n    AsDynGeneratedFileAuxData, AsDynMacroPlugin, DynPluginAuxData, PluginAuxData,\n    PluginMappedDiagnostic, SemanticPlugin,\n};\nuse crate::test_utils::{\n    get_crate_semantic_diagnostics, setup_test_crate, test_expr_diagnostics,\n    SemanticDatabaseForTesting,\n};\nuse crate::SemanticDiagnostic;\n\ncairo_lang_test_utils::test_file_test!(\n    diagnostics,\n    \"src/diagnostic_test_data\",\n    {\n        tests: \"tests\",\n        not_found: \"not_found\",\n        missing: \"missing\",\n        plus_eq: \"plus_eq\",\n        inline: \"inline\",\n    },\n    test_expr_diagnostics\n);\n\n#[test]\nfn test_missing_module_file() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let db = &mut db_val;\n    let crate_id = setup_test_crate(\n        db,\n        \"\n    mod a {\n        mod abc;\n    }\",\n    );\n\n    let submodule_id =\n        *db.module_submodules_ids(ModuleId::CrateRoot(crate_id)).unwrap().first().unwrap();\n\n    assert_eq!(\n        db.module_semantic_diagnostics(ModuleId::Submodule(submodule_id)).unwrap().format(db),\n        indoc! {\"\n            error: Module file not found. Expected path: src/a/abc.cairo\n             --> lib.cairo:3:9\n                    mod abc;\n                    ^******^\n\n            \"\n        },\n    );\n}\n\n// A dummy plugin that adds an inline module with a semantic error (per function\n// in the original module).\n// Used to test error location inside plugin generated inline modules.\n#[derive(Debug)]\nstruct AddInlineModuleDummyPlugin {}\n\nimpl MacroPlugin for AddInlineModuleDummyPlugin {\n    fn generate_code(\n        &self,\n        db: &dyn SyntaxGroup,\n        item_ast: syntax::node::ast::Item,\n    ) -> PluginResult {\n        match item_ast {\n            ast::Item::FreeFunction(func)\n                if func\n                    .attributes(db)\n                    .elements(db)\n                    .iter()\n                    .any(|attr| attr.attr(db).text(db) == \"test_change_return_type\") =>\n            {\n                let mut builder = PatchBuilder::new(db);\n                let mut new_func = RewriteNode::from_ast(&func);\n                if matches!(\n                    func.declaration(db).signature(db).ret_ty(db),\n                    ast::OptionReturnTypeClause::ReturnTypeClause(_)\n                ) {\n                    // Change the return type.\n                    new_func\n                        .modify_child(db, ast::FunctionWithBody::INDEX_DECLARATION)\n                        .modify_child(db, ast::FunctionDeclaration::INDEX_SIGNATURE)\n                        .modify_child(db, ast::FunctionSignature::INDEX_RET_TY)\n                        .modify_child(db, ast::ReturnTypeClause::INDEX_TY)\n                        .set_str(\"NewType\".into());\n                    // Remove the attribute.\n                    new_func\n                        .modify_child(db, ast::FunctionWithBody::INDEX_ATTRIBUTES)\n                        .modify(db)\n                        .children\n                        .as_mut()\n                        .unwrap()\n                        .remove(0);\n                }\n                builder.add_modified(RewriteNode::interpolate_patched(\n                    indoc! {\"\n                        mod inner_mod {{\n                            extern type NewType;\n                            // Comment 1.\n                            // Comment $$.\n                            $func$\n                        }}\n                    \"},\n                    [(\"func\".to_string(), new_func)].into(),\n                ));\n\n                PluginResult {\n                    code: Some(PluginGeneratedFile {\n                        name: \"virt2\".into(),\n                        content: builder.code,\n                        aux_data: DynGeneratedFileAuxData::new(DynPluginAuxData::new(\n                            PatchMapper { patches: builder.patches },\n                        )),\n                    }),\n                    diagnostics: vec![],\n                    remove_original_item: false,\n                }\n            }\n            _ => PluginResult::default(),\n        }\n    }\n}\nimpl AsDynMacroPlugin for AddInlineModuleDummyPlugin {\n    fn as_dyn_macro_plugin<'a>(self: Arc<Self>) -> Arc<dyn MacroPlugin + 'a>\n    where\n        Self: 'a,\n    {\n        self\n    }\n}\nimpl SemanticPlugin for AddInlineModuleDummyPlugin {}\n\n#[derive(Debug, PartialEq, Eq)]\npub struct PatchMapper {\n    patches: Patches,\n}\nimpl GeneratedFileAuxData for PatchMapper {\n    fn as_any(&self) -> &dyn std::any::Any {\n        self\n    }\n    fn eq(&self, other: &dyn GeneratedFileAuxData) -> bool {\n        if let Some(other) = other.as_any().downcast_ref::<Self>() { self == other } else { false }\n    }\n}\nimpl AsDynGeneratedFileAuxData for PatchMapper {\n    fn as_dyn_macro_token(&self) -> &(dyn GeneratedFileAuxData + 'static) {\n        self\n    }\n}\nimpl PluginAuxData for PatchMapper {\n    fn map_diag(\n        &self,\n        db: &(dyn SemanticGroup + 'static),\n        diag: &dyn std::any::Any,\n    ) -> Option<PluginMappedDiagnostic> {\n        let Some(diag) = diag.downcast_ref::<SemanticDiagnostic>() else {return None;};\n        let span = self\n            .patches\n            .translate(db.upcast(), diag.stable_location.diagnostic_location(db.upcast()).span)?;\n        Some(PluginMappedDiagnostic { span, message: format!(\"Mapped error. {}\", diag.format(db)) })\n    }\n}\n\n#[test]\nfn test_inline_module_diagnostics() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let db = &mut db_val;\n    db.set_semantic_plugins(vec![Arc::new(AddInlineModuleDummyPlugin {})]);\n    let crate_id = setup_test_crate(\n        db,\n        indoc! {\"\n            mod a {\n                #[test_change_return_type]\n                fn bad() -> u128 {\n                    return 5;\n                }\n            }\n       \"},\n    );\n\n    // Verify we get diagnostics both for the original and the generated code.\n    assert_eq!(\n        get_crate_semantic_diagnostics(db, crate_id).format(db),\n        indoc! {r#\"\n            error: Unexpected return type. Expected: \"core::integer::u128\", found: \"core::felt252\".\n             --> lib.cairo:4:16\n                    return 5;\n                           ^\n\n            error: Plugin diagnostic: Mapped error. Unexpected return type. Expected: \"test::a::inner_mod::NewType\", found: \"core::felt252\".\n             --> lib.cairo:4:16\n                    return 5;\n                           ^\n\n            \"#},\n    );\n}\n\n#[test]\nfn test_inline_inline_module_diagnostics() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let db = &mut db_val;\n    let crate_id = setup_test_crate(\n        db,\n        indoc! {\"\n            mod a {\n                fn bad_a() -> u128 {\n                    return 1;\n                }\n            }\n            mod b {\n                mod c {\n                    fn bad_c() -> u128 {\n                        return 2;\n                    }\n                }\n                mod d {\n                    fn foo_d() {\n                    }\n                }\n            }\n            fn foo() {\n                b::c::bad_c();\n            }\n       \"},\n    );\n\n    assert_eq!(\n        get_crate_semantic_diagnostics(db, crate_id).format(db),\n        indoc! {r#\"error: Unexpected return type. Expected: \"core::integer::u128\", found: \"core::felt252\".\n             --> lib.cairo:3:16\n                    return 1;\n                           ^\n\n            error: Unexpected return type. Expected: \"core::integer::u128\", found: \"core::felt252\".\n             --> lib.cairo:9:20\n                        return 2;\n                               ^\n\n    \"#},\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! This module is responsible of computing the semantic model of expressions and statements in\n//! the code, while type checking.\n//! It is invoked by queries for function bodies and other code blocks.\n\nuse std::collections::HashMap;\n\nuse ast::{BinaryOperator, PathSegment};\nuse cairo_lang_defs::ids::{FunctionTitleId, LanguageElementId, LocalVarLongId, MemberId, TraitId};\nuse cairo_lang_diagnostics::{Maybe, ToMaybe, ToOption};\nuse cairo_lang_syntax::node::ast::{BlockOrIf, PatternStructParam, UnaryOperator};\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::helpers::{GetIdentifier, PathSegmentEx};\nuse cairo_lang_syntax::node::ids::SyntaxStablePtrId;\nuse cairo_lang_syntax::node::{ast, Terminal, TypedSyntaxNode};\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse cairo_lang_utils::unordered_hash_map::UnorderedHashMap;\nuse cairo_lang_utils::unordered_hash_set::UnorderedHashSet;\nuse cairo_lang_utils::{try_extract_matches, OptionHelper};\nuse id_arena::Arena;\nuse itertools::{chain, zip_eq};\nuse num_bigint::{BigInt, Sign};\nuse smol_str::SmolStr;\nuse unescaper::unescape;\n\nuse super::inference::{Inference, InferenceError};\nuse super::objects::*;\nuse super::pattern::{\n    Pattern, PatternEnumVariant, PatternLiteral, PatternOtherwise, PatternTuple, PatternVariable,\n};\nuse crate::corelib::{\n    core_binary_operator, core_felt252_ty, core_unary_operator, false_literal_expr, never_ty,\n    true_literal_expr, try_get_core_ty_by_name, unit_ty, unwrap_error_propagation_type,\n    validate_literal,\n};\nuse crate::db::SemanticGroup;\nuse crate::diagnostic::SemanticDiagnosticKind::*;\nuse crate::diagnostic::{\n    ElementKind, NotFoundItemType, SemanticDiagnostics, UnsupportedOutsideOfFunctionFeatureName,\n};\nuse crate::items::enm::SemanticEnumEx;\nuse crate::items::imp::find_possible_impls_at_context;\nuse crate::items::modifiers::compute_mutability;\nuse crate::items::structure::SemanticStructEx;\nuse crate::items::trt::ConcreteTraitGenericFunctionLongId;\nuse crate::items::us::SemanticUseEx;\nuse crate::literals::LiteralLongId;\nuse crate::resolve_path::{ResolvedConcreteItem, ResolvedGenericItem, Resolver};\nuse crate::semantic::{self, FunctionId, LocalVariable, TypeId, TypeLongId, Variable};\nuse crate::substitution::SemanticRewriter;\nuse crate::types::{peel_snapshots, resolve_type, wrap_in_snapshots, ConcreteTypeId};\nuse crate::{ConcreteFunction, FunctionLongId, Mutability, Parameter, PatternStruct, Signature};\n\n/// Context for computing the semantic model of expression trees.\npub struct ComputationContext<'ctx> {\n    pub db: &'ctx dyn SemanticGroup,\n    pub diagnostics: &'ctx mut SemanticDiagnostics,\n    pub resolver: Resolver<'ctx>,\n    signature: Option<&'ctx Signature>,\n    environment: Box<Environment>,\n    pub exprs: Arena<semantic::Expr>,\n    pub statements: Arena<semantic::Statement>,\n    /// Definitions of semantic variables.\n    pub semantic_defs: UnorderedHashMap<semantic::VarId, semantic::Variable>,\n}\nimpl<'ctx> ComputationContext<'ctx> {\n    pub fn new(\n        db: &'ctx dyn SemanticGroup,\n        diagnostics: &'ctx mut SemanticDiagnostics,\n        resolver: Resolver<'ctx>,\n        signature: Option<&'ctx Signature>,\n        environment: Environment,\n    ) -> Self {\n        let semantic_defs =\n            environment.variables.values().by_ref().map(|var| (var.id(), var.clone())).collect();\n        Self {\n            db,\n            diagnostics,\n            resolver,\n            signature,\n            environment: Box::new(environment),\n            exprs: Arena::default(),\n            statements: Arena::default(),\n            semantic_defs,\n        }\n    }\n\n    /// Runs a function with a modified context, with a new environment for a subscope.\n    /// This environment holds no variable of its own, but points to the current environment as a\n    /// parent.\n    /// Used for block expressions.\n    fn run_in_subscope<T, F>(&mut self, f: F) -> T\n    where\n        F: FnOnce(&mut Self) -> T,\n    {\n        // Push an environment to the stack.\n        let new_environment = Box::<Environment>::default();\n        let old_environment = std::mem::replace(&mut self.environment, new_environment);\n        self.environment.parent = Some(old_environment);\n\n        let res = f(self);\n\n        // Pop the environment from the stack.\n        let parent = self.environment.parent.take();\n        self.environment = parent.unwrap();\n        res\n    }\n\n    /// Returns [Self::signature] if it exists. Otherwise, reports a diagnostic and returns `Err`.\n    fn get_signature(\n        &mut self,\n        stable_ptr: SyntaxStablePtrId,\n        feature_name: UnsupportedOutsideOfFunctionFeatureName,\n    ) -> Maybe<&'ctx Signature> {\n        if let Some(signature) = self.signature {\n            return Ok(signature);\n        }\n\n        Err(self\n            .diagnostics\n            .report_by_ptr(stable_ptr, UnsupportedOutsideOfFunction { feature_name }))\n    }\n\n    fn reduce_ty(&mut self, ty: TypeId) -> TypeId {\n        // TODO(spapini): Propagate error to diagnostics.\n        self.resolver.inference.rewrite(ty).unwrap()\n    }\n}\n\n// TODO(ilya): Change value to VarId.\npub type EnvVariables = HashMap<SmolStr, Variable>;\n\n// TODO(spapini): Consider using identifiers instead of SmolStr everywhere in the code.\n/// A state which contains all the variables defined at the current resolver until now, and a\n/// pointer to the parent environment.\n#[derive(Clone, Debug, PartialEq, Eq, Default)]\npub struct Environment {\n    parent: Option<Box<Environment>>,\n    variables: EnvVariables,\n}\nimpl Environment {\n    /// Adds a parameter to the environment.\n    pub fn add_param(\n        &mut self,\n        diagnostics: &mut SemanticDiagnostics,\n        semantic_param: Parameter,\n        ast_param: &ast::Param,\n        function_title_id: FunctionTitleId,\n    ) -> Maybe<()> {\n        let name = &semantic_param.name;\n        match self.variables.entry(name.clone()) {\n            std::collections::hash_map::Entry::Occupied(_) => Err(diagnostics.report(\n                ast_param,\n                ParamNameRedefinition { function_title_id, param_name: name.clone() },\n            )),\n            std::collections::hash_map::Entry::Vacant(entry) => {\n                entry.insert(Variable::Param(semantic_param));\n                Ok(())\n            }\n        }\n    }\n}\n\n/// Computes the semantic model of an expression.\npub fn compute_expr_semantic(ctx: &mut ComputationContext<'_>, syntax: &ast::Expr) -> Expr {\n    let expr = maybe_compute_expr_semantic(ctx, syntax);\n    wrap_maybe_with_missing(ctx, expr, syntax.stable_ptr())\n}\n\n/// Converts `Maybe<Expr>` to a possibly [missing](ExprMissing) [Expr].\nfn wrap_maybe_with_missing(\n    ctx: &mut ComputationContext<'_>,\n    expr: Maybe<Expr>,\n    stable_ptr: ast::ExprPtr,\n) -> Expr {\n    expr.unwrap_or_else(|diag_added| {\n        Expr::Missing(ExprMissing {\n            ty: TypeId::missing(ctx.db, diag_added),\n            stable_ptr,\n            diag_added,\n        })\n    })\n}\n\n/// Computes the semantic model of an expression, or returns a SemanticDiagnosticKind on error.\npub fn maybe_compute_expr_semantic(\n    ctx: &mut ComputationContext<'_>,\n    syntax: &ast::Expr,\n) -> Maybe<Expr> {\n    let db = ctx.db;\n    let syntax_db = db.upcast();\n    // TODO(spapini): When Expr holds the syntax pointer, add it here as well.\n    match syntax {\n        ast::Expr::Path(path) => resolve_expr_path(ctx, path),\n        ast::Expr::Literal(literal_syntax) => {\n            Ok(Expr::Literal(literal_to_semantic(ctx, literal_syntax)?))\n        }\n        ast::Expr::ShortString(literal_syntax) => {\n            Ok(Expr::Literal(short_string_to_semantic(ctx, literal_syntax)?))\n        }\n        ast::Expr::False(syntax) => Ok(false_literal_expr(ctx, syntax.stable_ptr().into())),\n        ast::Expr::True(syntax) => Ok(true_literal_expr(ctx, syntax.stable_ptr().into())),\n        ast::Expr::Parenthesized(paren_syntax) => {\n            maybe_compute_expr_semantic(ctx, &paren_syntax.expr(syntax_db))\n        }\n        ast::Expr::Unary(syntax) => compute_expr_unary_semantic(ctx, syntax),\n        ast::Expr::Binary(binary_op_syntax) => compute_expr_binary_semantic(ctx, binary_op_syntax),\n        ast::Expr::Tuple(tuple_syntax) => compute_expr_tuple_semantic(ctx, tuple_syntax),\n        ast::Expr::FunctionCall(call_syntax) => {\n            compute_expr_function_call_semantic(ctx, call_syntax)\n        }\n        ast::Expr::StructCtorCall(ctor_syntax) => struct_ctor_expr(ctx, ctor_syntax),\n        ast::Expr::Block(block_syntax) => compute_expr_block_semantic(ctx, block_syntax),\n        ast::Expr::Match(expr_match) => compute_expr_match_semantic(ctx, expr_match),\n        ast::Expr::If(expr_if) => compute_expr_if_semantic(ctx, expr_if),\n        ast::Expr::ErrorPropagate(expr) => compute_expr_error_propagate_semantic(ctx, expr),\n        ast::Expr::Missing(_) | ast::Expr::FieldInitShorthand(_) => {\n            Err(ctx.diagnostics.report(syntax, Unsupported))\n        }\n        ast::Expr::Indexed(_) => todo!(),\n    }\n}\n\nfn compute_expr_unary_semantic(\n    ctx: &mut ComputationContext<'_>,\n    syntax: &ast::ExprUnary,\n) -> Maybe<Expr> {\n    let syntax_db = ctx.db.upcast();\n\n    let unary_op = syntax.op(syntax_db);\n    let expr = compute_expr_semantic(ctx, &syntax.expr(syntax_db));\n\n    let expr_ty = ctx.reduce_ty(expr.ty());\n    if let UnaryOperator::At(_) = unary_op {\n        let ty = ctx.db.intern_type(TypeLongId::Snapshot(expr_ty));\n        return Ok(Expr::Snapshot(ExprSnapshot {\n            inner: ctx.exprs.alloc(expr),\n            ty,\n            stable_ptr: syntax.stable_ptr().into(),\n        }));\n    }\n    if let UnaryOperator::Desnap(_) = unary_op {\n        let Some(desnapped_ty) = try_extract_matches!(ctx.db.lookup_intern_type(expr_ty), TypeLongId::Snapshot) else {\n            return Err(ctx.diagnostics.report(&unary_op, DesnapNonSnapshot));\n        };\n        return Ok(Expr::Desnap(ExprDesnap {\n            inner: ctx.exprs.alloc(expr),\n            ty: desnapped_ty,\n            stable_ptr: syntax.stable_ptr().into(),\n        }));\n    }\n    let concrete_trait_function = match core_unary_operator(\n        ctx.db,\n        &mut ctx.resolver.inference,\n        &unary_op,\n        syntax.stable_ptr().untyped(),\n    )? {\n        Err(err_kind) => {\n            return Err(ctx.diagnostics.report(&unary_op, err_kind));\n        }\n        Ok(function) => function,\n    };\n\n    let function = ctx\n        .resolver\n        .inference\n        .infer_trait_function(\n            concrete_trait_function,\n            &ctx.resolver.impl_lookup_context(),\n            syntax.stable_ptr().untyped(),\n        )\n        .map_err(|err| err.report(ctx.diagnostics, syntax.stable_ptr().untyped()))?;\n\n    expr_function_call(\n        ctx,\n        function,\n        vec![(expr, None, Mutability::Immutable)],\n        syntax.stable_ptr().into(),\n    )\n}\n\nfn compute_expr_binary_semantic(\n    ctx: &mut ComputationContext<'_>,\n    syntax: &ast::ExprBinary,\n) -> Maybe<Expr> {\n    let db = ctx.db;\n    let syntax_db = db.upcast();\n\n    let stable_ptr = syntax.stable_ptr().into();\n    let binary_op = syntax.op(syntax_db);\n    let lhs_syntax = &syntax.lhs(syntax_db);\n    let lexpr = compute_expr_semantic(ctx, lhs_syntax);\n    let rhs_syntax = syntax.rhs(syntax_db);\n    if matches!(binary_op, BinaryOperator::Dot(_)) {\n        return dot_expr(ctx, lexpr, rhs_syntax, stable_ptr);\n    }\n    let rexpr = compute_expr_semantic(ctx, &rhs_syntax);\n    if matches!(binary_op, BinaryOperator::Eq(_)) {\n        let member_path = match lexpr {\n            Expr::Var(expr) => VarMemberPath::Var(expr),\n            Expr::MemberAccess(ExprMemberAccess { member_path: Some(ref_arg), .. }) => ref_arg,\n            _ => return Err(ctx.diagnostics.report(lhs_syntax, InvalidLhsForAssignment)),\n        };\n\n        let expected_ty = ctx.reduce_ty(member_path.ty());\n        let actual_ty = ctx.reduce_ty(rexpr.ty());\n\n        if ctx.resolver.inference.conform_ty(actual_ty, expected_ty).is_err() {\n            return Err(ctx\n                .diagnostics\n                .report(&rhs_syntax, WrongArgumentType { expected_ty, actual_ty }));\n        }\n        // Verify the variable argument is mutable.\n        if !ctx.semantic_defs[member_path.base_var()].is_mut() {\n            ctx.diagnostics.report(syntax, AssignmentToImmutableVar);\n        }\n        return Ok(Expr::Assignment(ExprAssignment {\n            ref_arg: member_path,\n            rhs: ctx.exprs.alloc(rexpr),\n            ty: unit_ty(db),\n            stable_ptr,\n        }));\n    }\n    call_core_binary_op(ctx, syntax, lexpr, rexpr)\n}\n\n/// Get the function call expression of a binary operation that is defined in the corelib.\nfn call_core_binary_op(\n    ctx: &mut ComputationContext<'_>,\n    syntax: &ast::ExprBinary,\n    lexpr: Expr,\n    rexpr: Expr,\n) -> Maybe<Expr> {\n    let db = ctx.db;\n    let stable_ptr = syntax.stable_ptr().into();\n    let binary_op = syntax.op(db.upcast());\n\n    ctx.reduce_ty(lexpr.ty()).check_not_missing(db)?;\n    ctx.reduce_ty(rexpr.ty()).check_not_missing(db)?;\n    let concrete_trait_function = match core_binary_operator(\n        db,\n        &mut ctx.resolver.inference,\n        &binary_op,\n        syntax.stable_ptr().untyped(),\n    )? {\n        Err(err_kind) => {\n            return Err(ctx.diagnostics.report(&binary_op, err_kind));\n        }\n        Ok(concrete_trait_function) => concrete_trait_function,\n    };\n\n    let function = ctx\n        .resolver\n        .inference\n        .infer_trait_function(\n            concrete_trait_function,\n            &ctx.resolver.impl_lookup_context(),\n            syntax.stable_ptr().untyped(),\n        )\n        .map_err(|err| err.report(ctx.diagnostics, syntax.stable_ptr().untyped()))?;\n\n    let sig = ctx.db.concrete_function_signature(function)?;\n    let first_param = sig.params.into_iter().next().unwrap();\n    expr_function_call(\n        ctx,\n        function,\n        vec![(lexpr, None, first_param.mutability), (rexpr, None, Mutability::Immutable)],\n        stable_ptr,\n    )\n}\n\nfn compute_expr_tuple_semantic(\n    ctx: &mut ComputationContext<'_>,\n    syntax: &ast::ExprTuple,\n) -> Maybe<Expr> {\n    let db = ctx.db;\n    let syntax_db = db.upcast();\n\n    let mut items: Vec<ExprId> = vec![];\n    let mut types: Vec<TypeId> = vec![];\n    for expr_syntax in syntax.expressions(syntax_db).elements(syntax_db) {\n        let expr_semantic = compute_expr_semantic(ctx, &expr_syntax);\n        types.push(ctx.reduce_ty(expr_semantic.ty()));\n        items.push(ctx.exprs.alloc(expr_semantic));\n    }\n    Ok(Expr::Tuple(ExprTuple {\n        items,\n        ty: db.intern_type(TypeLongId::Tuple(types)),\n        stable_ptr: syntax.stable_ptr().into(),\n    }))\n}\n\nfn compute_expr_function_call_semantic(\n    ctx: &mut ComputationContext<'_>,\n    syntax: &ast::ExprFunctionCall,\n) -> Maybe<Expr> {\n    let db = ctx.db;\n    let syntax_db = db.upcast();\n\n    let path = syntax.path(syntax_db);\n    let item =\n        ctx.resolver.resolve_concrete_path(ctx.diagnostics, &path, NotFoundItemType::Function)?;\n    let args_syntax = syntax.arguments(syntax_db);\n    let named_args: Vec<_> = args_syntax\n        .args(syntax_db)\n        .elements(syntax_db)\n        .into_iter()\n        .map(|arg_syntax| compute_named_argument_clause(ctx, arg_syntax))\n        .collect();\n    match item {\n        ResolvedConcreteItem::Variant(concrete_variant) => {\n            if named_args.len() != 1 {\n                return Err(ctx.diagnostics.report(\n                    &args_syntax,\n                    WrongNumberOfArguments { expected: 1, actual: named_args.len() },\n                ));\n            }\n            let (arg, name_terminal, mutability) = named_args[0].clone();\n            if let Some(name_terminal) = name_terminal {\n                ctx.diagnostics.report(&name_terminal, NamedArgumentsAreNotSupported);\n            }\n            if mutability != Mutability::Immutable {\n                return Err(ctx.diagnostics.report(&args_syntax, VariantCtorNotImmutable));\n            }\n            let expected_ty = ctx.reduce_ty(concrete_variant.ty);\n            let actual_ty = ctx.reduce_ty(arg.ty());\n            if ctx.resolver.inference.conform_ty(actual_ty, expected_ty).is_err() {\n                return Err(ctx\n                    .diagnostics\n                    .report(&args_syntax, WrongArgumentType { expected_ty, actual_ty }));\n            }\n            let concrete_enum_id = concrete_variant.concrete_enum_id;\n            Ok(semantic::Expr::EnumVariantCtor(semantic::ExprEnumVariantCtor {\n                variant: concrete_variant,\n                value_expr: ctx.exprs.alloc(arg),\n                ty: db.intern_type(TypeLongId::Concrete(ConcreteTypeId::Enum(concrete_enum_id))),\n                stable_ptr: syntax.stable_ptr().into(),\n            }))\n        }\n        ResolvedConcreteItem::Function(function) => {\n            expr_function_call(ctx, function, named_args, syntax.stable_ptr().into())\n        }\n        ResolvedConcreteItem::TraitFunction(trait_function) => {\n            let generic_function = ctx\n                .resolver\n                .inference\n                .infer_trait_generic_function(\n                    trait_function,\n                    &ctx.resolver.impl_lookup_context(),\n                    path.stable_ptr().untyped(),\n                )\n                .map_err(|err| err.report(ctx.diagnostics, path.stable_ptr().untyped()))?;\n            let function_id = ctx\n                .resolver\n                .inference\n                .infer_generic_function(\n                    generic_function,\n                    &ctx.resolver.impl_lookup_context(),\n                    path.stable_ptr().untyped(),\n                )\n                .map_err(|err| err.report(ctx.diagnostics, path.stable_ptr().untyped()))?;\n            expr_function_call(ctx, function_id, named_args, syntax.stable_ptr().into())\n        }\n        _ => Err(ctx.diagnostics.report(\n            &path,\n            UnexpectedElement { expected: vec![ElementKind::Function], actual: (&item).into() },\n        )),\n    }\n}\n\n/// Computes the semantic model of an expression of type [ast::Arg].\n///\n/// Returns the value and the optional argument name.\npub fn compute_named_argument_clause(\n    ctx: &mut ComputationContext<'_>,\n    arg_syntax: ast::Arg,\n) -> (Expr, Option<ast::TerminalIdentifier>, Mutability) {\n    let syntax_db = ctx.db.upcast();\n\n    let mutability = compute_mutability(\n        ctx.diagnostics,\n        syntax_db,\n        &arg_syntax.modifiers(syntax_db).elements(syntax_db),\n    );\n\n    let arg_clause = arg_syntax.arg_clause(syntax_db);\n    let (expr, arg_name_identifier) = match arg_clause {\n        ast::ArgClause::Unnamed(arg_unnamed) => {\n            (compute_expr_semantic(ctx, &arg_unnamed.value(syntax_db)), None)\n        }\n        ast::ArgClause::Named(arg_named) => (\n            compute_expr_semantic(ctx, &arg_named.value(syntax_db)),\n            Some(arg_named.name(syntax_db)),\n        ),\n        ast::ArgClause::FieldInitShorthand(arg_field_init_shorthand) => {\n            let name_expr = arg_field_init_shorthand.name(syntax_db);\n            let stable_ptr: ast::ExprPtr = name_expr.stable_ptr().into();\n            let arg_name_identifier = name_expr.name(syntax_db);\n            let maybe_expr = resolve_variable_by_name(ctx, &arg_name_identifier, stable_ptr);\n            let expr = wrap_maybe_with_missing(ctx, maybe_expr, stable_ptr);\n            (expr, Some(arg_name_identifier))\n        }\n    };\n\n    (expr, arg_name_identifier, mutability)\n}\n\npub fn compute_root_expr(\n    ctx: &mut ComputationContext<'_>,\n    syntax: &ast::ExprBlock,\n    return_type: TypeId,\n) -> Maybe<ExprId> {\n    let res = compute_expr_block_semantic(ctx, syntax)?;\n    let res_ty = res.ty();\n    let res = ctx.exprs.alloc(res);\n    if ctx.resolver.inference.conform_ty(res_ty, return_type).is_err() {\n        ctx.diagnostics\n            .report(syntax, WrongReturnType { expected_ty: return_type, actual_ty: res_ty });\n    }\n\n    // Check fully resolved.\n    if let Some((stable_ptr, inference_err)) = ctx.resolver.inference.finalize() {\n        inference_err.report(ctx.diagnostics, stable_ptr);\n        if ctx.diagnostics.diagnostics.count == 0 {\n            ctx.diagnostics.report_by_ptr(stable_ptr, InternalInferenceError(inference_err));\n        }\n        return Ok(res);\n    }\n\n    // Apply inference.\n    infer_all(ctx)?;\n\n    Ok(res)\n}\n\nfn infer_all(ctx: &mut ComputationContext<'_>) -> Maybe<()> {\n    let version = ctx.resolver.inference.version;\n    for (_id, expr) in ctx.exprs.iter_mut() {\n        *expr = ctx\n            .resolver\n            .inference\n            .rewrite(expr.clone())\n            .map_err(|err| err.report(ctx.diagnostics, expr.stable_ptr().untyped()))?;\n    }\n    for (_id, stmt) in ctx.statements.iter_mut() {\n        *stmt = ctx\n            .resolver\n            .inference\n            .rewrite(stmt.clone())\n            .map_err(|err| err.report(ctx.diagnostics, stmt.stable_ptr().untyped()))?;\n    }\n    assert!(ctx.resolver.inference.version == version, \"Inference is not stable!\");\n    Ok(())\n}\n\n/// Computes the semantic model of an expression of type [ast::ExprBlock].\npub fn compute_expr_block_semantic(\n    ctx: &mut ComputationContext<'_>,\n    syntax: &ast::ExprBlock,\n) -> Maybe<Expr> {\n    let db = ctx.db;\n    let syntax_db = db.upcast();\n\n    ctx.run_in_subscope(|new_ctx| {\n        let mut statements = syntax.statements(syntax_db).elements(syntax_db);\n        // Remove the tail expression, if exists.\n        // TODO(spapini): Consider splitting tail expression in the parser.\n        let tail = get_tail_expression(syntax_db, statements.as_slice());\n        if tail.is_some() {\n            statements.pop();\n        }\n\n        // Convert statements to semantic model.\n        let statements_semantic: Vec<_> = statements\n            .into_iter()\n            .filter_map(|statement_syntax| {\n                compute_statement_semantic(new_ctx, statement_syntax).to_option()\n            })\n            .collect();\n\n        // Convert tail expression (if exists) to semantic model.\n        let tail_semantic_expr = tail.map(|tail_expr| compute_expr_semantic(new_ctx, &tail_expr));\n        let ty = if let Some(t) = &tail_semantic_expr {\n            t.ty()\n        } else if let Some(statement) = statements_semantic.last() {\n            if let Statement::Return(_) = &new_ctx.statements[*statement] {\n                never_ty(new_ctx.db)\n            } else {\n                unit_ty(db)\n            }\n        } else {\n            unit_ty(db)\n        };\n        Ok(Expr::Block(ExprBlock {\n            statements: statements_semantic,\n            tail: tail_semantic_expr.map(|expr| new_ctx.exprs.alloc(expr)),\n            ty,\n            stable_ptr: syntax.stable_ptr().into(),\n        }))\n    })\n}\n\n/// Helper for merging the return types of branch blocks (match or if else).\nstruct FlowMergeTypeHelper<'a, 'ctx> {\n    inference: &'a mut Inference<'ctx>,\n    never_type: TypeId,\n    final_type: Option<TypeId>,\n}\nimpl<'a, 'ctx> FlowMergeTypeHelper<'a, 'ctx> {\n    fn new(db: &dyn SemanticGroup, inference: &'a mut Inference<'ctx>) -> Self {\n        Self { inference, never_type: never_ty(db), final_type: None }\n    }\n\n    /// Attempt merge a branch into the helper, on error will return the conflicting types.\n    fn try_merge_types(\n        &mut self,\n        db: &dyn SemanticGroup,\n        ty: TypeId,\n    ) -> Result<(), (TypeId, TypeId)> {\n        if ty != self.never_type && !ty.is_missing(db) {\n            if let Some(existing) = &self.final_type {\n                if self.inference.conform_ty(ty, *existing).is_err() {\n                    return Err((*existing, ty));\n                }\n            } else {\n                self.final_type = Some(ty);\n            }\n        }\n        Ok(())\n    }\n\n    /// Returns the merged type.\n    fn get_final_type(self) -> TypeId {\n        self.final_type.unwrap_or(self.never_type)\n    }\n}\n\nfn compute_expr_match_semantic(\n    ctx: &mut ComputationContext<'_>,\n    syntax: &ast::ExprMatch,\n) -> Maybe<Expr> {\n    // TODO(yuval): verify exhaustiveness.\n    let db = ctx.db;\n    let syntax_db = db.upcast();\n\n    let syntax_arms = syntax.arms(syntax_db).elements(syntax_db);\n    let expr = compute_expr_semantic(ctx, &syntax.expr(syntax_db));\n    // Run compute_pattern_semantic on every arm, even if other arms failed, to get as many\n    // diagnostics as possible.\n    let pattern_and_expr_options: Vec<_> = syntax_arms\n        .iter()\n        .map(|syntax_arm| {\n            let arm_expr_syntax = syntax_arm.expression(syntax_db);\n            ctx.run_in_subscope(|new_ctx| {\n                // Typecheck pattern, and introduce the new variables to the subscope.\n                // Note that if the arm expr is a block, there will be *another* subscope\n                // for it.\n                let pattern =\n                    compute_pattern_semantic(new_ctx, syntax_arm.pattern(syntax_db), expr.ty())?;\n                let variables = pattern.variables();\n                for v in variables {\n                    let var_def = Variable::Local(v.var.clone());\n                    // TODO(spapini): Wrap this in a function to couple with semantic_defs\n                    // insertion.\n                    new_ctx.environment.variables.insert(v.name.clone(), var_def.clone());\n                    new_ctx.semantic_defs.insert(var_def.id(), var_def);\n                }\n                let arm_expr = compute_expr_semantic(new_ctx, &arm_expr_syntax);\n                Ok((pattern, arm_expr))\n            })\n        })\n        .collect();\n    // Unify arm types.\n    let mut helper = FlowMergeTypeHelper::new(ctx.db, &mut ctx.resolver.inference);\n    for (_, expr) in pattern_and_expr_options.iter().flatten() {\n        if let Err((match_ty, arm_ty)) = helper.try_merge_types(ctx.db, expr.ty()) {\n            ctx.diagnostics.report_by_ptr(\n                expr.stable_ptr().untyped(),\n                IncompatibleMatchArms { match_ty, arm_ty },\n            );\n        }\n    }\n    // Compute semantic representation of the match arms.\n    let pattern_and_exprs: Vec<_> = pattern_and_expr_options.into_iter().collect::<Maybe<_>>()?;\n    let semantic_arms = pattern_and_exprs\n        .into_iter()\n        .map(|(pattern, arm_expr)| MatchArm { pattern, expression: ctx.exprs.alloc(arm_expr) })\n        .collect();\n    Ok(Expr::Match(ExprMatch {\n        matched_expr: ctx.exprs.alloc(expr),\n        arms: semantic_arms,\n        ty: helper.get_final_type(),\n        stable_ptr: syntax.stable_ptr().into(),\n    }))\n}\n\n/// Computes the semantic model of an expression of type [ast::ExprIf].\nfn compute_expr_if_semantic(ctx: &mut ComputationContext<'_>, syntax: &ast::ExprIf) -> Maybe<Expr> {\n    let syntax_db = ctx.db.upcast();\n\n    let expr = compute_expr_semantic(ctx, &syntax.condition(syntax_db));\n    let if_block = compute_expr_block_semantic(ctx, &syntax.if_block(syntax_db))?;\n\n    let (else_block_opt, else_block_ty) = match syntax.else_clause(syntax_db) {\n        ast::OptionElseClause::Empty(_) => (None, unit_ty(ctx.db)),\n        ast::OptionElseClause::ElseClause(else_clause) => {\n            match else_clause.else_block_or_if(syntax_db) {\n                BlockOrIf::Block(block) => {\n                    let else_block = compute_expr_block_semantic(ctx, &block)?;\n                    (Some(else_block.clone()), else_block.ty())\n                }\n                BlockOrIf::If(expr_if) => {\n                    let else_if = compute_expr_if_semantic(ctx, &expr_if)?;\n                    (Some(else_if.clone()), else_if.ty())\n                }\n            }\n        }\n    };\n\n    let mut helper = FlowMergeTypeHelper::new(ctx.db, &mut ctx.resolver.inference);\n    helper\n        .try_merge_types(ctx.db, if_block.ty())\n        .and(helper.try_merge_types(ctx.db, else_block_ty))\n        .unwrap_or_else(|(block_if_ty, block_else_ty)| {\n            ctx.diagnostics.report(syntax, IncompatibleIfBlockTypes { block_if_ty, block_else_ty });\n        });\n    Ok(Expr::If(ExprIf {\n        condition: ctx.exprs.alloc(expr),\n        if_block: ctx.exprs.alloc(if_block),\n        else_block: else_block_opt.map(|else_block| ctx.exprs.alloc(else_block)),\n        ty: helper.get_final_type(),\n        stable_ptr: syntax.stable_ptr().into(),\n    }))\n}\n\n/// Computes the semantic model of an expression of type [ast::ExprErrorPropagate].\nfn compute_expr_error_propagate_semantic(\n    ctx: &mut ComputationContext<'_>,\n    syntax: &ast::ExprErrorPropagate,\n) -> Maybe<Expr> {\n    let syntax_db = ctx.db.upcast();\n    let inner = compute_expr_semantic(ctx, &syntax.expr(syntax_db));\n    let inner_ty = ctx.reduce_ty(inner.ty());\n    inner_ty.check_not_missing(ctx.db)?;\n    let (ok_variant, err_variant) =\n        unwrap_error_propagation_type(ctx.db, inner_ty).ok_or_else(|| {\n            ctx.diagnostics.report(syntax, ErrorPropagateOnNonErrorType { ty: inner_ty })\n        })?;\n    let func_signature = ctx.get_signature(\n        syntax.stable_ptr().untyped(),\n        UnsupportedOutsideOfFunctionFeatureName::ErrorPropagate,\n    )?;\n    let (_, func_err_variant) = unwrap_error_propagation_type(ctx.db, func_signature.return_type)\n        .ok_or_else(|| {\n        ctx.diagnostics.report(\n            syntax,\n            IncompatibleErrorPropagateType {\n                return_ty: func_signature.return_type,\n                err_ty: err_variant.ty,\n            },\n        )\n    })?;\n    // TODO(orizi): When auto conversion of types is added, try to convert the error type.\n    if func_err_variant.ty != err_variant.ty\n        || func_err_variant.concrete_enum_id.enum_id(ctx.db)\n            != err_variant.concrete_enum_id.enum_id(ctx.db)\n    {\n        ctx.diagnostics.report(\n            syntax,\n            IncompatibleErrorPropagateType {\n                return_ty: func_signature.return_type,\n                err_ty: err_variant.ty,\n            },\n        );\n    }\n    Ok(Expr::PropagateError(ExprPropagateError {\n        inner: ctx.exprs.alloc(inner),\n        ok_variant,\n        err_variant,\n        func_err_variant,\n        stable_ptr: syntax.stable_ptr().into(),\n    }))\n}\n\n/// Computes the semantic model of a pattern, or None if invalid.\nfn compute_pattern_semantic(\n    ctx: &mut ComputationContext<'_>,\n    pattern_syntax: ast::Pattern,\n    ty: TypeId,\n) -> Maybe<Pattern> {\n    // TODO(spapini): Check for missing type, and don't reemit an error.\n    let syntax_db = ctx.db.upcast();\n    let ty = ctx.reduce_ty(ty);\n    Ok(match pattern_syntax {\n        ast::Pattern::Underscore(otherwise_pattern) => {\n            Pattern::Otherwise(PatternOtherwise { ty, stable_ptr: otherwise_pattern.stable_ptr() })\n        }\n        ast::Pattern::Literal(literal_pattern) => {\n            let literal = literal_to_semantic(ctx, &literal_pattern)?;\n            if ctx.resolver.inference.conform_ty(ty, core_felt252_ty(ctx.db)).is_err() {\n                return Err(ctx\n                    .diagnostics\n                    .report(&literal_pattern, UnexpectedLiteralPattern { ty }));\n            }\n            Pattern::Literal(PatternLiteral {\n                literal,\n                ty,\n                stable_ptr: literal_pattern.stable_ptr().into(),\n            })\n        }\n        ast::Pattern::ShortString(short_string_pattern) => {\n            let literal = short_string_to_semantic(ctx, &short_string_pattern)?;\n            if ctx.resolver.inference.conform_ty(ty, core_felt252_ty(ctx.db)).is_err() {\n                return Err(ctx\n                    .diagnostics\n                    .report(&short_string_pattern, UnexpectedLiteralPattern { ty }));\n            }\n            Pattern::Literal(PatternLiteral {\n                literal,\n                ty,\n                stable_ptr: short_string_pattern.stable_ptr().into(),\n            })\n        }\n        ast::Pattern::Enum(enum_pattern) => {\n            // Peel all snapshot wrappers.\n            let (n_snapshots, long_ty) = peel_snapshots(ctx.db, ty);\n\n            // Check that type is an enum, and get the concrete enum from it.\n            let concrete_enum = try_extract_matches!(long_ty, TypeLongId::Concrete)\n                .and_then(|c| try_extract_matches!(c, ConcreteTypeId::Enum))\n                .ok_or(())\n                .or_else(|_| {\n                    // Don't add a diagnostic if the type is missing.\n                    // A diagnostic should've already been added.\n                    ty.check_not_missing(ctx.db)?;\n                    Err(ctx.diagnostics.report(&enum_pattern, UnexpectedEnumPattern { ty }))\n                })?;\n\n            // Extract the enum variant from the path syntax.\n            let path = enum_pattern.path(syntax_db);\n            let item = ctx.resolver.resolve_generic_path(\n                ctx.diagnostics,\n                &path,\n                NotFoundItemType::Identifier,\n            )?;\n            let generic_variant = try_extract_matches!(item, ResolvedGenericItem::Variant)\n                .ok_or_else(|| ctx.diagnostics.report(&path, NotAVariant))?;\n\n            // Check that these are the same enums.\n            if generic_variant.enum_id != concrete_enum.enum_id(ctx.db) {\n                return Err(ctx.diagnostics.report(\n                    &path,\n                    WrongEnum {\n                        expected_enum: concrete_enum.enum_id(ctx.db),\n                        actual_enum: generic_variant.enum_id,\n                    },\n                ));\n            }\n            // TODO(lior): Should we report a diagnostic here?\n            let concrete_variant = ctx\n                .db\n                .concrete_enum_variant(concrete_enum, &generic_variant)\n                .map_err(|_| ctx.diagnostics.report(&path, UnknownEnum))?;\n\n            // Compute inner pattern.\n            let ty = wrap_in_snapshots(ctx.db, concrete_variant.ty, n_snapshots);\n            let inner_pattern =\n                compute_pattern_semantic(ctx, enum_pattern.pattern(syntax_db), ty)?.into();\n            Pattern::EnumVariant(PatternEnumVariant {\n                variant: concrete_variant,\n                inner_pattern,\n                ty,\n                stable_ptr: enum_pattern.stable_ptr(),\n            })\n        }\n        ast::Pattern::Path(path) => {\n            // A path of length 1 is an identifier, which will result in a variable pattern.\n            // Currently, other paths are not supported (and not clear if ever will be).\n            if path.elements(syntax_db).len() > 1 {\n                return Err(ctx.diagnostics.report(&path, Unsupported));\n            }\n            // TODO(spapini): Make sure this is a simple identifier. In particular, no generics.\n            let identifier = path.elements(syntax_db)[0].identifier_ast(syntax_db);\n            create_variable_pattern(ctx, identifier, &[], ty, path.stable_ptr().into())\n        }\n        ast::Pattern::Identifier(identifier) => create_variable_pattern(\n            ctx,\n            identifier.name(syntax_db),\n            &identifier.modifiers(syntax_db).elements(syntax_db),\n            ty,\n            identifier.stable_ptr().into(),\n        ),\n        ast::Pattern::Struct(pattern_struct) => {\n            // Peel all snapshot wrappers.\n            let (n_snapshots, long_ty) = peel_snapshots(ctx.db, ty);\n\n            // Check that type is an struct, and get the concrete struct from it.\n            let concrete_struct_id = try_extract_matches!(long_ty, TypeLongId::Concrete)\n                .and_then(|c| try_extract_matches!(c, ConcreteTypeId::Struct))\n                .ok_or(())\n                .or_else(|_| {\n                    // Don't add a diagnostic if the type is missing.\n                    // A diagnostic should've already been added.\n                    ty.check_not_missing(ctx.db)?;\n                    Err(ctx.diagnostics.report(&pattern_struct, UnexpectedEnumPattern { ty }))\n                })?;\n            let pattern_param_asts = pattern_struct.params(syntax_db).elements(syntax_db);\n            let struct_id = concrete_struct_id.struct_id(ctx.db);\n            let mut members = ctx.db.concrete_struct_members(concrete_struct_id)?;\n            let mut used_members = UnorderedHashSet::default();\n            let mut get_member = |ctx: &mut ComputationContext<'_>, member_name: SmolStr| {\n                let member = members.swap_remove(&member_name).on_none(|| {\n                    ctx.diagnostics.report(\n                        &pattern_struct,\n                        if used_members.contains(&member_name) {\n                            StructMemberRedefinition { struct_id, member_name: member_name.clone() }\n                        } else {\n                            NoSuchMember { struct_id, member_name: member_name.clone() }\n                        },\n                    );\n                })?;\n                used_members.insert(member_name);\n                Some(member)\n            };\n            let mut field_patterns = vec![];\n            let mut has_tail = false;\n            for pattern_param_ast in pattern_param_asts {\n                match pattern_param_ast {\n                    PatternStructParam::Single(single) => {\n                        let name = single.name(syntax_db);\n                        let member = get_member(ctx, name.text(syntax_db)).to_maybe()?;\n                        let ty = wrap_in_snapshots(ctx.db, member.ty, n_snapshots);\n                        let pattern = create_variable_pattern(\n                            ctx,\n                            name,\n                            &single.modifiers(syntax_db).elements(syntax_db),\n                            ty,\n                            single.stable_ptr().into(),\n                        );\n                        field_patterns.push((member, Box::new(pattern)));\n                    }\n                    PatternStructParam::WithExpr(with_expr) => {\n                        let member = get_member(ctx, with_expr.name(syntax_db).text(syntax_db))\n                            .to_maybe()?;\n                        let ty = wrap_in_snapshots(ctx.db, member.ty, n_snapshots);\n                        let pattern =\n                            compute_pattern_semantic(ctx, with_expr.pattern(syntax_db), ty)?;\n                        field_patterns.push((member, Box::new(pattern)));\n                    }\n                    PatternStructParam::Tail(_) => {\n                        has_tail = true;\n                    }\n                }\n            }\n            if !has_tail {\n                for (member_name, _) in members {\n                    ctx.diagnostics.report(&pattern_struct, MissingMember { member_name });\n                }\n            }\n            Pattern::Struct(PatternStruct {\n                concrete_struct_id,\n                field_patterns,\n                ty,\n                n_snapshots,\n                stable_ptr: pattern_struct.stable_ptr(),\n            })\n        }\n        ast::Pattern::Tuple(pattern_tuple) => {\n            // Peel all snapshot wrappers.\n            let (n_snapshots, long_ty) = peel_snapshots(ctx.db, ty);\n\n            let tys = try_extract_matches!(long_ty, TypeLongId::Tuple).ok_or_else(|| {\n                ctx.diagnostics.report(&pattern_tuple, UnexpectedTuplePattern { ty })\n            })?;\n\n            let patterns_ast = pattern_tuple.patterns(syntax_db).elements(syntax_db);\n            if tys.len() != patterns_ast.len() {\n                return Err(ctx.diagnostics.report(\n                    &pattern_tuple,\n                    WrongNumberOfGenericArguments {\n                        expected: tys.len(),\n                        actual: patterns_ast.len(),\n                    },\n                ));\n            }\n            // Iterator of Option<Pattern?, for each field.\n            let pattern_options = zip_eq(patterns_ast.into_iter(), tys).map(|(pattern_ast, ty)| {\n                let ty = wrap_in_snapshots(ctx.db, ty, n_snapshots);\n                Ok(Box::new(compute_pattern_semantic(ctx, pattern_ast, ty)?))\n            });\n            // If all are Some, collect into a Vec.\n            let field_patterns: Vec<_> = pattern_options.collect::<Maybe<_>>()?;\n\n            Pattern::Tuple(PatternTuple {\n                field_patterns,\n                ty,\n                stable_ptr: pattern_tuple.stable_ptr(),\n            })\n        }\n    })\n}\n\n/// Creates a local variable pattern.\nfn create_variable_pattern(\n    ctx: &mut ComputationContext<'_>,\n    identifier: ast::TerminalIdentifier,\n    modifier_list: &[ast::Modifier],\n    ty: TypeId,\n    stable_ptr: ast::PatternPtr,\n) -> Pattern {\n    let syntax_db = ctx.db.upcast();\n    let var_id = ctx\n        .db\n        .intern_local_var(LocalVarLongId(ctx.resolver.module_file_id, identifier.stable_ptr()));\n\n    let is_mut = match compute_mutability(ctx.diagnostics, syntax_db, modifier_list) {\n        Mutability::Immutable => false,\n        Mutability::Mutable => true,\n        Mutability::Reference => {\n            ctx.diagnostics.report(&identifier, ReferenceLocalVariable);\n            false\n        }\n    };\n    Pattern::Variable(PatternVariable {\n        name: identifier.text(syntax_db),\n        var: LocalVariable { id: var_id, ty, is_mut },\n        stable_ptr,\n    })\n}\n\n/// Creates a struct constructor semantic expression from its AST.\nfn struct_ctor_expr(\n    ctx: &mut ComputationContext<'_>,\n    ctor_syntax: &ast::ExprStructCtorCall,\n) -> Maybe<Expr> {\n    let db = ctx.db;\n    let syntax_db = db.upcast();\n    let path = ctor_syntax.path(syntax_db);\n\n    // Extract struct.\n    let ty = resolve_type(db, ctx.diagnostics, &mut ctx.resolver, &ast::Expr::Path(path.clone()));\n    ty.check_not_missing(db)?;\n\n    let concrete_struct_id =\n        try_extract_matches!(ctx.db.lookup_intern_type(ty), TypeLongId::Concrete)\n            .and_then(|c| try_extract_matches!(c, ConcreteTypeId::Struct))\n            .ok_or_else(|| ctx.diagnostics.report(&path, NotAStruct))?;\n\n    let members = db.concrete_struct_members(concrete_struct_id)?;\n    let mut member_exprs: OrderedHashMap<MemberId, ExprId> = OrderedHashMap::default();\n    // A set of struct members for which a diagnostic has been reported.\n    let mut skipped_members: UnorderedHashSet<MemberId> = UnorderedHashSet::default();\n    for arg in ctor_syntax.arguments(syntax_db).arguments(syntax_db).elements(syntax_db) {\n        // TODO: Extract to a function for results.\n        let arg = match arg {\n            ast::StructArg::StructArgSingle(arg) => arg,\n            ast::StructArg::StructArgTail(tail_expr) => {\n                ctx.diagnostics.report(&tail_expr, Unsupported);\n                continue;\n            }\n        };\n        let arg_identifier = arg.identifier(syntax_db);\n        let arg_name = arg_identifier.text(syntax_db);\n\n        // Find struct member by name.\n        let member = if let Some(member) = members.get(&arg_name) {\n            member\n        } else {\n            ctx.diagnostics.report(&arg_identifier, UnknownMember);\n            continue;\n        };\n\n        // Extract expression.\n        let arg_expr = match arg.arg_expr(syntax_db) {\n            ast::OptionStructArgExpr::Empty(_) => {\n                resolve_variable_by_name(ctx, &arg_identifier, path.stable_ptr().into())?\n            }\n            ast::OptionStructArgExpr::StructArgExpr(arg_expr) => {\n                compute_expr_semantic(ctx, &arg_expr.expr(syntax_db))\n            }\n        };\n\n        // Check types.\n        let expected_ty = ctx.reduce_ty(member.ty);\n        let actual_ty = ctx.reduce_ty(arg_expr.ty());\n        if ctx.resolver.inference.conform_ty(actual_ty, expected_ty).is_err() {\n            if !member.ty.is_missing(db) {\n                ctx.diagnostics\n                    .report(&arg_identifier, WrongArgumentType { expected_ty, actual_ty });\n            }\n            skipped_members.insert(member.id);\n            continue;\n        }\n        // Insert and check for duplicates.\n        if member_exprs.insert(member.id, ctx.exprs.alloc(arg_expr)).is_some() {\n            ctx.diagnostics.report(&arg_identifier, MemberSpecifiedMoreThanOnce);\n        }\n    }\n\n    // Report errors for missing members.\n    for (member_name, member) in members.iter() {\n        if !member_exprs.contains_key(&member.id) && !skipped_members.contains(&member.id) {\n            ctx.diagnostics.report(ctor_syntax, MissingMember { member_name: member_name.clone() });\n        }\n    }\n\n    Ok(Expr::StructCtor(ExprStructCtor {\n        concrete_struct_id,\n        members: member_exprs.into_iter().collect(),\n        ty: db.intern_type(TypeLongId::Concrete(ConcreteTypeId::Struct(concrete_struct_id))),\n        stable_ptr: ctor_syntax.stable_ptr().into(),\n    }))\n}\n\n/// Returns the tail expression of the given list of statements, if exists.\n/// A tail expression is the last statement in the list, if it is an expression and\n/// it does not end with a semicolon.\nfn get_tail_expression(\n    syntax_db: &dyn SyntaxGroup,\n    statements: &[ast::Statement],\n) -> Option<ast::Expr> {\n    let last = statements.last()?;\n    let statement_expr = try_extract_matches!(last, ast::Statement::Expr)?;\n    try_extract_matches!(statement_expr.semicolon(syntax_db), ast::OptionTerminalSemicolon::Empty)?;\n    Some(statement_expr.expr(syntax_db))\n}\n\n/// Creates the semantic model of a literal expression from its AST.\nfn literal_to_semantic(\n    ctx: &mut ComputationContext<'_>,\n    literal_syntax: &ast::TerminalLiteralNumber,\n) -> Maybe<ExprLiteral> {\n    let db = ctx.db;\n    let syntax_db = db.upcast();\n    let text = literal_syntax.text(syntax_db);\n\n    let (literal_text, ty) = if let Some((literal, ty)) = text.split_once('_') {\n        (literal.into(), Some(ty))\n    } else {\n        (text.clone(), None)\n    };\n    let value = LiteralLongId::try_from(literal_text)\n        .map_err(|_| ctx.diagnostics.report(literal_syntax, UnknownLiteral))?\n        .value;\n\n    let ty = if let Some(ty_str) = ty {\n        try_get_core_ty_by_name(db, ty_str.into(), vec![])\n            .map_err(|err| ctx.diagnostics.report(literal_syntax, err))?\n    } else {\n        db.core_felt252_ty()\n    };\n    validate_literal(db, ty, value.clone())\n        .map_err(|err| ctx.diagnostics.report(literal_syntax, err))?;\n    Ok(ExprLiteral { value, ty, stable_ptr: literal_syntax.stable_ptr().into() })\n}\n\n/// Creates the semantic model of a short string from its AST.\nfn short_string_to_semantic(\n    ctx: &mut ComputationContext<'_>,\n    short_string_syntax: &ast::TerminalShortString,\n) -> Maybe<ExprLiteral> {\n    let db = ctx.db;\n    let syntax_db = db.upcast();\n    let text = short_string_syntax.text(syntax_db);\n\n    if let Some((literal, suffix)) = text[1..].rsplit_once('\\'') {\n        let ty = if !suffix.is_empty() {\n            try_get_core_ty_by_name(db, suffix[1..].into(), vec![])\n                .map_err(|err| ctx.diagnostics.report(short_string_syntax, err))?\n        } else {\n            db.core_felt252_ty()\n        };\n        let unescaped_literal = unescape(literal).map_err(|err| {\n            ctx.diagnostics.report(short_string_syntax, IllegalStringEscaping(format!(\"{err}\")))\n        })?;\n        let value = BigInt::from_bytes_be(Sign::Plus, unescaped_literal.as_bytes());\n        validate_literal(db, ty, value.clone())\n            .map_err(|err| ctx.diagnostics.report(short_string_syntax, err))?;\n        if unescaped_literal.is_ascii() {\n            Ok(ExprLiteral { value, ty, stable_ptr: short_string_syntax.stable_ptr().into() })\n        } else {\n            Err(ctx.diagnostics.report(short_string_syntax, ShortStringMustBeAscii))\n        }\n    } else {\n        unreachable!();\n    }\n}\n\n/// Given an expression syntax, if it's an identifier, returns it. Otherwise, returns the proper\n/// error.\nfn expr_as_identifier(\n    ctx: &mut ComputationContext<'_>,\n    path: &ast::ExprPath,\n    syntax_db: &dyn SyntaxGroup,\n) -> Maybe<SmolStr> {\n    let segments = path.elements(syntax_db);\n    if segments.len() == 1 {\n        return Ok(segments[0].identifier(syntax_db));\n    }\n    Err(ctx.diagnostics.report(path, InvalidMemberExpression))\n}\n\n// TODO(spapini): Consider moving some checks here to the responsibility of the parser.\n/// Computes the semantic expression for a dot expression.\nfn dot_expr(\n    ctx: &mut ComputationContext<'_>,\n    lexpr: Expr,\n    rhs_syntax: ast::Expr,\n    stable_ptr: ast::ExprPtr,\n) -> Maybe<Expr> {\n    // Find MemberId.\n    match rhs_syntax {\n        ast::Expr::Path(expr) => member_access_expr(ctx, lexpr, expr, stable_ptr),\n        ast::Expr::FunctionCall(expr) => method_call_expr(ctx, lexpr, expr, stable_ptr),\n        _ => Err(ctx.diagnostics.report(&rhs_syntax, InvalidMemberExpression)),\n    }\n}\n\n/// Finds all the trait ids usable in the current context.\nfn all_module_trait_ids(ctx: &mut ComputationContext<'_>) -> Maybe<Vec<TraitId>> {\n    let mut module_traits = ctx.db.module_traits_ids(ctx.resolver.module_file_id.0)?;\n    for use_id in ctx.db.module_uses_ids(ctx.resolver.module_file_id.0)? {\n        if let Ok(ResolvedGenericItem::Trait(trait_id)) = ctx.db.use_resolved_item(use_id) {\n            module_traits.push(trait_id);\n        }\n    }\n    Ok(module_traits)\n}\n\n/// Computes the semantic model of a method call expression (e.g. \"expr.method(..)\").\n/// Finds all traits with at least one candidate impl with a matching `self` param.\n/// If more/less than 1 such trait exists, fails.\nfn method_call_expr(\n    ctx: &mut ComputationContext<'_>,\n    lexpr: Expr,\n    expr: ast::ExprFunctionCall,\n    stable_ptr: ast::ExprPtr,\n) -> Maybe<Expr> {\n    // TODO(spapini): Add ctx.module_id.\n    // TODO(spapini): Look also in uses.\n    let syntax_db = ctx.db.upcast();\n    let path = expr.path(syntax_db);\n    let segment = path.elements(syntax_db).last().unwrap().clone();\n    let func_name = segment.identifier(syntax_db);\n    let generic_args_syntax = segment.generic_args(syntax_db);\n    let mut candidates = vec![];\n    let ty = ctx.reduce_ty(lexpr.ty());\n    for trait_id in all_module_trait_ids(ctx)? {\n        for (name, trait_function) in ctx.db.trait_functions(trait_id)? {\n            if name != func_name {\n                continue;\n            }\n\n            // Check if trait function signature's first param can fit our expr type.\n            let mut inference = ctx.resolver.inference.clone();\n            let mut lookup_context = ctx.resolver.impl_lookup_context();\n            let Some((concrete_trait_id, _)) = inference.infer_concrete_trait_by_self(\n                trait_function, ty, &lookup_context, stable_ptr.untyped()\n            ) else {\n                continue;\n            };\n\n            // Find impls for it.\n            lookup_context.extra_modules.push(trait_id.module_file_id(ctx.db.upcast()).0);\n            let Ok(available_impls) = find_possible_impls_at_context(\n                ctx.db, &inference, &lookup_context, concrete_trait_id, stable_ptr.untyped()\n            ) else {\n                continue;\n            };\n            if available_impls.is_empty() {\n                continue;\n            }\n\n            candidates.push(trait_function);\n        }\n    }\n\n    let trait_function = match candidates[..] {\n        [] => {\n            return Err(ctx.diagnostics.report_by_ptr(\n                path.stable_ptr().untyped(),\n                NoSuchMethod { ty, method_name: func_name },\n            ));\n        }\n        [trait_function] => trait_function,\n        [trait_function_id0, trait_function_id1, ..] => {\n            return Err(ctx.diagnostics.report_by_ptr(\n                stable_ptr.untyped(),\n                AmbiguousTrait { trait_function_id0, trait_function_id1 },\n            ));\n        }\n    };\n\n    let mut lookup_context = ctx.resolver.impl_lookup_context();\n    lookup_context.extra_modules.push(trait_function.module_file_id(ctx.db.upcast()).0);\n    let (concrete_trait_id, n_snapshots) = ctx\n        .resolver\n        .inference\n        .infer_concrete_trait_by_self(trait_function, ty, &lookup_context, stable_ptr.untyped())\n        .unwrap();\n    let signature = ctx.db.trait_function_signature(trait_function).unwrap();\n    let first_param = signature.params.into_iter().next().unwrap();\n    let concrete_trait_function_id = ctx.db.intern_concrete_trait_function(\n        ConcreteTraitGenericFunctionLongId::new(ctx.db, concrete_trait_id, trait_function),\n    );\n    let trait_func_generic_params =\n        ctx.db.concrete_trait_function_generic_params(concrete_trait_function_id)?;\n    let generic_args = ctx.resolver.resolve_generic_args(\n        ctx.diagnostics,\n        &trait_func_generic_params,\n        generic_args_syntax.unwrap_or_default(),\n        stable_ptr.untyped(),\n    )?;\n\n    let generic_function = ctx\n        .resolver\n        .inference\n        .infer_trait_generic_function(\n            concrete_trait_function_id,\n            &ctx.resolver.impl_lookup_context(),\n            path.stable_ptr().untyped(),\n        )\n        .map_err(|err| err.report(ctx.diagnostics, path.stable_ptr().untyped()))?;\n\n    let function_id = ctx.db.intern_function(FunctionLongId {\n        function: ConcreteFunction { generic_function, generic_args },\n    });\n\n    let mut fixed_lexpr = lexpr;\n    for _ in 0..n_snapshots {\n        let ty = ctx.db.intern_type(TypeLongId::Snapshot(fixed_lexpr.ty()));\n        fixed_lexpr =\n            Expr::Snapshot(ExprSnapshot { inner: ctx.exprs.alloc(fixed_lexpr), ty, stable_ptr });\n    }\n\n    let named_args: Vec<_> = chain!(\n        [(fixed_lexpr, None, first_param.mutability)],\n        expr.arguments(syntax_db)\n            .args(syntax_db)\n            .elements(syntax_db)\n            .into_iter()\n            .map(|arg_syntax| compute_named_argument_clause(ctx, arg_syntax))\n    )\n    .collect();\n\n    expr_function_call(ctx, function_id, named_args, stable_ptr)\n}\n\n/// Computes the semantic model of a member access expression (e.g. \"expr.member\").\nfn member_access_expr(\n    ctx: &mut ComputationContext<'_>,\n    lexpr: Expr,\n    rhs_syntax: ast::ExprPath,\n    stable_ptr: ast::ExprPtr,\n) -> Maybe<Expr> {\n    let syntax_db = ctx.db.upcast();\n\n    // Find MemberId.\n    let member_name = expr_as_identifier(ctx, &rhs_syntax, syntax_db)?;\n    let ty = ctx.reduce_ty(lexpr.ty());\n    let (n_snapshots, long_ty) = peel_snapshots(ctx.db, ty);\n    match long_ty {\n        TypeLongId::Concrete(concrete) => match concrete {\n            ConcreteTypeId::Struct(concrete_struct_id) => {\n                // TODO(lior): Add a diagnostic test when accessing a member of a missing type.\n                let members = ctx.db.concrete_struct_members(concrete_struct_id)?;\n                let member = members.get(&member_name).ok_or_else(|| {\n                    ctx.diagnostics.report(\n                        &rhs_syntax,\n                        NoSuchMember {\n                            struct_id: concrete_struct_id.struct_id(ctx.db),\n                            member_name,\n                        },\n                    )\n                })?;\n                let member_path = if n_snapshots == 0 {\n                    lexpr.as_member_path().map(|parent| VarMemberPath::Member {\n                        parent: Box::new(parent),\n                        member_id: member.id,\n                        stable_ptr: lexpr.stable_ptr(),\n                        concrete_struct_id,\n                        ty: member.ty,\n                    })\n                } else {\n                    None\n                };\n                let lexpr_id = ctx.exprs.alloc(lexpr);\n\n                let ty = wrap_in_snapshots(ctx.db, member.ty, n_snapshots);\n                Ok(Expr::MemberAccess(ExprMemberAccess {\n                    expr: lexpr_id,\n                    concrete_struct_id,\n                    member: member.id,\n                    ty,\n                    member_path,\n                    n_snapshots,\n                    stable_ptr,\n                }))\n            }\n            _ => Err(ctx.diagnostics.report(&rhs_syntax, TypeHasNoMembers { ty, member_name })),\n        },\n        TypeLongId::Tuple(_) => {\n            // TODO(spapini): Handle .0, .1, etc. .\n            Err(ctx.diagnostics.report(&rhs_syntax, Unsupported))\n        }\n        TypeLongId::Snapshot(_) => {\n            // TODO(spapini): Handle snapshot members.\n            Err(ctx.diagnostics.report(&rhs_syntax, Unsupported))\n        }\n        TypeLongId::GenericParameter(_) => {\n            Err(ctx.diagnostics.report(&rhs_syntax, TypeHasNoMembers { ty, member_name }))\n        }\n        TypeLongId::Var(_) => Err(ctx\n            .diagnostics\n            .report(&rhs_syntax, InternalInferenceError(InferenceError::TypeNotInferred { ty }))),\n        TypeLongId::Missing(diag_added) => Err(diag_added),\n    }\n}\n\n/// Resolves a variable or a constant given a context and a path expression.\nfn resolve_expr_path(ctx: &mut ComputationContext<'_>, path: &ast::ExprPath) -> Maybe<Expr> {\n    let db = ctx.db;\n    let syntax_db = db.upcast();\n    let segments = path.elements(syntax_db);\n    if segments.is_empty() {\n        return Err(ctx.diagnostics.report(path, Unsupported));\n    }\n\n    // Check if this is a variable.\n    if let [PathSegment::Simple(ident_segment)] = &segments[..] {\n        let identifier = ident_segment.ident(syntax_db);\n        let variable_name = identifier.text(ctx.db.upcast());\n        if let Some(res) = get_variable_by_name(ctx, &variable_name, path.stable_ptr().into()) {\n            return Ok(res);\n        }\n    }\n\n    // Check if this is a constant.\n    let resolved_item =\n        ctx.resolver.resolve_concrete_path(ctx.diagnostics, path, NotFoundItemType::Identifier)?;\n    let ResolvedConcreteItem::Constant(constant_id) = resolved_item else {\n        return Err(\n            ctx.diagnostics.report(path, UnexpectedElement{\n                expected:vec![ElementKind::Variable, ElementKind::Constant],\n                actual: (&resolved_item).into(),\n            })\n        );\n    };\n\n    let ty = db.constant_semantic_data(constant_id)?.value.ty();\n    Ok(Expr::Constant(ExprConstant { constant_id, ty, stable_ptr: path.stable_ptr().into() }))\n}\n\n/// Resolves a variable given a context and a simple name.\n///\n/// Reports a diagnostic if the variable was not found.\npub fn resolve_variable_by_name(\n    ctx: &mut ComputationContext<'_>,\n    identifier: &ast::TerminalIdentifier,\n    stable_ptr: ast::ExprPtr,\n) -> Maybe<Expr> {\n    let variable_name = identifier.text(ctx.db.upcast());\n    get_variable_by_name(ctx, &variable_name, stable_ptr)\n        .ok_or_else(|| ctx.diagnostics.report(identifier, VariableNotFound { name: variable_name }))\n}\n\n/// Returns the requested variable from the environment if it exists. Returns None otherwise.\npub fn get_variable_by_name(\n    ctx: &mut ComputationContext<'_>,\n    variable_name: &SmolStr,\n    stable_ptr: ast::ExprPtr,\n) -> Option<Expr> {\n    let mut maybe_env = Some(&*ctx.environment);\n    while let Some(env) = maybe_env {\n        if let Some(var) = env.variables.get(variable_name) {\n            return Some(Expr::Var(ExprVar { var: var.id(), ty: var.ty(), stable_ptr }));\n        }\n        maybe_env = env.parent.as_deref();\n    }\n    None\n}\n\n/// Typechecks a function call.\nfn expr_function_call(\n    ctx: &mut ComputationContext<'_>,\n    function_id: FunctionId,\n    named_args: Vec<(Expr, Option<ast::TerminalIdentifier>, Mutability)>,\n    stable_ptr: ast::ExprPtr,\n) -> Maybe<Expr> {\n    // TODO(spapini): Better location for these diagnostics after the refactor for generics resolve.\n    // TODO(lior): Check whether concrete_function_signature should be `Option` instead of `Maybe`.\n    let signature = ctx.db.concrete_function_signature(function_id)?;\n\n    if named_args.len() != signature.params.len() {\n        return Err(ctx.diagnostics.report_by_ptr(\n            stable_ptr.untyped(),\n            WrongNumberOfArguments { expected: signature.params.len(), actual: named_args.len() },\n        ));\n    }\n\n    // Check panicable.\n    if signature.panicable\n        && !ctx\n            .get_signature(\n                stable_ptr.untyped(),\n                UnsupportedOutsideOfFunctionFeatureName::FunctionCall,\n            )?\n            .panicable\n    {\n        // TODO(spapini): Delay this check until after inference, to allow resolving specific\n        //   impls first.\n        return Err(ctx.diagnostics.report_by_ptr(stable_ptr.untyped(), PanicableFromNonPanicable));\n    }\n\n    // Check argument names and types.\n    check_named_arguments(&named_args, &signature, ctx)?;\n\n    let mut args = Vec::new();\n    for ((arg, _name, mutability), param) in named_args.into_iter().zip(signature.params.iter()) {\n        let arg_typ = arg.ty();\n        let param_typ = param.ty;\n        // Don't add diagnostic if the type is missing (a diagnostic should have already been\n        // added).\n        // TODO(lior): Add a test to missing type once possible.\n        let expected_ty = ctx.reduce_ty(param_typ);\n        let actual_ty = ctx.reduce_ty(arg_typ);\n        if !arg_typ.is_missing(ctx.db)\n            && ctx.resolver.inference.conform_ty(actual_ty, expected_ty).is_err()\n        {\n            ctx.diagnostics.report_by_ptr(\n                arg.stable_ptr().untyped(),\n                WrongArgumentType { expected_ty, actual_ty },\n            );\n        }\n\n        args.push(if param.mutability == Mutability::Reference {\n            // Verify the argument is a variable.\n            let Some(ref_arg) = arg.as_member_path() else {\n                return Err(ctx.diagnostics.report_by_ptr(\n                    arg.stable_ptr().untyped(), RefArgNotAVariable));\n            };\n            // Verify the variable argument is mutable.\n            if !ctx.semantic_defs[ref_arg.base_var()].is_mut() {\n                ctx.diagnostics.report_by_ptr(arg.stable_ptr().untyped(), RefArgNotMutable);\n            }\n            // Verify that it is passed explicitly as 'ref'.\n            if mutability != Mutability::Reference {\n                ctx.diagnostics.report_by_ptr(arg.stable_ptr().untyped(), RefArgNotExplicit);\n            }\n            ExprFunctionCallArg::Reference(ref_arg)\n        } else {\n            // Verify that it is passed without modifiers.\n            if mutability != Mutability::Immutable {\n                ctx.diagnostics\n                    .report_by_ptr(arg.stable_ptr().untyped(), ImmutableArgWithModifiers);\n            }\n            ExprFunctionCallArg::Value(ctx.exprs.alloc(arg))\n        });\n    }\n    Ok(Expr::FunctionCall(ExprFunctionCall {\n        function: function_id,\n        args,\n        ty: signature.return_type,\n        stable_ptr,\n    }))\n}\n\n/// Checks the correctness of the named arguments, and outputs diagnostics on errors.\nfn check_named_arguments(\n    named_args: &[(Expr, Option<ast::TerminalIdentifier>, Mutability)],\n    signature: &Signature,\n    ctx: &mut ComputationContext<'_>,\n) -> Maybe<()> {\n    let mut res: Maybe<()> = Ok(());\n\n    // Indicates whether we saw a named argument. Used to report a diagnostic if an unnamed argument\n    // will follow it.\n    let mut seen_named_arguments: bool = false;\n    // Indicates whether a [UnnamedArgumentFollowsNamed] diagnostic was reported. Used to prevent\n    // multiple similar diagnostics.\n    let mut reported_unnamed_argument_follows_named: bool = false;\n    for ((arg, name_opt, _mutability), param) in named_args.iter().zip(signature.params.iter()) {\n        // Check name.\n        if let Some(name_terminal) = name_opt {\n            seen_named_arguments = true;\n            let name = name_terminal.text(ctx.db.upcast());\n            if param.name != name.clone() {\n                res = Err(ctx.diagnostics.report_by_ptr(\n                    name_terminal.stable_ptr().untyped(),\n                    NamedArgumentMismatch { expected: param.name.clone(), found: name },\n                ));\n            }\n        } else if seen_named_arguments && !reported_unnamed_argument_follows_named {\n            reported_unnamed_argument_follows_named = true;\n            res = Err(ctx\n                .diagnostics\n                .report_by_ptr(arg.stable_ptr().untyped(), UnnamedArgumentFollowsNamed));\n        }\n    }\n    res\n}\n\n/// Computes the semantic model of a statement (excluding tail-expression).\npub fn compute_statement_semantic(\n    ctx: &mut ComputationContext<'_>,\n    syntax: ast::Statement,\n) -> Maybe<StatementId> {\n    let db = ctx.db;\n    let syntax_db = db.upcast();\n    let statement = match &syntax {\n        ast::Statement::Let(let_syntax) => {\n            let expr = compute_expr_semantic(ctx, &let_syntax.rhs(syntax_db));\n            let inferred_type = expr.ty();\n            let rhs_expr_id = ctx.exprs.alloc(expr);\n\n            let ty = match let_syntax.type_clause(syntax_db) {\n                ast::OptionTypeClause::Empty(_) => inferred_type,\n                ast::OptionTypeClause::TypeClause(type_clause) => {\n                    let var_type_path = type_clause.ty(syntax_db);\n                    let explicit_type =\n                        resolve_type(db, ctx.diagnostics, &mut ctx.resolver, &var_type_path);\n                    let explicit_type = ctx.reduce_ty(explicit_type);\n                    let inferred_type = ctx.reduce_ty(inferred_type);\n                    if !inferred_type.is_missing(db)\n                        && ctx.resolver.inference.conform_ty(inferred_type, explicit_type).is_err()\n                    {\n                        ctx.diagnostics.report(\n                            &let_syntax.rhs(syntax_db),\n                            WrongArgumentType {\n                                expected_ty: explicit_type,\n                                actual_ty: inferred_type,\n                            },\n                        );\n                    }\n                    explicit_type\n                }\n            };\n\n            let pattern = compute_pattern_semantic(ctx, let_syntax.pattern(syntax_db), ty)?;\n            let variables = pattern.variables();\n            // TODO(yuval): allow unnamed variables. Add them here to\n            // ctx.environment.unnamed_variables\n            for v in variables {\n                let var_def = Variable::Local(v.var.clone());\n                ctx.environment.variables.insert(v.name.clone(), var_def.clone());\n                ctx.semantic_defs.insert(var_def.id(), var_def);\n            }\n            semantic::Statement::Let(semantic::StatementLet {\n                pattern,\n                expr: rhs_expr_id,\n                stable_ptr: syntax.stable_ptr(),\n            })\n        }\n        ast::Statement::Expr(stmt_expr_syntax) => {\n            let expr_syntax = stmt_expr_syntax.expr(syntax_db);\n            let expr = compute_expr_semantic(ctx, &expr_syntax);\n            if matches!(\n                stmt_expr_syntax.semicolon(syntax_db),\n                ast::OptionTerminalSemicolon::Empty(_)\n            ) && !matches!(\n                expr_syntax,\n                ast::Expr::Block(_) | ast::Expr::If(_) | ast::Expr::Match(_)\n            ) {\n                // Point to after the expression, where the semicolon is missing.\n                ctx.diagnostics.report_after(&expr_syntax, MissingSemicolon);\n            }\n            semantic::Statement::Expr(semantic::StatementExpr {\n                expr: ctx.exprs.alloc(expr),\n                stable_ptr: syntax.stable_ptr(),\n            })\n        }\n        ast::Statement::Return(return_syntax) => {\n            let expr_syntax = return_syntax.expr(syntax_db);\n            let expr = compute_expr_semantic(ctx, &expr_syntax);\n            let expr_ty = expr.ty();\n            let expected_ty = ctx\n                .get_signature(\n                    return_syntax.stable_ptr().untyped(),\n                    UnsupportedOutsideOfFunctionFeatureName::ReturnStatement,\n                )?\n                .return_type;\n            if !expected_ty.is_missing(db)\n                && !expr_ty.is_missing(db)\n                && ctx.resolver.inference.conform_ty(expr_ty, expected_ty).is_err()\n            {\n                ctx.diagnostics\n                    .report(&expr_syntax, WrongReturnType { expected_ty, actual_ty: expr_ty });\n            }\n            semantic::Statement::Return(semantic::StatementReturn {\n                expr: ctx.exprs.alloc(expr),\n                stable_ptr: syntax.stable_ptr(),\n            })\n        }\n        ast::Statement::Missing(_) => todo!(),\n    };\n    Ok(ctx.statements.alloc(statement))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_defs::db::DefsGroup;\nuse cairo_lang_defs::ids::FunctionWithBodyId;\nuse cairo_lang_utils::Upcast;\n\nuse crate::db::SemanticGroup;\n\n/// Holds all the information needed for formatting expressions.\n/// Acts like a \"db\" for DebugWithDb.\npub struct ExprFormatter<'a> {\n    pub db: &'a (dyn SemanticGroup + 'static),\n    pub function_id: FunctionWithBodyId,\n}\n\nimpl<'a> Upcast<dyn SemanticGroup + 'static> for ExprFormatter<'a> {\n    fn upcast(&self) -> &(dyn SemanticGroup + 'static) {\n        self.db\n    }\n}\nimpl<'a> Upcast<dyn DefsGroup + 'static> for ExprFormatter<'a> {\n    fn upcast(&self) -> &(dyn DefsGroup + 'static) {\n        self.db.upcast()\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Bidirectional type inference.\n\nuse std::collections::HashMap;\n\nuse cairo_lang_debug::DebugWithDb;\nuse cairo_lang_defs::ids::{\n    ConstantId, EnumId, ExternFunctionId, ExternTypeId, FreeFunctionId, GenericParamId, ImplDefId,\n    ImplFunctionId, LanguageElementId, LocalVarId, MemberId, ParamId, StructId, TraitFunctionId,\n    TraitId, VarId, VariantId,\n};\nuse cairo_lang_diagnostics::{skip_diagnostic, DiagnosticAdded};\nuse cairo_lang_proc_macros::DebugWithDb;\nuse cairo_lang_syntax::node::ids::SyntaxStablePtrId;\nuse cairo_lang_utils::extract_matches;\nuse cairo_lang_utils::ordered_hash_set::OrderedHashSet;\nuse itertools::{zip_eq, Itertools};\n\nuse crate::corelib::never_ty;\nuse crate::db::SemanticGroup;\nuse crate::diagnostic::{SemanticDiagnosticKind, SemanticDiagnostics};\nuse crate::expr::objects::*;\nuse crate::expr::pattern::*;\nuse crate::items::functions::{\n    ConcreteFunctionWithBody, GenericFunctionId, GenericFunctionWithBodyId, ImplGenericFunctionId,\n    ImplGenericFunctionWithBodyId,\n};\nuse crate::items::generics::{GenericParamConst, GenericParamImpl, GenericParamType};\nuse crate::items::imp::{\n    find_possible_impls_at_context, ImplId, ImplLookupContext, UninferredImpl,\n};\nuse crate::items::trt::{ConcreteTraitGenericFunctionId, ConcreteTraitGenericFunctionLongId};\nuse crate::literals::LiteralId;\nuse crate::substitution::{GenericSubstitution, HasDb, SemanticRewriter, SubstitutionRewriter};\nuse crate::types::{\n    peel_snapshots, ConcreteEnumLongId, ConcreteExternTypeLongId, ConcreteStructLongId,\n};\nuse crate::{\n    add_basic_rewrites, add_expr_rewrites, ConcreteEnumId, ConcreteExternTypeId, ConcreteFunction,\n    ConcreteImplId, ConcreteImplLongId, ConcreteStructId, ConcreteTraitId, ConcreteTraitLongId,\n    ConcreteTypeId, ConcreteVariant, ExprLiteral, FunctionId, FunctionLongId, GenericArgumentId,\n    GenericParam, LocalVariable, Member, Parameter, Pattern, SemanticObject, Signature, TypeId,\n    TypeLongId,\n};\n/// A type variable, created when a generic type argument is not passed, and thus is not known\n/// yet and needs to be inferred.\n#[derive(Copy, Clone, Debug, PartialEq, Eq, Hash)]\npub struct TypeVar {\n    pub id: usize,\n    pub stable_ptr: SyntaxStablePtrId,\n}\n\n/// An impl variable, created when a generic type argument is not passed, and thus is not known\n/// yet and needs to be inferred.\n#[derive(Copy, Clone, Debug, PartialEq, Eq, Hash, DebugWithDb)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct ImplVar {\n    pub id: usize,\n    pub concrete_trait_id: ConcreteTraitId,\n    pub stable_ptr: SyntaxStablePtrId,\n}\n\n#[derive(Copy, Clone, Debug, Eq, Hash, PartialEq)]\npub enum InferenceVar {\n    Type(usize),\n    Impl(usize),\n}\n\n// TODO(spapini): Add to diagnostics.\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum InferenceError {\n    Failed(DiagnosticAdded),\n    Cycle { var: InferenceVar },\n    TypeKindMismatch { ty0: TypeId, ty1: TypeId },\n    ImplKindMismatch { impl0: ImplId, impl1: ImplId },\n    GenericArgMismatch { garg0: GenericArgumentId, garg1: GenericArgumentId },\n    TraitMismatch { trt0: TraitId, trt1: TraitId },\n    ConstInferenceNotSupported,\n    NoImplsFound { concrete_trait_id: ConcreteTraitId },\n    MultipleImplsFound { concrete_trait_id: ConcreteTraitId, impls: Vec<UninferredImpl> },\n    TypeNotInferred { ty: TypeId },\n    WillNotInfer { concrete_trait_id: ConcreteTraitId },\n    AlreadyReported,\n}\nimpl InferenceError {\n    pub fn format(&self, db: &(dyn SemanticGroup + 'static)) -> String {\n        match self {\n            InferenceError::Failed(_) => \"Inference error occurred\".into(),\n            InferenceError::AlreadyReported => \"Inference error occurred again\".into(),\n            InferenceError::Cycle { var: _ } => \"Inference cycle detected\".into(),\n            InferenceError::TypeKindMismatch { ty0, ty1 } => {\n                format!(\"Type mismatch: {:?} and {:?}\", ty0.debug(db), ty1.debug(db))\n            }\n            InferenceError::ImplKindMismatch { impl0, impl1 } => {\n                format!(\"Impl mismatch: {:?} and {:?}\", impl0.debug(db), impl1.debug(db))\n            }\n            InferenceError::GenericArgMismatch { garg0, garg1 } => {\n                format!(\"Generic arg mismatch: {:?} and {:?}\", garg0.debug(db), garg1.debug(db))\n            }\n            InferenceError::TraitMismatch { trt0, trt1 } => {\n                format!(\"Trait mismatch: {:?} and {:?}\", trt0.debug(db), trt1.debug(db))\n            }\n            InferenceError::ConstInferenceNotSupported => {\n                \"Const generic inference not yet supported.\".into()\n            }\n            InferenceError::NoImplsFound { concrete_trait_id } => {\n                format!(\"Trait has no implementation in context: {:?}\", concrete_trait_id.debug(db))\n            }\n            InferenceError::MultipleImplsFound { concrete_trait_id, impls } => {\n                let impls_str =\n                    impls.iter().map(|imp| format!(\"{:?}\", imp.debug(db.upcast()))).join(\", \");\n                format!(\n                    \"Trait `{:?}` has multiple implementations, in: {impls_str}\",\n                    concrete_trait_id.debug(db)\n                )\n            }\n            InferenceError::TypeNotInferred { ty } => {\n                format!(\"Type annotations needed. Failed to infer {:?}\", ty.debug(db))\n            }\n            InferenceError::WillNotInfer { concrete_trait_id } => format!(\n                \"Cannot infer trait {:?}. First generic argument must be known.\",\n                concrete_trait_id.debug(db)\n            ),\n        }\n    }\n}\n\npub type InferenceResult<T> = Result<T, InferenceError>;\n\nimpl From<DiagnosticAdded> for InferenceError {\n    fn from(value: DiagnosticAdded) -> Self {\n        InferenceError::Failed(value)\n    }\n}\nimpl InferenceError {\n    pub fn report(\n        &self,\n        diagnostics: &mut SemanticDiagnostics,\n        stable_ptr: SyntaxStablePtrId,\n    ) -> DiagnosticAdded {\n        match self {\n            InferenceError::Failed(diagnostic_added) => *diagnostic_added,\n            // TODO(spapini): Better save hte DiagnosticAdded on the variable.\n            InferenceError::AlreadyReported => skip_diagnostic(),\n            _ => diagnostics.report_by_ptr(\n                stable_ptr,\n                SemanticDiagnosticKind::InternalInferenceError(self.clone()),\n            ),\n        }\n    }\n}\n\n#[derive(Clone, Debug)]\nstruct ImplVarData {\n    lookup_context: ImplLookupContext,\n    candidates: Option<OrderedHashSet<UninferredImpl>>,\n}\n\n/// State of inference.\n#[derive(Clone)]\npub struct Inference<'db> {\n    db: &'db dyn SemanticGroup,\n    /// Current inferred assignment for type variables.\n    type_assignment: HashMap<usize, TypeId>,\n    /// Current inferred assignment for impl variables.\n    impl_assignment: HashMap<usize, ImplId>,\n    /// Stable pointers for each type variable, used for reporting diagnostics properly.\n    type_vars: Vec<TypeVar>,\n    impl_vars: Vec<ImplVar>,\n    impl_var_data: Vec<ImplVarData>,\n    pub version: usize,\n    // TODO(spapini): Rank.\n}\n\n/// A debug struct of debug printing [Inference].\n#[derive(Clone, DebugWithDb)]\n#[debug_db(dyn SemanticGroup + 'static)]\nstruct InferenceDebug {\n    type_assignment: Vec<(usize, TypeId)>,\n    impl_assignment: Vec<(usize, ImplId)>,\n    type_vars: Vec<TypeVar>,\n    impl_vars: Vec<ImplVar>,\n    impl_var_data: Vec<ImplVarData>,\n    pub version: usize,\n}\n\nimpl<'db> std::fmt::Debug for Inference<'db> {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        let Self {\n            type_assignment,\n            impl_assignment,\n            type_vars,\n            impl_vars,\n            impl_var_data,\n            version,\n            ..\n        } = self.clone();\n        let util = InferenceDebug {\n            type_assignment: type_assignment.into_iter().collect(),\n            impl_assignment: impl_assignment.into_iter().collect(),\n            type_vars,\n            impl_vars,\n            impl_var_data,\n            version,\n        };\n        let x = util.debug(self.db.elongate());\n        write!(f, \"{x:?}\")\n    }\n}\n\nimpl<'db> Inference<'db> {\n    /// Creates a new [Inference] instance.\n    pub fn new(db: &'db dyn SemanticGroup) -> Self {\n        Self {\n            db,\n            type_assignment: Default::default(),\n            impl_assignment: Default::default(),\n            type_vars: Default::default(),\n            impl_vars: Default::default(),\n            impl_var_data: Default::default(),\n            version: 0,\n        }\n    }\n\n    /// Allocated a new [TypeVar] for an unknown type that needs to be inferred,\n    pub fn new_type_var(&mut self, stable_ptr: SyntaxStablePtrId) -> TypeId {\n        let var = TypeVar { id: self.type_vars.len(), stable_ptr };\n        self.type_vars.push(var);\n        self.version += 1;\n        self.db.intern_type(TypeLongId::Var(var))\n    }\n\n    /// Allocated a new [ImplVar] for an unknown type that needs to be inferred,\n    pub fn new_impl_var(\n        &mut self,\n        concrete_trait_id: ConcreteTraitId,\n        stable_ptr: SyntaxStablePtrId,\n        lookup_context: ImplLookupContext,\n    ) -> InferenceResult<ImplId> {\n        let mut lookup_context = lookup_context;\n        lookup_context\n            .extra_modules\n            .push(concrete_trait_id.trait_id(self.db).module_file_id(self.db.upcast()).0);\n\n        self.impl_var_data.push(ImplVarData { lookup_context, candidates: None });\n\n        let var = ImplVar { id: self.impl_vars.len(), concrete_trait_id, stable_ptr };\n        self.impl_vars.push(var);\n        self.version += 1;\n        self.relax_impl_var(var)\n    }\n\n    /// Relaxes all the constraints until stable.\n    /// Retrieves the first variable that is still not inferred, or None, if everything is\n    /// inferred.\n    pub fn finalize(&mut self) -> Option<(SyntaxStablePtrId, InferenceError)> {\n        // TODO(spapini): Remove the iterative logic in favor of event listeners.\n        loop {\n            let version = self.version;\n            for var in self.impl_vars.clone().into_iter() {\n                if let Err(err) = self.relax_impl_var(var) {\n                    return Some((var.stable_ptr, err));\n                }\n            }\n            if version == self.version {\n                return self.first_undetermined_variable();\n            }\n        }\n    }\n\n    /// Retrieves the first variable that is still not inferred, or None, if everything is\n    /// inferred.\n    fn first_undetermined_variable(&mut self) -> Option<(SyntaxStablePtrId, InferenceError)> {\n        for (id, var) in self.type_vars.iter().enumerate() {\n            if !self.type_assignment.contains_key(&id) {\n                let ty = self.db.intern_type(TypeLongId::Var(*var));\n                return Some((var.stable_ptr, InferenceError::TypeNotInferred { ty }));\n            }\n        }\n        for (id, var) in self.impl_vars.clone().into_iter().enumerate() {\n            if let Err(err) = self.relax_impl_var(var) {\n                return Some((var.stable_ptr, err));\n            }\n            if !self.impl_assignment.contains_key(&id) {\n                let concrete_trait_id = match self.rewrite(var.concrete_trait_id) {\n                    Ok(concrete_trait_id) => concrete_trait_id,\n                    Err(err) => {\n                        return Some((var.stable_ptr, err));\n                    }\n                };\n                let Some(candidates) = &self.impl_var_data[id].candidates else\n                {\n                    let concrete_trait_id = self.impl_vars[id].concrete_trait_id;\n                    let concrete_trait_id = self\n                        .rewrite(concrete_trait_id)\n                        .unwrap_or(concrete_trait_id);\n                    return Some((var.stable_ptr, InferenceError::WillNotInfer{concrete_trait_id}));\n                };\n                if candidates.is_empty() {\n                    return Some((var.stable_ptr, InferenceError::AlreadyReported));\n                }\n                let impls = candidates.clone();\n                let impls = impls\n                    .into_iter()\n                    .map(|impl_id| self.rewrite(impl_id).unwrap_or(impl_id))\n                    .collect();\n                return Some((\n                    var.stable_ptr,\n                    InferenceError::MultipleImplsFound { concrete_trait_id, impls },\n                ));\n            }\n        }\n        None\n    }\n\n    /// Returns the number of variables allocated for current inference.\n    /// Useful for deciding if new variables were introduced.\n    pub fn n_variables(&self) -> usize {\n        self.type_vars.len() + self.impl_vars.len()\n    }\n\n    /// Conforms ty0 to ty1. Should be called when ty0 should be coerced to ty1. Not symmetric.\n    /// Returns the reduced type for ty0, or an error if the type is no coercible.\n    pub fn conform_ty(&mut self, ty0: TypeId, ty1: TypeId) -> Result<TypeId, InferenceError> {\n        Ok(self.conform_ty_ex(ty0, ty1, false)?.0)\n    }\n\n    /// Same as conform_ty but supports adding snapshots to ty0 if `ty0_is_self` is true.\n    /// Returns the reduced type for ty0 and the number of snapshots that needs to be added\n    /// for the types to conform.\n    pub fn conform_ty_ex(\n        &mut self,\n        ty0: TypeId,\n        ty1: TypeId,\n        ty0_is_self: bool,\n    ) -> Result<(TypeId, usize), InferenceError> {\n        let ty0 = self.rewrite(ty0)?;\n        let ty1 = self.rewrite(ty1)?;\n        if ty0 == never_ty(self.db) {\n            return Ok((ty1, 0));\n        }\n        if ty0 == ty1 {\n            return Ok((ty0, 0));\n        }\n        let long_ty1 = self.db.lookup_intern_type(ty1);\n        match long_ty1 {\n            TypeLongId::Var(var) => return Ok((self.assign_ty(var, ty0)?, 0)),\n            TypeLongId::Missing(_) => return Ok((ty1, 0)),\n            TypeLongId::Snapshot(inner_ty) if ty0_is_self && inner_ty == ty0 => {\n                return Ok((ty1, 1));\n            }\n            _ => {}\n        }\n        let n_snapshots = 0;\n        let long_ty0 = self.db.lookup_intern_type(ty0);\n\n        match long_ty0 {\n            TypeLongId::Concrete(concrete0) => {\n                let (n_snapshots, long_ty1) = self.maybe_peel_snapshots(ty0_is_self, ty1);\n                let TypeLongId::Concrete(concrete1) = long_ty1 else {\n                    return Err(InferenceError::TypeKindMismatch { ty0, ty1 });\n                };\n                if concrete0.generic_type(self.db) != concrete1.generic_type(self.db) {\n                    return Err(InferenceError::TypeKindMismatch { ty0, ty1 });\n                }\n                let gargs0 = concrete0.generic_args(self.db);\n                let gargs1 = concrete1.generic_args(self.db);\n                let gargs = self.conform_generic_args(&gargs0, &gargs1)?;\n                let long_ty = TypeLongId::Concrete(ConcreteTypeId::new(\n                    self.db,\n                    concrete0.generic_type(self.db),\n                    gargs,\n                ));\n                Ok((self.db.intern_type(long_ty), n_snapshots))\n            }\n            TypeLongId::Tuple(tys0) => {\n                let (n_snapshots, long_ty1) = self.maybe_peel_snapshots(ty0_is_self, ty1);\n                let TypeLongId::Tuple(tys1) = long_ty1 else {\n                    return Err(InferenceError::TypeKindMismatch { ty0, ty1 });\n                };\n                if tys0.len() != tys1.len() {\n                    return Err(InferenceError::TypeKindMismatch { ty0, ty1 });\n                }\n                let tys = zip_eq(tys0, tys1)\n                    .map(|(subty0, subty1)| self.conform_ty(subty0, subty1))\n                    .collect::<Result<Vec<_>, _>>()?;\n                Ok((self.db.intern_type(TypeLongId::Tuple(tys)), n_snapshots))\n            }\n            TypeLongId::Snapshot(ty0) => {\n                let TypeLongId::Snapshot(ty1) = long_ty1 else {\n                    return Err(InferenceError::TypeKindMismatch { ty0, ty1 });\n                };\n                let (ty, n_snapshots) = self.conform_ty_ex(ty0, ty1, ty0_is_self)?;\n                Ok((self.db.intern_type(TypeLongId::Snapshot(ty)), n_snapshots))\n            }\n            TypeLongId::GenericParameter(_) => Err(InferenceError::TypeKindMismatch { ty0, ty1 }),\n            TypeLongId::Var(var) => Ok((self.assign_ty(var, ty1)?, n_snapshots)),\n            TypeLongId::Missing(_) => Ok((ty0, n_snapshots)),\n        }\n    }\n\n    // Conditionally peels snapshots.\n    fn maybe_peel_snapshots(&mut self, ty0_is_self: bool, ty1: TypeId) -> (usize, TypeLongId) {\n        let (n_snapshots, long_ty1) = if ty0_is_self {\n            peel_snapshots(self.db, ty1)\n        } else {\n            (0, self.db.lookup_intern_type(ty1))\n        };\n        (n_snapshots, long_ty1)\n    }\n\n    /// Conforms generics args. See `conform_ty()`.\n    fn conform_generic_args(\n        &mut self,\n        gargs0: &[GenericArgumentId],\n        gargs1: &[GenericArgumentId],\n    ) -> Result<Vec<GenericArgumentId>, InferenceError> {\n        zip_eq(gargs0, gargs1)\n            .map(|(garg0, garg1)| self.conform_generic_arg(*garg0, *garg1))\n            .collect::<Result<Vec<_>, _>>()\n    }\n\n    /// Conforms a generics arg. See `conform_ty()`.\n    pub fn conform_generic_arg(\n        &mut self,\n        garg0: GenericArgumentId,\n        garg1: GenericArgumentId,\n    ) -> Result<GenericArgumentId, InferenceError> {\n        if garg0 == garg1 {\n            return Ok(garg0);\n        }\n        match garg0 {\n            GenericArgumentId::Type(gty0) => {\n                let GenericArgumentId::Type(gty1) = garg1 else {\n                    return Err(InferenceError::GenericArgMismatch { garg0, garg1 });\n                };\n                Ok(GenericArgumentId::Type(self.conform_ty(gty0, gty1)?))\n            }\n            GenericArgumentId::Literal(_) => {\n                Err(InferenceError::GenericArgMismatch { garg0, garg1 })\n            }\n            GenericArgumentId::Impl(impl0) => {\n                let GenericArgumentId::Impl(impl1) = garg1 else {\n                    return Err(InferenceError::GenericArgMismatch { garg0, garg1 });\n                };\n                Ok(GenericArgumentId::Impl(self.conform_impl(impl0, impl1)?))\n            }\n        }\n    }\n\n    /// Assigns a value to an [ImplVar]. Return the assigned impl, or an error.\n    /// Assumes the variable is not already assigned.\n    fn assign_impl(&mut self, var: ImplVar, impl_id: ImplId) -> InferenceResult<ImplId> {\n        if let Some(other_impl) = self.impl_assignment.get(&var.id) {\n            return self.conform_impl(impl_id, *other_impl);\n        }\n        assert!(!self.impl_assignment.contains_key(&var.id), \"Cannot reassign variable.\");\n        if self.impl_contains_var(&impl_id, InferenceVar::Impl(var.id))? {\n            return Err(InferenceError::Cycle { var: InferenceVar::Impl(var.id) });\n        }\n        self.impl_assignment.insert(var.id, impl_id);\n        self.version += 1;\n        Ok(impl_id)\n    }\n\n    /// Conforms an impl. See `conform_ty()`.\n    pub fn conform_impl(&mut self, impl0: ImplId, impl1: ImplId) -> InferenceResult<ImplId> {\n        let impl0 = self.rewrite(impl0)?;\n        let impl1 = self.rewrite(impl1)?;\n        if impl0 == impl1 {\n            return Ok(impl0);\n        }\n        if let ImplId::ImplVar(var) = impl1 {\n            self.conform_traits(var.concrete_trait_id, self.db.impl_concrete_trait(impl0)?)?;\n            let impl_id = self.rewrite(impl0)?;\n            return self.assign_impl(var, impl_id);\n        }\n        match impl0 {\n            ImplId::ImplVar(var) => {\n                self.conform_traits(var.concrete_trait_id, self.db.impl_concrete_trait(impl1)?)?;\n                let impl_id = self.rewrite(impl1)?;\n                self.assign_impl(var, impl_id)\n            }\n            ImplId::Concrete(concrete0) => {\n                let ImplId::Concrete(concrete1) = impl1 else {\n                    return Err(InferenceError::ImplKindMismatch { impl0, impl1 });\n                };\n                let concrete0 = self.db.lookup_intern_concrete_impl(concrete0);\n                let concrete1 = self.db.lookup_intern_concrete_impl(concrete1);\n                if concrete0.impl_def_id != concrete1.impl_def_id {\n                    return Err(InferenceError::ImplKindMismatch { impl0, impl1 });\n                }\n                let gargs0 = concrete0.generic_args;\n                let gargs1 = concrete1.generic_args;\n                let generic_args = self.conform_generic_args(&gargs0, &gargs1)?;\n                Ok(ImplId::Concrete(self.db.intern_concrete_impl(ConcreteImplLongId {\n                    impl_def_id: concrete0.impl_def_id,\n                    generic_args,\n                })))\n            }\n            ImplId::GenericParameter(_) => Err(InferenceError::ImplKindMismatch { impl0, impl1 }),\n        }\n    }\n\n    /// Conforms generics traits. See `conform_ty()`.\n    pub fn conform_traits(\n        &mut self,\n        trt0: ConcreteTraitId,\n        trt1: ConcreteTraitId,\n    ) -> Result<ConcreteTraitId, InferenceError> {\n        let trt0 = self.db.lookup_intern_concrete_trait(trt0);\n        let trt1 = self.db.lookup_intern_concrete_trait(trt1);\n        if trt0.trait_id != trt1.trait_id {\n            return Err(InferenceError::TraitMismatch { trt0: trt0.trait_id, trt1: trt1.trait_id });\n        }\n        let generic_args = self.conform_generic_args(&trt0.generic_args, &trt1.generic_args)?;\n        Ok(self\n            .db\n            .intern_concrete_trait(ConcreteTraitLongId { trait_id: trt0.trait_id, generic_args }))\n    }\n\n    /// Assigns a value to a [TypeVar]. Return the assigned type, or an error.\n    /// Assumes the variable is not already assigned.\n    fn assign_ty(&mut self, var: TypeVar, ty: TypeId) -> InferenceResult<TypeId> {\n        assert!(!self.type_assignment.contains_key(&var.id), \"Cannot reassign variable.\");\n        let inference_var = InferenceVar::Type(var.id);\n        if self.ty_contains_var(ty, inference_var)? {\n            return Err(InferenceError::Cycle { var: inference_var });\n        }\n        self.type_assignment.insert(var.id, ty);\n        self.version += 1;\n        Ok(ty)\n    }\n\n    /// Checks if a type tree contains a certain [InferenceVar] somewhere. Used to avoid inference\n    /// cycles.\n    pub fn ty_contains_var(&mut self, ty: TypeId, var: InferenceVar) -> InferenceResult<bool> {\n        Ok(match self.db.lookup_intern_type(self.rewrite(ty)?) {\n            TypeLongId::Concrete(concrete) => {\n                let generic_args = concrete.generic_args(self.db);\n                self.generic_args_contain_var(&generic_args, var)?\n            }\n            TypeLongId::Tuple(tys) => tys\n                .into_iter()\n                .map(|ty| self.ty_contains_var(ty, var))\n                .collect::<InferenceResult<Vec<_>>>()?\n                .into_iter()\n                .any(|x| x),\n            TypeLongId::Snapshot(ty) => self.ty_contains_var(ty, var)?,\n            TypeLongId::Var(new_var) => {\n                if InferenceVar::Type(new_var.id) == var {\n                    return Ok(true);\n                }\n                if let Some(ty) = self.type_assignment.get(&new_var.id) {\n                    return self.ty_contains_var(*ty, var);\n                }\n                false\n            }\n            TypeLongId::GenericParameter(_) | TypeLongId::Missing(_) => false,\n        })\n    }\n\n    /// Checks if a slice of generics arguments contain a certain [InferenceVar] somewhere. Used to\n    /// avoid inference cycles.\n    fn generic_args_contain_var(\n        &mut self,\n        generic_args: &[GenericArgumentId],\n        var: InferenceVar,\n    ) -> InferenceResult<bool> {\n        for garg in generic_args {\n            if match garg {\n                GenericArgumentId::Type(ty) => self.ty_contains_var(*ty, var)?,\n                GenericArgumentId::Literal(_) => false,\n                GenericArgumentId::Impl(impl_id) => self.impl_contains_var(impl_id, var)?,\n            } {\n                return Ok(true);\n            }\n        }\n        Ok(false)\n    }\n\n    /// Checks if an impl contains a certain [InferenceVar] somewhere. Used to avoid inference\n    /// cycles.\n    fn impl_contains_var(\n        &mut self,\n        impl_id: &ImplId,\n        var: InferenceVar,\n    ) -> Result<bool, InferenceError> {\n        Ok(match impl_id {\n            ImplId::Concrete(concrete_impl_id) => self.generic_args_contain_var(\n                &self.db.lookup_intern_concrete_impl(*concrete_impl_id).generic_args,\n                var,\n            )?,\n            ImplId::GenericParameter(_) => false,\n            ImplId::ImplVar(new_var) => {\n                if InferenceVar::Impl(new_var.id) == var {\n                    return Ok(true);\n                }\n                if let Some(impl_id) = self.impl_assignment.get(&new_var.id).copied() {\n                    return self.impl_contains_var(&impl_id, var);\n                }\n                false\n            }\n        })\n    }\n\n    /// Determines if an assignment to `generic_params` can be chosen s.t. `generic_args` will be\n    /// substituted to `expected_generic_args`.\n    // TODO(spapini): Fail gracefully on infinite loops.\n    pub fn can_infer_generics(\n        &self,\n        generic_params: &[GenericParam],\n        generic_args: &[GenericArgumentId],\n        expected_generic_args: &[GenericArgumentId],\n        lookup_context: &ImplLookupContext,\n        stable_ptr: SyntaxStablePtrId,\n    ) -> bool {\n        if generic_args.len() != expected_generic_args.len() {\n            return false;\n        }\n        let mut inference = self.clone();\n        let res = inference.infer_generic_assignment(\n            generic_params,\n            generic_args,\n            expected_generic_args,\n            lookup_context,\n            stable_ptr,\n        );\n        res.is_ok()\n    }\n\n    /// Determines if an impl (possibly with free generic params) can provide a concrete trait.\n    pub fn can_impl_trait(\n        &self,\n        impl_def_id: ImplDefId,\n        concrete_trait_id: ConcreteTraitId,\n        lookup_context: &ImplLookupContext,\n        stable_ptr: SyntaxStablePtrId,\n    ) -> bool {\n        let Ok(imp_generic_param) = self.db.impl_def_generic_params(impl_def_id) else {\n            return false\n        };\n        let Ok(imp_concrete_trait) = self.db.impl_def_concrete_trait(impl_def_id) else {\n            return false\n        };\n        if imp_concrete_trait.trait_id(self.db) != concrete_trait_id.trait_id(self.db) {\n            return false;\n        }\n\n        let long_concrete_trait = self.db.lookup_intern_concrete_trait(concrete_trait_id);\n        let long_imp_concrete_trait = self.db.lookup_intern_concrete_trait(imp_concrete_trait);\n        self.can_infer_generics(\n            &imp_generic_param,\n            &long_imp_concrete_trait.generic_args,\n            &long_concrete_trait.generic_args,\n            lookup_context,\n            stable_ptr,\n        )\n    }\n\n    /// Infers all the variables required to make an impl (possibly with free generic params)\n    /// provide a concrete trait.\n    pub fn infer_impl_trait(\n        &mut self,\n        impl_def_id: ImplDefId,\n        concrete_trait_id: ConcreteTraitId,\n        lookup_context: &ImplLookupContext,\n        stable_ptr: SyntaxStablePtrId,\n    ) -> Result<ImplId, InferenceError> {\n        let imp_generic_params = self.db.impl_def_generic_params(impl_def_id)?;\n        let imp_concrete_trait = self.db.impl_def_concrete_trait(impl_def_id)?;\n        if imp_concrete_trait.trait_id(self.db) != concrete_trait_id.trait_id(self.db) {\n            return Err(InferenceError::TraitMismatch {\n                trt0: imp_concrete_trait.trait_id(self.db),\n                trt1: concrete_trait_id.trait_id(self.db),\n            });\n        }\n\n        let long_concrete_trait = self.db.lookup_intern_concrete_trait(concrete_trait_id);\n        let long_imp_concrete_trait = self.db.lookup_intern_concrete_trait(imp_concrete_trait);\n        let generic_args = self.infer_generic_assignment(\n            &imp_generic_params,\n            &long_imp_concrete_trait.generic_args,\n            &long_concrete_trait.generic_args,\n            lookup_context,\n            stable_ptr,\n        )?;\n        Ok(ImplId::Concrete(\n            self.db.intern_concrete_impl(ConcreteImplLongId { impl_def_id, generic_args }),\n        ))\n    }\n\n    /// Chooses and assignment to generic_params s.t. generic_args will be substituted to\n    /// expected_generic_args.\n    /// Returns the generic_params assignment.\n    pub fn infer_generic_assignment(\n        &mut self,\n        generic_params: &[GenericParam],\n        generic_args: &[GenericArgumentId],\n        expected_generic_args: &[GenericArgumentId],\n        lookup_context: &ImplLookupContext,\n        stable_ptr: SyntaxStablePtrId,\n    ) -> InferenceResult<Vec<GenericArgumentId>> {\n        let new_generic_args =\n            self.infer_generic_args(generic_params, lookup_context, stable_ptr)?;\n        let substitution = GenericSubstitution::new(generic_params, &new_generic_args);\n        let mut rewriter = SubstitutionRewriter { db: self.db, substitution: &substitution };\n        let generic_args = rewriter.rewrite(generic_args.iter().copied().collect_vec())?;\n        self.conform_generic_args(&generic_args, expected_generic_args)?;\n        self.rewrite(new_generic_args)\n    }\n\n    /// Infers all generic_arguments given the parameters.\n    pub fn infer_generic_args(\n        &mut self,\n        generic_params: &[GenericParam],\n        lookup_context: &ImplLookupContext,\n        stable_ptr: SyntaxStablePtrId,\n    ) -> InferenceResult<Vec<GenericArgumentId>> {\n        let mut generic_args = vec![];\n        let mut substitution = GenericSubstitution::default();\n        for generic_param in generic_params {\n            let generic_param = SubstitutionRewriter { db: self.db, substitution: &substitution }\n                .rewrite(*generic_param)\n                .map_err(InferenceError::Failed)?;\n            let generic_arg =\n                self.infer_generic_arg(&generic_param, lookup_context.clone(), stable_ptr)?;\n            generic_args.push(generic_arg);\n            substitution.0.insert(generic_param.id(), generic_arg);\n        }\n        Ok(generic_args)\n    }\n\n    /// Tries to infer a trait function as a method for `self_ty`.\n    /// Supports snapshot snapshot coercions.\n    ///\n    /// Returns the deduced type and the number of snapshots that need to be added to it.\n    pub fn infer_concrete_trait_by_self(\n        &mut self,\n        trait_function: TraitFunctionId,\n        self_ty: TypeId,\n        lookup_context: &ImplLookupContext,\n        stable_ptr: SyntaxStablePtrId,\n    ) -> Option<(ConcreteTraitId, usize)> {\n        let trait_id = trait_function.trait_id(self.db.upcast());\n        let signature = self.db.trait_function_signature(trait_function).ok()?;\n        let first_param = signature.params.into_iter().next()?;\n        if first_param.name != \"self\" {\n            return None;\n        }\n        let generic_params = self.db.trait_generic_params(trait_id).ok()?;\n        let generic_args =\n            self.infer_generic_args(&generic_params, lookup_context, stable_ptr).ok()?;\n        let substitution = GenericSubstitution::new(&generic_params, &generic_args);\n        let mut rewriter = SubstitutionRewriter { db: self.db, substitution: &substitution };\n\n        let fixed_param_ty = rewriter.rewrite(first_param.ty).ok()?;\n        let (_, n_snapshots) = self.conform_ty_ex(self_ty, fixed_param_ty, true).ok()?;\n        let generic_args = self.rewrite(generic_args).ok()?;\n\n        Some((\n            self.db.intern_concrete_trait(ConcreteTraitLongId { trait_id, generic_args }),\n            n_snapshots,\n        ))\n    }\n\n    /// Infers a generic argument to be passed as a generic paramter.\n    /// Allocates a new inference variable of the correct kind, and wraps in a generic argument.\n    pub fn infer_generic_arg(\n        &mut self,\n        param: &GenericParam,\n        lookup_context: ImplLookupContext,\n        stable_ptr: SyntaxStablePtrId,\n    ) -> InferenceResult<GenericArgumentId> {\n        match param {\n            GenericParam::Type(_) => Ok(GenericArgumentId::Type(self.new_type_var(stable_ptr))),\n            GenericParam::Impl(param) => Ok(GenericArgumentId::Impl(self.new_impl_var(\n                param.concrete_trait?,\n                stable_ptr,\n                lookup_context,\n            )?)),\n            GenericParam::Const(_) => Err(InferenceError::ConstInferenceNotSupported),\n        }\n    }\n\n    /// Infers the impl to be substituted instead of a trait for a given trait function,\n    /// and the generic arguments to be passed to the function.\n    /// Returns the resulting impl function.\n    pub fn infer_trait_function(\n        &mut self,\n        concrete_trait_function: ConcreteTraitGenericFunctionId,\n        lookup_context: &ImplLookupContext,\n        stable_ptr: SyntaxStablePtrId,\n    ) -> InferenceResult<FunctionId> {\n        let generic_function =\n            self.infer_trait_generic_function(concrete_trait_function, lookup_context, stable_ptr)?;\n        self.infer_generic_function(generic_function, lookup_context, stable_ptr)\n    }\n\n    /// Infers generic arguments to be passed to a generic function.\n    /// Returns the resulting specialized function.\n    pub fn infer_generic_function(\n        &mut self,\n        generic_function: GenericFunctionId,\n        lookup_context: &ImplLookupContext,\n        stable_ptr: SyntaxStablePtrId,\n    ) -> InferenceResult<FunctionId> {\n        let generic_params = generic_function.generic_params(self.db)?;\n        let generic_args = self.infer_generic_args(&generic_params, lookup_context, stable_ptr)?;\n        Ok(self.db.intern_function(FunctionLongId {\n            function: ConcreteFunction { generic_function, generic_args },\n        }))\n    }\n\n    /// Infers the impl to be substituted instead of a trait for a given trait function.\n    /// Returns the resulting impl generic function.\n    pub fn infer_trait_generic_function(\n        &mut self,\n        trait_function: ConcreteTraitGenericFunctionId,\n        lookup_context: &ImplLookupContext,\n        stable_ptr: SyntaxStablePtrId,\n    ) -> InferenceResult<GenericFunctionId> {\n        let impl_id = self.new_impl_var(\n            trait_function.concrete_trait_id(self.db),\n            stable_ptr,\n            lookup_context.clone(),\n        )?;\n        Ok(GenericFunctionId::Impl(ImplGenericFunctionId {\n            impl_id,\n            function: trait_function.function_id(self.db),\n        }))\n    }\n\n    // Resumes inference for an impl var.\n    pub fn try_to_resume_impl_var(&mut self, var: ImplVar) -> InferenceResult<()> {\n        if self.impl_var_data[var.id].candidates.is_some() {\n            return Ok(());\n        }\n        let mut lookup_context = self.impl_var_data[var.id].lookup_context.clone();\n\n        let concrete_trait_id = self.rewrite(var.concrete_trait_id)?;\n        match concrete_trait_id.generic_args(self.db).get(0) {\n            Some(GenericArgumentId::Type(ty)) => {\n                match self.db.lookup_intern_type(*ty) {\n                    TypeLongId::Concrete(concrete) => {\n                        // Add the defining module of the first generic param to the lookup.\n                        lookup_context.extra_modules.push(\n                            concrete.generic_type(self.db).module_file_id(self.db.upcast()).0,\n                        );\n                    }\n                    TypeLongId::Var(_) => {\n                        // Don't try to infer such impls.\n                        return Ok(());\n                    }\n                    _ => {}\n                }\n            }\n            Some(GenericArgumentId::Impl(ImplId::ImplVar(_))) => {\n                // Don't try to infer such impls.\n                return Ok(());\n            }\n            _ => {}\n        };\n        let candidates = find_possible_impls_at_context(\n            self.db,\n            self,\n            &lookup_context,\n            concrete_trait_id,\n            var.stable_ptr,\n        )\n        .map_err(InferenceError::Failed)?;\n        self.impl_var_data[var.id].candidates = Some(candidates.clone());\n        log::debug!(\n            \"Impl inference candidates for {:?} at {:?}: {:?}\",\n            concrete_trait_id.debug(self.db.elongate()),\n            lookup_context.debug(self.db.elongate()),\n            candidates.iter().collect_vec().debug(self.db.elongate()),\n        );\n        if candidates.is_empty() {\n            return Err(InferenceError::NoImplsFound { concrete_trait_id });\n        }\n        self.version += 1;\n        Ok(())\n    }\n\n    /// Relaxes the information about an [ImplVar]. Prunes the current candidate impls, and assigns\n    /// if only a single candidate is left.\n    fn relax_impl_var(&mut self, var: ImplVar) -> InferenceResult<ImplId> {\n        // TODO(spapini): Beware of cycles.\n        if let Some(res) = self.impl_assignment.get(&var.id) {\n            return self.rewrite(*res);\n        }\n        let var_concrete_trait_id = self.rewrite(var.concrete_trait_id)?;\n        self.try_to_resume_impl_var(var)?;\n        let inference_clone = self.clone();\n        let lookup_context = self.impl_var_data[var.id].lookup_context.clone();\n        let Some(candidates) = &mut self.impl_var_data[var.id].candidates else {\n            return Ok(ImplId::ImplVar(var));\n        };\n        if candidates.is_empty() {\n            return Err(InferenceError::AlreadyReported);\n        }\n        for candidate in candidates.clone() {\n            let should_keep = match candidate {\n                UninferredImpl::Def(impl_def_id) => inference_clone.can_impl_trait(\n                    impl_def_id,\n                    var_concrete_trait_id,\n                    &lookup_context,\n                    var.stable_ptr,\n                ),\n\n                UninferredImpl::GenericParam(param_id) => {\n                    let param =\n                        self.db.generic_param_semantic(param_id).map_err(InferenceError::Failed)?;\n                    let GenericParam::Impl(param) = param else { continue; };\n                    let Ok(imp_concrete_trait_id) = param.concrete_trait else {continue};\n                    let mut temp_inference = inference_clone.clone();\n                    temp_inference\n                        .conform_traits(var_concrete_trait_id, imp_concrete_trait_id)\n                        .is_ok()\n                }\n            };\n            if !should_keep {\n                self.version += 1;\n                candidates.swap_remove(&candidate);\n            }\n        }\n        match candidates.len() {\n            0 => Err(InferenceError::NoImplsFound { concrete_trait_id: var_concrete_trait_id }),\n            1 => {\n                let candidates = std::mem::take(candidates);\n                let candidate = candidates.into_iter().next().unwrap();\n\n                let impl_id = match candidate {\n                    UninferredImpl::Def(impl_def_id) => self.infer_impl_trait(\n                        impl_def_id,\n                        var_concrete_trait_id,\n                        &lookup_context,\n                        var.stable_ptr,\n                    )?,\n                    UninferredImpl::GenericParam(param_id) => {\n                        let param = self\n                            .db\n                            .generic_param_semantic(param_id)\n                            .map_err(InferenceError::Failed)?;\n                        let param = extract_matches!(param, GenericParam::Impl);\n                        let imp_concrete_trait_id = param.concrete_trait.unwrap();\n                        self.conform_traits(var_concrete_trait_id, imp_concrete_trait_id)?;\n                        ImplId::GenericParameter(param_id)\n                    }\n                };\n\n                let impl_id = self.rewrite(impl_id)?;\n                self.assign_impl(var, impl_id)\n            }\n            _ => Ok(ImplId::ImplVar(var)),\n        }\n    }\n}\n\nimpl<'a> HasDb<&'a dyn SemanticGroup> for Inference<'a> {\n    fn get_db(&self) -> &'a dyn SemanticGroup {\n        self.db\n    }\n}\nadd_basic_rewrites!(<'a>, Inference<'a>, InferenceError, @exclude TypeLongId ImplId);\nadd_expr_rewrites!(<'a>, Inference<'a>, InferenceError, @exclude);\nimpl<'a> SemanticRewriter<TypeLongId, InferenceError> for Inference<'a> {\n    fn rewrite(&mut self, value: TypeLongId) -> Result<TypeLongId, InferenceError> {\n        if let TypeLongId::Var(var) = value {\n            if let Some(type_id) = self.type_assignment.get(&var.id) {\n                return self.rewrite(self.db.lookup_intern_type(*type_id));\n            }\n        }\n        value.default_rewrite(self)\n    }\n}\nimpl<'a> SemanticRewriter<ImplId, InferenceError> for Inference<'a> {\n    fn rewrite(&mut self, value: ImplId) -> InferenceResult<ImplId> {\n        if let ImplId::ImplVar(var) = value {\n            // Relax the candidates.\n            if let Some(impl_id) = self.impl_assignment.get(&var.id) {\n                return self.rewrite(*impl_id);\n            } else {\n                self.relax_impl_var(var)?;\n            }\n        }\n        value.default_rewrite(self)\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! This module is responsible for inner code elements, such as expressions and statements.\n#[cfg(test)]\nmod test;\n\npub mod compute;\npub mod fmt;\npub mod inference;\npub mod objects;\npub mod pattern;\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_debug::DebugWithDb;\nuse cairo_lang_defs::ids::{ConstantId, MemberId, VarId};\nuse cairo_lang_diagnostics::DiagnosticAdded;\nuse cairo_lang_proc_macros::{DebugWithDb, SemanticObject};\nuse cairo_lang_syntax::node::ast::{self};\nuse id_arena::Id;\nuse num_bigint::BigInt;\n\nuse super::fmt::ExprFormatter;\nuse super::pattern::Pattern;\nuse crate::{semantic, ConcreteStructId, FunctionId, TypeId};\n\npub type ExprId = Id<Expr>;\npub type StatementId = Id<Statement>;\n\nimpl DebugWithDb<ExprFormatter<'_>> for ExprId {\n    fn fmt(\n        &self,\n        f: &mut std::fmt::Formatter<'_>,\n        expr_formatter: &ExprFormatter<'_>,\n    ) -> std::fmt::Result {\n        expr_formatter.db.expr_semantic(expr_formatter.function_id, *self).fmt(f, expr_formatter)\n    }\n}\nimpl DebugWithDb<ExprFormatter<'_>> for StatementId {\n    fn fmt(\n        &self,\n        f: &mut std::fmt::Formatter<'_>,\n        expr_formatter: &ExprFormatter<'_>,\n    ) -> std::fmt::Result {\n        expr_formatter\n            .db\n            .statement_semantic(expr_formatter.function_id, *self)\n            .fmt(f, expr_formatter)\n    }\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub enum Statement {\n    Expr(StatementExpr),\n    Let(StatementLet),\n    Return(StatementReturn),\n}\nimpl Statement {\n    pub fn stable_ptr(&self) -> ast::StatementPtr {\n        match self {\n            Statement::Expr(stmt) => stmt.stable_ptr,\n            Statement::Let(stmt) => stmt.stable_ptr,\n            Statement::Return(stmt) => stmt.stable_ptr,\n        }\n    }\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub struct StatementExpr {\n    pub expr: ExprId,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub stable_ptr: ast::StatementPtr,\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub struct StatementLet {\n    pub pattern: Pattern,\n    pub expr: ExprId,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub stable_ptr: ast::StatementPtr,\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub struct StatementReturn {\n    pub expr: ExprId,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub stable_ptr: ast::StatementPtr,\n}\n\n// Expressions.\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub enum Expr {\n    Tuple(ExprTuple),\n    Snapshot(ExprSnapshot),\n    Desnap(ExprDesnap),\n    Assignment(ExprAssignment),\n    Block(ExprBlock),\n    FunctionCall(ExprFunctionCall),\n    Match(ExprMatch),\n    If(ExprIf),\n    Var(ExprVar),\n    Literal(ExprLiteral),\n    MemberAccess(ExprMemberAccess),\n    StructCtor(ExprStructCtor),\n    EnumVariantCtor(ExprEnumVariantCtor),\n    PropagateError(ExprPropagateError),\n    Constant(ExprConstant),\n    Missing(ExprMissing),\n}\nimpl Expr {\n    pub fn ty(&self) -> semantic::TypeId {\n        match self {\n            Expr::Assignment(expr) => expr.ty,\n            Expr::Tuple(expr) => expr.ty,\n            Expr::Snapshot(expr) => expr.ty,\n            Expr::Desnap(expr) => expr.ty,\n            Expr::Block(expr) => expr.ty,\n            Expr::FunctionCall(expr) => expr.ty,\n            Expr::Match(expr) => expr.ty,\n            Expr::If(expr) => expr.ty,\n            Expr::Var(expr) => expr.ty,\n            Expr::Literal(expr) => expr.ty,\n            Expr::MemberAccess(expr) => expr.ty,\n            Expr::StructCtor(expr) => expr.ty,\n            Expr::EnumVariantCtor(expr) => expr.ty,\n            Expr::PropagateError(expr) => expr.ok_variant.ty,\n            Expr::Constant(expr) => expr.ty,\n            Expr::Missing(expr) => expr.ty,\n        }\n    }\n    pub fn stable_ptr(&self) -> ast::ExprPtr {\n        match self {\n            Expr::Assignment(expr) => expr.stable_ptr,\n            Expr::Tuple(expr) => expr.stable_ptr,\n            Expr::Snapshot(expr) => expr.stable_ptr,\n            Expr::Desnap(expr) => expr.stable_ptr,\n            Expr::Block(expr) => expr.stable_ptr,\n            Expr::FunctionCall(expr) => expr.stable_ptr,\n            Expr::Match(expr) => expr.stable_ptr,\n            Expr::If(expr) => expr.stable_ptr,\n            Expr::Var(expr) => expr.stable_ptr,\n            Expr::Literal(expr) => expr.stable_ptr,\n            Expr::MemberAccess(expr) => expr.stable_ptr,\n            Expr::StructCtor(expr) => expr.stable_ptr,\n            Expr::EnumVariantCtor(expr) => expr.stable_ptr,\n            Expr::PropagateError(expr) => expr.stable_ptr,\n            Expr::Constant(expr) => expr.stable_ptr,\n            Expr::Missing(expr) => expr.stable_ptr,\n        }\n    }\n\n    pub fn as_member_path(&self) -> Option<VarMemberPath> {\n        match self {\n            Expr::Var(expr) => Some(VarMemberPath::Var(expr.clone())),\n            Expr::MemberAccess(expr) => expr.member_path.clone(),\n            _ => None,\n        }\n    }\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub struct ExprTuple {\n    pub items: Vec<ExprId>,\n    pub ty: semantic::TypeId,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub stable_ptr: ast::ExprPtr,\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub struct ExprSnapshot {\n    pub inner: ExprId,\n    pub ty: semantic::TypeId,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub stable_ptr: ast::ExprPtr,\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub struct ExprDesnap {\n    pub inner: ExprId,\n    pub ty: semantic::TypeId,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub stable_ptr: ast::ExprPtr,\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub struct ExprBlock {\n    pub statements: Vec<StatementId>,\n    /// Blocks may end with an expression, without a trailing `;`.\n    /// In this case, `tail` will be Some(expr) with that expression.\n    /// The block expression will evaluate to this tail expression.\n    /// Otherwise, this will be None.\n    pub tail: Option<ExprId>,\n    pub ty: semantic::TypeId,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub stable_ptr: ast::ExprPtr,\n}\n\n/// A sequence of member accesses of a variable. For example: a, a.b, a.b.c, ...\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub enum VarMemberPath {\n    Var(ExprVar),\n    Member {\n        parent: Box<VarMemberPath>,\n        member_id: MemberId,\n        #[dont_rewrite]\n        stable_ptr: ast::ExprPtr,\n        concrete_struct_id: ConcreteStructId,\n        // Type of the member.\n        ty: TypeId,\n    },\n}\nimpl VarMemberPath {\n    pub fn base_var(&self) -> VarId {\n        match self {\n            VarMemberPath::Var(expr) => expr.var,\n            VarMemberPath::Member { parent, .. } => parent.base_var(),\n        }\n    }\n    pub fn ty(&self) -> TypeId {\n        match self {\n            VarMemberPath::Var(expr) => expr.ty,\n            VarMemberPath::Member { ty, .. } => *ty,\n        }\n    }\n    pub fn stable_ptr(&self) -> ast::ExprPtr {\n        match self {\n            VarMemberPath::Var(var) => var.stable_ptr,\n            VarMemberPath::Member { stable_ptr, .. } => *stable_ptr,\n        }\n    }\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub enum ExprFunctionCallArg {\n    Reference(VarMemberPath),\n    Value(ExprId),\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub struct ExprFunctionCall {\n    pub function: FunctionId,\n    pub args: Vec<ExprFunctionCallArg>,\n    pub ty: semantic::TypeId,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub stable_ptr: ast::ExprPtr,\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub struct ExprMatch {\n    pub matched_expr: ExprId,\n    pub arms: Vec<MatchArm>,\n    pub ty: semantic::TypeId,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub stable_ptr: ast::ExprPtr,\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub struct ExprIf {\n    pub condition: ExprId,\n    pub if_block: ExprId,\n    pub else_block: Option<ExprId>,\n    pub ty: semantic::TypeId,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub stable_ptr: ast::ExprPtr,\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub struct MatchArm {\n    pub pattern: Pattern,\n    pub expression: ExprId,\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub struct ExprAssignment {\n    pub ref_arg: VarMemberPath,\n    pub rhs: semantic::ExprId,\n    // ExprAssignment is always of unit type.\n    pub ty: semantic::TypeId,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub stable_ptr: ast::ExprPtr,\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub struct ExprVar {\n    pub var: VarId,\n    pub ty: semantic::TypeId,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub stable_ptr: ast::ExprPtr,\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub struct ExprLiteral {\n    #[dont_rewrite]\n    pub value: BigInt,\n    pub ty: semantic::TypeId,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub stable_ptr: ast::ExprPtr,\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub struct ExprMemberAccess {\n    pub expr: semantic::ExprId,\n    pub concrete_struct_id: ConcreteStructId,\n    pub member: MemberId,\n    pub ty: semantic::TypeId,\n    #[hide_field_debug_with_db]\n    pub member_path: Option<VarMemberPath>,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub n_snapshots: usize,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub stable_ptr: ast::ExprPtr,\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub struct ExprStructCtor {\n    pub concrete_struct_id: ConcreteStructId,\n    pub members: Vec<(MemberId, ExprId)>,\n    pub ty: semantic::TypeId,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub stable_ptr: ast::ExprPtr,\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub struct ExprEnumVariantCtor {\n    pub variant: semantic::ConcreteVariant,\n    pub value_expr: ExprId,\n    pub ty: semantic::TypeId,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub stable_ptr: ast::ExprPtr,\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub struct ExprPropagateError {\n    pub inner: ExprId,\n    pub ok_variant: semantic::ConcreteVariant,\n    pub err_variant: semantic::ConcreteVariant,\n    pub func_err_variant: semantic::ConcreteVariant,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub stable_ptr: ast::ExprPtr,\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub struct ExprConstant {\n    pub constant_id: ConstantId,\n    pub ty: semantic::TypeId,\n    #[dont_rewrite]\n    #[hide_field_debug_with_db]\n    pub stable_ptr: ast::ExprPtr,\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub struct ExprMissing {\n    pub ty: semantic::TypeId,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub stable_ptr: ast::ExprPtr,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub diag_added: DiagnosticAdded,\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_debug::DebugWithDb;\nuse cairo_lang_proc_macros::{DebugWithDb, SemanticObject};\nuse cairo_lang_syntax::node::ast;\nuse smol_str::SmolStr;\n\nuse super::fmt::ExprFormatter;\nuse crate::corelib::core_felt252_ty;\nuse crate::db::SemanticGroup;\nuse crate::{semantic, ConcreteStructId, ExprLiteral, LocalVariable};\n\n/// Semantic representation of a Pattern.\n/// A pattern is a way to \"destructure\" values. A pattern may introduce new variables that are bound\n/// to inner values of a specific value. For example, a tuple pattern destructures a tuple\n/// and may result in new variables for an elements of that tuple.\n/// This is used both in let statements and match statements.\n// TODO(spapini): Replace this doc with a reference to the language documentation about patterns,\n// once it is available.\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub enum Pattern {\n    Literal(PatternLiteral),\n    Variable(PatternVariable),\n    Struct(PatternStruct),\n    Tuple(PatternTuple),\n    EnumVariant(PatternEnumVariant),\n    Otherwise(PatternOtherwise),\n}\nimpl Pattern {\n    pub fn ty(&self, db: &dyn SemanticGroup) -> semantic::TypeId {\n        match self {\n            Pattern::Literal(_) => core_felt252_ty(db),\n            Pattern::Variable(variable) => variable.var.ty,\n            Pattern::Struct(pattern_struct) => pattern_struct.ty,\n            Pattern::Tuple(pattern_tuple) => pattern_tuple.ty,\n            Pattern::EnumVariant(pattern_enum_variant) => pattern_enum_variant.ty,\n            Pattern::Otherwise(pattern_otherwise) => pattern_otherwise.ty,\n        }\n    }\n\n    pub fn variables(&self) -> Vec<&PatternVariable> {\n        match self {\n            Pattern::Variable(variable) => vec![variable],\n            Pattern::Struct(pattern_struct) => pattern_struct\n                .field_patterns\n                .iter()\n                .flat_map(|(_member, pattern)| pattern.variables())\n                .collect(),\n            Pattern::Tuple(pattern_tuple) => pattern_tuple\n                .field_patterns\n                .iter()\n                .flat_map(|pattern| pattern.variables())\n                .collect(),\n            Pattern::EnumVariant(pattern_enum_variant) => {\n                pattern_enum_variant.inner_pattern.variables()\n            }\n            Pattern::Literal(_) | Pattern::Otherwise(_) => vec![],\n        }\n    }\n\n    pub fn stable_ptr(&self) -> ast::PatternPtr {\n        match self {\n            Pattern::Literal(pat) => pat.stable_ptr,\n            Pattern::Variable(pat) => pat.stable_ptr,\n            Pattern::Struct(pat) => pat.stable_ptr.into(),\n            Pattern::Tuple(pat) => pat.stable_ptr.into(),\n            Pattern::EnumVariant(pat) => pat.stable_ptr.into(),\n            Pattern::Otherwise(pat) => pat.stable_ptr.into(),\n        }\n    }\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub struct PatternLiteral {\n    pub literal: ExprLiteral,\n    pub ty: semantic::TypeId,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub stable_ptr: ast::PatternPtr,\n}\n\n/// A pattern that binds the matched value to a variable.\n#[derive(Clone, Debug, Hash, PartialEq, Eq, SemanticObject)]\npub struct PatternVariable {\n    #[dont_rewrite]\n    pub name: SmolStr,\n    pub var: LocalVariable,\n    #[dont_rewrite]\n    pub stable_ptr: ast::PatternPtr,\n}\nimpl DebugWithDb<ExprFormatter<'_>> for PatternVariable {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, _db: &ExprFormatter<'_>) -> std::fmt::Result {\n        write!(f, \"{}\", self.name)\n    }\n}\n\n/// A pattern that destructures a struct to its fields.\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub struct PatternStruct {\n    pub concrete_struct_id: ConcreteStructId,\n    // TODO(spapini): This should be ConcreteMember, when available.\n    pub field_patterns: Vec<(semantic::Member, Box<Pattern>)>,\n    pub ty: semantic::TypeId,\n    #[dont_rewrite]\n    pub n_snapshots: usize,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub stable_ptr: ast::PatternStructPtr,\n}\n\n/// A pattern that destructures a tuple to its fields.\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub struct PatternTuple {\n    pub field_patterns: Vec<Box<Pattern>>,\n    pub ty: semantic::TypeId,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub stable_ptr: ast::PatternTuplePtr,\n}\n\n/// A pattern that destructures a specific variant of an enum to its inner value.\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub struct PatternEnumVariant {\n    pub variant: semantic::ConcreteVariant,\n    pub inner_pattern: Box<Pattern>,\n    pub ty: semantic::TypeId,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub stable_ptr: ast::PatternEnumPtr,\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(ExprFormatter<'a>)]\npub struct PatternOtherwise {\n    pub ty: semantic::TypeId,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub stable_ptr: ast::TerminalUnderscorePtr,\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use assert_matches::assert_matches;\nuse cairo_lang_debug::DebugWithDb;\nuse cairo_lang_defs::ids::{FunctionWithBodyId, ModuleItemId, VarId};\nuse cairo_lang_utils::extract_matches;\nuse indoc::indoc;\nuse num_bigint::ToBigInt;\nuse pretty_assertions::assert_eq;\nuse test_case::test_case;\n\nuse crate::corelib::{core_felt252_ty, get_core_ty_by_name, unit_ty};\nuse crate::db::SemanticGroup;\nuse crate::expr::fmt::ExprFormatter;\nuse crate::semantic;\nuse crate::test_utils::{\n    setup_test_expr, setup_test_function, setup_test_module, test_function_diagnostics,\n    SemanticDatabaseForTesting, TestModule,\n};\n\ncairo_lang_test_utils::test_file_test!(\n    expr_diagnostics,\n    \"src/expr/test_data\",\n    {\n        assignment: \"assignment\",\n        constant: \"constant\",\n        enum_: \"enum\",\n        error_propagate: \"error_propagate\",\n        function_call: \"function_call\",\n        generics: \"generics\",\n        if_: \"if\",\n        inference: \"inference\",\n        let_statement: \"let_statement\",\n        literal: \"literal\",\n        match_: \"match\",\n        method: \"method\",\n        operators: \"operators\",\n        snapshot: \"snapshot\",\n        pattern: \"pattern\",\n        return_: \"return\",\n        statements: \"statements\",\n    },\n    test_function_diagnostics\n);\n\n#[test_case(\"7\", 7, \"felt252\")]\n#[test_case(\"0x123\", 0x123, \"felt252\")]\n#[test_case(\"12_felt252\", 12, \"felt252\")]\n#[test_case(\"16_u128\", 16, \"u128\")]\n#[test_case(\"0x16_u128\", 0x16, \"u128\")]\n#[test_case(\"'a'\", 0x61, \"felt252\")]\n#[test_case(\"'B'_u128\", 0x42, \"u128\")]\n#[test_case(\"'hello world'_u128\", 0x68656c6c6f20776f726c64, \"u128\")]\n#[test_case(r\"'\\''\", 39, \"felt252\")]\n#[test_case(r\"'\\x12\\x34'_u128\", 0x1234, \"u128\")]\nfn test_expr_literal(expr: &str, value: i128, ty_name: &str) {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let test_expr = setup_test_expr(&mut db_val, expr, \"\", \"\").unwrap();\n    let db = &db_val;\n    let expr = db.expr_semantic(test_expr.function_id, test_expr.expr_id);\n    let expr_formatter = ExprFormatter { db, function_id: test_expr.function_id };\n    // TODO(spapini): Currently, DebugWithDb can't \"switch\" dbs, and thus ExternTypeId is not\n    // followed (it uses SyntaxGroup, and not SemanticGroup).\n    // Fix this.\n    assert_eq!(\n        format!(\"{:?}\", expr.debug(&expr_formatter)),\n        format!(\n            \"Literal(ExprLiteral {{ value: {}, ty: core::{} }})\",\n            value,\n            match ty_name {\n                \"felt252\" => \"felt252\",\n                \"u128\" => \"integer::u128\",\n                _ => unreachable!(),\n            }\n        )\n    );\n\n    // Check expr.\n    let semantic::ExprLiteral { value, ty, stable_ptr: _ } =\n        extract_matches!(expr, crate::Expr::Literal, \"Expected a literal.\");\n\n    assert_eq!(value, value.to_bigint().unwrap());\n    assert_eq!(ty, get_core_ty_by_name(db, ty_name.into(), vec![]));\n}\n\n#[test]\nfn test_expr_assignment() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let test_expr = setup_test_expr(&mut db_val, \"a = a * 3\", \"\", \"let mut a = 5;\").unwrap();\n    let db = &db_val;\n    let expr = db.expr_semantic(test_expr.function_id, test_expr.expr_id);\n    let expr_formatter = ExprFormatter { db, function_id: test_expr.function_id };\n\n    assert_eq!(\n        format!(\"{:?}\", expr.debug(&expr_formatter)),\n        \"Assignment(ExprAssignment { ref_arg: Var(ExprVar { var: LocalVarId(test::a), ty: \\\n         core::felt252 }), rhs: FunctionCall(ExprFunctionCall { function: core::Felt252Mul::mul, \\\n         args: [Value(Var(ExprVar { var: LocalVarId(test::a), ty: core::felt252 })), \\\n         Value(Literal(ExprLiteral { value: 3, ty: core::felt252 }))], ty: core::felt252 }), ty: \\\n         () })\"\n    );\n}\n\n#[test]\nfn test_expr_operator() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let test_expr = setup_test_expr(&mut db_val, \"!(-5 + 9 * 3 == 0)\", \"\", \"\").unwrap();\n    let db = &db_val;\n    let expr = db.expr_semantic(test_expr.function_id, test_expr.expr_id);\n    let expr_formatter = ExprFormatter { db, function_id: test_expr.function_id };\n\n    // TODO(spapini): Make transparent DebugWithDb attribute, to have better outputs.\n    // TODO(spapini): Have better whitespaces here somehow.\n    assert_eq!(\n        format!(\"{:?}\", expr.debug(&expr_formatter)),\n        \"FunctionCall(ExprFunctionCall { function: core::BoolNot::not, args: \\\n         [Value(FunctionCall(ExprFunctionCall { function: core::Felt252PartialEq::eq, args: \\\n         [Value(FunctionCall(ExprFunctionCall { function: core::Felt252Add::add, args: \\\n         [Value(FunctionCall(ExprFunctionCall { function: core::Felt252Neg::neg, args: \\\n         [Value(Literal(ExprLiteral { value: 5, ty: core::felt252 }))], ty: core::felt252 })), \\\n         Value(FunctionCall(ExprFunctionCall { function: core::Felt252Mul::mul, args: \\\n         [Value(Literal(ExprLiteral { value: 9, ty: core::felt252 })), Value(Literal(ExprLiteral \\\n         { value: 3, ty: core::felt252 }))], ty: core::felt252 }))], ty: core::felt252 })), \\\n         Value(Literal(ExprLiteral { value: 0, ty: core::felt252 }))], ty: core::bool }))], ty: \\\n         core::bool })\"\n    );\n}\n\n#[test]\nfn test_member_access() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let TestModule { module_id, .. } = setup_test_module(\n        &mut db_val,\n        indoc! {\"\n            struct A {\n                a: (felt252,),\n                b: felt252,\n                c: B,\n            }\n            struct B {\n                a: felt252\n            }\n            fn foo(a: A){\n                (a).a;\n                a.b;\n                a.c;\n                a.c.a;\n            }\n        \"},\n    )\n    .unwrap();\n    let db = &db_val;\n    let foo_id = FunctionWithBodyId::Free(extract_matches!(\n        db.module_item_by_name(module_id, \"foo\".into()).unwrap().unwrap(),\n        ModuleItemId::FreeFunction\n    ));\n    let expr_formatter = ExprFormatter { db, function_id: foo_id };\n    let block = extract_matches!(\n        db.expr_semantic(foo_id, db.function_body_expr(foo_id).unwrap()),\n        semantic::Expr::Block\n    );\n    let exprs: Vec<_> = block\n        .statements\n        .iter()\n        .map(|stmt_id| {\n            format!(\n                \"{:?}\",\n                db.expr_semantic(\n                    foo_id,\n                    extract_matches!(\n                        db.statement_semantic(foo_id, *stmt_id),\n                        semantic::Statement::Expr\n                    )\n                    .expr\n                )\n                .debug(&expr_formatter)\n            )\n        })\n        .collect();\n    assert_eq!(\n        exprs,\n        vec![\n            \"MemberAccess(ExprMemberAccess { expr: Var(ExprVar { var: ParamId(test::a), ty: \\\n             test::A }), concrete_struct_id: test::A, member: MemberId(test::a), ty: \\\n             (core::felt252,) })\",\n            \"MemberAccess(ExprMemberAccess { expr: Var(ExprVar { var: ParamId(test::a), ty: \\\n             test::A }), concrete_struct_id: test::A, member: MemberId(test::b), ty: \\\n             core::felt252 })\",\n            \"MemberAccess(ExprMemberAccess { expr: Var(ExprVar { var: ParamId(test::a), ty: \\\n             test::A }), concrete_struct_id: test::A, member: MemberId(test::c), ty: test::B })\",\n            \"MemberAccess(ExprMemberAccess { expr: MemberAccess(ExprMemberAccess { expr: \\\n             Var(ExprVar { var: ParamId(test::a), ty: test::A }), concrete_struct_id: test::A, \\\n             member: MemberId(test::c), ty: test::B }), concrete_struct_id: test::B, member: \\\n             MemberId(test::a), ty: core::felt252 })\",\n        ]\n    );\n}\n#[test]\nfn test_member_access_failures() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let diagnostics = setup_test_module(\n        &mut db_val,\n        indoc! {\"\n            struct A {\n                a: (felt252,),\n                b: felt252,\n                c: felt252,\n            }\n            fn foo(a: A){\n                a.f;\n                a.a::b;\n                a.4.4;\n                5.a;\n            }\n        \"},\n    )\n    .get_diagnostics();\n    assert_eq!(\n        diagnostics,\n        indoc! {r#\"\n            error: Struct \"test::A\" has no member \"f\"\n             --> lib.cairo:7:7\n                a.f;\n                  ^\n\n            error: Invalid member expression.\n             --> lib.cairo:8:7\n                a.a::b;\n                  ^**^\n\n            error: Invalid member expression.\n             --> lib.cairo:9:7\n                a.4.4;\n                  ^\n\n            error: Invalid member expression.\n             --> lib.cairo:9:9\n                a.4.4;\n                    ^\n\n            error: Type \"core::felt252\" has no members.\n             --> lib.cairo:10:7\n                5.a;\n                  ^\n\n        \"#}\n    );\n}\n\n#[test]\nfn test_function_with_param() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let test_function =\n        setup_test_function(&mut db_val, \"fn foo(a: felt252) {}\", \"foo\", \"\").unwrap();\n    let _db = &db_val;\n    let signature = test_function.signature;\n\n    // TODO(spapini): Verify params names and tests after StablePtr feature is added.\n    assert_eq!(signature.params.len(), 1);\n    let param = &signature.params[0];\n    let _param_ty = param.ty;\n}\n\n#[test]\nfn test_tuple_type() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let test_function =\n        setup_test_function(&mut db_val, \"fn foo(mut a: (felt252, (), (felt252,))) {}\", \"foo\", \"\")\n            .unwrap();\n    let db = &db_val;\n    let signature = test_function.signature;\n\n    assert_eq!(signature.params.len(), 1);\n    let param = &signature.params[0];\n    assert_eq!(\n        format!(\"{:?}\", param.debug(db)),\n        \"Parameter { id: ParamId(test::a), name: \\\"a\\\", ty: (core::felt252, (), \\\n         (core::felt252,)), mutability: Mutable }\"\n    );\n}\n\n#[test]\nfn test_function_with_return_type() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let test_function =\n        setup_test_function(&mut db_val, \"fn foo() -> felt252 { 5 }\", \"foo\", \"\").unwrap();\n    let _db = &db_val;\n    let signature = test_function.signature;\n\n    // TODO(spapini): Verify params names and tests after StablePtr feature is added.\n    let _ret_ty = signature.return_type;\n}\n\n#[test]\nfn test_function_with_return_type_failures() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let diagnostics =\n        setup_test_function(&mut db_val, \"fn foo() -> felt252 { }\", \"foo\", \"\").get_diagnostics();\n    assert_eq!(\n        diagnostics,\n        indoc! {r#\"\n            error: Unexpected return type. Expected: \"core::felt252\", found: \"()\".\n             --> lib.cairo:1:21\n            fn foo() -> felt252 { }\n                                ^*^\n\n        \"#}\n    );\n}\n\n#[test]\nfn test_let_statement() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let test_function = setup_test_function(\n        &mut db_val,\n        indoc! {\"\n            fn foo() {\n                let a: felt252 = 3;\n                let b = a;\n            }\n        \"},\n        \"foo\",\n        \"\",\n    )\n    .unwrap();\n    let db = &db_val;\n    let expr = db.expr_semantic(test_function.function_id, test_function.body);\n    let expr_formatter = ExprFormatter { db, function_id: test_function.function_id };\n\n    assert_eq!(\n        format!(\"{:?}\", expr.debug(&expr_formatter)),\n        \"Block(ExprBlock { statements: [Let(StatementLet { pattern: Variable(a), expr: \\\n         Literal(ExprLiteral { value: 3, ty: core::felt252 }) }), Let(StatementLet { pattern: \\\n         Variable(b), expr: Var(ExprVar { var: LocalVarId(test::a), ty: core::felt252 }) })], \\\n         tail: None, ty: () })\"\n    );\n}\n\n#[test]\nfn test_let_statement_failures() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let diagnostics = setup_test_function(\n        &mut db_val,\n        indoc! {\"\n            fn foo() {\n                let a: () = 3;\n            }\n        \"},\n        \"foo\",\n        \"\",\n    )\n    .get_diagnostics();\n    assert_eq!(\n        diagnostics,\n        indoc! {r#\"\n            error: Unexpected argument type. Expected: \"()\", found: \"core::felt252\".\n             --> lib.cairo:2:17\n                let a: () = 3;\n                            ^\n\n        \"#}\n    );\n}\n\n#[test]\nfn test_expr_var() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let test_function = setup_test_function(\n        &mut db_val,\n        indoc! {\"\n            fn foo(a: felt252) -> felt252 {\n                a\n            }\n        \"},\n        \"foo\",\n        \"\",\n    )\n    .unwrap();\n    let db = &db_val;\n\n    let semantic::ExprBlock { statements: _, tail, ty: _, stable_ptr: _ } = extract_matches!(\n        db.expr_semantic(test_function.function_id, test_function.body),\n        crate::Expr::Block\n    );\n\n    // Check expr.\n    let semantic::ExprVar { var: _, ty: _, stable_ptr: _ } = extract_matches!(\n        db.expr_semantic(test_function.function_id, tail.unwrap()),\n        crate::Expr::Var,\n        \"Expected a variable.\"\n    );\n    // TODO(spapini): Check Var against param using param.id.\n}\n\n#[test]\nfn test_expr_match() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let test_function = setup_test_function(\n        &mut db_val,\n        indoc! {\"\n            fn foo(a: felt252) -> felt252 {\n                match a {\n                    0 => 0,\n                    _ => 1,\n                }\n            }\n        \"},\n        \"foo\",\n        \"\",\n    )\n    .unwrap();\n    let db = &db_val;\n    let semantic::ExprBlock { statements: _, tail, ty: _, stable_ptr: _ } = extract_matches!(\n        db.expr_semantic(test_function.function_id, test_function.body),\n        crate::Expr::Block\n    );\n    let expr = db.expr_semantic(test_function.function_id, tail.unwrap());\n    let expr_formatter = ExprFormatter { db, function_id: test_function.function_id };\n    assert_eq!(\n        format!(\"{:?}\", expr.debug(&expr_formatter)),\n        \"Match(ExprMatch { matched_expr: Var(ExprVar { var: ParamId(test::a), ty: core::felt252 \\\n         }), arms: [MatchArm { pattern: Literal(PatternLiteral { literal: ExprLiteral { value: 0, \\\n         ty: core::felt252 }, ty: core::felt252 }), expression: Literal(ExprLiteral { value: 0, \\\n         ty: core::felt252 }) }, MatchArm { pattern: Otherwise(PatternOtherwise { ty: \\\n         core::felt252 }), expression: Literal(ExprLiteral { value: 1, ty: core::felt252 }) }], \\\n         ty: core::felt252 })\"\n    );\n}\n\n#[test]\nfn test_expr_match_failures() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let diagnostics = setup_test_function(\n        &mut db_val,\n        indoc! {\"\n            fn foo(a: felt252, b: bool) -> felt252 {\n                match a {\n                    0 => 0,\n                    _ => b,\n                }\n            }\n        \"},\n        \"foo\",\n        \"\",\n    )\n    .get_diagnostics();\n    assert_eq!(\n        diagnostics,\n        indoc! {r#\"\n            error: Match arms have incompatible types: \"core::felt252\" and \"core::bool\"\n             --> lib.cairo:4:14\n                    _ => b,\n                         ^\n\n        \"#}\n    )\n}\n\n#[test]\nfn test_expr_block() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let test_expr = setup_test_expr(&mut db_val, \"{6;8;}\", \"\", \"\").unwrap();\n    let db = &db_val;\n    let expr = db.expr_semantic(test_expr.function_id, test_expr.expr_id);\n\n    // Check expr.\n    let semantic::ExprBlock { statements, tail, ty, stable_ptr: _ } =\n        extract_matches!(expr, crate::Expr::Block, \"Expected a block.\");\n    assert_eq!(ty, unit_ty(db));\n    assert!(tail.is_none());\n\n    match statements[..] {\n        [stmt_id0, stmt_id1] => {\n            let stmt0 = db.statement_semantic(test_expr.function_id, stmt_id0);\n            let stmt1 = db.statement_semantic(test_expr.function_id, stmt_id1);\n            assert_matches!(stmt0, semantic::Statement::Expr(_));\n            assert_matches!(stmt1, semantic::Statement::Expr(_));\n        }\n        _ => panic!(\"Expected two statements.\"),\n    }\n}\n\n#[test]\nfn test_expr_block_with_tail_expression() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let test_expr = setup_test_expr(&mut db_val, \"{6;8;9}\", \"\", \"\").unwrap();\n    let db = &db_val;\n    let expr = db.expr_semantic(test_expr.function_id, test_expr.expr_id);\n\n    // Check expr.\n    let semantic::ExprBlock { statements, tail, ty, stable_ptr: _ } =\n        extract_matches!(expr, crate::Expr::Block, \"Expected a block.\");\n    assert_eq!(ty, core_felt252_ty(db));\n\n    // Check tail expression.\n    let semantic::ExprLiteral { value, ty: _, stable_ptr: _ } = extract_matches!(\n        db.expr_semantic(test_expr.function_id, tail.unwrap()),\n        crate::Expr::Literal,\n        \"Expected a literal expression.\"\n    );\n    assert_eq!(value, 9.to_bigint().unwrap());\n\n    // Check statements.\n    match statements[..] {\n        [stmt_id0, stmt_id1] => {\n            let stmt0 = db.statement_semantic(test_expr.function_id, stmt_id0);\n            let stmt1 = db.statement_semantic(test_expr.function_id, stmt_id1);\n            assert_matches!(stmt0, semantic::Statement::Expr(_));\n            assert_matches!(stmt1, semantic::Statement::Expr(_));\n        }\n        _ => panic!(\"Expected two statements.\"),\n    }\n}\n\n#[test]\nfn test_expr_call() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    // TODO(spapini): Add types.\n    let test_expr = setup_test_expr(&mut db_val, \"foo()\", \"fn foo() {6;}\", \"\").unwrap();\n    let db = &db_val;\n    let expr = db.expr_semantic(test_expr.function_id, test_expr.expr_id);\n\n    // Check expr.\n    let semantic::ExprFunctionCall { args, ty, .. } =\n        extract_matches!(expr, crate::Expr::FunctionCall, \"Unexpected expr.\");\n    assert!(args.is_empty());\n    assert_eq!(ty, unit_ty(db));\n}\n\n#[test]\nfn test_expr_call_failures() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    // TODO(spapini): Add types.\n    let (test_expr, diagnostics) = setup_test_expr(&mut db_val, \"foo()\", \"\", \"\").split();\n    let db = &db_val;\n    let expr_formatter = ExprFormatter { db, function_id: test_expr.function_id };\n\n    // Check expr.\n    assert_eq!(\n        diagnostics,\n        indoc! { \"\n            error: Function not found.\n             --> lib.cairo:2:1\n            foo()\n            ^*^\n\n        \"}\n    );\n    assert_eq!(format!(\"{:?}\", test_expr.module_id.debug(db)), \"ModuleId(test)\");\n    assert_eq!(\n        format!(\n            \"{:?}\",\n            db.expr_semantic(test_expr.function_id, test_expr.expr_id).debug(&expr_formatter)\n        ),\n        \"Missing(ExprMissing { ty: <missing> })\"\n    );\n}\n\n#[test]\nfn test_function_body() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let test_function = setup_test_function(\n        &mut db_val,\n        indoc! {\"\n            fn foo(a: felt252) {\n                a;\n            }\n        \"},\n        \"foo\",\n        \"\",\n    )\n    .unwrap();\n    let db = &db_val;\n    let item_id = db.module_item_by_name(test_function.module_id, \"foo\".into()).unwrap().unwrap();\n\n    let function_id =\n        FunctionWithBodyId::Free(extract_matches!(item_id, ModuleItemId::FreeFunction));\n    let body = db.function_body_expr(function_id).unwrap();\n\n    // Test the resulting semantic function body.\n    let semantic::ExprBlock { statements, .. } = extract_matches!(\n        db.expr_semantic(test_function.function_id, body),\n        crate::Expr::Block,\n        \"Expected a block.\"\n    );\n    assert_eq!(statements.len(), 1);\n    let expr = db.expr_semantic(\n        test_function.function_id,\n        extract_matches!(\n            db.statement_semantic(test_function.function_id, statements[0]),\n            crate::Statement::Expr\n        )\n        .expr,\n    );\n    let semantic::ExprVar { var, ty: _, stable_ptr: _ } = extract_matches!(expr, crate::Expr::Var);\n    let param = extract_matches!(var, VarId::Param);\n    assert_eq!(param.name(db), \"a\");\n}\n\n#[test]\nfn test_expr_struct_ctor() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let test_expr = setup_test_expr(\n        &mut db_val,\n        indoc! {\"\n            A { a: 1, b }\n        \"},\n        indoc! {\"\n            struct A {\n                a: felt252,\n                b: felt252\n            }\n        \"},\n        \"let b = 2;\",\n    )\n    .unwrap();\n    let db = &db_val;\n    let expr = db.expr_semantic(test_expr.function_id, test_expr.expr_id);\n    let expr_formatter = ExprFormatter { db, function_id: test_expr.function_id };\n    assert_eq!(\n        format!(\"{:?}\", expr.debug(&expr_formatter)),\n        \"StructCtor(ExprStructCtor { concrete_struct_id: test::A, members: [(MemberId(test::a), \\\n         Literal(ExprLiteral { value: 1, ty: core::felt252 })), (MemberId(test::b), Var(ExprVar { \\\n         var: LocalVarId(test::b), ty: core::felt252 }))], ty: test::A })\"\n    );\n}\n\n#[test]\nfn test_expr_tuple() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let test_expr = setup_test_expr(&mut db_val, \"(1 + 2, (2, 3))\", \"\", \"\").unwrap();\n    let db = &db_val;\n    let expr = db.expr_semantic(test_expr.function_id, test_expr.expr_id);\n    let expr_formatter = ExprFormatter { db, function_id: test_expr.function_id };\n    assert_eq!(\n        format!(\"{:?}\", expr.debug(&expr_formatter)),\n        \"Tuple(ExprTuple { items: [FunctionCall(ExprFunctionCall { function: \\\n         core::Felt252Add::add, args: [Value(Literal(ExprLiteral { value: 1, ty: core::felt252 \\\n         })), Value(Literal(ExprLiteral { value: 2, ty: core::felt252 }))], ty: core::felt252 }), \\\n         Tuple(ExprTuple { items: [Literal(ExprLiteral { value: 2, ty: core::felt252 }), \\\n         Literal(ExprLiteral { value: 3, ty: core::felt252 })], ty: (core::felt252, \\\n         core::felt252) })], ty: (core::felt252, (core::felt252, core::felt252)) })\"\n    );\n}\n\n#[test]\nfn test_expr_struct_ctor_failures() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let diagnostics = setup_test_module(\n        &mut db_val,\n        indoc! {\"\n            struct A {\n                a: felt252,\n                b: ()\n            }\n            fn foo(a: A) -> A {\n                A {\n                    b: 1,\n                    a: 2,\n                    c: 7,\n                    a: 3,\n                    ..d,\n                }\n            }\n        \"},\n    )\n    .get_diagnostics();\n    assert_eq!(\n        diagnostics,\n        indoc! {r#\"\n            error: Unexpected argument type. Expected: \"()\", found: \"core::felt252\".\n             --> lib.cairo:7:9\n                    b: 1,\n                    ^\n\n            error: Unknown member.\n             --> lib.cairo:9:9\n                    c: 7,\n                    ^\n\n            error: Member specified more than once.\n             --> lib.cairo:10:9\n                    a: 3,\n                    ^\n\n            error: Unsupported feature.\n             --> lib.cairo:11:9\n                    ..d,\n                    ^*^\n\n        \"#}\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_debug::DebugWithDb;\nuse cairo_lang_defs::ids::{LanguageElementId, ModuleId};\nuse cairo_lang_diagnostics::Maybe;\nuse cairo_lang_syntax::node::ast::OptionAttributeArgs;\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::{ast, Terminal, TypedSyntaxNode};\nuse smol_str::SmolStr;\n\nuse crate::db::SemanticGroup;\n\n/// Semantic representation of an attribute.\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct Attribute {\n    pub stable_ptr: ast::AttributePtr,\n    pub id: SmolStr,\n    pub id_stable_ptr: ast::TerminalIdentifierPtr,\n    pub args: Vec<ast::Expr>,\n    pub args_stable_ptr: ast::OptionAttributeArgsPtr,\n}\n\nimpl DebugWithDb<dyn SemanticGroup> for Attribute {\n    fn fmt(\n        &self,\n        f: &mut std::fmt::Formatter<'_>,\n        db: &(dyn SemanticGroup + 'static),\n    ) -> std::fmt::Result {\n        write!(f, r#\"Attribute {{ id: \"{}\"\"#, self.id)?;\n        if !self.args.is_empty() {\n            write!(f, \", args: [\")?;\n            for arg in self.args.iter() {\n                write!(f, \"{:?}, \", arg.as_syntax_node().get_text(db.upcast()))?;\n            }\n            write!(f, \"]\")?;\n        }\n        write!(f, \" }}\")\n    }\n}\n\n/// Returns the semantic attributes for the given AST attribute list.\npub fn ast_attributes_to_semantic(\n    syntax_db: &dyn SyntaxGroup,\n    attributes: ast::AttributeList,\n) -> Vec<Attribute> {\n    // TODO(ilya): Consider checking for attribute repetitions.\n    attributes\n        .elements(syntax_db)\n        .into_iter()\n        .map(|attribute| {\n            let attr_id = attribute.attr(syntax_db);\n            let attr_args = attribute.args(syntax_db);\n\n            Attribute {\n                stable_ptr: attribute.stable_ptr(),\n                id: attr_id.text(syntax_db),\n                id_stable_ptr: attr_id.stable_ptr(),\n                args: match attr_args {\n                    OptionAttributeArgs::AttributeArgs(ref attribute_args) => {\n                        attribute_args.arg_list(syntax_db).elements(syntax_db)\n                    }\n                    OptionAttributeArgs::Empty(_) => vec![],\n                },\n                args_stable_ptr: attr_args.stable_ptr(),\n            }\n        })\n        .collect()\n}\n\n/// Query implementation of [crate::db::SemanticGroup::module_attributes].\npub fn module_attributes(db: &dyn SemanticGroup, module_id: ModuleId) -> Maybe<Vec<Attribute>> {\n    Ok(match module_id {\n        ModuleId::CrateRoot(_) => vec![],\n        ModuleId::Submodule(submodule_id) => {\n            let module_ast =\n                &db.module_submodules(submodule_id.parent_module(db.upcast()))?[submodule_id];\n            let syntax_db = db.upcast();\n\n            ast_attributes_to_semantic(syntax_db, module_ast.attributes(syntax_db))\n        }\n    })\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse cairo_lang_defs::ids::{ConstantId, LanguageElementId};\nuse cairo_lang_diagnostics::{Diagnostics, Maybe, ToMaybe};\nuse cairo_lang_proc_macros::DebugWithDb;\n\nuse crate::db::SemanticGroup;\nuse crate::diagnostic::SemanticDiagnostics;\nuse crate::expr::compute::{compute_expr_semantic, ComputationContext, Environment};\nuse crate::resolve_path::{ResolvedLookback, Resolver};\nuse crate::types::resolve_type;\nuse crate::{Expr, SemanticDiagnostic};\n\n#[cfg(test)]\n#[path = \"constant_test.rs\"]\nmod test;\n\n#[derive(Clone, Debug, PartialEq, Eq, DebugWithDb)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct Constant {\n    pub value: Expr,\n}\n\n/// Information about a constant definition.\n///\n/// Helper struct for the data returned by [SemanticGroup::priv_constant_semantic_data].\n#[derive(Clone, Debug, PartialEq, Eq, DebugWithDb)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct ConstantData {\n    diagnostics: Diagnostics<SemanticDiagnostic>,\n    constant: Constant,\n    resolved_lookback: Arc<ResolvedLookback>,\n}\n\n/// Query implementation of [SemanticGroup::priv_constant_semantic_data].\npub fn priv_constant_semantic_data(\n    db: &dyn SemanticGroup,\n    const_id: ConstantId,\n) -> Maybe<ConstantData> {\n    let module_file_id = const_id.module_file_id(db.upcast());\n    let mut diagnostics = SemanticDiagnostics::new(module_file_id);\n    // TODO(spapini): when code changes in a file, all the AST items change (as they contain a path\n    // to the green root that changes. Once ASTs are rooted on items, use a selector that picks only\n    // the item instead of all the module data.\n    let module_constants = db.module_constants(module_file_id.0)?;\n    let const_ast = module_constants.get(&const_id).to_maybe()?;\n    let syntax_db = db.upcast();\n\n    let mut resolver = Resolver::new_without_inference(db, module_file_id);\n\n    let const_type = resolve_type(\n        db,\n        &mut diagnostics,\n        &mut resolver,\n        &const_ast.type_clause(syntax_db).ty(syntax_db),\n    );\n\n    let mut ctx =\n        ComputationContext::new(db, &mut diagnostics, resolver, None, Environment::default());\n    let value = compute_expr_semantic(&mut ctx, &const_ast.value(syntax_db));\n    let value_type = value.ty();\n\n    // Check that the type matches.\n    if !const_type.is_missing(db) && !value_type.is_missing(db) && value_type != const_type {\n        ctx.diagnostics.report(\n            &const_ast.value(syntax_db),\n            crate::diagnostic::SemanticDiagnosticKind::WrongType {\n                expected_ty: const_type,\n                actual_ty: value_type,\n            },\n        );\n    }\n\n    // Check that the expression is a literal.\n    if !matches!(value, Expr::Literal(_)) {\n        ctx.diagnostics.report(\n            &const_ast.value(syntax_db),\n            crate::diagnostic::SemanticDiagnosticKind::OnlyLiteralConstants,\n        );\n    };\n\n    let constant = Constant { value };\n    let resolved_lookback = Arc::new(ctx.resolver.lookback);\n    Ok(ConstantData { diagnostics: diagnostics.build(), constant, resolved_lookback })\n}\n\n/// Query implementation of [SemanticGroup::constant_semantic_diagnostics].\npub fn constant_semantic_diagnostics(\n    db: &dyn SemanticGroup,\n    const_id: ConstantId,\n) -> Diagnostics<SemanticDiagnostic> {\n    db.priv_constant_semantic_data(const_id).map(|data| data.diagnostics).unwrap_or_default()\n}\n\n/// Query implementation of [SemanticGroup::constant_semantic_data].\npub fn constant_semantic_data(db: &dyn SemanticGroup, const_id: ConstantId) -> Maybe<Constant> {\n    Ok(db.priv_constant_semantic_data(const_id)?.constant)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::constant_resolved_lookback].\npub fn constant_resolved_lookback(\n    db: &dyn SemanticGroup,\n    const_id: ConstantId,\n) -> Maybe<Arc<ResolvedLookback>> {\n    Ok(db.priv_constant_semantic_data(const_id)?.resolved_lookback)\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "// TODO(lior): Add semantic tests for constant definitions.\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse cairo_lang_defs::ids::{EnumId, LanguageElementId, VariantId, VariantLongId};\nuse cairo_lang_diagnostics::{Diagnostics, Maybe, ToMaybe};\nuse cairo_lang_proc_macros::{DebugWithDb, SemanticObject};\nuse cairo_lang_syntax::node::{Terminal, TypedSyntaxNode};\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse cairo_lang_utils::Upcast;\nuse itertools::enumerate;\nuse smol_str::SmolStr;\n\nuse super::attribute::{ast_attributes_to_semantic, Attribute};\nuse super::generics::semantic_generic_params;\nuse crate::db::SemanticGroup;\nuse crate::diagnostic::SemanticDiagnosticKind::*;\nuse crate::diagnostic::SemanticDiagnostics;\nuse crate::resolve_path::{ResolvedLookback, Resolver};\nuse crate::substitution::{GenericSubstitution, SemanticRewriter, SubstitutionRewriter};\nuse crate::types::resolve_type;\nuse crate::{semantic, ConcreteEnumId, SemanticDiagnostic};\n\n#[cfg(test)]\n#[path = \"enm_test.rs\"]\nmod test;\n\n// Declaration\n#[derive(Clone, Debug, PartialEq, Eq, DebugWithDb)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct EnumDeclarationData {\n    diagnostics: Diagnostics<SemanticDiagnostic>,\n    generic_params: Vec<semantic::GenericParam>,\n    attributes: Vec<Attribute>,\n    resolved_lookback: Arc<ResolvedLookback>,\n}\n\n/// Query implementation of [crate::db::SemanticGroup::priv_enum_declaration_data].\npub fn priv_enum_declaration_data(\n    db: &dyn SemanticGroup,\n    enum_id: EnumId,\n) -> Maybe<EnumDeclarationData> {\n    let module_file_id = enum_id.module_file_id(db.upcast());\n    let mut diagnostics = SemanticDiagnostics::new(module_file_id);\n    // TODO(spapini): when code changes in a file, all the AST items change (as they contain a path\n    // to the green root that changes. Once ASTs are rooted on items, use a selector that picks only\n    // the item instead of all the module data.\n    let module_enums = db.module_enums(module_file_id.0)?;\n    let enum_ast = module_enums.get(&enum_id).to_maybe()?;\n    let syntax_db = db.upcast();\n\n    // Generic params.\n    let mut resolver = Resolver::new_with_inference(db, module_file_id);\n    let generic_params = semantic_generic_params(\n        db,\n        &mut diagnostics,\n        &mut resolver,\n        module_file_id,\n        &enum_ast.generic_params(db.upcast()),\n    )?;\n\n    let attributes = ast_attributes_to_semantic(syntax_db, enum_ast.attributes(syntax_db));\n    let resolved_lookback = Arc::new(resolver.lookback);\n\n    Ok(EnumDeclarationData {\n        diagnostics: diagnostics.build(),\n        generic_params,\n        attributes,\n        resolved_lookback,\n    })\n}\n\n/// Query implementation of [crate::db::SemanticGroup::enum_declaration_diagnostics].\npub fn enum_declaration_diagnostics(\n    db: &dyn SemanticGroup,\n    enum_id: EnumId,\n) -> Diagnostics<SemanticDiagnostic> {\n    db.priv_enum_declaration_data(enum_id).map(|data| data.diagnostics).unwrap_or_default()\n}\n\n/// Query implementation of [crate::db::SemanticGroup::enum_generic_params].\npub fn enum_generic_params(\n    db: &dyn SemanticGroup,\n    enum_id: EnumId,\n) -> Maybe<Vec<semantic::GenericParam>> {\n    Ok(db.priv_enum_declaration_data(enum_id)?.generic_params)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::enum_declaration_resolved_lookback].\npub fn enum_declaration_resolved_lookback(\n    db: &dyn SemanticGroup,\n    enum_id: EnumId,\n) -> Maybe<Arc<ResolvedLookback>> {\n    Ok(db.priv_enum_declaration_data(enum_id)?.resolved_lookback)\n}\n\n// Definition\n#[derive(Clone, Debug, PartialEq, Eq, DebugWithDb)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct EnumDefinitionData {\n    diagnostics: Diagnostics<SemanticDiagnostic>,\n    variants: OrderedHashMap<SmolStr, VariantId>,\n    variant_semantic: OrderedHashMap<VariantId, Variant>,\n    resolved_lookback: Arc<ResolvedLookback>,\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct Variant {\n    pub enum_id: EnumId,\n    pub id: VariantId,\n    pub ty: semantic::TypeId,\n    /// The index of the variant from within the variant list.\n    pub idx: usize,\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct ConcreteVariant {\n    pub concrete_enum_id: ConcreteEnumId,\n    pub id: VariantId,\n    pub ty: semantic::TypeId,\n    /// The index of the variant from within the variant list.\n    #[dont_rewrite]\n    pub idx: usize,\n}\n\n/// Query implementation of [crate::db::SemanticGroup::priv_enum_definition_data].\npub fn priv_enum_definition_data(\n    db: &dyn SemanticGroup,\n    enum_id: EnumId,\n) -> Maybe<EnumDefinitionData> {\n    let module_file_id = enum_id.module_file_id(db.upcast());\n    let mut diagnostics = SemanticDiagnostics::new(module_file_id);\n    // TODO(spapini): when code changes in a file, all the AST items change (as they contain a path\n    // to the green root that changes. Once ASTs are rooted on items, use a selector that picks only\n    // the item instead of all the module data.\n    let module_enums = db.module_enums(module_file_id.0)?;\n    let enum_ast = module_enums.get(&enum_id).to_maybe()?;\n    let syntax_db = db.upcast();\n\n    // Generic params.\n    let mut resolver = Resolver::new_without_inference(db, module_file_id);\n    let generic_params = db.enum_generic_params(enum_id)?;\n    for generic_param in generic_params {\n        resolver.add_generic_param(generic_param);\n    }\n\n    // Variants.\n    let mut variants = OrderedHashMap::default();\n    let mut variant_semantic = OrderedHashMap::default();\n    for (variant_idx, variant) in enumerate(enum_ast.variants(syntax_db).elements(syntax_db)) {\n        let id = db.intern_variant(VariantLongId(module_file_id, variant.stable_ptr()));\n        let ty = resolve_type(\n            db,\n            &mut diagnostics,\n            &mut resolver,\n            &variant.type_clause(syntax_db).ty(syntax_db),\n        );\n        let variant_name = variant.name(syntax_db).text(syntax_db);\n        if let Some(_other_variant) = variants.insert(variant_name.clone(), id) {\n            diagnostics.report(&variant, EnumVariantRedefinition { enum_id, variant_name });\n        }\n        variant_semantic.insert(id, Variant { enum_id, id, ty, idx: variant_idx });\n    }\n\n    let resolved_lookback = Arc::new(resolver.lookback);\n\n    Ok(EnumDefinitionData {\n        diagnostics: diagnostics.build(),\n        variants,\n        variant_semantic,\n        resolved_lookback,\n    })\n}\n\n/// Query implementation of [crate::db::SemanticGroup::enum_definition_diagnostics].\npub fn enum_definition_diagnostics(\n    db: &dyn SemanticGroup,\n    enum_id: EnumId,\n) -> Diagnostics<SemanticDiagnostic> {\n    db.priv_enum_definition_data(enum_id).map(|data| data.diagnostics).unwrap_or_default()\n}\n\n/// Query implementation of [crate::db::SemanticGroup::enum_definition_resolved_lookback].\npub fn enum_definition_resolved_lookback(\n    db: &dyn SemanticGroup,\n    enum_id: EnumId,\n) -> Maybe<Arc<ResolvedLookback>> {\n    Ok(db.priv_enum_definition_data(enum_id)?.resolved_lookback)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::enum_variants].\npub fn enum_variants(\n    db: &dyn SemanticGroup,\n    enum_id: EnumId,\n) -> Maybe<OrderedHashMap<SmolStr, VariantId>> {\n    Ok(db.priv_enum_definition_data(enum_id)?.variants)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::variant_semantic].\npub fn variant_semantic(\n    db: &dyn SemanticGroup,\n    enum_id: EnumId,\n    variant_id: VariantId,\n) -> Maybe<Variant> {\n    let data = db.priv_enum_definition_data(enum_id)?;\n    data.variant_semantic.get(&variant_id).cloned().to_maybe()\n}\n\n// TODO(spapini): Consider making these queries.\npub trait SemanticEnumEx<'a>: Upcast<dyn SemanticGroup + 'a> {\n    /// Retrieves the [ConcreteVariant] for a [ConcreteEnumId] and a [Variant].\n    fn concrete_enum_variant(\n        &self,\n        concrete_enum_id: ConcreteEnumId,\n        variant: &Variant,\n    ) -> Maybe<ConcreteVariant> {\n        // TODO(spapini): Uphold the invariant that constructed ConcreteEnumId instances\n        //   always have the correct number of generic arguments.\n        let db = self.upcast();\n        let generic_params = db.enum_generic_params(concrete_enum_id.enum_id(db))?;\n        let generic_args = db.lookup_intern_concrete_enum(concrete_enum_id).generic_args;\n        let substitution = GenericSubstitution::new(&generic_params, &generic_args);\n        SubstitutionRewriter { db, substitution: &substitution }.rewrite(ConcreteVariant {\n            concrete_enum_id,\n            id: variant.id,\n            ty: variant.ty,\n            idx: variant.idx,\n        })\n    }\n\n    /// Retrieves all the [ConcreteVariant]s for a [ConcreteEnumId].\n    fn concrete_enum_variants(\n        &self,\n        concrete_enum_id: ConcreteEnumId,\n    ) -> Maybe<Vec<ConcreteVariant>> {\n        // TODO(spapini): Uphold the invariant that constructed ConcreteEnumId instances\n        //   always have the correct number of generic arguments.\n        let db = self.upcast();\n        let enum_id = concrete_enum_id.enum_id(db);\n        db.enum_variants(enum_id)?\n            .into_iter()\n            .map(|(_, variant_id)| {\n                db.concrete_enum_variant(\n                    concrete_enum_id,\n                    &db.variant_semantic(enum_id, variant_id)?,\n                )\n            })\n            .collect()\n    }\n}\n\nimpl<'a, T: Upcast<dyn SemanticGroup + 'a> + ?Sized> SemanticEnumEx<'a> for T {}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_debug::DebugWithDb;\nuse cairo_lang_defs::ids::ModuleItemId;\nuse cairo_lang_utils::extract_matches;\nuse indoc::indoc;\nuse pretty_assertions::assert_eq;\nuse test_log::test;\n\nuse crate::db::SemanticGroup;\nuse crate::test_utils::{setup_test_module, SemanticDatabaseForTesting};\n\n#[test]\nfn test_enum() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let db = &mut db_val;\n    let (test_module, diagnostics) = setup_test_module(\n        db,\n        indoc::indoc! {\"\n            enum A {\n                a: felt252,\n                b: (felt252, felt252),\n                c: (),\n                a: (),\n                a: ()\n            }\n\n            fn foo(a: A) {\n                5;\n            }\n        \"},\n    )\n    .split();\n    assert_eq!(\n        diagnostics,\n        indoc! {r#\"\n        error: Redefinition of variant \"a\" on enum \"test::A\".\n         --> lib.cairo:5:5\n            a: (),\n            ^***^\n\n        error: Redefinition of variant \"a\" on enum \"test::A\".\n         --> lib.cairo:6:5\n            a: ()\n            ^***^\n\n        \"#}\n    );\n    let module_id = test_module.module_id;\n\n    let enum_id = extract_matches!(\n        db.module_item_by_name(module_id, \"A\".into()).unwrap().unwrap(),\n        ModuleItemId::Enum\n    );\n    let actual = db\n        .enum_variants(enum_id)\n        .unwrap()\n        .iter()\n        .map(|(name, variant_id)| {\n            format!(\n                \"{name}: {:?}, ty: {:?}\",\n                variant_id.debug(db),\n                db.variant_semantic(enum_id, *variant_id).unwrap().ty.debug(db)\n            )\n        })\n        .collect::<Vec<_>>()\n        .join(\",\\n\");\n    assert_eq!(\n        actual,\n        indoc! {\"\n            a: VariantId(test::a), ty: (),\n            b: VariantId(test::b), ty: (core::felt252, core::felt252),\n            c: VariantId(test::c), ty: ()\"}\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse cairo_lang_defs::ids::{ExternFunctionId, FunctionTitleId, GenericKind, LanguageElementId};\nuse cairo_lang_diagnostics::{Diagnostics, Maybe, ToMaybe};\nuse cairo_lang_utils::extract_matches;\n\nuse super::attribute::ast_attributes_to_semantic;\nuse super::function_with_body::get_inline_config;\nuse super::functions::{FunctionDeclarationData, GenericFunctionId, InlineConfiguration};\nuse super::generics::semantic_generic_params;\nuse crate::corelib::get_core_generic_function_id;\nuse crate::db::SemanticGroup;\nuse crate::diagnostic::SemanticDiagnosticKind::*;\nuse crate::diagnostic::SemanticDiagnostics;\nuse crate::expr::compute::Environment;\nuse crate::resolve_path::{ResolvedLookback, Resolver};\nuse crate::{semantic, Mutability, Parameter, SemanticDiagnostic, TypeId};\n\n#[cfg(test)]\n#[path = \"extern_function_test.rs\"]\nmod test;\n\n// --- Selectors ---\n\n/// Query implementation of [crate::db::SemanticGroup::extern_function_declaration_inline_config].\npub fn extern_function_declaration_inline_config(\n    db: &dyn SemanticGroup,\n    extern_function_id: ExternFunctionId,\n) -> Maybe<InlineConfiguration> {\n    Ok(db.priv_extern_function_declaration_data(extern_function_id)?.inline_config)\n}\n// TODO(spapini): Remove declaration from the names.\n/// Query implementation of [crate::db::SemanticGroup::extern_function_declaration_diagnostics].\npub fn extern_function_declaration_diagnostics(\n    db: &dyn SemanticGroup,\n    extern_function_id: ExternFunctionId,\n) -> Diagnostics<SemanticDiagnostic> {\n    db.priv_extern_function_declaration_data(extern_function_id)\n        .map(|data| data.diagnostics)\n        .unwrap_or_default()\n}\n/// Query implementation of [crate::db::SemanticGroup::extern_function_signature].\npub fn extern_function_signature(\n    db: &dyn SemanticGroup,\n    extern_function_id: ExternFunctionId,\n) -> Maybe<semantic::Signature> {\n    Ok(db.priv_extern_function_declaration_data(extern_function_id)?.signature)\n}\n/// Query implementation of [crate::db::SemanticGroup::extern_function_declaration_generic_params].\npub fn extern_function_declaration_generic_params(\n    db: &dyn SemanticGroup,\n    extern_function_id: ExternFunctionId,\n) -> Maybe<Vec<semantic::GenericParam>> {\n    Ok(db.priv_extern_function_declaration_data(extern_function_id)?.generic_params)\n}\n/// Query implementation of [crate::db::SemanticGroup::extern_function_declaration_implicits].\npub fn extern_function_declaration_implicits(\n    db: &dyn SemanticGroup,\n    extern_function_id: ExternFunctionId,\n) -> Maybe<Vec<TypeId>> {\n    Ok(db.priv_extern_function_declaration_data(extern_function_id)?.signature.implicits)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::extern_function_declaration_refs].\npub fn extern_function_declaration_refs(\n    db: &dyn SemanticGroup,\n    extern_function_id: ExternFunctionId,\n) -> Maybe<Vec<Parameter>> {\n    Ok(db\n        .priv_extern_function_declaration_data(extern_function_id)?\n        .signature\n        .params\n        .into_iter()\n        .filter(|param| param.mutability == Mutability::Reference)\n        .collect())\n}\n\n/// Query implementation of\n/// [crate::db::SemanticGroup::extern_function_declaration_resolved_lookback].\npub fn extern_function_declaration_resolved_lookback(\n    db: &dyn SemanticGroup,\n    extern_function_id: ExternFunctionId,\n) -> Maybe<Arc<ResolvedLookback>> {\n    Ok(db.priv_extern_function_declaration_data(extern_function_id)?.resolved_lookback)\n}\n\n// --- Computation ---\n\n/// Query implementation of [crate::db::SemanticGroup::priv_extern_function_declaration_data].\npub fn priv_extern_function_declaration_data(\n    db: &dyn SemanticGroup,\n    extern_function_id: ExternFunctionId,\n) -> Maybe<FunctionDeclarationData> {\n    let syntax_db = db.upcast();\n    let module_file_id = extern_function_id.module_file_id(db.upcast());\n    let mut diagnostics = SemanticDiagnostics::new(module_file_id);\n    let module_extern_functions = db.module_extern_functions(module_file_id.0)?;\n    let function_syntax = module_extern_functions.get(&extern_function_id).to_maybe()?;\n    let declaration = function_syntax.declaration(syntax_db);\n\n    // Generic params.\n    let mut resolver = Resolver::new_with_inference(db, module_file_id);\n    let generic_params = semantic_generic_params(\n        db,\n        &mut diagnostics,\n        &mut resolver,\n        module_file_id,\n        &declaration.generic_params(syntax_db),\n    )?;\n    if let Some(param) = generic_params.iter().find(|param| param.kind() == GenericKind::Impl) {\n        diagnostics.report_by_ptr(\n            param.stable_ptr(db.upcast()).untyped(),\n            ExternItemWithImplGenericsNotSupported,\n        );\n    }\n\n    let mut environment = Environment::default();\n    let signature_syntax = declaration.signature(syntax_db);\n    let signature = semantic::Signature::from_ast(\n        &mut diagnostics,\n        db,\n        &mut resolver,\n        &signature_syntax,\n        FunctionTitleId::Extern(extern_function_id),\n        &mut environment,\n    );\n\n    if signature.panicable {\n        let panic_function = extract_matches!(\n            get_core_generic_function_id(db.upcast(), \"panic\".into()),\n            GenericFunctionId::Extern\n        );\n        if extern_function_id != panic_function {\n            diagnostics.report(function_syntax, PanicableExternFunction);\n        }\n    }\n\n    let attributes = ast_attributes_to_semantic(syntax_db, function_syntax.attributes(syntax_db));\n    let inline_config = get_inline_config(db, &mut diagnostics, &attributes)?;\n\n    match &inline_config {\n        InlineConfiguration::None => {}\n        InlineConfiguration::Always(attr) | InlineConfiguration::Never(attr) => {\n            diagnostics\n                .report_by_ptr(attr.stable_ptr.untyped(), InlineAttrForExternFunctionNotAllowed);\n        }\n    }\n\n    Ok(FunctionDeclarationData {\n        diagnostics: diagnostics.build(),\n        signature,\n        environment,\n        generic_params,\n        attributes,\n        resolved_lookback: Arc::new(resolver.lookback),\n        inline_config,\n    })\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_debug::DebugWithDb;\nuse cairo_lang_defs::ids::ModuleItemId;\nuse cairo_lang_utils::extract_matches;\nuse pretty_assertions::assert_eq;\nuse test_log::test;\n\nuse crate::db::SemanticGroup;\nuse crate::test_utils::{setup_test_module, SemanticDatabaseForTesting};\n\n#[test]\nfn test_extern_function() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let db = &mut db_val;\n    let test_module = setup_test_module(\n        db,\n        indoc::indoc! {\"\n            extern fn foo<A, B>() nopanic;\n        \"},\n    )\n    .unwrap();\n    let module_id = test_module.module_id;\n\n    let extern_function_id = extract_matches!(\n        db.module_item_by_name(module_id, \"foo\".into()).unwrap().unwrap(),\n        ModuleItemId::ExternFunction\n    );\n    let signature = db.extern_function_signature(extern_function_id).unwrap();\n    assert_eq!(\n        format!(\"{:?}\", signature.debug(db)),\n        \"Signature { params: [], return_type: (), implicits: [], panicable: false }\"\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_defs::ids::{ExternTypeId, GenericKind, LanguageElementId};\nuse cairo_lang_diagnostics::{Diagnostics, Maybe, ToMaybe};\nuse cairo_lang_proc_macros::DebugWithDb;\n\nuse super::generics::semantic_generic_params;\nuse crate::db::SemanticGroup;\nuse crate::diagnostic::SemanticDiagnosticKind::*;\nuse crate::diagnostic::SemanticDiagnostics;\nuse crate::resolve_path::Resolver;\nuse crate::{GenericParam, SemanticDiagnostic};\n\n#[cfg(test)]\n#[path = \"extern_type_test.rs\"]\nmod test;\n\n// Declaration.\n#[derive(Clone, Debug, PartialEq, Eq, DebugWithDb)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct ExternTypeDeclarationData {\n    diagnostics: Diagnostics<SemanticDiagnostic>,\n    generic_params: Vec<GenericParam>,\n}\n\n// Selectors.\n/// Query implementation of [crate::db::SemanticGroup::extern_type_declaration_diagnostics].\npub fn extern_type_declaration_diagnostics(\n    db: &dyn SemanticGroup,\n    extern_type_id: ExternTypeId,\n) -> Diagnostics<SemanticDiagnostic> {\n    db.priv_extern_type_declaration_data(extern_type_id)\n        .map(|data| data.diagnostics)\n        .unwrap_or_default()\n}\n/// Query implementation of [crate::db::SemanticGroup::extern_type_declaration_generic_params].\npub fn extern_type_declaration_generic_params(\n    db: &dyn SemanticGroup,\n    extern_type_id: ExternTypeId,\n) -> Maybe<Vec<GenericParam>> {\n    Ok(db.priv_extern_type_declaration_data(extern_type_id)?.generic_params)\n}\n\n// Computation.\n/// Query implementation of [crate::db::SemanticGroup::priv_extern_type_declaration_data].\npub fn priv_extern_type_declaration_data(\n    db: &dyn SemanticGroup,\n    extern_type_id: ExternTypeId,\n) -> Maybe<ExternTypeDeclarationData> {\n    let module_file_id = extern_type_id.module_file_id(db.upcast());\n    let mut diagnostics = SemanticDiagnostics::new(module_file_id);\n    let module_extern_types = db.module_extern_types(module_file_id.0)?;\n    let type_syntax = module_extern_types.get(&extern_type_id).to_maybe()?;\n\n    let mut resolver = Resolver::new_with_inference(db, module_file_id);\n    let generic_params = semantic_generic_params(\n        db,\n        &mut diagnostics,\n        &mut resolver,\n        module_file_id,\n        &type_syntax.generic_params(db.upcast()),\n    )?;\n    if let Some(param) = generic_params.iter().find(|param| param.kind() == GenericKind::Impl) {\n        diagnostics.report_by_ptr(\n            param.stable_ptr(db.upcast()).untyped(),\n            ExternItemWithImplGenericsNotSupported,\n        );\n    }\n    Ok(ExternTypeDeclarationData { diagnostics: diagnostics.build(), generic_params })\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_debug::DebugWithDb;\nuse cairo_lang_defs::ids::ModuleItemId;\nuse cairo_lang_utils::extract_matches;\nuse pretty_assertions::assert_eq;\nuse test_log::test;\n\nuse crate::db::SemanticGroup;\nuse crate::test_utils::{setup_test_module, SemanticDatabaseForTesting};\n\n#[test]\nfn test_extern_type() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let db = &mut db_val;\n    let test_module = setup_test_module(\n        db,\n        indoc::indoc! {\"\n            extern type S<A, B>;\n        \"},\n    )\n    .unwrap();\n    let module_id = test_module.module_id;\n\n    let extern_type_id = extract_matches!(\n        db.module_item_by_name(module_id, \"S\".into()).unwrap().unwrap(),\n        ModuleItemId::ExternType\n    );\n    let generic_params = db.extern_type_declaration_generic_params(extern_type_id).unwrap();\n    assert_eq!(\n        format!(\"{:?}\", generic_params.debug(db)),\n        \"[GenericParamType(test::S::A), GenericParamType(test::S::B)]\"\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashSet;\nuse std::sync::Arc;\n\nuse cairo_lang_defs::ids::{FreeFunctionId, FunctionTitleId, LanguageElementId};\nuse cairo_lang_diagnostics::{Diagnostics, Maybe, ToMaybe};\nuse cairo_lang_utils::try_extract_matches;\nuse cairo_lang_utils::unordered_hash_map::UnorderedHashMap;\n\nuse super::attribute::ast_attributes_to_semantic;\nuse super::function_with_body::{get_inline_config, FunctionBody, FunctionBodyData};\nuse super::functions::{\n    forbid_inline_always_with_impl_generic_param, FunctionDeclarationData, InlineConfiguration,\n};\nuse super::generics::semantic_generic_params;\nuse crate::db::SemanticGroup;\nuse crate::diagnostic::SemanticDiagnostics;\nuse crate::expr::compute::{compute_root_expr, ComputationContext, Environment};\nuse crate::resolve_path::{ResolvedLookback, Resolver};\nuse crate::{semantic, Expr, FunctionId, SemanticDiagnostic, TypeId};\n\n#[cfg(test)]\n#[path = \"free_function_test.rs\"]\nmod test;\n\n// === Declaration ===\n\n// --- Selectors ---\n\n/// Query implementation of [crate::db::SemanticGroup::free_function_declaration_diagnostics].\npub fn free_function_declaration_diagnostics(\n    db: &dyn SemanticGroup,\n    free_function_id: FreeFunctionId,\n) -> Diagnostics<SemanticDiagnostic> {\n    db.priv_free_function_declaration_data(free_function_id)\n        .map(|data| data.diagnostics)\n        .unwrap_or_default()\n}\n\n/// Query implementation of [crate::db::SemanticGroup::free_function_signature].\npub fn free_function_signature(\n    db: &dyn SemanticGroup,\n    free_function_id: FreeFunctionId,\n) -> Maybe<semantic::Signature> {\n    Ok(db.priv_free_function_declaration_data(free_function_id)?.signature)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::free_function_declaration_implicits].\npub fn free_function_declaration_implicits(\n    db: &dyn SemanticGroup,\n    free_function_id: FreeFunctionId,\n) -> Maybe<Vec<TypeId>> {\n    Ok(db.priv_free_function_declaration_data(free_function_id)?.signature.implicits)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::free_function_generic_params].\npub fn free_function_generic_params(\n    db: &dyn SemanticGroup,\n    free_function_id: FreeFunctionId,\n) -> Maybe<Vec<semantic::GenericParam>> {\n    Ok(db.priv_free_function_declaration_data(free_function_id)?.generic_params)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::free_function_declaration_resolved_lookback].\npub fn free_function_declaration_resolved_lookback(\n    db: &dyn SemanticGroup,\n    free_function_id: FreeFunctionId,\n) -> Maybe<Arc<ResolvedLookback>> {\n    Ok(db.priv_free_function_declaration_data(free_function_id)?.resolved_lookback)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::free_function_declaration_inline_config].\npub fn free_function_declaration_inline_config(\n    db: &dyn SemanticGroup,\n    free_function_id: FreeFunctionId,\n) -> Maybe<InlineConfiguration> {\n    Ok(db.priv_free_function_declaration_data(free_function_id)?.inline_config)\n}\n\n// --- Computation ---\n\n/// Query implementation of [crate::db::SemanticGroup::priv_free_function_declaration_data].\npub fn priv_free_function_declaration_data(\n    db: &dyn SemanticGroup,\n    free_function_id: FreeFunctionId,\n) -> Maybe<FunctionDeclarationData> {\n    let syntax_db = db.upcast();\n    let module_file_id = free_function_id.module_file_id(db.upcast());\n    let mut diagnostics = SemanticDiagnostics::new(module_file_id);\n    let module_free_functions = db.module_free_functions(module_file_id.0)?;\n    let function_syntax = module_free_functions.get(&free_function_id).to_maybe()?;\n    let declaration = function_syntax.declaration(syntax_db);\n\n    // Generic params.\n    let mut resolver = Resolver::new_with_inference(db, module_file_id);\n    let generic_params = semantic_generic_params(\n        db,\n        &mut diagnostics,\n        &mut resolver,\n        module_file_id,\n        &declaration.generic_params(syntax_db),\n    )?;\n\n    let mut environment = Environment::default();\n\n    let signature_syntax = declaration.signature(syntax_db);\n    let signature = semantic::Signature::from_ast(\n        &mut diagnostics,\n        db,\n        &mut resolver,\n        &signature_syntax,\n        FunctionTitleId::Free(free_function_id),\n        &mut environment,\n    );\n\n    let attributes = ast_attributes_to_semantic(syntax_db, function_syntax.attributes(syntax_db));\n\n    let inline_config = get_inline_config(db, &mut diagnostics, &attributes)?;\n\n    forbid_inline_always_with_impl_generic_param(&mut diagnostics, &generic_params, &inline_config);\n\n    Ok(FunctionDeclarationData {\n        diagnostics: diagnostics.build(),\n        signature,\n        environment,\n        generic_params,\n        attributes,\n        resolved_lookback: Arc::new(resolver.lookback),\n        inline_config,\n    })\n}\n\n// === Body ===\n\n// --- Selectors ---\n\n/// Query implementation of [crate::db::SemanticGroup::free_function_body_diagnostics].\npub fn free_function_body_diagnostics(\n    db: &dyn SemanticGroup,\n    free_function_id: FreeFunctionId,\n) -> Diagnostics<SemanticDiagnostic> {\n    db.priv_free_function_body_data(free_function_id)\n        .map(|data| data.diagnostics)\n        .unwrap_or_default()\n}\n\n/// Query implementation of [crate::db::SemanticGroup::free_function_body_resolved_lookback].\npub fn free_function_body_resolved_lookback(\n    db: &dyn SemanticGroup,\n    free_function_id: FreeFunctionId,\n) -> Maybe<Arc<ResolvedLookback>> {\n    Ok(db.priv_free_function_body_data(free_function_id)?.resolved_lookback)\n}\n\n// --- Computation ---\n\n/// Query implementation of [crate::db::SemanticGroup::priv_free_function_body_data].\npub fn priv_free_function_body_data(\n    db: &dyn SemanticGroup,\n    free_function_id: FreeFunctionId,\n) -> Maybe<FunctionBodyData> {\n    let module_file_id = free_function_id.module_file_id(db.upcast());\n    let mut diagnostics = SemanticDiagnostics::new(module_file_id);\n    let module_free_functions = db.module_free_functions(module_file_id.0)?;\n    let function_syntax = module_free_functions.get(&free_function_id).to_maybe()?.clone();\n    // Compute declaration semantic.\n    let declaration = db.priv_free_function_declaration_data(free_function_id)?;\n\n    // Generic params.\n    let mut resolver = Resolver::new_with_inference(db, module_file_id);\n    for generic_param in declaration.generic_params {\n        resolver.add_generic_param(generic_param);\n    }\n\n    let environment = declaration.environment;\n    // Compute body semantic expr.\n    let mut ctx = ComputationContext::new(\n        db,\n        &mut diagnostics,\n        resolver,\n        Some(&declaration.signature),\n        environment,\n    );\n    let function_body = function_syntax.body(db.upcast());\n    let return_type = declaration.signature.return_type;\n    let body_expr = compute_root_expr(&mut ctx, &function_body, return_type)?;\n    let ComputationContext { exprs, statements, resolver, .. } = ctx;\n\n    let direct_callees: HashSet<FunctionId> = exprs\n        .iter()\n        .filter_map(|(_id, expr)| try_extract_matches!(expr, Expr::FunctionCall))\n        .map(|f| f.function)\n        .collect();\n\n    let expr_lookup: UnorderedHashMap<_, _> =\n        exprs.iter().map(|(expr_id, expr)| (expr.stable_ptr(), expr_id)).collect();\n    let resolved_lookback = Arc::new(resolver.lookback);\n    Ok(FunctionBodyData {\n        diagnostics: diagnostics.build(),\n        expr_lookup,\n        resolved_lookback,\n        body: Arc::new(FunctionBody {\n            exprs,\n            statements,\n            body_expr,\n            direct_callees: direct_callees.into_iter().collect(),\n        }),\n    })\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_debug::DebugWithDb;\nuse cairo_lang_defs::ids::{FunctionWithBodyId, ModuleItemId};\nuse cairo_lang_utils::extract_matches;\nuse pretty_assertions::assert_eq;\nuse test_log::test;\n\nuse crate::db::SemanticGroup;\nuse crate::expr::fmt::ExprFormatter;\nuse crate::items::function_with_body::SemanticExprLookup;\nuse crate::test_utils::{setup_test_module, SemanticDatabaseForTesting};\n\n#[test]\nfn test_expr_lookup() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let db = &mut db_val;\n    let test_module = setup_test_module(\n        db,\n        indoc::indoc! {\"\n            #[external]\n            #[my_attr]\n            fn foo<A, B>(a: felt252) -> felt252 {\n                let x = 5 + 5;\n                match 1 * (1) {\n                    0 => {5},\n                    _ => {6}\n                }\n            }\n        \"},\n    )\n    .unwrap();\n    let module_id = test_module.module_id;\n\n    let function_id = FunctionWithBodyId::Free(extract_matches!(\n        db.module_item_by_name(module_id, \"foo\".into()).unwrap().unwrap(),\n        ModuleItemId::FreeFunction\n    ));\n    let expr_formatter = ExprFormatter { db, function_id };\n    let mut expr_debugs = Vec::new();\n    for (expr_id, expr) in &db.function_body(function_id).unwrap().exprs {\n        assert_eq!(db.lookup_expr_by_ptr(function_id, expr.stable_ptr()), Ok(expr_id));\n        expr_debugs.push(format!(\"{:?}\", expr.debug(&expr_formatter)));\n    }\n    expr_debugs.sort();\n    assert_eq!(\n        expr_debugs,\n        [\n            \"Block(ExprBlock { statements: [Let(StatementLet { pattern: Variable(x), expr: \\\n             FunctionCall(ExprFunctionCall { function: core::Felt252Add::add, args: \\\n             [Value(Literal(ExprLiteral { value: 5, ty: core::felt252 })), \\\n             Value(Literal(ExprLiteral { value: 5, ty: core::felt252 }))], ty: core::felt252 }) \\\n             })], tail: Some(Match(ExprMatch { matched_expr: FunctionCall(ExprFunctionCall { \\\n             function: core::Felt252Mul::mul, args: [Value(Literal(ExprLiteral { value: 1, ty: \\\n             core::felt252 })), Value(Literal(ExprLiteral { value: 1, ty: core::felt252 }))], ty: \\\n             core::felt252 }), arms: [MatchArm { pattern: Literal(PatternLiteral { literal: \\\n             ExprLiteral { value: 0, ty: core::felt252 }, ty: core::felt252 }), expression: \\\n             Block(ExprBlock { statements: [], tail: Some(Literal(ExprLiteral { value: 5, ty: \\\n             core::felt252 })), ty: core::felt252 }) }, MatchArm { pattern: \\\n             Otherwise(PatternOtherwise { ty: core::felt252 }), expression: Block(ExprBlock { \\\n             statements: [], tail: Some(Literal(ExprLiteral { value: 6, ty: core::felt252 })), \\\n             ty: core::felt252 }) }], ty: core::felt252 })), ty: core::felt252 })\",\n            \"Block(ExprBlock { statements: [], tail: Some(Literal(ExprLiteral { value: 5, ty: \\\n             core::felt252 })), ty: core::felt252 })\",\n            \"Block(ExprBlock { statements: [], tail: Some(Literal(ExprLiteral { value: 6, ty: \\\n             core::felt252 })), ty: core::felt252 })\",\n            \"FunctionCall(ExprFunctionCall { function: core::Felt252Add::add, args: \\\n             [Value(Literal(ExprLiteral { value: 5, ty: core::felt252 })), \\\n             Value(Literal(ExprLiteral { value: 5, ty: core::felt252 }))], ty: core::felt252 })\",\n            \"FunctionCall(ExprFunctionCall { function: core::Felt252Mul::mul, args: \\\n             [Value(Literal(ExprLiteral { value: 1, ty: core::felt252 })), \\\n             Value(Literal(ExprLiteral { value: 1, ty: core::felt252 }))], ty: core::felt252 })\",\n            \"Literal(ExprLiteral { value: 1, ty: core::felt252 })\",\n            \"Literal(ExprLiteral { value: 1, ty: core::felt252 })\",\n            \"Literal(ExprLiteral { value: 5, ty: core::felt252 })\",\n            \"Literal(ExprLiteral { value: 5, ty: core::felt252 })\",\n            \"Literal(ExprLiteral { value: 5, ty: core::felt252 })\",\n            \"Literal(ExprLiteral { value: 6, ty: core::felt252 })\",\n            \"Match(ExprMatch { matched_expr: FunctionCall(ExprFunctionCall { function: \\\n             core::Felt252Mul::mul, args: [Value(Literal(ExprLiteral { value: 1, ty: \\\n             core::felt252 })), Value(Literal(ExprLiteral { value: 1, ty: core::felt252 }))], ty: \\\n             core::felt252 }), arms: [MatchArm { pattern: Literal(PatternLiteral { literal: \\\n             ExprLiteral { value: 0, ty: core::felt252 }, ty: core::felt252 }), expression: \\\n             Block(ExprBlock { statements: [], tail: Some(Literal(ExprLiteral { value: 5, ty: \\\n             core::felt252 })), ty: core::felt252 }) }, MatchArm { pattern: \\\n             Otherwise(PatternOtherwise { ty: core::felt252 }), expression: Block(ExprBlock { \\\n             statements: [], tail: Some(Literal(ExprLiteral { value: 6, ty: core::felt252 })), \\\n             ty: core::felt252 }) }], ty: core::felt252 })\",\n        ]\n    );\n\n    let attributes = db.function_with_body_attributes(function_id).unwrap();\n    assert_eq!(\n        format!(\"{:?}\", attributes.debug(db)),\n        \"[Attribute { id: \\\"external\\\" }, Attribute { id: \\\"my_attr\\\" }]\"\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashSet;\nuse std::sync::Arc;\n\nuse cairo_lang_defs::ids::FunctionWithBodyId;\nuse cairo_lang_diagnostics::{Diagnostics, Maybe, ToMaybe};\nuse cairo_lang_proc_macros::DebugWithDb;\nuse cairo_lang_syntax::node::ast;\nuse cairo_lang_utils::unordered_hash_map::UnorderedHashMap;\nuse cairo_lang_utils::Upcast;\nuse id_arena::Arena;\n\nuse super::attribute::Attribute;\nuse super::functions::InlineConfiguration;\nuse crate::db::SemanticGroup;\nuse crate::diagnostic::{SemanticDiagnosticKind, SemanticDiagnostics};\nuse crate::resolve_path::ResolvedLookback;\nuse crate::{semantic, ExprId, FunctionId, SemanticDiagnostic};\n\n// === Declaration ===\n\n// --- Selectors ---\n\n/// Query implementation of [crate::db::SemanticGroup::function_declaration_diagnostics].\npub fn function_declaration_diagnostics(\n    db: &dyn SemanticGroup,\n    function_id: FunctionWithBodyId,\n) -> Diagnostics<SemanticDiagnostic> {\n    let declaration_data = match function_id {\n        FunctionWithBodyId::Free(free_function_id) => {\n            db.priv_free_function_declaration_data(free_function_id)\n        }\n        FunctionWithBodyId::Impl(impl_function_id) => db\n            .priv_impl_function_declaration_data(impl_function_id)\n            .map(|x| x.function_declaration_data),\n    };\n    declaration_data.map(|data| data.diagnostics).unwrap_or_default()\n}\n\n/// Query implementation of [crate::db::SemanticGroup::function_declaration_inline_config].\npub fn function_declaration_inline_config(\n    db: &dyn SemanticGroup,\n    function_id: FunctionWithBodyId,\n) -> Maybe<InlineConfiguration> {\n    match function_id {\n        FunctionWithBodyId::Free(free_function_id) => {\n            db.free_function_declaration_inline_config(free_function_id)\n        }\n        FunctionWithBodyId::Impl(impl_function_id) => {\n            db.impl_function_declaration_inline_config(impl_function_id)\n        }\n    }\n}\n\n/// Query implementation of [crate::db::SemanticGroup::function_with_body_signature].\npub fn function_with_body_signature(\n    db: &dyn SemanticGroup,\n    function_id: FunctionWithBodyId,\n) -> Maybe<semantic::Signature> {\n    match function_id {\n        FunctionWithBodyId::Free(free_function_id) => db.free_function_signature(free_function_id),\n        FunctionWithBodyId::Impl(impl_function_id) => db.impl_function_signature(impl_function_id),\n    }\n}\n\n/// Query implementation of\n/// [crate::db::SemanticGroup::function_with_body_generic_params].\npub fn function_with_body_generic_params(\n    db: &dyn SemanticGroup,\n    function_id: FunctionWithBodyId,\n) -> Maybe<Vec<semantic::GenericParam>> {\n    match function_id {\n        FunctionWithBodyId::Free(free_function_id) => {\n            db.free_function_generic_params(free_function_id)\n        }\n        FunctionWithBodyId::Impl(impl_function_id) => {\n            let mut res = db.impl_def_generic_params(impl_function_id.impl_def_id(db.upcast()))?;\n            res.extend(db.impl_function_generic_params(impl_function_id)?);\n            Ok(res)\n        }\n    }\n}\n\n/// Query implementation of [crate::db::SemanticGroup::function_with_body_attributes].\npub fn function_with_body_attributes(\n    db: &dyn SemanticGroup,\n    function_id: FunctionWithBodyId,\n) -> Maybe<Vec<Attribute>> {\n    match function_id {\n        FunctionWithBodyId::Free(free_function_id) => {\n            Ok(db.priv_free_function_declaration_data(free_function_id)?.attributes)\n        }\n        FunctionWithBodyId::Impl(impl_function_id) => Ok(db\n            .priv_impl_function_declaration_data(impl_function_id)?\n            .function_declaration_data\n            .attributes),\n    }\n}\n\n// === Body ===\n\n#[derive(Clone, Debug, PartialEq, Eq, DebugWithDb)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct FunctionBodyData {\n    pub diagnostics: Diagnostics<SemanticDiagnostic>,\n    pub expr_lookup: UnorderedHashMap<ast::ExprPtr, ExprId>,\n    pub resolved_lookback: Arc<ResolvedLookback>,\n    pub body: Arc<FunctionBody>,\n}\n\n#[derive(Clone, Debug, PartialEq, Eq, DebugWithDb)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct FunctionBody {\n    pub exprs: Arena<semantic::Expr>,\n    pub statements: Arena<semantic::Statement>,\n    pub body_expr: semantic::ExprId,\n    /// The set of direct callees of the function (user functions and libfuncs that are called\n    /// from this function).\n    pub direct_callees: HashSet<FunctionId>,\n}\n\n// --- Selectors ---\n\n/// Query implementation of [crate::db::SemanticGroup::function_body_diagnostics].\npub fn function_body_diagnostics(\n    db: &dyn SemanticGroup,\n    function_id: FunctionWithBodyId,\n) -> Diagnostics<SemanticDiagnostic> {\n    let body_data = match function_id {\n        FunctionWithBodyId::Free(free_function_id) => {\n            db.priv_free_function_body_data(free_function_id)\n        }\n        FunctionWithBodyId::Impl(impl_function_id) => {\n            db.priv_impl_function_body_data(impl_function_id)\n        }\n    };\n    body_data.map(|data| data.diagnostics).unwrap_or_default()\n}\n\n/// Query implementation of [crate::db::SemanticGroup::function_body_expr].\npub fn function_body_expr(\n    db: &dyn SemanticGroup,\n    function_id: FunctionWithBodyId,\n) -> Maybe<semantic::ExprId> {\n    Ok(db.function_body(function_id)?.body_expr)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::function_body].\npub fn function_body(\n    db: &dyn SemanticGroup,\n    function_id: FunctionWithBodyId,\n) -> Maybe<Arc<FunctionBody>> {\n    match function_id {\n        FunctionWithBodyId::Free(free_function_id) => {\n            Ok(db.priv_free_function_body_data(free_function_id)?.body)\n        }\n        FunctionWithBodyId::Impl(impl_function_id) => {\n            Ok(db.priv_impl_function_body_data(impl_function_id)?.body)\n        }\n    }\n}\n\n/// Query implementation of\n/// [crate::db::SemanticGroup::function_with_body_direct_callees].\npub fn function_with_body_direct_callees(\n    db: &dyn SemanticGroup,\n    function_id: FunctionWithBodyId,\n) -> Maybe<HashSet<FunctionId>> {\n    let direct_callees = match function_id {\n        FunctionWithBodyId::Free(free_function_id) => {\n            db.priv_free_function_body_data(free_function_id)?.body.direct_callees.clone()\n        }\n        FunctionWithBodyId::Impl(impl_function_id) => {\n            db.priv_impl_function_body_data(impl_function_id)?.body.direct_callees.clone()\n        }\n    };\n    Ok(direct_callees)\n}\n\n/// Query implementation of\n/// [crate::db::SemanticGroup::function_with_body_direct_function_with_body_callees].\npub fn function_with_body_direct_function_with_body_callees(\n    db: &dyn SemanticGroup,\n    function_id: FunctionWithBodyId,\n) -> Maybe<HashSet<FunctionWithBodyId>> {\n    Ok(db\n        .function_with_body_direct_callees(function_id)?\n        .into_iter()\n        .map(|function_id| function_id.try_get_function_with_body_id(db))\n        .collect::<Maybe<Vec<Option<_>>>>()?\n        .into_iter()\n        .flatten()\n        .collect())\n}\n\n// =========================================================\n\n/// Query implementation of [crate::db::SemanticGroup::expr_semantic].\npub fn expr_semantic(\n    db: &dyn SemanticGroup,\n    function_id: FunctionWithBodyId,\n    id: semantic::ExprId,\n) -> semantic::Expr {\n    db.function_body(function_id).unwrap().exprs.get(id).unwrap().clone()\n}\n\n/// Query implementation of [crate::db::SemanticGroup::statement_semantic].\npub fn statement_semantic(\n    db: &dyn SemanticGroup,\n    function_id: FunctionWithBodyId,\n    id: semantic::StatementId,\n) -> semantic::Statement {\n    db.function_body(function_id).unwrap().statements.get(id).unwrap().clone()\n}\n\npub trait SemanticExprLookup<'a>: Upcast<dyn SemanticGroup + 'a> {\n    fn lookup_expr_by_ptr(\n        &self,\n        function_id: FunctionWithBodyId,\n        ptr: ast::ExprPtr,\n    ) -> Maybe<ExprId> {\n        let body_data = match function_id {\n            FunctionWithBodyId::Free(free_function_id) => {\n                self.upcast().priv_free_function_body_data(free_function_id)\n            }\n            FunctionWithBodyId::Impl(impl_function_id) => {\n                self.upcast().priv_impl_function_body_data(impl_function_id)\n            }\n        };\n        body_data?.expr_lookup.get(&ptr).copied().to_maybe()\n    }\n}\nimpl<'a, T: Upcast<dyn SemanticGroup + 'a> + ?Sized> SemanticExprLookup<'a> for T {}\n\n/// Get the inline configuration of the given function by parsing its attributes.\npub fn get_inline_config(\n    db: &dyn SemanticGroup,\n    diagnostics: &mut SemanticDiagnostics,\n    attributes: &[Attribute],\n) -> Maybe<InlineConfiguration> {\n    let mut config = InlineConfiguration::None;\n    let mut seen_inline_attr = false;\n    for attr in attributes {\n        if attr.id != \"inline\" {\n            continue;\n        }\n\n        match &attr.args[..] {\n            [ast::Expr::Path(path)] if &path.node.get_text(db.upcast()) == \"always\" => {\n                config = InlineConfiguration::Always(attr.clone());\n            }\n            [ast::Expr::Path(path)] if &path.node.get_text(db.upcast()) == \"never\" => {\n                config = InlineConfiguration::Never(attr.clone());\n            }\n            [] => {\n                diagnostics.report_by_ptr(\n                    attr.id_stable_ptr.untyped(),\n                    SemanticDiagnosticKind::InlineWithoutArgumentNotSupported,\n                );\n            }\n            _ => {\n                diagnostics.report_by_ptr(\n                    attr.args_stable_ptr.untyped(),\n                    SemanticDiagnosticKind::UnsupportedInlineArguments,\n                );\n            }\n        }\n\n        if seen_inline_attr {\n            diagnostics.report_by_ptr(\n                attr.id_stable_ptr.untyped(),\n                SemanticDiagnosticKind::RedundantInlineAttribute,\n            );\n            // If we have multiple inline attributes revert to InlineConfiguration::None.\n            config = InlineConfiguration::None;\n        }\n\n        seen_inline_attr = true;\n    }\n    Ok(config)\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse cairo_lang_debug::DebugWithDb;\nuse cairo_lang_defs::ids::{\n    ExternFunctionId, FreeFunctionId, FunctionTitleId, FunctionWithBodyId, ImplFunctionId,\n    ModuleItemId, ParamLongId, TopLevelLanguageElementId, TraitFunctionId, UnstableSalsaId,\n};\nuse cairo_lang_diagnostics::{skip_diagnostic, Diagnostics, Maybe};\nuse cairo_lang_proc_macros::{DebugWithDb, SemanticObject};\nuse cairo_lang_syntax as syntax;\nuse cairo_lang_syntax::node::{ast, Terminal, TypedSyntaxNode};\nuse cairo_lang_utils::{define_short_id, try_extract_matches, OptionFrom};\nuse itertools::{chain, Itertools};\nuse smol_str::SmolStr;\n\nuse super::attribute::Attribute;\nuse super::imp::ImplId;\nuse super::modifiers;\nuse super::trt::ConcreteTraitGenericFunctionId;\nuse crate::corelib::unit_ty;\nuse crate::db::SemanticGroup;\nuse crate::diagnostic::{SemanticDiagnosticKind, SemanticDiagnostics};\nuse crate::expr::compute::Environment;\nuse crate::resolve_path::{ResolvedLookback, Resolver};\nuse crate::substitution::{GenericSubstitution, SemanticRewriter, SubstitutionRewriter};\nuse crate::types::resolve_type;\nuse crate::{semantic, semantic_object_for_id, ConcreteImplId, GenericParam, SemanticDiagnostic};\n\n/// A generic function of an impl.\n#[derive(Copy, Clone, Debug, Hash, PartialEq, Eq, SemanticObject)]\npub struct ImplGenericFunctionId {\n    // TODO(spapini): Consider making these private and enforcing invariants in the ctor.\n    pub impl_id: ImplId,\n    pub function: TraitFunctionId,\n}\nimpl ImplGenericFunctionId {\n    pub fn impl_function(&self, db: &dyn SemanticGroup) -> Maybe<Option<ImplFunctionId>> {\n        match self.impl_id {\n            ImplId::Concrete(concrete_impl_id) => {\n                concrete_impl_id.get_impl_function(db, self.function)\n            }\n            ImplId::GenericParameter(_) | ImplId::ImplVar(_) => Ok(None),\n        }\n    }\n    /// Converts to ImplGenericFunctionWithBodyId if this is a function of a concrete impl.\n    pub fn to_impl_generic_with_body(\n        &self,\n        db: &dyn SemanticGroup,\n    ) -> Maybe<Option<ImplGenericFunctionWithBodyId>> {\n        let ImplId::Concrete(concrete_impl_id) = self.impl_id else {\n                return Ok(None);\n            };\n        let Some(impl_function) = concrete_impl_id\n                .get_impl_function(db.upcast(), self.function)?\n                else {\n                    // Trait function not found in impl.\n                    return Err(skip_diagnostic());\n                };\n        Ok(Some(ImplGenericFunctionWithBodyId { concrete_impl_id, function: impl_function }))\n    }\n    /// Converts to GenericFunctionWithBodyId if this is a function of a concrete impl.\n    pub fn to_generic_with_body(\n        &self,\n        db: &dyn SemanticGroup,\n    ) -> Maybe<Option<GenericFunctionWithBodyId>> {\n        let Some(impl_generic_with_body) = self.to_impl_generic_with_body(db)? else {\n                return Ok(None);\n            };\n        Ok(Some(GenericFunctionWithBodyId::Impl(impl_generic_with_body)))\n    }\n    pub fn format(&self, db: &dyn SemanticGroup) -> SmolStr {\n        format!(\"{}::{}\", self.impl_id.name(db.upcast()), self.function.name(db.upcast())).into()\n    }\n}\n\n/// The ID of a generic function that can be concretized.\n#[derive(Copy, Clone, Debug, Hash, PartialEq, Eq, SemanticObject)]\npub enum GenericFunctionId {\n    /// A generic free function.\n    Free(FreeFunctionId),\n    /// A generic extern function.\n    Extern(ExternFunctionId),\n    /// A generic function of an impl.\n    Impl(ImplGenericFunctionId),\n}\nimpl GenericFunctionId {\n    pub fn from_generic_with_body(\n        db: &dyn SemanticGroup,\n        val: GenericFunctionWithBodyId,\n    ) -> Maybe<Self> {\n        Ok(match val {\n            GenericFunctionWithBodyId::Free(id) => GenericFunctionId::Free(id),\n            GenericFunctionWithBodyId::Impl(id) => GenericFunctionId::Impl(ImplGenericFunctionId {\n                impl_id: ImplId::Concrete(id.concrete_impl_id),\n                function: db.impl_function_trait_function(id.function)?,\n            }),\n        })\n    }\n    pub fn format(&self, db: &dyn SemanticGroup) -> String {\n        let defs_db = db.upcast();\n        match self {\n            GenericFunctionId::Free(id) => id.full_path(defs_db),\n            GenericFunctionId::Extern(id) => id.full_path(defs_db),\n            GenericFunctionId::Impl(id) => {\n                format!(\"{:?}::{}\", id.impl_id.debug(db.elongate()), id.function.name(defs_db))\n            }\n        }\n    }\n    pub fn generic_signature(&self, db: &dyn SemanticGroup) -> Maybe<Signature> {\n        match *self {\n            GenericFunctionId::Free(id) => db.free_function_signature(id),\n            GenericFunctionId::Extern(id) => db.extern_function_signature(id),\n            GenericFunctionId::Impl(id) => {\n                let concrete_trait_id = db.impl_concrete_trait(id.impl_id)?;\n                let id = ConcreteTraitGenericFunctionId::new(db, concrete_trait_id, id.function);\n\n                db.concrete_trait_function_signature(id)\n            }\n        }\n    }\n    pub fn generic_params(&self, db: &dyn SemanticGroup) -> Maybe<Vec<GenericParam>> {\n        match *self {\n            GenericFunctionId::Free(id) => db.free_function_generic_params(id),\n            GenericFunctionId::Extern(id) => db.extern_function_declaration_generic_params(id),\n            GenericFunctionId::Impl(id) => {\n                let concrete_trait_id = db.impl_concrete_trait(id.impl_id)?;\n                let id = ConcreteTraitGenericFunctionId::new(db, concrete_trait_id, id.function);\n                db.concrete_trait_function_generic_params(id)\n            }\n        }\n    }\n    pub fn name(&self, db: &dyn SemanticGroup) -> SmolStr {\n        match self {\n            GenericFunctionId::Free(free_function) => free_function.name(db.upcast()),\n            GenericFunctionId::Extern(extern_function) => extern_function.name(db.upcast()),\n            GenericFunctionId::Impl(impl_function) => impl_function.format(db.upcast()),\n        }\n    }\n}\n/// Conversion from ModuleItemId to GenericFunctionId.\nimpl OptionFrom<ModuleItemId> for GenericFunctionId {\n    fn option_from(item: ModuleItemId) -> Option<Self> {\n        match item {\n            ModuleItemId::FreeFunction(id) => Some(GenericFunctionId::Free(id)),\n            ModuleItemId::ExternFunction(id) => Some(GenericFunctionId::Extern(id)),\n            ModuleItemId::Constant(_)\n            | ModuleItemId::Submodule(_)\n            | ModuleItemId::Use(_)\n            | ModuleItemId::Trait(_)\n            | ModuleItemId::Impl(_)\n            | ModuleItemId::Struct(_)\n            | ModuleItemId::Enum(_)\n            | ModuleItemId::TypeAlias(_)\n            | ModuleItemId::ExternType(_) => None,\n        }\n    }\n}\n\n/// Function instance.\n/// For example: `ImplA::foo<A, B>`, or `bar<A>`.\n// TODO(spapini): Make it an enum and add a function pointer variant.\n#[derive(Clone, Debug, Hash, PartialEq, Eq, SemanticObject)]\npub struct FunctionLongId {\n    pub function: ConcreteFunction,\n}\nimpl DebugWithDb<dyn SemanticGroup> for FunctionLongId {\n    fn fmt(\n        &self,\n        f: &mut std::fmt::Formatter<'_>,\n        db: &(dyn SemanticGroup + 'static),\n    ) -> std::fmt::Result {\n        write!(f, \"{:?}\", self.function.debug(db))\n    }\n}\n\ndefine_short_id!(FunctionId, FunctionLongId, SemanticGroup, lookup_intern_function);\nsemantic_object_for_id!(FunctionId, lookup_intern_function, intern_function, FunctionLongId);\nimpl FunctionId {\n    pub fn get_concrete(&self, db: &dyn SemanticGroup) -> ConcreteFunction {\n        db.lookup_intern_function(*self).function\n    }\n\n    /// Returns the ExternFunctionId if this is an extern function. Otherwise returns none.\n    pub fn try_get_extern_function_id(&self, db: &dyn SemanticGroup) -> Option<ExternFunctionId> {\n        try_extract_matches!(self.get_concrete(db).generic_function, GenericFunctionId::Extern)\n    }\n\n    /// Returns the FunctionWithBodyId if this is a function with body, otherwise returns None.\n    pub fn try_get_function_with_body_id(\n        &self,\n        db: &dyn SemanticGroup,\n    ) -> Maybe<Option<FunctionWithBodyId>> {\n        Ok(match self.get_concrete(db).generic_function {\n            GenericFunctionId::Free(free_function_id) => {\n                Some(FunctionWithBodyId::Free(free_function_id))\n            }\n            GenericFunctionId::Impl(impl_generic_function_id) => {\n                impl_generic_function_id.impl_function(db)?.map(FunctionWithBodyId::Impl)\n            }\n            GenericFunctionId::Extern(_) => None,\n        })\n    }\n\n    pub fn name(&self, db: &dyn SemanticGroup) -> SmolStr {\n        format!(\"{:?}\", self.get_concrete(db)).into()\n    }\n}\n\n/// A generic function of a concrete impl.\n#[derive(Copy, Clone, Debug, Hash, PartialEq, Eq, SemanticObject)]\npub struct ImplGenericFunctionWithBodyId {\n    pub concrete_impl_id: ConcreteImplId,\n    pub function: ImplFunctionId,\n}\n\n/// The ID of a generic function with body that can be concretized.\n#[derive(Copy, Clone, Debug, Hash, PartialEq, Eq, SemanticObject)]\npub enum GenericFunctionWithBodyId {\n    Free(FreeFunctionId),\n    Impl(ImplGenericFunctionWithBodyId),\n}\nimpl GenericFunctionWithBodyId {\n    pub fn from_generic(db: &dyn SemanticGroup, other: GenericFunctionId) -> Maybe<Option<Self>> {\n        Ok(Some(match other {\n            GenericFunctionId::Free(id) => GenericFunctionWithBodyId::Free(id),\n            GenericFunctionId::Impl(ImplGenericFunctionId {\n                impl_id: ImplId::Concrete(concrete_impl_id),\n                function,\n            }) => {\n                let Some(impl_function) = db.impl_function_by_trait_function(\n                    concrete_impl_id.impl_def_id(db),\n                    function,\n                )? else {\n                    return Ok(None);\n                };\n                GenericFunctionWithBodyId::Impl(ImplGenericFunctionWithBodyId {\n                    concrete_impl_id,\n                    function: impl_function,\n                })\n            }\n            _ => return Ok(None),\n        }))\n    }\n    pub fn name(&self, db: &dyn SemanticGroup) -> SmolStr {\n        match self {\n            GenericFunctionWithBodyId::Free(free) => free.name(db.upcast()),\n            GenericFunctionWithBodyId::Impl(imp) => {\n                format!(\"{}::{}\", imp.concrete_impl_id.name(db), imp.function.name(db.upcast()))\n                    .into()\n            }\n        }\n    }\n}\n\n/// A long Id of a concrete function with body.\n#[derive(Clone, Debug, Hash, PartialEq, Eq, SemanticObject)]\npub struct ConcreteFunctionWithBody {\n    pub generic_function: GenericFunctionWithBodyId,\n    pub generic_args: Vec<semantic::GenericArgumentId>,\n}\nimpl ConcreteFunctionWithBody {\n    pub fn function_with_body_id(&self) -> FunctionWithBodyId {\n        match self.generic_function {\n            GenericFunctionWithBodyId::Free(id) => FunctionWithBodyId::Free(id),\n            GenericFunctionWithBodyId::Impl(id) => FunctionWithBodyId::Impl(id.function),\n        }\n    }\n    pub fn substitution(&self, db: &dyn SemanticGroup) -> Maybe<GenericSubstitution> {\n        Ok(match self.generic_function {\n            GenericFunctionWithBodyId::Free(f) => {\n                GenericSubstitution::new(&db.free_function_generic_params(f)?, &self.generic_args)\n            }\n            GenericFunctionWithBodyId::Impl(f) => {\n                let concrete_impl = db.lookup_intern_concrete_impl(f.concrete_impl_id);\n                GenericSubstitution::new(\n                    &chain!(\n                        db.impl_function_generic_params(f.function)?,\n                        db.impl_def_generic_params(concrete_impl.impl_def_id)?\n                    )\n                    .collect_vec(),\n                    &chain!(\n                        self.generic_args.iter().copied(),\n                        concrete_impl.generic_args.iter().copied()\n                    )\n                    .collect_vec(),\n                )\n            }\n        })\n    }\n    pub fn from_no_generics_free(\n        db: &dyn SemanticGroup,\n        free_function_id: FreeFunctionId,\n    ) -> Option<Self> {\n        if !db.free_function_generic_params(free_function_id).ok()?.is_empty() {\n            return None;\n        }\n        Some(ConcreteFunctionWithBody {\n            generic_function: GenericFunctionWithBodyId::Free(free_function_id),\n            generic_args: vec![],\n        })\n    }\n    pub fn concrete(&self, db: &dyn SemanticGroup) -> Maybe<ConcreteFunction> {\n        Ok(ConcreteFunction {\n            generic_function: GenericFunctionId::from_generic_with_body(db, self.generic_function)?,\n            generic_args: self.generic_args.clone(),\n        })\n    }\n    pub fn function_id(&self, db: &dyn SemanticGroup) -> Maybe<FunctionId> {\n        Ok(db.intern_function(FunctionLongId { function: self.concrete(db)? }))\n    }\n    pub fn name(&self, db: &dyn SemanticGroup) -> SmolStr {\n        self.function_with_body_id().name(db.upcast())\n    }\n}\n\ndefine_short_id!(\n    ConcreteFunctionWithBodyId,\n    ConcreteFunctionWithBody,\n    SemanticGroup,\n    lookup_intern_concrete_function_with_body\n);\nsemantic_object_for_id!(\n    ConcreteFunctionWithBodyId,\n    lookup_intern_concrete_function_with_body,\n    intern_concrete_function_with_body,\n    ConcreteFunctionWithBody\n);\nimpl ConcreteFunctionWithBodyId {\n    fn get(&self, db: &dyn SemanticGroup) -> ConcreteFunctionWithBody {\n        db.lookup_intern_concrete_function_with_body(*self)\n    }\n    pub fn function_with_body_id(&self, db: &dyn SemanticGroup) -> FunctionWithBodyId {\n        self.get(db).function_with_body_id()\n    }\n    pub fn substitution(&self, db: &dyn SemanticGroup) -> Maybe<GenericSubstitution> {\n        self.get(db).substitution(db)\n    }\n    pub fn from_no_generics_free(\n        db: &dyn SemanticGroup,\n        free_function_id: FreeFunctionId,\n    ) -> Option<Self> {\n        Some(db.intern_concrete_function_with_body(\n            ConcreteFunctionWithBody::from_no_generics_free(db, free_function_id)?,\n        ))\n    }\n    pub fn concrete(&self, db: &dyn SemanticGroup) -> Maybe<ConcreteFunction> {\n        self.get(db).concrete(db)\n    }\n    pub fn function_id(&self, db: &dyn SemanticGroup) -> Maybe<FunctionId> {\n        self.get(db).function_id(db)\n    }\n    pub fn generic_function(&self, db: &dyn SemanticGroup) -> GenericFunctionWithBodyId {\n        self.get(db).generic_function\n    }\n    pub fn name(&self, db: &dyn SemanticGroup) -> SmolStr {\n        self.get(db).name(db)\n    }\n}\n\nimpl UnstableSalsaId for ConcreteFunctionWithBodyId {\n    fn get_internal_id(&self) -> &salsa::InternId {\n        &self.0\n    }\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, SemanticObject)]\npub struct ConcreteFunction {\n    pub generic_function: GenericFunctionId,\n    pub generic_args: Vec<semantic::GenericArgumentId>,\n}\nimpl ConcreteFunction {\n    pub fn get_body(&self, db: &dyn SemanticGroup) -> Maybe<Option<ConcreteFunctionWithBodyId>> {\n        let Some(generic_function) = GenericFunctionWithBodyId::from_generic(\n            db,\n            self.generic_function,\n        )? else {\n            return Ok(None);\n        };\n        Ok(Some(db.intern_concrete_function_with_body(ConcreteFunctionWithBody {\n            generic_function,\n            generic_args: self.generic_args.clone(),\n        })))\n    }\n}\nimpl DebugWithDb<dyn SemanticGroup> for ConcreteFunction {\n    fn fmt(\n        &self,\n        f: &mut std::fmt::Formatter<'_>,\n        db: &(dyn SemanticGroup + 'static),\n    ) -> std::fmt::Result {\n        write!(f, \"{}\", self.generic_function.format(db.upcast()))?;\n        if !self.generic_args.is_empty() {\n            write!(f, \"::<\")?;\n            for (i, arg) in self.generic_args.iter().enumerate() {\n                if i > 0 {\n                    write!(f, \", \")?;\n                }\n                write!(f, \"{:?}\", arg.debug(db))?;\n            }\n            write!(f, \">\")?;\n        }\n        Ok(())\n    }\n}\n\n#[derive(Clone, Debug, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct Signature {\n    pub params: Vec<semantic::Parameter>,\n    pub return_type: semantic::TypeId,\n    /// implicit parameters\n    pub implicits: Vec<semantic::TypeId>,\n    #[dont_rewrite]\n    pub panicable: bool,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub stable_ptr: ast::FunctionSignaturePtr,\n}\n\nimpl Signature {\n    pub fn from_ast(\n        diagnostics: &mut SemanticDiagnostics,\n        db: &dyn SemanticGroup,\n        resolver: &mut Resolver<'_>,\n        signature_syntax: &ast::FunctionSignature,\n        function_title_id: FunctionTitleId,\n        environment: &mut Environment,\n    ) -> Self {\n        let return_type =\n            function_signature_return_type(diagnostics, db, resolver, signature_syntax);\n        let params = function_signature_params(\n            diagnostics,\n            db,\n            resolver,\n            signature_syntax,\n            function_title_id,\n            environment,\n        );\n        let implicits =\n            function_signature_implicit_parameters(diagnostics, db, resolver, signature_syntax);\n        let panicable = match signature_syntax.optional_no_panic(db.upcast()) {\n            ast::OptionTerminalNoPanic::Empty(_) => true,\n            ast::OptionTerminalNoPanic::TerminalNoPanic(_) => false,\n        };\n        let stable_ptr = signature_syntax.stable_ptr();\n        semantic::Signature { params, return_type, implicits, panicable, stable_ptr }\n    }\n}\n\npub fn function_signature_return_type(\n    diagnostics: &mut SemanticDiagnostics,\n    db: &dyn SemanticGroup,\n    resolver: &mut Resolver<'_>,\n    sig: &ast::FunctionSignature,\n) -> semantic::TypeId {\n    let ty_syntax = match sig.ret_ty(db.upcast()) {\n        ast::OptionReturnTypeClause::Empty(_) => {\n            return unit_ty(db);\n        }\n        ast::OptionReturnTypeClause::ReturnTypeClause(ret_type_clause) => {\n            ret_type_clause.ty(db.upcast())\n        }\n    };\n    resolve_type(db, diagnostics, resolver, &ty_syntax)\n}\n\n/// Returns the implicit parameters of the given function signature's AST.\npub fn function_signature_implicit_parameters(\n    diagnostics: &mut SemanticDiagnostics,\n    db: &dyn SemanticGroup,\n    resolver: &mut Resolver<'_>,\n    sig: &ast::FunctionSignature,\n) -> Vec<semantic::TypeId> {\n    let syntax_db = db.upcast();\n\n    let ast_implicits = match sig.implicits_clause(syntax_db) {\n        ast::OptionImplicitsClause::Empty(_) => Vec::new(),\n        ast::OptionImplicitsClause::ImplicitsClause(implicits_clause) => {\n            implicits_clause.implicits(syntax_db).elements(syntax_db)\n        }\n    };\n\n    let mut implicits = Vec::new();\n    for implicit in ast_implicits {\n        implicits.push(resolve_type(\n            db,\n            diagnostics,\n            resolver,\n            &syntax::node::ast::Expr::Path(implicit),\n        ));\n    }\n    implicits\n}\n\n/// Returns the parameters of the given function signature's AST.\npub fn function_signature_params(\n    diagnostics: &mut SemanticDiagnostics,\n    db: &dyn SemanticGroup,\n    resolver: &mut Resolver<'_>,\n    sig: &ast::FunctionSignature,\n    function_title_id: FunctionTitleId,\n    env: &mut Environment,\n) -> Vec<semantic::Parameter> {\n    let syntax_db = db.upcast();\n    update_env_with_ast_params(\n        diagnostics,\n        db,\n        resolver,\n        &sig.parameters(syntax_db).elements(syntax_db),\n        function_title_id,\n        env,\n    )\n}\n\n/// Query implementation of [crate::db::SemanticGroup::function_title_signature].\npub fn function_title_signature(\n    db: &dyn SemanticGroup,\n    function_title_id: FunctionTitleId,\n) -> Maybe<Signature> {\n    match function_title_id {\n        FunctionTitleId::Free(free_function) => db.free_function_signature(free_function),\n        FunctionTitleId::Extern(extern_function) => db.extern_function_signature(extern_function),\n        FunctionTitleId::Trait(trait_function) => db.trait_function_signature(trait_function),\n        FunctionTitleId::Impl(impl_function) => db.impl_function_signature(impl_function),\n    }\n}\n/// Query implementation of [crate::db::SemanticGroup::function_title_generic_params].\npub fn function_title_generic_params(\n    db: &dyn SemanticGroup,\n    function_title_id: FunctionTitleId,\n) -> Maybe<Vec<semantic::GenericParam>> {\n    match function_title_id {\n        FunctionTitleId::Free(free_function) => db.free_function_generic_params(free_function),\n        FunctionTitleId::Extern(extern_function) => {\n            db.extern_function_declaration_generic_params(extern_function)\n        }\n        FunctionTitleId::Trait(trait_function) => db.trait_function_generic_params(trait_function),\n        FunctionTitleId::Impl(impl_function) => db.impl_function_generic_params(impl_function),\n    }\n}\n\n/// Query implementation of [crate::db::SemanticGroup::concrete_function_signature].\npub fn concrete_function_signature(\n    db: &dyn SemanticGroup,\n    function_id: FunctionId,\n) -> Maybe<Signature> {\n    let ConcreteFunction { generic_function, generic_args, .. } =\n        db.lookup_intern_function(function_id).function;\n    let generic_params = generic_function.generic_params(db)?;\n    let generic_signature = generic_function.generic_signature(db)?;\n    // TODO(spapini): When trait generics are supported, they need to be substituted\n    //   one by one, not together.\n    // Panic shouldn't occur since ConcreteFunction is assumed to be constructed correctly.\n    let substitution = GenericSubstitution::new(&generic_params, &generic_args);\n    SubstitutionRewriter { db, substitution: &substitution }.rewrite(generic_signature)\n}\n\n/// For a given list of AST parameters, returns the list of semantic parameters along with the\n/// corresponding environment.\nfn update_env_with_ast_params(\n    diagnostics: &mut SemanticDiagnostics,\n    db: &dyn SemanticGroup,\n    resolver: &mut Resolver<'_>,\n    ast_params: &[ast::Param],\n    function_title_id: FunctionTitleId,\n    env: &mut Environment,\n) -> Vec<semantic::Parameter> {\n    let mut semantic_params = Vec::new();\n    for ast_param in ast_params.iter() {\n        let semantic_param = ast_param_to_semantic(diagnostics, db, resolver, ast_param);\n\n        if env.add_param(diagnostics, semantic_param.clone(), ast_param, function_title_id).is_ok()\n        {\n            semantic_params.push(semantic_param);\n        }\n    }\n    semantic_params\n}\n\n/// Returns a semantic parameter (and its name) for the given AST parameter.\nfn ast_param_to_semantic(\n    diagnostics: &mut SemanticDiagnostics,\n    db: &dyn SemanticGroup,\n    resolver: &mut Resolver<'_>,\n    ast_param: &ast::Param,\n) -> semantic::Parameter {\n    let syntax_db = db.upcast();\n\n    let name = ast_param.name(syntax_db).text(syntax_db);\n\n    let id = db.intern_param(ParamLongId(resolver.module_file_id, ast_param.stable_ptr()));\n    let ty_syntax = ast_param.type_clause(syntax_db).ty(syntax_db);\n    let ty = resolve_type(db, diagnostics, resolver, &ty_syntax);\n\n    let mutability = modifiers::compute_mutability(\n        diagnostics,\n        syntax_db,\n        &ast_param.modifiers(syntax_db).elements(syntax_db),\n    );\n\n    semantic::Parameter {\n        id,\n        name,\n        ty,\n        mutability,\n        stable_ptr: ast_param.name(syntax_db).stable_ptr(),\n    }\n}\n\n// === Function Declaration ===\n\n#[derive(Clone, Debug, PartialEq, Eq, DebugWithDb)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct FunctionDeclarationData {\n    pub diagnostics: Diagnostics<SemanticDiagnostic>,\n    pub signature: semantic::Signature,\n    /// The environment induced by the function's signature.\n    pub environment: Environment,\n    pub generic_params: Vec<semantic::GenericParam>,\n    pub attributes: Vec<Attribute>,\n    pub resolved_lookback: Arc<ResolvedLookback>,\n    pub inline_config: InlineConfiguration,\n}\n\n#[derive(Debug, PartialEq, Eq, Clone)]\npub enum InlineConfiguration {\n    /// The user did not specify any inlining preferences.\n    None,\n    Always(Attribute),\n    Never(Attribute),\n}\n\n/// If a function with impl generic parameters is marked as '#[inline(always)]', raise a diagnostic.\npub fn forbid_inline_always_with_impl_generic_param(\n    diagnostics: &mut SemanticDiagnostics,\n    generic_params: &[GenericParam],\n    inline_config: &InlineConfiguration,\n) {\n    let has_impl_generic_param = generic_params.iter().any(|p| matches!(p, GenericParam::Impl(_)));\n    match &inline_config {\n        InlineConfiguration::Always(attr) if has_impl_generic_param => {\n            diagnostics.report_by_ptr(\n                attr.stable_ptr.untyped(),\n                SemanticDiagnosticKind::InlineAlwaysWithImplGenericArgNotAllowed,\n            );\n        }\n        _ => {}\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_debug::DebugWithDb;\nuse cairo_lang_defs::db::DefsGroup;\nuse cairo_lang_defs::ids::{\n    GenericItemId, GenericKind, GenericParamId, GenericParamLongId, ModuleFileId,\n};\nuse cairo_lang_diagnostics::Maybe;\nuse cairo_lang_proc_macros::{DebugWithDb, SemanticObject};\nuse cairo_lang_syntax as syntax;\nuse cairo_lang_syntax::node::{ast, TypedSyntaxNode};\nuse cairo_lang_utils::try_extract_matches;\n\nuse super::imp::{ImplHead, ImplId};\nuse crate::db::SemanticGroup;\nuse crate::diagnostic::{NotFoundItemType, SemanticDiagnosticKind, SemanticDiagnostics};\nuse crate::literals::LiteralId;\nuse crate::resolve_path::{ResolvedConcreteItem, Resolver};\nuse crate::types::TypeHead;\nuse crate::{ConcreteTraitId, TypeId};\n\n/// Generic argument.\n/// A value assigned to a generic parameter.\n/// May be a type, impl, constant, etc..\n#[derive(Copy, Clone, Debug, Hash, PartialEq, Eq, SemanticObject)]\npub enum GenericArgumentId {\n    Type(TypeId),\n    Literal(LiteralId),\n    Impl(ImplId), // TODO(spapini): impls and constants as generic values.\n}\nimpl GenericArgumentId {\n    pub fn kind(&self) -> GenericKind {\n        match self {\n            GenericArgumentId::Type(_) => GenericKind::Type,\n            GenericArgumentId::Literal(_) => GenericKind::Const,\n            GenericArgumentId::Impl(_) => GenericKind::Impl,\n        }\n    }\n    pub fn format(&self, db: &dyn SemanticGroup) -> String {\n        match self {\n            GenericArgumentId::Type(ty) => ty.format(db),\n            GenericArgumentId::Literal(lit) => lit.format(db),\n            GenericArgumentId::Impl(imp) => format!(\"{:?}\", imp.debug(db.elongate())),\n        }\n    }\n    /// Returns the [GenericArgumentHead] for a generic argument if available.\n    pub fn head(&self, db: &dyn SemanticGroup) -> Option<GenericArgumentHead> {\n        Some(match self {\n            GenericArgumentId::Type(ty) => GenericArgumentHead::Type(ty.head(db)?),\n            GenericArgumentId::Literal(_) => GenericArgumentHead::Const,\n            GenericArgumentId::Impl(impl_id) => GenericArgumentHead::Impl(impl_id.head(db)?),\n        })\n    }\n}\nimpl DebugWithDb<dyn SemanticGroup> for GenericArgumentId {\n    fn fmt(\n        &self,\n        f: &mut std::fmt::Formatter<'_>,\n        db: &(dyn SemanticGroup + 'static),\n    ) -> std::fmt::Result {\n        match self {\n            GenericArgumentId::Type(id) => write!(f, \"{:?}\", id.debug(db)),\n            GenericArgumentId::Literal(id) => write!(f, \"{:?}\", id.debug(db)),\n            GenericArgumentId::Impl(id) => write!(f, \"{:?}\", id.debug(db)),\n        }\n    }\n}\n\n/// Head of a generic argument. A non-param non-variable generic argument has a head, which\n/// represents the kind of the root node in its tree. This is used for caching queries for fast\n/// lookups when the generic argument is not completely inferred yet.\n#[derive(Clone, Debug, Hash, PartialEq, Eq)]\npub enum GenericArgumentHead {\n    Type(TypeHead),\n    Impl(ImplHead),\n    Const,\n}\n\n/// Generic parameter.\n#[derive(Copy, Clone, Debug, Hash, PartialEq, Eq, SemanticObject)]\npub enum GenericParam {\n    Type(GenericParamType),\n    // TODO(spapini): Add expression.\n    Const(GenericParamConst),\n    Impl(GenericParamImpl),\n}\nimpl GenericParam {\n    pub fn id(&self) -> GenericParamId {\n        match self {\n            GenericParam::Type(param) => param.id,\n            GenericParam::Const(param) => param.id,\n            GenericParam::Impl(param) => param.id,\n        }\n    }\n    pub fn kind(&self) -> GenericKind {\n        match self {\n            GenericParam::Type(_) => GenericKind::Type,\n            GenericParam::Const(_) => GenericKind::Const,\n            GenericParam::Impl(_) => GenericKind::Impl,\n        }\n    }\n    pub fn stable_ptr(&self, db: &dyn DefsGroup) -> ast::GenericParamPtr {\n        self.id().stable_ptr(db)\n    }\n}\nimpl DebugWithDb<dyn SemanticGroup> for GenericParam {\n    fn fmt(\n        &self,\n        f: &mut std::fmt::Formatter<'_>,\n        db: &(dyn SemanticGroup + 'static),\n    ) -> std::fmt::Result {\n        write!(f, \"{:?}\", self.id().debug(db))\n    }\n}\n\n#[derive(Copy, Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct GenericParamType {\n    pub id: GenericParamId,\n}\n#[derive(Copy, Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct GenericParamConst {\n    pub id: GenericParamId,\n}\n#[derive(Copy, Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct GenericParamImpl {\n    pub id: GenericParamId,\n    pub concrete_trait: Maybe<ConcreteTraitId>,\n}\n\npub fn generic_param_semantic(\n    db: &dyn SemanticGroup,\n    generic_param_id: GenericParamId,\n) -> Maybe<GenericParam> {\n    let generic_item = generic_param_id.generic_item(db.upcast());\n    let generic_params = generic_item_generic_params(db, generic_item)?;\n    Ok(*generic_params.iter().find(|generic_param| generic_param.id() == generic_param_id).unwrap())\n}\n\nfn generic_item_generic_params(\n    db: &dyn SemanticGroup,\n    generic_item: GenericItemId,\n) -> Maybe<Vec<GenericParam>> {\n    match generic_item {\n        GenericItemId::FreeFunc(id) => db.free_function_generic_params(id),\n        GenericItemId::ExternFunc(id) => db.extern_function_declaration_generic_params(id),\n        GenericItemId::TraitFunc(id) => db.trait_function_generic_params(id),\n        GenericItemId::ImplFunc(id) => db.impl_function_generic_params(id),\n        GenericItemId::Trait(id) => db.trait_generic_params(id),\n        GenericItemId::Impl(id) => db.impl_def_generic_params(id),\n        GenericItemId::Struct(id) => db.struct_generic_params(id),\n        GenericItemId::Enum(id) => db.enum_generic_params(id),\n        GenericItemId::ExternType(id) => db.extern_type_declaration_generic_params(id),\n        GenericItemId::TypeAlias(id) => db.type_alias_generic_params(id),\n    }\n}\n\n/// Returns the parameters of the given function signature's AST.\npub fn semantic_generic_params(\n    db: &dyn SemanticGroup,\n    diagnostics: &mut SemanticDiagnostics,\n    resolver: &mut Resolver<'_>,\n    module_file_id: ModuleFileId,\n    generic_params: &ast::OptionWrappedGenericParamList,\n) -> Maybe<Vec<GenericParam>> {\n    let syntax_db = db.upcast();\n\n    let res = match generic_params {\n        syntax::node::ast::OptionWrappedGenericParamList::Empty(_) => vec![],\n        syntax::node::ast::OptionWrappedGenericParamList::WrappedGenericParamList(syntax) => syntax\n            .generic_params(syntax_db)\n            .elements(syntax_db)\n            .iter()\n            .map(|param_syntax| {\n                let param_semantic = semantic_from_generic_param_ast(\n                    db,\n                    resolver,\n                    diagnostics,\n                    module_file_id,\n                    param_syntax,\n                );\n                resolver.add_generic_param(param_semantic);\n                param_semantic\n            })\n            .collect(),\n    };\n\n    if let Some((stable_ptr, inference_err)) = resolver.inference.finalize() {\n        return Err(inference_err.report(diagnostics, stable_ptr));\n    }\n    Ok(res)\n}\n\n/// Computes the semantic model of a generic parameter give its ast.\nfn semantic_from_generic_param_ast(\n    db: &dyn SemanticGroup,\n    resolver: &mut Resolver<'_>,\n    diagnostics: &mut SemanticDiagnostics,\n    module_file_id: ModuleFileId,\n    param_syntax: &ast::GenericParam,\n) -> GenericParam {\n    let id = db.intern_generic_param(GenericParamLongId(module_file_id, param_syntax.stable_ptr()));\n    match param_syntax {\n        ast::GenericParam::Type(_) => GenericParam::Type(GenericParamType { id }),\n        ast::GenericParam::Const(_) => GenericParam::Const(GenericParamConst { id }),\n        ast::GenericParam::Impl(syntax) => {\n            let path_syntax = syntax.trait_path(db.upcast());\n            let concrete_trait = resolver\n                .resolve_concrete_path(diagnostics, &path_syntax, NotFoundItemType::Trait)\n                .and_then(|resolved_item| {\n                    try_extract_matches!(resolved_item, ResolvedConcreteItem::Trait).ok_or_else(\n                        || diagnostics.report(&path_syntax, SemanticDiagnosticKind::UnknownTrait),\n                    )\n                });\n            GenericParam::Impl(GenericParamImpl { id, concrete_trait })\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashSet;\nuse std::sync::Arc;\nuse std::vec;\n\nuse cairo_lang_debug::DebugWithDb;\nuse cairo_lang_defs::ids::{\n    FunctionTitleId, GenericParamId, ImplDefId, ImplFunctionId, ImplFunctionLongId,\n    LanguageElementId, ModuleId, TopLevelLanguageElementId, TraitFunctionId, TraitId,\n};\nuse cairo_lang_diagnostics::{\n    skip_diagnostic, Diagnostics, DiagnosticsBuilder, Maybe, ToMaybe, ToOption,\n};\nuse cairo_lang_proc_macros::{DebugWithDb, SemanticObject};\nuse cairo_lang_syntax as syntax;\nuse cairo_lang_syntax::node::ast::{self, Item, MaybeImplBody, OptionReturnTypeClause};\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::ids::SyntaxStablePtrId;\nuse cairo_lang_syntax::node::TypedSyntaxNode;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse cairo_lang_utils::ordered_hash_set::OrderedHashSet;\nuse cairo_lang_utils::unordered_hash_map::UnorderedHashMap;\nuse cairo_lang_utils::{define_short_id, extract_matches, try_extract_matches};\nuse itertools::{chain, izip, Itertools};\nuse smol_str::SmolStr;\n\nuse super::attribute::{ast_attributes_to_semantic, Attribute};\nuse super::enm::SemanticEnumEx;\nuse super::function_with_body::{get_inline_config, FunctionBody, FunctionBodyData};\nuse super::functions::{\n    forbid_inline_always_with_impl_generic_param, FunctionDeclarationData, InlineConfiguration,\n};\nuse super::generics::{semantic_generic_params, GenericArgumentHead};\nuse super::structure::SemanticStructEx;\nuse super::trt::ConcreteTraitGenericFunctionId;\nuse crate::corelib::{copy_trait, core_module, drop_trait};\nuse crate::db::SemanticGroup;\nuse crate::diagnostic::SemanticDiagnosticKind::{self, *};\nuse crate::diagnostic::{NotFoundItemType, SemanticDiagnostics};\nuse crate::expr::compute::{compute_root_expr, ComputationContext, Environment};\nuse crate::expr::inference::{ImplVar, Inference, InferenceResult};\nuse crate::items::us::SemanticUseEx;\nuse crate::resolve_path::{ResolvedConcreteItem, ResolvedGenericItem, ResolvedLookback, Resolver};\nuse crate::substitution::{GenericSubstitution, SemanticRewriter, SubstitutionRewriter};\nuse crate::{\n    semantic, semantic_object_for_id, ConcreteTraitId, ConcreteTraitLongId, Expr, FunctionId,\n    GenericArgumentId, GenericParam, Mutability, SemanticDiagnostic, TypeId, TypeLongId,\n};\n\n#[cfg(test)]\n#[path = \"imp_test.rs\"]\nmod test;\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, SemanticObject)]\npub struct ConcreteImplLongId {\n    pub impl_def_id: ImplDefId,\n    pub generic_args: Vec<GenericArgumentId>,\n}\ndefine_short_id!(ConcreteImplId, ConcreteImplLongId, SemanticGroup, lookup_intern_concrete_impl);\nsemantic_object_for_id!(\n    ConcreteImplId,\n    lookup_intern_concrete_impl,\n    intern_concrete_impl,\n    ConcreteImplLongId\n);\nimpl DebugWithDb<dyn SemanticGroup> for ConcreteImplLongId {\n    fn fmt(\n        &self,\n        f: &mut std::fmt::Formatter<'_>,\n        db: &(dyn SemanticGroup + 'static),\n    ) -> std::fmt::Result {\n        write!(f, \"{}\", self.impl_def_id.full_path(db.upcast()))?;\n        if !self.generic_args.is_empty() {\n            write!(f, \"::<\")?;\n            for (i, arg) in self.generic_args.iter().enumerate() {\n                if i > 0 {\n                    write!(f, \", \")?;\n                }\n                write!(f, \"{:?}\", arg.debug(db))?;\n            }\n            write!(f, \">\")?;\n        }\n        Ok(())\n    }\n}\nimpl ConcreteImplId {\n    pub fn impl_def_id(&self, db: &dyn SemanticGroup) -> ImplDefId {\n        db.lookup_intern_concrete_impl(*self).impl_def_id\n    }\n    pub fn get_impl_function(\n        &self,\n        db: &dyn SemanticGroup,\n        function: TraitFunctionId,\n    ) -> Maybe<Option<ImplFunctionId>> {\n        db.impl_function_by_trait_function(self.impl_def_id(db), function)\n    }\n    pub fn name(&self, db: &dyn SemanticGroup) -> SmolStr {\n        self.impl_def_id(db).name(db.upcast())\n    }\n}\n\n/// Represents a \"callee\" impl that can be referred to in the code.\n/// Traits should be resolved to this.\n#[derive(Copy, Clone, Debug, Hash, PartialEq, Eq, SemanticObject)]\npub enum ImplId {\n    Concrete(ConcreteImplId),\n    GenericParameter(GenericParamId),\n    ImplVar(ImplVar),\n}\nimpl ImplId {\n    /// Returns the [ImplHead] of an impl if available.\n    pub fn head(&self, db: &dyn SemanticGroup) -> Option<ImplHead> {\n        Some(match self {\n            ImplId::Concrete(concrete) => ImplHead::Concrete(concrete.impl_def_id(db)),\n            ImplId::GenericParameter(_) | ImplId::ImplVar(_) => return None,\n        })\n    }\n    pub fn name(&self, db: &dyn SemanticGroup) -> SmolStr {\n        match self {\n            ImplId::Concrete(concrete_impl) => concrete_impl.name(db),\n            ImplId::GenericParameter(generic_param_impl) => generic_param_impl.name(db.upcast()),\n            ImplId::ImplVar(var) => format!(\"{var:?}\").into(),\n        }\n    }\n}\nimpl DebugWithDb<dyn SemanticGroup> for ImplId {\n    fn fmt(\n        &self,\n        f: &mut std::fmt::Formatter<'_>,\n        db: &(dyn SemanticGroup + 'static),\n    ) -> std::fmt::Result {\n        match self {\n            ImplId::Concrete(concrete_impl_id) => write!(f, \"{:?}\", concrete_impl_id.debug(db)),\n            ImplId::GenericParameter(param) => write!(f, \"{:?}\", param.debug(db)),\n            ImplId::ImplVar(var) => write!(f, \"?{}\", var.id),\n        }\n    }\n}\n\n/// Head of an impl. A non-param non-variable impl has a head, which represents the kind of the root\n/// node in its tree representation. This is used for caching queries for fast lookups when the impl\n/// is not completely inferred yet.\n#[derive(Clone, Debug, Hash, PartialEq, Eq)]\npub enum ImplHead {\n    Concrete(ImplDefId),\n}\n\n#[derive(Clone, Debug, PartialEq, Eq, DebugWithDb)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct ImplDeclarationData {\n    diagnostics: Diagnostics<SemanticDiagnostic>,\n    generic_params: Vec<semantic::GenericParam>,\n    /// The concrete trait this impl implements, or Err if cannot be resolved.\n    concrete_trait: Maybe<ConcreteTraitId>,\n    attributes: Vec<Attribute>,\n    resolved_lookback: Arc<ResolvedLookback>,\n}\n\nimpl ImplDeclarationData {\n    /// Returns Maybe::Err if a cycle is detected here.\n    // TODO(orizi): Remove this function when cycle validation is not required through a type's\n    // field.\n    pub fn check_no_cycle(&self) -> Maybe<()> {\n        self.concrete_trait?;\n        Ok(())\n    }\n}\n\n/// Query implementation of [crate::db::SemanticGroup::impl_semantic_declaration_diagnostics].\npub fn impl_semantic_declaration_diagnostics(\n    db: &dyn SemanticGroup,\n    impl_def_id: ImplDefId,\n) -> Diagnostics<SemanticDiagnostic> {\n    db.priv_impl_declaration_data(impl_def_id).map(|data| data.diagnostics).unwrap_or_default()\n}\n\n/// Query implementation of [crate::db::SemanticGroup::impl_def_generic_params].\npub fn impl_def_generic_params(\n    db: &dyn SemanticGroup,\n    impl_def_id: ImplDefId,\n) -> Maybe<Vec<semantic::GenericParam>> {\n    Ok(db.priv_impl_declaration_data(impl_def_id)?.generic_params)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::impl_def_resolved_lookback].\npub fn impl_def_resolved_lookback(\n    db: &dyn SemanticGroup,\n    impl_def_id: ImplDefId,\n) -> Maybe<Arc<ResolvedLookback>> {\n    Ok(db.priv_impl_declaration_data(impl_def_id)?.resolved_lookback)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::impl_def_concrete_trait].\npub fn impl_def_concrete_trait(\n    db: &dyn SemanticGroup,\n    impl_def_id: ImplDefId,\n) -> Maybe<ConcreteTraitId> {\n    db.priv_impl_declaration_data(impl_def_id)?.concrete_trait\n}\n\n/// Query implementation of [crate::db::SemanticGroup::impl_def_concrete_trait].\npub fn impl_concrete_trait(db: &dyn SemanticGroup, impl_id: ImplId) -> Maybe<ConcreteTraitId> {\n    match impl_id {\n        ImplId::Concrete(concrete_impl_id) => {\n            let long_impl = db.lookup_intern_concrete_impl(concrete_impl_id);\n            let substitution = GenericSubstitution::new(\n                &db.impl_def_generic_params(long_impl.impl_def_id)?,\n                &long_impl.generic_args,\n            );\n\n            let impl_concrete_trait_id = db.impl_def_concrete_trait(long_impl.impl_def_id)?;\n            SubstitutionRewriter { db, substitution: &substitution }.rewrite(impl_concrete_trait_id)\n        }\n        ImplId::GenericParameter(param) => {\n            let param_impl =\n                extract_matches!(db.generic_param_semantic(param)?, GenericParam::Impl);\n            param_impl.concrete_trait\n        }\n        ImplId::ImplVar(var) => Ok(var.concrete_trait_id),\n    }\n}\n\n/// Cycle handling for [crate::db::SemanticGroup::priv_impl_declaration_data].\npub fn priv_impl_declaration_data_cycle(\n    db: &dyn SemanticGroup,\n    _cycle: &[String],\n    impl_def_id: &ImplDefId,\n) -> Maybe<ImplDeclarationData> {\n    priv_impl_declaration_data_inner(db, *impl_def_id, false)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::priv_impl_declaration_data].\npub fn priv_impl_declaration_data(\n    db: &dyn SemanticGroup,\n    impl_def_id: ImplDefId,\n) -> Maybe<ImplDeclarationData> {\n    priv_impl_declaration_data_inner(db, impl_def_id, true)\n}\n\n/// Shared code for the query and cycle handling.\n/// The cycle handling logic needs to pass resolve_trait=false to prevent the cycle.\npub fn priv_impl_declaration_data_inner(\n    db: &dyn SemanticGroup,\n    impl_def_id: ImplDefId,\n    resolve_trait: bool,\n) -> Maybe<ImplDeclarationData> {\n    let module_file_id = impl_def_id.module_file_id(db.upcast());\n    let mut diagnostics = SemanticDiagnostics::new(module_file_id);\n\n    // TODO(spapini): when code changes in a file, all the AST items change (as they contain a path\n    // to the green root that changes. Once ASTs are rooted on items, use a selector that picks only\n    // the item instead of all the module data.\n    let module_impls = db.module_impls(module_file_id.0)?;\n    let syntax_db = db.upcast();\n    let impl_ast = module_impls.get(&impl_def_id).to_maybe()?;\n\n    // Generic params.\n    let mut resolver = Resolver::new_with_inference(db, module_file_id);\n    let generic_params = semantic_generic_params(\n        db,\n        &mut diagnostics,\n        &mut resolver,\n        module_file_id,\n        &impl_ast.generic_params(syntax_db),\n    )?;\n\n    let trait_path_syntax = impl_ast.trait_path(syntax_db);\n\n    let concrete_trait = if resolve_trait {\n        resolver\n            .resolve_concrete_path(&mut diagnostics, &trait_path_syntax, NotFoundItemType::Trait)\n            .ok()\n            .and_then(|concrete_item| {\n                try_extract_matches!(concrete_item, ResolvedConcreteItem::Trait)\n            })\n    } else {\n        None\n    }\n    .ok_or_else(|| diagnostics.report(&trait_path_syntax, NotATrait));\n\n    let attributes = ast_attributes_to_semantic(syntax_db, impl_ast.attributes(syntax_db));\n    let resolved_lookback = Arc::new(resolver.lookback);\n    Ok(ImplDeclarationData {\n        diagnostics: diagnostics.build(),\n        generic_params,\n        concrete_trait,\n        attributes,\n        resolved_lookback,\n    })\n}\n\n#[derive(Clone, Debug, PartialEq, Eq, DebugWithDb)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct ImplDefinitionData {\n    diagnostics: Diagnostics<SemanticDiagnostic>,\n    function_asts: OrderedHashMap<ImplFunctionId, ast::FunctionWithBody>,\n}\n\n/// Query implementation of [crate::db::SemanticGroup::impl_semantic_definition_diagnostics].\npub fn impl_semantic_definition_diagnostics(\n    db: &dyn SemanticGroup,\n    impl_def_id: ImplDefId,\n) -> Diagnostics<SemanticDiagnostic> {\n    let mut diagnostics = DiagnosticsBuilder::default();\n\n    let Ok(data) = db.priv_impl_definition_data(impl_def_id) else {\n        return Diagnostics::default();\n    };\n\n    diagnostics.extend(data.diagnostics);\n    for impl_function_id in data.function_asts.keys() {\n        diagnostics.extend(db.impl_function_declaration_diagnostics(*impl_function_id));\n        diagnostics.extend(db.impl_function_body_diagnostics(*impl_function_id));\n    }\n\n    diagnostics.build()\n}\n\n/// An helper function to report diagnostics of items in an impl (used in\n/// priv_impl_definition_data).\nfn report_invalid_impl_item<Terminal: syntax::node::Terminal>(\n    syntax_db: &dyn SyntaxGroup,\n    diagnostics: &mut SemanticDiagnostics,\n    kw_terminal: Terminal,\n) {\n    diagnostics.report_by_ptr(\n        kw_terminal.as_syntax_node().stable_ptr(),\n        InvalidImplItem { item_kw: kw_terminal.text(syntax_db) },\n    );\n}\n\n/// Query implementation of [crate::db::SemanticGroup::priv_impl_definition_data].\npub fn priv_impl_definition_data(\n    db: &dyn SemanticGroup,\n    impl_def_id: ImplDefId,\n) -> Maybe<ImplDefinitionData> {\n    let defs_db = db.upcast();\n    let syntax_db = db.upcast();\n\n    let module_file_id = impl_def_id.module_file_id(defs_db);\n    let mut diagnostics = SemanticDiagnostics::new(module_file_id);\n\n    let declaration_data = db.priv_impl_declaration_data(impl_def_id)?;\n    let concrete_trait = declaration_data.concrete_trait?;\n\n    let module_impls = db.module_impls(module_file_id.0)?;\n    let impl_ast = module_impls.get(&impl_def_id).to_maybe()?;\n\n    let lookup_context = ImplLookupContext {\n        module_id: module_file_id.0,\n        extra_modules: Default::default(),\n        generic_params: declaration_data.generic_params,\n    };\n    check_special_impls(\n        db,\n        &mut diagnostics,\n        lookup_context,\n        concrete_trait,\n        impl_ast.stable_ptr().untyped(),\n    )\n    // Ignore the result.\n    .ok();\n\n    // TODO(yuval): verify that all functions of `concrete_trait` appear in this impl.\n\n    let mut function_asts = OrderedHashMap::default();\n    let mut impl_item_names = OrderedHashSet::default();\n\n    if let MaybeImplBody::Some(body) = impl_ast.body(syntax_db) {\n        for item in body.items(syntax_db).elements(syntax_db) {\n            match item {\n                Item::Constant(constant) => report_invalid_impl_item(\n                    syntax_db,\n                    &mut diagnostics,\n                    constant.const_kw(syntax_db),\n                ),\n                Item::Module(module) => report_invalid_impl_item(\n                    syntax_db,\n                    &mut diagnostics,\n                    module.module_kw(syntax_db),\n                ),\n\n                Item::Use(use_item) => report_invalid_impl_item(\n                    syntax_db,\n                    &mut diagnostics,\n                    use_item.use_kw(syntax_db),\n                ),\n                Item::ExternFunction(extern_func) => report_invalid_impl_item(\n                    syntax_db,\n                    &mut diagnostics,\n                    extern_func.extern_kw(syntax_db),\n                ),\n                Item::ExternType(extern_type) => report_invalid_impl_item(\n                    syntax_db,\n                    &mut diagnostics,\n                    extern_type.extern_kw(syntax_db),\n                ),\n                Item::Trait(trt) => {\n                    report_invalid_impl_item(syntax_db, &mut diagnostics, trt.trait_kw(syntax_db))\n                }\n                Item::Impl(imp) => {\n                    report_invalid_impl_item(syntax_db, &mut diagnostics, imp.impl_kw(syntax_db))\n                }\n                Item::Struct(structure) => report_invalid_impl_item(\n                    syntax_db,\n                    &mut diagnostics,\n                    structure.struct_kw(syntax_db),\n                ),\n                Item::Enum(enm) => {\n                    report_invalid_impl_item(syntax_db, &mut diagnostics, enm.enum_kw(syntax_db))\n                }\n                Item::TypeAlias(ty) => {\n                    report_invalid_impl_item(syntax_db, &mut diagnostics, ty.type_kw(syntax_db))\n                }\n                Item::FreeFunction(func) => {\n                    let impl_function_id = db.intern_impl_function(ImplFunctionLongId(\n                        module_file_id,\n                        func.stable_ptr(),\n                    ));\n                    function_asts.insert(impl_function_id, func);\n                    impl_item_names.insert(impl_function_id.name(defs_db));\n                }\n            }\n        }\n    }\n\n    // It is later verified that all items in this impl match items from `concrete_trait`.\n    // To ensure exact match (up to trait functions with default implementation), it is sufficient\n    // to verify here that all items in `concrete_trait` appear in this impl.\n    // TODO(yuval): Once default implementation of trait functions is supported, filter such\n    // functions out.\n    let trait_item_names = db\n        .trait_functions(db.lookup_intern_concrete_trait(concrete_trait).trait_id)?\n        .into_keys()\n        .collect::<OrderedHashSet<_>>();\n    let missing_items_in_impl =\n        trait_item_names.difference(&impl_item_names).cloned().collect::<Vec<_>>();\n    if !missing_items_in_impl.is_empty() {\n        diagnostics.report(\n            // TODO(yuval): change this to point to impl declaration (need to add ImplDeclaration\n            // in cairo_spec).\n            &impl_ast.name(syntax_db),\n            SemanticDiagnosticKind::MissingItemsInImpl { item_names: missing_items_in_impl },\n        );\n    }\n\n    Ok(ImplDefinitionData { diagnostics: diagnostics.build(), function_asts })\n}\n\n/// Query implementation of [crate::db::SemanticGroup::impl_functions].\npub fn impl_functions(\n    db: &dyn SemanticGroup,\n    impl_def_id: ImplDefId,\n) -> Maybe<OrderedHashMap<SmolStr, ImplFunctionId>> {\n    Ok(db\n        .priv_impl_definition_data(impl_def_id)?\n        .function_asts\n        .keys()\n        .map(|function_id| {\n            let function_long_id = db.lookup_intern_impl_function(*function_id);\n            (function_long_id.name(db.upcast()), *function_id)\n        })\n        .collect())\n}\n\n/// Query implementation of [crate::db::SemanticGroup::impl_function_by_trait_function].\npub fn impl_function_by_trait_function(\n    db: &dyn SemanticGroup,\n    impl_def_id: ImplDefId,\n    trait_function_id: TraitFunctionId,\n) -> Maybe<Option<ImplFunctionId>> {\n    let defs_db = db.upcast();\n    let name = trait_function_id.name(defs_db);\n    for impl_function_id in db.priv_impl_definition_data(impl_def_id)?.function_asts.keys() {\n        if db.lookup_intern_impl_function(*impl_function_id).name(defs_db) == name {\n            return Ok(Some(*impl_function_id));\n        }\n    }\n    Ok(None)\n}\n\n/// Handle special cases such as Copy and Drop checking.\nfn check_special_impls(\n    db: &dyn SemanticGroup,\n    diagnostics: &mut SemanticDiagnostics,\n    lookup_context: ImplLookupContext,\n    concrete_trait: ConcreteTraitId,\n    stable_ptr: SyntaxStablePtrId,\n) -> Maybe<()> {\n    let ConcreteTraitLongId { trait_id, generic_args } =\n        db.lookup_intern_concrete_trait(concrete_trait);\n    let copy = copy_trait(db);\n    let drop = drop_trait(db);\n\n    if trait_id == copy {\n        let tys = get_inner_types(db, extract_matches!(generic_args[0], GenericArgumentId::Type))?;\n        if let Some(inference_error) = tys\n            .into_iter()\n            .filter_map(|ty| db.type_info(lookup_context.clone(), ty).to_option())\n            .flat_map(|info| info.duplicatable.err())\n            .next()\n        {\n            return Err(\n                diagnostics.report_by_ptr(stable_ptr, InvalidCopyTraitImpl { inference_error })\n            );\n        }\n    }\n    if trait_id == drop {\n        let tys = get_inner_types(db, extract_matches!(generic_args[0], GenericArgumentId::Type))?;\n        if let Some(inference_error) = tys\n            .into_iter()\n            .filter_map(|ty| db.type_info(lookup_context.clone(), ty).to_option())\n            .flat_map(|info| info.droppable.err())\n            .next()\n        {\n            return Err(\n                diagnostics.report_by_ptr(stable_ptr, InvalidDropTraitImpl { inference_error })\n            );\n        }\n    }\n\n    Ok(())\n}\n\n/// Retrieves all the inner types (members of a struct / tuple or variants of an enum).\n/// These are the types that are required to implement some trait,\n/// in order for the original type to be able to implement this trait.\nfn get_inner_types(db: &dyn SemanticGroup, ty: TypeId) -> Maybe<Vec<TypeId>> {\n    Ok(match db.lookup_intern_type(ty) {\n        TypeLongId::Concrete(concrete_type_id) => {\n            // Look for Copy and Drop trait in the defining module.\n            match concrete_type_id {\n                crate::ConcreteTypeId::Struct(concrete_struct_id) => db\n                    .concrete_struct_members(concrete_struct_id)?\n                    .values()\n                    .map(|member| member.ty)\n                    .collect(),\n                crate::ConcreteTypeId::Enum(concrete_enum_id) => db\n                    .concrete_enum_variants(concrete_enum_id)?\n                    .into_iter()\n                    .map(|variant| variant.ty)\n                    .collect(),\n                crate::ConcreteTypeId::Extern(_) => vec![],\n            }\n        }\n        TypeLongId::Tuple(tys) => tys,\n        TypeLongId::Snapshot(_) => vec![],\n        TypeLongId::GenericParameter(_) => {\n            return Err(skip_diagnostic());\n        }\n        TypeLongId::Var(_) => panic!(\"Types should be fully resolved at this point.\"),\n        TypeLongId::Missing(diag_added) => {\n            return Err(diag_added);\n        }\n    })\n}\n\n/// A filter for trait lookup that is not based on current inference state. This is\n/// used for caching queries.\n#[derive(Clone, Debug, Hash, PartialEq, Eq)]\npub struct TraitFilter {\n    trait_id: TraitId,\n    /// The filter on the generic arguments.\n    generics_filter: GenericsHeadFilter,\n}\n\n/// A lookup filter on generic arguments that is not based on current inference state.\n/// This is used for caching queries.\n#[derive(Clone, Debug, Hash, PartialEq, Eq)]\npub enum GenericsHeadFilter {\n    /// No filter is applied. When nothing is known about th generics, this will lead to a\n    /// wider search.\n    NoFilter,\n    /// Generics exists and the first generic parameter has a filter.\n    /// This is usually enough to considerably reduce the number of searched items.\n    FirstGenericFilter(GenericArgumentHead),\n    /// Generics must not exist.\n    NoGenerics,\n}\n\n/// Query implementation of [crate::db::SemanticGroup::module_impl_ids_for_trait_info].\npub fn module_impl_ids_for_trait_info(\n    db: &dyn SemanticGroup,\n    module_id: ModuleId,\n    trait_filter: TraitFilter,\n) -> Maybe<Vec<ImplDefId>> {\n    let mut res = Vec::new();\n\n    let mut impls = db.module_impls_ids(module_id)?;\n    for use_id in db.module_uses_ids(module_id)? {\n        if let Ok(ResolvedGenericItem::Impl(impl_def_id)) = db.use_resolved_item(use_id) {\n            impls.push(impl_def_id);\n        }\n    }\n    for impl_def_id in impls {\n        if let Ok(true) = impl_fits_trait_filter(db, impl_def_id, &trait_filter) {\n            res.push(impl_def_id);\n        }\n    }\n\n    Ok(res)\n}\n\n/// Checks whether an [ImplDefId] passes a [TraitFilter].\nfn impl_fits_trait_filter(\n    db: &dyn SemanticGroup,\n    impl_def_id: ImplDefId,\n    trait_filter: &TraitFilter,\n) -> Maybe<bool> {\n    let impl_def_concrete_trait_id = db.impl_def_concrete_trait(impl_def_id)?;\n    if trait_filter.trait_id != impl_def_concrete_trait_id.trait_id(db) {\n        return Ok(false);\n    }\n    let generic_args = impl_def_concrete_trait_id.generic_args(db);\n    let first_generic = generic_args.first();\n    Ok(match &trait_filter.generics_filter {\n        GenericsHeadFilter::NoFilter => true,\n        GenericsHeadFilter::FirstGenericFilter(constraint_head) => {\n            let Some(first_generic) = first_generic else {\n                return Ok(false);\n            };\n            let Some(first_generic_head) = first_generic.head(db) else {\n                return Ok(true);\n            };\n            &first_generic_head == constraint_head\n        }\n        GenericsHeadFilter::NoGenerics => first_generic.is_none(),\n    })\n}\n\n/// Finds implementations for a concrete trait in a module.\nfn find_impls_at_module(\n    db: &dyn SemanticGroup,\n    inference: &Inference<'_>,\n    lookup_context: &ImplLookupContext,\n    module_id: ModuleId,\n    concrete_trait_id: ConcreteTraitId,\n    stable_ptr: SyntaxStablePtrId,\n) -> Maybe<Vec<UninferredImpl>> {\n    let mut res = Vec::new();\n\n    let trait_id = concrete_trait_id.trait_id(db);\n    let first_generic_filter = match concrete_trait_id.generic_args(db).first() {\n        Some(first_generic) => match first_generic.head(db) {\n            Some(head) => GenericsHeadFilter::FirstGenericFilter(head),\n            None => GenericsHeadFilter::NoFilter,\n        },\n        None => GenericsHeadFilter::NoGenerics,\n    };\n\n    let impls = db.module_impl_ids_for_trait_info(\n        module_id,\n        TraitFilter { trait_id, generics_filter: first_generic_filter },\n    )?;\n\n    for impl_def_id in impls {\n        if !inference.can_impl_trait(impl_def_id, concrete_trait_id, lookup_context, stable_ptr) {\n            continue;\n        }\n        res.push(UninferredImpl::Def(impl_def_id));\n    }\n    Ok(res)\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct ImplLookupContext {\n    pub module_id: ModuleId,\n    // TODO(spapini): Make a hash set.\n    pub extra_modules: Vec<ModuleId>,\n    pub generic_params: Vec<semantic::GenericParam>,\n}\n\n/// An candidate impl for later inference.\n#[derive(Copy, Clone, Debug, Hash, PartialEq, Eq, SemanticObject)]\npub enum UninferredImpl {\n    Def(ImplDefId),\n    GenericParam(GenericParamId),\n}\nimpl DebugWithDb<dyn SemanticGroup> for UninferredImpl {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>, db: &dyn SemanticGroup) -> std::fmt::Result {\n        match self {\n            UninferredImpl::Def(impl_def) => write!(f, \"{:?}\", impl_def.full_path(db.upcast())),\n            UninferredImpl::GenericParam(param) => {\n                write!(f, \"generic param {}\", param.name(db.upcast()))\n            }\n        }\n    }\n}\n\n/// Finds all the implementations of a concrete trait, in a specific lookup context.\npub fn find_possible_impls_at_context(\n    db: &dyn SemanticGroup,\n    inference: &Inference<'_>,\n    lookup_context: &ImplLookupContext,\n    concrete_trait_id: ConcreteTraitId,\n    stable_ptr: SyntaxStablePtrId,\n) -> Maybe<OrderedHashSet<UninferredImpl>> {\n    let mut res = OrderedHashSet::default();\n    for generic_param in &lookup_context.generic_params {\n        let GenericParam::Impl(param) = generic_param else {continue};\n        let Ok(imp_concrete_trait_id) = param.concrete_trait else {continue};\n\n        let mut temp_inference = inference.clone();\n        if temp_inference.conform_traits(concrete_trait_id, imp_concrete_trait_id).is_err() {\n            continue;\n        }\n        res.insert(UninferredImpl::GenericParam(generic_param.id()));\n    }\n    res.extend(find_impls_at_module(\n        db,\n        inference,\n        lookup_context,\n        lookup_context.module_id,\n        concrete_trait_id,\n        stable_ptr,\n    )?);\n    let core_module = core_module(db);\n    for module_id in chain!(lookup_context.extra_modules.iter(), [&core_module]) {\n        if let Ok(imps) = find_impls_at_module(\n            db,\n            inference,\n            lookup_context,\n            *module_id,\n            concrete_trait_id,\n            stable_ptr,\n        ) {\n            res.extend(imps);\n        }\n    }\n    for submodule in db.module_submodules_ids(lookup_context.module_id)? {\n        res.extend(find_impls_at_module(\n            db,\n            inference,\n            lookup_context,\n            ModuleId::Submodule(submodule),\n            concrete_trait_id,\n            stable_ptr,\n        )?);\n    }\n    for use_id in db.module_uses_ids(lookup_context.module_id)? {\n        if let Ok(ResolvedGenericItem::Module(submodule)) = db.use_resolved_item(use_id) {\n            res.extend(find_impls_at_module(\n                db,\n                inference,\n                lookup_context,\n                submodule,\n                concrete_trait_id,\n                stable_ptr,\n            )?);\n        }\n    }\n    Ok(res)\n}\n\n/// Infers a unique impl for a trait. If more or less than one found, fails and emits diagnostics.\npub fn infer_impl_at_context(\n    db: &dyn SemanticGroup,\n    diagnostics: &mut SemanticDiagnostics,\n    inference: &mut Inference<'_>,\n    lookup_context: &ImplLookupContext,\n    concrete_trait_id: ConcreteTraitId,\n    stable_ptr: SyntaxStablePtrId,\n) -> Maybe<ImplId> {\n    let uninferred_impl_id = match &find_possible_impls_at_context(\n        db,\n        inference,\n        lookup_context,\n        concrete_trait_id,\n        stable_ptr,\n    )?\n    .into_iter()\n    .collect_vec()[..]\n    {\n        &[] => {\n            let generic_args = db.lookup_intern_concrete_trait(concrete_trait_id).generic_args;\n            let generic_args = inference.rewrite(generic_args.clone()).unwrap_or(generic_args);\n            return Err(diagnostics.report_by_ptr(\n                stable_ptr,\n                NoImplementationOfTrait { concrete_trait_id, generic_args },\n            ));\n        }\n        &[uninferred_impl_id] => uninferred_impl_id,\n        impls => {\n            return Err(diagnostics.report_by_ptr(\n                stable_ptr,\n                MultipleImplementationOfTrait {\n                    trait_id: concrete_trait_id.trait_id(db),\n                    all_impl_ids: impls.to_vec(),\n                },\n            ));\n        }\n    };\n    Ok(match uninferred_impl_id {\n        UninferredImpl::Def(impl_def_id) => inference\n            .infer_impl_trait(impl_def_id, concrete_trait_id, lookup_context, stable_ptr)\n            .map_err(|err| err.report(diagnostics, stable_ptr))?,\n        UninferredImpl::GenericParam(param) => ImplId::GenericParameter(param),\n    })\n}\n\n/// Checks if there is at least one impl that can be inferred for a specific concrete trait.\npub fn get_impl_at_context(\n    db: &dyn SemanticGroup,\n    lookup_context: ImplLookupContext,\n    concrete_trait_id: ConcreteTraitId,\n    stable_ptr: SyntaxStablePtrId,\n) -> InferenceResult<ImplId> {\n    let mut inference = Inference::new(db);\n    let impl_id = inference.new_impl_var(concrete_trait_id, stable_ptr, lookup_context)?;\n    if let Some((_, err)) = inference.finalize() {\n        return Err(err);\n    };\n    inference.rewrite(impl_id)\n}\n\n// === Declaration ===\n\n#[derive(Clone, Debug, PartialEq, Eq, DebugWithDb)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct ImplFunctionDeclarationData {\n    pub function_declaration_data: FunctionDeclarationData,\n    trait_function_id: Maybe<TraitFunctionId>,\n}\n\n/// Query implementation of [crate::db::SemanticGroup::impl_function_signature].\npub fn impl_function_signature(\n    db: &dyn SemanticGroup,\n    impl_function_id: ImplFunctionId,\n) -> Maybe<semantic::Signature> {\n    Ok(db\n        .priv_impl_function_declaration_data(impl_function_id)?\n        .function_declaration_data\n        .signature)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::impl_function_declaration_implicits].\npub fn impl_function_declaration_implicits(\n    db: &dyn SemanticGroup,\n    impl_function_id: ImplFunctionId,\n) -> Maybe<Vec<TypeId>> {\n    Ok(db\n        .priv_impl_function_declaration_data(impl_function_id)?\n        .function_declaration_data\n        .signature\n        .implicits)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::impl_function_generic_params].\npub fn impl_function_generic_params(\n    db: &dyn SemanticGroup,\n    impl_function_id: ImplFunctionId,\n) -> Maybe<Vec<semantic::GenericParam>> {\n    Ok(db\n        .priv_impl_function_declaration_data(impl_function_id)?\n        .function_declaration_data\n        .generic_params)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::impl_function_declaration_diagnostics].\npub fn impl_function_declaration_diagnostics(\n    db: &dyn SemanticGroup,\n    impl_function_id: ImplFunctionId,\n) -> Diagnostics<SemanticDiagnostic> {\n    db.priv_impl_function_declaration_data(impl_function_id)\n        .map(|data| data.function_declaration_data.diagnostics)\n        .unwrap_or_default()\n}\n\n/// Query implementation of [crate::db::SemanticGroup::impl_function_resolved_lookback].\npub fn impl_function_resolved_lookback(\n    db: &dyn SemanticGroup,\n    impl_function_id: ImplFunctionId,\n) -> Maybe<Arc<ResolvedLookback>> {\n    Ok(db\n        .priv_impl_function_declaration_data(impl_function_id)?\n        .function_declaration_data\n        .resolved_lookback)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::impl_function_declaration_inline_config].\npub fn impl_function_declaration_inline_config(\n    db: &dyn SemanticGroup,\n    impl_function_id: ImplFunctionId,\n) -> Maybe<InlineConfiguration> {\n    Ok(db\n        .priv_impl_function_declaration_data(impl_function_id)?\n        .function_declaration_data\n        .inline_config)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::impl_function_trait_function].\npub fn impl_function_trait_function(\n    db: &dyn SemanticGroup,\n    impl_function_id: ImplFunctionId,\n) -> Maybe<TraitFunctionId> {\n    db.priv_impl_function_declaration_data(impl_function_id)?.trait_function_id\n}\n\n/// Query implementation of [crate::db::SemanticGroup::priv_impl_function_declaration_data].\npub fn priv_impl_function_declaration_data(\n    db: &dyn SemanticGroup,\n    impl_function_id: ImplFunctionId,\n) -> Maybe<ImplFunctionDeclarationData> {\n    let module_file_id = impl_function_id.module_file_id(db.upcast());\n    let mut diagnostics = SemanticDiagnostics::new(module_file_id);\n    let impl_def_id = impl_function_id.impl_def_id(db.upcast());\n    let data = db.priv_impl_definition_data(impl_def_id)?;\n    let function_syntax = &data.function_asts[impl_function_id];\n    let syntax_db = db.upcast();\n    let declaration = function_syntax.declaration(syntax_db);\n    let mut resolver = Resolver::new_with_inference(db, module_file_id);\n    let impl_def_generic_params = db.impl_def_generic_params(impl_def_id)?;\n    for generic_param in impl_def_generic_params {\n        resolver.add_generic_param(generic_param);\n    }\n    let function_generic_params = semantic_generic_params(\n        db,\n        &mut diagnostics,\n        &mut resolver,\n        module_file_id,\n        &declaration.generic_params(syntax_db),\n    )?;\n\n    let signature_syntax = declaration.signature(syntax_db);\n\n    let mut environment = Environment::default();\n    let signature = semantic::Signature::from_ast(\n        &mut diagnostics,\n        db,\n        &mut resolver,\n        &signature_syntax,\n        FunctionTitleId::Impl(impl_function_id),\n        &mut environment,\n    );\n\n    let trait_function_id = validate_impl_function_signature(\n        db,\n        &mut diagnostics,\n        impl_function_id,\n        &signature_syntax,\n        &signature,\n        function_syntax,\n        &function_generic_params,\n    );\n\n    let attributes = ast_attributes_to_semantic(syntax_db, function_syntax.attributes(syntax_db));\n    let resolved_lookback = Arc::new(resolver.lookback);\n\n    let inline_config = get_inline_config(db, &mut diagnostics, &attributes)?;\n\n    forbid_inline_always_with_impl_generic_param(\n        &mut diagnostics,\n        &function_generic_params,\n        &inline_config,\n    );\n\n    Ok(ImplFunctionDeclarationData {\n        function_declaration_data: FunctionDeclarationData {\n            diagnostics: diagnostics.build(),\n            signature,\n            generic_params: function_generic_params,\n            environment,\n            attributes,\n            resolved_lookback,\n            inline_config,\n        },\n        trait_function_id,\n    })\n}\n\nfn validate_impl_function_signature(\n    db: &dyn SemanticGroup,\n    diagnostics: &mut SemanticDiagnostics,\n    impl_function_id: ImplFunctionId,\n    signature_syntax: &ast::FunctionSignature,\n    signature: &semantic::Signature,\n    function_syntax: &ast::FunctionWithBody,\n    impl_func_generics: &[GenericParam],\n) -> Maybe<TraitFunctionId> {\n    let syntax_db = db.upcast();\n    let impl_def_id = impl_function_id.impl_def_id(db.upcast());\n    let declaration_data = db.priv_impl_declaration_data(impl_def_id)?;\n    let concrete_trait_id = declaration_data.concrete_trait?;\n    let concrete_trait_long_id = db.lookup_intern_concrete_trait(concrete_trait_id);\n    let trait_id = concrete_trait_long_id.trait_id;\n    let trait_functions = db.trait_functions(trait_id)?;\n    let function_name = db.lookup_intern_impl_function(impl_function_id).name(db.upcast());\n    let trait_function_id = *trait_functions.get(&function_name).ok_or_else(|| {\n        diagnostics.report(\n            function_syntax,\n            FunctionNotMemberOfTrait { impl_def_id, impl_function_id, trait_id },\n        )\n    })?;\n    let concrete_trait_function =\n        ConcreteTraitGenericFunctionId::new(db, concrete_trait_id, trait_function_id);\n    let concrete_trait_signature = db.concrete_trait_function_signature(concrete_trait_function)?;\n\n    // Match generics of the function.\n    let func_generics = db.concrete_trait_function_generic_params(concrete_trait_function)?;\n    if impl_func_generics.len() != func_generics.len() {\n        diagnostics.report(\n            &function_syntax.declaration(syntax_db).name(syntax_db),\n            WrongNumberOfGenericArguments {\n                expected: func_generics.len(),\n                actual: impl_func_generics.len(),\n            },\n        );\n        return Ok(trait_function_id);\n    }\n    let substitution = GenericSubstitution::new(\n        &func_generics,\n        &impl_func_generics\n            .iter()\n            .map(|param| {\n                GenericArgumentId::Type(db.intern_type(TypeLongId::GenericParameter(param.id())))\n            })\n            .collect_vec(),\n    );\n    let concrete_trait_signature = SubstitutionRewriter { db, substitution: &substitution }\n        .rewrite(concrete_trait_signature)?;\n\n    if signature.params.len() != concrete_trait_signature.params.len() {\n        diagnostics.report(\n            &signature_syntax.parameters(syntax_db),\n            WrongNumberOfParameters {\n                impl_def_id,\n                impl_function_id,\n                trait_id,\n                expected: concrete_trait_signature.params.len(),\n                actual: signature.params.len(),\n            },\n        );\n    }\n    for (idx, (param, trait_param)) in\n        izip!(signature.params.iter(), concrete_trait_signature.params.iter()).enumerate()\n    {\n        let expected_ty = trait_param.ty;\n        let actual_ty = param.ty;\n\n        if expected_ty != actual_ty {\n            diagnostics.report(\n                &signature_syntax.parameters(syntax_db).elements(syntax_db)[idx]\n                    .type_clause(syntax_db)\n                    .ty(syntax_db),\n                WrongParameterType {\n                    impl_def_id,\n                    impl_function_id,\n                    trait_id,\n                    expected_ty,\n                    actual_ty,\n                },\n            );\n        }\n\n        if trait_param.mutability != param.mutability {\n            if trait_param.mutability == Mutability::Reference {\n                diagnostics.report(\n                    &signature_syntax.parameters(syntax_db).elements(syntax_db)[idx]\n                        .modifiers(syntax_db),\n                    ParamaterShouldBeReference { impl_def_id, impl_function_id, trait_id },\n                );\n            }\n\n            if param.mutability == Mutability::Reference {\n                diagnostics.report(\n                    &signature_syntax.parameters(syntax_db).elements(syntax_db)[idx]\n                        .modifiers(syntax_db),\n                    ParameterShouldNotBeReference { impl_def_id, impl_function_id, trait_id },\n                );\n            }\n        }\n    }\n\n    if !concrete_trait_signature.panicable && signature.panicable {\n        diagnostics.report(signature_syntax, PassPanicAsNopanic { impl_function_id, trait_id });\n    }\n\n    let expected_ty = concrete_trait_signature.return_type;\n    let actual_ty = signature.return_type;\n    if expected_ty != actual_ty {\n        let location_ptr = match signature_syntax.ret_ty(syntax_db) {\n            OptionReturnTypeClause::ReturnTypeClause(ret_ty) => {\n                ret_ty.ty(syntax_db).as_syntax_node()\n            }\n            OptionReturnTypeClause::Empty(_) => {\n                function_syntax.body(syntax_db).lbrace(syntax_db).as_syntax_node()\n            }\n        }\n        .stable_ptr();\n        diagnostics.report_by_ptr(\n            location_ptr,\n            WrongReturnTypeForImpl {\n                impl_def_id,\n                impl_function_id,\n                trait_id,\n                expected_ty,\n                actual_ty,\n            },\n        );\n    }\n    Ok(trait_function_id)\n}\n\n// === Body ===\n\n// --- Selectors ---\n\n/// Query implementation of [crate::db::SemanticGroup::impl_function_body_diagnostics].\npub fn impl_function_body_diagnostics(\n    db: &dyn SemanticGroup,\n    impl_function_id: ImplFunctionId,\n) -> Diagnostics<SemanticDiagnostic> {\n    db.priv_impl_function_body_data(impl_function_id)\n        .map(|data| data.diagnostics)\n        .unwrap_or_default()\n}\n\n/// Query implementation of [crate::db::SemanticGroup::impl_function_body].\npub fn impl_function_body(\n    db: &dyn SemanticGroup,\n    impl_function_id: ImplFunctionId,\n) -> Maybe<Arc<FunctionBody>> {\n    Ok(db.priv_impl_function_body_data(impl_function_id)?.body)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::impl_function_body_resolved_lookback].\npub fn impl_function_body_resolved_lookback(\n    db: &dyn SemanticGroup,\n    impl_function_id: ImplFunctionId,\n) -> Maybe<Arc<ResolvedLookback>> {\n    Ok(db.priv_impl_function_body_data(impl_function_id)?.resolved_lookback)\n}\n\n// --- Computation ---\n\n/// Query implementation of [crate::db::SemanticGroup::priv_impl_function_body_data].\npub fn priv_impl_function_body_data(\n    db: &dyn SemanticGroup,\n    impl_function_id: ImplFunctionId,\n) -> Maybe<FunctionBodyData> {\n    let defs_db = db.upcast();\n    let module_file_id = impl_function_id.module_file_id(defs_db);\n    let mut diagnostics = SemanticDiagnostics::new(module_file_id);\n    let impl_def_id = impl_function_id.impl_def_id(defs_db);\n    let data = db.priv_impl_definition_data(impl_def_id)?;\n    let function_syntax = &data.function_asts[impl_function_id];\n    // Compute declaration semantic.\n    let declaration = db.priv_impl_function_declaration_data(impl_function_id)?;\n    let mut resolver = Resolver::new_with_inference(db, module_file_id);\n    for generic_param in db.impl_def_generic_params(impl_def_id)? {\n        resolver.add_generic_param(generic_param);\n    }\n    for generic_param in declaration.function_declaration_data.generic_params {\n        resolver.add_generic_param(generic_param);\n    }\n    let environment = declaration.function_declaration_data.environment;\n\n    // Compute body semantic expr.\n    let mut ctx = ComputationContext::new(\n        db,\n        &mut diagnostics,\n        resolver,\n        Some(&declaration.function_declaration_data.signature),\n        environment,\n    );\n    let function_body = function_syntax.body(db.upcast());\n    let return_type = declaration.function_declaration_data.signature.return_type;\n    let body_expr = compute_root_expr(&mut ctx, &function_body, return_type)?;\n    let ComputationContext { exprs, statements, resolver, .. } = ctx;\n\n    let direct_callees: HashSet<FunctionId> = exprs\n        .iter()\n        .filter_map(|(_id, expr)| try_extract_matches!(expr, Expr::FunctionCall))\n        .map(|f| f.function)\n        .collect();\n\n    let expr_lookup: UnorderedHashMap<_, _> =\n        exprs.iter().map(|(expr_id, expr)| (expr.stable_ptr(), expr_id)).collect();\n    let resolved_lookback = Arc::new(resolver.lookback);\n    Ok(FunctionBodyData {\n        diagnostics: diagnostics.build(),\n        expr_lookup,\n        resolved_lookback,\n        body: Arc::new(FunctionBody {\n            exprs,\n            statements,\n            body_expr,\n            direct_callees: direct_callees.into_iter().collect(),\n        }),\n    })\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_debug::DebugWithDb;\nuse cairo_lang_defs::ids::ModuleItemId;\nuse cairo_lang_utils::extract_matches;\nuse pretty_assertions::assert_eq;\nuse test_log::test;\n\nuse crate::db::SemanticGroup;\nuse crate::test_utils::{setup_test_module, SemanticDatabaseForTesting};\n\n#[test]\nfn test_impl() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let db = &mut db_val;\n    let (test_module, diagnostics) = setup_test_module(\n        db,\n        indoc::indoc! {\"\n            #[ABI]\n            trait IContract {\n                fn foo(a: felt252);\n            }\n\n\n            #[Contract]\n            impl Contract of IContract {\n                fn foo(a: felt252) {\n                }\n            }\n        \"},\n    )\n    .split();\n\n    assert!(diagnostics.is_empty());\n\n    let impl_def_id = extract_matches!(\n        db.module_item_by_name(test_module.module_id, \"Contract\".into()).unwrap().unwrap(),\n        ModuleItemId::Impl\n    );\n\n    assert_eq!(format!(\"{:?}\", db.impl_def_generic_params(impl_def_id).unwrap()), \"[]\");\n\n    let impl_functions = db.impl_functions(impl_def_id).unwrap();\n    let impl_function_id = impl_functions.get(\"foo\").unwrap();\n    let signature = db.impl_function_signature(*impl_function_id).unwrap();\n    assert_eq!(\n        format!(\"{:?}\", signature.debug(db)),\n        \"Signature { params: [Parameter { id: ParamId(test::a), name: \\\"a\\\", ty: core::felt252, \\\n         mutability: Immutable }], return_type: (), implicits: [], panicable: true }\"\n    );\n\n    assert_eq!(\n        format!(\"{:?}\", db.impl_def_concrete_trait(impl_def_id).unwrap()),\n        \"ConcreteTraitId(0)\"\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "pub mod attribute;\npub mod constant;\npub mod enm;\npub mod extern_function;\npub mod extern_type;\npub mod free_function;\npub mod function_with_body;\npub mod functions;\npub mod generics;\npub mod imp;\npub mod modifiers;\npub mod module;\npub mod structure;\npub mod trt;\npub mod type_alias;\npub mod us;\n\n#[cfg(test)]\nmod test;\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_syntax::node::ast::Modifier;\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::Terminal;\nuse smol_str::SmolStr;\n\nuse crate::diagnostic::SemanticDiagnosticKind::RedundantModifier;\nuse crate::diagnostic::SemanticDiagnostics;\nuse crate::Mutability;\n\n/// Returns the mutability of a variable, given the list of modifiers in the AST.\npub fn compute_mutability(\n    diagnostics: &mut SemanticDiagnostics,\n    syntax_db: &dyn SyntaxGroup,\n    modifier_list: &[Modifier],\n) -> Mutability {\n    let mut mutability = Mutability::Immutable;\n\n    for modifier in modifier_list {\n        match mutability {\n            Mutability::Immutable => {\n                mutability = match modifier {\n                    Modifier::Ref(_) => Mutability::Reference,\n                    Modifier::Mut(_) => Mutability::Mutable,\n                };\n            }\n            Mutability::Mutable | Mutability::Reference => match modifier {\n                Modifier::Ref(terminal) => {\n                    diagnostics.report(\n                        terminal,\n                        RedundantModifier {\n                            current_modifier: terminal.text(syntax_db),\n                            previous_modifier: get_relevant_modifier(&mutability),\n                        },\n                    );\n                }\n                Modifier::Mut(terminal) => {\n                    diagnostics.report(\n                        terminal,\n                        RedundantModifier {\n                            current_modifier: terminal.text(syntax_db),\n                            previous_modifier: get_relevant_modifier(&mutability),\n                        },\n                    );\n                }\n            },\n        }\n    }\n    mutability\n}\n\n/// Gets the text of the modifier that causes a variable to have the given mutability status.\nfn get_relevant_modifier(mutability: &Mutability) -> SmolStr {\n    match mutability {\n        Mutability::Immutable => \"\",\n        Mutability::Mutable => \"mut\",\n        Mutability::Reference => \"ref\",\n    }\n    .to_string()\n    .into()\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse cairo_lang_defs::diagnostic_utils::StableLocation;\nuse cairo_lang_defs::ids::{LanguageElementId, ModuleId, ModuleItemId};\nuse cairo_lang_diagnostics::{Diagnostics, DiagnosticsBuilder, Maybe};\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse smol_str::SmolStr;\n\nuse crate::db::SemanticGroup;\nuse crate::diagnostic::SemanticDiagnosticKind;\nuse crate::SemanticDiagnostic;\n\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct ModuleSemanticData {\n    // The items in the module without duplicates.\n    pub items: OrderedHashMap<SmolStr, ModuleItemId>,\n    pub diagnostics: Diagnostics<SemanticDiagnostic>,\n}\n\npub fn priv_module_items_data(\n    db: &dyn SemanticGroup,\n    module_id: ModuleId,\n) -> Maybe<Arc<ModuleSemanticData>> {\n    let def_db = db.upcast();\n    // We use the builder here since the items can come from different file_ids.\n    let mut diagnostics = DiagnosticsBuilder::default();\n    let mut items = OrderedHashMap::default();\n    for item in db.module_items(module_id)?.iter() {\n        let name = match item {\n            ModuleItemId::Constant(item_id) => item_id.name(def_db),\n            ModuleItemId::Submodule(item_id) => item_id.name(def_db),\n            ModuleItemId::Use(item_id) => item_id.name(def_db),\n            ModuleItemId::FreeFunction(item_id) => item_id.name(def_db),\n            ModuleItemId::Struct(item_id) => item_id.name(def_db),\n            ModuleItemId::Enum(item_id) => item_id.name(def_db),\n            ModuleItemId::TypeAlias(item_id) => item_id.name(def_db),\n            ModuleItemId::Trait(item_id) => item_id.name(def_db),\n            ModuleItemId::Impl(item_id) => item_id.name(def_db),\n            ModuleItemId::ExternType(item_id) => item_id.name(def_db),\n            ModuleItemId::ExternFunction(item_id) => item_id.name(def_db),\n        };\n\n        if items.insert(name.clone(), *item).is_some() {\n            let stable_location = StableLocation::new(\n                item.module_file_id(def_db),\n                db.module_item_name_stable_ptr(module_id, *item)?,\n            );\n            let kind = SemanticDiagnosticKind::NameDefinedMultipleTimes { name: name.clone() };\n            diagnostics.add(SemanticDiagnostic::new(stable_location, kind));\n        }\n    }\n    Ok(Arc::new(ModuleSemanticData { items, diagnostics: diagnostics.build() }))\n}\n\npub fn module_item_by_name(\n    db: &dyn SemanticGroup,\n    module_id: ModuleId,\n    name: SmolStr,\n) -> Maybe<Option<ModuleItemId>> {\n    let module_data = db.priv_module_items_data(module_id)?;\n    Ok(module_data.items.get(&name).copied())\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse cairo_lang_defs::ids::{LanguageElementId, MemberId, MemberLongId, StructId};\nuse cairo_lang_diagnostics::{Diagnostics, Maybe, ToMaybe};\nuse cairo_lang_proc_macros::{DebugWithDb, SemanticObject};\nuse cairo_lang_syntax::node::{Terminal, TypedSyntaxNode};\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse cairo_lang_utils::Upcast;\nuse smol_str::SmolStr;\n\nuse super::attribute::{ast_attributes_to_semantic, Attribute};\nuse super::generics::semantic_generic_params;\nuse crate::db::SemanticGroup;\nuse crate::diagnostic::SemanticDiagnosticKind::*;\nuse crate::diagnostic::SemanticDiagnostics;\nuse crate::resolve_path::{ResolvedLookback, Resolver};\nuse crate::substitution::{GenericSubstitution, SemanticRewriter, SubstitutionRewriter};\nuse crate::types::{resolve_type, ConcreteStructId};\nuse crate::{semantic, SemanticDiagnostic};\n\n#[cfg(test)]\n#[path = \"structure_test.rs\"]\nmod test;\n\n// TODO(spapini): Check for bad recursive types - those that will fail in Sierra generation.\n\n// Declaration.\n#[derive(Clone, Debug, PartialEq, Eq, DebugWithDb)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct StructDeclarationData {\n    diagnostics: Diagnostics<SemanticDiagnostic>,\n    generic_params: Vec<semantic::GenericParam>,\n    attributes: Vec<Attribute>,\n    resolved_lookback: Arc<ResolvedLookback>,\n}\n\n/// Query implementation of [crate::db::SemanticGroup::priv_struct_declaration_data].\npub fn priv_struct_declaration_data(\n    db: &dyn SemanticGroup,\n    struct_id: StructId,\n) -> Maybe<StructDeclarationData> {\n    let module_file_id = struct_id.module_file_id(db.upcast());\n    let mut diagnostics = SemanticDiagnostics::new(module_file_id);\n    // TODO(spapini): when code changes in a file, all the AST items change (as they contain a path\n    // to the green root that changes. Once ASTs are rooted on items, use a selector that picks only\n    // the item instead of all the module data.\n    // TODO(spapini): Add generic args when they are supported on structs.\n    let module_structs = db.module_structs(module_file_id.0)?;\n    let struct_ast = module_structs.get(&struct_id).to_maybe()?;\n    let syntax_db = db.upcast();\n\n    // Generic params.\n    let mut resolver = Resolver::new_with_inference(db, module_file_id);\n    let generic_params = semantic_generic_params(\n        db,\n        &mut diagnostics,\n        &mut resolver,\n        module_file_id,\n        &struct_ast.generic_params(db.upcast()),\n    )?;\n\n    let attributes = ast_attributes_to_semantic(syntax_db, struct_ast.attributes(syntax_db));\n    let resolved_lookback = Arc::new(resolver.lookback);\n\n    Ok(StructDeclarationData {\n        diagnostics: diagnostics.build(),\n        generic_params,\n        attributes,\n        resolved_lookback,\n    })\n}\n\n/// Query implementation of [crate::db::SemanticGroup::struct_declaration_diagnostics].\npub fn struct_declaration_diagnostics(\n    db: &dyn SemanticGroup,\n    struct_id: StructId,\n) -> Diagnostics<SemanticDiagnostic> {\n    db.priv_struct_declaration_data(struct_id).map(|data| data.diagnostics).unwrap_or_default()\n}\n\n/// Query implementation of [crate::db::SemanticGroup::struct_generic_params].\npub fn struct_generic_params(\n    db: &dyn SemanticGroup,\n    struct_id: StructId,\n) -> Maybe<Vec<semantic::GenericParam>> {\n    Ok(db.priv_struct_declaration_data(struct_id)?.generic_params)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::struct_attributes].\npub fn struct_attributes(db: &dyn SemanticGroup, struct_id: StructId) -> Maybe<Vec<Attribute>> {\n    Ok(db.priv_struct_declaration_data(struct_id)?.attributes)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::struct_declaration_resolved_lookback].\npub fn struct_declaration_resolved_lookback(\n    db: &dyn SemanticGroup,\n    struct_id: StructId,\n) -> Maybe<Arc<ResolvedLookback>> {\n    Ok(db.priv_struct_declaration_data(struct_id)?.resolved_lookback)\n}\n\n// Definition.\n#[derive(Clone, Debug, PartialEq, Eq, DebugWithDb)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct StructDefinitionData {\n    diagnostics: Diagnostics<SemanticDiagnostic>,\n    members: OrderedHashMap<SmolStr, Member>,\n    resolved_lookback: Arc<ResolvedLookback>,\n}\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct Member {\n    pub id: MemberId,\n    pub ty: semantic::TypeId,\n}\n\n/// Query implementation of [crate::db::SemanticGroup::priv_struct_definition_data].\npub fn priv_struct_definition_data(\n    db: &dyn SemanticGroup,\n    struct_id: StructId,\n) -> Maybe<StructDefinitionData> {\n    let module_file_id = struct_id.module_file_id(db.upcast());\n    let mut diagnostics = SemanticDiagnostics::new(module_file_id);\n    // TODO(spapini): when code changes in a file, all the AST items change (as they contain a path\n    // to the green root that changes. Once ASTs are rooted on items, use a selector that picks only\n    // the item instead of all the module data.\n    // TODO(spapini): Add generic args when they are supported on structs.\n    let module_structs = db.module_structs(module_file_id.0)?;\n    let struct_ast = module_structs.get(&struct_id).to_maybe()?;\n    let syntax_db = db.upcast();\n\n    // Generic params.\n    let mut resolver = Resolver::new_without_inference(db, module_file_id);\n    let generic_params = db.struct_generic_params(struct_id)?;\n    for generic_param in generic_params {\n        resolver.add_generic_param(generic_param);\n    }\n\n    // Members.\n    let mut members = OrderedHashMap::default();\n    for member in struct_ast.members(syntax_db).elements(syntax_db) {\n        let id = db.intern_member(MemberLongId(module_file_id, member.stable_ptr()));\n        let ty = resolve_type(\n            db,\n            &mut diagnostics,\n            &mut resolver,\n            &member.type_clause(syntax_db).ty(syntax_db),\n        );\n        let member_name = member.name(syntax_db).text(syntax_db);\n        if let Some(_other_member) = members.insert(member_name.clone(), Member { id, ty }) {\n            diagnostics.report(&member, StructMemberRedefinition { struct_id, member_name });\n        }\n    }\n\n    let resolved_lookback = Arc::new(resolver.lookback);\n\n    Ok(StructDefinitionData { diagnostics: diagnostics.build(), members, resolved_lookback })\n}\n\n/// Query implementation of [crate::db::SemanticGroup::struct_definition_diagnostics].\npub fn struct_definition_diagnostics(\n    db: &dyn SemanticGroup,\n    struct_id: StructId,\n) -> Diagnostics<SemanticDiagnostic> {\n    db.priv_struct_definition_data(struct_id).map(|data| data.diagnostics).unwrap_or_default()\n}\n\n/// Query implementation of [crate::db::SemanticGroup::struct_members].\npub fn struct_members(\n    db: &dyn SemanticGroup,\n    struct_id: StructId,\n) -> Maybe<OrderedHashMap<SmolStr, Member>> {\n    Ok(db.priv_struct_definition_data(struct_id)?.members)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::struct_definition_resolved_lookback].\npub fn struct_definition_resolved_lookback(\n    db: &dyn SemanticGroup,\n    struct_id: StructId,\n) -> Maybe<Arc<ResolvedLookback>> {\n    Ok(db.priv_struct_declaration_data(struct_id)?.resolved_lookback)\n}\n\npub trait SemanticStructEx<'a>: Upcast<dyn SemanticGroup + 'a> {\n    fn concrete_struct_members(\n        &self,\n        concrete_struct_id: ConcreteStructId,\n    ) -> Maybe<OrderedHashMap<SmolStr, semantic::Member>> {\n        // TODO(spapini): Uphold the invariant that constructed ConcreteEnumId instances\n        //   always have the correct number of generic arguments.\n        let db = self.upcast();\n        let generic_params = db.struct_generic_params(concrete_struct_id.struct_id(db))?;\n        let generic_args = db.lookup_intern_concrete_struct(concrete_struct_id).generic_args;\n        let substitution = GenericSubstitution::new(&generic_params, &generic_args);\n\n        let generic_members =\n            self.upcast().struct_members(concrete_struct_id.struct_id(self.upcast()))?;\n        generic_members\n            .into_iter()\n            .map(|(name, member)| {\n                let ty =\n                    SubstitutionRewriter { db, substitution: &substitution }.rewrite(member.ty)?;\n                let member = semantic::Member { ty, ..member };\n                Ok((name, member))\n            })\n            .collect::<Maybe<_>>()\n    }\n}\n\nimpl<'a, T: Upcast<dyn SemanticGroup + 'a> + ?Sized> SemanticStructEx<'a> for T {}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_debug::DebugWithDb;\nuse cairo_lang_defs::ids::ModuleItemId;\nuse cairo_lang_utils::extract_matches;\nuse indoc::indoc;\nuse pretty_assertions::assert_eq;\nuse test_log::test;\n\nuse crate::db::SemanticGroup;\nuse crate::test_utils::{setup_test_module, SemanticDatabaseForTesting};\n\n#[test]\nfn test_struct() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let db = &mut db_val;\n    let (test_module, diagnostics) = setup_test_module(\n        db,\n        indoc::indoc! {\"\n            #[contract(MyImpl1, MyImpl2)]\n            struct A {\n                a: felt252,\n                b: (felt252, felt252),\n                c: (),\n                a: (),\n                a: ()\n            }\n\n            fn foo(a: A) {\n                5;\n            }\n        \"},\n    )\n    .split();\n    assert_eq!(\n        diagnostics,\n        indoc! {r#\"\n        error: Redefinition of member \"a\" on struct \"test::A\".\n         --> lib.cairo:6:5\n            a: (),\n            ^***^\n\n        error: Redefinition of member \"a\" on struct \"test::A\".\n         --> lib.cairo:7:5\n            a: ()\n            ^***^\n\n        \"#}\n    );\n    let module_id = test_module.module_id;\n\n    let struct_id = extract_matches!(\n        db.module_item_by_name(module_id, \"A\".into()).unwrap().unwrap(),\n        ModuleItemId::Struct\n    );\n    let actual = db\n        .struct_members(struct_id)\n        .unwrap()\n        .iter()\n        .map(|(name, member)| format!(\"{name}: {:?}\", member.debug(db)))\n        .collect::<Vec<_>>()\n        .join(\",\\n\");\n    assert_eq!(\n        actual,\n        indoc! {\"\n            a: Member { id: MemberId(test::a), ty: () },\n            b: Member { id: MemberId(test::b), ty: (core::felt252, core::felt252) },\n            c: Member { id: MemberId(test::c), ty: () }\"}\n    );\n\n    assert_eq!(\n        db.struct_attributes(struct_id)\n            .unwrap()\n            .iter()\n            .map(|attr| format!(\"{:?}\", attr.debug(db)))\n            .collect::<Vec<_>>()\n            .join(\",\\n\"),\n        r#\"Attribute { id: \"contract\", args: [\"MyImpl1\", \"MyImpl2\", ] }\"#\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use crate::test_utils::test_function_diagnostics;\n\ncairo_lang_test_utils::test_file_test!(\n    diagnostics,\n    \"src/items/tests\",\n    {\n        enum_: \"enum\",\n        extern_func: \"extern_func\",\n        free_function: \"free_function\",\n        panicable: \"panicable\",\n        struct_: \"struct\",\n        trait_: \"trait\",\n        type_alias: \"type_alias\",\n        module: \"module\",\n    },\n    test_function_diagnostics\n);\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse cairo_lang_debug::DebugWithDb;\nuse cairo_lang_defs::ids::{\n    FunctionTitleId, LanguageElementId, TopLevelLanguageElementId, TraitFunctionId,\n    TraitFunctionLongId, TraitId,\n};\nuse cairo_lang_diagnostics::{Diagnostics, DiagnosticsBuilder, Maybe, ToMaybe};\nuse cairo_lang_proc_macros::{DebugWithDb, SemanticObject};\nuse cairo_lang_syntax::node::{ast, TypedSyntaxNode};\nuse cairo_lang_utils::define_short_id;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse smol_str::SmolStr;\n\nuse super::attribute::{ast_attributes_to_semantic, Attribute};\nuse super::generics::semantic_generic_params;\nuse crate::db::SemanticGroup;\nuse crate::diagnostic::SemanticDiagnostics;\nuse crate::expr::compute::Environment;\nuse crate::resolve_path::{ResolvedLookback, Resolver};\nuse crate::substitution::{GenericSubstitution, SemanticRewriter, SubstitutionRewriter};\nuse crate::{\n    semantic, semantic_object_for_id, GenericArgumentId, GenericParam, Mutability,\n    SemanticDiagnostic,\n};\n\n#[cfg(test)]\n#[path = \"trt_test.rs\"]\nmod test;\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, SemanticObject)]\npub struct ConcreteTraitLongId {\n    pub trait_id: TraitId,\n    pub generic_args: Vec<GenericArgumentId>,\n}\nimpl DebugWithDb<dyn SemanticGroup> for ConcreteTraitLongId {\n    fn fmt(\n        &self,\n        f: &mut std::fmt::Formatter<'_>,\n        db: &(dyn SemanticGroup + 'static),\n    ) -> std::fmt::Result {\n        write!(f, \"{}\", self.trait_id.full_path(db.upcast()))?;\n        if !self.generic_args.is_empty() {\n            write!(f, \"::<\")?;\n            for (i, arg) in self.generic_args.iter().enumerate() {\n                if i > 0 {\n                    write!(f, \", \")?;\n                }\n                write!(f, \"{:?}\", arg.debug(db))?;\n            }\n            write!(f, \">\")?;\n        }\n        Ok(())\n    }\n}\n\ndefine_short_id!(ConcreteTraitId, ConcreteTraitLongId, SemanticGroup, lookup_intern_concrete_trait);\nsemantic_object_for_id!(\n    ConcreteTraitId,\n    lookup_intern_concrete_trait,\n    intern_concrete_trait,\n    ConcreteTraitLongId\n);\nimpl ConcreteTraitId {\n    pub fn trait_id(&self, db: &dyn SemanticGroup) -> TraitId {\n        db.lookup_intern_concrete_trait(*self).trait_id\n    }\n    pub fn generic_args(&self, db: &dyn SemanticGroup) -> Vec<GenericArgumentId> {\n        db.lookup_intern_concrete_trait(*self).generic_args\n    }\n}\n\n/// The ID of a generic function in a concrete trait.\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct ConcreteTraitGenericFunctionLongId {\n    // Note the members are private to prevent direct call to the constructor.\n    concrete_trait_id: ConcreteTraitId,\n    function_id: TraitFunctionId,\n}\nimpl ConcreteTraitGenericFunctionLongId {\n    pub fn new(\n        db: &dyn SemanticGroup,\n        concrete_trait_id: ConcreteTraitId,\n        function_id: TraitFunctionId,\n    ) -> Self {\n        assert_eq!(\n            concrete_trait_id.trait_id(db),\n            function_id.trait_id(db.upcast()),\n            \"Concrete trait a trait function must belong to the same generic trait.\"\n        );\n        Self { concrete_trait_id, function_id }\n    }\n}\ndefine_short_id!(\n    ConcreteTraitGenericFunctionId,\n    ConcreteTraitGenericFunctionLongId,\n    SemanticGroup,\n    lookup_intern_concrete_trait_function\n);\nsemantic_object_for_id!(\n    ConcreteTraitGenericFunctionId,\n    lookup_intern_concrete_trait_function,\n    intern_concrete_trait_function,\n    ConcreteTraitGenericFunctionLongId\n);\nimpl ConcreteTraitGenericFunctionId {\n    pub fn new(\n        db: &dyn SemanticGroup,\n        concrete_trait_id: ConcreteTraitId,\n        function_id: TraitFunctionId,\n    ) -> Self {\n        db.intern_concrete_trait_function(ConcreteTraitGenericFunctionLongId::new(\n            db,\n            concrete_trait_id,\n            function_id,\n        ))\n    }\n\n    pub fn function_id(&self, db: &dyn SemanticGroup) -> TraitFunctionId {\n        db.lookup_intern_concrete_trait_function(*self).function_id\n    }\n\n    pub fn concrete_trait_id(&self, db: &dyn SemanticGroup) -> ConcreteTraitId {\n        db.lookup_intern_concrete_trait_function(*self).concrete_trait_id\n    }\n}\n\n#[derive(Clone, Debug, PartialEq, Eq, DebugWithDb)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct TraitData {\n    diagnostics: Diagnostics<SemanticDiagnostic>,\n    generic_params: Vec<GenericParam>,\n    attributes: Vec<Attribute>,\n    function_asts: OrderedHashMap<TraitFunctionId, ast::TraitItemFunction>,\n}\n\n/// Query implementation of [crate::db::SemanticGroup::trait_semantic_diagnostics].\npub fn trait_semantic_diagnostics(\n    db: &dyn SemanticGroup,\n    trait_id: TraitId,\n) -> Diagnostics<SemanticDiagnostic> {\n    let mut diagnostics = DiagnosticsBuilder::default();\n\n    let Ok(data) = db.priv_trait_semantic_data(trait_id) else {\n        return Diagnostics::default();\n    };\n\n    diagnostics.extend(data.diagnostics);\n    for trait_function_id in data.function_asts.keys() {\n        diagnostics.extend(db.trait_function_diagnostics(*trait_function_id));\n    }\n\n    diagnostics.build()\n}\n\n/// Query implementation of [crate::db::SemanticGroup::trait_generic_params].\npub fn trait_generic_params(db: &dyn SemanticGroup, trait_id: TraitId) -> Maybe<Vec<GenericParam>> {\n    Ok(db.priv_trait_semantic_data(trait_id)?.generic_params)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::trait_attributes].\npub fn trait_attributes(db: &dyn SemanticGroup, trait_id: TraitId) -> Maybe<Vec<Attribute>> {\n    Ok(db.priv_trait_semantic_data(trait_id)?.attributes)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::trait_functions].\npub fn trait_functions(\n    db: &dyn SemanticGroup,\n    trait_id: TraitId,\n) -> Maybe<OrderedHashMap<SmolStr, TraitFunctionId>> {\n    Ok(db\n        .priv_trait_semantic_data(trait_id)?\n        .function_asts\n        .keys()\n        .map(|function_id| {\n            let function_long_id = db.lookup_intern_trait_function(*function_id);\n            (function_long_id.name(db.upcast()), *function_id)\n        })\n        .collect())\n}\n\n/// Query implementation of [crate::db::SemanticGroup::trait_function_by_name].\npub fn trait_function_by_name(\n    db: &dyn SemanticGroup,\n    trait_id: TraitId,\n    name: SmolStr,\n) -> Maybe<Option<TraitFunctionId>> {\n    Ok(db.trait_functions(trait_id)?.get(&name).copied())\n}\n\n/// Query implementation of [crate::db::SemanticGroup::priv_trait_semantic_data].\npub fn priv_trait_semantic_data(db: &dyn SemanticGroup, trait_id: TraitId) -> Maybe<TraitData> {\n    let syntax_db = db.upcast();\n    let module_file_id = trait_id.module_file_id(db.upcast());\n    let mut diagnostics = SemanticDiagnostics::new(module_file_id);\n    // TODO(spapini): when code changes in a file, all the AST items change (as they contain a path\n    // to the green root that changes. Once ASTs are rooted on items, use a selector that picks only\n    // the item instead of all the module data.\n    let module_traits = db.module_traits(module_file_id.0)?;\n    let trait_ast = module_traits.get(&trait_id).to_maybe()?;\n\n    // Generic params.\n    let mut resolver = Resolver::new_with_inference(db, module_file_id);\n    let generic_params = semantic_generic_params(\n        db,\n        &mut diagnostics,\n        &mut resolver,\n        module_file_id,\n        &trait_ast.generic_params(syntax_db),\n    )?;\n\n    let attributes = ast_attributes_to_semantic(syntax_db, trait_ast.attributes(syntax_db));\n    let mut function_asts = OrderedHashMap::default();\n    if let ast::MaybeTraitBody::Some(body) = trait_ast.body(syntax_db) {\n        for item in body.items(syntax_db).elements(syntax_db) {\n            match item {\n                ast::TraitItem::Function(func) => {\n                    function_asts.insert(\n                        db.intern_trait_function(TraitFunctionLongId(\n                            module_file_id,\n                            func.stable_ptr(),\n                        )),\n                        func,\n                    );\n                }\n            }\n        }\n    }\n\n    Ok(TraitData { diagnostics: diagnostics.build(), generic_params, attributes, function_asts })\n}\n\n// Trait function.\n#[derive(Clone, Debug, PartialEq, Eq, DebugWithDb)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct TraitFunctionData {\n    diagnostics: Diagnostics<SemanticDiagnostic>,\n    signature: semantic::Signature,\n    generic_params: Vec<GenericParam>,\n    attributes: Vec<Attribute>,\n    resolved_lookback: Arc<ResolvedLookback>,\n}\n\n// Selectors.\n/// Query implementation of [crate::db::SemanticGroup::trait_function_diagnostics].\npub fn trait_function_diagnostics(\n    db: &dyn SemanticGroup,\n    trait_function_id: TraitFunctionId,\n) -> Diagnostics<SemanticDiagnostic> {\n    db.priv_trait_function_data(trait_function_id).map(|data| data.diagnostics).unwrap_or_default()\n}\n/// Query implementation of [crate::db::SemanticGroup::trait_function_signature].\npub fn trait_function_signature(\n    db: &dyn SemanticGroup,\n    trait_function_id: TraitFunctionId,\n) -> Maybe<semantic::Signature> {\n    Ok(db.priv_trait_function_data(trait_function_id)?.signature)\n}\n/// Query implementation of [crate::db::SemanticGroup::trait_function_attributes].\npub fn trait_function_attributes(\n    db: &dyn SemanticGroup,\n    trait_function_id: TraitFunctionId,\n) -> Maybe<Vec<Attribute>> {\n    Ok(db.priv_trait_function_data(trait_function_id)?.attributes)\n}\n/// Query implementation of [crate::db::SemanticGroup::trait_function_generic_params].\npub fn trait_function_generic_params(\n    db: &dyn SemanticGroup,\n    trait_function_id: TraitFunctionId,\n) -> Maybe<Vec<GenericParam>> {\n    Ok(db.priv_trait_function_data(trait_function_id)?.generic_params)\n}\n/// Query implementation of [crate::db::SemanticGroup::trait_function_resolved_lookback].\npub fn trait_function_resolved_lookback(\n    db: &dyn SemanticGroup,\n    trait_function_id: TraitFunctionId,\n) -> Maybe<Arc<ResolvedLookback>> {\n    Ok(db.priv_trait_function_data(trait_function_id)?.resolved_lookback)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::priv_trait_function_data].\npub fn priv_trait_function_data(\n    db: &dyn SemanticGroup,\n    trait_function_id: TraitFunctionId,\n) -> Maybe<TraitFunctionData> {\n    let syntax_db = db.upcast();\n    let module_file_id = trait_function_id.module_file_id(db.upcast());\n    let mut diagnostics = SemanticDiagnostics::new(module_file_id);\n    let trait_id = trait_function_id.trait_id(db.upcast());\n    let data = db.priv_trait_semantic_data(trait_id)?;\n    let function_syntax = &data.function_asts[trait_function_id];\n    let declaration = function_syntax.declaration(syntax_db);\n    let mut resolver = Resolver::new_with_inference(db, module_file_id);\n    let trait_generic_params = db.trait_generic_params(trait_id)?;\n    for generic_param in trait_generic_params {\n        resolver.add_generic_param(generic_param);\n    }\n    let function_generic_params = semantic_generic_params(\n        db,\n        &mut diagnostics,\n        &mut resolver,\n        module_file_id,\n        &declaration.generic_params(syntax_db),\n    )?;\n\n    let signature_syntax = declaration.signature(syntax_db);\n    let mut environment = Environment::default();\n    let signature = semantic::Signature::from_ast(\n        &mut diagnostics,\n        db,\n        &mut resolver,\n        &signature_syntax,\n        FunctionTitleId::Trait(trait_function_id),\n        &mut environment,\n    );\n\n    validate_trait_function_signature(\n        db,\n        &mut diagnostics,\n        trait_id,\n        trait_function_id,\n        &signature,\n        &signature_syntax,\n    );\n    // Validate trait function body is empty.\n    if matches!(function_syntax.body(syntax_db), ast::MaybeTraitFunctionBody::Some(_)) {\n        diagnostics.report(\n            &function_syntax.body(syntax_db),\n            crate::diagnostic::SemanticDiagnosticKind::TraitFunctionWithBody {\n                trait_id,\n                function_id: trait_function_id,\n            },\n        );\n    }\n\n    let attributes = ast_attributes_to_semantic(syntax_db, function_syntax.attributes(syntax_db));\n    let resolved_lookback = Arc::new(resolver.lookback);\n\n    Ok(TraitFunctionData {\n        diagnostics: diagnostics.build(),\n        signature,\n        generic_params: function_generic_params,\n        attributes,\n        resolved_lookback,\n    })\n}\n\n/// Query implementation of [crate::db::SemanticGroup::concrete_trait_function_generic_params].\npub fn concrete_trait_function_generic_params(\n    db: &dyn SemanticGroup,\n    concrete_trait_function_id: ConcreteTraitGenericFunctionId,\n) -> Maybe<Vec<GenericParam>> {\n    let concrete_trait_id = concrete_trait_function_id.concrete_trait_id(db);\n    let substitution = GenericSubstitution::new(\n        &db.trait_generic_params(concrete_trait_id.trait_id(db))?,\n        &concrete_trait_id.generic_args(db),\n    );\n    let generic_params =\n        db.trait_function_generic_params(concrete_trait_function_id.function_id(db))?;\n    let mut rewriter = SubstitutionRewriter { db, substitution: &substitution };\n    rewriter.rewrite(generic_params)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::concrete_trait_function_signature].\npub fn concrete_trait_function_signature(\n    db: &dyn SemanticGroup,\n    concrete_trait_function_id: ConcreteTraitGenericFunctionId,\n) -> Maybe<semantic::Signature> {\n    let concrete_trait_id = concrete_trait_function_id.concrete_trait_id(db);\n    let substitution = GenericSubstitution::new(\n        &db.trait_generic_params(concrete_trait_id.trait_id(db))?,\n        &concrete_trait_id.generic_args(db),\n    );\n    let generic_signature =\n        db.trait_function_signature(concrete_trait_function_id.function_id(db))?;\n    SubstitutionRewriter { db, substitution: &substitution }.rewrite(generic_signature)\n}\n\nfn validate_trait_function_signature(\n    db: &dyn SemanticGroup,\n    diagnostics: &mut SemanticDiagnostics,\n    trait_id: TraitId,\n    function_id: TraitFunctionId,\n    sig: &semantic::Signature,\n    sig_syntax: &ast::FunctionSignature,\n) {\n    let syntax_db = db.upcast();\n    for (idx, param) in sig.params.iter().enumerate() {\n        if param.mutability == Mutability::Mutable {\n            diagnostics.report(\n                &sig_syntax.parameters(syntax_db).elements(syntax_db)[idx].modifiers(syntax_db),\n                crate::diagnostic::SemanticDiagnosticKind::TraitParamMutable {\n                    trait_id,\n                    function_id,\n                },\n            );\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_debug::DebugWithDb;\nuse cairo_lang_defs::ids::ModuleItemId;\nuse cairo_lang_utils::extract_matches;\nuse pretty_assertions::assert_eq;\nuse test_log::test;\n\nuse crate::db::SemanticGroup;\nuse crate::test_utils::{setup_test_module, SemanticDatabaseForTesting};\n\n#[test]\nfn test_trait() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let db = &mut db_val;\n    let test_module = setup_test_module(\n        db,\n        indoc::indoc! {\"\n            #[contract]\n            trait MyContract {\n                fn foo(a: felt252);\n            }\n        \"},\n    )\n    .unwrap();\n\n    let trait_id = extract_matches!(\n        db.module_item_by_name(test_module.module_id, \"MyContract\".into()).unwrap().unwrap(),\n        ModuleItemId::Trait\n    );\n\n    assert_eq!(format!(\"{:?}\", db.trait_generic_params(trait_id).unwrap()), \"[]\");\n    assert_eq!(\n        format!(\"{:?}\", db.trait_attributes(trait_id).unwrap().debug(db)),\n        \"[Attribute { id: \\\"contract\\\" }]\"\n    );\n\n    let trait_functions = db.trait_functions(trait_id).unwrap();\n    let trait_function_id = trait_functions.get(\"foo\").unwrap();\n    let signature = db.trait_function_signature(*trait_function_id).unwrap();\n    assert_eq!(\n        format!(\"{:?}\", signature.debug(db)),\n        \"Signature { params: [Parameter { id: ParamId(test::a), name: \\\"a\\\", ty: core::felt252, \\\n         mutability: Immutable }], return_type: (), implicits: [], panicable: true }\"\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse cairo_lang_defs::ids::{LanguageElementId, TypeAliasId};\nuse cairo_lang_diagnostics::{Diagnostics, Maybe, ToMaybe};\nuse cairo_lang_proc_macros::DebugWithDb;\n\nuse super::generics::semantic_generic_params;\nuse crate::db::SemanticGroup;\nuse crate::diagnostic::{SemanticDiagnosticKind, SemanticDiagnostics};\nuse crate::resolve_path::{ResolvedLookback, Resolver};\nuse crate::types::resolve_type;\nuse crate::{GenericParam, SemanticDiagnostic, TypeId};\n\n#[derive(Clone, Debug, PartialEq, Eq, DebugWithDb)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct TypeAliasData {\n    diagnostics: Diagnostics<SemanticDiagnostic>,\n    resolved_type: Maybe<TypeId>,\n    generic_params: Vec<GenericParam>,\n    resolved_lookback: Arc<ResolvedLookback>,\n}\nimpl TypeAliasData {\n    /// Returns Maybe::Err if a cycle is detected here.\n    // TODO(orizi): Remove this function when cycle validation is not required through a type's\n    // field.\n    pub fn check_no_cycle(&self) -> Maybe<()> {\n        self.resolved_type?;\n        Ok(())\n    }\n}\n\n/// Query implementation of [crate::db::SemanticGroup::priv_type_alias_semantic_data].\npub fn priv_type_alias_semantic_data(\n    db: &(dyn SemanticGroup),\n    type_alias_id: TypeAliasId,\n) -> Maybe<TypeAliasData> {\n    let module_file_id = type_alias_id.module_file_id(db.upcast());\n    let mut diagnostics = SemanticDiagnostics::new(module_file_id);\n    // TODO(spapini): when code changes in a file, all the AST items change (as they contain a path\n    // to the green root that changes. Once ASTs are rooted on items, use a selector that picks only\n    // the item instead of all the module data.\n    // TODO(spapini): Add generic args when they are supported on structs.\n    let module_type_aliases = db.module_type_aliases(module_file_id.0)?;\n    let type_alias_ast = module_type_aliases.get(&type_alias_id).to_maybe()?;\n    let syntax_db = db.upcast();\n    let mut resolver = Resolver::new_with_inference(db, module_file_id);\n    let generic_params = semantic_generic_params(\n        db,\n        &mut diagnostics,\n        &mut resolver,\n        module_file_id,\n        &type_alias_ast.generic_params(syntax_db),\n    )?;\n    let ty = resolve_type(db, &mut diagnostics, &mut resolver, &type_alias_ast.ty(syntax_db));\n    let resolved_lookback = Arc::new(resolver.lookback);\n    Ok(TypeAliasData {\n        diagnostics: diagnostics.build(),\n        resolved_type: Ok(ty),\n        generic_params,\n        resolved_lookback,\n    })\n}\n\n/// Cycle handling for [crate::db::SemanticGroup::priv_type_alias_semantic_data].\npub fn priv_type_alias_semantic_data_cycle(\n    db: &dyn SemanticGroup,\n    _cycle: &[String],\n    type_alias_id: &TypeAliasId,\n) -> Maybe<TypeAliasData> {\n    let module_file_id = type_alias_id.module_file_id(db.upcast());\n    let mut diagnostics = SemanticDiagnostics::new(module_file_id);\n    let module_type_aliases = db.module_type_aliases(module_file_id.0)?;\n    let type_alias_ast = module_type_aliases.get(type_alias_id).to_maybe()?;\n    let syntax_db = db.upcast();\n    let err =\n        Err(diagnostics\n            .report(&type_alias_ast.name(syntax_db), SemanticDiagnosticKind::TypeAliasCycle));\n    let mut resolver = Resolver::new_with_inference(db, module_file_id);\n    let generic_params = semantic_generic_params(\n        db,\n        &mut diagnostics,\n        &mut resolver,\n        module_file_id,\n        &type_alias_ast.generic_params(syntax_db),\n    )?;\n    Ok(TypeAliasData {\n        diagnostics: diagnostics.build(),\n        resolved_type: err,\n        generic_params,\n        resolved_lookback: Arc::new(ResolvedLookback::default()),\n    })\n}\n\n/// Query implementation of [crate::db::SemanticGroup::type_alias_semantic_diagnostics].\npub fn type_alias_semantic_diagnostics(\n    db: &dyn SemanticGroup,\n    type_alias_id: TypeAliasId,\n) -> Diagnostics<SemanticDiagnostic> {\n    db.priv_type_alias_semantic_data(type_alias_id).map(|data| data.diagnostics).unwrap_or_default()\n}\n\n/// Query implementation of [crate::db::SemanticGroup::type_alias_resolved_type].\npub fn type_alias_resolved_type(\n    db: &dyn SemanticGroup,\n    type_alias_id: TypeAliasId,\n) -> Maybe<TypeId> {\n    db.priv_type_alias_semantic_data(type_alias_id)?.resolved_type\n}\n\n/// Query implementation of [crate::db::SemanticGroup::type_alias_generic_params].\npub fn type_alias_generic_params(\n    db: &dyn SemanticGroup,\n    type_alias_id: TypeAliasId,\n) -> Maybe<Vec<GenericParam>> {\n    Ok(db.priv_type_alias_semantic_data(type_alias_id)?.generic_params)\n}\n\n/// Query implementation of [crate::db::SemanticGroup::type_alias_resolved_lookback].\npub fn type_alias_resolved_lookback(\n    db: &dyn SemanticGroup,\n    type_alias_id: TypeAliasId,\n) -> Maybe<Arc<ResolvedLookback>> {\n    Ok(db.priv_type_alias_semantic_data(type_alias_id)?.resolved_lookback)\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse cairo_lang_defs::ids::{LanguageElementId, UseId};\nuse cairo_lang_diagnostics::{Diagnostics, Maybe, ToMaybe};\nuse cairo_lang_proc_macros::DebugWithDb;\nuse cairo_lang_utils::Upcast;\n\nuse crate::db::SemanticGroup;\nuse crate::diagnostic::{NotFoundItemType, SemanticDiagnosticKind, SemanticDiagnostics};\nuse crate::resolve_path::{ResolvedGenericItem, ResolvedLookback, Resolver};\nuse crate::SemanticDiagnostic;\n\n#[derive(Clone, Debug, PartialEq, Eq, DebugWithDb)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct UseData {\n    diagnostics: Diagnostics<SemanticDiagnostic>,\n    resolved_item: Maybe<ResolvedGenericItem>,\n    resolved_lookback: Arc<ResolvedLookback>,\n}\n\n/// Query implementation of [crate::db::SemanticGroup::priv_use_semantic_data].\npub fn priv_use_semantic_data(db: &(dyn SemanticGroup), use_id: UseId) -> Maybe<UseData> {\n    let module_file_id = use_id.module_file_id(db.upcast());\n    let mut diagnostics = SemanticDiagnostics::new(module_file_id);\n    // TODO(spapini): Add generic args when they are supported on structs.\n    let mut resolver = Resolver::new_without_inference(db, module_file_id);\n    // TODO(spapini): when code changes in a file, all the AST items change (as they contain a path\n    // to the green root that changes. Once ASTs are rooted on items, use a selector that picks only\n    // the item instead of all the module data.\n    let module_uses = db.module_uses(module_file_id.0)?;\n    let use_ast = module_uses.get(&use_id).to_maybe()?;\n    let syntax_db = db.upcast();\n    let resolved_item = resolver.resolve_generic_path(\n        &mut diagnostics,\n        &use_ast.name(syntax_db),\n        NotFoundItemType::Identifier,\n    );\n    let resolved_lookback = Arc::new(resolver.lookback);\n    Ok(UseData { diagnostics: diagnostics.build(), resolved_item, resolved_lookback })\n}\n\n/// Cycle handling for [crate::db::SemanticGroup::priv_use_semantic_data].\npub fn priv_use_semantic_data_cycle(\n    db: &dyn SemanticGroup,\n    cycle: &[String],\n    use_id: &UseId,\n) -> Maybe<UseData> {\n    let module_file_id = use_id.module_file_id(db.upcast());\n    let mut diagnostics = SemanticDiagnostics::new(module_file_id);\n    let module_uses = db.module_uses(module_file_id.0)?;\n    let use_ast = module_uses.get(use_id).to_maybe()?;\n    let syntax_db = db.upcast();\n    let err = Err(diagnostics.report(\n        &use_ast.name(syntax_db),\n        if cycle.len() == 1 {\n            // `use bad_name`, finds itself but we don't want to report a cycle in that case.\n            SemanticDiagnosticKind::PathNotFound(NotFoundItemType::Identifier)\n        } else {\n            SemanticDiagnosticKind::UseCycle\n        },\n    ));\n    Ok(UseData {\n        diagnostics: diagnostics.build(),\n        resolved_item: err,\n        resolved_lookback: Arc::new(ResolvedLookback::default()),\n    })\n}\n\n/// Query implementation of [crate::db::SemanticGroup::use_semantic_diagnostics].\npub fn use_semantic_diagnostics(\n    db: &dyn SemanticGroup,\n    use_id: UseId,\n) -> Diagnostics<SemanticDiagnostic> {\n    db.priv_use_semantic_data(use_id).map(|data| data.diagnostics).unwrap_or_default()\n}\n\n/// Query implementation of [crate::db::SemanticGroup::use_resolved_lookback].\npub fn use_resolved_lookback(\n    db: &dyn SemanticGroup,\n    use_id: UseId,\n) -> Maybe<Arc<ResolvedLookback>> {\n    Ok(db.priv_use_semantic_data(use_id)?.resolved_lookback)\n}\n\npub trait SemanticUseEx<'a>: Upcast<dyn SemanticGroup + 'a> {\n    /// Returns the resolved items.\n    ///\n    /// This is not a query as the cycle handling is done in priv_use_semantic_data.\n    fn use_resolved_item(&self, use_id: UseId) -> Maybe<ResolvedGenericItem> {\n        let db = self.upcast();\n        db.priv_use_semantic_data(use_id)?.resolved_item\n    }\n}\n\nimpl<'a, T: Upcast<dyn SemanticGroup + 'a> + ?Sized> SemanticUseEx<'a> for T {}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Semantic model representation and queries for Cairo.\n//! The semantic model represents the Cairo program after type resolution and some syntax\n//! desugaring.\n\npub mod corelib;\npub mod db;\npub mod diagnostic;\npub mod expr;\npub mod items;\npub mod literals;\npub mod patcher;\npub mod plugin;\npub mod resolve_path;\npub mod substitution;\npub mod types;\n\nmod semantic;\n\npub use diagnostic::SemanticDiagnostic;\npub use substitution::SemanticObject;\n\npub use self::semantic::*;\n\n#[cfg(any(feature = \"testing\", test))]\npub mod test_utils;\n\n#[cfg(test)]\nmod test;\n",
    "metadata": {}
  },
  {
    "pageContent": "use num_bigint::BigInt;\nuse num_traits::Num;\nuse smol_str::SmolStr;\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq)]\npub struct LiteralLongId {\n    pub value: BigInt,\n}\n\nimpl TryFrom<SmolStr> for LiteralLongId {\n    type Error = ();\n\n    fn try_from(text: SmolStr) -> Result<Self, Self::Error> {\n        Ok(Self {\n            value: match text.strip_prefix(\"0x\") {\n                Some(num_no_prefix) => BigInt::from_str_radix(num_no_prefix, 16),\n                None => text.parse::<BigInt>(),\n            }\n            .map_err(|_| ())?,\n        })\n    }\n}\n\nuse cairo_lang_utils::define_short_id;\n\nuse crate::db::SemanticGroup;\n\ndefine_short_id!(LiteralId, LiteralLongId, SemanticGroup, lookup_intern_literal);\nimpl LiteralId {\n    pub fn format(&self, db: &dyn SemanticGroup) -> String {\n        db.lookup_intern_literal(*self).value.to_string()\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashMap;\n\nuse cairo_lang_defs::db::DefsGroup;\nuse cairo_lang_filesystem::span::{TextOffset, TextSpan, TextWidth};\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::{SyntaxNode, TypedSyntaxNode};\nuse cairo_lang_utils::extract_matches;\n\n/// Interface for modifying syntax nodes.\n#[derive(Clone, Debug, PartialEq, Eq)]\npub enum RewriteNode {\n    /// A rewrite node that represents a trimmed copy of a syntax node:\n    /// one with the leading and trailing trivia excluded.\n    Trimmed {\n        node: SyntaxNode,\n        trim_left: bool,\n        trim_right: bool,\n    },\n    Copied(SyntaxNode),\n    Modified(ModifiedNode),\n    Text(String),\n}\nimpl RewriteNode {\n    pub fn new_trimmed(syntax_node: SyntaxNode) -> Self {\n        Self::Trimmed { node: syntax_node, trim_left: true, trim_right: true }\n    }\n\n    pub fn new_modified(children: Vec<RewriteNode>) -> Self {\n        Self::Modified(ModifiedNode { children: Some(children) })\n    }\n\n    /// Creates a rewrite node from an AST object.\n    pub fn from_ast<T: TypedSyntaxNode>(node: &T) -> Self {\n        RewriteNode::Copied(node.as_syntax_node())\n    }\n\n    /// Prepares a node for modification.\n    pub fn modify(&mut self, db: &dyn SyntaxGroup) -> &mut ModifiedNode {\n        match self {\n            RewriteNode::Copied(syntax_node) => {\n                *self = RewriteNode::new_modified(\n                    syntax_node.children(db).map(RewriteNode::Copied).collect(),\n                );\n                extract_matches!(self, RewriteNode::Modified)\n            }\n\n            RewriteNode::Trimmed { node, trim_left, trim_right } => {\n                let num_children = node.children(db).len();\n                let mut new_children = Vec::new();\n\n                // Get the index of the leftmost nonempty child.\n                let Some(left_idx) = node.children(db).position(|child| child.width(db) != TextWidth::default()) else {\n                    *self = RewriteNode::Modified(ModifiedNode { children: None });\n                    return extract_matches!(self, RewriteNode::Modified);\n                };\n                // Get the index of the rightmost nonempty child.\n                let right_idx = node\n                    .children(db)\n                    .rposition(|child| child.width(db) != TextWidth::default())\n                    .unwrap();\n                new_children.extend(itertools::repeat_n(\n                    RewriteNode::Modified(ModifiedNode { children: None }),\n                    left_idx,\n                ));\n\n                // The number of children between the first and last nonempty nodes.\n                let num_middle = right_idx - left_idx + 1;\n                let mut children_iter = node.children(db).skip(left_idx);\n                match num_middle {\n                    1 => {\n                        new_children.push(RewriteNode::Trimmed {\n                            node: children_iter.next().unwrap(),\n                            trim_left: *trim_left,\n                            trim_right: *trim_right,\n                        });\n                    }\n                    _ => {\n                        new_children.push(RewriteNode::Trimmed {\n                            node: children_iter.next().unwrap(),\n                            trim_left: *trim_left,\n                            trim_right: false,\n                        });\n                        for _ in 0..(num_middle - 2) {\n                            let child = children_iter.next().unwrap();\n                            new_children.push(RewriteNode::Copied(child));\n                        }\n                        new_children.push(RewriteNode::Trimmed {\n                            node: children_iter.next().unwrap(),\n                            trim_left: false,\n                            trim_right: *trim_right,\n                        });\n                    }\n                };\n                new_children.extend(itertools::repeat_n(\n                    RewriteNode::Modified(ModifiedNode { children: None }),\n                    num_children - right_idx - 1,\n                ));\n\n                *self = RewriteNode::Modified(ModifiedNode { children: Some(new_children) });\n                extract_matches!(self, RewriteNode::Modified)\n            }\n            RewriteNode::Modified(modified) => modified,\n            RewriteNode::Text(_) => panic!(\"A text node can't be modified\"),\n        }\n    }\n\n    /// Prepares a node for modification and returns a specific child.\n    pub fn modify_child(&mut self, db: &dyn SyntaxGroup, index: usize) -> &mut RewriteNode {\n        if matches!(self, RewriteNode::Modified(ModifiedNode { children: None })) {\n            // Modification of an empty node is idempotent.\n            return self;\n        }\n        &mut self.modify(db).children.as_mut().unwrap()[index]\n    }\n\n    /// Replaces this node with text.\n    pub fn set_str(&mut self, s: String) {\n        *self = RewriteNode::Text(s)\n    }\n    /// Creates a new Rewrite node by interpolating a string with patches.\n    /// Each substring of the form `$<name>$` is replaced with syntax nodes from `patches`.\n    /// A `$$` substring is replaced with `$`.\n    pub fn interpolate_patched(code: &str, patches: HashMap<String, RewriteNode>) -> RewriteNode {\n        let mut chars = code.chars().peekable();\n        let mut pending_text = String::new();\n        let mut children = Vec::new();\n        while let Some(c) = chars.next() {\n            if c != '$' {\n                pending_text.push(c);\n                continue;\n            }\n\n            // An opening $ was detected.\n\n            // Read the name\n            let mut name = String::new();\n            for c in chars.by_ref() {\n                if c == '$' {\n                    break;\n                }\n                name.push(c);\n            }\n\n            // A closing $ was found.\n            // If the string between the `$`s is empty - push a single `$` to the output.\n            if name.is_empty() {\n                pending_text.push('$');\n                continue;\n            }\n            // If the string wasn't empty and there is some pending text, first flush it as a text\n            // child.\n            if !pending_text.is_empty() {\n                children.push(RewriteNode::Text(pending_text.clone()));\n                pending_text.clear();\n            }\n            // Replace the substring with the relevant rewrite node.\n            // TODO(yuval): this currently panics. Fix it.\n            children.push(patches[&name].clone());\n        }\n        // Flush the remaining text as a text child.\n        if !pending_text.is_empty() {\n            children.push(RewriteNode::Text(pending_text.clone()));\n        }\n\n        RewriteNode::new_modified(children)\n    }\n}\nimpl From<SyntaxNode> for RewriteNode {\n    fn from(node: SyntaxNode) -> Self {\n        RewriteNode::Copied(node)\n    }\n}\n\n/// A modified rewrite node.\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct ModifiedNode {\n    /// Children of the node.\n    /// Can be None, in which case this is an empty node (of width 0). It's not the same as\n    /// Some(vec![]) - None can be (idempotently) modified, whereas modifying Some(vec![]) would\n    /// panic.\n    pub children: Option<Vec<RewriteNode>>,\n}\n\n#[derive(Debug, PartialEq, Eq)]\npub struct Patch {\n    span: TextSpan,\n    origin_span: TextSpan,\n}\n\n#[derive(Debug, Default, PartialEq, Eq)]\npub struct Patches {\n    patches: Vec<Patch>,\n}\nimpl Patches {\n    pub fn translate(&self, _db: &dyn DefsGroup, span: TextSpan) -> Option<TextSpan> {\n        for Patch { span: patch_span, origin_span } in &self.patches {\n            if patch_span.contains(span) {\n                let start = origin_span.start.add_width(span.start - patch_span.start);\n                return Some(TextSpan { start, end: start.add_width(span.end - span.start) });\n            }\n        }\n        None\n    }\n}\n\npub struct PatchBuilder<'a> {\n    pub db: &'a dyn SyntaxGroup,\n    pub code: String,\n    pub patches: Patches,\n}\nimpl<'a> PatchBuilder<'a> {\n    pub fn new(db: &'a dyn SyntaxGroup) -> Self {\n        Self { db, code: String::default(), patches: Patches::default() }\n    }\n\n    pub fn add_char(&mut self, c: char) {\n        self.code.push(c);\n    }\n\n    pub fn add_str(&mut self, s: &str) {\n        self.code += s;\n    }\n\n    pub fn add_modified(&mut self, node: RewriteNode) {\n        match node {\n            RewriteNode::Copied(node) => self.add_node(node),\n            RewriteNode::Trimmed { node, trim_left, trim_right } => {\n                self.add_trimmed_node(node, trim_left, trim_right)\n            }\n            RewriteNode::Modified(modified) => {\n                if let Some(children) = modified.children {\n                    for child in children {\n                        self.add_modified(child)\n                    }\n                }\n            }\n            RewriteNode::Text(s) => self.add_str(s.as_str()),\n        }\n    }\n\n    pub fn add_node(&mut self, node: SyntaxNode) {\n        let orig_span = node.span(self.db);\n        let start = TextOffset::default().add_width(TextWidth::from_str(&self.code));\n        self.patches.patches.push(Patch {\n            span: TextSpan { start, end: start.add_width(orig_span.end - orig_span.start) },\n            origin_span: node.span(self.db),\n        });\n        self.code += node.get_text(self.db).as_str();\n    }\n\n    fn add_trimmed_node(&mut self, node: SyntaxNode, trim_left: bool, trim_right: bool) {\n        let TextSpan { start: trimmed_start, end: trimmed_end } = node.span_without_trivia(self.db);\n        let orig_start = if trim_left { trimmed_start } else { node.span(self.db).start };\n        let orig_end = if trim_right { trimmed_end } else { node.span(self.db).end };\n        let origin_span = TextSpan { start: orig_start, end: orig_end };\n\n        let text = node.get_text_of_span(self.db, origin_span);\n        let start = TextOffset::default().add_width(TextWidth::from_str(&self.code));\n\n        self.code += &text;\n\n        self.patches.patches.push(Patch {\n            span: TextSpan { start, end: start.add_width(TextWidth::from_str(&text)) },\n            origin_span,\n        });\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::any::Any;\nuse std::ops::Deref;\nuse std::sync::Arc;\n\nuse cairo_lang_defs::plugin::{GeneratedFileAuxData, MacroPlugin};\nuse cairo_lang_filesystem::span::TextSpan;\n\nuse crate::db::SemanticGroup;\n\npub trait SemanticPlugin: std::fmt::Debug + Sync + Send + AsDynMacroPlugin {}\n\npub trait AsDynMacroPlugin {\n    fn as_dyn_macro_plugin<'a>(self: Arc<Self>) -> Arc<dyn MacroPlugin + 'a>\n    where\n        Self: 'a;\n}\n\n/// A trait for Plugins auxiliary data.\n///\n/// The auxiliary data can assist in mapping plugin generated diagnostics to more readable\n/// diagnostics.\npub trait PluginAuxData:\n    std::fmt::Debug + Sync + Send + GeneratedFileAuxData + AsDynGeneratedFileAuxData\n{\n    fn map_diag(\n        &self,\n        db: &(dyn SemanticGroup + 'static),\n        diag: &dyn Any,\n    ) -> Option<PluginMappedDiagnostic>;\n}\npub trait AsDynGeneratedFileAuxData {\n    fn as_dyn_macro_token(&self) -> &(dyn GeneratedFileAuxData + 'static);\n}\n\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct PluginMappedDiagnostic {\n    pub span: TextSpan,\n    pub message: String,\n}\n\n// `dyn` wrapper for `PluginAuxData`.\n#[derive(Clone, Debug)]\npub struct DynPluginAuxData(pub Arc<dyn PluginAuxData>);\nimpl DynPluginAuxData {\n    pub fn new<T: PluginAuxData + 'static>(aux_data: T) -> Self {\n        DynPluginAuxData(Arc::new(aux_data))\n    }\n}\nimpl Deref for DynPluginAuxData {\n    type Target = Arc<dyn PluginAuxData>;\n\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\nimpl GeneratedFileAuxData for DynPluginAuxData {\n    fn as_any(&self) -> &dyn Any {\n        self\n    }\n\n    fn eq(&self, other: &dyn GeneratedFileAuxData) -> bool {\n        if let Some(other) = other.as_any().downcast_ref::<DynPluginAuxData>() {\n            self.0.eq(other.0.as_dyn_macro_token())\n        } else {\n            false\n        }\n    }\n}\n\n#[derive(Debug, PartialEq, Eq)]\npub struct TrivialPluginAuxData {}\nimpl GeneratedFileAuxData for TrivialPluginAuxData {\n    fn as_any(&self) -> &dyn Any {\n        self\n    }\n\n    fn eq(&self, other: &dyn GeneratedFileAuxData) -> bool {\n        if let Some(other) = other.as_any().downcast_ref::<Self>() { self == other } else { false }\n    }\n}\nimpl AsDynGeneratedFileAuxData for TrivialPluginAuxData {\n    fn as_dyn_macro_token(&self) -> &(dyn GeneratedFileAuxData + 'static) {\n        self\n    }\n}\nimpl PluginAuxData for TrivialPluginAuxData {\n    fn map_diag(\n        &self,\n        _db: &dyn SemanticGroup,\n        _diag: &dyn std::any::Any,\n    ) -> Option<PluginMappedDiagnostic> {\n        None\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "#[cfg(test)]\n#[path = \"resolve_path_test.rs\"]\nmod test;\n\nuse std::iter::Peekable;\n\nuse cairo_lang_defs::ids::{\n    ConstantId, GenericTypeId, ImplDefId, LanguageElementId, ModuleFileId, ModuleId, ModuleItemId,\n    TraitFunctionId, TraitId, TypeAliasId,\n};\nuse cairo_lang_diagnostics::Maybe;\nuse cairo_lang_filesystem::ids::CrateLongId;\nuse cairo_lang_proc_macros::DebugWithDb;\nuse cairo_lang_syntax as syntax;\nuse cairo_lang_syntax::node::helpers::PathSegmentEx;\nuse cairo_lang_syntax::node::ids::SyntaxStablePtrId;\nuse cairo_lang_syntax::node::{ast, Terminal, TypedSyntaxNode};\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse cairo_lang_utils::try_extract_matches;\nuse cairo_lang_utils::unordered_hash_map::UnorderedHashMap;\nuse itertools::Itertools;\nuse smol_str::SmolStr;\n\nuse crate::corelib::core_module;\nuse crate::db::SemanticGroup;\nuse crate::diagnostic::SemanticDiagnosticKind::*;\nuse crate::diagnostic::{NotFoundItemType, SemanticDiagnostics};\nuse crate::expr::inference::Inference;\nuse crate::items::enm::{ConcreteVariant, SemanticEnumEx};\nuse crate::items::functions::{GenericFunctionId, ImplGenericFunctionId};\nuse crate::items::imp::{ConcreteImplId, ConcreteImplLongId, ImplId, ImplLookupContext};\nuse crate::items::trt::{\n    ConcreteTraitGenericFunctionId, ConcreteTraitGenericFunctionLongId, ConcreteTraitId,\n    ConcreteTraitLongId,\n};\nuse crate::items::us::SemanticUseEx;\nuse crate::literals::LiteralLongId;\nuse crate::substitution::{GenericSubstitution, SemanticRewriter, SubstitutionRewriter};\nuse crate::types::resolve_type;\nuse crate::{\n    ConcreteFunction, ConcreteTypeId, FunctionId, FunctionLongId, GenericArgumentId, GenericParam,\n    TypeId, TypeLongId, Variant,\n};\n\n// Resolved items:\n// ResolvedConcreteItem - returned by resolve_concrete_path(). Paths with generic arguments.\n// ResolvedGenericItem - returned by resolve_generic_path(). Paths without generic arguments.\n#[derive(Clone, PartialEq, Eq, Debug, DebugWithDb)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub enum ResolvedConcreteItem {\n    Constant(ConstantId),\n    Module(ModuleId),\n    Function(FunctionId),\n    TraitFunction(ConcreteTraitGenericFunctionId),\n    Type(TypeId),\n    Variant(ConcreteVariant),\n    Trait(ConcreteTraitId),\n    Impl(ImplId),\n}\n#[derive(Clone, PartialEq, Eq, Debug, DebugWithDb)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub enum ResolvedGenericItem {\n    Constant(ConstantId),\n    Module(ModuleId),\n    GenericFunction(GenericFunctionId),\n    TraitFunction(TraitFunctionId),\n    GenericType(GenericTypeId),\n    GenericTypeAlias(TypeAliasId),\n    Variant(Variant),\n    Trait(TraitId),\n    Impl(ImplDefId),\n}\nimpl ResolvedConcreteItem {\n    pub fn generic(&self, db: &dyn SemanticGroup) -> Option<ResolvedGenericItem> {\n        Some(match self {\n            ResolvedConcreteItem::Constant(id) => ResolvedGenericItem::Constant(*id),\n            ResolvedConcreteItem::Module(item) => ResolvedGenericItem::Module(*item),\n            ResolvedConcreteItem::Function(function) => ResolvedGenericItem::GenericFunction(\n                db.lookup_intern_function(*function).function.generic_function,\n            ),\n            ResolvedConcreteItem::TraitFunction(trait_function) => {\n                ResolvedGenericItem::TraitFunction(trait_function.function_id(db))\n            }\n            ResolvedConcreteItem::Type(ty) => {\n                if let TypeLongId::Concrete(concrete) = db.lookup_intern_type(*ty) {\n                    ResolvedGenericItem::GenericType(concrete.generic_type(db))\n                } else {\n                    return None;\n                }\n            }\n            ResolvedConcreteItem::Variant(ConcreteVariant { concrete_enum_id, id, ty, idx }) => {\n                ResolvedGenericItem::Variant(Variant {\n                    enum_id: concrete_enum_id.enum_id(db),\n                    id: *id,\n                    ty: *ty,\n                    idx: *idx,\n                })\n            }\n            ResolvedConcreteItem::Trait(concrete_trait) => ResolvedGenericItem::Trait(\n                db.lookup_intern_concrete_trait(*concrete_trait).trait_id,\n            ),\n            ResolvedConcreteItem::Impl(impl_id) => match impl_id {\n                ImplId::Concrete(concrete_impl_id) => ResolvedGenericItem::Impl(\n                    db.lookup_intern_concrete_impl(*concrete_impl_id).impl_def_id,\n                ),\n                ImplId::GenericParameter(_) | ImplId::ImplVar(_) => return None,\n            },\n        })\n    }\n}\n\n/// Lookback maps for item resolving. Can be used to quickly check what is the semantic resolution\n/// of any path segment.\n#[derive(Clone, Default, Debug, PartialEq, Eq, DebugWithDb)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct ResolvedLookback {\n    pub concrete: UnorderedHashMap<ast::TerminalIdentifierPtr, ResolvedConcreteItem>,\n    pub generic: UnorderedHashMap<ast::TerminalIdentifierPtr, ResolvedGenericItem>,\n}\nimpl ResolvedLookback {\n    // Relates a path segment to a ResolvedConcreteItem, and adds to a lookback map. This will be\n    // used in \"Go to definition\".\n    pub fn mark_concrete(\n        &mut self,\n        db: &dyn SemanticGroup,\n        segment: &syntax::node::ast::PathSegment,\n        resolved_item: ResolvedConcreteItem,\n    ) -> ResolvedConcreteItem {\n        let identifier = segment.identifier_ast(db.upcast());\n        if let Some(generic_item) = resolved_item.generic(db) {\n            // Mark the generic item as well, for language server lookback.\n            self.generic.insert(identifier.stable_ptr(), generic_item);\n        }\n        self.concrete.insert(identifier.stable_ptr(), resolved_item.clone());\n        resolved_item\n    }\n    // Relates a path segment to a ResolvedGenericItem, and adds to a lookback map. This will be\n    // used in \"Go to definition\".\n    pub fn mark_generic(\n        &mut self,\n        db: &dyn SemanticGroup,\n        segment: &syntax::node::ast::PathSegment,\n        resolved_item: ResolvedGenericItem,\n    ) -> ResolvedGenericItem {\n        let identifier = segment.identifier_ast(db.upcast());\n        self.generic.insert(identifier.stable_ptr(), resolved_item.clone());\n        resolved_item\n    }\n}\n\n/// Resolves paths semantically.\npub struct Resolver<'db> {\n    db: &'db dyn SemanticGroup,\n    // Current module in which to resolve the path.\n    pub module_file_id: ModuleFileId,\n    // Generic parameters accessible to the resolver.\n    generic_params: OrderedHashMap<SmolStr, GenericParam>,\n    // Lookback map for resolved identifiers in path. Used in \"Go to definition\".\n    pub lookback: ResolvedLookback,\n    pub inference: Inference<'db>,\n}\nimpl<'db> Resolver<'db> {\n    pub fn new_with_inference(db: &'db dyn SemanticGroup, module_file_id: ModuleFileId) -> Self {\n        Self {\n            db,\n            module_file_id,\n            generic_params: Default::default(),\n            lookback: ResolvedLookback::default(),\n            inference: Inference::new(db),\n        }\n    }\n\n    pub fn new_without_inference(db: &'db dyn SemanticGroup, module_file_id: ModuleFileId) -> Self {\n        Self {\n            db,\n            module_file_id,\n            generic_params: Default::default(),\n            lookback: ResolvedLookback::default(),\n            inference: Inference::new(db),\n        }\n    }\n\n    /// Adds a generic param to an existing resolver.\n    /// This is required since a resolver needs to exist before resolving the generic params,\n    /// and thus, they are added to the Resolver only after they are resolved.\n    pub fn add_generic_param(&mut self, generic_param: GenericParam) {\n        self.generic_params.insert(generic_param.id().name(self.db.upcast()), generic_param);\n    }\n\n    /// Resolves a concrete item, given a path.\n    /// Guaranteed to result in at most one diagnostic.\n    pub fn resolve_concrete_path(\n        &mut self,\n        diagnostics: &mut SemanticDiagnostics,\n        path: &ast::ExprPath,\n        item_type: NotFoundItemType,\n    ) -> Maybe<ResolvedConcreteItem> {\n        let syntax_db = self.db.upcast();\n        let elements_vec = path.elements(syntax_db);\n        let mut segments = elements_vec.iter().peekable();\n\n        // Find where the first segment lies in.\n        let mut item = self.resolve_concrete_path_first_segment(diagnostics, &mut segments)?;\n\n        // Follow modules.\n        while segments.peek().is_some() {\n            let segment = segments.next().unwrap();\n            let identifier = segment.identifier_ast(syntax_db);\n            let generic_args = segment.generic_args(syntax_db);\n\n            // If this is not the last segment, set the expected type to\n            // [NotFoundItemType::Identifier].\n            let cur_item_type =\n                if segments.peek().is_some() { NotFoundItemType::Identifier } else { item_type };\n            item = self.resolve_next_concrete(\n                diagnostics,\n                &item,\n                &identifier,\n                generic_args,\n                cur_item_type,\n            )?;\n            self.lookback.mark_concrete(self.db, segment, item.clone());\n        }\n        Ok(item)\n    }\n\n    /// Resolves the first segment of a concrete path.\n    fn resolve_concrete_path_first_segment(\n        &mut self,\n        diagnostics: &mut SemanticDiagnostics,\n        segments: &mut Peekable<std::slice::Iter<'_, ast::PathSegment>>,\n    ) -> Maybe<ResolvedConcreteItem> {\n        if let Some(base_module) = self.try_handle_super_segments(diagnostics, segments) {\n            return Ok(ResolvedConcreteItem::Module(base_module?));\n        }\n        let syntax_db = self.db.upcast();\n        Ok(match segments.peek().unwrap() {\n            syntax::node::ast::PathSegment::WithGenericArgs(generic_segment) => {\n                let identifier = generic_segment.ident(syntax_db);\n                // Identifier with generic args cannot be a local item.\n                if let Some(module_id) = self.determine_base_module(&identifier) {\n                    ResolvedConcreteItem::Module(module_id)\n                } else {\n                    // Crates do not have generics.\n                    return Err(diagnostics\n                        .report(&generic_segment.generic_args(syntax_db), UnexpectedGenericArgs));\n                }\n            }\n            syntax::node::ast::PathSegment::Simple(simple_segment) => {\n                let identifier = simple_segment.ident(syntax_db);\n                if let Some(local_item) = self.determine_base_item_in_local_scope(&identifier) {\n                    self.lookback.mark_concrete(self.db, segments.next().unwrap(), local_item)\n                } else if let Some(module_id) = self.determine_base_module(&identifier) {\n                    // This item lies inside a module.\n                    ResolvedConcreteItem::Module(module_id)\n                } else {\n                    // This identifier is a crate.\n                    self.lookback.mark_concrete(\n                        self.db,\n                        segments.next().unwrap(),\n                        ResolvedConcreteItem::Module(ModuleId::CrateRoot(\n                            self.db.intern_crate(CrateLongId(identifier.text(syntax_db))),\n                        )),\n                    )\n                }\n            }\n        })\n    }\n\n    /// Resolves a generic item, given a path.\n    /// Guaranteed to result in at most one diagnostic.\n    pub fn resolve_generic_path(\n        &mut self,\n        diagnostics: &mut SemanticDiagnostics,\n        path: &ast::ExprPath,\n        item_type: NotFoundItemType,\n    ) -> Maybe<ResolvedGenericItem> {\n        let syntax_db = self.db.upcast();\n        let elements_vec = path.elements(syntax_db);\n        let mut segments = elements_vec.iter().peekable();\n\n        // Find where the first segment lies in.\n        let mut item = self.resolve_generic_path_first_segment(diagnostics, &mut segments)?;\n\n        // Follow modules.\n        while segments.peek().is_some() {\n            let segment = segments.next().unwrap();\n            let identifier = match segment {\n                syntax::node::ast::PathSegment::WithGenericArgs(segment) => {\n                    return Err(\n                        diagnostics.report(&segment.generic_args(syntax_db), UnexpectedGenericArgs)\n                    );\n                }\n                syntax::node::ast::PathSegment::Simple(segment) => segment.ident(syntax_db),\n            };\n\n            // If this is not the last segment, set the expected type to\n            // [NotFoundItemType::Identifier].\n            let cur_item_type =\n                if segments.peek().is_some() { NotFoundItemType::Identifier } else { item_type };\n            item = self.resolve_next_generic(diagnostics, &item, &identifier, cur_item_type)?;\n            self.lookback.mark_generic(self.db, segment, item.clone());\n        }\n        Ok(item)\n    }\n\n    /// Resolves the first segment of a generic path.\n    fn resolve_generic_path_first_segment(\n        &mut self,\n        diagnostics: &mut SemanticDiagnostics,\n        segments: &mut Peekable<std::slice::Iter<'_, ast::PathSegment>>,\n    ) -> Maybe<ResolvedGenericItem> {\n        if let Some(base_module) = self.try_handle_super_segments(diagnostics, segments) {\n            return Ok(ResolvedGenericItem::Module(base_module?));\n        }\n        let syntax_db = self.db.upcast();\n        Ok(match segments.peek().unwrap() {\n            syntax::node::ast::PathSegment::WithGenericArgs(generic_segment) => {\n                return Err(diagnostics\n                    .report(&generic_segment.generic_args(syntax_db), UnexpectedGenericArgs));\n            }\n            syntax::node::ast::PathSegment::Simple(simple_segment) => {\n                let identifier = simple_segment.ident(syntax_db);\n                if let Some(module_id) = self.determine_base_module(&identifier) {\n                    // This item lies inside a module.\n                    ResolvedGenericItem::Module(module_id)\n                } else {\n                    // This identifier is a crate.\n                    self.lookback.mark_generic(\n                        self.db,\n                        segments.next().unwrap(),\n                        ResolvedGenericItem::Module(ModuleId::CrateRoot(\n                            self.db.intern_crate(CrateLongId(identifier.text(syntax_db))),\n                        )),\n                    )\n                }\n            }\n        })\n    }\n\n    /// Handles `super::` initial segments, by removing them, and returning the valid module if\n    /// exists. If there's none - returns None.\n    /// If there are, but that's an invalid path, adds to diagnostics and returns `Some(Err)`.\n    fn try_handle_super_segments(\n        &self,\n        diagnostics: &mut SemanticDiagnostics,\n        segments: &mut Peekable<std::slice::Iter<'_, ast::PathSegment>>,\n    ) -> Option<Maybe<ModuleId>> {\n        let syntax_db = self.db.upcast();\n        let mut module_id = self.module_file_id.0;\n        for segment in segments.peeking_take_while(|segment| match segment {\n            ast::PathSegment::WithGenericArgs(_) => false,\n            ast::PathSegment::Simple(simple) => simple.ident(syntax_db).text(syntax_db) == \"super\",\n        }) {\n            module_id = match module_id {\n                ModuleId::CrateRoot(_) => {\n                    return Some(Err(diagnostics.report(segment, SuperUsedInRootModule)));\n                }\n                ModuleId::Submodule(submodule_id) => submodule_id.parent_module(self.db.upcast()),\n            };\n        }\n        if module_id == self.module_file_id.0 { None } else { Some(Ok(module_id)) }\n    }\n\n    /// Given the current resolved item, resolves the next segment.\n    fn resolve_next_concrete(\n        &mut self,\n        diagnostics: &mut SemanticDiagnostics,\n        item: &ResolvedConcreteItem,\n        identifier: &ast::TerminalIdentifier,\n        generic_args_syntax: Option<Vec<ast::GenericArg>>,\n        item_type: NotFoundItemType,\n    ) -> Maybe<ResolvedConcreteItem> {\n        let syntax_db = self.db.upcast();\n        let ident = identifier.text(syntax_db);\n        match item {\n            ResolvedConcreteItem::Module(module_id) => {\n                if ident == \"super\" {\n                    return Err(diagnostics.report(identifier, InvalidPath));\n                }\n                let module_item = self\n                    .db\n                    .module_item_by_name(*module_id, ident)?\n                    .ok_or_else(|| diagnostics.report(identifier, PathNotFound(item_type)))?;\n                let generic_item = self.module_item_to_generic_item(diagnostics, module_item)?;\n                Ok(self.specialize_generic_module_item(\n                    diagnostics,\n                    identifier,\n                    generic_item,\n                    generic_args_syntax,\n                )?)\n            }\n            ResolvedConcreteItem::Type(ty) => {\n                if let TypeLongId::Concrete(ConcreteTypeId::Enum(concrete_enum_id)) =\n                    self.db.lookup_intern_type(*ty)\n                {\n                    let enum_id = concrete_enum_id.enum_id(self.db);\n                    let variants = self\n                        .db\n                        .enum_variants(enum_id)\n                        .map_err(|_| diagnostics.report(identifier, UnknownEnum))?;\n                    let variant_id = variants.get(&ident).ok_or_else(|| {\n                        diagnostics\n                            .report(identifier, NoSuchVariant { enum_id, variant_name: ident })\n                    })?;\n                    let variant = self.db.variant_semantic(enum_id, *variant_id)?;\n                    let concrete_variant =\n                        self.db.concrete_enum_variant(concrete_enum_id, &variant)?;\n                    Ok(ResolvedConcreteItem::Variant(concrete_variant))\n                } else {\n                    Err(diagnostics.report(identifier, InvalidPath))\n                }\n            }\n            ResolvedConcreteItem::Trait(concrete_trait_id) => {\n                // Find the relevant function in the trait.\n                let long_trait_id = self.db.lookup_intern_concrete_trait(*concrete_trait_id);\n                let trait_id = long_trait_id.trait_id;\n                let Some(trait_function_id) = self.db.trait_function_by_name(trait_id, ident)? else {\n                    return Err(diagnostics.report(identifier, InvalidPath));\n                };\n\n                let concrete_trait_function = self.db.intern_concrete_trait_function(\n                    ConcreteTraitGenericFunctionLongId::new(\n                        self.db,\n                        *concrete_trait_id,\n                        trait_function_id,\n                    ),\n                );\n                let generic_function = self\n                    .inference\n                    .infer_trait_generic_function(\n                        concrete_trait_function,\n                        &self.impl_lookup_context(),\n                        identifier.stable_ptr().untyped(),\n                    )\n                    .map_err(|err| err.report(diagnostics, identifier.stable_ptr().untyped()))?;\n\n                Ok(ResolvedConcreteItem::Function(self.specialize_function(\n                    diagnostics,\n                    identifier.stable_ptr().untyped(),\n                    generic_function,\n                    generic_args_syntax.unwrap_or_default(),\n                )?))\n            }\n            ResolvedConcreteItem::Impl(impl_id) => {\n                let concrete_trait_id = self.db.impl_concrete_trait(*impl_id)?;\n                let trait_id = concrete_trait_id.trait_id(self.db);\n                let Some(trait_function_id) = self.db.trait_function_by_name(\n                    trait_id, ident,\n                )? else {\n                    return Err(diagnostics.report(identifier, InvalidPath));\n                };\n                let generic_function_id = GenericFunctionId::Impl(ImplGenericFunctionId {\n                    impl_id: *impl_id,\n                    function: trait_function_id,\n                });\n\n                Ok(ResolvedConcreteItem::Function(self.specialize_function(\n                    diagnostics,\n                    identifier.stable_ptr().untyped(),\n                    generic_function_id,\n                    generic_args_syntax.unwrap_or_default(),\n                )?))\n            }\n            _ => Err(diagnostics.report(identifier, InvalidPath)),\n        }\n    }\n\n    /// Specializes a ResolvedGenericItem that came from a ModuleItem.\n    fn specialize_generic_module_item(\n        &mut self,\n        diagnostics: &mut SemanticDiagnostics,\n        identifier: &syntax::node::ast::TerminalIdentifier,\n        generic_item: ResolvedGenericItem,\n        generic_args_syntax: Option<Vec<ast::GenericArg>>,\n    ) -> Maybe<ResolvedConcreteItem> {\n        Ok(match generic_item {\n            ResolvedGenericItem::Constant(id) => ResolvedConcreteItem::Constant(id),\n            ResolvedGenericItem::Module(module_id) => {\n                if generic_args_syntax.is_some() {\n                    return Err(diagnostics.report(identifier, UnexpectedGenericArgs));\n                }\n                ResolvedConcreteItem::Module(module_id)\n            }\n            ResolvedGenericItem::GenericFunction(generic_function) => {\n                ResolvedConcreteItem::Function(self.specialize_function(\n                    diagnostics,\n                    identifier.stable_ptr().untyped(),\n                    generic_function,\n                    generic_args_syntax.unwrap_or_default(),\n                )?)\n            }\n            ResolvedGenericItem::GenericType(generic_type) => {\n                ResolvedConcreteItem::Type(self.specialize_type(\n                    diagnostics,\n                    identifier.stable_ptr().untyped(),\n                    generic_type,\n                    generic_args_syntax.unwrap_or_default(),\n                )?)\n            }\n            ResolvedGenericItem::GenericTypeAlias(type_alias_id) => {\n                // Check for cycles in this type alias definition.\n                // TODO(orizi): Handle this without using `priv_type_alias_semantic_data`.\n                self.db.priv_type_alias_semantic_data(type_alias_id)?.check_no_cycle()?;\n\n                let ty = self.db.type_alias_resolved_type(type_alias_id)?;\n                let generic_params = self.db.type_alias_generic_params(type_alias_id)?;\n                let generic_args = self.resolve_generic_args(\n                    diagnostics,\n                    &generic_params,\n                    generic_args_syntax.unwrap_or_default(),\n                    identifier.stable_ptr().untyped(),\n                )?;\n                let substitution = GenericSubstitution::new(&generic_params, &generic_args);\n                let ty = SubstitutionRewriter { db: self.db, substitution: &substitution }\n                    .rewrite(ty)?;\n                ResolvedConcreteItem::Type(ty)\n            }\n            ResolvedGenericItem::Trait(trait_id) => {\n                ResolvedConcreteItem::Trait(self.specialize_trait(\n                    diagnostics,\n                    identifier.stable_ptr().untyped(),\n                    trait_id,\n                    generic_args_syntax.unwrap_or_default(),\n                )?)\n            }\n            ResolvedGenericItem::Impl(impl_def_id) => {\n                ResolvedConcreteItem::Impl(ImplId::Concrete(self.specialize_impl(\n                    diagnostics,\n                    identifier.stable_ptr().untyped(),\n                    impl_def_id,\n                    generic_args_syntax.unwrap_or_default(),\n                )?))\n            }\n            ResolvedGenericItem::Variant(_) => panic!(\"Variant is not a module item.\"),\n            ResolvedGenericItem::TraitFunction(_) => panic!(\"TraitFunction is not a module item.\"),\n        })\n    }\n\n    /// Given the current resolved item, resolves the next segment.\n    fn resolve_next_generic(\n        &mut self,\n        diagnostics: &mut SemanticDiagnostics,\n        item: &ResolvedGenericItem,\n        identifier: &ast::TerminalIdentifier,\n        item_type: NotFoundItemType,\n    ) -> Maybe<ResolvedGenericItem> {\n        let syntax_db = self.db.upcast();\n        let ident = identifier.text(syntax_db);\n        match item {\n            ResolvedGenericItem::Module(module_id) => {\n                let module_item = self\n                    .db\n                    .module_item_by_name(*module_id, ident)?\n                    .ok_or_else(|| diagnostics.report(identifier, PathNotFound(item_type)))?;\n                self.module_item_to_generic_item(diagnostics, module_item)\n            }\n            ResolvedGenericItem::GenericType(GenericTypeId::Enum(enum_id)) => {\n                let variants = self.db.enum_variants(*enum_id)?;\n                let variant_id = variants.get(&ident).ok_or_else(|| {\n                    diagnostics.report(\n                        identifier,\n                        NoSuchVariant { enum_id: *enum_id, variant_name: ident },\n                    )\n                })?;\n                let variant = self.db.variant_semantic(*enum_id, *variant_id)?;\n                Ok(ResolvedGenericItem::Variant(variant))\n            }\n            _ => Err(diagnostics.report(identifier, InvalidPath)),\n        }\n    }\n\n    /// Wraps a ModuleItem with the corresponding ResolveGenericItem.\n    fn module_item_to_generic_item(\n        &mut self,\n        diagnostics: &mut SemanticDiagnostics,\n        module_item: ModuleItemId,\n    ) -> Maybe<ResolvedGenericItem> {\n        Ok(match module_item {\n            ModuleItemId::Constant(id) => ResolvedGenericItem::Constant(id),\n            ModuleItemId::Submodule(id) => ResolvedGenericItem::Module(ModuleId::Submodule(id)),\n            ModuleItemId::Use(id) => {\n                // Note that `use_resolved_item` needs to be called before\n                // `use_semantic_diagnostics` to handle cycles.\n                let resolved_item = self.db.use_resolved_item(id)?;\n                diagnostics.diagnostics.extend(self.db.use_semantic_diagnostics(id));\n                resolved_item\n            }\n            ModuleItemId::FreeFunction(id) => {\n                ResolvedGenericItem::GenericFunction(GenericFunctionId::Free(id))\n            }\n            ModuleItemId::ExternFunction(id) => {\n                ResolvedGenericItem::GenericFunction(GenericFunctionId::Extern(id))\n            }\n            ModuleItemId::Struct(id) => ResolvedGenericItem::GenericType(GenericTypeId::Struct(id)),\n            ModuleItemId::Enum(id) => ResolvedGenericItem::GenericType(GenericTypeId::Enum(id)),\n            ModuleItemId::TypeAlias(id) => ResolvedGenericItem::GenericTypeAlias(id),\n            ModuleItemId::ExternType(id) => {\n                ResolvedGenericItem::GenericType(GenericTypeId::Extern(id))\n            }\n            ModuleItemId::Trait(id) => ResolvedGenericItem::Trait(id),\n            ModuleItemId::Impl(id) => ResolvedGenericItem::Impl(id),\n        })\n    }\n\n    /// Determines whether the first identifier of a path is a local item.\n    fn determine_base_item_in_local_scope(\n        &mut self,\n        identifier: &ast::TerminalIdentifier,\n    ) -> Option<ResolvedConcreteItem> {\n        let syntax_db = self.db.upcast();\n        let ident = identifier.text(syntax_db);\n\n        // If a generic param with this name is found, use it.\n        if let Some(generic_param_id) = self.generic_params.get(&ident) {\n            let item = match generic_param_id {\n                GenericParam::Type(param) => ResolvedConcreteItem::Type(\n                    self.db.intern_type(TypeLongId::GenericParameter(param.id)),\n                ),\n                GenericParam::Const(_) => todo!(\"Add a variant to ConstId.\"),\n                GenericParam::Impl(param) => {\n                    ResolvedConcreteItem::Impl(ImplId::GenericParameter(param.id))\n                }\n            };\n            return Some(item);\n        }\n\n        // TODO(spapini): Resolve local variables.\n\n        None\n    }\n\n    /// Determines the base module for the path resolving. Looks only in non-local scope (i.e.\n    /// current module, or crates).\n    /// Returns Some(module) if the identifier is an item in a module. Otherwise, the path is fully\n    /// qualified, which means the identifier is a crate. In this case, returns None.\n    fn determine_base_module(&mut self, identifier: &ast::TerminalIdentifier) -> Option<ModuleId> {\n        let syntax_db = self.db.upcast();\n        let ident = identifier.text(syntax_db);\n\n        // If an item with this name is found inside the current module, use the current module.\n        if let Ok(Some(_)) = self.db.module_item_by_name(self.module_file_id.0, ident.clone()) {\n            return Some(self.module_file_id.0);\n        }\n\n        // If the first segment is a name of a crate, use the crate's root module as the base\n        // module.\n        let crate_id = self.db.intern_crate(CrateLongId(ident));\n        // TODO(spapini): Use a better interface to check if the crate exists (not using `dir`).\n        if self.db.crate_root_dir(crate_id).is_some() {\n            return None;\n        }\n\n        // Last resort, use the `core` crate root module as the base module.\n        Some(core_module(self.db))\n    }\n\n    /// Specializes a trait.\n    fn specialize_trait(\n        &mut self,\n        diagnostics: &mut SemanticDiagnostics,\n        stable_ptr: SyntaxStablePtrId,\n        trait_id: TraitId,\n        generic_args: Vec<ast::GenericArg>,\n    ) -> Maybe<ConcreteTraitId> {\n        // TODO(lior): Should we report diagnostic if `trait_generic_params` failed?\n        let generic_params = self\n            .db\n            .trait_generic_params(trait_id)\n            .map_err(|_| diagnostics.report_by_ptr(stable_ptr, UnknownTrait))?;\n\n        let generic_args =\n            self.resolve_generic_args(diagnostics, &generic_params, generic_args, stable_ptr)?;\n\n        Ok(self.db.intern_concrete_trait(ConcreteTraitLongId { trait_id, generic_args }))\n    }\n\n    /// Specializes an impl.\n    fn specialize_impl(\n        &mut self,\n        diagnostics: &mut SemanticDiagnostics,\n        stable_ptr: SyntaxStablePtrId,\n        impl_def_id: ImplDefId,\n        generic_args: Vec<ast::GenericArg>,\n    ) -> Maybe<ConcreteImplId> {\n        // Check for cycles in this type alias definition.\n        // TODO(orizi): Handle this without using `priv_impl_declaration_data`.\n        self.db.priv_impl_declaration_data(impl_def_id)?.check_no_cycle()?;\n\n        // TODO(lior): Should we report diagnostic if `impl_def_generic_params` failed?\n        let generic_params = self\n            .db\n            .impl_def_generic_params(impl_def_id)\n            .map_err(|_| diagnostics.report_by_ptr(stable_ptr, UnknownImpl))?;\n\n        let generic_args =\n            self.resolve_generic_args(diagnostics, &generic_params, generic_args, stable_ptr)?;\n\n        Ok(self.db.intern_concrete_impl(ConcreteImplLongId { impl_def_id, generic_args }))\n    }\n\n    /// Specializes a generic function.\n    pub fn specialize_function(\n        &mut self,\n        diagnostics: &mut SemanticDiagnostics,\n        stable_ptr: SyntaxStablePtrId,\n        generic_function: GenericFunctionId,\n        generic_args: Vec<ast::GenericArg>,\n    ) -> Maybe<FunctionId> {\n        // TODO(lior): Should we report diagnostic if `impl_def_generic_params` failed?\n        let generic_params: Vec<_> = generic_function.generic_params(self.db)?;\n\n        let generic_args =\n            self.resolve_generic_args(diagnostics, &generic_params, generic_args, stable_ptr)?;\n\n        Ok(self.db.intern_function(FunctionLongId {\n            function: ConcreteFunction { generic_function, generic_args },\n        }))\n    }\n\n    /// Specializes a generic type.\n    pub fn specialize_type(\n        &mut self,\n        diagnostics: &mut SemanticDiagnostics,\n        stable_ptr: SyntaxStablePtrId,\n        generic_type: GenericTypeId,\n        generic_args: Vec<ast::GenericArg>,\n    ) -> Maybe<TypeId> {\n        let generic_params = self\n            .db\n            .generic_type_generic_params(generic_type)\n            .map_err(|_| diagnostics.report_by_ptr(stable_ptr, UnknownType))?;\n\n        let generic_args =\n            self.resolve_generic_args(diagnostics, &generic_params, generic_args, stable_ptr)?;\n\n        Ok(self.db.intern_type(TypeLongId::Concrete(ConcreteTypeId::new(\n            self.db,\n            generic_type,\n            generic_args,\n        ))))\n    }\n\n    pub fn impl_lookup_context(&self) -> ImplLookupContext {\n        let lookup_context = ImplLookupContext {\n            module_id: self.module_file_id.0,\n            extra_modules: vec![],\n            generic_params: self.generic_params.values().copied().collect(),\n        };\n        lookup_context\n    }\n\n    pub fn resolve_generic_args(\n        &mut self,\n        diagnostics: &mut SemanticDiagnostics,\n        generic_params: &[GenericParam],\n        generic_args_syntax: Vec<ast::GenericArg>,\n        stable_ptr: SyntaxStablePtrId,\n    ) -> Maybe<Vec<GenericArgumentId>> {\n        let mut substitution = GenericSubstitution::default();\n        let mut resolved_args = vec![];\n\n        // If too many generic argument are given, trim and report.\n        if generic_args_syntax.len() > generic_params.len() {\n            diagnostics.report_by_ptr(\n                stable_ptr,\n                WrongNumberOfGenericArguments {\n                    expected: generic_params.len(),\n                    actual: generic_args_syntax.len(),\n                },\n            );\n        }\n\n        for (i, generic_param) in generic_params.iter().enumerate() {\n            let generic_param = SubstitutionRewriter { db: self.db, substitution: &substitution }\n                .rewrite(*generic_param)?;\n            let generic_arg = self.resolve_generic_arg(\n                generic_param,\n                generic_args_syntax.get(i),\n                stable_ptr,\n                diagnostics,\n            )?;\n            resolved_args.push(generic_arg);\n            substitution.0.insert(generic_param.id(), generic_arg);\n        }\n\n        Ok(resolved_args)\n    }\n\n    fn resolve_generic_arg(\n        &mut self,\n        generic_param: GenericParam,\n        generic_arg_syntax_opt: Option<&ast::GenericArg>,\n        stable_ptr: SyntaxStablePtrId,\n        diagnostics: &mut SemanticDiagnostics,\n    ) -> Result<GenericArgumentId, cairo_lang_diagnostics::DiagnosticAdded> {\n        let generic_arg_syntax = match generic_arg_syntax_opt {\n            None | Some(ast::GenericArg::Underscore(_)) => {\n                return self\n                    .inference\n                    .infer_generic_arg(&generic_param, self.impl_lookup_context(), stable_ptr)\n                    .map_err(|err| err.report(diagnostics, stable_ptr));\n            }\n            Some(ast::GenericArg::Expr(generic_arg_expr)) => {\n                generic_arg_expr.value(self.db.upcast())\n            }\n        };\n\n        Ok(match generic_param {\n            GenericParam::Type(_) => {\n                let ty = resolve_type(self.db, diagnostics, self, &generic_arg_syntax);\n                GenericArgumentId::Type(ty)\n            }\n            GenericParam::Const(_) => {\n                let text =\n                    generic_arg_syntax.as_syntax_node().get_text_without_trivia(self.db.upcast());\n                let literal = LiteralLongId::try_from(SmolStr::from(text))\n                    .map_err(|_| diagnostics.report(&generic_arg_syntax, UnknownLiteral))?;\n                GenericArgumentId::Literal(self.db.intern_literal(literal))\n            }\n            GenericParam::Impl(param) => {\n                let expr_path = try_extract_matches!(&generic_arg_syntax, ast::Expr::Path)\n                    .ok_or_else(|| diagnostics.report(&generic_arg_syntax, UnknownImpl))?;\n                let resolved_impl = try_extract_matches!(\n                    self.resolve_concrete_path(diagnostics, expr_path, NotFoundItemType::Impl,)?,\n                    ResolvedConcreteItem::Impl\n                )\n                .ok_or_else(|| diagnostics.report(&generic_arg_syntax, UnknownImpl))?;\n                let impl_def_concrete_trait = self.db.impl_concrete_trait(resolved_impl)?;\n                let expected_concrete_trait = param.concrete_trait?;\n                if self\n                    .inference\n                    .conform_traits(impl_def_concrete_trait, expected_concrete_trait)\n                    .is_err()\n                {\n                    diagnostics.report(&generic_arg_syntax, TraitMismatch);\n                }\n                GenericArgumentId::Impl(resolved_impl)\n            }\n        })\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse cairo_lang_debug::DebugWithDb;\nuse cairo_lang_defs::ids::{FunctionWithBodyId, ModuleId, ModuleItemId};\nuse cairo_lang_diagnostics::ToOption;\nuse cairo_lang_filesystem::db::{AsFilesGroupMut, FilesGroup, FilesGroupEx};\nuse cairo_lang_filesystem::ids::{CrateLongId, Directory, FileLongId};\nuse cairo_lang_utils::extract_matches;\nuse indoc::indoc;\nuse pretty_assertions::assert_eq;\nuse test_log::test;\n\nuse crate::db::SemanticGroup;\nuse crate::expr::fmt::ExprFormatter;\nuse crate::test_utils::{setup_test_module, SemanticDatabaseForTesting};\n\n#[test]\nfn test_resolve_path() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let db = &mut db_val;\n    let test_module = setup_test_module(\n        db,\n        indoc! {\"\n            use core::Box;\n            extern type S<T>;\n            extern fn bar<T>(value: S::<felt252>) -> S::<()> nopanic;\n\n            fn foo<Q>(value: S::<felt252>, b: Q, c: Box::<Q>) {\n                bar::<(felt252,Q)>(value);\n                let c = b;\n            }\n        \"},\n    )\n    .unwrap();\n    let module_id = test_module.module_id;\n\n    let function_id = FunctionWithBodyId::Free(extract_matches!(\n        db.module_item_by_name(module_id, \"foo\".into()).unwrap().unwrap(),\n        ModuleItemId::FreeFunction\n    ));\n    let expr_formatter = ExprFormatter { db, function_id };\n    let body = db.function_body_expr(function_id);\n    assert_eq!(\n        format!(\"{:?}\", body.to_option().debug(&expr_formatter)),\n        \"Some(Block(ExprBlock { statements: [Expr(StatementExpr { expr: \\\n         FunctionCall(ExprFunctionCall { function: test::bar::<(core::felt252, \\\n         GenericParamType(test::foo::Q))>, args: [Value(Var(ExprVar { var: ParamId(test::value), \\\n         ty: test::S::<core::felt252> }))], ty: test::S::<()> }) }), Let(StatementLet { pattern: \\\n         Variable(c), expr: Var(ExprVar { var: ParamId(test::b), ty: \\\n         GenericParamType(test::foo::Q) }) })], tail: None, ty: () }))\"\n    );\n}\n\nfn set_file_content(db: &mut SemanticDatabaseForTesting, path: &str, content: &str) {\n    let file_id = db.intern_file(FileLongId::OnDisk(path.into()));\n    db.as_files_group_mut().override_file_content(file_id, Some(Arc::new(content.into())));\n}\n\n#[test]\nfn test_resolve_path_super() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let db = &mut db_val;\n\n    let crate_id = db.intern_crate(CrateLongId(\"test\".into()));\n    let root = Directory(\"src\".into());\n    db.set_crate_root(crate_id, Some(root));\n\n    // Main module file.\n    set_file_content(\n        db,\n        \"src/lib.cairo\",\n        indoc! {\"\n        mod inner1;\n        mod inner2;\n        struct OuterStruct {}\n    \"},\n    );\n    set_file_content(db, \"src/inner1.cairo\", \"struct InnerStruct1 {}\");\n    set_file_content(\n        db,\n        \"src/inner2.cairo\",\n        indoc! {\"\n            struct InnerStruct2 {\n                a: super::inner1::InnerStruct1,\n                b: super::OuterStruct,\n            }\n        \"},\n    );\n    let test_module = ModuleId::CrateRoot(crate_id);\n    let inner2_module_id = ModuleId::Submodule(extract_matches!(\n        db.module_item_by_name(test_module, \"inner2\".into()).unwrap().unwrap(),\n        ModuleItemId::Submodule\n    ));\n    let struct_id = extract_matches!(\n        db.module_item_by_name(inner2_module_id, \"InnerStruct2\".into()).unwrap().unwrap(),\n        ModuleItemId::Struct\n    );\n    let members = db.struct_members(struct_id).unwrap();\n    assert_eq!(\n        format!(\"{:?}\", members[\"a\"].debug(db)),\n        \"Member { id: MemberId(test::inner2::a), ty: test::inner1::InnerStruct1 }\"\n    );\n    assert_eq!(\n        format!(\"{:?}\", members[\"b\"].debug(db)),\n        \"Member { id: MemberId(test::inner2::b), ty: test::OuterStruct }\"\n    );\n}\n\n#[test]\nfn test_resolve_path_trait_impl() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let db = &mut db_val;\n    let test_module = setup_test_module(\n        db,\n        indoc! {\"\n            trait MyTrait {\n                fn foo() -> felt252;\n            }\n\n            impl MyImpl of MyTrait {\n                fn foo() -> felt252 {\n                    7\n                }\n            }\n\n            fn main() -> felt252 {\n                MyTrait::foo() + 1\n            }\n        \"},\n    )\n    .unwrap();\n    let module_id = test_module.module_id;\n\n    let function_id = FunctionWithBodyId::Free(extract_matches!(\n        db.module_item_by_name(module_id, \"main\".into()).unwrap().unwrap(),\n        ModuleItemId::FreeFunction\n    ));\n    let expr_formatter = ExprFormatter { db, function_id };\n    let body = db.function_body_expr(function_id);\n    assert_eq!(\n        format!(\"{:?}\", body.to_option().debug(&expr_formatter)),\n        \"Some(Block(ExprBlock { statements: [], tail: Some(FunctionCall(ExprFunctionCall { \\\n         function: core::Felt252Add::add, args: [Value(FunctionCall(ExprFunctionCall { function: \\\n         test::MyImpl::foo, args: [], ty: core::felt252 })), Value(Literal(ExprLiteral { value: \\\n         1, ty: core::felt252 }))], ty: core::felt252 })), ty: core::felt252 }))\"\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_defs::db::DefsGroup;\nuse cairo_lang_defs::ids::LocalVarId;\n// Reexport objects\npub use cairo_lang_defs::ids::{ParamId, VarId};\nuse cairo_lang_proc_macros::{DebugWithDb, SemanticObject};\nuse cairo_lang_syntax::node::ast;\nuse smol_str::SmolStr;\n\npub use super::expr::objects::*;\nuse crate::db::SemanticGroup;\npub use crate::expr::pattern::{\n    Pattern, PatternEnumVariant, PatternLiteral, PatternOtherwise, PatternStruct, PatternTuple,\n    PatternVariable,\n};\npub use crate::items::enm::{ConcreteVariant, Variant};\npub use crate::items::function_with_body::FunctionBody;\npub use crate::items::functions::{\n    ConcreteFunction, ConcreteFunctionWithBodyId, FunctionId, FunctionLongId, Signature,\n};\npub use crate::items::generics::{GenericArgumentId, GenericParam};\npub use crate::items::imp::{ConcreteImplId, ConcreteImplLongId};\npub use crate::items::structure::Member;\npub use crate::items::trt::{ConcreteTraitId, ConcreteTraitLongId};\npub use crate::types::{\n    ConcreteEnumId, ConcreteExternTypeId, ConcreteStructId, ConcreteTypeId, TypeId, TypeLongId,\n};\n\n/// Semantic model of a variable.\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct LocalVariable {\n    pub id: LocalVarId,\n    pub ty: TypeId,\n    #[dont_rewrite]\n    pub is_mut: bool,\n}\nimpl LocalVariable {\n    pub fn stable_ptr(&self, db: &dyn DefsGroup) -> ast::TerminalIdentifierPtr {\n        self.id.stable_ptr(db)\n    }\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb, SemanticObject)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub struct Parameter {\n    pub id: ParamId,\n    #[dont_rewrite]\n    pub name: SmolStr,\n    pub ty: TypeId,\n    #[dont_rewrite]\n    pub mutability: Mutability,\n    #[hide_field_debug_with_db]\n    #[dont_rewrite]\n    pub stable_ptr: ast::TerminalIdentifierPtr,\n}\n\n/// The mutability attribute of a variable.\n#[derive(Debug, Clone, Hash, PartialEq, Eq)]\npub enum Mutability {\n    /// The variable can't be changed.\n    Immutable,\n    /// The variable can be changed locally.\n    Mutable,\n    /// Only relevant for a parameter.\n    /// The parameter is an in-out parameter and a change in it affects the outer scope.\n    Reference,\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, DebugWithDb)]\n#[debug_db(dyn SemanticGroup + 'static)]\npub enum Variable {\n    Local(LocalVariable),\n    Param(Parameter),\n}\nimpl Variable {\n    pub fn id(&self) -> VarId {\n        match self {\n            Variable::Local(local) => VarId::Local(local.id),\n            Variable::Param(param) => VarId::Param(param.id),\n        }\n    }\n    pub fn ty(&self) -> TypeId {\n        match self {\n            Variable::Local(local) => local.ty,\n            Variable::Param(param) => param.ty,\n        }\n    }\n    pub fn is_mut(&self) -> bool {\n        match self {\n            Variable::Local(local) => local.is_mut,\n            Variable::Param(param) => param.mutability != Mutability::Immutable,\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::ops::Deref;\n\nuse cairo_lang_defs::ids::{\n    EnumId, ExternFunctionId, ExternTypeId, FreeFunctionId, GenericParamId, ImplDefId,\n    ImplFunctionId, ParamId, StructId, TraitFunctionId, TraitId, VariantId,\n};\nuse cairo_lang_diagnostics::{DiagnosticAdded, Maybe};\nuse cairo_lang_utils::extract_matches;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse itertools::{zip_eq, Itertools};\n\nuse crate::db::SemanticGroup;\nuse crate::expr::inference::{ImplVar, TypeVar};\nuse crate::items::functions::{\n    ConcreteFunctionWithBody, GenericFunctionId, GenericFunctionWithBodyId, ImplGenericFunctionId,\n    ImplGenericFunctionWithBodyId,\n};\nuse crate::items::generics::{GenericParamConst, GenericParamImpl, GenericParamType};\nuse crate::items::imp::{ImplId, UninferredImpl};\nuse crate::items::trt::{ConcreteTraitGenericFunctionId, ConcreteTraitGenericFunctionLongId};\nuse crate::literals::LiteralId;\nuse crate::types::{ConcreteEnumLongId, ConcreteExternTypeLongId, ConcreteStructLongId};\nuse crate::{\n    ConcreteEnumId, ConcreteExternTypeId, ConcreteFunction, ConcreteImplId, ConcreteImplLongId,\n    ConcreteStructId, ConcreteTraitId, ConcreteTraitLongId, ConcreteTypeId, ConcreteVariant,\n    FunctionId, FunctionLongId, GenericArgumentId, GenericParam, Parameter, Signature, TypeId,\n    TypeLongId,\n};\n\n/// A substitution of generic arguments in generic parameters. Used for concretization.\n#[derive(Clone, Debug, Default, PartialEq, Eq)]\npub struct GenericSubstitution(pub OrderedHashMap<GenericParamId, GenericArgumentId>);\nimpl GenericSubstitution {\n    pub fn new(generic_params: &[GenericParam], generic_args: &[GenericArgumentId]) -> Self {\n        GenericSubstitution(\n            zip_eq(generic_params.iter().map(|param| param.id()), generic_args.iter().copied())\n                .collect(),\n        )\n    }\n    pub fn concat(mut self, other: GenericSubstitution) -> Self {\n        for (key, value) in other.0.into_iter() {\n            self.0.insert(key, value);\n        }\n        self\n    }\n}\nimpl Deref for GenericSubstitution {\n    type Target = OrderedHashMap<GenericParamId, GenericArgumentId>;\n\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\n#[allow(clippy::derived_hash_with_manual_eq)]\nimpl std::hash::Hash for GenericSubstitution {\n    fn hash<H: std::hash::Hasher>(&self, state: &mut H) {\n        self.0.iter().collect_vec().hash(state);\n    }\n}\n\n#[macro_export]\nmacro_rules! semantic_object_for_id {\n    ($name:ident, $lookup:ident, $intern:ident, $long_ty:ident) => {\n        impl<\n            'a,\n            Error,\n            TRewriter: $crate::substitution::HasDb<&'a dyn $crate::db::SemanticGroup>\n                + $crate::substitution::SemanticRewriter<$long_ty, Error>,\n        > $crate::substitution::SemanticObject<TRewriter, Error> for $name\n        {\n            fn default_rewrite(self, rewriter: &mut TRewriter) -> Result<Self, Error> {\n                let val = $crate::substitution::HasDb::get_db(rewriter).$lookup(self);\n                let val = $crate::substitution::SemanticRewriter::rewrite(rewriter, val)?;\n                Ok($crate::substitution::HasDb::get_db(rewriter).$intern(val))\n            }\n        }\n    };\n}\n\n#[macro_export]\nmacro_rules! add_rewrite {\n    (<$($generics:lifetime)*>, $self_ty:ty, $err_ty:ty, $ty:ident) => {\n        impl <$($generics)*> SemanticRewriter<$ty, $err_ty> for $self_ty {\n            fn rewrite(&mut self, value: $ty) -> Result<$ty, $err_ty> {\n                $crate::substitution::SemanticObject::default_rewrite(value, self)\n            }\n        }\n    };\n}\n\n#[macro_export]\nmacro_rules! add_rewrite_identity {\n    (<$($generics:lifetime)*>, $self_ty:ty, $err_ty:ty, $ty:ident) => {\n        impl <$($generics)*> SemanticRewriter<$ty, $err_ty> for $self_ty {\n            fn rewrite(&mut self, value: $ty) -> Result<$ty, $err_ty> {\n                Ok(value)\n            }\n        }\n    };\n}\n\npub trait SemanticObject<TRewriter, Error>: Sized {\n    fn default_rewrite(self, rewriter: &mut TRewriter) -> Result<Self, Error>;\n}\nimpl<T, E, TRewriter: SemanticRewriter<T, E>> SemanticRewriter<Vec<T>, E> for TRewriter {\n    fn rewrite(&mut self, value: Vec<T>) -> Result<Vec<T>, E> {\n        value.into_iter().map(|el| self.rewrite(el)).collect()\n    }\n}\nimpl<T: Clone, E, TRewriter: SemanticRewriter<T, E>> SemanticRewriter<Box<T>, E> for TRewriter {\n    fn rewrite(&mut self, value: Box<T>) -> Result<Box<T>, E> {\n        Ok(Box::new(self.rewrite((*value).clone())?))\n    }\n}\nimpl<T0, T1, E, TRewriter: SemanticRewriter<T0, E> + SemanticRewriter<T1, E>>\n    SemanticRewriter<(T0, T1), E> for TRewriter\n{\n    fn rewrite(&mut self, value: (T0, T1)) -> Result<(T0, T1), E> {\n        let (a, b) = value;\n        Ok((self.rewrite(a)?, self.rewrite(b)?))\n    }\n}\nimpl<T, E, TRewriter: SemanticRewriter<T, E>> SemanticRewriter<Option<T>, E> for TRewriter {\n    fn rewrite(&mut self, value: Option<T>) -> Result<Option<T>, E> {\n        match value {\n            Some(val) => Ok(Some(self.rewrite(val)?)),\n            None => Ok(None),\n        }\n    }\n}\nimpl<T, E, TRewriter: SemanticRewriter<T, E>, E2> SemanticRewriter<Result<T, E2>, E> for TRewriter {\n    fn rewrite(&mut self, value: Result<T, E2>) -> Result<Result<T, E2>, E> {\n        match value {\n            Ok(val) => Ok(Ok(self.rewrite(val)?)),\n            Err(err) => Ok(Err(err)),\n        }\n    }\n}\npub trait HasDb<T> {\n    fn get_db(&self) -> T;\n}\npub trait SemanticRewriter<T, Error> {\n    fn rewrite(&mut self, value: T) -> Result<T, Error>;\n}\n\n#[macro_export]\nmacro_rules! prune_single {\n    ($macro:ident, $item:ident, ) => {$macro!($item);};\n    ($macro:ident, $item:ident, $item0:ident $($item_rest:ident)*) => {\n        macro_rules! __inner_helper {\n            // Identifiers equal, skip.\n            ($item $item) => { };\n            // Identifiers not equal, continue scanning.\n            ($item $item0) => { $crate::prune_single!($macro, $item, $($item_rest)*); };\n        }\n        __inner_helper!($item $item0);\n    }\n}\n\n#[macro_export]\nmacro_rules! add_basic_rewrites {\n    (<$($generics:lifetime)*>, $self_ty:ty, $err_ty:ty, @exclude $($exclude:ident)*) => {\n        macro_rules! __identitity_helper {\n            ($item:ident) => { $crate::add_rewrite_identity!(<$($generics)*>, $self_ty, $err_ty, $item); }\n        }\n        macro_rules! __regular_helper {\n            ($item:ident) => { $crate::add_rewrite!(<$($generics)*>, $self_ty, $err_ty, $item); }\n        }\n\n        $crate::prune_single!(__identitity_helper, ParamId, $($exclude)*);\n        $crate::prune_single!(__identitity_helper, LiteralId, $($exclude)*);\n        $crate::prune_single!(__identitity_helper, FreeFunctionId, $($exclude)*);\n        $crate::prune_single!(__identitity_helper, ExternFunctionId, $($exclude)*);\n        $crate::prune_single!(__identitity_helper, ExternTypeId, $($exclude)*);\n        $crate::prune_single!(__identitity_helper, ImplDefId, $($exclude)*);\n        $crate::prune_single!(__identitity_helper, TraitId, $($exclude)*);\n        $crate::prune_single!(__identitity_helper, TraitFunctionId, $($exclude)*);\n        $crate::prune_single!(__identitity_helper, VariantId, $($exclude)*);\n        $crate::prune_single!(__identitity_helper, ImplFunctionId, $($exclude)*);\n        $crate::prune_single!(__identitity_helper, EnumId, $($exclude)*);\n        $crate::prune_single!(__identitity_helper, StructId, $($exclude)*);\n        $crate::prune_single!(__identitity_helper, GenericParamId, $($exclude)*);\n        $crate::prune_single!(__identitity_helper, TypeVar, $($exclude)*);\n        $crate::prune_single!(__identitity_helper, ImplVar, $($exclude)*);\n\n        $crate::prune_single!(__regular_helper, Signature, $($exclude)*);\n        $crate::prune_single!(__regular_helper, GenericFunctionId, $($exclude)*);\n        $crate::prune_single!(__regular_helper, GenericFunctionWithBodyId, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ConcreteFunction, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ConcreteFunctionWithBody, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ImplGenericFunctionId, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ImplGenericFunctionWithBodyId, $($exclude)*);\n        $crate::prune_single!(__regular_helper, Parameter, $($exclude)*);\n        $crate::prune_single!(__regular_helper, GenericParam, $($exclude)*);\n        $crate::prune_single!(__regular_helper, GenericParamType, $($exclude)*);\n        $crate::prune_single!(__regular_helper, GenericParamConst, $($exclude)*);\n        $crate::prune_single!(__regular_helper, GenericParamImpl, $($exclude)*);\n        $crate::prune_single!(__regular_helper, GenericArgumentId, $($exclude)*);\n        $crate::prune_single!(__regular_helper, FunctionId, $($exclude)*);\n        $crate::prune_single!(__regular_helper, FunctionLongId, $($exclude)*);\n        $crate::prune_single!(__regular_helper, TypeId, $($exclude)*);\n        $crate::prune_single!(__regular_helper, TypeLongId, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ConcreteVariant, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ConcreteTypeId, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ConcreteStructId, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ConcreteStructLongId, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ConcreteEnumId, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ConcreteEnumLongId, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ConcreteExternTypeId, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ConcreteExternTypeLongId, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ConcreteTraitId, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ConcreteTraitLongId, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ConcreteImplId, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ConcreteImplLongId, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ConcreteTraitGenericFunctionLongId, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ConcreteTraitGenericFunctionId, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ImplId, $($exclude)*);\n        $crate::prune_single!(__regular_helper, UninferredImpl, $($exclude)*);\n    };\n}\n\n#[macro_export]\nmacro_rules! add_expr_rewrites {\n    (<$($generics:lifetime)*>, $self_ty:ty, $err_ty:ty, @exclude $($exclude:ident)*) => {\n        macro_rules! __identitity_helper {\n            ($item:ident) => { $crate::add_rewrite_identity!(<$($generics)*>, $self_ty, $err_ty, $item); }\n        }\n        macro_rules! __regular_helper {\n            ($item:ident) => { $crate::add_rewrite!(<$($generics)*>, $self_ty, $err_ty, $item); }\n        }\n\n        $crate::prune_single!(__identitity_helper, ExprId, $($exclude)*);\n        $crate::prune_single!(__identitity_helper, StatementId, $($exclude)*);\n        $crate::prune_single!(__identitity_helper, VarId, $($exclude)*);\n        $crate::prune_single!(__identitity_helper, MemberId, $($exclude)*);\n        $crate::prune_single!(__identitity_helper, ConstantId, $($exclude)*);\n        $crate::prune_single!(__identitity_helper, LocalVarId, $($exclude)*);\n\n        $crate::prune_single!(__regular_helper, Expr, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ExprTuple, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ExprSnapshot, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ExprDesnap, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ExprAssignment, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ExprBlock, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ExprFunctionCall, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ExprMatch, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ExprIf, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ExprVar, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ExprLiteral, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ExprMemberAccess, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ExprStructCtor, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ExprEnumVariantCtor, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ExprPropagateError, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ExprConstant, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ExprMissing, $($exclude)*);\n        $crate::prune_single!(__regular_helper, VarMemberPath, $($exclude)*);\n        $crate::prune_single!(__regular_helper, ExprFunctionCallArg, $($exclude)*);\n        $crate::prune_single!(__regular_helper, MatchArm, $($exclude)*);\n        $crate::prune_single!(__regular_helper, Statement, $($exclude)*);\n        $crate::prune_single!(__regular_helper, StatementExpr, $($exclude)*);\n        $crate::prune_single!(__regular_helper, StatementLet, $($exclude)*);\n        $crate::prune_single!(__regular_helper, StatementReturn, $($exclude)*);\n        $crate::prune_single!(__regular_helper, Pattern, $($exclude)*);\n        $crate::prune_single!(__regular_helper, PatternLiteral, $($exclude)*);\n        $crate::prune_single!(__regular_helper, PatternVariable, $($exclude)*);\n        $crate::prune_single!(__regular_helper, PatternStruct, $($exclude)*);\n        $crate::prune_single!(__regular_helper, PatternTuple, $($exclude)*);\n        $crate::prune_single!(__regular_helper, PatternEnumVariant, $($exclude)*);\n        $crate::prune_single!(__regular_helper, PatternOtherwise, $($exclude)*);\n        $crate::prune_single!(__regular_helper, LocalVariable, $($exclude)*);\n        $crate::prune_single!(__regular_helper, Member, $($exclude)*);\n    };\n}\n\npub struct SubstitutionRewriter<'a> {\n    pub db: &'a dyn SemanticGroup,\n    pub substitution: &'a GenericSubstitution,\n}\nimpl<'a> HasDb<&'a dyn SemanticGroup> for SubstitutionRewriter<'a> {\n    fn get_db(&self) -> &'a dyn SemanticGroup {\n        self.db\n    }\n}\nadd_basic_rewrites!(<'a>, SubstitutionRewriter<'a>, DiagnosticAdded, @exclude TypeLongId ImplId);\nimpl<'a> SemanticRewriter<TypeLongId, DiagnosticAdded> for SubstitutionRewriter<'a> {\n    fn rewrite(&mut self, value: TypeLongId) -> Maybe<TypeLongId> {\n        if let TypeLongId::GenericParameter(generic_param) = value {\n            if let Some(generic_arg) = self.substitution.get(&generic_param) {\n                let type_id = *extract_matches!(generic_arg, GenericArgumentId::Type);\n                // return self.rewrite(self.db.lookup_intern_type(type_id));\n                return Ok(self.db.lookup_intern_type(type_id));\n            }\n        }\n        value.default_rewrite(self)\n    }\n}\nimpl<'a> SemanticRewriter<ImplId, DiagnosticAdded> for SubstitutionRewriter<'a> {\n    fn rewrite(&mut self, value: ImplId) -> Maybe<ImplId> {\n        if let ImplId::GenericParameter(generic_param) = value {\n            if let Some(generic_arg) = self.substitution.get(&generic_param) {\n                let impl_id = *extract_matches!(generic_arg, GenericArgumentId::Impl);\n                return self.rewrite(impl_id);\n            }\n        }\n        value.default_rewrite(self)\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_debug::DebugWithDb;\nuse cairo_lang_defs::ids::ModuleItemId;\nuse indoc::indoc;\n\nuse crate::db::SemanticGroup;\nuse crate::test_utils::{setup_test_module, SemanticDatabaseForTesting};\n\n#[test]\nfn test_resolve() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let (test_module, _diagnostics) = setup_test_module(\n        &mut db_val,\n        indoc! {\"\n            fn foo() -> felt252 { 5 }\n            extern fn felt252_add(a: felt252, b: felt252) -> felt252 nopanic;\n        \"},\n    )\n    .split();\n\n    let module_id = test_module.module_id;\n    let db = &db_val;\n    assert!(db.module_item_by_name(module_id, \"doesnt_exist\".into()).unwrap().is_none());\n    let felt252_add = db.module_item_by_name(module_id, \"felt252_add\".into()).unwrap();\n    assert_eq!(format!(\"{:?}\", felt252_add.debug(db)), \"Some(ExternFunctionId(test::felt252_add))\");\n    match db.module_item_by_name(module_id, \"felt252_add\".into()).unwrap().unwrap() {\n        ModuleItemId::ExternFunction(_) => {}\n        _ => panic!(\"Expected an extern function\"),\n    };\n    match db.module_item_by_name(module_id, \"foo\".into()).unwrap().unwrap() {\n        ModuleItemId::FreeFunction(_) => {}\n        _ => panic!(\"Expected a free function\"),\n    };\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse cairo_lang_defs::db::{DefsDatabase, DefsGroup, HasMacroPlugins};\nuse cairo_lang_defs::ids::{FunctionWithBodyId, ModuleId};\nuse cairo_lang_defs::plugin::MacroPlugin;\nuse cairo_lang_diagnostics::{Diagnostics, DiagnosticsBuilder};\nuse cairo_lang_filesystem::db::{\n    init_dev_corelib, init_files_group, AsFilesGroupMut, FilesDatabase, FilesGroup, FilesGroupEx,\n};\nuse cairo_lang_filesystem::detect::detect_corelib;\nuse cairo_lang_filesystem::ids::{CrateId, CrateLongId, Directory};\nuse cairo_lang_parser::db::ParserDatabase;\nuse cairo_lang_syntax::node::db::{SyntaxDatabase, SyntaxGroup};\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse cairo_lang_utils::{extract_matches, OptionFrom, Upcast};\nuse pretty_assertions::assert_eq;\n\nuse crate::db::{SemanticDatabase, SemanticGroup, SemanticGroupEx};\nuse crate::items::functions::GenericFunctionId;\nuse crate::{semantic, ConcreteFunctionWithBodyId, SemanticDiagnostic};\n\n#[salsa::database(SemanticDatabase, DefsDatabase, ParserDatabase, SyntaxDatabase, FilesDatabase)]\npub struct SemanticDatabaseForTesting {\n    storage: salsa::Storage<SemanticDatabaseForTesting>,\n}\nimpl salsa::Database for SemanticDatabaseForTesting {}\nimpl Default for SemanticDatabaseForTesting {\n    fn default() -> Self {\n        let mut res = Self { storage: Default::default() };\n        init_files_group(&mut res);\n        res.set_semantic_plugins(vec![]);\n        let corelib_path = detect_corelib().expect(\"Corelib not found in default location.\");\n        init_dev_corelib(&mut res, corelib_path);\n        res\n    }\n}\nimpl AsFilesGroupMut for SemanticDatabaseForTesting {\n    fn as_files_group_mut(&mut self) -> &mut (dyn FilesGroup + 'static) {\n        self\n    }\n}\nimpl Upcast<dyn FilesGroup> for SemanticDatabaseForTesting {\n    fn upcast(&self) -> &(dyn FilesGroup + 'static) {\n        self\n    }\n}\nimpl Upcast<dyn SyntaxGroup> for SemanticDatabaseForTesting {\n    fn upcast(&self) -> &(dyn SyntaxGroup + 'static) {\n        self\n    }\n}\nimpl Upcast<dyn DefsGroup> for SemanticDatabaseForTesting {\n    fn upcast(&self) -> &(dyn DefsGroup + 'static) {\n        self\n    }\n}\nimpl Upcast<dyn SemanticGroup> for SemanticDatabaseForTesting {\n    fn upcast(&self) -> &(dyn SemanticGroup + 'static) {\n        self\n    }\n}\nimpl HasMacroPlugins for SemanticDatabaseForTesting {\n    fn macro_plugins(&self) -> Vec<Arc<dyn MacroPlugin>> {\n        self.get_macro_plugins()\n    }\n}\n\npub struct WithStringDiagnostics<T> {\n    value: T,\n    diagnostics: String,\n}\nimpl<T> WithStringDiagnostics<T> {\n    /// Verifies that there are no diagnostics (fails otherwise), and returns the inner value.\n    pub fn unwrap(self) -> T {\n        assert_eq!(self.diagnostics, \"\");\n        self.value\n    }\n\n    /// Returns the inner value and the diagnostics (as a string).\n    pub fn split(self) -> (T, String) {\n        (self.value, self.diagnostics)\n    }\n\n    /// Returns the diagnostics (as a string).\n    pub fn get_diagnostics(self) -> String {\n        self.diagnostics\n    }\n}\n\n/// Helper struct for the return value of [setup_test_module].\npub struct TestModule {\n    pub crate_id: CrateId,\n    pub module_id: ModuleId,\n}\n\n/// Sets up a crate with given content, and returns its crate id.\npub fn setup_test_crate(db: &mut (dyn SemanticGroup + 'static), content: &str) -> CrateId {\n    let crate_id = db.intern_crate(CrateLongId(\"test\".into()));\n    let directory = Directory(\"src\".into());\n    db.set_crate_root(crate_id, Some(directory));\n    let file_id = db.module_main_file(ModuleId::CrateRoot(crate_id)).unwrap();\n    db.as_files_group_mut().override_file_content(file_id, Some(Arc::new(content.to_string())));\n    crate_id\n}\n\n/// Sets up a module with given content, and returns its module id.\npub fn setup_test_module(\n    db: &mut (dyn SemanticGroup + 'static),\n    content: &str,\n) -> WithStringDiagnostics<TestModule> {\n    let crate_id = setup_test_crate(db, content);\n    let module_id = ModuleId::CrateRoot(crate_id);\n    let file_id = db.module_main_file(module_id).unwrap();\n\n    let syntax_diagnostics = db.file_syntax_diagnostics(file_id).format(Upcast::upcast(db));\n    let semantic_diagnostics = db.module_semantic_diagnostics(module_id).unwrap().format(db);\n\n    WithStringDiagnostics {\n        value: TestModule { crate_id, module_id },\n        diagnostics: format!(\"{syntax_diagnostics}{semantic_diagnostics}\"),\n    }\n}\n\n/// Helper struct for the return value of [setup_test_function].\npub struct TestFunction {\n    pub module_id: ModuleId,\n    pub function_id: FunctionWithBodyId,\n    pub concrete_function_id: ConcreteFunctionWithBodyId,\n    pub signature: semantic::Signature,\n    pub body: semantic::ExprId,\n}\n\n/// Returns the semantic model of a given function.\n/// function_name - name of the function.\n/// module_code - extra setup code in the module context.\npub fn setup_test_function(\n    db: &mut (dyn SemanticGroup + 'static),\n    function_code: &str,\n    function_name: &str,\n    module_code: &str,\n) -> WithStringDiagnostics<TestFunction> {\n    let content = if module_code.is_empty() {\n        function_code.to_string()\n    } else {\n        format!(\"{module_code}\\n{function_code}\")\n    };\n    let (test_module, diagnostics) = setup_test_module(db, &content).split();\n    let generic_function_id = db\n        .module_item_by_name(test_module.module_id, function_name.into())\n        .expect(\"Failed to load module\")\n        .and_then(GenericFunctionId::option_from)\n        .unwrap_or_else(|| panic!(\"Function '{function_name}' was not found.\"));\n    let free_function_id = extract_matches!(generic_function_id, GenericFunctionId::Free);\n    let function_id = FunctionWithBodyId::Free(free_function_id);\n    WithStringDiagnostics {\n        value: TestFunction {\n            module_id: test_module.module_id,\n            function_id,\n            concrete_function_id: ConcreteFunctionWithBodyId::from_no_generics_free(\n                db,\n                free_function_id,\n            )\n            .unwrap(),\n            signature: db.function_with_body_signature(function_id).unwrap(),\n            body: db.function_body_expr(function_id).unwrap(),\n        },\n        diagnostics,\n    }\n}\n\n/// Helper struct for the return value of [setup_test_expr] and [setup_test_block].\npub struct TestExpr {\n    pub module_id: ModuleId,\n    pub function_id: FunctionWithBodyId,\n    pub signature: semantic::Signature,\n    pub body: semantic::ExprId,\n    pub expr_id: semantic::ExprId,\n}\n\n/// Returns the semantic model of a given expression.\n/// module_code - extra setup code in the module context.\n/// function_body - extra setup code in the function context.\npub fn setup_test_expr(\n    db: &mut (dyn SemanticGroup + 'static),\n    expr_code: &str,\n    module_code: &str,\n    function_body: &str,\n) -> WithStringDiagnostics<TestExpr> {\n    let function_code = format!(\"fn test_func() {{ {function_body} {{\\n{expr_code}\\n}}; }}\");\n    let (test_function, diagnostics) =\n        setup_test_function(db, &function_code, \"test_func\", module_code).split();\n    let semantic::ExprBlock { statements, .. } = extract_matches!(\n        db.expr_semantic(test_function.function_id, test_function.body),\n        semantic::Expr::Block\n    );\n    let statement_expr = extract_matches!(\n        db.statement_semantic(test_function.function_id, *statements.last().unwrap()),\n        semantic::Statement::Expr\n    );\n    let semantic::ExprBlock { statements, tail, .. } = extract_matches!(\n        db.expr_semantic(test_function.function_id, statement_expr.expr),\n        semantic::Expr::Block\n    );\n    assert!(\n        statements.is_empty(),\n        \"expr_code is not a valid expression. Consider using setup_test_block().\"\n    );\n    WithStringDiagnostics {\n        value: TestExpr {\n            module_id: test_function.module_id,\n            function_id: test_function.function_id,\n            signature: test_function.signature,\n            body: test_function.body,\n            expr_id: tail.unwrap(),\n        },\n        diagnostics,\n    }\n}\n\n/// Returns the semantic model of a given block expression.\n/// module_code - extra setup code in the module context.\n/// function_body - extra setup code in the function context.\npub fn setup_test_block(\n    db: &mut (dyn SemanticGroup + 'static),\n    expr_code: &str,\n    module_code: &str,\n    function_body: &str,\n) -> WithStringDiagnostics<TestExpr> {\n    setup_test_expr(db, &format!(\"{{ \\n{expr_code}\\n }}\"), module_code, function_body)\n}\n\npub fn test_expr_diagnostics(\n    inputs: &OrderedHashMap<String, String>,\n) -> OrderedHashMap<String, String> {\n    let db = &mut SemanticDatabaseForTesting::default();\n    OrderedHashMap::from([(\n        \"expected_diagnostics\".into(),\n        setup_test_expr(\n            db,\n            inputs[\"expr_code\"].as_str(),\n            inputs[\"module_code\"].as_str(),\n            inputs[\"function_body\"].as_str(),\n        )\n        .get_diagnostics(),\n    )])\n}\n\npub fn test_function_diagnostics(\n    inputs: &OrderedHashMap<String, String>,\n) -> OrderedHashMap<String, String> {\n    let db = &mut SemanticDatabaseForTesting::default();\n    OrderedHashMap::from([(\n        \"expected_diagnostics\".into(),\n        setup_test_function(\n            db,\n            inputs[\"function\"].as_str(),\n            inputs[\"function_name\"].as_str(),\n            inputs[\"module_code\"].as_str(),\n        )\n        .get_diagnostics(),\n    )])\n}\n\n/// Gets the diagnostics for all the modules (including nested) in the given crate.\npub fn get_crate_semantic_diagnostics(\n    db: &dyn SemanticGroup,\n    crate_id: CrateId,\n) -> Diagnostics<SemanticDiagnostic> {\n    let submodules = db.crate_modules(crate_id);\n    let mut diagnostics = DiagnosticsBuilder::default();\n    for submodule_id in submodules.iter() {\n        diagnostics.extend(db.module_semantic_diagnostics(*submodule_id).unwrap());\n    }\n    diagnostics.build()\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_debug::DebugWithDb;\nuse cairo_lang_defs::ids::{\n    EnumId, ExternTypeId, GenericParamId, GenericTypeId, LanguageElementId, StructId,\n};\nuse cairo_lang_diagnostics::{DiagnosticAdded, Maybe};\nuse cairo_lang_proc_macros::SemanticObject;\nuse cairo_lang_syntax::node::ast;\nuse cairo_lang_syntax::node::stable_ptr::SyntaxStablePtr;\nuse cairo_lang_utils::{define_short_id, try_extract_matches, OptionFrom};\nuse itertools::Itertools;\n\nuse crate::corelib::{concrete_copy_trait, concrete_destruct_trait, concrete_drop_trait};\nuse crate::db::SemanticGroup;\nuse crate::diagnostic::SemanticDiagnosticKind::*;\nuse crate::diagnostic::{NotFoundItemType, SemanticDiagnostics};\nuse crate::expr::inference::{InferenceResult, TypeVar};\nuse crate::items::imp::{get_impl_at_context, ImplId, ImplLookupContext};\nuse crate::resolve_path::{ResolvedConcreteItem, Resolver};\nuse crate::{semantic, semantic_object_for_id};\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, SemanticObject)]\npub enum TypeLongId {\n    Concrete(ConcreteTypeId),\n    /// Some expressions might have invalid types during processing, either due to errors or\n    /// during inference.\n    Tuple(Vec<TypeId>),\n    Snapshot(TypeId),\n    GenericParameter(GenericParamId),\n    Var(TypeVar),\n    Missing(#[dont_rewrite] DiagnosticAdded),\n}\nimpl OptionFrom<TypeLongId> for ConcreteTypeId {\n    fn option_from(other: TypeLongId) -> Option<Self> {\n        try_extract_matches!(other, TypeLongId::Concrete)\n    }\n}\n\ndefine_short_id!(TypeId, TypeLongId, SemanticGroup, lookup_intern_type);\nsemantic_object_for_id!(TypeId, lookup_intern_type, intern_type, TypeLongId);\nimpl TypeId {\n    pub fn missing(db: &dyn SemanticGroup, diag_added: DiagnosticAdded) -> Self {\n        db.intern_type(TypeLongId::Missing(diag_added))\n    }\n\n    pub fn format(&self, db: &dyn SemanticGroup) -> String {\n        db.lookup_intern_type(*self).format(db)\n    }\n\n    /// Returns [Maybe::Err] if the type is [TypeLongId::Missing].\n    pub fn check_not_missing(&self, db: &dyn SemanticGroup) -> Maybe<()> {\n        if let TypeLongId::Missing(diag_added) = db.lookup_intern_type(*self) {\n            Err(diag_added)\n        } else {\n            Ok(())\n        }\n    }\n\n    /// Returns `true` if the type is [TypeLongId::Missing].\n    pub fn is_missing(&self, db: &dyn SemanticGroup) -> bool {\n        self.check_not_missing(db).is_err()\n    }\n\n    /// Returns `true` if the type is `()`.\n    pub fn is_unit(&self, db: &dyn SemanticGroup) -> bool {\n        matches!(db.lookup_intern_type(*self), TypeLongId::Tuple(types) if types.is_empty())\n    }\n\n    /// Returns the [TypeHead] for a type if available.\n    pub fn head(&self, db: &dyn SemanticGroup) -> Option<TypeHead> {\n        db.lookup_intern_type(*self).head(db)\n    }\n}\nimpl TypeLongId {\n    pub fn format(&self, db: &dyn SemanticGroup) -> String {\n        match self {\n            TypeLongId::Concrete(concrete) => concrete.format(db),\n            TypeLongId::Tuple(inner_types) => {\n                if inner_types.len() == 1 {\n                    format!(\"({},)\", inner_types[0].format(db))\n                } else {\n                    format!(\"({})\", inner_types.iter().map(|ty| ty.format(db)).join(\", \"))\n                }\n            }\n            TypeLongId::Snapshot(ty) => format!(\"@{}\", ty.format(db)),\n            TypeLongId::GenericParameter(generic_param) => {\n                format!(\"{:?}\", generic_param.debug(db.elongate()))\n            }\n            TypeLongId::Var(var) => format!(\"?{}\", var.id),\n            TypeLongId::Missing(_) => \"<missing>\".to_string(),\n        }\n    }\n\n    /// Returns the [TypeHead] for a type if available.\n    pub fn head(&self, db: &dyn SemanticGroup) -> Option<TypeHead> {\n        Some(match self {\n            TypeLongId::Concrete(concrete) => TypeHead::Concrete(concrete.generic_type(db)),\n            TypeLongId::Tuple(_) => TypeHead::Tuple,\n            TypeLongId::Snapshot(inner) => TypeHead::Snapshot(Box::new(inner.head(db)?)),\n            TypeLongId::GenericParameter(_) | TypeLongId::Var(_) | TypeLongId::Missing(_) => {\n                return None;\n            }\n        })\n    }\n}\nimpl DebugWithDb<dyn SemanticGroup> for TypeLongId {\n    fn fmt(\n        &self,\n        f: &mut std::fmt::Formatter<'_>,\n        db: &(dyn SemanticGroup + 'static),\n    ) -> std::fmt::Result {\n        write!(f, \"{}\", self.format(db))\n    }\n}\n\n/// Head of a type. A non-param non-variable type has a head, which represents the kind of the root\n/// node in its type tree. This is used for caching queries for fast lookups when the type is not\n/// completely inferred yet.\n#[derive(Clone, Debug, Hash, PartialEq, Eq)]\npub enum TypeHead {\n    Concrete(GenericTypeId),\n    Snapshot(Box<TypeHead>),\n    Tuple,\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, SemanticObject)]\npub enum ConcreteTypeId {\n    Struct(ConcreteStructId),\n    Enum(ConcreteEnumId),\n    Extern(ConcreteExternTypeId),\n}\nimpl ConcreteTypeId {\n    pub fn new(\n        db: &dyn SemanticGroup,\n        generic_ty: GenericTypeId,\n        generic_args: Vec<semantic::GenericArgumentId>,\n    ) -> Self {\n        match generic_ty {\n            GenericTypeId::Struct(id) => ConcreteTypeId::Struct(\n                db.intern_concrete_struct(ConcreteStructLongId { struct_id: id, generic_args }),\n            ),\n            GenericTypeId::Enum(id) => ConcreteTypeId::Enum(\n                db.intern_concrete_enum(ConcreteEnumLongId { enum_id: id, generic_args }),\n            ),\n            GenericTypeId::Extern(id) => {\n                ConcreteTypeId::Extern(db.intern_concrete_extern_type(ConcreteExternTypeLongId {\n                    extern_type_id: id,\n                    generic_args,\n                }))\n            }\n        }\n    }\n    pub fn generic_type(&self, db: &dyn SemanticGroup) -> GenericTypeId {\n        match self {\n            ConcreteTypeId::Struct(id) => {\n                GenericTypeId::Struct(db.lookup_intern_concrete_struct(*id).struct_id)\n            }\n            ConcreteTypeId::Enum(id) => {\n                GenericTypeId::Enum(db.lookup_intern_concrete_enum(*id).enum_id)\n            }\n            ConcreteTypeId::Extern(id) => {\n                GenericTypeId::Extern(db.lookup_intern_concrete_extern_type(*id).extern_type_id)\n            }\n        }\n    }\n    pub fn generic_args(&self, db: &dyn SemanticGroup) -> Vec<semantic::GenericArgumentId> {\n        match self {\n            ConcreteTypeId::Struct(id) => db.lookup_intern_concrete_struct(*id).generic_args,\n            ConcreteTypeId::Enum(id) => db.lookup_intern_concrete_enum(*id).generic_args,\n            ConcreteTypeId::Extern(id) => db.lookup_intern_concrete_extern_type(*id).generic_args,\n        }\n    }\n    pub fn format(&self, db: &dyn SemanticGroup) -> String {\n        // TODO(spapini): Format generics.\n        let generic_type_format = self.generic_type(db).format(db.upcast());\n        let generic_args = self.generic_args(db);\n        if generic_args.is_empty() {\n            generic_type_format\n        } else {\n            format!(\n                \"{}::<{}>\",\n                generic_type_format,\n                generic_args.iter().map(|arg| arg.format(db)).join(\", \")\n            )\n        }\n    }\n}\nimpl DebugWithDb<dyn SemanticGroup> for ConcreteTypeId {\n    fn fmt(\n        &self,\n        f: &mut std::fmt::Formatter<'_>,\n        db: &(dyn SemanticGroup + 'static),\n    ) -> std::fmt::Result {\n        write!(f, \"{}\", self.format(db))\n    }\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, SemanticObject)]\npub struct ConcreteStructLongId {\n    pub struct_id: StructId,\n    pub generic_args: Vec<semantic::GenericArgumentId>,\n}\ndefine_short_id!(\n    ConcreteStructId,\n    ConcreteStructLongId,\n    SemanticGroup,\n    lookup_intern_concrete_struct\n);\nsemantic_object_for_id!(\n    ConcreteStructId,\n    lookup_intern_concrete_struct,\n    intern_concrete_struct,\n    ConcreteStructLongId\n);\nimpl ConcreteStructId {\n    pub fn struct_id(&self, db: &dyn SemanticGroup) -> StructId {\n        db.lookup_intern_concrete_struct(*self).struct_id\n    }\n}\nimpl DebugWithDb<dyn SemanticGroup> for ConcreteStructLongId {\n    fn fmt(\n        &self,\n        f: &mut std::fmt::Formatter<'_>,\n        db: &(dyn SemanticGroup + 'static),\n    ) -> std::fmt::Result {\n        write!(f, \"{:?}\", ConcreteTypeId::Struct(db.intern_concrete_struct(self.clone())).debug(db))\n    }\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, SemanticObject)]\npub struct ConcreteEnumLongId {\n    pub enum_id: EnumId,\n    pub generic_args: Vec<semantic::GenericArgumentId>,\n}\ndefine_short_id!(ConcreteEnumId, ConcreteEnumLongId, SemanticGroup, lookup_intern_concrete_enum);\nsemantic_object_for_id!(\n    ConcreteEnumId,\n    lookup_intern_concrete_enum,\n    intern_concrete_enum,\n    ConcreteEnumLongId\n);\nimpl ConcreteEnumId {\n    pub fn enum_id(&self, db: &dyn SemanticGroup) -> EnumId {\n        db.lookup_intern_concrete_enum(*self).enum_id\n    }\n}\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq, SemanticObject)]\npub struct ConcreteExternTypeLongId {\n    pub extern_type_id: ExternTypeId,\n    pub generic_args: Vec<semantic::GenericArgumentId>,\n}\ndefine_short_id!(\n    ConcreteExternTypeId,\n    ConcreteExternTypeLongId,\n    SemanticGroup,\n    lookup_intern_concrete_extern_type\n);\nsemantic_object_for_id!(\n    ConcreteExternTypeId,\n    lookup_intern_concrete_extern_type,\n    intern_concrete_extern_type,\n    ConcreteExternTypeLongId\n);\nimpl ConcreteExternTypeId {\n    pub fn extern_type_id(&self, db: &dyn SemanticGroup) -> ExternTypeId {\n        db.lookup_intern_concrete_extern_type(*self).extern_type_id\n    }\n}\n\n// TODO(spapini): add a query wrapper.\n/// Resolves a type given a module and a path.\npub fn resolve_type(\n    db: &dyn SemanticGroup,\n    diagnostics: &mut SemanticDiagnostics,\n    resolver: &mut Resolver<'_>,\n    ty_syntax: &ast::Expr,\n) -> TypeId {\n    maybe_resolve_type(db, diagnostics, resolver, ty_syntax)\n        .unwrap_or_else(|diag_added| TypeId::missing(db, diag_added))\n}\npub fn maybe_resolve_type(\n    db: &dyn SemanticGroup,\n    diagnostics: &mut SemanticDiagnostics,\n    resolver: &mut Resolver<'_>,\n    ty_syntax: &ast::Expr,\n) -> Maybe<TypeId> {\n    let syntax_db = db.upcast();\n    Ok(match ty_syntax {\n        ast::Expr::Path(path) => {\n            match resolver.resolve_concrete_path(diagnostics, path, NotFoundItemType::Type)? {\n                ResolvedConcreteItem::Type(ty) => ty,\n                _ => {\n                    return Err(diagnostics.report(path, NotAType));\n                }\n            }\n        }\n        ast::Expr::Parenthesized(expr_syntax) => {\n            resolve_type(db, diagnostics, resolver, &expr_syntax.expr(syntax_db))\n        }\n        ast::Expr::Tuple(tuple_syntax) => {\n            let sub_tys = tuple_syntax\n                .expressions(syntax_db)\n                .elements(syntax_db)\n                .into_iter()\n                .map(|subexpr_syntax| resolve_type(db, diagnostics, resolver, &subexpr_syntax))\n                .collect();\n            db.intern_type(TypeLongId::Tuple(sub_tys))\n        }\n        ast::Expr::Unary(unary_syntax)\n            if matches!(unary_syntax.op(syntax_db), ast::UnaryOperator::At(_)) =>\n        {\n            let ty = resolve_type(db, diagnostics, resolver, &unary_syntax.expr(syntax_db));\n            db.intern_type(TypeLongId::Snapshot(ty))\n        }\n        ast::Expr::Unary(unary_syntax)\n            if matches!(unary_syntax.op(syntax_db), ast::UnaryOperator::Desnap(_)) =>\n        {\n            let ty = resolve_type(db, diagnostics, resolver, &unary_syntax.expr(syntax_db));\n            if let Some(desnapped_ty) =\n                try_extract_matches!(db.lookup_intern_type(ty), TypeLongId::Snapshot)\n            {\n                desnapped_ty\n            } else {\n                return Err(diagnostics.report(ty_syntax, DesnapNonSnapshot));\n            }\n        }\n        _ => {\n            return Err(diagnostics.report(ty_syntax, UnknownType));\n        }\n    })\n}\n\n/// Query implementation of [crate::db::SemanticGroup::generic_type_generic_params].\npub fn generic_type_generic_params(\n    db: &dyn SemanticGroup,\n    generic_type: GenericTypeId,\n) -> Maybe<Vec<semantic::GenericParam>> {\n    match generic_type {\n        GenericTypeId::Struct(id) => db.struct_generic_params(id),\n        GenericTypeId::Enum(id) => db.enum_generic_params(id),\n        GenericTypeId::Extern(id) => db.extern_type_declaration_generic_params(id),\n    }\n}\n\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct TypeInfo {\n    pub droppable: InferenceResult<()>,\n    pub duplicatable: InferenceResult<()>,\n    pub destruct_impl: InferenceResult<ImplId>,\n}\n\n// TODO(spapini): type info lookup for non generic types needs to not depend on lookup_context.\n// This is to ensure that sierra genreator will see a consistent type info of types.\n/// Query implementation of [crate::db::SemanticGroup::type_info].\npub fn type_info(\n    db: &dyn SemanticGroup,\n    mut lookup_context: ImplLookupContext,\n    ty: TypeId,\n) -> Maybe<TypeInfo> {\n    // Dummy stable pointer for type inference variables, since inference is disabled.\n    let stable_ptr = db.intern_stable_ptr(SyntaxStablePtr::Root);\n    let destruct_impl = get_impl_at_context(\n        db,\n        lookup_context.clone(),\n        concrete_destruct_trait(db, ty),\n        stable_ptr,\n    );\n    Ok(match db.lookup_intern_type(ty) {\n        TypeLongId::Concrete(concrete_type_id) => {\n            let module = concrete_type_id.generic_type(db).parent_module(db.upcast());\n            // Look for Copy and Drop trait also in the defining module.\n            if !lookup_context.extra_modules.contains(&module) {\n                lookup_context.extra_modules.push(module);\n            }\n            let droppable = get_impl_at_context(\n                db,\n                lookup_context.clone(),\n                concrete_drop_trait(db, ty),\n                stable_ptr,\n            )\n            .map(|_| ());\n            let duplicatable = get_impl_at_context(\n                db,\n                lookup_context.clone(),\n                concrete_copy_trait(db, ty),\n                stable_ptr,\n            )\n            .map(|_| ());\n            TypeInfo { droppable, duplicatable, destruct_impl }\n        }\n        TypeLongId::GenericParameter(_) => {\n            let droppable = get_impl_at_context(\n                db,\n                lookup_context.clone(),\n                concrete_drop_trait(db, ty),\n                stable_ptr,\n            )\n            .map(|_| ());\n            let duplicatable = get_impl_at_context(\n                db,\n                lookup_context.clone(),\n                concrete_copy_trait(db, ty),\n                stable_ptr,\n            )\n            .map(|_| ());\n\n            TypeInfo { droppable, duplicatable, destruct_impl }\n        }\n        TypeLongId::Tuple(tys) => {\n            let infos = tys\n                .into_iter()\n                .map(|ty| db.type_info(lookup_context.clone(), ty))\n                .collect::<Maybe<Vec<_>>>()?;\n            let droppable = if let Some(err) =\n                infos.iter().filter_map(|info| info.droppable.clone().err()).next()\n            {\n                Err(err)\n            } else {\n                Ok(())\n            };\n            let duplicatable = if let Some(err) =\n                infos.iter().filter_map(|info| info.duplicatable.clone().err()).next()\n            {\n                Err(err)\n            } else {\n                Ok(())\n            };\n            TypeInfo { droppable, duplicatable, destruct_impl }\n        }\n        TypeLongId::Var(_) => panic!(\"Types should be fully resolved at this point.\"),\n        TypeLongId::Missing(diag_added) => {\n            return Err(diag_added);\n        }\n        TypeLongId::Snapshot(_) => {\n            TypeInfo { droppable: Ok(()), duplicatable: Ok(()), destruct_impl }\n        }\n    })\n}\n\n/// Peels all wrapping Snapshot (`@`) from the type.\n/// Returns the number of peeled snapshots and the inner type.\npub fn peel_snapshots(db: &dyn SemanticGroup, ty: TypeId) -> (usize, TypeLongId) {\n    let mut long_ty = db.lookup_intern_type(ty);\n    let mut n_snapshots = 0;\n    while let TypeLongId::Snapshot(ty) = long_ty {\n        long_ty = db.lookup_intern_type(ty);\n        n_snapshots += 1;\n    }\n    (n_snapshots, long_ty)\n}\n\n/// Wraps a type with Snapshot (`@`) `n_snapshots` times.\npub fn wrap_in_snapshots(db: &dyn SemanticGroup, mut ty: TypeId, n_snapshots: usize) -> TypeId {\n    for _ in 0..n_snapshots {\n        ty = db.intern_type(TypeLongId::Snapshot(ty));\n    }\n    ty\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use lalrpop::process_root;\n\nfn main() {\n    process_root().unwrap();\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashMap;\nuse std::hash::Hash;\n\nuse itertools::Itertools;\nuse serde::{Deserialize, Serialize};\nuse smol_str::SmolStr;\n\nuse crate::ids::{ConcreteLibfuncId, ConcreteTypeId, FunctionId};\nuse crate::program::{GenericArg, Program, Statement};\n\n#[cfg(test)]\n#[path = \"debug_info_test.rs\"]\nmod test;\n\n/// Debug information for a Sierra program, to get readable names.\n#[derive(Debug, Eq, PartialEq, Serialize, Deserialize)]\npub struct DebugInfo {\n    #[serde(\n        serialize_with = \"serialize_map::<ConcreteTypeId, _>\",\n        deserialize_with = \"deserialize_map::<ConcreteTypeId, _>\"\n    )]\n    pub type_names: HashMap<ConcreteTypeId, SmolStr>,\n    #[serde(\n        serialize_with = \"serialize_map::<ConcreteLibfuncId, _>\",\n        deserialize_with = \"deserialize_map::<ConcreteLibfuncId, _>\"\n    )]\n    pub libfunc_names: HashMap<ConcreteLibfuncId, SmolStr>,\n    #[serde(\n        serialize_with = \"serialize_map::<FunctionId, _>\",\n        deserialize_with = \"deserialize_map::<FunctionId, _>\"\n    )]\n    pub user_func_names: HashMap<FunctionId, SmolStr>,\n}\nimpl DebugInfo {\n    /// Extracts the existing debug info from a program.\n    pub fn extract(program: &Program) -> Self {\n        Self {\n            type_names: program\n                .type_declarations\n                .iter()\n                .filter_map(|decl| {\n                    decl.id.debug_name.clone().map(|name| (ConcreteTypeId::new(decl.id.id), name))\n                })\n                .collect(),\n            libfunc_names: program\n                .libfunc_declarations\n                .iter()\n                .filter_map(|decl| {\n                    decl.id\n                        .debug_name\n                        .clone()\n                        .map(|name| (ConcreteLibfuncId::new(decl.id.id), name))\n                })\n                .collect(),\n            user_func_names: program\n                .funcs\n                .iter()\n                .filter_map(|func| {\n                    func.id.debug_name.clone().map(|name| (FunctionId::new(func.id.id), name))\n                })\n                .collect(),\n        }\n    }\n\n    /// Populates a program with debug info.\n    pub fn populate(&self, program: &mut Program) {\n        for decl in &mut program.type_declarations {\n            self.try_replace_type_id(&mut decl.id);\n            self.try_replace_generic_arg_ids(&mut decl.long_id.generic_args);\n        }\n        for decl in &mut program.libfunc_declarations {\n            self.try_replace_libfunc_id(&mut decl.id);\n            self.try_replace_generic_arg_ids(&mut decl.long_id.generic_args);\n        }\n        for func in &mut program.funcs {\n            self.try_replace_function_id(&mut func.id);\n            for param in &mut func.params {\n                self.try_replace_type_id(&mut param.ty);\n            }\n            for id in &mut func.signature.param_types {\n                self.try_replace_type_id(id);\n            }\n            for id in &mut func.signature.ret_types {\n                self.try_replace_type_id(id);\n            }\n        }\n        for statement in &mut program.statements {\n            match statement {\n                Statement::Invocation(invocation) => {\n                    self.try_replace_libfunc_id(&mut invocation.libfunc_id)\n                }\n                Statement::Return(_) => {}\n            }\n        }\n    }\n\n    /// Replaces the debug names of the generic args if exists in the maps.\n    fn try_replace_generic_arg_ids(&self, generic_args: &mut Vec<GenericArg>) {\n        for generic_arg in generic_args {\n            match generic_arg {\n                GenericArg::Type(id) => self.try_replace_type_id(id),\n                GenericArg::Libfunc(id) => self.try_replace_libfunc_id(id),\n                GenericArg::UserFunc(id) => self.try_replace_function_id(id),\n                GenericArg::Value(_) | GenericArg::UserType(_) => {}\n            }\n        }\n    }\n\n    /// Replaces the debug name of an id if exists in the matching map.\n    fn try_replace_type_id(&self, id: &mut ConcreteTypeId) {\n        if let Some(name) = self.type_names.get(id).cloned() {\n            let _ = id.debug_name.insert(name);\n        }\n    }\n\n    /// Replaces the debug name of an id if exists in the matching map.\n    fn try_replace_libfunc_id(&self, id: &mut ConcreteLibfuncId) {\n        if let Some(name) = self.libfunc_names.get(id).cloned() {\n            let _ = id.debug_name.insert(name);\n        }\n    }\n\n    /// Replaces the debug name of an id if exists in the matching map.\n    fn try_replace_function_id(&self, id: &mut FunctionId) {\n        if let Some(name) = self.user_func_names.get(id).cloned() {\n            let _ = id.debug_name.insert(name);\n        }\n    }\n}\n\n/// Trait for handling serde for the ids as map keys.\npub trait IdAsHashKey: Hash + Eq {\n    /// Gets the inner id.\n    fn get(&self) -> u64;\n    /// Returns a new id from the given value.\n    fn new(id: u64) -> Self;\n}\n\nimpl IdAsHashKey for ConcreteTypeId {\n    fn get(&self) -> u64 {\n        self.id\n    }\n\n    fn new(id: u64) -> Self {\n        Self::new(id)\n    }\n}\nimpl IdAsHashKey for ConcreteLibfuncId {\n    fn get(&self) -> u64 {\n        self.id\n    }\n\n    fn new(id: u64) -> Self {\n        Self::new(id)\n    }\n}\nimpl IdAsHashKey for FunctionId {\n    fn get(&self) -> u64 {\n        self.id\n    }\n\n    fn new(id: u64) -> Self {\n        Self::new(id)\n    }\n}\n\nfn serialize_map<Id: IdAsHashKey, S: serde::Serializer>(\n    m: &HashMap<Id, SmolStr>,\n    serializer: S,\n) -> Result<S::Ok, S::Error> {\n    let v: Vec<_> = m.iter().map(|(id, name)| (id.get(), name)).sorted().collect();\n    v.serialize(serializer)\n}\n\nfn deserialize_map<'de, Id: IdAsHashKey, D: serde::Deserializer<'de>>(\n    deserializer: D,\n) -> Result<HashMap<Id, SmolStr>, D::Error> {\n    Ok(Vec::<(u64, SmolStr)>::deserialize(deserializer)?\n        .into_iter()\n        .map(|(id, name)| (Id::new(id), name))\n        .collect())\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashMap;\n\nuse indoc::indoc;\n\nuse super::DebugInfo;\nuse crate::ProgramParser;\n\n#[test]\nfn test_extract_names() {\n    assert_eq!(\n        DebugInfo::extract(\n            &ProgramParser::new()\n                .parse(indoc! {\"\n                    type u128 = u128;\n                    type GasBuiltin = GasBuiltin;\n                    type NonZeroInt = NonZero<u128>;\n                    libfunc rename_u128 = rename<u128>;\n                    libfunc rename_gb = rename<GasBuiltin>;\n                    Func1@1(a: u128, gb: GasBuiltin) -> (GasBuiltin);\n                    Func2@6() -> ();\n                \"})\n                .unwrap(),\n        ),\n        DebugInfo {\n            type_names: HashMap::from([\n                (\"u128\".into(), \"u128\".into()),\n                (\"GasBuiltin\".into(), \"GasBuiltin\".into()),\n                (\"NonZeroInt\".into(), \"NonZeroInt\".into())\n            ]),\n            libfunc_names: HashMap::from([\n                (\"rename_u128\".into(), \"rename_u128\".into()),\n                (\"rename_gb\".into(), \"rename_gb\".into())\n            ]),\n            user_func_names: HashMap::from([\n                (\"Func1\".into(), \"Func1\".into()),\n                (\"Func2\".into(), \"Func2\".into())\n            ]),\n        }\n    );\n}\n\n#[test]\nfn test_populate_names() {\n    let mut program = ProgramParser::new()\n        .parse(indoc! {\"\n        type [0] = u128;\n        type [1] = GasBuiltin;\n        type [2] = NonZero<[0]>;\n\n        libfunc [0] = rename<[0]>;\n        libfunc [1] = rename<[1]>;\n\n        [0](a) -> (a);\n        [1](gb) -> (gb);\n\n        Func1@1(a: [0], gb: [1]) -> ([1]);\n        Func2@6() -> ();\n    \"})\n        .unwrap();\n    DebugInfo {\n        type_names: HashMap::from([\n            (0.into(), \"u128\".into()),\n            (1.into(), \"GasBuiltin\".into()),\n            (2.into(), \"NonZeroInt\".into()),\n        ]),\n        libfunc_names: HashMap::from([\n            (0.into(), \"rename_u128\".into()),\n            (1.into(), \"rename_gb\".into()),\n        ]),\n        user_func_names: HashMap::from([(0.into(), \"Func1\".into()), (1.into(), \"Func2\".into())]),\n    }\n    .populate(&mut program);\n\n    assert_eq!(\n        program.to_string(),\n        indoc! {\"\n            type u128 = u128;\n            type GasBuiltin = GasBuiltin;\n            type NonZeroInt = NonZero<u128>;\n\n            libfunc rename_u128 = rename<u128>;\n            libfunc rename_gb = rename<GasBuiltin>;\n\n            rename_u128(a) -> (a);\n            rename_gb(gb) -> (gb);\n\n            Func1@1(a: u128, gb: GasBuiltin) -> (GasBuiltin);\n            Func2@6() -> ();\n        \"}\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashMap;\n\nuse thiserror::Error;\n\nuse crate::ids::VarId;\n\n#[cfg(test)]\n#[path = \"edit_state_test.rs\"]\nmod test;\n\n#[derive(Error, Debug, Eq, PartialEq)]\npub enum EditStateError {\n    #[error(\"Missing reference\")]\n    MissingReference(VarId),\n    #[error(\"Overridden variable\")]\n    VariableOverride(VarId),\n}\nimpl EditStateError {\n    pub fn var_id(self) -> VarId {\n        match self {\n            EditStateError::MissingReference(var_id) => var_id,\n            EditStateError::VariableOverride(var_id) => var_id,\n        }\n    }\n}\n\n/// Given a map with var ids as keys, extracts out the given ids, failing if some id is missing.\npub fn take_args<'a, V: 'a>(\n    mut state: HashMap<VarId, V>,\n    ids: impl Iterator<Item = &'a VarId>,\n) -> Result<(HashMap<VarId, V>, Vec<V>), EditStateError> {\n    let mut vals = vec![];\n    for id in ids {\n        match state.remove(id) {\n            None => {\n                return Err(EditStateError::MissingReference(id.clone()));\n            }\n            Some(v) => {\n                vals.push(v);\n            }\n        }\n    }\n    Ok((state, vals))\n}\n\n/// Adds the given pairs to map with var ids as keys, failing if some variable is overriden.\npub fn put_results<'a, V>(\n    mut state: HashMap<VarId, V>,\n    results: impl Iterator<Item = (&'a VarId, V)>,\n) -> Result<HashMap<VarId, V>, EditStateError> {\n    for (id, v) in results {\n        if state.insert(id.clone(), v).is_some() {\n            return Err(EditStateError::VariableOverride(id.clone()));\n        }\n    }\n    Ok(state)\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashMap;\n\nuse test_log::test;\n\nuse crate::edit_state::{put_results, take_args, EditStateError};\nuse crate::ids::VarId;\n\npub type State = HashMap<VarId, i64>;\n\n#[test]\nfn empty() {\n    assert_eq!(take_args(State::new(), vec![].into_iter()), Ok((State::new(), vec![])));\n    assert_eq!(put_results(State::new(), vec![].into_iter()), Ok(State::new()));\n}\n\n#[test]\nfn basic_mapping() {\n    assert_eq!(\n        take_args(State::from([(\"arg\".into(), 0)]), vec![&\"arg\".into()].into_iter(),),\n        Ok((State::new(), vec![0]))\n    );\n    assert_eq!(\n        put_results(State::new(), vec![(&\"res\".into(), 1)].into_iter(),),\n        Ok(State::from([(\"res\".into(), 1)]))\n    );\n    assert_eq!(\n        take_args(State::new(), vec![&\"arg\".into()].into_iter(),),\n        Err(EditStateError::MissingReference(\"arg\".into()))\n    );\n    assert_eq!(\n        put_results(State::from([(\"res\".into(), 1)]), vec![(&\"res\".into(), 1)].into_iter(),),\n        Err(EditStateError::VariableOverride(\"res\".into()))\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use super::ap_tracking::ApTrackingLibfunc;\nuse super::array::{ArrayLibfunc, ArrayType};\nuse super::bitwise::{BitwiseLibfunc, BitwiseType};\nuse super::boolean::BoolLibfunc;\nuse super::branch_align::BranchAlignLibfunc;\nuse super::builtin_cost::{BuiltinCostLibfunc, BuiltinCostsType};\nuse super::casts::CastLibfunc;\nuse super::debug::DebugLibfunc;\nuse super::drop::DropLibfunc;\nuse super::duplicate::DupLibfunc;\nuse super::ec::{EcLibfunc, EcOpType, EcPointType, EcStateType};\nuse super::enm::{EnumLibfunc, EnumType};\nuse super::felt252_dict::{Felt252DictLibfunc, Felt252DictType};\nuse super::modules::boxing::{BoxLibfunc, BoxType};\nuse super::modules::felt252::{Felt252Libfunc, Felt252Type};\nuse super::modules::function_call::FunctionCallLibfunc;\nuse super::modules::gas::{GasBuiltinType, GasLibfunc};\nuse super::modules::mem::MemLibfunc;\nuse super::modules::non_zero::{NonZeroType, UnwrapNonZeroLibfunc};\nuse super::modules::uint128::{Uint128Libfunc, Uint128Type};\nuse super::modules::unconditional_jump::UnconditionalJumpLibfunc;\nuse super::nullable::{NullableLibfunc, NullableType};\nuse super::pedersen::{PedersenLibfunc, PedersenType};\nuse super::range_check::RangeCheckType;\nuse super::segment_arena::SegmentArenaType;\nuse super::snapshot::{SnapshotTakeLibfunc, SnapshotType};\nuse super::squashed_felt252_dict::SquashedFelt252DictType;\nuse super::starknet::{StarkNetLibfunc, StarkNetType};\nuse super::structure::{StructLibfunc, StructType};\nuse super::uint::{\n    Uint16Libfunc, Uint16Type, Uint32Libfunc, Uint32Type, Uint64Libfunc, Uint64Type, Uint8Libfunc,\n    Uint8Type,\n};\nuse super::uninitialized::UninitializedType;\nuse crate::{define_libfunc_hierarchy, define_type_hierarchy};\n\ndefine_type_hierarchy! {\n    pub enum CoreType {\n        Array(ArrayType),\n        Bitwise(BitwiseType),\n        Box(BoxType),\n        EcOp(EcOpType),\n        EcPoint(EcPointType),\n        EcState(EcStateType),\n        Felt252(Felt252Type),\n        GasBuiltin(GasBuiltinType),\n        BuiltinCosts(BuiltinCostsType),\n        Uint8(Uint8Type),\n        Uint16(Uint16Type),\n        Uint32(Uint32Type),\n        Uint64(Uint64Type),\n        Uint128(Uint128Type),\n        NonZero(NonZeroType),\n        Nullable(NullableType),\n        RangeCheck(RangeCheckType),\n        Uninitialized(UninitializedType),\n        Enum(EnumType),\n        Struct(StructType),\n        Felt252Dict(Felt252DictType),\n        SquashedFelt252Dict(SquashedFelt252DictType),\n        Pedersen(PedersenType),\n        StarkNet(StarkNetType),\n        SegmentArena(SegmentArenaType),\n        Snapshot(SnapshotType),\n    }, CoreTypeConcrete\n}\n\ndefine_libfunc_hierarchy! {\n    pub enum CoreLibfunc {\n        ApTracking(ApTrackingLibfunc),\n        Array(ArrayLibfunc),\n        Bitwise(BitwiseLibfunc),\n        BranchAlign(BranchAlignLibfunc),\n        Bool(BoolLibfunc),\n        Box(BoxLibfunc),\n        BuiltinCost(BuiltinCostLibfunc),\n        Cast(CastLibfunc),\n        Drop(DropLibfunc),\n        Dup(DupLibfunc),\n        Ec(EcLibfunc),\n        Felt252(Felt252Libfunc),\n        FunctionCall(FunctionCallLibfunc),\n        Gas(GasLibfunc),\n        Uint8(Uint8Libfunc),\n        Uint16(Uint16Libfunc),\n        Uint32(Uint32Libfunc),\n        Uint64(Uint64Libfunc),\n        Uint128(Uint128Libfunc),\n        Mem(MemLibfunc),\n        Nullable(NullableLibfunc),\n        UnwrapNonZero(UnwrapNonZeroLibfunc),\n        UnconditionalJump(UnconditionalJumpLibfunc),\n        Enum(EnumLibfunc),\n        Struct(StructLibfunc),\n        Felt252Dict(Felt252DictLibfunc),\n        Pedersen(PedersenLibfunc),\n        StarkNet(StarkNetLibfunc),\n        Debug(DebugLibfunc),\n        SnapshotTake(SnapshotTakeLibfunc),\n    }, CoreConcreteLibfunc\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use num_bigint::BigInt;\nuse smol_str::SmolStr;\nuse thiserror::Error;\n\nuse crate::ids::{ConcreteTypeId, FunctionId, GenericLibfuncId, GenericTypeId};\nuse crate::program::GenericArg;\n\n/// Error occurring while specializing extensions.\n#[derive(Error, Debug, Eq, PartialEq)]\npub enum SpecializationError {\n    #[error(\"Could not find the requested extension: {0}\")]\n    UnsupportedId(SmolStr),\n    #[error(\"Expected a different number of generic arguments\")]\n    WrongNumberOfGenericArgs,\n    #[error(\"Provided generic argument is unsupported\")]\n    UnsupportedGenericArg,\n    #[error(\"index is out of a relevant range\")]\n    IndexOutOfRange {\n        index: BigInt,\n        /// Range is [0, range_size - 1]\n        range_size: usize,\n    },\n    #[error(\"Could not find the requested function\")]\n    MissingFunction(FunctionId),\n    #[error(\"Generic type was not specialized with such arguments\")]\n    TypeWasNotDeclared(GenericTypeId, Vec<GenericArg>),\n    #[error(\"Missing type info for the requested type\")]\n    MissingTypeInfo(ConcreteTypeId),\n}\n\n/// Extension related errors.\n#[derive(Error, Debug, Eq, PartialEq)]\npub enum ExtensionError {\n    #[error(\"Could not specialize type\")]\n    TypeSpecialization { type_id: GenericTypeId, error: SpecializationError },\n    #[error(\n        \"Could not specialize libfunc `{libfunc_id}` with generic_args: {generic_args:?}. Error: \\\n         {error}.\"\n    )]\n    LibfuncSpecialization {\n        libfunc_id: GenericLibfuncId,\n        generic_args: Vec<GenericArg>,\n        error: SpecializationError,\n    },\n    #[error(\"The requested functionality is not implemented yet\")]\n    NotImplemented,\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use itertools::Itertools;\n\nuse super::args_as_single_type;\nuse super::error::{ExtensionError, SpecializationError};\nuse super::type_specialization_context::TypeSpecializationContext;\nuse crate::ids::{ConcreteTypeId, FunctionId, GenericLibfuncId, GenericTypeId};\nuse crate::program::{Function, FunctionSignature, GenericArg};\n\n/// Trait for the specialization of libfunc signatures.\npub trait SignatureSpecializationContext: TypeSpecializationContext {\n    /// Returns concrete type id given a generic type and the generic arguments.\n    fn try_get_concrete_type(\n        &self,\n        id: GenericTypeId,\n        generic_args: &[GenericArg],\n    ) -> Option<ConcreteTypeId>;\n\n    /// Wraps [Self::try_get_concrete_type] with a result object.\n    fn get_concrete_type(\n        &self,\n        id: GenericTypeId,\n        generic_args: &[GenericArg],\n    ) -> Result<ConcreteTypeId, SpecializationError> {\n        self.try_get_concrete_type(id.clone(), generic_args)\n            .ok_or_else(|| SpecializationError::TypeWasNotDeclared(id, generic_args.to_vec()))\n    }\n\n    /// Returns the function's signature object associated with the given [FunctionId].\n    fn try_get_function_signature(&self, function_id: &FunctionId) -> Option<FunctionSignature>;\n\n    /// Wraps [Self::try_get_function_signature] with a result object.\n    fn get_function_signature(\n        &self,\n        function_id: &FunctionId,\n    ) -> Result<FunctionSignature, SpecializationError> {\n        self.try_get_function_signature(function_id)\n            .ok_or_else(|| SpecializationError::MissingFunction(function_id.clone()))\n    }\n\n    /// Returns the ap-change of the given function.\n    fn try_get_function_ap_change(&self, function_id: &FunctionId) -> Option<SierraApChange>;\n\n    /// Wraps [Self::try_get_function_ap_change] with a result object.\n    fn get_function_ap_change(\n        &self,\n        function_id: &FunctionId,\n    ) -> Result<SierraApChange, SpecializationError> {\n        self.try_get_function_ap_change(function_id)\n            .ok_or_else(|| SpecializationError::MissingFunction(function_id.clone()))\n    }\n\n    /// Returns the concrete id of `T<S>` given generic type T and concrete type S.\n    fn get_wrapped_concrete_type(\n        &self,\n        id: GenericTypeId,\n        wrapped: ConcreteTypeId,\n    ) -> Result<ConcreteTypeId, SpecializationError> {\n        self.get_concrete_type(id, &[GenericArg::Type(wrapped)])\n    }\n\n    /// Upcasting to the [TypeSpecializationContext], since trait upcasting is still experimental.\n    fn as_type_specialization_context(&self) -> &dyn TypeSpecializationContext;\n}\n\n/// Trait for the specialization of full libfuncs.\npub trait SpecializationContext: SignatureSpecializationContext {\n    /// Upcasting to the [SignatureSpecializationContext], since trait upcasting is still\n    /// experimental.\n    fn upcast(&self) -> &dyn SignatureSpecializationContext;\n\n    /// Returns the function object associated with the given [FunctionId].\n    fn try_get_function(&self, function_id: &FunctionId) -> Option<Function>;\n\n    /// Wraps [Self::try_get_function] with a result object.\n    fn get_function(&self, function_id: &FunctionId) -> Result<Function, SpecializationError> {\n        self.try_get_function(function_id)\n            .ok_or_else(|| SpecializationError::MissingFunction(function_id.clone()))\n    }\n}\n\n/// Trait for implementing a libfunc specialization generator.\npub trait GenericLibfunc: Sized {\n    type Concrete: ConcreteLibfunc;\n\n    /// Returns the list of generic libfuncs ids that can be instantiated through this type.\n    /// This is useful on hierarchical libfunc aggregates such as `CoreLibfunc`.\n    fn supported_ids() -> Vec<GenericLibfuncId>;\n\n    /// Instantiates the libfunc by id.\n    fn by_id(id: &GenericLibfuncId) -> Option<Self>;\n\n    /// Creates the specialization of the libfunc's signature with the template arguments.\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError>;\n\n    /// Creates the specialization with the template arguments.\n    fn specialize(\n        &self,\n        context: &dyn SpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<Self::Concrete, SpecializationError>;\n}\n\n/// Trait for introducing helper methods on [GenericLibfunc].\npub trait GenericLibfuncEx: GenericLibfunc {\n    fn specialize_signature_by_id(\n        context: &dyn SignatureSpecializationContext,\n        libfunc_id: &GenericLibfuncId,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, ExtensionError>;\n\n    fn specialize_by_id(\n        context: &dyn SpecializationContext,\n        libfunc_id: &GenericLibfuncId,\n        args: &[GenericArg],\n    ) -> Result<Self::Concrete, ExtensionError>;\n}\nimpl<TGenericLibfunc: GenericLibfunc> GenericLibfuncEx for TGenericLibfunc {\n    fn specialize_signature_by_id(\n        context: &dyn SignatureSpecializationContext,\n        libfunc_id: &GenericLibfuncId,\n        generic_args: &[GenericArg],\n    ) -> Result<LibfuncSignature, ExtensionError> {\n        if let Some(generic_libfunc) = Self::by_id(libfunc_id) {\n            generic_libfunc.specialize_signature(context, generic_args)\n        } else {\n            Err(SpecializationError::UnsupportedId(libfunc_id.0.clone()))\n        }\n        .map_err(move |error| ExtensionError::LibfuncSpecialization {\n            libfunc_id: libfunc_id.clone(),\n            generic_args: generic_args.iter().cloned().collect_vec(),\n            error,\n        })\n    }\n\n    fn specialize_by_id(\n        context: &dyn SpecializationContext,\n        libfunc_id: &GenericLibfuncId,\n        generic_args: &[GenericArg],\n    ) -> Result<TGenericLibfunc::Concrete, ExtensionError> {\n        if let Some(generic_libfunc) = Self::by_id(libfunc_id) {\n            generic_libfunc.specialize(context, generic_args)\n        } else {\n            Err(SpecializationError::UnsupportedId(libfunc_id.0.clone()))\n        }\n        .map_err(move |error| ExtensionError::LibfuncSpecialization {\n            libfunc_id: libfunc_id.clone(),\n            generic_args: generic_args.iter().cloned().collect_vec(),\n            error,\n        })\n    }\n}\n\n/// Trait for implementing a specialization generator with a simple id.\npub trait NamedLibfunc: Default {\n    type Concrete: ConcreteLibfunc;\n    const STR_ID: &'static str;\n\n    /// Creates the specialization of the libfunc's signature with the template arguments.\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError>;\n\n    /// Creates the specialization with the template arguments.\n    fn specialize(\n        &self,\n        context: &dyn SpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<Self::Concrete, SpecializationError>;\n}\nimpl<TNamedLibfunc: NamedLibfunc> GenericLibfunc for TNamedLibfunc {\n    type Concrete = <Self as NamedLibfunc>::Concrete;\n\n    fn supported_ids() -> Vec<GenericLibfuncId> {\n        vec![GenericLibfuncId::from(Self::STR_ID)]\n    }\n\n    fn by_id(id: &GenericLibfuncId) -> Option<Self> {\n        if Self::STR_ID == id.0 { Some(Self::default()) } else { None }\n    }\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        self.specialize_signature(context, args)\n    }\n\n    fn specialize(\n        &self,\n        context: &dyn SpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<Self::Concrete, SpecializationError> {\n        self.specialize(context, args)\n    }\n}\n\n/// Trait for implementing a specialization generator not holding anything more than a signature.\npub trait SignatureOnlyGenericLibfunc: Default {\n    const STR_ID: &'static str;\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError>;\n}\n\nimpl<T: SignatureOnlyGenericLibfunc> NamedLibfunc for T {\n    type Concrete = SignatureOnlyConcreteLibfunc;\n    const STR_ID: &'static str = <Self as SignatureOnlyGenericLibfunc>::STR_ID;\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        self.specialize_signature(context, args)\n    }\n\n    fn specialize(\n        &self,\n        context: &dyn SpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<Self::Concrete, SpecializationError> {\n        Ok(SignatureOnlyConcreteLibfunc {\n            signature: self.specialize_signature(context.upcast(), args)?,\n        })\n    }\n}\n\n/// Trait for implementing a specialization generator expecting a single generic param type, and\n/// creating a concrete libfunc containing that type as well.\npub trait SignatureAndTypeGenericLibfunc: Default {\n    const STR_ID: &'static str;\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        ty: ConcreteTypeId,\n    ) -> Result<LibfuncSignature, SpecializationError>;\n}\n\n/// Wrapper to prevent implementation collisions for [NamedLibfunc].\n#[derive(Default)]\npub struct WrapSignatureAndTypeGenericLibfunc<T: SignatureAndTypeGenericLibfunc>(T);\n\nimpl<T: SignatureAndTypeGenericLibfunc> NamedLibfunc for WrapSignatureAndTypeGenericLibfunc<T> {\n    type Concrete = SignatureAndTypeConcreteLibfunc;\n    const STR_ID: &'static str = <T as SignatureAndTypeGenericLibfunc>::STR_ID;\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        self.0.specialize_signature(context, args_as_single_type(args)?)\n    }\n\n    fn specialize(\n        &self,\n        context: &dyn SpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<Self::Concrete, SpecializationError> {\n        let ty = args_as_single_type(args)?;\n        Ok(SignatureAndTypeConcreteLibfunc {\n            ty: ty.clone(),\n            signature: self.0.specialize_signature(context.upcast(), ty)?,\n        })\n    }\n}\n\n/// Trait for implementing a specialization generator with no generic arguments.\npub trait NoGenericArgsGenericLibfunc: Default {\n    const STR_ID: &'static str;\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError>;\n}\nimpl<T: NoGenericArgsGenericLibfunc> SignatureOnlyGenericLibfunc for T {\n    const STR_ID: &'static str = <Self as NoGenericArgsGenericLibfunc>::STR_ID;\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        if args.is_empty() {\n            self.specialize_signature(context)\n        } else {\n            Err(SpecializationError::WrongNumberOfGenericArgs)\n        }\n    }\n}\n\n/// Information regarding a parameter of the libfunc.\npub struct ParamSignature {\n    /// The type of the parameter.\n    pub ty: ConcreteTypeId,\n    /// Whether the libfunc argument can be an expression of the form `[ap/fp + i] + [ap/fp + j]`.\n    /// For example, `store_temp()` and `store_local()`.\n    pub allow_deferred: bool,\n    /// Whether the libfunc argument can be an expression of the form `[ap + i] + const`.\n    pub allow_add_const: bool,\n    /// Whether the libfunc argument can be a constant.\n    pub allow_const: bool,\n}\nimpl ParamSignature {\n    /// Returns a [ParamSignature] with default attributes.\n    pub fn new(ty: ConcreteTypeId) -> Self {\n        Self { ty, allow_add_const: false, allow_deferred: false, allow_const: false }\n    }\n}\nimpl From<ConcreteTypeId> for ParamSignature {\n    fn from(ty: ConcreteTypeId) -> Self {\n        Self::new(ty)\n    }\n}\n\n/// Information regarding the reference created as an output of a library function.\n/// For example, whether the reference is equal to one of the parameters (as in the dup() function),\n/// or whether it's newly allocated local variable.\n#[derive(Debug)]\npub enum OutputVarReferenceInfo {\n    /// The output value is exactly the same as one of the parameters.\n    SameAsParam { param_idx: usize },\n    /// The output value is a part of one of the parameters.\n    /// For example, it may be the first element of a struct.\n    ///\n    /// Information, such as whether the parameter was a temporary or local variable, will be\n    /// copied to the output variable.\n    PartialParam { param_idx: usize },\n    /// The output was allocated as a temporary variable.\n    /// For the outputs that are at the top of the stack (contiguously), contains the index of the\n    /// temporary variable in the stack (0 is the lowest variable).\n    NewTempVar { idx: Option<usize> },\n    /// The output was allocated as a local variable.\n    NewLocalVar,\n    /// The output is the result of a computation. For example `[ap] + [fp]`,\n    /// `[ap + 1] * [fp - 3]`, `[ap] + 3`, `7`.\n    Deferred(DeferredOutputKind),\n}\n\n/// The type of a deferred output.\n#[derive(Clone, Debug, Eq, PartialEq)]\npub enum DeferredOutputKind {\n    /// The output is a constant. For example, `7`.\n    Const,\n    /// The output is the addition of a constant to one of the parameters. For example, `x + 3`.\n    AddConst { param_idx: usize },\n    /// The output is not one of the above (e.g., `[ap] + [fp]`, `[ap + 1] * [fp - 3]`,\n    /// `[ap] * 3`).\n    Generic,\n}\n\n/// Contains information regarding an output variable in a single branch.\n#[derive(Debug)]\npub struct OutputVarInfo {\n    pub ty: ConcreteTypeId,\n    pub ref_info: OutputVarReferenceInfo,\n}\n\n/// Contains information on the variables returned in a single libfunc branch\n/// for all the output variables in an output branch.\n///\n/// See [OutputVarInfo].\n#[derive(Debug)]\npub struct BranchSignature {\n    /// Information about the new variables created in the branch.\n    pub vars: Vec<OutputVarInfo>,\n    /// Information about the change in the `ap` register in the branch.\n    pub ap_change: SierraApChange,\n}\n\n/// Describes the effect on the `ap` register in a given libfunc branch.\n#[derive(Clone, Debug, Eq, PartialEq)]\npub enum SierraApChange {\n    /// The libfunc changes `ap` in an unknown way.\n    Unknown,\n    /// The libfunc changes `ap` in a known (during compilation) way.\n    Known {\n        /// `true` if all the new stack cells created by the libfunc are its output\n        /// variables (as described in [OutputVarReferenceInfo::NewTempVar] in\n        /// [`BranchSignature::vars`]).\n        new_vars_only: bool,\n    },\n    /// The lib func is `branch_align`.\n    /// The `ap` change is know during compilation.\n    BranchAlign,\n}\n/// Trait for a specialized library function.\npub trait ConcreteLibfunc {\n    /// The parameter types and other information for the parameters for calling a library\n    /// function.\n    fn param_signatures(&self) -> &[ParamSignature];\n    /// The output types and other information returning from a library function per branch.\n    fn branch_signatures(&self) -> &[BranchSignature];\n    /// The index of the fallthrough branch of the library function if any.\n    fn fallthrough(&self) -> Option<usize>;\n\n    /// Returns the output types returning from a library function per branch.\n    fn output_types(&self) -> Vec<Vec<ConcreteTypeId>> {\n        self.branch_signatures()\n            .iter()\n            .map(|branch_info| {\n                branch_info.vars.iter().map(|var_info| var_info.ty.clone()).collect()\n            })\n            .collect()\n    }\n}\n\n/// Represents the signature of a library function.\npub struct LibfuncSignature {\n    /// The parameter types and other information for the parameters for calling a library\n    /// function.\n    pub param_signatures: Vec<ParamSignature>,\n    /// The output types and other information for the return values of a library function per\n    /// branch.\n    pub branch_signatures: Vec<BranchSignature>,\n    /// The index of the fallthrough branch of the library function if any.\n    pub fallthrough: Option<usize>,\n}\nimpl LibfuncSignature {\n    /// Creates a non branch signature.\n    pub fn new_non_branch(\n        input_types: Vec<ConcreteTypeId>,\n        output_info: Vec<OutputVarInfo>,\n        ap_change: SierraApChange,\n    ) -> Self {\n        Self::new_non_branch_ex(\n            input_types.into_iter().map(ParamSignature::new).collect(),\n            output_info,\n            ap_change,\n        )\n    }\n\n    /// Same as [LibfuncSignature::new_non_branch], except that more complicated [ParamSignature]\n    /// are supported.\n    pub fn new_non_branch_ex(\n        param_signatures: Vec<ParamSignature>,\n        output_info: Vec<OutputVarInfo>,\n        ap_change: SierraApChange,\n    ) -> LibfuncSignature {\n        Self {\n            param_signatures,\n            branch_signatures: vec![BranchSignature { vars: output_info, ap_change }],\n            fallthrough: Some(0),\n        }\n    }\n}\n\n/// Trait for implementing a [ConcreteLibfunc] that returns a reference to the full signature of the\n/// library function.\npub trait SignatureBasedConcreteLibfunc {\n    fn signature(&self) -> &LibfuncSignature;\n}\n\nimpl<TSignatureBasedConcreteLibfunc: SignatureBasedConcreteLibfunc> ConcreteLibfunc\n    for TSignatureBasedConcreteLibfunc\n{\n    fn param_signatures(&self) -> &[ParamSignature] {\n        &self.signature().param_signatures\n    }\n    fn branch_signatures(&self) -> &[BranchSignature] {\n        &self.signature().branch_signatures\n    }\n    fn fallthrough(&self) -> Option<usize> {\n        self.signature().fallthrough\n    }\n}\n\n/// Struct providing a [ConcreteLibfunc] only with a signature and a type.\npub struct SignatureAndTypeConcreteLibfunc {\n    pub ty: ConcreteTypeId,\n    pub signature: LibfuncSignature,\n}\nimpl SignatureBasedConcreteLibfunc for SignatureAndTypeConcreteLibfunc {\n    fn signature(&self) -> &LibfuncSignature {\n        &self.signature\n    }\n}\n\n/// Struct providing a [ConcreteLibfunc] only with a signature - should not be implemented for\n/// concrete libfuncs that require any extra data.\npub struct SignatureOnlyConcreteLibfunc {\n    pub signature: LibfuncSignature,\n}\nimpl SignatureBasedConcreteLibfunc for SignatureOnlyConcreteLibfunc {\n    fn signature(&self) -> &LibfuncSignature {\n        &self.signature\n    }\n}\n\n/// Forms a concrete library function type from an enum of library calls.\n/// The new enum implements [ConcreteLibfunc].\n/// All the variant types must also implement [ConcreteLibfunc].\n/// Usage example:\n/// ```ignore\n/// define_concrete_libfunc_hierarchy! {\n///     pub enum MyLibfunc {\n///       LF0(Libfunc0),\n///       LF1(Libfunc1),\n///     }\n/// }\n/// ```\n#[macro_export]\nmacro_rules! define_concrete_libfunc_hierarchy {\n    (pub enum $name:ident { $($variant_name:ident ($variant:ty),)* }) => {\n        #[allow(clippy::enum_variant_names)]\n        pub enum $name {\n            $($variant_name ($variant),)*\n        }\n        impl $crate::extensions::ConcreteLibfunc for $name {\n            $crate::extensions::lib_func::concrete_method_impl! {\n                fn param_signatures(&self) -> &[$crate::extensions::lib_func::ParamSignature] {\n                    $($variant_name => $variant,)*\n                }\n            }\n            $crate::extensions::lib_func::concrete_method_impl!{\n                fn branch_signatures(&self) -> &[$crate::extensions::lib_func::BranchSignature] {\n                    $($variant_name => $variant,)*\n                }\n            }\n            $crate::extensions::lib_func::concrete_method_impl!{\n                fn fallthrough(&self) -> Option<usize> {\n                    $($variant_name => $variant,)*\n                }\n            }\n        }\n    }\n}\n\n/// Implements a method for an enum of library calls by recursively calling the enum option existing\n/// implementation.\nmacro_rules! concrete_method_impl {\n    (fn $method_name:ident(&self $(,$var_name:ident : $var:ty)*) -> $ret_type:ty {\n        $($variant_name:ident => $variant:ty,)*\n    }) => {\n        fn $method_name(&self $(,$var_name:ident : $var:ty)*) -> $ret_type {\n            match self {\n                $(Self::$variant_name(value) => value.$method_name()),*\n            }\n        }\n    }\n}\npub(crate) use concrete_method_impl;\n\n/// Forms a libfunc type from an enum of libfuncs.\n/// The new enum implements [GenericLibfunc].\n/// All the variant types must also implement [GenericLibfunc].\n/// Usage example:\n/// ```ignore\n/// define_libfunc_hierarchy! {\n///     pub enum MyLibfunc {\n///       LF0(Libfunc0),\n///       LF1(Libfunc1),\n///     }, MyLibfuncConcrete\n/// }\n/// ```\n#[macro_export]\nmacro_rules! define_libfunc_hierarchy {\n    (pub enum $name:ident { $($variant_name:ident ($variant:ty),)* },\n    $concrete_name:ident) => {\n        #[allow(clippy::enum_variant_names)]\n        pub enum $name {\n            $($variant_name ($variant)),*\n        }\n\n        impl $crate::extensions::GenericLibfunc for $name {\n            type Concrete = $concrete_name;\n            fn supported_ids() -> Vec<$crate::ids::GenericLibfuncId> {\n                itertools::chain!(\n                    $(\n                        <$variant as $crate::extensions::GenericLibfunc>::supported_ids()\n                    ),*\n                ).collect()\n            }\n            fn by_id(id: &$crate::ids::GenericLibfuncId) -> Option<Self> {\n                $(\n                    if let Some(res) = <$variant>::by_id(id){\n                        return Some(Self::$variant_name(res));\n                    }\n                )*\n                None\n            }\n            fn specialize_signature(\n                    &self,\n                    context: &dyn $crate::extensions::lib_func::SignatureSpecializationContext,\n                    args: &[$crate::program::GenericArg],\n            ) -> Result<\n                    $crate::extensions::lib_func::LibfuncSignature,\n                    $crate::extensions::SpecializationError\n                >{\n                match self {\n                    $(\n                        Self::$variant_name(value) => {\n                            <$variant as $crate::extensions::GenericLibfunc>::specialize_signature(\n                                value, context, args,\n                            )\n                        }\n                    ),*\n                }\n            }\n            fn specialize(\n                    &self,\n                    context: &dyn $crate::extensions::lib_func::SpecializationContext,\n                    args: &[$crate::program::GenericArg],\n            ) -> Result<Self::Concrete, $crate::extensions::SpecializationError>{\n                match self {\n                    $(\n                        Self::$variant_name(value) => {\n                            Ok(Self::Concrete::$variant_name(\n                                <$variant as $crate::extensions::GenericLibfunc>::specialize(\n                                    value, context, args,\n                                )?\n                                .into(),\n                            ))\n                        }\n                    ),*\n                }\n            }\n        }\n\n        $crate::define_concrete_libfunc_hierarchy! {\n            pub enum $concrete_name {\n                $($variant_name (<$variant as $crate::extensions::GenericLibfunc> ::Concrete),)*\n            }\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "/// Module for the set of core extensions.\npub mod core;\npub mod error;\npub mod lib_func;\n/// All implementations of basic extensions are under this module.\npub mod modules;\npub mod type_specialization_context;\npub mod types;\n\npub use self::error::{ExtensionError, SpecializationError};\npub use self::lib_func::{\n    ConcreteLibfunc, GenericLibfunc, GenericLibfuncEx, NamedLibfunc, NoGenericArgsGenericLibfunc,\n    OutputVarReferenceInfo, SignatureBasedConcreteLibfunc,\n};\npub use self::modules::*;\npub use self::types::{\n    ConcreteType, GenericType, GenericTypeEx, NamedType, NoGenericArgsGenericType,\n};\nuse crate::ids::ConcreteTypeId;\nuse crate::program::GenericArg;\n\n/// Helper for extracting the type from the template arguments.\nfn args_as_single_type(args: &[GenericArg]) -> Result<ConcreteTypeId, SpecializationError> {\n    match args {\n        [GenericArg::Type(ty)] => Ok(ty.clone()),\n        [_] => Err(SpecializationError::UnsupportedGenericArg),\n        _ => Err(SpecializationError::WrongNumberOfGenericArgs),\n    }\n}\n\n/// Helper for extracting two types from the template arguments.\nfn args_as_two_types(\n    args: &[GenericArg],\n) -> Result<(ConcreteTypeId, ConcreteTypeId), SpecializationError> {\n    match args {\n        [GenericArg::Type(ty0), GenericArg::Type(ty1)] => Ok((ty0.clone(), ty1.clone())),\n        [_, _] => Err(SpecializationError::UnsupportedGenericArg),\n        _ => Err(SpecializationError::WrongNumberOfGenericArgs),\n    }\n}\n\n#[cfg(test)]\nmod test;\n",
    "metadata": {}
  },
  {
    "pageContent": "use crate::define_libfunc_hierarchy;\nuse crate::extensions::lib_func::{\n    LibfuncSignature, SierraApChange, SignatureSpecializationContext,\n};\nuse crate::extensions::{NoGenericArgsGenericLibfunc, SpecializationError};\n\ndefine_libfunc_hierarchy! {\n    pub enum ApTrackingLibfunc {\n        Revoke(RevokeApTrackingLibfunc),\n        Enable(EnableApTrackingLibfunc),\n        Disable(DisableApTrackingLibfunc),\n    }, ApTrackingConcreteLibfunc\n}\n\n/// Revoke the ap tracking.\n/// This Libfunc is changes to ap_tracking state to unknown,\n/// allowing a path with known ap tracking to converge with a path with unknown ap tracking.\n#[derive(Default)]\npub struct RevokeApTrackingLibfunc {}\nimpl NoGenericArgsGenericLibfunc for RevokeApTrackingLibfunc {\n    const STR_ID: &'static str = \"revoke_ap_tracking\";\n\n    fn specialize_signature(\n        &self,\n        _context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        Ok(LibfuncSignature::new_non_branch(vec![], vec![], SierraApChange::Unknown))\n    }\n}\n\n/// Enable ap tracking.\n/// This Libfunc is used to enable ap tracking to allow branches that may diverge and merge after\n/// this point to have an aligned ap.\n#[derive(Default)]\npub struct EnableApTrackingLibfunc {}\nimpl NoGenericArgsGenericLibfunc for EnableApTrackingLibfunc {\n    const STR_ID: &'static str = \"enable_ap_tracking\";\n\n    fn specialize_signature(\n        &self,\n        _context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        Ok(LibfuncSignature::new_non_branch(\n            vec![],\n            vec![],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n\n/// Disable ap tracking.\n/// This Libfunc is used to disable ap tracking to allow merging branches that some have unknown ap\n/// change, without actually revoking the local stack.\n#[derive(Default)]\npub struct DisableApTrackingLibfunc {}\nimpl NoGenericArgsGenericLibfunc for DisableApTrackingLibfunc {\n    const STR_ID: &'static str = \"disable_ap_tracking\";\n\n    fn specialize_signature(\n        &self,\n        _context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        Ok(LibfuncSignature::new_non_branch(\n            vec![],\n            vec![],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use super::range_check::RangeCheckType;\nuse super::snapshot::snapshot_ty;\nuse super::starknet::getter::boxed_ty;\nuse crate::define_libfunc_hierarchy;\nuse crate::extensions::lib_func::{\n    BranchSignature, DeferredOutputKind, LibfuncSignature, OutputVarInfo, ParamSignature,\n    SierraApChange, SignatureAndTypeGenericLibfunc, SignatureOnlyGenericLibfunc,\n    SignatureSpecializationContext, WrapSignatureAndTypeGenericLibfunc,\n};\nuse crate::extensions::types::{\n    GenericTypeArgGenericType, GenericTypeArgGenericTypeWrapper, TypeInfo,\n};\nuse crate::extensions::{\n    args_as_single_type, NamedType, OutputVarReferenceInfo, SpecializationError,\n};\nuse crate::ids::{ConcreteTypeId, GenericTypeId};\nuse crate::program::GenericArg;\n\ntype ArrayIndexType = super::uint::Uint32Type;\n\n/// Type representing an array.\n#[derive(Default)]\npub struct ArrayTypeWrapped {}\nimpl GenericTypeArgGenericType for ArrayTypeWrapped {\n    const ID: GenericTypeId = GenericTypeId::new_inline(\"Array\");\n\n    fn calc_info(\n        &self,\n        long_id: crate::program::ConcreteTypeLongId,\n        TypeInfo { storable, droppable, size, .. }: TypeInfo,\n    ) -> Result<TypeInfo, SpecializationError> {\n        if storable && size > 0 {\n            Ok(TypeInfo { long_id, duplicatable: false, droppable, storable: true, size: 2 })\n        } else {\n            Err(SpecializationError::UnsupportedGenericArg)\n        }\n    }\n}\npub type ArrayType = GenericTypeArgGenericTypeWrapper<ArrayTypeWrapped>;\n\ndefine_libfunc_hierarchy! {\n    pub enum ArrayLibfunc {\n        New(ArrayNewLibfunc),\n        Append(ArrayAppendLibfunc),\n        PopFront(ArrayPopFrontLibfunc),\n        Get(ArrayGetLibfunc),\n        Len(ArrayLenLibfunc),\n        SnapshotPopFront(ArraySnapshotPopFrontLibfunc),\n    }, ArrayConcreteLibfunc\n}\n\n/// Libfunc for creating a new array.\n#[derive(Default)]\npub struct ArrayNewLibfunc {}\nimpl SignatureOnlyGenericLibfunc for ArrayNewLibfunc {\n    const STR_ID: &'static str = \"array_new\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let ty = args_as_single_type(args)?;\n        Ok(LibfuncSignature::new_non_branch(\n            vec![],\n            vec![OutputVarInfo {\n                ty: context.get_wrapped_concrete_type(ArrayType::id(), ty)?,\n                ref_info: OutputVarReferenceInfo::NewTempVar { idx: None },\n            }],\n            SierraApChange::Known { new_vars_only: false },\n        ))\n    }\n}\n\n/// Libfunc for getting the length of the array.\n#[derive(Default)]\npub struct ArrayLenLibfuncWrapped {}\nimpl SignatureAndTypeGenericLibfunc for ArrayLenLibfuncWrapped {\n    const STR_ID: &'static str = \"array_len\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        ty: ConcreteTypeId,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let arr_ty = context.get_wrapped_concrete_type(ArrayType::id(), ty)?;\n        Ok(LibfuncSignature::new_non_branch(\n            vec![snapshot_ty(context, arr_ty)?],\n            vec![OutputVarInfo {\n                ty: context.get_concrete_type(ArrayIndexType::id(), &[])?,\n                ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n            }],\n            SierraApChange::Known { new_vars_only: false },\n        ))\n    }\n}\npub type ArrayLenLibfunc = WrapSignatureAndTypeGenericLibfunc<ArrayLenLibfuncWrapped>;\n\n/// Libfunc for pushing a value into the end of an array.\n#[derive(Default)]\npub struct ArrayAppendLibfuncWrapped {}\nimpl SignatureAndTypeGenericLibfunc for ArrayAppendLibfuncWrapped {\n    const STR_ID: &'static str = \"array_append\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        ty: ConcreteTypeId,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let arr_ty = context.get_wrapped_concrete_type(ArrayType::id(), ty.clone())?;\n        Ok(LibfuncSignature::new_non_branch_ex(\n            vec![\n                ParamSignature {\n                    ty: arr_ty.clone(),\n                    allow_deferred: false,\n                    allow_add_const: true,\n                    allow_const: false,\n                },\n                ParamSignature::new(ty),\n            ],\n            vec![OutputVarInfo {\n                ty: arr_ty,\n                ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::AddConst {\n                    param_idx: 0,\n                }),\n            }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\npub type ArrayAppendLibfunc = WrapSignatureAndTypeGenericLibfunc<ArrayAppendLibfuncWrapped>;\n\n/// Libfunc for popping the first value from the begining of an array.\n#[derive(Default)]\npub struct ArrayPopFrontLibfuncWrapped {}\nimpl SignatureAndTypeGenericLibfunc for ArrayPopFrontLibfuncWrapped {\n    const STR_ID: &'static str = \"array_pop_front\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        ty: ConcreteTypeId,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let arr_ty = context.get_wrapped_concrete_type(ArrayType::id(), ty.clone())?;\n        Ok(LibfuncSignature {\n            param_signatures: vec![ParamSignature::new(arr_ty.clone())],\n            branch_signatures: vec![\n                // Non-empty.\n                BranchSignature {\n                    vars: vec![\n                        OutputVarInfo {\n                            ty: arr_ty.clone(),\n                            ref_info: OutputVarReferenceInfo::Deferred(\n                                DeferredOutputKind::AddConst { param_idx: 0 },\n                            ),\n                        },\n                        OutputVarInfo {\n                            ty: boxed_ty(context, ty)?,\n                            ref_info: OutputVarReferenceInfo::PartialParam { param_idx: 0 },\n                        },\n                    ],\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n                // Empty.\n                BranchSignature {\n                    vars: vec![OutputVarInfo {\n                        ty: arr_ty,\n                        ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 0 },\n                    }],\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n            ],\n            fallthrough: Some(0),\n        })\n    }\n}\npub type ArrayPopFrontLibfunc = WrapSignatureAndTypeGenericLibfunc<ArrayPopFrontLibfuncWrapped>;\n\n/// Libfunc for fetching a value from a specific array index.\n#[derive(Default)]\npub struct ArrayGetLibfuncWrapped {}\nimpl SignatureAndTypeGenericLibfunc for ArrayGetLibfuncWrapped {\n    const STR_ID: &'static str = \"array_get\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        ty: ConcreteTypeId,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let arr_type = context.get_wrapped_concrete_type(ArrayType::id(), ty.clone())?;\n        let range_check_type = context.get_concrete_type(RangeCheckType::id(), &[])?;\n        let index_type = context.get_concrete_type(ArrayIndexType::id(), &[])?;\n        let param_signatures = vec![\n            ParamSignature::new(range_check_type.clone()),\n            ParamSignature::new(snapshot_ty(context, arr_type)?),\n            ParamSignature::new(index_type),\n        ];\n        let branch_signatures = vec![\n            // First (success) branch returns rc, array and element; failure branch does not return\n            // an element.\n            BranchSignature {\n                vars: vec![\n                    OutputVarInfo {\n                        ty: range_check_type.clone(),\n                        ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::AddConst {\n                            param_idx: 0,\n                        }),\n                    },\n                    OutputVarInfo {\n                        ty: boxed_ty(context, snapshot_ty(context, ty)?)?,\n                        ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n                    },\n                ],\n                ap_change: SierraApChange::Known { new_vars_only: false },\n            },\n            BranchSignature {\n                vars: vec![OutputVarInfo {\n                    ty: range_check_type,\n                    ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::AddConst {\n                        param_idx: 0,\n                    }),\n                }],\n                ap_change: SierraApChange::Known { new_vars_only: false },\n            },\n        ];\n        Ok(LibfuncSignature { param_signatures, branch_signatures, fallthrough: Some(0) })\n    }\n}\npub type ArrayGetLibfunc = WrapSignatureAndTypeGenericLibfunc<ArrayGetLibfuncWrapped>;\n\n/// Libfunc for popping the first value from the begining of an array snapshot.\n#[derive(Default)]\npub struct ArraySnapshotPopFrontLibfuncWrapped {}\nimpl SignatureAndTypeGenericLibfunc for ArraySnapshotPopFrontLibfuncWrapped {\n    const STR_ID: &'static str = \"array_snapshot_pop_front\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        ty: ConcreteTypeId,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let arr_ty = context.get_wrapped_concrete_type(ArrayType::id(), ty.clone())?;\n        let arr_snapshot_ty = snapshot_ty(context, arr_ty)?;\n        Ok(LibfuncSignature {\n            param_signatures: vec![ParamSignature::new(arr_snapshot_ty.clone())],\n            branch_signatures: vec![\n                BranchSignature {\n                    vars: vec![\n                        OutputVarInfo {\n                            ty: arr_snapshot_ty.clone(),\n                            ref_info: OutputVarReferenceInfo::Deferred(\n                                DeferredOutputKind::AddConst { param_idx: 0 },\n                            ),\n                        },\n                        OutputVarInfo {\n                            ty: boxed_ty(context, snapshot_ty(context, ty)?)?,\n                            ref_info: OutputVarReferenceInfo::PartialParam { param_idx: 0 },\n                        },\n                    ],\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n                BranchSignature {\n                    vars: vec![OutputVarInfo {\n                        ty: arr_snapshot_ty,\n                        ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 0 },\n                    }],\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n            ],\n            fallthrough: Some(0),\n        })\n    }\n}\npub type ArraySnapshotPopFrontLibfunc =\n    WrapSignatureAndTypeGenericLibfunc<ArraySnapshotPopFrontLibfuncWrapped>;\n",
    "metadata": {}
  },
  {
    "pageContent": "use super::uint128::Uint128Type;\nuse crate::extensions::lib_func::{\n    DeferredOutputKind, LibfuncSignature, OutputVarInfo, ParamSignature, SierraApChange,\n    SignatureSpecializationContext,\n};\nuse crate::extensions::{\n    NamedType, NoGenericArgsGenericLibfunc, NoGenericArgsGenericType, OutputVarReferenceInfo,\n    SpecializationError,\n};\nuse crate::ids::GenericTypeId;\n\n/// Type representing the Bitwise builtin.\n#[derive(Default)]\npub struct BitwiseType {}\nimpl NoGenericArgsGenericType for BitwiseType {\n    const ID: GenericTypeId = GenericTypeId::new_inline(\"Bitwise\");\n    const STORABLE: bool = true;\n    const DUPLICATABLE: bool = false;\n    const DROPPABLE: bool = false;\n    const SIZE: i16 = 1;\n}\n\n/// Libfunc for computing the Bitwise (and,or,xor) of two u128s.\n/// Returns 3 u128s (and the updated builtin pointer).\n#[derive(Default)]\npub struct BitwiseLibfunc {}\nimpl NoGenericArgsGenericLibfunc for BitwiseLibfunc {\n    const STR_ID: &'static str = \"bitwise\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let bitwise_ty = context.get_concrete_type(BitwiseType::id(), &[])?;\n        let u128_ty = context.get_concrete_type(Uint128Type::id(), &[])?;\n        Ok(LibfuncSignature::new_non_branch_ex(\n            vec![\n                ParamSignature {\n                    ty: bitwise_ty.clone(),\n                    allow_deferred: false,\n                    allow_add_const: true,\n                    allow_const: false,\n                },\n                ParamSignature::new(u128_ty.clone()),\n                ParamSignature::new(u128_ty.clone()),\n            ],\n            vec![\n                OutputVarInfo {\n                    ty: bitwise_ty,\n                    ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::AddConst {\n                        param_idx: 0,\n                    }),\n                },\n                OutputVarInfo {\n                    ty: u128_ty.clone(),\n                    ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n                },\n                OutputVarInfo {\n                    ty: u128_ty.clone(),\n                    ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n                },\n                OutputVarInfo {\n                    ty: u128_ty,\n                    ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n                },\n            ],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use super::get_bool_type;\nuse crate::define_libfunc_hierarchy;\nuse crate::extensions::felt252::Felt252Type;\nuse crate::extensions::lib_func::{\n    DeferredOutputKind, LibfuncSignature, OutputVarInfo, ParamSignature, SierraApChange,\n    SignatureSpecializationContext,\n};\nuse crate::extensions::{\n    NamedType, NoGenericArgsGenericLibfunc, OutputVarReferenceInfo, SpecializationError,\n};\n\ndefine_libfunc_hierarchy! {\n    pub enum BoolLibfunc {\n        And(BoolAndLibfunc),\n        Not(BoolNotLibfunc),\n        Xor(BoolXorLibfunc),\n        Or(BoolOrLibfunc),\n        ToFelt252(BoolToFelt252Libfunc),\n    }, BoolConcreteLibfunc\n}\n\n/// Libfunc for converting a bool into a felt252.\n#[derive(Default)]\npub struct BoolToFelt252Libfunc {}\nimpl NoGenericArgsGenericLibfunc for BoolToFelt252Libfunc {\n    const STR_ID: &'static str = \"bool_to_felt252\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        Ok(LibfuncSignature::new_non_branch_ex(\n            vec![ParamSignature {\n                ty: get_bool_type(context)?,\n                allow_deferred: true,\n                allow_add_const: true,\n                allow_const: true,\n            }],\n            vec![OutputVarInfo {\n                ty: context.get_concrete_type(Felt252Type::id(), &[])?,\n                ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 0 },\n            }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n\n/// Utility for common boolean libfunc signature definitions.\nfn boolean_libfunc_signature(\n    context: &dyn SignatureSpecializationContext,\n    new_vars_only: bool,\n    is_unary: bool,\n) -> Result<LibfuncSignature, SpecializationError> {\n    let bool_type = get_bool_type(context)?;\n    Ok(LibfuncSignature::new_non_branch(\n        if is_unary { vec![bool_type.clone()] } else { vec![bool_type.clone(), bool_type.clone()] },\n        vec![OutputVarInfo {\n            ty: bool_type,\n            ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n        }],\n        SierraApChange::Known { new_vars_only },\n    ))\n}\n\n/// Libfunc for boolean AND.\n#[derive(Default)]\npub struct BoolAndLibfunc {}\nimpl NoGenericArgsGenericLibfunc for BoolAndLibfunc {\n    const STR_ID: &'static str = \"bool_and_impl\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        boolean_libfunc_signature(context, true, false)\n    }\n}\n\n/// Libfunc for boolean NOT.\n#[derive(Default)]\npub struct BoolNotLibfunc {}\nimpl NoGenericArgsGenericLibfunc for BoolNotLibfunc {\n    const STR_ID: &'static str = \"bool_not_impl\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        boolean_libfunc_signature(context, false, true)\n    }\n}\n\n/// Libfunc for boolean XOR.\n#[derive(Default)]\npub struct BoolXorLibfunc {}\nimpl NoGenericArgsGenericLibfunc for BoolXorLibfunc {\n    const STR_ID: &'static str = \"bool_xor_impl\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        boolean_libfunc_signature(context, false, false)\n    }\n}\n\n/// Libfunc for boolean OR.\n#[derive(Default)]\npub struct BoolOrLibfunc {}\nimpl NoGenericArgsGenericLibfunc for BoolOrLibfunc {\n    const STR_ID: &'static str = \"bool_or_impl\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        boolean_libfunc_signature(context, false, false)\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use crate::define_libfunc_hierarchy;\nuse crate::extensions::lib_func::{\n    DeferredOutputKind, LibfuncSignature, OutputVarInfo, SierraApChange,\n    SignatureAndTypeGenericLibfunc, SignatureSpecializationContext,\n    WrapSignatureAndTypeGenericLibfunc,\n};\nuse crate::extensions::types::{\n    GenericTypeArgGenericType, GenericTypeArgGenericTypeWrapper, TypeInfo,\n};\nuse crate::extensions::{NamedType, OutputVarReferenceInfo, SpecializationError};\nuse crate::ids::{ConcreteTypeId, GenericTypeId};\n\n/// Type wrapping a value.\n#[derive(Default)]\npub struct BoxTypeWrapped {}\nimpl GenericTypeArgGenericType for BoxTypeWrapped {\n    const ID: GenericTypeId = GenericTypeId::new_inline(\"Box\");\n\n    fn calc_info(\n        &self,\n        long_id: crate::program::ConcreteTypeLongId,\n        TypeInfo { storable, droppable, duplicatable, .. }: TypeInfo,\n    ) -> Result<TypeInfo, SpecializationError> {\n        if storable {\n            Ok(TypeInfo { long_id, size: 1, storable, droppable, duplicatable })\n        } else {\n            Err(SpecializationError::UnsupportedGenericArg)\n        }\n    }\n}\npub type BoxType = GenericTypeArgGenericTypeWrapper<BoxTypeWrapped>;\n\ndefine_libfunc_hierarchy! {\n    pub enum BoxLibfunc {\n        Into(IntoBoxLibfunc),\n        Unbox(UnboxLibfunc),\n    }, BoxConcreteLibfunc\n}\n\n/// Libfunc for wrapping an object of type T into a box.\n#[derive(Default)]\npub struct IntoBoxLibfuncWrapped {}\nimpl SignatureAndTypeGenericLibfunc for IntoBoxLibfuncWrapped {\n    const STR_ID: &'static str = \"into_box\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        ty: ConcreteTypeId,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        Ok(LibfuncSignature::new_non_branch(\n            vec![ty.clone()],\n            vec![OutputVarInfo {\n                ty: context.get_wrapped_concrete_type(BoxType::id(), ty)?,\n                ref_info: OutputVarReferenceInfo::NewTempVar { idx: Some(0) },\n            }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\npub type IntoBoxLibfunc = WrapSignatureAndTypeGenericLibfunc<IntoBoxLibfuncWrapped>;\n\n/// Libfunc for unboxing a `Box<T>` back into a T.\n#[derive(Default)]\npub struct UnboxLibfuncWrapped {}\nimpl SignatureAndTypeGenericLibfunc for UnboxLibfuncWrapped {\n    const STR_ID: &'static str = \"unbox\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        ty: ConcreteTypeId,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        Ok(LibfuncSignature::new_non_branch(\n            vec![context.get_wrapped_concrete_type(BoxType::id(), ty.clone())?],\n            vec![OutputVarInfo {\n                ty,\n                ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n            }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\npub type UnboxLibfunc = WrapSignatureAndTypeGenericLibfunc<UnboxLibfuncWrapped>;\n",
    "metadata": {}
  },
  {
    "pageContent": "use crate::extensions::lib_func::{\n    LibfuncSignature, SierraApChange, SignatureSpecializationContext,\n};\nuse crate::extensions::{NoGenericArgsGenericLibfunc, SpecializationError};\n\n/// Libfunc for aligning branches.\n/// Used to equalize environment changes across merging paths.\n/// This may include gas usages and ap changes.\n#[derive(Default)]\npub struct BranchAlignLibfunc {}\nimpl NoGenericArgsGenericLibfunc for BranchAlignLibfunc {\n    const STR_ID: &'static str = \"branch_align\";\n\n    fn specialize_signature(\n        &self,\n        _context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        Ok(LibfuncSignature::new_non_branch(vec![], vec![], SierraApChange::BranchAlign))\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use convert_case::Casing;\nuse itertools::chain;\n\nuse super::gas::GasBuiltinType;\nuse super::range_check::RangeCheckType;\nuse crate::define_libfunc_hierarchy;\nuse crate::extensions::lib_func::{\n    BranchSignature, DeferredOutputKind, LibfuncSignature, OutputVarInfo, ParamSignature,\n    SierraApChange, SignatureSpecializationContext,\n};\nuse crate::extensions::{\n    NamedType, NoGenericArgsGenericLibfunc, NoGenericArgsGenericType, OutputVarReferenceInfo,\n    SpecializationError,\n};\nuse crate::ids::GenericTypeId;\n\n/// Represents different type of costs.\n#[derive(Copy, Clone, Debug, Hash, PartialEq, Eq)]\npub enum CostTokenType {\n    /// A compile time known cost unit.\n    Const,\n    /// One invocation of the pedersen hash function.\n    Pedersen,\n    /// One invocation of the bitwise builtin.\n    Bitwise,\n    /// One invocation of the EC op builtin.\n    EcOp,\n}\nimpl CostTokenType {\n    pub fn iter()\n    -> std::iter::Chain<std::slice::Iter<'static, Self>, std::slice::Iter<'static, Self>> {\n        chain!(Self::iter_precost(), [CostTokenType::Const].iter())\n    }\n\n    pub fn iter_precost() -> std::slice::Iter<'static, Self> {\n        [CostTokenType::Pedersen, CostTokenType::Bitwise, CostTokenType::EcOp].iter()\n    }\n\n    /// Returns the name of the token type, in snake_case.\n    pub fn name(&self) -> String {\n        match self {\n            CostTokenType::Const => \"const\",\n            CostTokenType::Pedersen => \"pedersen\",\n            CostTokenType::Bitwise => \"bitwise\",\n            CostTokenType::EcOp => \"ec_op\",\n        }\n        .into()\n    }\n\n    pub fn camel_case_name(&self) -> String {\n        self.name().to_case(convert_case::Case::UpperCamel)\n    }\n\n    pub fn offset_in_builtin_costs(&self) -> i16 {\n        match self {\n            CostTokenType::Const => {\n                panic!(\"offset_in_builtin_costs is not supported for '{}'.\", self.camel_case_name())\n            }\n            CostTokenType::Pedersen => 0,\n            CostTokenType::Bitwise => 1,\n            CostTokenType::EcOp => 2,\n        }\n    }\n}\n\n/// Represents a pointer to an array with the builtin costs.\n/// Every element in the array is the cost of a single invocation of a builtin.\n///\n/// Offsets to the array are given by [CostTokenType::offset_in_builtin_costs].\n#[derive(Default)]\npub struct BuiltinCostsType {}\nimpl NoGenericArgsGenericType for BuiltinCostsType {\n    const ID: GenericTypeId = GenericTypeId::new_inline(\"BuiltinCosts\");\n    const STORABLE: bool = true;\n    const DUPLICATABLE: bool = true;\n    const DROPPABLE: bool = true;\n    const SIZE: i16 = 1;\n}\n\ndefine_libfunc_hierarchy! {\n    pub enum BuiltinCostLibfunc {\n        BuiltinWithdrawGas(BuiltinCostWithdrawGasLibfunc),\n        GetBuiltinCosts(BuiltinCostGetBuiltinCostsLibfunc),\n    }, BuiltinCostConcreteLibfunc\n}\n\n/// Libfunc for withdrawing gas to be used by a builtin.\n#[derive(Default)]\npub struct BuiltinCostWithdrawGasLibfunc;\nimpl BuiltinCostWithdrawGasLibfunc {\n    /// Returns the number of steps required for the computation of the requested cost, given the\n    /// number of requested token usages. The number of steps is also the change in `ap` (every\n    /// step includes `ap++`).\n    pub fn cost_computation_steps<TokenUsages: Fn(CostTokenType) -> usize>(\n        token_usages: TokenUsages,\n    ) -> usize {\n        CostTokenType::iter_precost()\n            .map(|token_type| match token_usages(*token_type) {\n                0 => 0,\n                1 => 2,\n                _ => 3,\n            })\n            .sum()\n    }\n}\n\nimpl NoGenericArgsGenericLibfunc for BuiltinCostWithdrawGasLibfunc {\n    const STR_ID: &'static str = \"withdraw_gas_all\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let gas_builtin_type = context.get_concrete_type(GasBuiltinType::id(), &[])?;\n        let range_check_type = context.get_concrete_type(RangeCheckType::id(), &[])?;\n        let builtin_costs_type = context.get_concrete_type(BuiltinCostsType::id(), &[])?;\n        Ok(LibfuncSignature {\n            param_signatures: vec![\n                ParamSignature {\n                    ty: range_check_type.clone(),\n                    allow_deferred: false,\n                    allow_add_const: true,\n                    allow_const: false,\n                },\n                ParamSignature::new(gas_builtin_type.clone()),\n                ParamSignature::new(builtin_costs_type),\n            ],\n            branch_signatures: vec![\n                // Success:\n                BranchSignature {\n                    vars: vec![\n                        OutputVarInfo {\n                            ty: range_check_type.clone(),\n                            ref_info: OutputVarReferenceInfo::Deferred(\n                                DeferredOutputKind::AddConst { param_idx: 0 },\n                            ),\n                        },\n                        OutputVarInfo {\n                            ty: gas_builtin_type.clone(),\n                            ref_info: OutputVarReferenceInfo::NewTempVar { idx: Some(0) },\n                        },\n                    ],\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n                // Failure:\n                BranchSignature {\n                    vars: vec![\n                        OutputVarInfo {\n                            ty: range_check_type,\n                            ref_info: OutputVarReferenceInfo::Deferred(\n                                DeferredOutputKind::AddConst { param_idx: 0 },\n                            ),\n                        },\n                        OutputVarInfo {\n                            ty: gas_builtin_type,\n                            ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 1 },\n                        },\n                    ],\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n            ],\n            fallthrough: Some(0),\n        })\n    }\n}\n\n/// Libfunc for getting the pointer to the gas cost array.\n/// See [BuiltinCostsType].\n#[derive(Default)]\npub struct BuiltinCostGetBuiltinCostsLibfunc {}\n\nimpl NoGenericArgsGenericLibfunc for BuiltinCostGetBuiltinCostsLibfunc {\n    const STR_ID: &'static str = \"get_builtin_costs\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let builtin_costs_type = context.get_concrete_type(BuiltinCostsType::id(), &[])?;\n        Ok(LibfuncSignature::new_non_branch(\n            vec![],\n            vec![OutputVarInfo {\n                ty: builtin_costs_type,\n                ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n            }],\n            SierraApChange::Known { new_vars_only: false },\n        ))\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_utils::unordered_hash_map::UnorderedHashMap;\n\nuse super::range_check::RangeCheckType;\nuse super::uint::Uint16Type;\nuse crate::define_libfunc_hierarchy;\nuse crate::extensions::lib_func::{\n    BranchSignature, DeferredOutputKind, LibfuncSignature, OutputVarInfo, ParamSignature,\n    SierraApChange, SignatureOnlyGenericLibfunc, SignatureSpecializationContext,\n    SpecializationContext,\n};\nuse crate::extensions::uint::{Uint32Type, Uint64Type, Uint8Type};\nuse crate::extensions::uint128::Uint128Type;\nuse crate::extensions::{\n    args_as_two_types, NamedLibfunc, NamedType, OutputVarReferenceInfo,\n    SignatureBasedConcreteLibfunc, SpecializationError,\n};\nuse crate::ids::ConcreteTypeId;\nuse crate::program::GenericArg;\n\ndefine_libfunc_hierarchy! {\n    pub enum CastLibfunc {\n        Downcast(DowncastLibfunc),\n        Upcast(UpcastLibfunc),\n    }, CastConcreteLibfunc\n}\n\n/// Returns a map from (concrete) integer type to the number of bits in the type.\nfn get_type_to_nbits_map(\n    context: &dyn SignatureSpecializationContext,\n) -> UnorderedHashMap<ConcreteTypeId, usize> {\n    vec![\n        (Uint8Type::ID, 8),\n        (Uint16Type::ID, 16),\n        (Uint32Type::ID, 32),\n        (Uint64Type::ID, 64),\n        (Uint128Type::ID, 128),\n    ]\n    .into_iter()\n    .filter_map(|(generic_type, n_bits)| {\n        Some((context.get_concrete_type(generic_type, &[]).ok()?, n_bits))\n    })\n    .collect()\n}\n\n/// Returns the number of bits for the given types.\n// TODO(lior): Convert to a generic function that can take arbitrary number of arguments once\n//   `try_map` is a stable feature.\nfn get_n_bits(\n    context: &dyn SignatureSpecializationContext,\n    from_type: &ConcreteTypeId,\n    to_type: &ConcreteTypeId,\n) -> Result<(usize, usize), SpecializationError> {\n    let type_to_n_bits = get_type_to_nbits_map(context);\n    let from_nbits =\n        *type_to_n_bits.get(from_type).ok_or(SpecializationError::UnsupportedGenericArg)?;\n    let to_nbits =\n        *type_to_n_bits.get(to_type).ok_or(SpecializationError::UnsupportedGenericArg)?;\n    Ok((from_nbits, to_nbits))\n}\n\n/// Libfunc for casting from one type to another where any input value can fit into the destination\n/// type. For example, from u8 to u64.\n#[derive(Default)]\npub struct UpcastLibfunc {}\nimpl SignatureOnlyGenericLibfunc for UpcastLibfunc {\n    const STR_ID: &'static str = \"upcast\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let (from_ty, to_ty) = args_as_two_types(args)?;\n        let (from_nbits, to_nbits) = get_n_bits(context, &from_ty, &to_ty)?;\n\n        let is_valid = from_nbits <= to_nbits;\n        if !is_valid {\n            return Err(SpecializationError::UnsupportedGenericArg);\n        }\n\n        Ok(LibfuncSignature::new_non_branch(\n            vec![from_ty],\n            vec![OutputVarInfo {\n                ty: to_ty,\n                ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 0 },\n            }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n\n/// A concrete version of the `downcast` libfunc. See [DowncastLibfunc].\npub struct DowncastConcreteLibfunc {\n    pub signature: LibfuncSignature,\n    pub from_ty: ConcreteTypeId,\n    pub from_nbits: usize,\n    pub to_ty: ConcreteTypeId,\n    pub to_nbits: usize,\n}\nimpl SignatureBasedConcreteLibfunc for DowncastConcreteLibfunc {\n    fn signature(&self) -> &LibfuncSignature {\n        &self.signature\n    }\n}\n\n/// Libfunc for casting from one type to another where the input value may not fit into the\n/// destination type. For example, from u64 to u8.\n#[derive(Default)]\npub struct DowncastLibfunc {}\nimpl NamedLibfunc for DowncastLibfunc {\n    type Concrete = DowncastConcreteLibfunc;\n    const STR_ID: &'static str = \"downcast\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let (from_ty, to_ty) = args_as_two_types(args)?;\n        let (from_nbits, to_nbits) = get_n_bits(context, &from_ty, &to_ty)?;\n\n        let is_valid = from_nbits >= to_nbits;\n        if !is_valid {\n            return Err(SpecializationError::UnsupportedGenericArg);\n        }\n\n        let range_check_type = context.get_concrete_type(RangeCheckType::id(), &[])?;\n        Ok(LibfuncSignature {\n            param_signatures: vec![\n                ParamSignature {\n                    ty: range_check_type.clone(),\n                    allow_deferred: false,\n                    allow_add_const: true,\n                    allow_const: false,\n                },\n                ParamSignature::new(from_ty),\n            ],\n            branch_signatures: vec![\n                // Success.\n                BranchSignature {\n                    vars: vec![\n                        OutputVarInfo {\n                            ty: range_check_type.clone(),\n                            ref_info: OutputVarReferenceInfo::Deferred(\n                                DeferredOutputKind::AddConst { param_idx: 0 },\n                            ),\n                        },\n                        OutputVarInfo {\n                            ty: to_ty,\n                            ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 1 },\n                        },\n                    ],\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n                // Failure.\n                BranchSignature {\n                    vars: vec![OutputVarInfo {\n                        ty: range_check_type,\n                        ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::AddConst {\n                            param_idx: 0,\n                        }),\n                    }],\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n            ],\n            fallthrough: Some(0),\n        })\n    }\n\n    fn specialize(\n        &self,\n        context: &dyn SpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<Self::Concrete, SpecializationError> {\n        let (from_ty, to_ty) = args_as_two_types(args)?;\n        let (from_nbits, to_nbits) = get_n_bits(context.upcast(), &from_ty, &to_ty)?;\n\n        Ok(DowncastConcreteLibfunc {\n            signature: self.specialize_signature(context.upcast(), args)?,\n            from_ty,\n            from_nbits,\n            to_ty,\n            to_nbits,\n        })\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use num_bigint::BigInt;\n\nuse crate::extensions::lib_func::{\n    DeferredOutputKind, LibfuncSignature, OutputVarInfo, SierraApChange,\n    SignatureSpecializationContext, SpecializationContext,\n};\nuse crate::extensions::{\n    NamedLibfunc, OutputVarReferenceInfo, SignatureBasedConcreteLibfunc, SpecializationError,\n};\nuse crate::ids::GenericTypeId;\nuse crate::program::GenericArg;\n\n/// Trait for implementing a library function that returns a const of a given type.\npub trait ConstGenLibfunc: Default {\n    /// The library function id.\n    const STR_ID: &'static str;\n    /// The id of the generic type to implement the library functions for.\n    const GENERIC_TYPE_ID: GenericTypeId;\n}\n\n/// Wrapper to prevent implementation collisions for `NamedLibfunc`.\n#[derive(Default)]\npub struct WrapConstGenLibfunc<T: ConstGenLibfunc>(T);\n\nimpl<T: ConstGenLibfunc> NamedLibfunc for WrapConstGenLibfunc<T> {\n    const STR_ID: &'static str = <T as ConstGenLibfunc>::STR_ID;\n    type Concrete = SignatureAndConstConcreteLibfunc;\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        _args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        Ok(LibfuncSignature::new_non_branch(\n            vec![],\n            vec![OutputVarInfo {\n                ty: context.get_concrete_type(<T as ConstGenLibfunc>::GENERIC_TYPE_ID, &[])?,\n                ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Const),\n            }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n\n    fn specialize(\n        &self,\n        context: &dyn SpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<Self::Concrete, SpecializationError> {\n        match args {\n            [GenericArg::Value(c)] => Ok(SignatureAndConstConcreteLibfunc {\n                c: c.clone(),\n                signature: <Self as NamedLibfunc>::specialize_signature(\n                    self,\n                    context.upcast(),\n                    args,\n                )?,\n            }),\n            _ => Err(SpecializationError::UnsupportedGenericArg),\n        }\n    }\n}\n\n/// Struct providing a ConcreteLibfunc signature and a const.\npub struct SignatureAndConstConcreteLibfunc {\n    pub c: BigInt,\n    pub signature: LibfuncSignature,\n}\nimpl SignatureBasedConcreteLibfunc for SignatureAndConstConcreteLibfunc {\n    fn signature(&self) -> &LibfuncSignature {\n        &self.signature\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use super::array::ArrayType;\nuse super::felt252::Felt252Type;\nuse crate::define_libfunc_hierarchy;\nuse crate::extensions::lib_func::{\n    LibfuncSignature, SierraApChange, SignatureSpecializationContext,\n};\nuse crate::extensions::{NamedType, NoGenericArgsGenericLibfunc, SpecializationError};\n\ndefine_libfunc_hierarchy! {\n    pub enum DebugLibfunc {\n        Print(PrintLibfunc),\n    }, DebugConcreteLibfunc\n}\n\n/// Libfunc for debug printing.\n#[derive(Default)]\npub struct PrintLibfunc {}\nimpl NoGenericArgsGenericLibfunc for PrintLibfunc {\n    const STR_ID: &'static str = \"print\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        // TODO(spapini): We should get a StringView, which is something like\n        // (Span<StringLimb>, len), or something like that.\n        let felt252_ty = context.get_concrete_type(Felt252Type::id(), &[])?;\n        let arr_type = context.get_wrapped_concrete_type(ArrayType::id(), felt252_ty)?;\n        Ok(LibfuncSignature::new_non_branch(\n            vec![arr_type],\n            vec![],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use crate::extensions::lib_func::{\n    LibfuncSignature, ParamSignature, SierraApChange, SignatureOnlyGenericLibfunc,\n    SignatureSpecializationContext,\n};\nuse crate::extensions::{args_as_single_type, SpecializationError};\nuse crate::program::GenericArg;\n\n/// Libfunc for ignoring a plain old data object.\n#[derive(Default)]\npub struct DropLibfunc {}\nimpl SignatureOnlyGenericLibfunc for DropLibfunc {\n    const STR_ID: &'static str = \"drop\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        generic_args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let ty = args_as_single_type(generic_args)?;\n        let info = context.get_type_info(ty.clone())?;\n        if info.droppable {\n            Ok(LibfuncSignature::new_non_branch_ex(\n                vec![ParamSignature {\n                    ty,\n                    allow_deferred: true,\n                    allow_add_const: true,\n                    allow_const: true,\n                }],\n                vec![],\n                SierraApChange::Known { new_vars_only: true },\n            ))\n        } else {\n            Err(SpecializationError::UnsupportedGenericArg)\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use crate::extensions::lib_func::{\n    LibfuncSignature, OutputVarInfo, SierraApChange, SignatureOnlyGenericLibfunc,\n    SignatureSpecializationContext,\n};\nuse crate::extensions::{args_as_single_type, OutputVarReferenceInfo, SpecializationError};\nuse crate::program::GenericArg;\n\n/// Libfunc for duplicating an object.\n#[derive(Default)]\npub struct DupLibfunc {}\nimpl SignatureOnlyGenericLibfunc for DupLibfunc {\n    const STR_ID: &'static str = \"dup\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        generic_args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let ty = args_as_single_type(generic_args)?;\n        let info = context.get_type_info(ty.clone())?;\n        if !info.duplicatable {\n            return Err(SpecializationError::UnsupportedGenericArg);\n        }\n\n        Ok(LibfuncSignature::new_non_branch(\n            vec![ty.clone()],\n            vec![\n                OutputVarInfo {\n                    ty: ty.clone(),\n                    ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 0 },\n                },\n                OutputVarInfo {\n                    ty,\n                    ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 0 },\n                },\n            ],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use super::felt252::Felt252Type;\nuse super::non_zero::nonzero_ty;\nuse super::range_check::RangeCheckType;\nuse crate::define_libfunc_hierarchy;\nuse crate::extensions::lib_func::{\n    BranchSignature, DeferredOutputKind, LibfuncSignature, OutputVarInfo, ParamSignature,\n    SierraApChange, SignatureSpecializationContext,\n};\nuse crate::extensions::{\n    NamedType, NoGenericArgsGenericLibfunc, NoGenericArgsGenericType, OutputVarReferenceInfo,\n    SpecializationError,\n};\nuse crate::ids::GenericTypeId;\n\n// Type representing the EcOp builtin.\n#[derive(Default)]\npub struct EcOpType {}\nimpl NoGenericArgsGenericType for EcOpType {\n    const ID: GenericTypeId = GenericTypeId::new_inline(\"EcOp\");\n    const STORABLE: bool = true;\n    const DUPLICATABLE: bool = false;\n    const DROPPABLE: bool = false;\n    const SIZE: i16 = 1;\n}\n\n/// An EC point is a pair (x,y) on the curve.\n#[derive(Default)]\npub struct EcPointType {}\nimpl NoGenericArgsGenericType for EcPointType {\n    const ID: GenericTypeId = GenericTypeId::new_inline(\"EcPoint\");\n    const STORABLE: bool = true;\n    const DUPLICATABLE: bool = true;\n    const DROPPABLE: bool = true;\n    const SIZE: i16 = 2;\n}\n\n/// An EC state is an EC point and a pointer to a random EC point shift.\n#[derive(Default)]\npub struct EcStateType {}\nimpl NoGenericArgsGenericType for EcStateType {\n    const ID: GenericTypeId = GenericTypeId::new_inline(\"EcState\");\n    const STORABLE: bool = true;\n    const DUPLICATABLE: bool = true;\n    const DROPPABLE: bool = true;\n    const SIZE: i16 = 3;\n}\n\ndefine_libfunc_hierarchy! {\n    pub enum EcLibfunc {\n        IsZero(EcIsZeroLibfunc),\n        Neg(EcNegLibfunc),\n        StateAdd(EcStateAddLibfunc),\n        TryNew(EcCreatePointLibfunc),\n        StateFinalize(EcStateFinalizeLibfunc),\n        StateInit(EcStateInitLibfunc),\n        StateAddMul(EcStateAddMulLibfunc),\n        PointFromX(EcPointFromXLibfunc),\n        UnwrapPoint(EcUnwrapPointLibfunc),\n        Zero(EcZeroLibfunc),\n    }, EcConcreteLibfunc\n}\n\n/// Libfunc for returning the zero point (the point at infinity).\n#[derive(Default)]\npub struct EcZeroLibfunc {}\nimpl NoGenericArgsGenericLibfunc for EcZeroLibfunc {\n    const STR_ID: &'static str = \"ec_point_zero\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let ecpoint_ty = context.get_concrete_type(EcPointType::id(), &[])?;\n\n        Ok(LibfuncSignature::new_non_branch(\n            vec![],\n            vec![OutputVarInfo {\n                ty: ecpoint_ty,\n                ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Const),\n            }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n\n/// Libfunc for creating an EC point from its coordinates `x` and `y`.\n/// If `(x, y)` is not on the curve, nothing is returned.\n#[derive(Default)]\npub struct EcCreatePointLibfunc {}\nimpl NoGenericArgsGenericLibfunc for EcCreatePointLibfunc {\n    const STR_ID: &'static str = \"ec_point_try_new_nz\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let felt252_ty = context.get_concrete_type(Felt252Type::id(), &[])?;\n        let ecpoint_ty = context.get_concrete_type(EcPointType::id(), &[])?;\n        let nonzero_ecpoint_ty = nonzero_ty(context, &ecpoint_ty)?;\n\n        Ok(LibfuncSignature {\n            param_signatures: vec![\n                ParamSignature::new(felt252_ty.clone()),\n                ParamSignature::new(felt252_ty),\n            ],\n            branch_signatures: vec![\n                // Success.\n                BranchSignature {\n                    vars: vec![OutputVarInfo {\n                        ty: nonzero_ecpoint_ty,\n                        ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n                    }],\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n                // Failure.\n                BranchSignature {\n                    vars: vec![],\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n            ],\n            fallthrough: Some(0),\n        })\n    }\n}\n\n/// Libfunc for creating an EC point from its x coordinate.\n/// If there exists `y` such that `(x, y)` is on the curve, either `(x, y)` or `(x, -y)` (both\n/// constitute valid points on the curve) is returned.\n/// Otherwise, nothing is returned.\n#[derive(Default)]\npub struct EcPointFromXLibfunc {}\nimpl NoGenericArgsGenericLibfunc for EcPointFromXLibfunc {\n    const STR_ID: &'static str = \"ec_point_from_x_nz\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let felt252_ty = context.get_concrete_type(Felt252Type::id(), &[])?;\n        let ecpoint_ty = context.get_concrete_type(EcPointType::id(), &[])?;\n        let nonzero_ecpoint_ty = nonzero_ty(context, &ecpoint_ty)?;\n        let range_check_type = context.get_concrete_type(RangeCheckType::id(), &[])?;\n\n        Ok(LibfuncSignature {\n            param_signatures: vec![\n                ParamSignature {\n                    ty: range_check_type.clone(),\n                    allow_deferred: false,\n                    allow_add_const: true,\n                    allow_const: false,\n                },\n                ParamSignature::new(felt252_ty),\n            ],\n            branch_signatures: vec![\n                // Success.\n                BranchSignature {\n                    vars: vec![\n                        OutputVarInfo {\n                            ty: range_check_type.clone(),\n                            ref_info: OutputVarReferenceInfo::Deferred(\n                                DeferredOutputKind::AddConst { param_idx: 0 },\n                            ),\n                        },\n                        OutputVarInfo {\n                            ty: nonzero_ecpoint_ty,\n                            ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n                        },\n                    ],\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n                // Failure.\n                BranchSignature {\n                    vars: vec![OutputVarInfo {\n                        ty: range_check_type,\n                        ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 0 },\n                    }],\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n            ],\n            fallthrough: Some(0),\n        })\n    }\n}\n\n/// Libfunc for unwrapping the x,y values of an EC point.\n#[derive(Default)]\npub struct EcUnwrapPointLibfunc {}\nimpl NoGenericArgsGenericLibfunc for EcUnwrapPointLibfunc {\n    const STR_ID: &'static str = \"ec_point_unwrap\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let felt252_ty = context.get_concrete_type(Felt252Type::id(), &[])?;\n        let ecpoint_ty = context.get_concrete_type(EcPointType::id(), &[])?;\n        let nonzero_ecpoint_ty = nonzero_ty(context, &ecpoint_ty)?;\n\n        Ok(LibfuncSignature::new_non_branch(\n            vec![nonzero_ecpoint_ty],\n            vec![\n                OutputVarInfo {\n                    ty: felt252_ty.clone(),\n                    ref_info: OutputVarReferenceInfo::PartialParam { param_idx: 0 },\n                },\n                OutputVarInfo {\n                    ty: felt252_ty,\n                    ref_info: OutputVarReferenceInfo::PartialParam { param_idx: 0 },\n                },\n            ],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n\n/// Libfunc for unwrapping the x,y values of an EC point.\n#[derive(Default)]\npub struct EcNegLibfunc {}\nimpl NoGenericArgsGenericLibfunc for EcNegLibfunc {\n    const STR_ID: &'static str = \"ec_neg\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let ecpoint_ty = context.get_concrete_type(EcPointType::id(), &[])?;\n\n        Ok(LibfuncSignature::new_non_branch(\n            vec![ecpoint_ty.clone()],\n            vec![OutputVarInfo {\n                ty: ecpoint_ty,\n                ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n            }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n\n/// Libfunc for checking whether the given `EcPoint` is the zero point.\n#[derive(Default)]\npub struct EcIsZeroLibfunc {}\nimpl NoGenericArgsGenericLibfunc for EcIsZeroLibfunc {\n    const STR_ID: &'static str = \"ec_point_is_zero\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let ecpoint_ty = context.get_concrete_type(EcPointType::id(), &[])?;\n        let nonzero_ecpoint_ty = nonzero_ty(context, &ecpoint_ty)?;\n\n        Ok(LibfuncSignature {\n            param_signatures: vec![ParamSignature::new(ecpoint_ty)],\n            branch_signatures: vec![\n                // Zero.\n                BranchSignature {\n                    vars: vec![],\n                    ap_change: SierraApChange::Known { new_vars_only: true },\n                },\n                // NonZero.\n                BranchSignature {\n                    vars: vec![OutputVarInfo {\n                        ty: nonzero_ecpoint_ty,\n                        ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 0 },\n                    }],\n                    ap_change: SierraApChange::Known { new_vars_only: true },\n                },\n            ],\n            fallthrough: Some(0),\n        })\n    }\n}\n\n/// Libfunc for initializing an EC state from an EC point.\n#[derive(Default)]\npub struct EcStateInitLibfunc {}\nimpl NoGenericArgsGenericLibfunc for EcStateInitLibfunc {\n    const STR_ID: &'static str = \"ec_state_init\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        Ok(LibfuncSignature::new_non_branch(\n            vec![],\n            vec![OutputVarInfo {\n                ty: context.get_concrete_type(EcStateType::id(), &[])?,\n                ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n            }],\n            SierraApChange::Known { new_vars_only: false },\n        ))\n    }\n}\n\n/// Libfunc for initializing an EC state from an EC point.\n#[derive(Default)]\npub struct EcStateAddLibfunc {}\nimpl NoGenericArgsGenericLibfunc for EcStateAddLibfunc {\n    const STR_ID: &'static str = \"ec_state_add\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let state_ty = context.get_concrete_type(EcStateType::id(), &[])?;\n        let ecpoint_ty = context.get_concrete_type(EcPointType::id(), &[])?;\n        let nonzero_ecpoint_ty = nonzero_ty(context, &ecpoint_ty)?;\n\n        Ok(LibfuncSignature::new_non_branch(\n            vec![state_ty.clone(), nonzero_ecpoint_ty],\n            vec![OutputVarInfo {\n                ty: state_ty,\n                ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n            }],\n            SierraApChange::Known { new_vars_only: false },\n        ))\n    }\n}\n\n/// Libfunc for initializing an EC state from an EC point.\n#[derive(Default)]\npub struct EcStateFinalizeLibfunc {}\nimpl NoGenericArgsGenericLibfunc for EcStateFinalizeLibfunc {\n    const STR_ID: &'static str = \"ec_state_try_finalize_nz\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let ecpoint_ty = context.get_concrete_type(EcPointType::id(), &[])?;\n        let nonzero_ecpoint_ty = nonzero_ty(context, &ecpoint_ty)?;\n\n        Ok(LibfuncSignature {\n            param_signatures: vec![ParamSignature::new(\n                context.get_concrete_type(EcStateType::id(), &[])?,\n            )],\n            branch_signatures: vec![\n                BranchSignature {\n                    vars: vec![OutputVarInfo {\n                        ty: nonzero_ecpoint_ty,\n                        ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n                    }],\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n                BranchSignature {\n                    vars: vec![],\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n            ],\n            fallthrough: Some(0),\n        })\n    }\n}\n\n/// Libfunc for applying the EC op builtin: given an EC state `S`, a scalar `M` and an EC point `Q`,\n/// computes a new EC state `S + M * Q`.\n#[derive(Default)]\npub struct EcStateAddMulLibfunc {}\nimpl NoGenericArgsGenericLibfunc for EcStateAddMulLibfunc {\n    const STR_ID: &'static str = \"ec_state_add_mul\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let ec_builtin_ty = context.get_concrete_type(EcOpType::id(), &[])?;\n        let ec_state_ty = context.get_concrete_type(EcStateType::id(), &[])?;\n        let ecpoint_ty = context.get_concrete_type(EcPointType::id(), &[])?;\n        let nonzero_ecpoint_ty = nonzero_ty(context, &ecpoint_ty)?;\n\n        Ok(LibfuncSignature::new_non_branch(\n            vec![\n                ec_builtin_ty.clone(),\n                ec_state_ty.clone(),\n                context.get_concrete_type(Felt252Type::id(), &[])?,\n                nonzero_ecpoint_ty,\n            ],\n            vec![\n                OutputVarInfo {\n                    ty: ec_builtin_ty,\n                    ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::AddConst {\n                        param_idx: 0,\n                    }),\n                },\n                OutputVarInfo {\n                    ty: ec_state_ty,\n                    ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n                },\n            ],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Sierra example:\n//! ```ignore\n//! type felt252_ty = felt252;\n//! type unit_ty = Tuple;\n//! type Option = Enum<felt252_ty, unit_ty>;\n//! libfunc init_option_some = enum_init<Option, 0>;\n//! libfunc init_option_none = enum_init<Option, 1>;\n//! libfunc match_option = enum_match<Option>;\n//! ...\n//! felt252_const<0>() -> (felt0);\n//! tuple_const() -> (unit);\n//! init_option_some(felt0) -> (some_id);\n//! init_option_none(unit) -> (none_id);\n//! match_option(some_id) {1000(some), 2000(none)};\n//! match_option(none_id) {1000(some), 2000(none)};\n//! ```\n\nuse std::cmp;\n\nuse cairo_lang_utils::try_extract_matches;\nuse num_bigint::ToBigInt;\nuse num_traits::Signed;\n\nuse super::snapshot::snapshot_ty;\nuse crate::define_libfunc_hierarchy;\nuse crate::extensions::lib_func::{\n    BranchSignature, DeferredOutputKind, LibfuncSignature, OutputVarInfo, ParamSignature,\n    SierraApChange, SignatureOnlyGenericLibfunc, SignatureSpecializationContext,\n    SpecializationContext,\n};\nuse crate::extensions::type_specialization_context::TypeSpecializationContext;\nuse crate::extensions::types::TypeInfo;\nuse crate::extensions::{\n    args_as_single_type, ConcreteType, NamedLibfunc, NamedType, OutputVarReferenceInfo,\n    SignatureBasedConcreteLibfunc, SpecializationError,\n};\nuse crate::ids::{ConcreteTypeId, GenericTypeId};\nuse crate::program::{ConcreteTypeLongId, GenericArg};\n\n/// Type representing an enum.\n#[derive(Default)]\npub struct EnumType {}\nimpl NamedType for EnumType {\n    type Concrete = EnumConcreteType;\n    const ID: GenericTypeId = GenericTypeId::new_inline(\"Enum\");\n\n    fn specialize(\n        &self,\n        context: &dyn TypeSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<Self::Concrete, SpecializationError> {\n        Self::Concrete::new(context, args)\n    }\n}\n\npub struct EnumConcreteType {\n    pub info: TypeInfo,\n    pub variants: Vec<ConcreteTypeId>,\n}\nimpl EnumConcreteType {\n    fn new(\n        context: &dyn TypeSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<Self, SpecializationError> {\n        let mut args_iter = args.iter();\n        args_iter\n            .next()\n            .and_then(|arg| try_extract_matches!(arg, GenericArg::UserType))\n            .ok_or(SpecializationError::UnsupportedGenericArg)?;\n        let mut duplicatable = true;\n        let mut droppable = true;\n        let mut variants: Vec<ConcreteTypeId> = Vec::new();\n        let mut variant_max_size = 0;\n        for arg in args_iter {\n            let ty = try_extract_matches!(arg, GenericArg::Type)\n                .ok_or(SpecializationError::UnsupportedGenericArg)?\n                .clone();\n            let info = context.get_type_info(ty.clone())?;\n            if !info.storable {\n                return Err(SpecializationError::UnsupportedGenericArg);\n            }\n            if !info.duplicatable {\n                duplicatable = false;\n            }\n            if !info.droppable {\n                droppable = false;\n            }\n            variants.push(ty);\n            variant_max_size = cmp::max(variant_max_size, info.size);\n        }\n        Ok(EnumConcreteType {\n            info: TypeInfo {\n                long_id: ConcreteTypeLongId {\n                    generic_id: \"Enum\".into(),\n                    generic_args: args.to_vec(),\n                },\n                duplicatable,\n                droppable,\n                storable: true,\n                size: 1 + variant_max_size,\n            },\n            variants,\n        })\n    }\n}\nimpl ConcreteType for EnumConcreteType {\n    fn info(&self) -> &TypeInfo {\n        &self.info\n    }\n}\n\ndefine_libfunc_hierarchy! {\n    pub enum EnumLibfunc {\n        Init(EnumInitLibfunc),\n        Match(EnumMatchLibfunc),\n        SnapshotMatch(EnumSnapshotMatchLibfunc),\n    }, EnumConcreteLibfunc\n}\n\npub struct EnumInitConcreteLibfunc {\n    pub signature: LibfuncSignature,\n    /// The number of variants of the enum.\n    pub num_variants: usize,\n    /// The index of the relevant variant from the enum.\n    pub index: usize,\n}\nimpl SignatureBasedConcreteLibfunc for EnumInitConcreteLibfunc {\n    fn signature(&self) -> &LibfuncSignature {\n        &self.signature\n    }\n}\n\n/// Libfunc for setting a value to an enum.\n#[derive(Default)]\npub struct EnumInitLibfunc {}\nimpl EnumInitLibfunc {\n    /// Creates the specialization of the enum-init libfunc with the given template arguments.\n    fn specialize_concrete_lib_func(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<EnumInitConcreteLibfunc, SpecializationError> {\n        let (enum_type, index) = match args {\n            [GenericArg::Type(enum_type), GenericArg::Value(index)] => {\n                (enum_type.clone(), index.clone())\n            }\n            [_, _] => return Err(SpecializationError::UnsupportedGenericArg),\n            _ => return Err(SpecializationError::WrongNumberOfGenericArgs),\n        };\n        let generic_args = context.get_type_info(enum_type.clone())?.long_id.generic_args;\n        let variant_types =\n            EnumConcreteType::new(context.as_type_specialization_context(), &generic_args)?\n                .variants;\n        let num_variants = variant_types.len();\n        if index.is_negative() || index >= num_variants.to_bigint().unwrap() {\n            return Err(SpecializationError::IndexOutOfRange { index, range_size: num_variants });\n        }\n        let index: usize = index.try_into().unwrap();\n        let variant_type = variant_types[index].clone();\n        Ok(EnumInitConcreteLibfunc {\n            signature: LibfuncSignature::new_non_branch_ex(\n                vec![ParamSignature {\n                    ty: variant_type,\n                    allow_deferred: true,\n                    allow_add_const: true,\n                    allow_const: true,\n                }],\n                vec![OutputVarInfo {\n                    ty: enum_type,\n                    ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n                }],\n                SierraApChange::Known { new_vars_only: true },\n            ),\n            num_variants,\n            index,\n        })\n    }\n}\nimpl NamedLibfunc for EnumInitLibfunc {\n    type Concrete = EnumInitConcreteLibfunc;\n    const STR_ID: &'static str = \"enum_init\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        Ok(self.specialize_concrete_lib_func(context, args)?.signature)\n    }\n\n    fn specialize(\n        &self,\n        context: &dyn SpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<Self::Concrete, SpecializationError> {\n        self.specialize_concrete_lib_func(context.upcast(), args)\n    }\n}\n\n/// Libfunc for matching an enum.\n#[derive(Default)]\npub struct EnumMatchLibfunc {}\nimpl SignatureOnlyGenericLibfunc for EnumMatchLibfunc {\n    const STR_ID: &'static str = \"enum_match\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let enum_type = args_as_single_type(args)?;\n        let generic_args = context.get_type_info(enum_type.clone())?.long_id.generic_args;\n        let variant_types =\n            EnumConcreteType::new(context.as_type_specialization_context(), &generic_args)?\n                .variants;\n        let branch_signatures = variant_types\n            .into_iter()\n            .map(|ty| BranchSignature {\n                vars: vec![OutputVarInfo {\n                    ty,\n                    ref_info: OutputVarReferenceInfo::PartialParam { param_idx: 0 },\n                }],\n                ap_change: SierraApChange::Known { new_vars_only: true },\n            })\n            .collect();\n\n        Ok(LibfuncSignature {\n            param_signatures: vec![enum_type.into()],\n            branch_signatures,\n            fallthrough: Some(0),\n        })\n    }\n}\n\n/// Libfunc for matching an enum snapshot.\n#[derive(Default)]\npub struct EnumSnapshotMatchLibfunc {}\nimpl SignatureOnlyGenericLibfunc for EnumSnapshotMatchLibfunc {\n    const STR_ID: &'static str = \"enum_snapshot_match\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let enum_type = args_as_single_type(args)?;\n        let generic_args = context.get_type_info(enum_type.clone())?.long_id.generic_args;\n        let variant_types =\n            EnumConcreteType::new(context.as_type_specialization_context(), &generic_args)?\n                .variants;\n        let branch_signatures = variant_types\n            .into_iter()\n            .map(|ty| {\n                Ok(BranchSignature {\n                    vars: vec![OutputVarInfo {\n                        ty: snapshot_ty(context, ty)?,\n                        ref_info: OutputVarReferenceInfo::PartialParam { param_idx: 0 },\n                    }],\n                    ap_change: SierraApChange::Known { new_vars_only: true },\n                })\n            })\n            .collect::<Result<Vec<_>, _>>()?;\n\n        Ok(LibfuncSignature {\n            param_signatures: vec![snapshot_ty(context, enum_type)?.into()],\n            branch_signatures,\n            fallthrough: Some(0),\n        })\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use num_bigint::BigInt;\nuse num_traits::Zero;\n\nuse super::is_zero::{IsZeroLibfunc, IsZeroTraits};\nuse super::non_zero::nonzero_ty;\nuse crate::define_libfunc_hierarchy;\nuse crate::extensions::lib_func::{\n    DeferredOutputKind, LibfuncSignature, OutputVarInfo, ParamSignature, SierraApChange,\n    SignatureSpecializationContext, SpecializationContext,\n};\nuse crate::extensions::{\n    GenericLibfunc, NamedLibfunc, NamedType, NoGenericArgsGenericType, OutputVarReferenceInfo,\n    SignatureBasedConcreteLibfunc, SpecializationError,\n};\nuse crate::ids::{GenericLibfuncId, GenericTypeId};\nuse crate::program::GenericArg;\n\n/// Type for felt252.\n/// The native type of the Cairo architecture.\n#[derive(Default)]\npub struct Felt252Type {}\nimpl NoGenericArgsGenericType for Felt252Type {\n    const ID: GenericTypeId = GenericTypeId::new_inline(\"felt252\");\n    const STORABLE: bool = true;\n    const DUPLICATABLE: bool = true;\n    const DROPPABLE: bool = true;\n    const SIZE: i16 = 1;\n}\n\ndefine_libfunc_hierarchy! {\n    pub enum Felt252Libfunc {\n        BinaryOperation(Felt252BinaryOperationLibfunc),\n        Const(Felt252ConstLibfunc),\n        IsZero(Felt252JumpNotZeroLibfunc),\n    }, Felt252Concrete\n}\n\ndefine_libfunc_hierarchy! {\n    pub enum Felt252BinaryOperationLibfunc {\n        WithVar(Felt252BinaryOperationWithVarLibfunc),\n        WithConst(Felt252BinaryOperationWithConstLibfunc),\n    }, Felt252BinaryOperationConcrete\n}\n\n#[derive(Default)]\npub struct Felt252Traits {}\nimpl IsZeroTraits for Felt252Traits {\n    const IS_ZERO: &'static str = \"felt252_is_zero\";\n    const GENERIC_TYPE_ID: GenericTypeId = <Felt252Type as NamedType>::ID;\n}\npub type Felt252JumpNotZeroLibfunc = IsZeroLibfunc<Felt252Traits>;\n\n/// Felt252 binary operators.\n#[derive(Copy, Clone, Debug, PartialEq, Eq)]\npub enum Felt252BinaryOperator {\n    Add,\n    Sub,\n    Mul,\n    Div,\n}\n\n/// Libfunc for felt252 binary operations.\npub struct Felt252BinaryOperationWithVarLibfunc {\n    pub operator: Felt252BinaryOperator,\n}\nimpl Felt252BinaryOperationWithVarLibfunc {\n    fn new(operator: Felt252BinaryOperator) -> Self {\n        Self { operator }\n    }\n    const ADD: &str = \"felt252_add\";\n    const SUB: &str = \"felt252_sub\";\n    const MUL: &str = \"felt252_mul\";\n    const DIV: &str = \"felt252_div\";\n}\nimpl GenericLibfunc for Felt252BinaryOperationWithVarLibfunc {\n    type Concrete = Felt252BinaryOpConcreteLibfunc;\n\n    fn supported_ids() -> Vec<GenericLibfuncId> {\n        vec![\n            GenericLibfuncId::from(Self::ADD),\n            GenericLibfuncId::from(Self::SUB),\n            GenericLibfuncId::from(Self::MUL),\n            GenericLibfuncId::from(Self::DIV),\n        ]\n    }\n\n    fn by_id(id: &GenericLibfuncId) -> Option<Self> {\n        match id.0.as_str() {\n            Self::ADD => Some(Self::new(Felt252BinaryOperator::Add)),\n            Self::SUB => Some(Self::new(Felt252BinaryOperator::Sub)),\n            Self::MUL => Some(Self::new(Felt252BinaryOperator::Mul)),\n            Self::DIV => Some(Self::new(Felt252BinaryOperator::Div)),\n            _ => None,\n        }\n    }\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let ty = context.get_concrete_type(Felt252Type::id(), &[])?;\n        let (second_param_type, output_ref_info) =\n            if matches!(self.operator, Felt252BinaryOperator::Div) {\n                (nonzero_ty(context, &ty)?, OutputVarReferenceInfo::NewTempVar { idx: Some(0) })\n            } else {\n                (ty.clone(), OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic))\n            };\n        match args {\n            [] => Ok(LibfuncSignature::new_non_branch_ex(\n                vec![\n                    ParamSignature::new(ty.clone()),\n                    ParamSignature {\n                        ty: second_param_type,\n                        allow_deferred: false,\n                        allow_add_const: false,\n                        allow_const: true,\n                    },\n                ],\n                vec![OutputVarInfo { ty, ref_info: output_ref_info }],\n                SierraApChange::Known { new_vars_only: true },\n            )),\n            _ => Err(SpecializationError::WrongNumberOfGenericArgs),\n        }\n    }\n\n    fn specialize(\n        &self,\n        context: &dyn SpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<Self::Concrete, SpecializationError> {\n        match args {\n            [] => Ok({\n                Felt252BinaryOpConcreteLibfunc {\n                    operator: self.operator,\n                    signature: self.specialize_signature(context.upcast(), args)?,\n                }\n            }),\n            _ => Err(SpecializationError::WrongNumberOfGenericArgs),\n        }\n    }\n}\n\n/// Libfunc for felt252 binary operations with const.\npub struct Felt252BinaryOperationWithConstLibfunc {\n    pub operator: Felt252BinaryOperator,\n}\nimpl Felt252BinaryOperationWithConstLibfunc {\n    fn new(operator: Felt252BinaryOperator) -> Self {\n        Self { operator }\n    }\n    const ADD: &str = \"felt252_add_const\";\n    const SUB: &str = \"felt252_sub_const\";\n    const MUL: &str = \"felt252_mul_const\";\n    const DIV: &str = \"felt252_div_const\";\n}\nimpl GenericLibfunc for Felt252BinaryOperationWithConstLibfunc {\n    type Concrete = Felt252OperationWithConstConcreteLibfunc;\n\n    fn supported_ids() -> Vec<GenericLibfuncId> {\n        vec![\n            GenericLibfuncId::from(Self::ADD),\n            GenericLibfuncId::from(Self::SUB),\n            GenericLibfuncId::from(Self::MUL),\n            GenericLibfuncId::from(Self::DIV),\n        ]\n    }\n\n    fn by_id(id: &GenericLibfuncId) -> Option<Self> {\n        match id.0.as_str() {\n            Self::ADD => Some(Self::new(Felt252BinaryOperator::Add)),\n            Self::SUB => Some(Self::new(Felt252BinaryOperator::Sub)),\n            Self::MUL => Some(Self::new(Felt252BinaryOperator::Mul)),\n            Self::DIV => Some(Self::new(Felt252BinaryOperator::Div)),\n            _ => None,\n        }\n    }\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let ty = context.get_concrete_type(Felt252Type::id(), &[])?;\n        match args {\n            [GenericArg::Value(c)] => {\n                if matches!(self.operator, Felt252BinaryOperator::Div) && c.is_zero() {\n                    return Err(SpecializationError::UnsupportedGenericArg);\n                }\n\n                Ok(LibfuncSignature::new_non_branch(\n                    vec![ty.clone()],\n                    vec![OutputVarInfo {\n                        ty,\n                        ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n                    }],\n                    SierraApChange::Known { new_vars_only: true },\n                ))\n            }\n            _ => Err(SpecializationError::WrongNumberOfGenericArgs),\n        }\n    }\n\n    fn specialize(\n        &self,\n        context: &dyn SpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<Self::Concrete, SpecializationError> {\n        match args {\n            [GenericArg::Value(c)] => {\n                if matches!(self.operator, Felt252BinaryOperator::Div) && c.is_zero() {\n                    Err(SpecializationError::UnsupportedGenericArg)\n                } else {\n                    Ok(Felt252OperationWithConstConcreteLibfunc {\n                        operator: self.operator,\n                        c: c.clone(),\n                        signature: self.specialize_signature(context.upcast(), args)?,\n                    })\n                }\n            }\n            _ => Err(SpecializationError::WrongNumberOfGenericArgs),\n        }\n    }\n}\n\npub struct Felt252BinaryOpConcreteLibfunc {\n    pub operator: Felt252BinaryOperator,\n    pub signature: LibfuncSignature,\n}\nimpl SignatureBasedConcreteLibfunc for Felt252BinaryOpConcreteLibfunc {\n    fn signature(&self) -> &LibfuncSignature {\n        &self.signature\n    }\n}\n\n/// Felt252 operations with a const.\npub struct Felt252OperationWithConstConcreteLibfunc {\n    pub operator: Felt252BinaryOperator,\n    pub c: BigInt,\n    pub signature: LibfuncSignature,\n}\n\nimpl SignatureBasedConcreteLibfunc for Felt252OperationWithConstConcreteLibfunc {\n    fn signature(&self) -> &LibfuncSignature {\n        &self.signature\n    }\n}\n\n/// Libfunc for creating a constant felt252.\n#[derive(Default)]\npub struct Felt252ConstLibfunc {}\nimpl NamedLibfunc for Felt252ConstLibfunc {\n    type Concrete = Felt252ConstConcreteLibfunc;\n    const STR_ID: &'static str = \"felt252_const\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        _args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        Ok(LibfuncSignature::new_non_branch(\n            vec![],\n            vec![OutputVarInfo {\n                ty: context.get_concrete_type(Felt252Type::id(), &[])?,\n                ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Const),\n            }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n\n    fn specialize(\n        &self,\n        context: &dyn SpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<Self::Concrete, SpecializationError> {\n        match args {\n            [GenericArg::Value(c)] => Ok(Felt252ConstConcreteLibfunc {\n                c: c.clone(),\n                signature: <Self as NamedLibfunc>::specialize_signature(\n                    self,\n                    context.upcast(),\n                    args,\n                )?,\n            }),\n            _ => Err(SpecializationError::UnsupportedGenericArg),\n        }\n    }\n}\n\npub struct Felt252ConstConcreteLibfunc {\n    pub c: BigInt,\n    pub signature: LibfuncSignature,\n}\nimpl SignatureBasedConcreteLibfunc for Felt252ConstConcreteLibfunc {\n    fn signature(&self) -> &LibfuncSignature {\n        &self.signature\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use super::felt252::Felt252Type;\nuse super::gas::GasBuiltinType;\nuse super::nullable::NullableType;\nuse super::range_check::RangeCheckType;\nuse super::segment_arena::SegmentArenaType;\nuse super::squashed_felt252_dict::SquashedFelt252DictType;\nuse super::uint::{Uint16Type, Uint32Type, Uint64Type, Uint8Type};\nuse super::uint128::Uint128Type;\nuse crate::define_libfunc_hierarchy;\nuse crate::extensions::lib_func::{\n    DeferredOutputKind, LibfuncSignature, OutputVarInfo, ParamSignature, SierraApChange,\n    SignatureOnlyGenericLibfunc, SignatureSpecializationContext,\n};\nuse crate::extensions::types::{\n    GenericTypeArgGenericType, GenericTypeArgGenericTypeWrapper, TypeInfo,\n};\nuse crate::extensions::{\n    args_as_single_type, NamedType, OutputVarReferenceInfo, SpecializationError,\n};\nuse crate::ids::GenericTypeId;\nuse crate::program::GenericArg;\n\n/// Type representing a dictionary from a felt252 to types of size one.\n#[derive(Default)]\npub struct Felt252DictTypeWrapped {}\nimpl GenericTypeArgGenericType for Felt252DictTypeWrapped {\n    const ID: GenericTypeId = GenericTypeId::new_inline(\"Felt252Dict\");\n\n    fn calc_info(\n        &self,\n        long_id: crate::program::ConcreteTypeLongId,\n        TypeInfo { long_id: wrapped_long_id, storable, droppable, duplicatable, .. }: TypeInfo,\n    ) -> Result<TypeInfo, SpecializationError> {\n        // List of specific types allowed as dictionary values.\n        // TODO(Gil): Check in the higher level compiler and raise proper diagnostic (when we'll\n        // have a 'where' equivalent).\n        // TODO(Gil): Allow any type of size 1 which implement the 'Default' trait.\n        let allowed_types = [\n            Felt252Type::id(),\n            Uint8Type::id(),\n            Uint16Type::id(),\n            Uint32Type::id(),\n            Uint64Type::id(),\n            Uint128Type::id(),\n            NullableType::id(),\n        ];\n        if allowed_types.contains(&wrapped_long_id.generic_id)\n            && storable\n            && droppable\n            && duplicatable\n        {\n            Ok(TypeInfo { long_id, duplicatable: false, droppable: false, storable: true, size: 1 })\n        } else {\n            Err(SpecializationError::UnsupportedGenericArg)\n        }\n    }\n}\npub type Felt252DictType = GenericTypeArgGenericTypeWrapper<Felt252DictTypeWrapped>;\n\ndefine_libfunc_hierarchy! {\n    pub enum Felt252DictLibfunc {\n        New(Felt252DictNewLibfunc),\n        Read(Felt252DictReadLibfunc),\n        Write(Felt252DictWriteLibfunc),\n        Squash(Felt252DictSquashLibfunc),\n    }, Felt252DictConcreteLibfunc\n}\n\n/// Libfunc for creating a new felt252_dict.\n#[derive(Default)]\npub struct Felt252DictNewLibfunc {}\nimpl SignatureOnlyGenericLibfunc for Felt252DictNewLibfunc {\n    const STR_ID: &'static str = \"felt252_dict_new\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let ty = args_as_single_type(args)?;\n        let segment_arena_ty = context.get_concrete_type(SegmentArenaType::id(), &[])?;\n        Ok(LibfuncSignature::new_non_branch_ex(\n            vec![ParamSignature {\n                ty: segment_arena_ty.clone(),\n                allow_deferred: false,\n                allow_add_const: true,\n                allow_const: false,\n            }],\n            vec![\n                OutputVarInfo {\n                    ty: segment_arena_ty,\n                    ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::AddConst {\n                        param_idx: 0,\n                    }),\n                },\n                OutputVarInfo {\n                    ty: context.get_wrapped_concrete_type(Felt252DictType::id(), ty)?,\n                    ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n                },\n            ],\n            SierraApChange::Known { new_vars_only: false },\n        ))\n    }\n}\n\n/// Libfunc for writing a new value to a felt252_dict.\n#[derive(Default)]\npub struct Felt252DictWriteLibfunc {}\nimpl SignatureOnlyGenericLibfunc for Felt252DictWriteLibfunc {\n    const STR_ID: &'static str = \"felt252_dict_write\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let ty = args_as_single_type(args)?;\n        let felt252_ty = context.get_concrete_type(Felt252Type::id(), &[])?;\n        let dict_ty = context.get_wrapped_concrete_type(Felt252DictType::id(), ty.clone())?;\n        Ok(LibfuncSignature::new_non_branch_ex(\n            vec![\n                ParamSignature {\n                    ty: dict_ty.clone(),\n                    allow_deferred: false,\n                    allow_add_const: true,\n                    allow_const: false,\n                },\n                ParamSignature::new(felt252_ty),\n                ParamSignature::new(ty),\n            ],\n            vec![OutputVarInfo {\n                ty: dict_ty,\n                ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::AddConst {\n                    param_idx: 0,\n                }),\n            }],\n            SierraApChange::Known { new_vars_only: false },\n        ))\n    }\n}\n\n/// Libfunc for reading a value corresponding to a key, from a felt252_dict.\n#[derive(Default)]\npub struct Felt252DictReadLibfunc {}\nimpl SignatureOnlyGenericLibfunc for Felt252DictReadLibfunc {\n    const STR_ID: &'static str = \"felt252_dict_read\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let generic_ty = args_as_single_type(args)?;\n        let dict_ty =\n            context.get_wrapped_concrete_type(Felt252DictType::id(), generic_ty.clone())?;\n        let felt252_ty = context.get_concrete_type(Felt252Type::id(), &[])?;\n        Ok(LibfuncSignature::new_non_branch_ex(\n            vec![\n                ParamSignature {\n                    ty: dict_ty.clone(),\n                    allow_deferred: false,\n                    allow_add_const: true,\n                    allow_const: false,\n                },\n                ParamSignature::new(felt252_ty),\n            ],\n            vec![\n                OutputVarInfo {\n                    ty: dict_ty,\n                    ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::AddConst {\n                        param_idx: 0,\n                    }),\n                },\n                OutputVarInfo {\n                    ty: generic_ty,\n                    ref_info: OutputVarReferenceInfo::NewTempVar { idx: Some(0) },\n                },\n            ],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n\n/// Libfunc for performing a `squash` opertaion on a dict. Returns a pointer to the squashed dict.\n#[derive(Default)]\npub struct Felt252DictSquashLibfunc {}\nimpl SignatureOnlyGenericLibfunc for Felt252DictSquashLibfunc {\n    const STR_ID: &'static str = \"felt252_dict_squash\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let generic_ty = args_as_single_type(args)?;\n        let dict_ty =\n            context.get_wrapped_concrete_type(Felt252DictType::id(), generic_ty.clone())?;\n        let squashed_dict_ty =\n            context.get_wrapped_concrete_type(SquashedFelt252DictType::id(), generic_ty)?;\n        let range_check_type = context.get_concrete_type(RangeCheckType::id(), &[])?;\n        let gas_builtin_type = context.get_concrete_type(GasBuiltinType::id(), &[])?;\n        let segment_arena_ty = context.get_concrete_type(SegmentArenaType::id(), &[])?;\n        Ok(LibfuncSignature::new_non_branch(\n            vec![\n                range_check_type.clone(),\n                gas_builtin_type.clone(),\n                segment_arena_ty.clone(),\n                dict_ty,\n            ],\n            vec![\n                OutputVarInfo {\n                    ty: range_check_type,\n                    ref_info: OutputVarReferenceInfo::NewTempVar { idx: Some(0) },\n                },\n                OutputVarInfo {\n                    ty: gas_builtin_type,\n                    ref_info: OutputVarReferenceInfo::NewTempVar { idx: Some(1) },\n                },\n                OutputVarInfo {\n                    ty: segment_arena_ty,\n                    ref_info: OutputVarReferenceInfo::NewTempVar { idx: Some(2) },\n                },\n                OutputVarInfo {\n                    ty: squashed_dict_ty,\n                    ref_info: OutputVarReferenceInfo::NewTempVar { idx: Some(3) },\n                },\n            ],\n            SierraApChange::Unknown,\n        ))\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use crate::extensions::lib_func::{\n    LibfuncSignature, OutputVarInfo, SignatureBasedConcreteLibfunc, SignatureSpecializationContext,\n    SpecializationContext,\n};\nuse crate::extensions::{NamedLibfunc, OutputVarReferenceInfo, SpecializationError};\nuse crate::program::{Function, GenericArg};\n\n/// Libfunc used to call user functions.\n#[derive(Default)]\npub struct FunctionCallLibfunc {}\nimpl NamedLibfunc for FunctionCallLibfunc {\n    type Concrete = FunctionCallConcreteLibfunc;\n    const STR_ID: &'static str = \"function_call\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        match args {\n            [GenericArg::UserFunc(function_id)] => {\n                let signature = context.get_function_signature(function_id)?;\n                let ap_change = context.get_function_ap_change(function_id)?;\n                Ok(LibfuncSignature::new_non_branch(\n                    signature.param_types.clone(),\n                    signature\n                        .ret_types\n                        .iter()\n                        .enumerate()\n                        .map(|(i, ty)| OutputVarInfo {\n                            ty: ty.clone(),\n                            ref_info: OutputVarReferenceInfo::NewTempVar { idx: Some(i) },\n                        })\n                        .collect(),\n                    ap_change,\n                ))\n            }\n            _ => Err(SpecializationError::UnsupportedGenericArg),\n        }\n    }\n\n    fn specialize(\n        &self,\n        context: &dyn SpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<Self::Concrete, SpecializationError> {\n        match args {\n            [GenericArg::UserFunc(function_id)] => Ok(Self::Concrete {\n                function: context.get_function(function_id)?,\n                signature: self.specialize_signature(context.upcast(), args)?,\n            }),\n            _ => Err(SpecializationError::UnsupportedGenericArg),\n        }\n    }\n}\n\npub struct FunctionCallConcreteLibfunc {\n    pub function: Function,\n    pub signature: LibfuncSignature,\n}\nimpl SignatureBasedConcreteLibfunc for FunctionCallConcreteLibfunc {\n    fn signature(&self) -> &LibfuncSignature {\n        &self.signature\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "// Module providing the gas related extensions.\nuse super::range_check::RangeCheckType;\nuse super::uint128::Uint128Type;\nuse crate::define_libfunc_hierarchy;\nuse crate::extensions::lib_func::{\n    BranchSignature, DeferredOutputKind, LibfuncSignature, OutputVarInfo, ParamSignature,\n    SierraApChange, SignatureSpecializationContext,\n};\nuse crate::extensions::{\n    NamedType, NoGenericArgsGenericLibfunc, NoGenericArgsGenericType, OutputVarReferenceInfo,\n    SpecializationError,\n};\nuse crate::ids::GenericTypeId;\n\n/// Type for gas actions.\n#[derive(Default)]\npub struct GasBuiltinType {}\nimpl NoGenericArgsGenericType for GasBuiltinType {\n    const ID: GenericTypeId = GenericTypeId::new_inline(\"GasBuiltin\");\n    const STORABLE: bool = true;\n    const DUPLICATABLE: bool = false;\n    const DROPPABLE: bool = false;\n    const SIZE: i16 = 1;\n}\n\ndefine_libfunc_hierarchy! {\n    pub enum GasLibfunc {\n        WithdrawGas(WithdrawGasLibfunc),\n        RedepositGas(RedepositGasLibfunc),\n        GetAvailableGas(GetAvailableGasLibfunc),\n    }, GasConcreteLibfunc\n}\n\n/// Libfunc for withdrawing gas.\n#[derive(Default)]\npub struct WithdrawGasLibfunc {}\nimpl NoGenericArgsGenericLibfunc for WithdrawGasLibfunc {\n    const STR_ID: &'static str = \"withdraw_gas\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let gas_builtin_type = context.get_concrete_type(GasBuiltinType::id(), &[])?;\n        let range_check_type = context.get_concrete_type(RangeCheckType::id(), &[])?;\n        Ok(LibfuncSignature {\n            param_signatures: vec![\n                ParamSignature {\n                    ty: range_check_type.clone(),\n                    allow_deferred: false,\n                    allow_add_const: true,\n                    allow_const: false,\n                },\n                ParamSignature::new(gas_builtin_type.clone()),\n            ],\n            branch_signatures: vec![\n                // Success:\n                BranchSignature {\n                    vars: vec![\n                        OutputVarInfo {\n                            ty: range_check_type.clone(),\n                            ref_info: OutputVarReferenceInfo::Deferred(\n                                DeferredOutputKind::AddConst { param_idx: 0 },\n                            ),\n                        },\n                        OutputVarInfo {\n                            ty: gas_builtin_type.clone(),\n                            ref_info: OutputVarReferenceInfo::NewTempVar { idx: Some(0) },\n                        },\n                    ],\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n                // Failure:\n                BranchSignature {\n                    vars: vec![\n                        OutputVarInfo {\n                            ty: range_check_type,\n                            ref_info: OutputVarReferenceInfo::Deferred(\n                                DeferredOutputKind::AddConst { param_idx: 0 },\n                            ),\n                        },\n                        OutputVarInfo {\n                            ty: gas_builtin_type,\n                            ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 1 },\n                        },\n                    ],\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n            ],\n            fallthrough: Some(0),\n        })\n    }\n}\n\n/// Libfunc for returning unused gas.\n#[derive(Default)]\npub struct RedepositGasLibfunc {}\nimpl NoGenericArgsGenericLibfunc for RedepositGasLibfunc {\n    const STR_ID: &'static str = \"redeposit_gas\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let gas_builtin_type = context.get_concrete_type(GasBuiltinType::id(), &[])?;\n        Ok(LibfuncSignature::new_non_branch(\n            vec![gas_builtin_type.clone()],\n            vec![OutputVarInfo {\n                ty: gas_builtin_type,\n                ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n            }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n\n/// Libfunc for returning the amount of available gas.\n#[derive(Default)]\npub struct GetAvailableGasLibfunc {}\nimpl NoGenericArgsGenericLibfunc for GetAvailableGasLibfunc {\n    const STR_ID: &'static str = \"get_available_gas\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let gas_builtin_type = context.get_concrete_type(GasBuiltinType::id(), &[])?;\n        Ok(LibfuncSignature::new_non_branch(\n            vec![gas_builtin_type.clone()],\n            vec![\n                OutputVarInfo {\n                    ty: gas_builtin_type,\n                    ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 0 },\n                },\n                OutputVarInfo {\n                    ty: context.get_concrete_type(Uint128Type::id(), &[])?,\n                    ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 0 },\n                },\n            ],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::marker::PhantomData;\n\nuse super::non_zero::nonzero_ty;\nuse crate::extensions::lib_func::{\n    BranchSignature, LibfuncSignature, OutputVarInfo, ParamSignature, SierraApChange,\n    SignatureSpecializationContext,\n};\nuse crate::extensions::{NoGenericArgsGenericLibfunc, OutputVarReferenceInfo, SpecializationError};\nuse crate::ids::GenericTypeId;\n\n/// Trait for implementing a IsZero library function for a type.\npub trait IsZeroTraits: Default {\n    /// The is_zero library function id.\n    const IS_ZERO: &'static str;\n    /// The id of the generic type to implement the library functions for.\n    const GENERIC_TYPE_ID: GenericTypeId;\n}\n\n/// Libfunc for checking whether the given value is zero or not, and returning a non-zero wrapped\n/// value in case of success.\n#[derive(Default)]\npub struct IsZeroLibfunc<TIsZeroTraits: IsZeroTraits> {\n    _phantom: PhantomData<TIsZeroTraits>,\n}\nimpl<TIsZeroTraits: IsZeroTraits> NoGenericArgsGenericLibfunc for IsZeroLibfunc<TIsZeroTraits> {\n    const STR_ID: &'static str = TIsZeroTraits::IS_ZERO;\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let ty = context.get_concrete_type(TIsZeroTraits::GENERIC_TYPE_ID, &[])?;\n        Ok(LibfuncSignature {\n            param_signatures: vec![ParamSignature::new(ty.clone())],\n            branch_signatures: vec![\n                // Zero.\n                BranchSignature {\n                    vars: vec![],\n                    ap_change: SierraApChange::Known { new_vars_only: true },\n                },\n                // NonZero.\n                BranchSignature {\n                    vars: vec![OutputVarInfo {\n                        ty: nonzero_ty(context, &ty)?,\n                        ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 0 },\n                    }],\n                    ap_change: SierraApChange::Known { new_vars_only: true },\n                },\n            ],\n            fallthrough: Some(0),\n        })\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use super::uninitialized::UninitializedType;\nuse crate::define_libfunc_hierarchy;\nuse crate::extensions::lib_func::{\n    LibfuncSignature, OutputVarInfo, ParamSignature, SierraApChange,\n    SignatureAndTypeGenericLibfunc, SignatureOnlyGenericLibfunc, SignatureSpecializationContext,\n    WrapSignatureAndTypeGenericLibfunc,\n};\nuse crate::extensions::{\n    args_as_single_type, NamedType, NoGenericArgsGenericLibfunc, OutputVarReferenceInfo,\n    SpecializationError,\n};\nuse crate::ids::ConcreteTypeId;\nuse crate::program::GenericArg;\n\ndefine_libfunc_hierarchy! {\n    pub enum MemLibfunc {\n        StoreTemp(StoreTempLibfunc),\n        StoreLocal(StoreLocalLibfunc),\n        FinalizeLocals(FinalizeLocalsLibfunc),\n        AllocLocal(AllocLocalLibfunc),\n        Rename(RenameLibfunc),\n    }, MemConcreteLibfunc\n}\n\n/// Libfunc for storing a value into temporary memory.\n#[derive(Default)]\npub struct StoreTempLibfuncWrapped {}\nimpl SignatureAndTypeGenericLibfunc for StoreTempLibfuncWrapped {\n    const STR_ID: &'static str = \"store_temp\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        ty: ConcreteTypeId,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        context.as_type_specialization_context().get_type_info(ty.clone())?;\n        Ok(LibfuncSignature::new_non_branch_ex(\n            vec![ParamSignature {\n                ty: ty.clone(),\n                allow_deferred: true,\n                allow_add_const: true,\n                allow_const: true,\n            }],\n            vec![OutputVarInfo {\n                ty,\n                ref_info: OutputVarReferenceInfo::NewTempVar { idx: Some(0) },\n            }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\npub type StoreTempLibfunc = WrapSignatureAndTypeGenericLibfunc<StoreTempLibfuncWrapped>;\n\n/// Libfunc for storing a value into local memory.\n#[derive(Default)]\npub struct StoreLocalLibfuncWrapped {}\nimpl SignatureAndTypeGenericLibfunc for StoreLocalLibfuncWrapped {\n    const STR_ID: &'static str = \"store_local\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        ty: ConcreteTypeId,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let uninitialized_type =\n            context.get_wrapped_concrete_type(UninitializedType::id(), ty.clone())?;\n        Ok(LibfuncSignature::new_non_branch_ex(\n            vec![\n                ParamSignature::new(uninitialized_type),\n                ParamSignature {\n                    ty: ty.clone(),\n                    allow_deferred: true,\n                    allow_add_const: true,\n                    allow_const: true,\n                },\n            ],\n            vec![OutputVarInfo { ty, ref_info: OutputVarReferenceInfo::NewLocalVar }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\npub type StoreLocalLibfunc = WrapSignatureAndTypeGenericLibfunc<StoreLocalLibfuncWrapped>;\n\n/// Libfunc for finalizing the locals for current function.\n#[derive(Default)]\npub struct FinalizeLocalsLibfunc {}\nimpl NoGenericArgsGenericLibfunc for FinalizeLocalsLibfunc {\n    const STR_ID: &'static str = \"finalize_locals\";\n\n    fn specialize_signature(\n        &self,\n        _context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        Ok(LibfuncSignature::new_non_branch(\n            vec![],\n            vec![],\n            SierraApChange::Known { new_vars_only: false },\n        ))\n    }\n}\n\n/// Libfunc for allocating locals for later stores.\n#[derive(Default)]\npub struct AllocLocalLibfuncWrapped {}\nimpl SignatureAndTypeGenericLibfunc for AllocLocalLibfuncWrapped {\n    const STR_ID: &'static str = \"alloc_local\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        ty: ConcreteTypeId,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        Ok(LibfuncSignature::new_non_branch(\n            vec![],\n            vec![OutputVarInfo {\n                ty: context.get_wrapped_concrete_type(UninitializedType::id(), ty)?,\n                ref_info: OutputVarReferenceInfo::NewLocalVar,\n            }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\npub type AllocLocalLibfunc = WrapSignatureAndTypeGenericLibfunc<AllocLocalLibfuncWrapped>;\n\n/// Libfunc for renaming an identifier - used to align identities for flow control merge.\n#[derive(Default)]\npub struct RenameLibfunc {}\nimpl SignatureOnlyGenericLibfunc for RenameLibfunc {\n    const STR_ID: &'static str = \"rename\";\n\n    fn specialize_signature(\n        &self,\n        _context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let ty = args_as_single_type(args)?;\n        Ok(LibfuncSignature::new_non_branch(\n            vec![ty.clone()],\n            vec![OutputVarInfo {\n                ty,\n                ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 0 },\n            }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use self::enm::EnumType;\nuse self::structure::StructType;\nuse super::lib_func::SignatureSpecializationContext;\nuse super::{NamedType, SpecializationError};\nuse crate::ids::{ConcreteTypeId, UserTypeId};\nuse crate::program::GenericArg;\n\npub mod ap_tracking;\npub mod array;\npub mod bitwise;\npub mod boolean;\npub mod boxing;\npub mod branch_align;\npub mod builtin_cost;\npub mod casts;\npub mod consts;\npub mod debug;\npub mod drop;\npub mod duplicate;\npub mod ec;\npub mod enm;\npub mod felt252;\npub mod felt252_dict;\npub mod function_call;\npub mod gas;\npub mod is_zero;\npub mod mem;\npub mod non_zero;\npub mod nullable;\npub mod pedersen;\npub mod range_check;\npub mod segment_arena;\npub mod snapshot;\npub mod squashed_felt252_dict;\npub mod starknet;\npub mod structure;\npub mod try_from_felt252;\npub mod uint;\npub mod uint128;\npub mod unconditional_jump;\npub mod uninitialized;\n\n/// Helper for Unit type def.\nfn get_unit_type(\n    context: &dyn SignatureSpecializationContext,\n) -> Result<ConcreteTypeId, SpecializationError> {\n    context.get_concrete_type(\n        StructType::id(),\n        &[GenericArg::UserType(UserTypeId::from_string(\"Tuple\"))],\n    )\n}\n\n/// Helper for Bool type def.\nfn get_bool_type(\n    context: &dyn SignatureSpecializationContext,\n) -> Result<ConcreteTypeId, SpecializationError> {\n    let unit_type = get_unit_type(context)?;\n    context.get_concrete_type(\n        EnumType::id(),\n        &[\n            GenericArg::UserType(UserTypeId::from_string(\"core::bool\")),\n            GenericArg::Type(unit_type.clone()),\n            GenericArg::Type(unit_type),\n        ],\n    )\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use crate::extensions::lib_func::{\n    LibfuncSignature, OutputVarInfo, SierraApChange, SignatureOnlyGenericLibfunc,\n    SignatureSpecializationContext,\n};\nuse crate::extensions::types::{\n    GenericTypeArgGenericType, GenericTypeArgGenericTypeWrapper, TypeInfo,\n};\nuse crate::extensions::{\n    args_as_single_type, NamedType, OutputVarReferenceInfo, SpecializationError,\n};\nuse crate::ids::{ConcreteTypeId, GenericTypeId};\nuse crate::program::GenericArg;\n\n/// Type wrapping a value as non zero.\n#[derive(Default)]\npub struct NonZeroTypeWrapped {}\nimpl GenericTypeArgGenericType for NonZeroTypeWrapped {\n    const ID: GenericTypeId = GenericTypeId::new_inline(\"NonZero\");\n\n    fn calc_info(\n        &self,\n        long_id: crate::program::ConcreteTypeLongId,\n        TypeInfo { size, storable, droppable, duplicatable, .. }: TypeInfo,\n    ) -> Result<TypeInfo, SpecializationError> {\n        if storable {\n            Ok(TypeInfo { long_id, size, storable, droppable, duplicatable })\n        } else {\n            Err(SpecializationError::UnsupportedGenericArg)\n        }\n    }\n}\npub type NonZeroType = GenericTypeArgGenericTypeWrapper<NonZeroTypeWrapped>;\n\n/// Returns the type `NonZero<T>` for a given type `T`.\npub fn nonzero_ty(\n    context: &dyn SignatureSpecializationContext,\n    ty: &ConcreteTypeId,\n) -> Result<ConcreteTypeId, SpecializationError> {\n    context.get_wrapped_concrete_type(NonZeroType::id(), ty.clone())\n}\n\n/// Libfunc for unwrapping a `NonZero<T>` back into a T.\n#[derive(Default)]\npub struct UnwrapNonZeroLibfunc {}\nimpl SignatureOnlyGenericLibfunc for UnwrapNonZeroLibfunc {\n    const STR_ID: &'static str = \"unwrap_non_zero\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let ty = args_as_single_type(args)?;\n        Ok(LibfuncSignature::new_non_branch(\n            vec![nonzero_ty(context, &ty)?],\n            vec![OutputVarInfo {\n                ty,\n                ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 0 },\n            }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use super::boxing::BoxType;\nuse crate::define_libfunc_hierarchy;\nuse crate::extensions::lib_func::{\n    BranchSignature, DeferredOutputKind, LibfuncSignature, OutputVarInfo, ParamSignature,\n    SierraApChange, SignatureAndTypeGenericLibfunc, SignatureOnlyGenericLibfunc,\n    SignatureSpecializationContext, WrapSignatureAndTypeGenericLibfunc,\n};\nuse crate::extensions::types::{\n    GenericTypeArgGenericType, GenericTypeArgGenericTypeWrapper, TypeInfo,\n};\nuse crate::extensions::{\n    args_as_single_type, ConcreteType, NamedType, OutputVarReferenceInfo, SpecializationError,\n};\nuse crate::ids::{ConcreteTypeId, GenericTypeId};\nuse crate::program::GenericArg;\n\n/// A type that holds a possibly-null pointer to an object.\n///\n/// It behaves exactly like `Option<Box<T>>`, except that it only uses 1 memory cell (rather than 2\n/// in `Option<Box<T>>`) - the value is 0 if and only if there is no object.\n///\n/// This type uses the fact that Casm pointers can never be zero.\n#[derive(Default)]\npub struct NullableTypeWrapped {}\nimpl GenericTypeArgGenericType for NullableTypeWrapped {\n    const ID: GenericTypeId = GenericTypeId::new_inline(\"Nullable\");\n    fn calc_info(\n        &self,\n        long_id: crate::program::ConcreteTypeLongId,\n        TypeInfo { storable, droppable, duplicatable, .. }: TypeInfo,\n    ) -> Result<TypeInfo, SpecializationError> {\n        if storable {\n            Ok(TypeInfo { long_id, size: 1, storable, droppable, duplicatable })\n        } else {\n            Err(SpecializationError::UnsupportedGenericArg)\n        }\n    }\n}\npub type NullableType = GenericTypeArgGenericTypeWrapper<NullableTypeWrapped>;\n\npub struct NullableConcreteType {\n    pub info: TypeInfo,\n    pub ty: ConcreteTypeId,\n}\nimpl ConcreteType for NullableConcreteType {\n    fn info(&self) -> &TypeInfo {\n        &self.info\n    }\n}\n\ndefine_libfunc_hierarchy! {\n    pub enum NullableLibfunc {\n        Null(NullLibfunc),\n        NullableFromBox(NullableFromBoxLibfunc),\n        MatchNullable(MatchNullableLibfunc),\n    }, NullableConcreteLibfunc\n}\n\n/// Libfunc for creating a null object of type `Nullable<T>`.\n#[derive(Default)]\npub struct NullLibfunc {}\nimpl SignatureOnlyGenericLibfunc for NullLibfunc {\n    const STR_ID: &'static str = \"null\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let ty = args_as_single_type(args)?;\n        Ok(LibfuncSignature::new_non_branch(\n            vec![],\n            vec![OutputVarInfo {\n                ty: context.get_wrapped_concrete_type(NullableType::id(), ty)?,\n                ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n            }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n\n/// Libfunc for converting `Box<T>` to `Nullable<T>`.\n#[derive(Default)]\npub struct NullableFromBoxLibfuncWrapped {}\nimpl SignatureAndTypeGenericLibfunc for NullableFromBoxLibfuncWrapped {\n    const STR_ID: &'static str = \"nullable_from_box\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        ty: ConcreteTypeId,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        Ok(LibfuncSignature::new_non_branch_ex(\n            vec![ParamSignature {\n                ty: context.get_wrapped_concrete_type(BoxType::id(), ty.clone())?,\n                allow_deferred: true,\n                allow_add_const: true,\n                allow_const: true,\n            }],\n            vec![OutputVarInfo {\n                ty: context.get_wrapped_concrete_type(NullableType::id(), ty)?,\n                ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 0 },\n            }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\npub type NullableFromBoxLibfunc = WrapSignatureAndTypeGenericLibfunc<NullableFromBoxLibfuncWrapped>;\n\n/// Libfunc for converting `Nullable<T>` to either `Box<T>` or nothing (in the case of `null`).\n#[derive(Default)]\npub struct MatchNullableLibfuncWrapped {}\nimpl SignatureAndTypeGenericLibfunc for MatchNullableLibfuncWrapped {\n    const STR_ID: &'static str = \"match_nullable\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        ty: ConcreteTypeId,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        Ok(LibfuncSignature {\n            param_signatures: vec![ParamSignature::new(\n                context.get_wrapped_concrete_type(NullableType::id(), ty.clone())?,\n            )],\n            branch_signatures: vec![\n                // `null`.\n                BranchSignature {\n                    vars: vec![],\n                    ap_change: SierraApChange::Known { new_vars_only: true },\n                },\n                // `Box<T>`.\n                BranchSignature {\n                    vars: vec![OutputVarInfo {\n                        ty: context.get_wrapped_concrete_type(BoxType::id(), ty)?,\n                        ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 0 },\n                    }],\n                    ap_change: SierraApChange::Known { new_vars_only: true },\n                },\n            ],\n            fallthrough: Some(0),\n        })\n    }\n}\npub type MatchNullableLibfunc = WrapSignatureAndTypeGenericLibfunc<MatchNullableLibfuncWrapped>;\n",
    "metadata": {}
  },
  {
    "pageContent": "use super::felt252::Felt252Type;\nuse crate::define_libfunc_hierarchy;\nuse crate::extensions::lib_func::{\n    DeferredOutputKind, LibfuncSignature, OutputVarInfo, ParamSignature, SierraApChange,\n    SignatureSpecializationContext,\n};\nuse crate::extensions::{\n    NamedType, NoGenericArgsGenericLibfunc, NoGenericArgsGenericType, OutputVarReferenceInfo,\n    SpecializationError,\n};\nuse crate::ids::GenericTypeId;\n\n/// Type representing the Pedersen hash builtin.\n#[derive(Default)]\npub struct PedersenType {}\nimpl NoGenericArgsGenericType for PedersenType {\n    const ID: GenericTypeId = GenericTypeId::new_inline(\"Pedersen\");\n    const STORABLE: bool = true;\n    const DUPLICATABLE: bool = false;\n    const DROPPABLE: bool = false;\n    const SIZE: i16 = 1;\n}\n\ndefine_libfunc_hierarchy! {\n    pub enum PedersenLibfunc {\n        PedersenHash(PedersenHashLibfunc),\n    }, PedersenConcreteLibfunc\n}\n\n/// Libfunc for computing the Pedersen hash of two felt252s.\n/// Returns a felt252 (and the updated builtin pointer).\n#[derive(Default)]\npub struct PedersenHashLibfunc {}\nimpl NoGenericArgsGenericLibfunc for PedersenHashLibfunc {\n    const STR_ID: &'static str = \"pedersen\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let pedersen_ty = context.get_concrete_type(PedersenType::id(), &[])?;\n        let felt252_ty = context.get_concrete_type(Felt252Type::id(), &[])?;\n        Ok(LibfuncSignature::new_non_branch_ex(\n            vec![\n                ParamSignature {\n                    ty: pedersen_ty.clone(),\n                    allow_deferred: false,\n                    allow_add_const: true,\n                    allow_const: false,\n                },\n                ParamSignature::new(felt252_ty.clone()),\n                ParamSignature::new(felt252_ty.clone()),\n            ],\n            vec![\n                OutputVarInfo {\n                    ty: pedersen_ty,\n                    ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::AddConst {\n                        param_idx: 0,\n                    }),\n                },\n                OutputVarInfo {\n                    ty: felt252_ty,\n                    ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n                },\n            ],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use crate::extensions::NoGenericArgsGenericType;\nuse crate::ids::GenericTypeId;\n\n/// Type for Range Check builtin.\n#[derive(Default)]\npub struct RangeCheckType {}\nimpl NoGenericArgsGenericType for RangeCheckType {\n    const ID: GenericTypeId = GenericTypeId::new_inline(\"RangeCheck\");\n    const STORABLE: bool = true;\n    const DUPLICATABLE: bool = false;\n    const DROPPABLE: bool = false;\n    const SIZE: i16 = 1;\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use crate::extensions::NoGenericArgsGenericType;\nuse crate::ids::GenericTypeId;\n\n/// Type for the Segment Arena builtin.\n/// This type should be initialized and destructed by the OS.\n/// It is assumed to be a pointer to a segment containing the following struct:\n/// A data segment start.\n/// Number of segments in the data segment.\n/// Number of destructed segments.\n/// On each new segment/segment finalization the struct is appended to the buffer and the returned\n/// pointer is incremented accrodingly.\n/// The data segment contains the following info for each allocated segment:\n/// The start of the segment (written on allocation).\n/// The end of the segment (written on finalization).\n/// A sequential number of the segment when destructed (written on finalize).\n#[derive(Default)]\npub struct SegmentArenaType {}\nimpl NoGenericArgsGenericType for SegmentArenaType {\n    const ID: GenericTypeId = GenericTypeId::new_inline(\"SegmentArena\");\n    const STORABLE: bool = true;\n    const DUPLICATABLE: bool = false;\n    const DROPPABLE: bool = false;\n    const SIZE: i16 = 1;\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use crate::extensions::lib_func::{\n    LibfuncSignature, OutputVarInfo, ParamSignature, SierraApChange, SignatureOnlyGenericLibfunc,\n    SignatureSpecializationContext,\n};\nuse crate::extensions::types::{\n    GenericTypeArgGenericType, GenericTypeArgGenericTypeWrapper, TypeInfo,\n};\nuse crate::extensions::{\n    args_as_single_type, NamedType, OutputVarReferenceInfo, SpecializationError,\n};\nuse crate::ids::{ConcreteTypeId, GenericTypeId};\nuse crate::program::GenericArg;\n\n/// Type for a type's snapshot.\n#[derive(Default)]\npub struct SnapshotTypeWrapped {}\nimpl GenericTypeArgGenericType for SnapshotTypeWrapped {\n    const ID: GenericTypeId = GenericTypeId::new_inline(\"Snapshot\");\n\n    fn calc_info(\n        &self,\n        long_id: crate::program::ConcreteTypeLongId,\n        TypeInfo { size, storable, duplicatable, .. }: TypeInfo,\n    ) -> Result<TypeInfo, SpecializationError> {\n        // Duplicatable types are their own snapshot - as the snapshot itself is useless if we can\n        // dup the value already.\n        if storable && !duplicatable {\n            Ok(TypeInfo { long_id, size, storable, droppable: true, duplicatable: true })\n        } else {\n            Err(SpecializationError::UnsupportedGenericArg)\n        }\n    }\n}\npub type SnapshotType = GenericTypeArgGenericTypeWrapper<SnapshotTypeWrapped>;\n\n/// Returns the type snapshot for a given type `T`.\n/// For duplicatable returns `T` itself, as a regular dup is already a snapshot.\npub fn snapshot_ty(\n    context: &dyn SignatureSpecializationContext,\n    ty: ConcreteTypeId,\n) -> Result<ConcreteTypeId, SpecializationError> {\n    if context.get_type_info(ty.clone())?.duplicatable {\n        Ok(ty)\n    } else {\n        context.get_wrapped_concrete_type(SnapshotType::id(), ty)\n    }\n}\n\n/// Libfunc for taking a snapshot `Snapshot<T>` from a T.\n#[derive(Default)]\npub struct SnapshotTakeLibfunc {}\nimpl SignatureOnlyGenericLibfunc for SnapshotTakeLibfunc {\n    const STR_ID: &'static str = \"snapshot_take\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let ty = args_as_single_type(args)?;\n        Ok(LibfuncSignature::new_non_branch_ex(\n            vec![ParamSignature {\n                ty: ty.clone(),\n                allow_deferred: true,\n                allow_add_const: true,\n                allow_const: true,\n            }],\n            vec![\n                OutputVarInfo {\n                    ty: ty.clone(),\n                    ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 0 },\n                },\n                OutputVarInfo {\n                    ty: snapshot_ty(context, ty)?,\n                    ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 0 },\n                },\n            ],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use crate::extensions::types::{\n    GenericTypeArgGenericType, GenericTypeArgGenericTypeWrapper, TypeInfo,\n};\nuse crate::extensions::SpecializationError;\nuse crate::ids::GenericTypeId;\n\n/// Type representing a static squashed dictionary from a felt252 to any type of size one.\n#[derive(Default)]\npub struct SquashedFelt252DictTypeWrapped {}\nimpl GenericTypeArgGenericType for SquashedFelt252DictTypeWrapped {\n    const ID: GenericTypeId = GenericTypeId::new_inline(\"SquashedFelt252Dict\");\n\n    fn calc_info(\n        &self,\n        long_id: crate::program::ConcreteTypeLongId,\n        TypeInfo { size, storable, droppable, .. }: TypeInfo,\n    ) -> Result<TypeInfo, SpecializationError> {\n        // Note: SquashedFelt252Dict is defined as non-duplicatable even if the inner type is\n        // duplicatable to allow libfunc that adds entries to it (treat it similarly to an array).\n        // TODO(Gil): the implementation support values of size 1. Remove when other sizes are\n        // supported.\n        if storable && size == 1 {\n            Ok(TypeInfo { long_id, storable: true, droppable, duplicatable: false, size: 2 })\n        } else {\n            Err(SpecializationError::UnsupportedGenericArg)\n        }\n    }\n}\npub type SquashedFelt252DictType = GenericTypeArgGenericTypeWrapper<SquashedFelt252DictTypeWrapped>;\n",
    "metadata": {}
  },
  {
    "pageContent": "use super::felt252_span_ty;\nuse super::syscalls::SyscallGenericLibfunc;\nuse crate::extensions::lib_func::SignatureSpecializationContext;\nuse crate::extensions::SpecializationError;\n\n/// Libfunc for an emit event system call.\n#[derive(Default)]\npub struct EmitEventLibfunc {}\nimpl SyscallGenericLibfunc for EmitEventLibfunc {\n    const STR_ID: &'static str = \"emit_event_syscall\";\n\n    fn input_tys(\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<Vec<crate::ids::ConcreteTypeId>, SpecializationError> {\n        let span_ty = felt252_span_ty(context)?;\n        Ok(vec![\n            // keys\n            span_ty.clone(),\n            // data\n            span_ty,\n        ])\n    }\n\n    fn success_output_tys(\n        _context: &dyn SignatureSpecializationContext,\n    ) -> Result<Vec<crate::ids::ConcreteTypeId>, SpecializationError> {\n        Ok(vec![])\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::marker::PhantomData;\n\nuse super::felt252_span_ty;\nuse super::interoperability::ContractAddressType;\nuse super::syscalls::SyscallGenericLibfunc;\nuse crate::extensions::boxing::BoxType;\nuse crate::extensions::felt252::Felt252Type;\nuse crate::extensions::lib_func::SignatureSpecializationContext;\nuse crate::extensions::structure::StructType;\nuse crate::extensions::uint::Uint64Type;\nuse crate::extensions::uint128::Uint128Type;\nuse crate::extensions::{NamedType, NoGenericArgsGenericType, SpecializationError};\nuse crate::ids::{ConcreteTypeId, UserTypeId};\nuse crate::program::GenericArg;\n\n/// Trait for implementing getters.\npub trait GetterTraits: Default {\n    /// The generic libfunc id for the getter libfunc.\n    const STR_ID: &'static str;\n    /// The simple sierra generic type returned by the getter.\n    type InfoType: NoGenericArgsGenericType;\n}\n\n/// Same as GetterTraits, but with a function to return the concrete TypeId.\npub trait GetterTraitsEx: Default {\n    /// The generic libfunc id for the getter libfunc.\n    const STR_ID: &'static str;\n    /// The simple sierra generic type returned by the getter.\n    fn info_type_id(\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<ConcreteTypeId, SpecializationError>;\n}\n\nimpl<TGetterTraits: GetterTraits> GetterTraitsEx for TGetterTraits {\n    const STR_ID: &'static str = TGetterTraits::STR_ID;\n    fn info_type_id(\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<ConcreteTypeId, SpecializationError> {\n        context.get_concrete_type(TGetterTraits::InfoType::id(), &[])\n    }\n}\n\n/// Libfunc for a getter system call.\n#[derive(Default)]\npub struct GetterLibfunc<TGetterTraitsEx: GetterTraitsEx> {\n    _phantom: PhantomData<TGetterTraitsEx>,\n}\nimpl<TGetterTraitsEx: GetterTraitsEx> SyscallGenericLibfunc for GetterLibfunc<TGetterTraitsEx> {\n    const STR_ID: &'static str = TGetterTraitsEx::STR_ID;\n\n    fn input_tys(\n        _context: &dyn SignatureSpecializationContext,\n    ) -> Result<Vec<crate::ids::ConcreteTypeId>, SpecializationError> {\n        Ok(vec![])\n    }\n\n    fn success_output_tys(\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<Vec<crate::ids::ConcreteTypeId>, SpecializationError> {\n        Ok(vec![TGetterTraitsEx::info_type_id(context)?])\n    }\n}\n\n/// Helper for getting a boxed type.\n\n/// Helper for getting a boxed type for a given type `T`.\npub fn boxed_ty(\n    context: &dyn SignatureSpecializationContext,\n    ty: ConcreteTypeId,\n) -> Result<ConcreteTypeId, SpecializationError> {\n    context.get_wrapped_concrete_type(BoxType::id(), ty)\n}\n\n/// Helper for ExecutionInfo type def.\nfn get_execution_info_type(\n    context: &dyn SignatureSpecializationContext,\n) -> Result<ConcreteTypeId, SpecializationError> {\n    let felt252_ty = context.get_concrete_type(Felt252Type::id(), &[])?;\n    let contract_address_ty = context.get_concrete_type(ContractAddressType::id(), &[])?;\n    context.get_concrete_type(\n        StructType::id(),\n        &[\n            GenericArg::UserType(UserTypeId::from_string(\"core::starknet::info::ExecutionInfo\")),\n            // block_info\n            GenericArg::Type(boxed_ty(context, get_block_info_type(context)?)?),\n            // tx_info\n            GenericArg::Type(boxed_ty(context, get_tx_info_type(context)?)?),\n            // caller_address\n            GenericArg::Type(contract_address_ty.clone()),\n            // contract_address\n            GenericArg::Type(contract_address_ty),\n            // entry_point_selector\n            GenericArg::Type(felt252_ty),\n        ],\n    )\n}\n\n/// Helper for BlockInfo type def.\nfn get_block_info_type(\n    context: &dyn SignatureSpecializationContext,\n) -> Result<ConcreteTypeId, SpecializationError> {\n    let contract_address_ty = context.get_concrete_type(ContractAddressType::id(), &[])?;\n    let u64_ty = context.get_concrete_type(Uint64Type::id(), &[])?;\n    context.get_concrete_type(\n        StructType::id(),\n        &[\n            GenericArg::UserType(UserTypeId::from_string(\"core::starknet::info::BlockInfo\")),\n            // block_number\n            GenericArg::Type(u64_ty.clone()),\n            // block_timestamp\n            GenericArg::Type(u64_ty),\n            // sequencer_address\n            GenericArg::Type(contract_address_ty),\n        ],\n    )\n}\n\n/// Helper for TxInfo type def.\nfn get_tx_info_type(\n    context: &dyn SignatureSpecializationContext,\n) -> Result<ConcreteTypeId, SpecializationError> {\n    let felt252_ty = context.get_concrete_type(Felt252Type::id(), &[])?;\n    let contract_address_ty = context.get_concrete_type(ContractAddressType::id(), &[])?;\n    let u128_ty = context.get_concrete_type(Uint128Type::id(), &[])?;\n    context.get_concrete_type(\n        StructType::id(),\n        &[\n            GenericArg::UserType(UserTypeId::from_string(\"core::starknet::info::TxInfo\")),\n            // version\n            GenericArg::Type(felt252_ty.clone()),\n            // account_contract_address\n            GenericArg::Type(contract_address_ty),\n            // max_fee\n            GenericArg::Type(u128_ty),\n            // signature\n            GenericArg::Type(felt252_span_ty(context)?),\n            // transaction_hash\n            GenericArg::Type(felt252_ty.clone()),\n            // chain_id\n            GenericArg::Type(felt252_ty.clone()),\n            // nonce\n            GenericArg::Type(felt252_ty),\n        ],\n    )\n}\n\n#[derive(Default)]\npub struct GetExecutionInfoTrait {}\nimpl GetterTraitsEx for GetExecutionInfoTrait {\n    const STR_ID: &'static str = \"get_execution_info_syscall\";\n\n    fn info_type_id(\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<ConcreteTypeId, SpecializationError> {\n        boxed_ty(context, get_execution_info_type(context)?)\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use super::felt252_span_ty;\nuse super::syscalls::SyscallGenericLibfunc;\nuse crate::extensions::consts::{ConstGenLibfunc, WrapConstGenLibfunc};\nuse crate::extensions::felt252::Felt252Type;\nuse crate::extensions::lib_func::{\n    LibfuncSignature, OutputVarInfo, ParamSignature, SierraApChange, SignatureSpecializationContext,\n};\nuse crate::extensions::modules::get_bool_type;\nuse crate::extensions::try_from_felt252::TryFromFelt252;\nuse crate::extensions::{\n    NamedType, NoGenericArgsGenericLibfunc, NoGenericArgsGenericType, OutputVarReferenceInfo,\n    SpecializationError,\n};\nuse crate::ids::GenericTypeId;\n\n/// Type for Starknet contract address, a value in the range [0, 2 ** 251).\n#[derive(Default)]\npub struct ContractAddressType {}\nimpl NoGenericArgsGenericType for ContractAddressType {\n    const ID: GenericTypeId = GenericTypeId::new_inline(\"ContractAddress\");\n    const STORABLE: bool = true;\n    const DUPLICATABLE: bool = true;\n    const DROPPABLE: bool = true;\n    const SIZE: i16 = 1;\n}\n\n/// Libfunc for creating a constant storage address.\n#[derive(Default)]\npub struct ContractAddressConstLibfuncWrapped {}\nimpl ConstGenLibfunc for ContractAddressConstLibfuncWrapped {\n    const STR_ID: &'static str = \"contract_address_const\";\n    const GENERIC_TYPE_ID: GenericTypeId = <ContractAddressType as NoGenericArgsGenericType>::ID;\n}\n\npub type ContractAddressConstLibfunc = WrapConstGenLibfunc<ContractAddressConstLibfuncWrapped>;\n\n/// Libfunc for attempting to convert a felt252 into a contract address.\n#[derive(Default)]\npub struct ContractAddressTryFromFelt252Libfunc;\nimpl TryFromFelt252 for ContractAddressTryFromFelt252Libfunc {\n    const STR_ID: &'static str = \"contract_address_try_from_felt252\";\n    const GENERIC_TYPE_ID: GenericTypeId = <ContractAddressType as NoGenericArgsGenericType>::ID;\n}\n\n/// Libfunc for converting a ContractAddress into a felt252.\n#[derive(Default)]\npub struct ContractAddressToFelt252Libfunc {}\nimpl NoGenericArgsGenericLibfunc for ContractAddressToFelt252Libfunc {\n    const STR_ID: &'static str = \"contract_address_to_felt252\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        Ok(LibfuncSignature::new_non_branch_ex(\n            vec![ParamSignature {\n                ty: context.get_concrete_type(ContractAddressType::id(), &[])?,\n                allow_deferred: true,\n                allow_add_const: true,\n                allow_const: true,\n            }],\n            vec![OutputVarInfo {\n                ty: context.get_concrete_type(Felt252Type::id(), &[])?,\n                ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 0 },\n            }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n\n/// Type for Starknet class hash, a value in the range [0, 2 ** 251).\n#[derive(Default)]\npub struct ClassHashType {}\nimpl NoGenericArgsGenericType for ClassHashType {\n    const ID: GenericTypeId = GenericTypeId::new_inline(\"ClassHash\");\n    const STORABLE: bool = true;\n    const DUPLICATABLE: bool = true;\n    const DROPPABLE: bool = true;\n    const SIZE: i16 = 1;\n}\n\n/// Libfunc for creating a constant storage address.\n#[derive(Default)]\npub struct ClassHashConstLibfuncWrapped {}\nimpl ConstGenLibfunc for ClassHashConstLibfuncWrapped {\n    const STR_ID: &'static str = \"class_hash_const\";\n    const GENERIC_TYPE_ID: GenericTypeId = <ClassHashType as NoGenericArgsGenericType>::ID;\n}\n\npub type ClassHashConstLibfunc = WrapConstGenLibfunc<ClassHashConstLibfuncWrapped>;\n\n/// Libfunc for attempting to convert a felt252 into a class hash.\n#[derive(Default)]\npub struct ClassHashTryFromFelt252Trait;\nimpl TryFromFelt252 for ClassHashTryFromFelt252Trait {\n    const STR_ID: &'static str = \"class_hash_try_from_felt252\";\n    const GENERIC_TYPE_ID: GenericTypeId = <ClassHashType as NoGenericArgsGenericType>::ID;\n}\n\n/// Libfunc for converting a class hash into a felt252.\n#[derive(Default)]\npub struct ClassHashToFelt252Libfunc {}\nimpl NoGenericArgsGenericLibfunc for ClassHashToFelt252Libfunc {\n    const STR_ID: &'static str = \"class_hash_to_felt252\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        Ok(LibfuncSignature::new_non_branch_ex(\n            vec![ParamSignature {\n                ty: context.get_concrete_type(ClassHashType::id(), &[])?,\n                allow_deferred: true,\n                allow_add_const: true,\n                allow_const: true,\n            }],\n            vec![OutputVarInfo {\n                ty: context.get_concrete_type(Felt252Type::id(), &[])?,\n                ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 0 },\n            }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n\n/// Libfunc for a storage call contract system call.\n#[derive(Default)]\npub struct CallContractLibfunc {}\nimpl SyscallGenericLibfunc for CallContractLibfunc {\n    const STR_ID: &'static str = \"call_contract_syscall\";\n\n    fn input_tys(\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<Vec<crate::ids::ConcreteTypeId>, SpecializationError> {\n        Ok(vec![\n            // Address\n            context.get_concrete_type(ContractAddressType::id(), &[])?,\n            // Entry point selector.\n            context.get_concrete_type(Felt252Type::id(), &[])?,\n            // Call data\n            felt252_span_ty(context)?,\n        ])\n    }\n\n    fn success_output_tys(\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<Vec<crate::ids::ConcreteTypeId>, SpecializationError> {\n        Ok(vec![felt252_span_ty(context)?])\n    }\n}\n\n/// Libfunc for a deploying a declared class system call.\n#[derive(Default)]\npub struct DeployLibfunc {}\nimpl SyscallGenericLibfunc for DeployLibfunc {\n    const STR_ID: &'static str = \"deploy_syscall\";\n\n    fn input_tys(\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<Vec<crate::ids::ConcreteTypeId>, SpecializationError> {\n        Ok(vec![\n            // Class hash\n            context.get_concrete_type(ClassHashType::id(), &[])?,\n            // Contract address salt\n            context.get_concrete_type(Felt252Type::id(), &[])?,\n            // Constructor call data\n            felt252_span_ty(context)?,\n            // Deploy from zero\n            get_bool_type(context)?,\n        ])\n    }\n\n    fn success_output_tys(\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<Vec<crate::ids::ConcreteTypeId>, SpecializationError> {\n        Ok(vec![\n            context.get_concrete_type(ContractAddressType::id(), &[])?,\n            felt252_span_ty(context)?,\n        ])\n    }\n}\n\n/// Libfunc for a library call system call.\n#[derive(Default)]\npub struct LibraryCallLibfunc {}\nimpl SyscallGenericLibfunc for LibraryCallLibfunc {\n    const STR_ID: &'static str = \"library_call_syscall\";\n\n    fn input_tys(\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<Vec<crate::ids::ConcreteTypeId>, SpecializationError> {\n        Ok(vec![\n            // Class hash\n            context.get_concrete_type(ClassHashType::id(), &[])?,\n            // Function selector\n            context.get_concrete_type(Felt252Type::id(), &[])?,\n            // Call data\n            felt252_span_ty(context)?,\n        ])\n    }\n\n    fn success_output_tys(\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<Vec<crate::ids::ConcreteTypeId>, SpecializationError> {\n        Ok(vec![felt252_span_ty(context)?])\n    }\n}\n\n/// Libfunc for sending message to l1 system call.\n#[derive(Default)]\npub struct SendMessageToL1Libfunc {}\nimpl SyscallGenericLibfunc for SendMessageToL1Libfunc {\n    const STR_ID: &'static str = \"send_message_to_l1_syscall\";\n\n    fn input_tys(\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<Vec<crate::ids::ConcreteTypeId>, SpecializationError> {\n        Ok(vec![\n            // Address\n            context.get_concrete_type(Felt252Type::id(), &[])?,\n            // Payload\n            felt252_span_ty(context)?,\n        ])\n    }\n\n    fn success_output_tys(\n        _context: &dyn SignatureSpecializationContext,\n    ) -> Result<Vec<crate::ids::ConcreteTypeId>, SpecializationError> {\n        Ok(vec![])\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use crate::extensions::lib_func::SignatureSpecializationContext;\nuse crate::extensions::{NamedType, SpecializationError};\nuse crate::ids::{ConcreteTypeId, UserTypeId};\nuse crate::program::GenericArg;\nuse crate::{define_libfunc_hierarchy, define_type_hierarchy};\n\npub mod storage;\nuse storage::{\n    StorageAddressToFelt252Libfunc, StorageBaseAddressConstLibfunc, StorageBaseAddressType,\n    StorageReadLibfunc, StorageWriteLibfunc,\n};\n\npub mod syscalls;\nuse syscalls::{ReplaceClassLibfunc, SystemType};\n\npub mod getter;\n\npub mod emit_event;\nuse emit_event::EmitEventLibfunc;\npub mod testing;\n\npub mod interoperability;\nuse interoperability::{CallContractLibfunc, ContractAddressConstLibfunc, ContractAddressType};\n\nuse self::getter::{GetExecutionInfoTrait, GetterLibfunc};\nuse self::interoperability::{\n    ClassHashConstLibfunc, ClassHashToFelt252Libfunc, ClassHashTryFromFelt252Trait, ClassHashType,\n    ContractAddressToFelt252Libfunc, ContractAddressTryFromFelt252Libfunc, DeployLibfunc,\n    LibraryCallLibfunc, SendMessageToL1Libfunc,\n};\nuse self::storage::{\n    StorageAddressFromBaseAndOffsetLibfunc, StorageAddressFromBaseLibfunc,\n    StorageAddressTryFromFelt252Trait, StorageAddressType, StorageBaseAddressFromFelt252Libfunc,\n};\nuse self::testing::TestingLibfunc;\nuse super::array::ArrayType;\nuse super::felt252::Felt252Type;\nuse super::snapshot::snapshot_ty;\nuse super::structure::StructType;\nuse super::try_from_felt252::TryFromFelt252Libfunc;\n\ndefine_type_hierarchy! {\n    pub enum StarkNetType {\n        ClassHash(ClassHashType),\n        ContractAddress(ContractAddressType),\n        StorageBaseAddress(StorageBaseAddressType),\n        StorageAddress(StorageAddressType),\n        System(SystemType),\n    }, StarkNetTypeConcrete\n}\n\ndefine_libfunc_hierarchy! {\n    pub enum StarkNetLibfunc {\n         CallContract(CallContractLibfunc),\n         ClassHashConst(ClassHashConstLibfunc),\n         ClassHashTryFromFelt252(TryFromFelt252Libfunc<ClassHashTryFromFelt252Trait>),\n         ClassHashToFelt252(ClassHashToFelt252Libfunc),\n         ContractAddressConst(ContractAddressConstLibfunc),\n         ContractAddressTryFromFelt252(TryFromFelt252Libfunc<ContractAddressTryFromFelt252Libfunc>),\n         ContractAddressToFelt252(ContractAddressToFelt252Libfunc),\n         StorageRead(StorageReadLibfunc),\n         StorageWrite(StorageWriteLibfunc),\n         StorageBaseAddressConst(StorageBaseAddressConstLibfunc),\n         StorageBaseAddressFromFelt252(StorageBaseAddressFromFelt252Libfunc),\n         StorageAddressFromBase(StorageAddressFromBaseLibfunc),\n         StorageAddressFromBaseAndOffset(StorageAddressFromBaseAndOffsetLibfunc),\n         StorageAddressToFelt252(StorageAddressToFelt252Libfunc),\n         StorageAddressTryFromFelt252(TryFromFelt252Libfunc<StorageAddressTryFromFelt252Trait>),\n         EmitEvent(EmitEventLibfunc),\n         GetExecutionInfo(GetterLibfunc<GetExecutionInfoTrait>),\n         Deploy(DeployLibfunc),\n         LibraryCall(LibraryCallLibfunc),\n         ReplaceClass(ReplaceClassLibfunc),\n         SendMessageToL1(SendMessageToL1Libfunc),\n         Testing(TestingLibfunc),\n    }, StarkNetConcreteLibfunc\n}\n\n/// User type for `Span<felt252>`.\nfn felt252_span_ty(\n    context: &dyn SignatureSpecializationContext,\n) -> Result<ConcreteTypeId, SpecializationError> {\n    let felt252_array_ty = context.get_wrapped_concrete_type(\n        ArrayType::id(),\n        context.get_concrete_type(Felt252Type::id(), &[])?,\n    )?;\n    context.get_concrete_type(\n        StructType::id(),\n        &[\n            GenericArg::UserType(UserTypeId::from_string(\"core::array::Span::<core::felt252>\")),\n            GenericArg::Type(snapshot_ty(context, felt252_array_ty)?),\n        ],\n    )\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use super::syscalls::SyscallGenericLibfunc;\nuse crate::extensions::consts::{ConstGenLibfunc, WrapConstGenLibfunc};\nuse crate::extensions::felt252::Felt252Type;\nuse crate::extensions::lib_func::{\n    DeferredOutputKind, LibfuncSignature, OutputVarInfo, ParamSignature, SierraApChange,\n    SignatureSpecializationContext,\n};\nuse crate::extensions::range_check::RangeCheckType;\nuse crate::extensions::try_from_felt252::TryFromFelt252;\nuse crate::extensions::uint::{Uint32Type, Uint8Type};\nuse crate::extensions::{\n    NamedType, NoGenericArgsGenericLibfunc, NoGenericArgsGenericType, OutputVarReferenceInfo,\n    SpecializationError,\n};\nuse crate::ids::GenericTypeId;\n\n/// Type for Starknet storage base address, a value in the range [0, 2 ** 251 - 256).\n#[derive(Default)]\npub struct StorageBaseAddressType {}\nimpl NoGenericArgsGenericType for StorageBaseAddressType {\n    const ID: GenericTypeId = GenericTypeId::new_inline(\"StorageBaseAddress\");\n    const STORABLE: bool = true;\n    const DUPLICATABLE: bool = true;\n    const DROPPABLE: bool = true;\n    const SIZE: i16 = 1;\n}\n\n/// Libfunc for creating a constant storage base address.\n#[derive(Default)]\npub struct StorageBaseAddressConstLibfuncWrapped {}\nimpl ConstGenLibfunc for StorageBaseAddressConstLibfuncWrapped {\n    const STR_ID: &'static str = (\"storage_base_address_const\");\n    const GENERIC_TYPE_ID: GenericTypeId = <StorageBaseAddressType as NoGenericArgsGenericType>::ID;\n}\n\npub type StorageBaseAddressConstLibfunc =\n    WrapConstGenLibfunc<StorageBaseAddressConstLibfuncWrapped>;\n\n/// Type for Starknet storage base address, a value in the range [0, 2 ** 251).\n#[derive(Default)]\npub struct StorageAddressType {}\nimpl NoGenericArgsGenericType for StorageAddressType {\n    const ID: GenericTypeId = GenericTypeId::new_inline(\"StorageAddress\");\n    const STORABLE: bool = true;\n    const DUPLICATABLE: bool = true;\n    const DROPPABLE: bool = true;\n    const SIZE: i16 = 1;\n}\n\n/// Libfunc for converting a StorageAddress into a felt252.\n#[derive(Default)]\npub struct StorageAddressToFelt252Libfunc {}\nimpl NoGenericArgsGenericLibfunc for StorageAddressToFelt252Libfunc {\n    const STR_ID: &'static str = \"storage_address_to_felt252\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        Ok(LibfuncSignature::new_non_branch_ex(\n            vec![ParamSignature {\n                ty: context.get_concrete_type(StorageAddressType::id(), &[])?,\n                allow_deferred: true,\n                allow_add_const: true,\n                allow_const: true,\n            }],\n            vec![OutputVarInfo {\n                ty: context.get_concrete_type(Felt252Type::id(), &[])?,\n                ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 0 },\n            }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n\n/// Libfunc for attempting to convert a felt252 into a storage address.\n#[derive(Default)]\npub struct StorageAddressTryFromFelt252Trait;\nimpl TryFromFelt252 for StorageAddressTryFromFelt252Trait {\n    const STR_ID: &'static str = \"storage_address_try_from_felt252\";\n    const GENERIC_TYPE_ID: GenericTypeId = <StorageAddressType as NoGenericArgsGenericType>::ID;\n}\n\n/// Libfunc for converting a base address into a storage address.\n#[derive(Default)]\npub struct StorageAddressFromBaseLibfunc {}\nimpl NoGenericArgsGenericLibfunc for StorageAddressFromBaseLibfunc {\n    const STR_ID: &'static str = \"storage_address_from_base\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        Ok(LibfuncSignature::new_non_branch_ex(\n            vec![ParamSignature {\n                ty: context.get_concrete_type(StorageBaseAddressType::id(), &[])?,\n                allow_deferred: true,\n                allow_add_const: true,\n                allow_const: true,\n            }],\n            vec![OutputVarInfo {\n                ty: context.get_concrete_type(StorageAddressType::id(), &[])?,\n                ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 0 },\n            }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n\n/// Libfunc for converting a base address and offset into a storage address.\n#[derive(Default)]\npub struct StorageAddressFromBaseAndOffsetLibfunc {}\nimpl NoGenericArgsGenericLibfunc for StorageAddressFromBaseAndOffsetLibfunc {\n    const STR_ID: &'static str = \"storage_address_from_base_and_offset\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        Ok(LibfuncSignature::new_non_branch_ex(\n            vec![\n                ParamSignature::new(context.get_concrete_type(StorageBaseAddressType::id(), &[])?),\n                ParamSignature {\n                    ty: context.get_concrete_type(Uint8Type::id(), &[])?,\n                    allow_deferred: false,\n                    allow_add_const: false,\n                    allow_const: true,\n                },\n            ],\n            vec![OutputVarInfo {\n                ty: context.get_concrete_type(StorageAddressType::id(), &[])?,\n                ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n            }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n\n/// Libfunc for converting a felt252 into a storage base address.\n#[derive(Default)]\npub struct StorageBaseAddressFromFelt252Libfunc {}\nimpl NoGenericArgsGenericLibfunc for StorageBaseAddressFromFelt252Libfunc {\n    const STR_ID: &'static str = \"storage_base_address_from_felt252\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let range_check_ty = context.get_concrete_type(RangeCheckType::id(), &[])?;\n        Ok(LibfuncSignature::new_non_branch_ex(\n            vec![\n                ParamSignature {\n                    ty: range_check_ty.clone(),\n                    allow_deferred: false,\n                    allow_add_const: true,\n                    allow_const: false,\n                },\n                ParamSignature::new(context.get_concrete_type(Felt252Type::id(), &[])?),\n            ],\n            vec![\n                OutputVarInfo {\n                    ty: range_check_ty,\n                    ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::AddConst {\n                        param_idx: 0,\n                    }),\n                },\n                OutputVarInfo {\n                    ty: context.get_concrete_type(StorageBaseAddressType::id(), &[])?,\n                    ref_info: OutputVarReferenceInfo::NewTempVar { idx: Some(0) },\n                },\n            ],\n            SierraApChange::Known { new_vars_only: false },\n        ))\n    }\n}\n\n/// Libfunc for a storage read system call.\n#[derive(Default)]\npub struct StorageReadLibfunc {}\nimpl SyscallGenericLibfunc for StorageReadLibfunc {\n    const STR_ID: &'static str = \"storage_read_syscall\";\n\n    fn input_tys(\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<Vec<crate::ids::ConcreteTypeId>, SpecializationError> {\n        Ok(vec![\n            // Address domain.\n            context.get_concrete_type(Uint32Type::id(), &[])?,\n            // Storage key.\n            context.get_concrete_type(StorageAddressType::id(), &[])?,\n        ])\n    }\n\n    fn success_output_tys(\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<Vec<crate::ids::ConcreteTypeId>, SpecializationError> {\n        Ok(vec![context.get_concrete_type(Felt252Type::id(), &[])?])\n    }\n}\n\n/// Libfunc for a storage write system call.\n#[derive(Default)]\npub struct StorageWriteLibfunc {}\nimpl SyscallGenericLibfunc for StorageWriteLibfunc {\n    const STR_ID: &'static str = \"storage_write_syscall\";\n\n    fn input_tys(\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<Vec<crate::ids::ConcreteTypeId>, SpecializationError> {\n        Ok(vec![\n            // Address domain\n            context.get_concrete_type(Uint32Type::id(), &[])?,\n            // Storage key\n            context.get_concrete_type(StorageAddressType::id(), &[])?,\n            // Value\n            context.get_concrete_type(Felt252Type::id(), &[])?,\n        ])\n    }\n\n    fn success_output_tys(\n        _context: &dyn SignatureSpecializationContext,\n    ) -> Result<Vec<crate::ids::ConcreteTypeId>, SpecializationError> {\n        Ok(vec![])\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use itertools::chain;\n\nuse super::interoperability::ClassHashType;\nuse crate::extensions::array::ArrayType;\nuse crate::extensions::felt252::Felt252Type;\nuse crate::extensions::gas::GasBuiltinType;\nuse crate::extensions::lib_func::{\n    BranchSignature, DeferredOutputKind, LibfuncSignature, OutputVarInfo, ParamSignature,\n    SierraApChange, SignatureSpecializationContext,\n};\nuse crate::extensions::{\n    NamedType, NoGenericArgsGenericLibfunc, NoGenericArgsGenericType, OutputVarReferenceInfo,\n    SpecializationError,\n};\nuse crate::ids::{ConcreteTypeId, GenericTypeId};\n\n/// Type for Starknet system object.\n/// Used to make system calls.\n#[derive(Default)]\npub struct SystemType {}\nimpl NoGenericArgsGenericType for SystemType {\n    const ID: GenericTypeId = GenericTypeId::new_inline(\"System\");\n    const STORABLE: bool = true;\n    const DUPLICATABLE: bool = false;\n    const DROPPABLE: bool = false;\n    const SIZE: i16 = 1;\n}\n\n/// Trait for implementing a library function for syscalls.\npub trait SyscallGenericLibfunc: Default {\n    /// The library function id.\n    const STR_ID: &'static str;\n    /// The non implicits inputs for the libfunc.\n    fn input_tys(\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<Vec<ConcreteTypeId>, SpecializationError>;\n    /// The success case non implicits outputs of the libfunc.\n    fn success_output_tys(\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<Vec<ConcreteTypeId>, SpecializationError>;\n}\n\nimpl<T: SyscallGenericLibfunc> NoGenericArgsGenericLibfunc for T {\n    const STR_ID: &'static str = T::STR_ID;\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let gas_builtin_ty = context.get_concrete_type(GasBuiltinType::id(), &[])?;\n        let system_ty = context.get_concrete_type(SystemType::id(), &[])?;\n        let felt252_ty = context.get_concrete_type(Felt252Type::id(), &[])?;\n        let felt252_array_ty = context.get_wrapped_concrete_type(ArrayType::id(), felt252_ty)?;\n\n        Ok(LibfuncSignature {\n            param_signatures: chain!(\n                [\n                    // Gas builtin\n                    ParamSignature::new(gas_builtin_ty.clone()),\n                    // System\n                    ParamSignature {\n                        ty: system_ty.clone(),\n                        allow_deferred: false,\n                        allow_add_const: true,\n                        allow_const: false,\n                    }\n                ],\n                T::input_tys(context)?.into_iter().map(ParamSignature::new)\n            )\n            .collect(),\n            branch_signatures: vec![\n                // Success branch.\n                BranchSignature {\n                    vars: chain!(\n                        [\n                            // Gas builtin\n                            OutputVarInfo {\n                                ty: gas_builtin_ty.clone(),\n                                ref_info: OutputVarReferenceInfo::Deferred(\n                                    DeferredOutputKind::Generic\n                                ),\n                            },\n                            // System\n                            OutputVarInfo {\n                                ty: system_ty.clone(),\n                                ref_info: OutputVarReferenceInfo::Deferred(\n                                    DeferredOutputKind::AddConst { param_idx: 1 },\n                                ),\n                            }\n                        ],\n                        T::success_output_tys(context)?.into_iter().map(|ty| OutputVarInfo {\n                            ty,\n                            ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n                        })\n                    )\n                    .collect(),\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n                // Failure branch.\n                BranchSignature {\n                    vars: vec![\n                        // Gas builtin\n                        OutputVarInfo {\n                            ty: gas_builtin_ty,\n                            ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n                        },\n                        // System\n                        OutputVarInfo {\n                            ty: system_ty,\n                            ref_info: OutputVarReferenceInfo::Deferred(\n                                DeferredOutputKind::AddConst { param_idx: 1 },\n                            ),\n                        },\n                        // Revert reason\n                        OutputVarInfo {\n                            ty: felt252_array_ty,\n                            ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n                        },\n                    ],\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n            ],\n            fallthrough: Some(0),\n        })\n    }\n}\n\n/// Libfunc for the replace_class system call.\n#[derive(Default)]\npub struct ReplaceClassLibfunc {}\nimpl SyscallGenericLibfunc for ReplaceClassLibfunc {\n    const STR_ID: &'static str = \"replace_class_syscall\";\n\n    fn input_tys(\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<Vec<crate::ids::ConcreteTypeId>, SpecializationError> {\n        let class_hash_ty = context.get_concrete_type(ClassHashType::id(), &[])?;\n        Ok(vec![\n            // class_hash\n            class_hash_ty,\n        ])\n    }\n\n    fn success_output_tys(\n        _context: &dyn SignatureSpecializationContext,\n    ) -> Result<Vec<crate::ids::ConcreteTypeId>, SpecializationError> {\n        Ok(vec![])\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::marker::PhantomData;\n\nuse super::interoperability::ContractAddressType;\nuse crate::define_libfunc_hierarchy;\nuse crate::extensions::lib_func::{\n    LibfuncSignature, SierraApChange, SignatureSpecializationContext,\n};\nuse crate::extensions::uint::Uint64Type;\nuse crate::extensions::{\n    NamedType, NoGenericArgsGenericLibfunc, NoGenericArgsGenericType, SpecializationError,\n};\nuse crate::ids::ConcreteTypeId;\n\n/// Trait for implementing test setters.\npub trait TestSetterTraits: Default {\n    /// The generic libfunc id for the setter libfunc.\n    const STR_ID: &'static str;\n    /// The simple sierra generic type as the setter's value.\n    type ValueType: NoGenericArgsGenericType;\n}\n\n/// Same as GetterTraits, but with a function to return the concrete TypeId.\npub trait TestSetterTraitsEx: Default {\n    /// The generic libfunc id for the setter libfunc.\n    const STR_ID: &'static str;\n    /// The value type for the setter.\n    fn value_type_id(\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<ConcreteTypeId, SpecializationError>;\n}\n\nimpl<TTestSetterTraits: TestSetterTraits> TestSetterTraitsEx for TTestSetterTraits {\n    const STR_ID: &'static str = TTestSetterTraits::STR_ID;\n\n    fn value_type_id(\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<ConcreteTypeId, SpecializationError> {\n        context.get_concrete_type(TTestSetterTraits::ValueType::id(), &[])\n    }\n}\n\n/// Libfunc for a test setter.\n#[derive(Default)]\npub struct TestSetterLibfunc<TTestSetterTraitsEx: TestSetterTraitsEx> {\n    _phantom: PhantomData<TTestSetterTraitsEx>,\n}\nimpl<TTestSetterTraitsEx: TestSetterTraitsEx> NoGenericArgsGenericLibfunc\n    for TestSetterLibfunc<TTestSetterTraitsEx>\n{\n    const STR_ID: &'static str = TTestSetterTraitsEx::STR_ID;\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        Ok(LibfuncSignature::new_non_branch(\n            vec![TTestSetterTraitsEx::value_type_id(context)?],\n            vec![],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n\n#[derive(Default)]\npub struct SetBlockNumberTrait {}\nimpl TestSetterTraits for SetBlockNumberTrait {\n    const STR_ID: &'static str = \"set_block_number\";\n    type ValueType = Uint64Type;\n}\n\n#[derive(Default)]\npub struct SetBlockTimestampTrait {}\nimpl TestSetterTraits for SetBlockTimestampTrait {\n    const STR_ID: &'static str = \"set_block_timestamp\";\n    type ValueType = Uint64Type;\n}\n\n#[derive(Default)]\npub struct SetCallerAddressTrait {}\nimpl TestSetterTraits for SetCallerAddressTrait {\n    const STR_ID: &'static str = \"set_caller_address\";\n    type ValueType = ContractAddressType;\n}\n\n#[derive(Default)]\npub struct SetContractAddressTrait {}\nimpl TestSetterTraits for SetContractAddressTrait {\n    const STR_ID: &'static str = \"set_contract_address\";\n    type ValueType = ContractAddressType;\n}\n\n#[derive(Default)]\npub struct SetSequencerAddressTrait {}\nimpl TestSetterTraits for SetSequencerAddressTrait {\n    const STR_ID: &'static str = \"set_sequencer_address\";\n    type ValueType = ContractAddressType;\n}\n\ndefine_libfunc_hierarchy! {\n    pub enum TestingLibfunc {\n         SetBlockNumber(TestSetterLibfunc<SetBlockNumberTrait>),\n         SetBlockTimestamp(TestSetterLibfunc<SetBlockTimestampTrait>),\n         SetCallerAddress(TestSetterLibfunc<SetCallerAddressTrait>),\n         SetContractAddress(TestSetterLibfunc<SetContractAddressTrait>),\n         SetSequencerAddress(TestSetterLibfunc<SetSequencerAddressTrait>),\n    }, TestingConcreteLibfunc\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Sierra example:\n//! ```ignore\n//! type felt252 = felt252;\n//! type Tuple<felt252, felt252> = Struct<ut@Tuple, felt252, felt252>;\n//! libfunc tuple_construct = struct_construct<Tuple<felt252, felt252>>;\n//! libfunc tuple_deconstruct = struct_deconstruct<Tuple<felt252, felt252>>;\n//! ...\n//! felt252_const<0>() -> (felt0);\n//! felt252_const<1>() -> (felt1);\n//! tuple_construct(felt0, felt1) -> (tup);\n//! tuple_deconstruct(tup) -> (felt0, felt1);\n//! ```\n\nuse cairo_lang_utils::try_extract_matches;\n\nuse super::snapshot::snapshot_ty;\nuse crate::define_libfunc_hierarchy;\nuse crate::extensions::lib_func::{\n    DeferredOutputKind, LibfuncSignature, OutputVarInfo, ParamSignature, SierraApChange,\n    SignatureOnlyGenericLibfunc, SignatureSpecializationContext,\n};\nuse crate::extensions::type_specialization_context::TypeSpecializationContext;\nuse crate::extensions::types::TypeInfo;\nuse crate::extensions::{\n    args_as_single_type, ConcreteType, NamedType, OutputVarReferenceInfo, SpecializationError,\n};\nuse crate::ids::{ConcreteTypeId, GenericTypeId};\nuse crate::program::{ConcreteTypeLongId, GenericArg};\n\n/// Type representing a struct.\n#[derive(Default)]\npub struct StructType {}\nimpl NamedType for StructType {\n    type Concrete = StructConcreteType;\n    const ID: GenericTypeId = GenericTypeId::new_inline(\"Struct\");\n\n    fn specialize(\n        &self,\n        context: &dyn TypeSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<Self::Concrete, SpecializationError> {\n        Self::Concrete::new(context, args)\n    }\n}\n\npub struct StructConcreteType {\n    pub info: TypeInfo,\n    pub members: Vec<ConcreteTypeId>,\n}\nimpl StructConcreteType {\n    fn new(\n        context: &dyn TypeSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<Self, SpecializationError> {\n        let mut args_iter = args.iter();\n        args_iter\n            .next()\n            .and_then(|arg| try_extract_matches!(arg, GenericArg::UserType))\n            .ok_or(SpecializationError::UnsupportedGenericArg)?;\n        let mut duplicatable = true;\n        let mut droppable = true;\n        let mut members: Vec<ConcreteTypeId> = Vec::new();\n        let mut size = 0;\n        for arg in args_iter {\n            let ty = try_extract_matches!(arg, GenericArg::Type)\n                .ok_or(SpecializationError::UnsupportedGenericArg)?\n                .clone();\n            let info = context.get_type_info(ty.clone())?;\n            if !info.storable {\n                return Err(SpecializationError::UnsupportedGenericArg);\n            }\n            if !info.duplicatable {\n                duplicatable = false;\n            }\n            if !info.droppable {\n                droppable = false;\n            }\n            size += info.size;\n            members.push(ty);\n        }\n        Ok(StructConcreteType {\n            info: TypeInfo {\n                long_id: ConcreteTypeLongId {\n                    generic_id: \"Struct\".into(),\n                    generic_args: args.to_vec(),\n                },\n                duplicatable,\n                droppable,\n                storable: true,\n                size,\n            },\n            members,\n        })\n    }\n}\nimpl ConcreteType for StructConcreteType {\n    fn info(&self) -> &TypeInfo {\n        &self.info\n    }\n}\n\ndefine_libfunc_hierarchy! {\n    pub enum StructLibfunc {\n        Construct(StructConstructLibfunc),\n        Deconstruct(StructDeconstructLibfunc),\n        SnapshotDeconstruct(StructSnapshotDeconstructLibfunc),\n    }, StructConcreteLibfunc\n}\n\n/// Libfunc for constructing a struct.\n#[derive(Default)]\npub struct StructConstructLibfunc {}\nimpl SignatureOnlyGenericLibfunc for StructConstructLibfunc {\n    const STR_ID: &'static str = \"struct_construct\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let struct_type = args_as_single_type(args)?;\n        let generic_args = context.get_type_info(struct_type.clone())?.long_id.generic_args;\n        let member_types =\n            StructConcreteType::new(context.as_type_specialization_context(), &generic_args)?\n                .members;\n        Ok(LibfuncSignature::new_non_branch_ex(\n            member_types\n                .into_iter()\n                .map(|ty| ParamSignature {\n                    ty,\n                    allow_deferred: true,\n                    allow_add_const: true,\n                    allow_const: true,\n                })\n                .collect(),\n            vec![OutputVarInfo {\n                ty: struct_type,\n                ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n            }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n\n/// Libfunc for deconstructing a struct.\n#[derive(Default)]\npub struct StructDeconstructLibfunc {}\nimpl SignatureOnlyGenericLibfunc for StructDeconstructLibfunc {\n    const STR_ID: &'static str = \"struct_deconstruct\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let struct_type = args_as_single_type(args)?;\n        let generic_args = context.get_type_info(struct_type.clone())?.long_id.generic_args;\n        let member_types =\n            StructConcreteType::new(context.as_type_specialization_context(), &generic_args)?\n                .members;\n        Ok(LibfuncSignature::new_non_branch_ex(\n            vec![ParamSignature {\n                ty: struct_type,\n                allow_deferred: true,\n                allow_add_const: false,\n                allow_const: true,\n            }],\n            member_types\n                .into_iter()\n                .map(|ty| OutputVarInfo {\n                    ty,\n                    // All memory of the deconstruction would have the same lifetime as the first\n                    // param - as it is its deconstruction.\n                    ref_info: OutputVarReferenceInfo::PartialParam { param_idx: 0 },\n                })\n                .collect(),\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n\n/// Libfunc for deconstructing a struct snapshot.\n#[derive(Default)]\npub struct StructSnapshotDeconstructLibfunc {}\nimpl SignatureOnlyGenericLibfunc for StructSnapshotDeconstructLibfunc {\n    const STR_ID: &'static str = \"struct_snapshot_deconstruct\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let struct_type = args_as_single_type(args)?;\n        let generic_args = context.get_type_info(struct_type.clone())?.long_id.generic_args;\n        let member_types =\n            StructConcreteType::new(context.as_type_specialization_context(), &generic_args)?\n                .members;\n        Ok(LibfuncSignature::new_non_branch(\n            vec![snapshot_ty(context, struct_type)?],\n            member_types\n                .into_iter()\n                .map(|ty| {\n                    Ok(OutputVarInfo {\n                        ty: snapshot_ty(context, ty)?,\n                        // All memory of the deconstruction would have the same lifetime as the\n                        // first param - as it is its deconstruction.\n                        ref_info: OutputVarReferenceInfo::PartialParam { param_idx: 0 },\n                    })\n                })\n                .collect::<Result<Vec<_>, _>>()?,\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::marker::PhantomData;\n\nuse super::felt252::Felt252Type;\nuse super::range_check::RangeCheckType;\nuse crate::extensions::lib_func::{\n    BranchSignature, DeferredOutputKind, LibfuncSignature, OutputVarInfo, ParamSignature,\n    SierraApChange, SignatureSpecializationContext,\n};\nuse crate::extensions::{\n    NamedType, NoGenericArgsGenericLibfunc, OutputVarReferenceInfo, SpecializationError,\n};\nuse crate::ids::GenericTypeId;\n\n/// Trait for implementing try_{ty}_from_felt252.\npub trait TryFromFelt252: Default {\n    /// The try_{ty}_from_felt252 library function id.\n    const STR_ID: &'static str;\n    /// The id of the generic type to implement the library functions for.\n    const GENERIC_TYPE_ID: GenericTypeId;\n}\n/// Libfunc for attempting to convert a felt252 into a uint.\n#[derive(Default)]\npub struct TryFromFelt252Libfunc<TTryFromFelt252: TryFromFelt252> {\n    _phantom: PhantomData<TTryFromFelt252>,\n}\nimpl<TTryFromFelt252: TryFromFelt252> NoGenericArgsGenericLibfunc\n    for TryFromFelt252Libfunc<TTryFromFelt252>\n{\n    const STR_ID: &'static str = TTryFromFelt252::STR_ID;\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let range_check_type = context.get_concrete_type(RangeCheckType::id(), &[])?;\n        Ok(LibfuncSignature {\n            param_signatures: vec![\n                ParamSignature {\n                    ty: range_check_type.clone(),\n                    allow_deferred: false,\n                    allow_add_const: true,\n                    allow_const: false,\n                },\n                ParamSignature::new(context.get_concrete_type(Felt252Type::id(), &[])?),\n            ],\n            branch_signatures: vec![\n                BranchSignature {\n                    vars: vec![\n                        OutputVarInfo {\n                            ty: range_check_type.clone(),\n                            ref_info: OutputVarReferenceInfo::Deferred(\n                                DeferredOutputKind::AddConst { param_idx: 0 },\n                            ),\n                        },\n                        OutputVarInfo {\n                            ty: context.get_concrete_type(TTryFromFelt252::GENERIC_TYPE_ID, &[])?,\n                            ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 1 },\n                        },\n                    ],\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n                BranchSignature {\n                    vars: vec![OutputVarInfo {\n                        ty: range_check_type,\n                        ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::AddConst {\n                            param_idx: 0,\n                        }),\n                    }],\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n            ],\n            fallthrough: Some(0),\n        })\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::marker::PhantomData;\n\nuse num_bigint::BigInt;\n\nuse super::felt252::Felt252Type;\nuse super::is_zero::{IsZeroLibfunc, IsZeroTraits};\nuse super::non_zero::nonzero_ty;\nuse super::range_check::RangeCheckType;\nuse super::try_from_felt252::{TryFromFelt252, TryFromFelt252Libfunc};\nuse super::uint128::Uint128Type;\nuse crate::define_libfunc_hierarchy;\nuse crate::extensions::lib_func::{\n    BranchSignature, DeferredOutputKind, LibfuncSignature, OutputVarInfo, ParamSignature,\n    SierraApChange, SignatureSpecializationContext, SpecializationContext,\n};\nuse crate::extensions::{\n    GenericLibfunc, NamedLibfunc, NamedType, NoGenericArgsGenericLibfunc, NoGenericArgsGenericType,\n    OutputVarReferenceInfo, SignatureBasedConcreteLibfunc, SpecializationError,\n};\nuse crate::ids::{GenericLibfuncId, GenericTypeId};\nuse crate::program::GenericArg;\n\n/// Operators for integers.\n#[derive(Copy, Clone, Debug, PartialEq, Eq)]\npub enum IntOperator {\n    OverflowingAdd,\n    OverflowingSub,\n}\n\n/// Trait for implementing unsigned integers.\npub trait UintTraits: Default {\n    /// The rust matching type to this type.\n    type UintType: TryFrom<BigInt> + Into<BigInt> + Copy;\n    /// Is the type smaller than 128 bits.\n    /// Relevant since some implementations are different due to range check being 128 bits based.\n    const IS_SMALL: bool;\n    /// The generic type id for this type.\n    const GENERIC_TYPE_ID: GenericTypeId;\n    /// The generic libfunc id for getting a const of this type.\n    const CONST: &'static str;\n    /// The generic libfunc id for comparing equality.\n    const EQUAL: &'static str;\n    /// The generic libfunc id for calculating the integer square root.\n    const SQUARE_ROOT: &'static str;\n    /// The generic libfunc id for testing if less than.\n    const LESS_THAN: &'static str;\n    /// The generic libfunc id for testing if less than or equal.\n    const LESS_THAN_OR_EQUAL: &'static str;\n    /// The generic libfunc id for addition.\n    const OVERFLOWING_ADD: &'static str;\n    /// The generic libfunc id for subtraction.\n    const OVERFLOWING_SUB: &'static str;\n    /// The generic libfunc id for conversion to felt252.\n    const TO_FELT252: &'static str;\n    /// The generic libfunc id for conversion from felt252.\n    const TRY_FROM_FELT252: &'static str;\n    /// The generic libfunc id that divides two integers.\n    const DIVMOD: &'static str;\n}\n\n/// Trait for implementing multiplication for unsigned integers.\npub trait UintMulTraits: UintTraits {\n    /// The generic libfunc id that multiplies two integers.\n    const WIDE_MUL: &'static str;\n    /// The generic type id for this type multiplication result.\n    const WIDE_MUL_RES_TYPE_ID: GenericTypeId;\n}\n\n#[derive(Default)]\npub struct UintType<TUintTraits: UintTraits> {\n    _phantom: PhantomData<TUintTraits>,\n}\nimpl<TUintTraits: UintTraits> NoGenericArgsGenericType for UintType<TUintTraits> {\n    const ID: GenericTypeId = TUintTraits::GENERIC_TYPE_ID;\n    const STORABLE: bool = true;\n    const DUPLICATABLE: bool = true;\n    const DROPPABLE: bool = true;\n    const SIZE: i16 = 1;\n}\n\n/// Libfunc for creating a constant unsigned integer.\n#[derive(Default)]\npub struct UintConstLibfunc<TUintTraits: UintTraits> {\n    _phantom: PhantomData<TUintTraits>,\n}\nimpl<TUintTraits: UintTraits> NamedLibfunc for UintConstLibfunc<TUintTraits> {\n    const STR_ID: &'static str = TUintTraits::CONST;\n    type Concrete = UintConstConcreteLibfunc<TUintTraits>;\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        _args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        Ok(LibfuncSignature::new_non_branch(\n            vec![],\n            vec![OutputVarInfo {\n                ty: context.get_concrete_type(TUintTraits::GENERIC_TYPE_ID, &[])?,\n                ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Const),\n            }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n\n    fn specialize(\n        &self,\n        context: &dyn SpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<Self::Concrete, SpecializationError> {\n        match args {\n            [GenericArg::Value(c)] => Ok(Self::Concrete {\n                c: TUintTraits::UintType::try_from(c.clone())\n                    .map_err(|_| SpecializationError::UnsupportedGenericArg)?,\n                signature: <Self as NamedLibfunc>::specialize_signature(\n                    self,\n                    context.upcast(),\n                    args,\n                )?,\n            }),\n            _ => Err(SpecializationError::UnsupportedGenericArg),\n        }\n    }\n}\n\npub struct UintConstConcreteLibfunc<TUintTraits: UintTraits> {\n    pub c: TUintTraits::UintType,\n    pub signature: LibfuncSignature,\n}\nimpl<TUintTraits: UintTraits> SignatureBasedConcreteLibfunc\n    for UintConstConcreteLibfunc<TUintTraits>\n{\n    fn signature(&self) -> &LibfuncSignature {\n        &self.signature\n    }\n}\n\n/// Libfunc for comparing uints` equality.\n#[derive(Default)]\npub struct UintEqualLibfunc<TUintTraits: UintTraits> {\n    _phantom: PhantomData<TUintTraits>,\n}\nimpl<TUintTraits: UintTraits> NoGenericArgsGenericLibfunc for UintEqualLibfunc<TUintTraits> {\n    const STR_ID: &'static str = TUintTraits::EQUAL;\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let ty = context.get_concrete_type(TUintTraits::GENERIC_TYPE_ID, &[])?;\n        let param_signatures = vec![\n            ParamSignature {\n                ty: ty.clone(),\n                allow_deferred: false,\n                allow_add_const: false,\n                allow_const: true,\n            },\n            ParamSignature { ty, allow_deferred: false, allow_add_const: false, allow_const: true },\n        ];\n        let branch_signatures = (0..2)\n            .map(|_| BranchSignature {\n                vars: vec![],\n                ap_change: SierraApChange::Known { new_vars_only: false },\n            })\n            .collect();\n        Ok(LibfuncSignature { param_signatures, branch_signatures, fallthrough: Some(0) })\n    }\n}\n\n/// Libfunc for calculating uint's square root.\n#[derive(Default)]\npub struct UintSquareRootLibfunc<TUintTraits: UintTraits> {\n    _phantom: PhantomData<TUintTraits>,\n}\nimpl<TUintTraits: UintTraits> NoGenericArgsGenericLibfunc for UintSquareRootLibfunc<TUintTraits> {\n    const STR_ID: &'static str = TUintTraits::SQUARE_ROOT;\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let ty = context.get_concrete_type(TUintTraits::GENERIC_TYPE_ID, &[])?;\n        let range_check_type = context.get_concrete_type(RangeCheckType::id(), &[])?;\n        Ok(LibfuncSignature::new_non_branch_ex(\n            vec![\n                ParamSignature {\n                    ty: range_check_type.clone(),\n                    allow_deferred: false,\n                    allow_add_const: true,\n                    allow_const: false,\n                },\n                ParamSignature::new(ty.clone()),\n            ],\n            vec![\n                OutputVarInfo {\n                    ty: range_check_type,\n                    ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::AddConst {\n                        param_idx: 0,\n                    }),\n                },\n                OutputVarInfo { ty, ref_info: OutputVarReferenceInfo::NewTempVar { idx: Some(0) } },\n            ],\n            SierraApChange::Known { new_vars_only: false },\n        ))\n    }\n}\n\n/// Libfunc for comparing uints.\n#[derive(Default)]\npub struct UintLessThanLibfunc<TUintTraits: UintTraits> {\n    _phantom: PhantomData<TUintTraits>,\n}\nimpl<TUintTraits: UintTraits> NoGenericArgsGenericLibfunc for UintLessThanLibfunc<TUintTraits> {\n    const STR_ID: &'static str = TUintTraits::LESS_THAN;\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let ty = context.get_concrete_type(TUintTraits::GENERIC_TYPE_ID, &[])?;\n        let range_check_type = context.get_concrete_type(RangeCheckType::id(), &[])?;\n        let param_signatures = vec![\n            ParamSignature {\n                ty: range_check_type.clone(),\n                allow_deferred: false,\n                allow_add_const: true,\n                allow_const: false,\n            },\n            ParamSignature::new(ty.clone()),\n            ParamSignature::new(ty),\n        ];\n        let branch_signatures = (0..2)\n            .map(|_| BranchSignature {\n                vars: vec![OutputVarInfo {\n                    ty: range_check_type.clone(),\n                    ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::AddConst {\n                        param_idx: 0,\n                    }),\n                }],\n                ap_change: SierraApChange::Known { new_vars_only: false },\n            })\n            .collect();\n        Ok(LibfuncSignature { param_signatures, branch_signatures, fallthrough: Some(0) })\n    }\n}\n\n/// Libfunc for comparing uints.\n#[derive(Default)]\npub struct UintLessThanOrEqualLibfunc<TUintTraits: UintTraits> {\n    _phantom: PhantomData<TUintTraits>,\n}\nimpl<TUintTraits: UintTraits> NoGenericArgsGenericLibfunc\n    for UintLessThanOrEqualLibfunc<TUintTraits>\n{\n    const STR_ID: &'static str = TUintTraits::LESS_THAN_OR_EQUAL;\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let ty = context.get_concrete_type(TUintTraits::GENERIC_TYPE_ID, &[])?;\n        let range_check_type = context.get_concrete_type(RangeCheckType::id(), &[])?;\n        let param_signatures = vec![\n            ParamSignature {\n                ty: range_check_type.clone(),\n                allow_deferred: false,\n                allow_add_const: true,\n                allow_const: false,\n            },\n            ParamSignature::new(ty.clone()),\n            ParamSignature::new(ty),\n        ];\n        let branch_signatures = (0..2)\n            .map(|_| BranchSignature {\n                vars: vec![OutputVarInfo {\n                    ty: range_check_type.clone(),\n                    ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::AddConst {\n                        param_idx: 0,\n                    }),\n                }],\n                ap_change: SierraApChange::Known { new_vars_only: false },\n            })\n            .collect();\n        Ok(LibfuncSignature { param_signatures, branch_signatures, fallthrough: Some(0) })\n    }\n}\n\npub struct UintOperationConcreteLibfunc {\n    pub operator: IntOperator,\n    pub signature: LibfuncSignature,\n}\nimpl SignatureBasedConcreteLibfunc for UintOperationConcreteLibfunc {\n    fn signature(&self) -> &LibfuncSignature {\n        &self.signature\n    }\n}\n\n/// Libfunc for uints operations.\npub struct UintOperationLibfunc<TUintTraits: UintTraits> {\n    pub operator: IntOperator,\n    _phantom: PhantomData<TUintTraits>,\n}\nimpl<TUintTraits: UintTraits> UintOperationLibfunc<TUintTraits> {\n    const OVERFLOWING_ADD: &'static str = TUintTraits::OVERFLOWING_ADD;\n    const OVERFLOWING_SUB: &'static str = TUintTraits::OVERFLOWING_SUB;\n    fn new(operator: IntOperator) -> Option<Self> {\n        Some(Self { operator, _phantom: PhantomData::default() })\n    }\n}\nimpl<TUintTraits: UintTraits> GenericLibfunc for UintOperationLibfunc<TUintTraits> {\n    type Concrete = UintOperationConcreteLibfunc;\n\n    fn supported_ids() -> Vec<GenericLibfuncId> {\n        vec![\n            GenericLibfuncId::from(Self::OVERFLOWING_ADD),\n            GenericLibfuncId::from(Self::OVERFLOWING_SUB),\n        ]\n    }\n\n    fn by_id(id: &GenericLibfuncId) -> Option<Self> {\n        match id.0.as_str() {\n            id if id == Self::OVERFLOWING_ADD => Self::new(IntOperator::OverflowingAdd),\n            id if id == Self::OVERFLOWING_SUB => Self::new(IntOperator::OverflowingSub),\n            _ => None,\n        }\n    }\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        if !args.is_empty() {\n            return Err(SpecializationError::WrongNumberOfGenericArgs);\n        }\n        let ty = context.get_concrete_type(TUintTraits::GENERIC_TYPE_ID, &[])?;\n        let range_check_type = context.get_concrete_type(RangeCheckType::id(), &[])?;\n        let is_wrapping_result_at_end =\n            !TUintTraits::IS_SMALL || self.operator == IntOperator::OverflowingSub;\n        Ok(LibfuncSignature {\n            param_signatures: vec![\n                ParamSignature {\n                    ty: range_check_type.clone(),\n                    allow_deferred: false,\n                    allow_add_const: true,\n                    allow_const: false,\n                },\n                ParamSignature::new(ty.clone()),\n                ParamSignature::new(ty.clone()),\n            ],\n            branch_signatures: vec![\n                BranchSignature {\n                    vars: vec![\n                        OutputVarInfo {\n                            ty: range_check_type.clone(),\n                            ref_info: OutputVarReferenceInfo::Deferred(\n                                DeferredOutputKind::AddConst { param_idx: 0 },\n                            ),\n                        },\n                        OutputVarInfo {\n                            ty: ty.clone(),\n                            ref_info: OutputVarReferenceInfo::NewTempVar { idx: Some(0) },\n                        },\n                    ],\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n                BranchSignature {\n                    vars: vec![\n                        OutputVarInfo {\n                            ty: range_check_type,\n                            ref_info: OutputVarReferenceInfo::Deferred(\n                                DeferredOutputKind::AddConst { param_idx: 0 },\n                            ),\n                        },\n                        OutputVarInfo {\n                            ty,\n                            ref_info: OutputVarReferenceInfo::NewTempVar {\n                                idx: if is_wrapping_result_at_end { Some(0) } else { None },\n                            },\n                        },\n                    ],\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n            ],\n            fallthrough: Some(0),\n        })\n    }\n\n    fn specialize(\n        &self,\n        context: &dyn SpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<Self::Concrete, SpecializationError> {\n        Ok(UintOperationConcreteLibfunc {\n            operator: self.operator,\n            signature: self.specialize_signature(context.upcast(), args)?,\n        })\n    }\n}\n\n/// Libfunc for converting a uint into a felt252.\n#[derive(Default)]\npub struct UintToFelt252Libfunc<TUintTraits: UintTraits> {\n    _phantom: PhantomData<TUintTraits>,\n}\nimpl<TUintTraits: UintTraits> NoGenericArgsGenericLibfunc for UintToFelt252Libfunc<TUintTraits> {\n    const STR_ID: &'static str = TUintTraits::TO_FELT252;\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        Ok(LibfuncSignature::new_non_branch_ex(\n            vec![ParamSignature {\n                ty: context.get_concrete_type(TUintTraits::GENERIC_TYPE_ID, &[])?,\n                allow_deferred: true,\n                allow_add_const: true,\n                allow_const: true,\n            }],\n            vec![OutputVarInfo {\n                ty: context.get_concrete_type(Felt252Type::id(), &[])?,\n                ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 0 },\n            }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n\n/// Libfunc for attempting to convert a felt252 into a uint.\n#[derive(Default)]\npub struct UintFromFelt252Trait<TUintTraits: UintTraits> {\n    _phantom: PhantomData<TUintTraits>,\n}\nimpl<TUintTraits: UintTraits> TryFromFelt252 for UintFromFelt252Trait<TUintTraits> {\n    const STR_ID: &'static str = TUintTraits::TRY_FROM_FELT252;\n    const GENERIC_TYPE_ID: GenericTypeId = TUintTraits::GENERIC_TYPE_ID;\n}\n\npub type UintFromFelt252Libfunc<T> = TryFromFelt252Libfunc<UintFromFelt252Trait<T>>;\n\n/// Libfunc for uint divmod.\n#[derive(Default)]\npub struct UintDivmodLibfunc<TUintTraits: UintTraits> {\n    _phantom: PhantomData<TUintTraits>,\n}\nimpl<TUintTraits: UintTraits> NoGenericArgsGenericLibfunc for UintDivmodLibfunc<TUintTraits> {\n    const STR_ID: &'static str = TUintTraits::DIVMOD;\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let ty = context.get_concrete_type(TUintTraits::GENERIC_TYPE_ID, &[])?;\n        let range_check_type = context.get_concrete_type(RangeCheckType::id(), &[])?;\n        Ok(LibfuncSignature::new_non_branch_ex(\n            vec![\n                ParamSignature {\n                    ty: range_check_type.clone(),\n                    allow_deferred: false,\n                    allow_add_const: true,\n                    allow_const: false,\n                },\n                ParamSignature::new(ty.clone()),\n                ParamSignature::new(nonzero_ty(context, &ty)?),\n            ],\n            vec![\n                OutputVarInfo {\n                    ty: range_check_type,\n                    ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::AddConst {\n                        param_idx: 0,\n                    }),\n                },\n                OutputVarInfo {\n                    ty: ty.clone(),\n                    ref_info: OutputVarReferenceInfo::NewTempVar { idx: Some(0) },\n                },\n                OutputVarInfo { ty, ref_info: OutputVarReferenceInfo::NewTempVar { idx: Some(1) } },\n            ],\n            SierraApChange::Known { new_vars_only: false },\n        ))\n    }\n}\n\n/// Libfunc for uint wide multiplication.\n#[derive(Default)]\npub struct UintWideMulLibfunc<TUintMulTraits: UintMulTraits> {\n    _phantom: PhantomData<TUintMulTraits>,\n}\nimpl<TUintMulTraits: UintMulTraits> NoGenericArgsGenericLibfunc\n    for UintWideMulLibfunc<TUintMulTraits>\n{\n    const STR_ID: &'static str = TUintMulTraits::WIDE_MUL;\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let ty = context.get_concrete_type(TUintMulTraits::GENERIC_TYPE_ID, &[])?;\n        Ok(LibfuncSignature::new_non_branch_ex(\n            vec![\n                ParamSignature::new(ty.clone()),\n                ParamSignature {\n                    ty,\n                    allow_deferred: false,\n                    allow_add_const: false,\n                    allow_const: true,\n                },\n            ],\n            vec![OutputVarInfo {\n                ty: context.get_concrete_type(TUintMulTraits::WIDE_MUL_RES_TYPE_ID, &[])?,\n                ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n            }],\n            SierraApChange::Known { new_vars_only: true },\n        ))\n    }\n}\n\n#[derive(Default)]\npub struct Uint8Traits;\n\nimpl UintTraits for Uint8Traits {\n    type UintType = u8;\n    const GENERIC_TYPE_ID: GenericTypeId = GenericTypeId::new_inline(\"u8\");\n    const IS_SMALL: bool = true;\n    const CONST: &'static str = \"u8_const\";\n    const EQUAL: &'static str = \"u8_eq\";\n    const SQUARE_ROOT: &'static str = \"u8_sqrt\";\n    const LESS_THAN: &'static str = \"u8_lt\";\n    const LESS_THAN_OR_EQUAL: &'static str = \"u8_le\";\n    const OVERFLOWING_ADD: &'static str = \"u8_overflowing_add\";\n    const OVERFLOWING_SUB: &'static str = \"u8_overflowing_sub\";\n    const TO_FELT252: &'static str = \"u8_to_felt252\";\n    const TRY_FROM_FELT252: &'static str = \"u8_try_from_felt252\";\n    const DIVMOD: &'static str = \"u8_safe_divmod\";\n}\n\nimpl UintMulTraits for Uint8Traits {\n    const WIDE_MUL: &'static str = \"u8_wide_mul\";\n    const WIDE_MUL_RES_TYPE_ID: GenericTypeId = <Uint16Type as NamedType>::ID;\n}\n\nimpl IsZeroTraits for Uint8Traits {\n    const IS_ZERO: &'static str = \"u8_is_zero\";\n    const GENERIC_TYPE_ID: GenericTypeId = <Uint8Type as NamedType>::ID;\n}\n\n/// Type for u8.\npub type Uint8Type = UintType<Uint8Traits>;\n\ndefine_libfunc_hierarchy! {\n    pub enum Uint8Libfunc {\n        Const(UintConstLibfunc<Uint8Traits>),\n        Operation(UintOperationLibfunc<Uint8Traits>),\n        LessThan(UintLessThanLibfunc<Uint8Traits>),\n        SquareRoot(UintSquareRootLibfunc<Uint8Traits>),\n        Equal(UintEqualLibfunc<Uint8Traits>),\n        LessThanOrEqual(UintLessThanOrEqualLibfunc<Uint8Traits>),\n        ToFelt252(UintToFelt252Libfunc<Uint8Traits>),\n        FromFelt252(UintFromFelt252Libfunc<Uint8Traits>),\n        IsZero(IsZeroLibfunc<Uint8Traits>),\n        Divmod(UintDivmodLibfunc<Uint8Traits>),\n        WideMul(UintWideMulLibfunc<Uint8Traits>),\n    }, Uint8Concrete\n}\n\n#[derive(Default)]\npub struct Uint16Traits;\n\nimpl UintTraits for Uint16Traits {\n    type UintType = u16;\n    const GENERIC_TYPE_ID: GenericTypeId = GenericTypeId::new_inline(\"u16\");\n    const IS_SMALL: bool = true;\n    const CONST: &'static str = \"u16_const\";\n    const EQUAL: &'static str = \"u16_eq\";\n    const SQUARE_ROOT: &'static str = \"u16_sqrt\";\n    const LESS_THAN: &'static str = \"u16_lt\";\n    const LESS_THAN_OR_EQUAL: &'static str = \"u16_le\";\n    const OVERFLOWING_ADD: &'static str = \"u16_overflowing_add\";\n    const OVERFLOWING_SUB: &'static str = \"u16_overflowing_sub\";\n    const TO_FELT252: &'static str = \"u16_to_felt252\";\n    const TRY_FROM_FELT252: &'static str = \"u16_try_from_felt252\";\n    const DIVMOD: &'static str = \"u16_safe_divmod\";\n}\n\nimpl UintMulTraits for Uint16Traits {\n    const WIDE_MUL: &'static str = \"u16_wide_mul\";\n    const WIDE_MUL_RES_TYPE_ID: GenericTypeId = <Uint32Type as NamedType>::ID;\n}\n\nimpl IsZeroTraits for Uint16Traits {\n    const IS_ZERO: &'static str = \"u16_is_zero\";\n    const GENERIC_TYPE_ID: GenericTypeId = <Uint16Type as NamedType>::ID;\n}\n\n/// Type for u16.\npub type Uint16Type = UintType<Uint16Traits>;\n\ndefine_libfunc_hierarchy! {\n    pub enum Uint16Libfunc {\n        Const(UintConstLibfunc<Uint16Traits>),\n        Operation(UintOperationLibfunc<Uint16Traits>),\n        LessThan(UintLessThanLibfunc<Uint16Traits>),\n        SquareRoot(UintSquareRootLibfunc<Uint16Traits>),\n        Equal(UintEqualLibfunc<Uint16Traits>),\n        LessThanOrEqual(UintLessThanOrEqualLibfunc<Uint16Traits>),\n        ToFelt252(UintToFelt252Libfunc<Uint16Traits>),\n        FromFelt252(UintFromFelt252Libfunc<Uint16Traits>),\n        IsZero(IsZeroLibfunc<Uint16Traits>),\n        Divmod(UintDivmodLibfunc<Uint16Traits>),\n        WideMul(UintWideMulLibfunc<Uint16Traits>),\n    }, Uint16Concrete\n}\n\n#[derive(Default)]\npub struct Uint32Traits;\n\nimpl UintTraits for Uint32Traits {\n    type UintType = u32;\n    const GENERIC_TYPE_ID: GenericTypeId = GenericTypeId::new_inline(\"u32\");\n    const IS_SMALL: bool = true;\n    const CONST: &'static str = \"u32_const\";\n    const EQUAL: &'static str = \"u32_eq\";\n    const SQUARE_ROOT: &'static str = \"u32_sqrt\";\n    const LESS_THAN: &'static str = \"u32_lt\";\n    const LESS_THAN_OR_EQUAL: &'static str = \"u32_le\";\n    const OVERFLOWING_ADD: &'static str = \"u32_overflowing_add\";\n    const OVERFLOWING_SUB: &'static str = \"u32_overflowing_sub\";\n    const TO_FELT252: &'static str = \"u32_to_felt252\";\n    const TRY_FROM_FELT252: &'static str = \"u32_try_from_felt252\";\n    const DIVMOD: &'static str = \"u32_safe_divmod\";\n}\n\nimpl UintMulTraits for Uint32Traits {\n    const WIDE_MUL: &'static str = \"u32_wide_mul\";\n    const WIDE_MUL_RES_TYPE_ID: GenericTypeId = <Uint64Type as NamedType>::ID;\n}\n\nimpl IsZeroTraits for Uint32Traits {\n    const IS_ZERO: &'static str = \"u32_is_zero\";\n    const GENERIC_TYPE_ID: GenericTypeId = <Uint32Type as NamedType>::ID;\n}\n\n/// Type for u32.\npub type Uint32Type = UintType<Uint32Traits>;\n\ndefine_libfunc_hierarchy! {\n    pub enum Uint32Libfunc {\n        Const(UintConstLibfunc<Uint32Traits>),\n        Operation(UintOperationLibfunc<Uint32Traits>),\n        LessThan(UintLessThanLibfunc<Uint32Traits>),\n        SquareRoot(UintSquareRootLibfunc<Uint32Traits>),\n        Equal(UintEqualLibfunc<Uint32Traits>),\n        LessThanOrEqual(UintLessThanOrEqualLibfunc<Uint32Traits>),\n        ToFelt252(UintToFelt252Libfunc<Uint32Traits>),\n        FromFelt252(UintFromFelt252Libfunc<Uint32Traits>),\n        IsZero(IsZeroLibfunc<Uint32Traits>),\n        Divmod(UintDivmodLibfunc<Uint32Traits>),\n        WideMul(UintWideMulLibfunc<Uint32Traits>),\n    }, Uint32Concrete\n}\n\n#[derive(Default)]\npub struct Uint64Traits;\n\nimpl UintTraits for Uint64Traits {\n    type UintType = u64;\n    const GENERIC_TYPE_ID: GenericTypeId = GenericTypeId::new_inline(\"u64\");\n    const IS_SMALL: bool = true;\n    const CONST: &'static str = \"u64_const\";\n    const EQUAL: &'static str = \"u64_eq\";\n    const SQUARE_ROOT: &'static str = \"u64_sqrt\";\n    const LESS_THAN: &'static str = \"u64_lt\";\n    const LESS_THAN_OR_EQUAL: &'static str = \"u64_le\";\n    const OVERFLOWING_ADD: &'static str = \"u64_overflowing_add\";\n    const OVERFLOWING_SUB: &'static str = \"u64_overflowing_sub\";\n    const TO_FELT252: &'static str = \"u64_to_felt252\";\n    const TRY_FROM_FELT252: &'static str = \"u64_try_from_felt252\";\n    const DIVMOD: &'static str = \"u64_safe_divmod\";\n}\n\nimpl UintMulTraits for Uint64Traits {\n    const WIDE_MUL: &'static str = \"u64_wide_mul\";\n    const WIDE_MUL_RES_TYPE_ID: GenericTypeId = <Uint128Type as NamedType>::ID;\n}\n\nimpl IsZeroTraits for Uint64Traits {\n    const IS_ZERO: &'static str = \"u64_is_zero\";\n    const GENERIC_TYPE_ID: GenericTypeId = <Uint64Type as NamedType>::ID;\n}\n\n/// Type for u64.\npub type Uint64Type = UintType<Uint64Traits>;\n\ndefine_libfunc_hierarchy! {\n    pub enum Uint64Libfunc {\n        Const(UintConstLibfunc<Uint64Traits>),\n        Operation(UintOperationLibfunc<Uint64Traits>),\n        LessThan(UintLessThanLibfunc<Uint64Traits>),\n        SquareRoot(UintSquareRootLibfunc<Uint64Traits>),\n        Equal(UintEqualLibfunc<Uint64Traits>),\n        LessThanOrEqual(UintLessThanOrEqualLibfunc<Uint64Traits>),\n        ToFelt252(UintToFelt252Libfunc<Uint64Traits>),\n        FromFelt252(UintFromFelt252Libfunc<Uint64Traits>),\n        IsZero(IsZeroLibfunc<Uint64Traits>),\n        Divmod(UintDivmodLibfunc<Uint64Traits>),\n        WideMul(UintWideMulLibfunc<Uint64Traits>),\n    }, Uint64Concrete\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use super::felt252::Felt252Type;\nuse super::is_zero::{IsZeroLibfunc, IsZeroTraits};\nuse super::range_check::RangeCheckType;\nuse super::uint::{\n    IntOperator, UintConstLibfunc, UintDivmodLibfunc, UintEqualLibfunc, UintLessThanLibfunc,\n    UintLessThanOrEqualLibfunc, UintOperationConcreteLibfunc, UintOperationLibfunc,\n    UintSquareRootLibfunc, UintToFelt252Libfunc, UintTraits, UintType,\n};\nuse crate::define_libfunc_hierarchy;\nuse crate::extensions::lib_func::{\n    BranchSignature, DeferredOutputKind, LibfuncSignature, OutputVarInfo, ParamSignature,\n    SierraApChange, SignatureSpecializationContext, SpecializationContext,\n};\nuse crate::extensions::{\n    GenericLibfunc, NamedType, NoGenericArgsGenericLibfunc, OutputVarReferenceInfo,\n    SpecializationError,\n};\nuse crate::ids::{GenericLibfuncId, GenericTypeId};\nuse crate::program::GenericArg;\n\n/// Type for u128.\npub type Uint128Type = UintType<Uint128Traits>;\n\ndefine_libfunc_hierarchy! {\n    pub enum Uint128Libfunc {\n        Operation(UintOperationLibfunc<Uint128Traits>),\n        Divmod(UintDivmodLibfunc<Uint128Traits>),\n        WideMul(Uint128WideMulLibfunc),\n        LessThan(UintLessThanLibfunc<Uint128Traits>),\n        Equal(UintEqualLibfunc<Uint128Traits>),\n        SquareRoot(UintSquareRootLibfunc<Uint128Traits>),\n        LessThanOrEqual(UintLessThanOrEqualLibfunc<Uint128Traits>),\n        Const(UintConstLibfunc<Uint128Traits>),\n        FromFelt252(Uint128sFromFelt252Libfunc),\n        ToFelt252(UintToFelt252Libfunc<Uint128Traits>),\n        IsZero(IsZeroLibfunc<Uint128Traits>),\n    }, Uint128Concrete\n}\n\n#[derive(Default)]\npub struct Uint128Traits;\n\nimpl UintTraits for Uint128Traits {\n    type UintType = u128;\n    const GENERIC_TYPE_ID: GenericTypeId = GenericTypeId::new_inline(\"u128\");\n    const IS_SMALL: bool = false;\n    const CONST: &'static str = \"u128_const\";\n    const EQUAL: &'static str = \"u128_eq\";\n    const SQUARE_ROOT: &'static str = \"u128_sqrt\";\n    const LESS_THAN: &'static str = \"u128_lt\";\n    const LESS_THAN_OR_EQUAL: &'static str = \"u128_le\";\n    const OVERFLOWING_ADD: &'static str = \"u128_overflowing_add\";\n    const OVERFLOWING_SUB: &'static str = \"u128_overflowing_sub\";\n    const TO_FELT252: &'static str = \"u128_to_felt252\";\n    const TRY_FROM_FELT252: &'static str = \"u128_try_from_felt252\";\n    const DIVMOD: &'static str = \"u128_safe_divmod\";\n}\n\nimpl IsZeroTraits for Uint128Traits {\n    const IS_ZERO: &'static str = \"u128_is_zero\";\n    const GENERIC_TYPE_ID: GenericTypeId = <Uint128Type as NamedType>::ID;\n}\n\n/// Libfunc for u128 operations.\npub struct Uint128OperationLibfunc {\n    pub operator: IntOperator,\n}\nimpl Uint128OperationLibfunc {\n    fn new(operator: IntOperator) -> Self {\n        Self { operator }\n    }\n    const OVERFLOWING_ADD: &str = \"u128_overflowing_add\";\n    const OVERFLOWING_SUB: &str = \"u128_overflowing_sub\";\n}\nimpl GenericLibfunc for Uint128OperationLibfunc {\n    type Concrete = UintOperationConcreteLibfunc;\n\n    fn supported_ids() -> Vec<GenericLibfuncId> {\n        vec![\n            GenericLibfuncId::from(Self::OVERFLOWING_ADD),\n            GenericLibfuncId::from(Self::OVERFLOWING_SUB),\n        ]\n    }\n\n    fn by_id(id: &GenericLibfuncId) -> Option<Self> {\n        match id.0.as_str() {\n            Self::OVERFLOWING_ADD => Some(Self::new(IntOperator::OverflowingAdd)),\n            Self::OVERFLOWING_SUB => Some(Self::new(IntOperator::OverflowingSub)),\n            _ => None,\n        }\n    }\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        if !args.is_empty() {\n            return Err(SpecializationError::WrongNumberOfGenericArgs);\n        }\n        let ty = context.get_concrete_type(Uint128Type::id(), &[])?;\n        let range_check_type = context.get_concrete_type(RangeCheckType::id(), &[])?;\n        Ok(LibfuncSignature {\n            param_signatures: vec![\n                ParamSignature {\n                    ty: range_check_type.clone(),\n                    allow_deferred: false,\n                    allow_add_const: true,\n                    allow_const: false,\n                },\n                ParamSignature::new(ty.clone()),\n                ParamSignature::new(ty.clone()),\n            ],\n            branch_signatures: vec![\n                BranchSignature {\n                    vars: vec![\n                        OutputVarInfo {\n                            ty: range_check_type.clone(),\n                            ref_info: OutputVarReferenceInfo::Deferred(\n                                DeferredOutputKind::AddConst { param_idx: 0 },\n                            ),\n                        },\n                        OutputVarInfo {\n                            ty: ty.clone(),\n                            ref_info: OutputVarReferenceInfo::NewTempVar { idx: Some(0) },\n                        },\n                    ],\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n                BranchSignature {\n                    vars: vec![\n                        OutputVarInfo {\n                            ty: range_check_type,\n                            ref_info: OutputVarReferenceInfo::Deferred(\n                                DeferredOutputKind::AddConst { param_idx: 0 },\n                            ),\n                        },\n                        OutputVarInfo {\n                            ty,\n                            ref_info: OutputVarReferenceInfo::NewTempVar { idx: Some(0) },\n                        },\n                    ],\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n            ],\n            fallthrough: Some(0),\n        })\n    }\n\n    fn specialize(\n        &self,\n        context: &dyn SpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<Self::Concrete, SpecializationError> {\n        Ok(UintOperationConcreteLibfunc {\n            operator: self.operator,\n            signature: self.specialize_signature(context.upcast(), args)?,\n        })\n    }\n}\n\n/// Libfunc for u128 wide mul.\n#[derive(Default)]\npub struct Uint128WideMulLibfunc {}\nimpl NoGenericArgsGenericLibfunc for Uint128WideMulLibfunc {\n    const STR_ID: &'static str = \"u128_wide_mul\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let ty = context.get_concrete_type(Uint128Type::id(), &[])?;\n        let range_check_type = context.get_concrete_type(RangeCheckType::id(), &[])?;\n        Ok(LibfuncSignature::new_non_branch_ex(\n            vec![\n                ParamSignature {\n                    ty: range_check_type.clone(),\n                    allow_deferred: false,\n                    allow_add_const: true,\n                    allow_const: false,\n                },\n                ParamSignature::new(ty.clone()),\n                ParamSignature::new(ty.clone()),\n            ],\n            vec![\n                OutputVarInfo {\n                    ty: range_check_type,\n                    ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::AddConst {\n                        param_idx: 0,\n                    }),\n                },\n                OutputVarInfo {\n                    ty: ty.clone(),\n                    ref_info: OutputVarReferenceInfo::NewTempVar { idx: Some(0) },\n                },\n                OutputVarInfo { ty, ref_info: OutputVarReferenceInfo::NewTempVar { idx: Some(1) } },\n            ],\n            SierraApChange::Known { new_vars_only: false },\n        ))\n    }\n}\n\n/// Libfunc for converting a felt252 into a u128, or the number and the overflow in the case of\n/// failure.\n#[derive(Default)]\npub struct Uint128sFromFelt252Libfunc {}\nimpl NoGenericArgsGenericLibfunc for Uint128sFromFelt252Libfunc {\n    const STR_ID: &'static str = \"u128s_from_felt252\";\n\n    fn specialize_signature(\n        &self,\n        context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        let range_check_type = context.get_concrete_type(RangeCheckType::id(), &[])?;\n        Ok(LibfuncSignature {\n            param_signatures: vec![\n                ParamSignature {\n                    ty: range_check_type.clone(),\n                    allow_deferred: false,\n                    allow_add_const: true,\n                    allow_const: false,\n                },\n                ParamSignature::new(context.get_concrete_type(Felt252Type::id(), &[])?),\n            ],\n            branch_signatures: vec![\n                BranchSignature {\n                    vars: vec![\n                        OutputVarInfo {\n                            ty: range_check_type.clone(),\n                            ref_info: OutputVarReferenceInfo::Deferred(\n                                DeferredOutputKind::AddConst { param_idx: 0 },\n                            ),\n                        },\n                        OutputVarInfo {\n                            ty: context.get_concrete_type(Uint128Type::id(), &[])?,\n                            ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 1 },\n                        },\n                    ],\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n                BranchSignature {\n                    vars: vec![\n                        OutputVarInfo {\n                            ty: range_check_type,\n                            ref_info: OutputVarReferenceInfo::Deferred(\n                                DeferredOutputKind::AddConst { param_idx: 0 },\n                            ),\n                        },\n                        OutputVarInfo {\n                            ty: context.get_concrete_type(Uint128Type::id(), &[])?,\n                            ref_info: OutputVarReferenceInfo::NewTempVar { idx: Some(0) },\n                        },\n                        OutputVarInfo {\n                            ty: context.get_concrete_type(Uint128Type::id(), &[])?,\n                            ref_info: OutputVarReferenceInfo::NewTempVar { idx: Some(1) },\n                        },\n                    ],\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                },\n            ],\n            fallthrough: Some(0),\n        })\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use crate::extensions::lib_func::{\n    BranchSignature, LibfuncSignature, SierraApChange, SignatureSpecializationContext,\n};\nuse crate::extensions::{NoGenericArgsGenericLibfunc, SpecializationError};\n\n#[derive(Default)]\npub struct UnconditionalJumpLibfunc {}\nimpl NoGenericArgsGenericLibfunc for UnconditionalJumpLibfunc {\n    const STR_ID: &'static str = \"jump\";\n\n    fn specialize_signature(\n        &self,\n        _context: &dyn SignatureSpecializationContext,\n    ) -> Result<LibfuncSignature, SpecializationError> {\n        Ok(LibfuncSignature {\n            param_signatures: vec![],\n            branch_signatures: vec![BranchSignature {\n                vars: vec![],\n                ap_change: SierraApChange::Known { new_vars_only: true },\n            }],\n            fallthrough: None,\n        })\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use crate::extensions::types::{\n    GenericTypeArgGenericType, GenericTypeArgGenericTypeWrapper, TypeInfo,\n};\nuse crate::extensions::SpecializationError;\nuse crate::ids::GenericTypeId;\n\n/// Uninitialized value of type T.\n#[derive(Default)]\npub struct UninitializedTypeWrapped {}\nimpl GenericTypeArgGenericType for UninitializedTypeWrapped {\n    const ID: GenericTypeId = GenericTypeId::new_inline(\"Uninitialized\");\n\n    fn calc_info(\n        &self,\n        long_id: crate::program::ConcreteTypeLongId,\n        TypeInfo { storable, .. }: TypeInfo,\n    ) -> Result<TypeInfo, SpecializationError> {\n        if storable {\n            Ok(TypeInfo { long_id, storable: false, droppable: true, duplicatable: false, size: 0 })\n        } else {\n            Err(SpecializationError::UnsupportedGenericArg)\n        }\n    }\n}\npub type UninitializedType = GenericTypeArgGenericTypeWrapper<UninitializedTypeWrapped>;\n",
    "metadata": {}
  },
  {
    "pageContent": "use bimap::BiMap;\nuse num_bigint::BigInt;\nuse test_case::test_case;\n\nuse super::core::{CoreLibfunc, CoreType};\nuse super::lib_func::{SierraApChange, SignatureSpecializationContext, SpecializationContext};\nuse super::types::TypeInfo;\nuse super::SpecializationError::{\n    self, IndexOutOfRange, MissingFunction, UnsupportedGenericArg, UnsupportedId,\n    WrongNumberOfGenericArgs,\n};\nuse crate::extensions::type_specialization_context::TypeSpecializationContext;\nuse crate::extensions::{GenericLibfunc, GenericType};\nuse crate::ids::{ConcreteTypeId, FunctionId, GenericTypeId};\nuse crate::program::{ConcreteTypeLongId, Function, FunctionSignature, GenericArg, StatementIdx};\nuse crate::test_utils::build_bijective_mapping;\n\nfn type_arg(name: &str) -> GenericArg {\n    GenericArg::Type(name.into())\n}\n\nfn user_type_arg(name: &str) -> GenericArg {\n    GenericArg::UserType(name.into())\n}\n\nfn value_arg(v: i64) -> GenericArg {\n    GenericArg::Value(BigInt::from(v))\n}\n\nstruct MockSpecializationContext {\n    mapping: BiMap<ConcreteTypeId, ConcreteTypeLongId>,\n}\nimpl MockSpecializationContext {\n    pub fn new() -> Self {\n        Self { mapping: build_bijective_mapping() }\n    }\n}\n\nimpl TypeSpecializationContext for MockSpecializationContext {\n    fn try_get_type_info(&self, id: ConcreteTypeId) -> Option<TypeInfo> {\n        if id == \"T\".into()\n            || id == \"felt252\".into()\n            || id == \"u128\".into()\n            || id == \"Option\".into()\n            || id == \"NonZeroFelt252\".into()\n            || id == \"NonZeroInt\".into()\n            || id == \"Tuple<>\".into()\n            || id == \"U128AndFelt252\".into()\n            || id == \"StorageAddress\".into()\n            || id == \"ContractAddress\".into()\n        {\n            Some(TypeInfo {\n                long_id: self.mapping.get_by_left(&id)?.clone(),\n                storable: true,\n                droppable: true,\n                duplicatable: true,\n                size: 1,\n            })\n        } else if id == \"ArrayFelt252\".into() || id == \"ArrayU128\".into() {\n            Some(TypeInfo {\n                long_id: self.mapping.get_by_left(&id)?.clone(),\n                storable: true,\n                droppable: true,\n                duplicatable: false,\n                size: 2,\n            })\n        } else if id == \"UninitializedFelt252\".into() || id == \"UninitializedU128\".into() {\n            Some(TypeInfo {\n                long_id: self.mapping.get_by_left(&id)?.clone(),\n                storable: false,\n                droppable: true,\n                duplicatable: false,\n                size: 0,\n            })\n        } else if id == \"GasBuiltin\".into() || id == \"System\".into() || id == \"RangeCheck\".into() {\n            Some(TypeInfo {\n                long_id: self.mapping.get_by_left(&id)?.clone(),\n                storable: true,\n                droppable: false,\n                duplicatable: false,\n                size: 1,\n            })\n        } else if id == \"NonDupEnum\".into() || id == \"NonDupStruct\".into() {\n            Some(TypeInfo {\n                long_id: self.mapping.get_by_left(&id)?.clone(),\n                storable: true,\n                droppable: false,\n                duplicatable: false,\n                size: 2,\n            })\n        } else if id == \"SnapshotRangeCheck\".into() {\n            Some(TypeInfo {\n                long_id: self.mapping.get_by_left(&id)?.clone(),\n                storable: true,\n                droppable: true,\n                duplicatable: true,\n                size: 1,\n            })\n        } else if id == \"SnapshotArrayU128\".into() {\n            Some(TypeInfo {\n                long_id: self.mapping.get_by_left(&id)?.clone(),\n                storable: true,\n                droppable: true,\n                duplicatable: true,\n                size: 2,\n            })\n        } else {\n            None\n        }\n    }\n}\nimpl SignatureSpecializationContext for MockSpecializationContext {\n    fn try_get_concrete_type(\n        &self,\n        id: GenericTypeId,\n        generic_args: &[GenericArg],\n    ) -> Option<ConcreteTypeId> {\n        self.mapping\n            .get_by_right(&ConcreteTypeLongId {\n                generic_id: id,\n                generic_args: generic_args.to_vec(),\n            })\n            .cloned()\n    }\n\n    fn try_get_function_signature(&self, function_id: &FunctionId) -> Option<FunctionSignature> {\n        self.try_get_function(function_id).map(|f| f.signature)\n    }\n\n    fn as_type_specialization_context(&self) -> &dyn TypeSpecializationContext {\n        self\n    }\n\n    fn try_get_function_ap_change(&self, _function_id: &FunctionId) -> Option<SierraApChange> {\n        Some(SierraApChange::Unknown)\n    }\n}\n\nimpl SpecializationContext for MockSpecializationContext {\n    fn upcast(&self) -> &dyn SignatureSpecializationContext {\n        self\n    }\n\n    fn try_get_function(&self, function_id: &FunctionId) -> Option<Function> {\n        match function_id {\n            id if id == &\"RegisteredFunction\".into() => {\n                Some(Function::new(\"RegisteredFunction\".into(), vec![], vec![], StatementIdx(5)))\n            }\n            _ => None,\n        }\n    }\n}\n\n#[test_case(\"NoneExistent\", vec![] => Err(UnsupportedId(\"NoneExistent\".into())); \"NoneExistent\")]\n#[test_case(\"GasBuiltin\", vec![] => Ok(()); \"GasBuiltin\")]\n#[test_case(\"GasBuiltin\", vec![type_arg(\"T\")] => Err(WrongNumberOfGenericArgs); \"GasBuiltin<T>\")]\n#[test_case(\"RangeCheck\", vec![] => Ok(()); \"RangeCheck\")]\n#[test_case(\"RangeCheck\", vec![type_arg(\"T\")] => Err(WrongNumberOfGenericArgs); \"RangeCheck<T>\")]\n#[test_case(\"felt252\", vec![] => Ok(()); \"felt252\")]\n#[test_case(\"felt252\", vec![type_arg(\"T\")] => Err(WrongNumberOfGenericArgs); \"felt252<T>\")]\n#[test_case(\"u128\", vec![] => Ok(()); \"u128\")]\n#[test_case(\"u128\", vec![type_arg(\"T\")] => Err(WrongNumberOfGenericArgs); \"u128<T>\")]\n#[test_case(\"Array\", vec![type_arg(\"u128\")] => Ok(()); \"Array<u128>\")]\n#[test_case(\"Array\", vec![] => Err(WrongNumberOfGenericArgs); \"Array\")]\n#[test_case(\"Array\", vec![value_arg(5)] => Err(UnsupportedGenericArg); \"Array<5>\")]\n#[test_case(\"Array\", vec![user_type_arg(\"Unit\")] => Err(UnsupportedGenericArg); \"Array<Unit>\")]\n#[test_case(\"Array\", vec![type_arg(\"UninitializedFelt252\")] => Err(UnsupportedGenericArg);\n            \"Array<UninitializedFelt252>\")]\n#[test_case(\"NonZero\", vec![type_arg(\"T\")] => Ok(()); \"NonZero<T>\")]\n#[test_case(\"NonZero\", vec![] => Err(WrongNumberOfGenericArgs); \"NonZero\")]\n#[test_case(\"NonZero\", vec![value_arg(5)] => Err(UnsupportedGenericArg); \"NonZero<5>\")]\n#[test_case(\"Box\", vec![type_arg(\"T\")] => Ok(()); \"Box<T>\")]\n#[test_case(\"Box\", vec![] => Err(WrongNumberOfGenericArgs); \"Box<>\")]\n#[test_case(\"Box\", vec![value_arg(5)] => Err(UnsupportedGenericArg); \"Box<5>\")]\n#[test_case(\"Uninitialized\", vec![type_arg(\"T\")] => Ok(()); \"Uninitialized<T>\")]\n#[test_case(\"Enum\", vec![user_type_arg(\"name\")] => Ok(()); \"Enum<name>\")]\n#[test_case(\"Enum\", vec![user_type_arg(\"name\"), type_arg(\"u128\")] => Ok(());\n            \"Enum<name, u128>\")]\n#[test_case(\"Enum\", vec![user_type_arg(\"name\"), type_arg(\"u128\"), type_arg(\"felt252\")] => Ok(());\n            \"Enum<name, u128, felt252>\")]\n#[test_case(\"Enum\", vec![user_type_arg(\"name\"), value_arg(5)] => Err(UnsupportedGenericArg);\n            \"Enum<name, 5>\")]\n#[test_case(\"Enum\", vec![user_type_arg(\"name\"), type_arg(\"UninitializedFelt252\")]\n            => Err(UnsupportedGenericArg);\n            \"Enum<name, UninitializedFelt252>\")]\n#[test_case(\"Enum\", vec![type_arg(\"u128\"), type_arg(\"felt252\")] => Err(UnsupportedGenericArg);\n            \"Enum<u128, felt252>\")]\n#[test_case(\"Struct\", vec![user_type_arg(\"Unit\")] => Ok(()); \"Struct<Unit>\")]\n#[test_case(\"Struct\", vec![user_type_arg(\"Wrap\"), type_arg(\"u128\")] => Ok(());\n            \"Struct<Wrap, u128>\")]\n#[test_case(\"Struct\", vec![user_type_arg(\"Pair\"), type_arg(\"u128\"), type_arg(\"felt252\")] => Ok(());\n            \"Struct<Pair, u128, felt252>\")]\n#[test_case(\"Struct\", vec![user_type_arg(\"name\"), value_arg(5)] => Err(UnsupportedGenericArg);\n            \"Struct<name, 5>\")]\n#[test_case(\"Struct\", vec![user_type_arg(\"name\"), type_arg(\"UninitializedFelt252\")]\n            => Err(UnsupportedGenericArg);\n            \"Struct<name, UninitializedFelt252>\")]\n#[test_case(\"Struct\", vec![type_arg(\"u128\"), type_arg(\"felt252\")] => Err(UnsupportedGenericArg);\n            \"Struct<u128, felt252>\")]\n#[test_case(\"System\", vec![] => Ok(()); \"System\")]\n#[test_case(\"StorageBaseAddress\", vec![] => Ok(()); \"StorageBaseAddress\")]\n#[test_case(\"Snapshot\", vec![type_arg(\"RangeCheck\")] => Ok(()); \"Snapshot<RangeCheck>\")]\n#[test_case(\"Snapshot\", vec![type_arg(\"felt252\")] => Err(UnsupportedGenericArg); \"Snapshot<felt252>\")]\n#[test_case(\"Snapshot\", vec![type_arg(\"UninitializedFelt252\")] => Err(UnsupportedGenericArg);\n            \"Snapshot<UninitializedFelt252>\")]\n#[test_case(\"Snapshot\", vec![type_arg(\"SnapshotRangeCheck\")] => Err(UnsupportedGenericArg);\n            \"Snapshot<SnapshotRangeCheck>\")]\nfn find_type_specialization(\n    id: &str,\n    generic_args: Vec<GenericArg>,\n) -> Result<(), SpecializationError> {\n    CoreType::by_id(&id.into())\n        .ok_or(UnsupportedId(id.into()))?\n        .specialize(&MockSpecializationContext::new(), &generic_args)\n        .map(|_| ())\n}\n\n#[test_case(\"NoneExistent\", vec![] => Err(UnsupportedId(\"NoneExistent\".into())); \"NoneExistent\")]\n#[test_case(\"function_call\", vec![GenericArg::UserFunc(\"UnregisteredFunction\".into())]\n            => Err(MissingFunction(\"UnregisteredFunction\".into()));\n            \"function_call<&UnregisteredFunction>\")]\n#[test_case(\"function_call\", vec![GenericArg::UserFunc(\"RegisteredFunction\".into())]\n            => Ok(()); \"function_call<&RegisteredFunction>\")]\n#[test_case(\"function_call\", vec![] => Err(UnsupportedGenericArg); \"function_call\")]\n#[test_case(\"array_new\", vec![] => Err(WrongNumberOfGenericArgs); \"array_new\")]\n#[test_case(\"array_new\", vec![type_arg(\"u128\")] => Ok(()); \"array_new<u128>\")]\n#[test_case(\"array_append\", vec![] => Err(WrongNumberOfGenericArgs); \"array_append\")]\n#[test_case(\"array_append\", vec![type_arg(\"u128\")] => Ok(()); \"array_append<u128>\")]\n#[test_case(\"array_get\", vec![] => Err(WrongNumberOfGenericArgs); \"array_get\")]\n#[test_case(\"array_get\", vec![type_arg(\"u128\")] => Ok(()); \"array_get<u128>\")]\n#[test_case(\"array_len\", vec![] => Err(WrongNumberOfGenericArgs); \"array_len\")]\n#[test_case(\"array_len\", vec![type_arg(\"u128\")] => Ok(()); \"array_len<u128>\")]\n#[test_case(\"withdraw_gas\", vec![value_arg(0)] => Err(WrongNumberOfGenericArgs); \"withdraw_gas<0>\")]\n#[test_case(\"withdraw_gas\", vec![] => Ok(()); \"withdraw_gas\")]\n#[test_case(\"redeposit_gas\", vec![value_arg(0)] => Err(WrongNumberOfGenericArgs); \"redeposit_gas<0>\")]\n#[test_case(\"redeposit_gas\", vec![] => Ok(()); \"redeposit_gas\")]\n#[test_case(\"felt252_add\", vec![] => Ok(()); \"felt252_add\")]\n#[test_case(\"felt252_add_const\", vec![value_arg(0)] =>  Ok(()); \"felt252_add_const<0>\")]\n#[test_case(\"felt252_mul\", vec![] => Ok(()); \"felt252_mul\")]\n#[test_case(\"felt252_mul_const\", vec![value_arg(0)] =>  Ok(()); \"felt252_mul_const<0>\")]\n#[test_case(\"felt252_is_zero\", vec![] => Ok(()); \"felt252_is_zero<>\")]\n#[test_case(\"felt252_is_zero\", vec![type_arg(\"felt252\")]\n            => Err(WrongNumberOfGenericArgs); \"felt252_is_zero<int>\")]\n#[test_case(\"u128_overflowing_add\", vec![] => Ok(()); \"u128_overflowing_add\")]\n#[test_case(\"u128_overflowing_sub\", vec![] => Ok(()); \"u128_overflowing_sub\")]\n#[test_case(\"u128_safe_divmod\", vec![] => Ok(()); \"u128_safe_divmod\")]\n#[test_case(\"u128_const\", vec![value_arg(8)] => Ok(()); \"u128_const<8>\")]\n#[test_case(\"u128_const\", vec![] => Err(UnsupportedGenericArg); \"u128_const\")]\n#[test_case(\"storage_base_address_const\", vec![value_arg(8)] => Ok(()); \"storage_base_address_const<8>\")]\n#[test_case(\"storage_base_address_const\", vec![] => Err(UnsupportedGenericArg);\n\"storage_base_address_const\")]\n#[test_case(\"contract_address_const\", vec![value_arg(8)] => Ok(()); \"contract_address_const<8>\")]\n#[test_case(\"contract_address_const\", vec![] => Err(UnsupportedGenericArg);\n\"contract_address_const\")]\n#[test_case(\"drop\", vec![type_arg(\"u128\")] => Ok(()); \"drop<u128>\")]\n#[test_case(\"drop\", vec![] => Err(WrongNumberOfGenericArgs); \"drop<>\")]\n#[test_case(\"drop\", vec![type_arg(\"GasBuiltin\")] => Err(UnsupportedGenericArg);\n\"drop<GasBuiltin>\")]\n#[test_case(\"dup\", vec![type_arg(\"u128\")] => Ok(()); \"dup<u128>\")]\n#[test_case(\"dup\", vec![] => Err(WrongNumberOfGenericArgs); \"dup<>\")]\n#[test_case(\"dup\", vec![type_arg(\"GasBuiltin\")] => Err(UnsupportedGenericArg);\n\"dup<GasBuiltin>\")]\n#[test_case(\"u128_is_zero\", vec![] => Ok(()); \"u128_is_zero<>\")]\n#[test_case(\"u128_is_zero\", vec![type_arg(\"u128\")]\n            => Err(WrongNumberOfGenericArgs); \"u128_is_zero<u128>\")]\n#[test_case(\"unwrap_non_zero\", vec![type_arg(\"u128\")] => Ok(()); \"unwrap_non_zero<u128>\")]\n#[test_case(\"unwrap_non_zero\", vec![] => Err(WrongNumberOfGenericArgs); \"unwrap_non_zero\")]\n#[test_case(\"store_temp\", vec![type_arg(\"u128\")] => Ok(()); \"store_temp<u128>\")]\n#[test_case(\"store_temp\", vec![] => Err(WrongNumberOfGenericArgs); \"store_temp\")]\n#[test_case(\"store_local\", vec![type_arg(\"u128\")] => Ok(()); \"store_local<u128>\")]\n#[test_case(\"store_local\", vec![] => Err(WrongNumberOfGenericArgs); \"store_local\")]\n#[test_case(\"finalize_locals\", vec![] => Ok(()); \"finalize_locals\")]\n#[test_case(\"finalize_locals\", vec![type_arg(\"u128\")]\n            => Err(WrongNumberOfGenericArgs); \"finalize_locals<u128>\")]\n#[test_case(\"alloc_local\", vec![type_arg(\"u128\")] => Ok(()); \"alloc_local<u128>\")]\n#[test_case(\"alloc_local\", vec![] => Err(WrongNumberOfGenericArgs); \"alloc_local<>\")]\n#[test_case(\"rename\", vec![type_arg(\"u128\")] => Ok(()); \"rename<u128>\")]\n#[test_case(\"rename\", vec![] => Err(WrongNumberOfGenericArgs); \"rename\")]\n#[test_case(\"jump\", vec![] => Ok(()); \"jump\")]\n#[test_case(\"jump\", vec![type_arg(\"T\")] => Err(WrongNumberOfGenericArgs); \"jump<T>\")]\n#[test_case(\"revoke_ap_tracking\", vec![] => Ok(()); \"revoke_ap_tracking\")]\n#[test_case(\"enum_init\", vec![type_arg(\"Option\"), value_arg(0)] => Ok(());\n\"enum_init<Option,0>\")]\n#[test_case(\"enum_init\", vec![type_arg(\"Option\"), value_arg(1)] =>\nOk(());\"enum_init<Option,1>\")]\n#[test_case(\"enum_init\", vec![type_arg(\"Option\"), value_arg(2)]\n            => Err(IndexOutOfRange{index: BigInt::from(2), range_size: 2});\n\"enum_init<Option,2>\")]\n#[test_case(\"enum_init\", vec![type_arg(\"Option\"), value_arg(-3)]\n            => Err(IndexOutOfRange{index: BigInt::from(-3), range_size: 2});\n\"enum_init<Option,-3>\")]\n#[test_case(\"enum_init\", vec![type_arg(\"Option\")]\n            => Err(WrongNumberOfGenericArgs); \"enum_init<Option>\")]\n#[test_case(\"enum_init\", vec![value_arg(0)] => Err(WrongNumberOfGenericArgs); \"enum_init<0>\")]\n#[test_case(\"enum_init\", vec![] => Err(WrongNumberOfGenericArgs); \"enum_init\")]\n#[test_case(\"enum_init\", vec![value_arg(0),type_arg(\"Option\")]\n            => Err(UnsupportedGenericArg); \"enum_init<0,Option>\")]\n#[test_case(\"enum_init\", vec![type_arg(\"Option\"), type_arg(\"Option\")]\n            => Err(UnsupportedGenericArg); \"enum_init<Option,Option>\")]\n#[test_case(\"enum_init\", vec![value_arg(0), value_arg(0)]\n            => Err(UnsupportedGenericArg); \"enum_init<0,0>\")]\n#[test_case(\"enum_match\", vec![type_arg(\"Option\")] => Ok(()); \"enum_match<Option>\")]\n#[test_case(\"enum_match\", vec![value_arg(4)] => Err(UnsupportedGenericArg); \"enum_match<4>\")]\n#[test_case(\"enum_match\", vec![] => Err(WrongNumberOfGenericArgs); \"enum_match\")]\n#[test_case(\"enum_snapshot_match\", vec![type_arg(\"Option\")] => Ok(()); \"enum_snapshot_match<Option>\")]\n#[test_case(\"enum_snapshot_match\", vec![type_arg(\"NonDupEnum\")] => Ok(()); \"enum_snapshot_match<NonDupEnum>\")]\n#[test_case(\"struct_construct\", vec![type_arg(\"U128AndFelt252\")] => Ok(());\n            \"struct_construct<U128AndFelt252>\")]\n#[test_case(\"struct_construct\", vec![value_arg(4)] => Err(UnsupportedGenericArg);\n            \"struct_construct<4>\")]\n#[test_case(\"struct_deconstruct\", vec![type_arg(\"U128AndFelt252\")] => Ok(());\n            \"struct_deconstruct<U128AndFelt252>\")]\n#[test_case(\"struct_deconstruct\", vec![value_arg(4)] => Err(UnsupportedGenericArg);\n            \"struct_deconstruct<4>\")]\n#[test_case(\"struct_snapshot_deconstruct\", vec![type_arg(\"U128AndFelt252\")] => Ok(());\n            \"struct_snapshot_deconstruct<U128AndFelt252>\")]\n#[test_case(\"struct_snapshot_deconstruct\", vec![type_arg(\"NonDupStruct\")] => Ok(());\n            \"struct_snapshot_deconstruct<NonDupStruct>\")]\n#[test_case(\"storage_read_syscall\", vec![] => Ok(()); \"storage_read_syscall\")]\n#[test_case(\"storage_write_syscall\", vec![] => Ok(()); \"storage_write_syscall\")]\n#[test_case(\"snapshot_take\", vec![type_arg(\"RangeCheck\")] => Ok(()); \"snapshot_take<RangeCheck>\")]\n#[test_case(\"snapshot_take\", vec![type_arg(\"NonDupStruct\")] => Ok(());\n            \"snapshot_take<NonDupStruct>\")]\n#[test_case(\"snapshot_take\", vec![type_arg(\"NonDupEnum\")] => Ok(()); \"snapshot_take<NonDupEnum>\")]\n#[test_case(\"snapshot_take\", vec![type_arg(\"felt252\")] => Ok(()); \"snapshot_take<felt252>\")]\n#[test_case(\"snapshot_take\", vec![type_arg(\"SnapshotRangeCheck\")] => Ok(());\n            \"snapshot_take<SnapshotRangeCheck>\")]\nfn find_libfunc_specialization(\n    id: &str,\n    generic_args: Vec<GenericArg>,\n) -> Result<(), SpecializationError> {\n    CoreLibfunc::by_id(&id.into())\n        .ok_or(UnsupportedId(id.into()))?\n        .specialize(&MockSpecializationContext::new(), &generic_args)\n        .map(|_| ())\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use super::types::TypeInfo;\nuse super::SpecializationError;\nuse crate::ids::ConcreteTypeId;\n\n/// Trait for the specialization of types.\npub trait TypeSpecializationContext {\n    /// Returns the type information for the type with the given id.\n    fn try_get_type_info(&self, id: ConcreteTypeId) -> Option<TypeInfo>;\n\n    /// Wraps [Self::try_get_type_info] with a result object.\n    fn get_type_info(&self, id: ConcreteTypeId) -> Result<TypeInfo, SpecializationError> {\n        self.try_get_type_info(id.clone()).ok_or(SpecializationError::MissingTypeInfo(id))\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use super::args_as_single_type;\nuse super::error::{ExtensionError, SpecializationError};\nuse super::type_specialization_context::TypeSpecializationContext;\nuse crate::ids::{ConcreteTypeId, GenericTypeId};\nuse crate::program::{ConcreteTypeLongId, GenericArg};\n\n/// Trait for implementing a specialization generator for types.\npub trait GenericType: Sized {\n    type Concrete: ConcreteType;\n\n    /// Instantiates the type by id.\n    fn by_id(id: &GenericTypeId) -> Option<Self>;\n    /// Creates the specialization with the template arguments.\n    fn specialize(\n        &self,\n        context: &dyn TypeSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<Self::Concrete, SpecializationError>;\n}\n\n/// Trait for introducing helper methods on GenericType.\npub trait GenericTypeEx: GenericType {\n    fn specialize_by_id(\n        context: &dyn TypeSpecializationContext,\n        type_id: &GenericTypeId,\n        args: &[GenericArg],\n    ) -> Result<Self::Concrete, ExtensionError>;\n}\nimpl<TGenericType: GenericType> GenericTypeEx for TGenericType {\n    fn specialize_by_id(\n        context: &dyn TypeSpecializationContext,\n        type_id: &GenericTypeId,\n        args: &[GenericArg],\n    ) -> Result<TGenericType::Concrete, ExtensionError> {\n        Self::by_id(type_id)\n            .ok_or_else(move || ExtensionError::TypeSpecialization {\n                type_id: type_id.clone(),\n                error: SpecializationError::UnsupportedId(type_id.0.clone()),\n            })?\n            .specialize(context, args)\n            .map_err(move |error| ExtensionError::TypeSpecialization {\n                type_id: type_id.clone(),\n                error,\n            })\n    }\n}\n\n/// Trait for implementing a specialization generator with with a simple id.\npub trait NamedType: Default {\n    type Concrete: ConcreteType;\n    const ID: GenericTypeId;\n    /// Returns the generic id of named types.\n    fn id() -> GenericTypeId {\n        Self::ID\n    }\n    /// Returns the long ID of the concrete type with `ID` as the generic ID and the given args.\n    fn concrete_type_long_id(generic_args: &[GenericArg]) -> ConcreteTypeLongId {\n        ConcreteTypeLongId { generic_id: Self::id(), generic_args: generic_args.to_vec() }\n    }\n    /// Creates the specialization with the template arguments.\n    fn specialize(\n        &self,\n        context: &dyn TypeSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<Self::Concrete, SpecializationError>;\n}\nimpl<TNamedType: NamedType> GenericType for TNamedType {\n    type Concrete = <Self as NamedType>::Concrete;\n\n    fn by_id(id: &GenericTypeId) -> Option<Self> {\n        if &Self::ID == id { Some(Self::default()) } else { None }\n    }\n\n    fn specialize(\n        &self,\n        context: &dyn TypeSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<Self::Concrete, SpecializationError> {\n        <Self as NamedType>::specialize(self, context, args)\n    }\n}\n\n/// Trait for describing a generic type with no generic arguments.\npub trait NoGenericArgsGenericType: Default {\n    const ID: GenericTypeId;\n    const STORABLE: bool;\n    const DUPLICATABLE: bool;\n    const DROPPABLE: bool;\n    const SIZE: i16;\n}\nimpl<T: NoGenericArgsGenericType> NamedType for T {\n    type Concrete = InfoOnlyConcreteType;\n    const ID: GenericTypeId = <Self as NoGenericArgsGenericType>::ID;\n\n    fn specialize(\n        &self,\n        _context: &dyn TypeSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<Self::Concrete, SpecializationError> {\n        if args.is_empty() {\n            Ok(Self::Concrete {\n                info: TypeInfo {\n                    long_id: Self::concrete_type_long_id(args),\n                    storable: T::STORABLE,\n                    droppable: T::DROPPABLE,\n                    duplicatable: T::DUPLICATABLE,\n                    size: T::SIZE,\n                },\n            })\n        } else {\n            Err(SpecializationError::WrongNumberOfGenericArgs)\n        }\n    }\n}\n\n/// Trait for describing a generic type with a single type arg.\npub trait GenericTypeArgGenericType: Default {\n    const ID: GenericTypeId;\n\n    /// Returns the type info of the wrapping type.\n    fn calc_info(\n        &self,\n        long_id: ConcreteTypeLongId,\n        wrapped_info: TypeInfo,\n    ) -> Result<TypeInfo, SpecializationError>;\n}\n\n/// Wrapper for a specialization generator with a single type arg.\n#[derive(Default)]\npub struct GenericTypeArgGenericTypeWrapper<T: GenericTypeArgGenericType>(T);\nimpl<T: GenericTypeArgGenericType> NamedType for GenericTypeArgGenericTypeWrapper<T> {\n    type Concrete = InfoAndTypeConcreteType;\n    const ID: GenericTypeId = T::ID;\n\n    fn specialize(\n        &self,\n        context: &dyn TypeSpecializationContext,\n        args: &[GenericArg],\n    ) -> Result<Self::Concrete, SpecializationError> {\n        let ty = args_as_single_type(args)?;\n        let long_id = Self::concrete_type_long_id(args);\n        let wrapped_info = context.get_type_info(ty.clone())?;\n        Ok(Self::Concrete { info: self.0.calc_info(long_id, wrapped_info)?, ty })\n    }\n}\n\n/// Information on Sierra types required for generic libfunc calls.\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct TypeInfo {\n    /// The long ID of the concrete type.\n    pub long_id: ConcreteTypeLongId,\n    /// Can the type be stored by any of the store commands.\n    pub storable: bool,\n    /// Can the type be (trivially) dropped.\n    pub droppable: bool,\n    /// Can the type be (trivially) duplicated.\n    pub duplicatable: bool,\n    /// The size of an element of this type.\n    pub size: i16,\n}\n\n/// Trait for a specialized type.\npub trait ConcreteType {\n    fn info(&self) -> &TypeInfo;\n}\n\n/// Struct providing a ConcreteType only with the type info - should not be implemented for\n/// concrete types that require any extra data.\npub struct InfoOnlyConcreteType {\n    pub info: TypeInfo,\n}\n\nimpl ConcreteType for InfoOnlyConcreteType {\n    fn info(&self) -> &TypeInfo {\n        &self.info\n    }\n}\n\n/// Struct providing a ConcreteType with the type info and a wrapped type.\npub struct InfoAndTypeConcreteType {\n    pub info: TypeInfo,\n    pub ty: ConcreteTypeId,\n}\n\nimpl ConcreteType for InfoAndTypeConcreteType {\n    fn info(&self) -> &TypeInfo {\n        &self.info\n    }\n}\n\n/// Forms a Sierra type used by extensions type from an enum of such types.\n/// The new enum implements GenericType.\n/// All the variant types must also implement GenericType.\n/// Usage example:\n/// ```ignore\n/// define_type_hierarchy! {\n///     pub enum MyType {\n///       Ty0(Type0),\n///       Ty1(Type1),\n///     }, MyTypeConcrete\n/// }\n/// ```\n#[macro_export]\nmacro_rules! define_type_hierarchy {\n    (pub enum $name:ident { $($variant_name:ident ($variant:ty),)* },\n    $concrete_name:ident) => {\n        #[allow(clippy::enum_variant_names)]\n        pub enum $name {\n            $($variant_name ($variant)),*\n        }\n\n        impl $crate::extensions::types::GenericType for $name {\n            type Concrete = $concrete_name;\n            fn by_id(id: &$crate::ids::GenericTypeId) -> Option<Self> {\n                $(\n                    if let Some(res) = <$variant>::by_id(id){\n                        return Some(Self::$variant_name(res));\n                    }\n                )*\n                None\n            }\n            fn specialize(\n                    &self,\n                    context: &dyn $crate::extensions::type_specialization_context::TypeSpecializationContext,\n                    args: &[$crate::program::GenericArg]\n            ) -> Result<Self::Concrete, $crate::extensions::SpecializationError>{\n                match self {\n                    $(\n                        Self::$variant_name(value) => {\n                            Ok(Self::Concrete::$variant_name(\n                                <$variant as $crate::extensions::GenericType>::specialize(\n                                    value, context, args,\n                                )?\n                                .into(),\n                            ))\n                        }\n                    ),*\n                }\n            }\n        }\n\n        pub enum $concrete_name {\n            $($variant_name (<$variant as $crate::extensions::GenericType> ::Concrete),)*\n        }\n        impl $crate::extensions::ConcreteType for $concrete_name {\n            fn info(&self) -> &$crate::extensions::types::TypeInfo {\n                match self {\n                    $(Self::$variant_name(value) => value.info()),*\n                }\n            }\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::fmt;\n\nuse cairo_lang_utils::write_comma_separated;\n\nuse crate::ids::{\n    ConcreteLibfuncId, ConcreteTypeId, FunctionId, GenericLibfuncId, GenericTypeId, UserTypeId,\n    VarId,\n};\nuse crate::program::{\n    ConcreteLibfuncLongId, ConcreteTypeLongId, DeclaredTypeInfo, Function, GenBranchInfo,\n    GenBranchTarget, GenInvocation, GenStatement, GenericArg, LibfuncDeclaration, Param, Program,\n    StatementIdx, TypeDeclaration,\n};\n\nimpl fmt::Display for Program {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        for declaration in &self.type_declarations {\n            writeln!(f, \"{declaration};\")?;\n        }\n        writeln!(f)?;\n        for declaration in &self.libfunc_declarations {\n            writeln!(f, \"{declaration};\")?;\n        }\n        writeln!(f)?;\n        for statement in &self.statements {\n            writeln!(f, \"{statement};\")?;\n        }\n        writeln!(f)?;\n        for func in &self.funcs {\n            writeln!(f, \"{func};\")?;\n        }\n        Ok(())\n    }\n}\n\nimpl fmt::Display for TypeDeclaration {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        let TypeDeclaration { id, long_id, declared_type_info } = self;\n        write!(f, \"type {} = {}\", id, long_id)?;\n        if let Some(DeclaredTypeInfo { storable, droppable, duplicatable, size }) =\n            declared_type_info\n        {\n            writeln!(f, \" with_info {{\")?;\n            writeln!(f, \"  storable: {:?}\", storable)?;\n            writeln!(f, \"  droppable: {:?}\", droppable)?;\n            writeln!(f, \"  duplicatable: {:?}\", duplicatable)?;\n            writeln!(f, \"  size: {:?}\", size)?;\n            write!(f, \"}}\")?;\n        }\n        Ok(())\n    }\n}\n\nimpl fmt::Display for ConcreteTypeLongId {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"{}\", self.generic_id)?;\n        write_template_args(f, &self.generic_args)\n    }\n}\n\nimpl fmt::Display for LibfuncDeclaration {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"libfunc {} = {}\", self.id, self.long_id)\n    }\n}\n\nimpl fmt::Display for ConcreteLibfuncLongId {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"{}\", self.generic_id)?;\n        write_template_args(f, &self.generic_args)\n    }\n}\n\nimpl fmt::Display for Function {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"{}@{}(\", self.id, self.entry_point.0)?;\n        write_comma_separated(f, &self.params)?;\n        write!(f, \") -> (\")?;\n        write_comma_separated(f, &self.signature.ret_types)?;\n        write!(f, \")\")\n    }\n}\n\nimpl fmt::Display for Param {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"{}: {}\", self.id, self.ty)\n    }\n}\n\nmacro_rules! display_generic_identity {\n    ($type_name:tt) => {\n        impl fmt::Display for $type_name {\n            fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n                write!(f, \"{}\", self.0)\n            }\n        }\n    };\n}\n\ndisplay_generic_identity!(GenericLibfuncId);\ndisplay_generic_identity!(GenericTypeId);\n\nmacro_rules! display_identity {\n    ($type_name:tt) => {\n        impl fmt::Display for $type_name {\n            fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n                match &self.debug_name {\n                    Some(name) => write!(f, \"{name}\"),\n                    None => write!(f, \"[{}]\", self.id),\n                }\n            }\n        }\n    };\n}\n\ndisplay_identity!(ConcreteLibfuncId);\ndisplay_identity!(FunctionId);\ndisplay_identity!(UserTypeId);\ndisplay_identity!(VarId);\ndisplay_identity!(ConcreteTypeId);\n\nimpl fmt::Display for GenericArg {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            GenericArg::Type(id) => write!(f, \"{id}\"),\n            GenericArg::UserType(id) => write!(f, \"ut@{id}\"),\n            GenericArg::Value(v) => write!(f, \"{v}\"),\n            GenericArg::UserFunc(id) => write!(f, \"user@{id}\"),\n            GenericArg::Libfunc(id) => write!(f, \"lib@{id}\"),\n        }\n    }\n}\n\nimpl<StatementId: fmt::Display> fmt::Display for GenStatement<StatementId> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            GenStatement::Invocation(invocation) => write!(f, \"{invocation}\"),\n            GenStatement::Return(ids) => {\n                write!(f, \"return(\")?;\n                write_comma_separated(f, ids)?;\n                write!(f, \")\")\n            }\n        }\n    }\n}\n\nimpl<StatementId: fmt::Display> fmt::Display for GenInvocation<StatementId> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"{}(\", self.libfunc_id)?;\n        write_comma_separated(f, &self.args)?;\n        if let [GenBranchInfo { target: GenBranchTarget::Fallthrough, results }] =\n            &self.branches[..]\n        {\n            write!(f, \") -> (\")?;\n            write_comma_separated(f, results)?;\n            write!(f, \")\")\n        } else {\n            write!(f, \") {{ \")?;\n            self.branches.iter().try_for_each(|branch_info| write!(f, \"{branch_info} \"))?;\n            write!(f, \"}}\")\n        }\n    }\n}\n\nimpl<StatementId: fmt::Display> fmt::Display for GenBranchInfo<StatementId> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"{}(\", self.target)?;\n        write_comma_separated(f, &self.results)?;\n        write!(f, \")\")\n    }\n}\n\nimpl<StatementId: fmt::Display> fmt::Display for GenBranchTarget<StatementId> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            GenBranchTarget::Fallthrough => write!(f, \"fallthrough\"),\n            GenBranchTarget::Statement(id) => write!(f, \"{id}\"),\n        }\n    }\n}\n\nimpl fmt::Display for StatementIdx {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"{}\", self.0)\n    }\n}\n\nfn write_template_args(f: &mut fmt::Formatter<'_>, args: &[GenericArg]) -> fmt::Result {\n    if args.is_empty() {\n        Ok(())\n    } else {\n        write!(f, \"<\")?;\n        write_comma_separated(f, args)?;\n        write!(f, \">\")\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use derivative::Derivative;\nuse num_bigint::BigUint;\nuse num_traits::ToPrimitive;\nuse salsa;\nuse sha3::{Digest, Keccak256};\nuse smol_str::SmolStr;\n\nmacro_rules! define_generic_identity {\n    ($doc:literal, $type_name:ident) => {\n        #[doc=$doc]\n        #[derive(Clone, Debug, Eq, Hash, PartialEq)]\n        pub struct $type_name(pub SmolStr);\n        impl $type_name {\n            pub const fn new_inline(name: &'static str) -> Self {\n                Self(SmolStr::new_inline(name))\n            }\n\n            pub fn from_string(name: impl Into<SmolStr>) -> Self {\n                Self(name.into())\n            }\n        }\n        impl From<&str> for $type_name {\n            fn from(name: &str) -> Self {\n                Self::from_string(name.to_string())\n            }\n        }\n        impl From<String> for $type_name {\n            fn from(name: String) -> Self {\n                Self::from_string(name)\n            }\n        }\n    };\n}\n\ndefine_generic_identity!(\"The identity of a generic library function\", GenericLibfuncId);\n\ndefine_generic_identity!(\"The identity of a generic type.\", GenericTypeId);\n\nmacro_rules! define_identity {\n    ($doc:literal, $type_name:ident) => {\n        #[doc=$doc]\n        #[derive(Clone, Debug, Derivative)]\n        #[derivative(Eq, Hash, PartialEq)]\n        pub struct $type_name {\n            pub id: u64,\n            /// Optional name for testing and debugging.\n            #[derivative(Hash = \"ignore\")]\n            #[derivative(PartialEq = \"ignore\")]\n            pub debug_name: Option<SmolStr>,\n        }\n        impl $type_name {\n            pub fn new(id: u64) -> Self {\n                Self { id, debug_name: None }\n            }\n\n            pub fn from_string(name: impl Into<SmolStr>) -> Self {\n                let s: SmolStr = name.into();\n                Self { id: const_fnv1a_hash::fnv1a_hash_str_64(&s), debug_name: Some(s) }\n            }\n        }\n        impl From<&str> for $type_name {\n            fn from(name: &str) -> Self {\n                Self::from_string(name.to_string())\n            }\n        }\n        impl From<String> for $type_name {\n            fn from(name: String) -> Self {\n                Self::from_string(name)\n            }\n        }\n        impl From<u64> for $type_name {\n            fn from(id: u64) -> Self {\n                Self::new(id)\n            }\n        }\n        impl salsa::InternKey for $type_name {\n            fn from_intern_id(salsa_id: salsa::InternId) -> Self {\n                Self::new(salsa_id.as_u32() as u64)\n            }\n\n            fn as_intern_id(&self) -> salsa::InternId {\n                let id_usize: usize = self.id.try_into().unwrap();\n                id_usize.into()\n            }\n        }\n    };\n}\n\ndefine_identity!(\"The identity of a concrete library function.\", ConcreteLibfuncId);\n\ndefine_identity!(\"The identity of a user function.\", FunctionId);\n\ndefine_identity!(\"The identity of a variable.\", VarId);\n\ndefine_identity!(\"The identity of a concrete type.\", ConcreteTypeId);\n\n/// The identity of a user type.\n#[derive(Clone, Debug, Derivative)]\n#[derivative(Eq, Hash, PartialEq)]\npub struct UserTypeId {\n    pub id: BigUint,\n    /// Optional name for testing and debugging.\n    #[derivative(Hash = \"ignore\")]\n    #[derivative(PartialEq = \"ignore\")]\n    pub debug_name: Option<SmolStr>,\n}\nimpl UserTypeId {\n    pub fn from_string(name: impl Into<SmolStr>) -> Self {\n        let s: SmolStr = name.into();\n        // TODO(orizi): Extract Keccak into felt252 implementation and use it at the starknet\n        // crate as well.\n        let mut hasher = Keccak256::new();\n        hasher.update(s.as_bytes());\n        let mut result = hasher.finalize();\n        // Truncate result to 250 bits.\n        *result.first_mut().unwrap() &= 3;\n        let id = BigUint::from_bytes_be(&result);\n        Self { id, debug_name: Some(s) }\n    }\n}\nimpl From<&str> for UserTypeId {\n    fn from(name: &str) -> Self {\n        Self::from_string(name.to_string())\n    }\n}\nimpl From<String> for UserTypeId {\n    fn from(name: String) -> Self {\n        Self::from_string(name)\n    }\n}\nimpl salsa::InternKey for UserTypeId {\n    fn from_intern_id(salsa_id: salsa::InternId) -> Self {\n        Self { id: salsa_id.as_usize().into(), debug_name: None }\n    }\n\n    fn as_intern_id(&self) -> salsa::InternId {\n        self.id.to_usize().unwrap().into()\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Sierra is an intermediate representation between high level Cairo and compilation targets,\n//! such as CASM. Sierra code is guaranteed to be \"safe\"* by construction.\n//! Sierra has a primitive, yet rich typing system to express all high level code while guaranteeing\n//! safety and allowing for efficient compilation down to the target.\n//!\n//! Safety - this means a few things:\n//! 1. There are no \"panics\" / \"runtime errors\". Every function is guaranteed to return.\n//! 2. There are no infinite loops. Moreover, every program \"counts\" its own steps, and returns when\n//!    the limit is reached.\n//! 3. Builtin library functions are always used correctly.\n\nuse lalrpop_util::lalrpop_mod;\n\npub mod debug_info;\npub mod edit_state;\npub mod extensions;\npub mod fmt;\npub mod ids;\npub mod program;\npub mod program_registry;\npub mod simulation;\n#[cfg(test)]\nmod test_utils;\n\nlalrpop_mod!(\n    #[allow(clippy::all, unused_extern_crates)]\n    parser\n);\n\npub type ProgramParser = parser::ProgramParser;\npub type ConcreteLibfuncLongIdParser = parser::ConcreteLibfuncLongIdParser;\npub type ConcreteTypeLongIdParser = parser::ConcreteTypeLongIdParser;\n",
    "metadata": {}
  },
  {
    "pageContent": "use num_bigint::BigInt;\n\nuse crate::ids::{\n    ConcreteLibfuncId, ConcreteTypeId, FunctionId, GenericLibfuncId, GenericTypeId, UserTypeId,\n    VarId,\n};\n\n/// A full Sierra program.\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct Program {\n    /// Declarations for all the used types.\n    pub type_declarations: Vec<TypeDeclaration>,\n    /// Declarations for all the used library functions.\n    pub libfunc_declarations: Vec<LibfuncDeclaration>,\n    /// The code of the program.\n    pub statements: Vec<Statement>,\n    /// Descriptions of the functions - signatures and entry points.\n    pub funcs: Vec<Function>,\n}\nimpl Program {\n    pub fn get_statement(&self, id: &StatementIdx) -> Option<&Statement> {\n        self.statements.get(id.0)\n    }\n}\n\n/// Declaration of a concrete type.\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct TypeDeclaration {\n    /// The id of the declared concrete type.\n    pub id: ConcreteTypeId,\n    pub long_id: ConcreteTypeLongId,\n    pub declared_type_info: Option<DeclaredTypeInfo>,\n}\n\n/// Declaration of a concrete type info.\n#[derive(Clone, Debug, Eq, PartialEq, Hash)]\npub struct DeclaredTypeInfo {\n    /// Can the type be stored by any of the store commands.\n    pub storable: bool,\n    /// Can the type be (trivially) dropped.\n    pub droppable: bool,\n    /// Can the type be (trivially) duplicated.\n    pub duplicatable: bool,\n    /// The size of an element of this type.\n    pub size: i16,\n}\n\n/// A concrete type (the generic parent type and the generic arguments).\n#[derive(Clone, Debug, Eq, PartialEq, Hash)]\npub struct ConcreteTypeLongId {\n    /// The id of the used generic type.\n    pub generic_id: GenericTypeId,\n    /// The arguments for the generic type.\n    pub generic_args: Vec<GenericArg>,\n}\n\n/// Declaration of a concrete library function.\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct LibfuncDeclaration {\n    /// The id of the declared concrete libfunc.\n    pub id: ConcreteLibfuncId,\n    pub long_id: ConcreteLibfuncLongId,\n}\n\n/// A concrete library function (the generic parent function and the generic arguments).\n#[derive(Clone, Debug, Eq, PartialEq, Hash)]\npub struct ConcreteLibfuncLongId {\n    /// The id of the used generic libfunc.\n    pub generic_id: GenericLibfuncId,\n    /// The arguments for the specialization.\n    pub generic_args: Vec<GenericArg>,\n}\n\n/// Represents the signature of a function.\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct FunctionSignature {\n    /// The types of the parameters of the function.\n    pub param_types: Vec<ConcreteTypeId>,\n    /// The return types.\n    pub ret_types: Vec<ConcreteTypeId>,\n}\n\n/// Represents a function (its name, signature and entry point).\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct GenFunction<StatementId> {\n    /// The name of the function.\n    pub id: FunctionId,\n    /// The parameter types and return types.\n    pub signature: FunctionSignature,\n    /// The parameters of the function.\n    // TODO(lior): Consider keeping here only the var ids, instead of the full Param (the types\n    //   are stored in `signature`).\n    pub params: Vec<Param>,\n    /// The statement id where the function starts.\n    pub entry_point: StatementId,\n}\n\nimpl<StatementId> GenFunction<StatementId> {\n    pub fn new(\n        id: FunctionId,\n        params: Vec<Param>,\n        ret_types: Vec<ConcreteTypeId>,\n        entry_point: StatementId,\n    ) -> Self {\n        let param_types: Vec<_> = params.iter().map(|Param { id: _, ty }| ty.clone()).collect();\n        GenFunction {\n            id,\n            signature: FunctionSignature { param_types, ret_types },\n            params,\n            entry_point,\n        }\n    }\n}\n\n/// Descriptor of a variable.\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct Param {\n    pub id: VarId,\n    pub ty: ConcreteTypeId,\n}\n\n/// Represents the index of a Sierra statement in the Program::statements vector.\n#[derive(Clone, Copy, Debug, Eq, Hash, PartialEq)]\npub struct StatementIdx(pub usize);\nimpl StatementIdx {\n    pub fn next(&self, target: &BranchTarget) -> StatementIdx {\n        match target {\n            BranchTarget::Fallthrough => StatementIdx(self.0 + 1),\n            BranchTarget::Statement(id) => *id,\n        }\n    }\n}\n\n/// Possible arguments for generic type.\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum GenericArg {\n    UserType(UserTypeId),\n    Type(ConcreteTypeId),\n    Value(BigInt),\n    UserFunc(FunctionId),\n    Libfunc(ConcreteLibfuncId),\n}\n\n/// A possible statement.\n#[derive(Clone, Debug, Eq, PartialEq)]\npub enum GenStatement<StatementId> {\n    Invocation(GenInvocation<StatementId>),\n    Return(Vec<VarId>),\n}\n\n/// An invocation statement.\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct GenInvocation<StatementId> {\n    /// The called libfunc.\n    pub libfunc_id: ConcreteLibfuncId,\n    /// The arguments consumed by the libfunc's invocation.\n    pub args: Vec<VarId>,\n    /// The possible branches to continue to after the invocation.\n    /// The program would continue to exactly one of the branches.\n    pub branches: Vec<GenBranchInfo<StatementId>>,\n}\n\n/// Describes the flow of a chosen libfunc's branch.\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct GenBranchInfo<StatementId> {\n    /// The target the branch continues the run through.\n    pub target: GenBranchTarget<StatementId>,\n    /// The resulting identifiers from the libfunc call.\n    pub results: Vec<VarId>,\n}\n\n#[derive(Clone, Debug, Eq, PartialEq)]\npub enum GenBranchTarget<StatementId> {\n    /// Continues a run to the next statement.\n    Fallthrough,\n    /// Continues the run to provided statement.\n    Statement(StatementId),\n}\n\npub type Function = GenFunction<StatementIdx>;\npub type Statement = GenStatement<StatementIdx>;\npub type Invocation = GenInvocation<StatementIdx>;\npub type BranchInfo = GenBranchInfo<StatementIdx>;\npub type BranchTarget = GenBranchTarget<StatementIdx>;\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::hash_map::Entry;\nuse std::collections::HashMap;\n\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse thiserror::Error;\n\nuse crate::extensions::lib_func::{\n    SierraApChange, SignatureSpecializationContext, SpecializationContext,\n};\nuse crate::extensions::type_specialization_context::TypeSpecializationContext;\nuse crate::extensions::types::TypeInfo;\nuse crate::extensions::{\n    ConcreteType, ExtensionError, GenericLibfunc, GenericLibfuncEx, GenericType, GenericTypeEx,\n};\nuse crate::ids::{ConcreteLibfuncId, ConcreteTypeId, FunctionId, GenericTypeId};\nuse crate::program::{\n    DeclaredTypeInfo, Function, FunctionSignature, GenericArg, Program, TypeDeclaration,\n};\n\n#[cfg(test)]\n#[path = \"program_registry_test.rs\"]\nmod test;\n\n/// Errors encountered in the program registry.\n#[derive(Error, Debug, Eq, PartialEq)]\npub enum ProgramRegistryError {\n    #[error(\"used the same function id twice\")]\n    FunctionIdAlreadyExists(FunctionId),\n    #[error(\"Could not find the requested function\")]\n    MissingFunction(FunctionId),\n    #[error(\"Error during type specialization\")]\n    TypeSpecialization { concrete_id: ConcreteTypeId, error: ExtensionError },\n    #[error(\"Used the same concrete type id twice\")]\n    TypeConcreteIdAlreadyExists(ConcreteTypeId),\n    #[error(\"Declared the same concrete type twice\")]\n    TypeAlreadyDeclared(Box<TypeDeclaration>),\n    #[error(\"Could not find the requested type\")]\n    MissingType(ConcreteTypeId),\n    #[error(\"Error during libfunc specialization\")]\n    LibfuncSpecialization { concrete_id: ConcreteLibfuncId, error: ExtensionError },\n    #[error(\"Used the same concrete libfunc id twice\")]\n    LibfuncConcreteIdAlreadyExists(ConcreteLibfuncId),\n    #[error(\"Could not find the requested libfunc\")]\n    MissingLibfunc(ConcreteLibfuncId),\n    #[error(\"Type info declaration mismatch\")]\n    TypeInfoDeclarationMismatch(ConcreteTypeId),\n}\n\ntype TypeMap<TType> = HashMap<ConcreteTypeId, TType>;\ntype LibfuncMap<TLibfunc> = HashMap<ConcreteLibfuncId, TLibfunc>;\ntype FunctionMap = HashMap<FunctionId, Function>;\n/// Mapping from the arguments for generating a concrete type (the generic-id and the arguments) to\n/// the concrete-id that points to it.\ntype ConcreteTypeIdMap<'a> = HashMap<(GenericTypeId, &'a [GenericArg]), ConcreteTypeId>;\n\n/// Registry for the data of the compiler, for all program specific data.\npub struct ProgramRegistry<TType: GenericType, TLibfunc: GenericLibfunc> {\n    /// Mapping ids to the corresponding user function declaration from the program.\n    functions: FunctionMap,\n    /// Mapping ids to the concrete types reperesented by them.\n    concrete_types: TypeMap<TType::Concrete>,\n    /// Mapping ids to the concrete libfuncs reperesented by them.\n    concrete_libfuncs: LibfuncMap<TLibfunc::Concrete>,\n}\nimpl<TType: GenericType, TLibfunc: GenericLibfunc> ProgramRegistry<TType, TLibfunc> {\n    /// Create a registry for the program.\n    pub fn with_ap_change(\n        program: &Program,\n        function_ap_change: OrderedHashMap<FunctionId, usize>,\n    ) -> Result<ProgramRegistry<TType, TLibfunc>, Box<ProgramRegistryError>> {\n        let functions = get_functions(program)?;\n        let (concrete_types, concrete_type_ids) = get_concrete_types_maps::<TType>(program)?;\n        let concrete_libfuncs = get_concrete_libfuncs::<TType, TLibfunc>(\n            program,\n            &SpecializationContextForRegistry {\n                functions: &functions,\n                concrete_type_ids: &concrete_type_ids,\n                concrete_types: &concrete_types,\n                function_ap_change,\n            },\n        )?;\n        Ok(ProgramRegistry { functions, concrete_types, concrete_libfuncs })\n    }\n\n    pub fn new(\n        program: &Program,\n    ) -> Result<ProgramRegistry<TType, TLibfunc>, Box<ProgramRegistryError>> {\n        Self::with_ap_change(program, Default::default())\n    }\n    /// Gets a function from the input program.\n    pub fn get_function<'a>(\n        &'a self,\n        id: &FunctionId,\n    ) -> Result<&'a Function, Box<ProgramRegistryError>> {\n        self.functions\n            .get(id)\n            .ok_or_else(|| Box::new(ProgramRegistryError::MissingFunction(id.clone())))\n    }\n    /// Gets a type from the input program.\n    pub fn get_type<'a>(\n        &'a self,\n        id: &ConcreteTypeId,\n    ) -> Result<&'a TType::Concrete, Box<ProgramRegistryError>> {\n        self.concrete_types\n            .get(id)\n            .ok_or_else(|| Box::new(ProgramRegistryError::MissingType(id.clone())))\n    }\n    /// Gets a libfunc from the input program.\n    pub fn get_libfunc<'a>(\n        &'a self,\n        id: &ConcreteLibfuncId,\n    ) -> Result<&'a TLibfunc::Concrete, Box<ProgramRegistryError>> {\n        self.concrete_libfuncs\n            .get(id)\n            .ok_or_else(|| Box::new(ProgramRegistryError::MissingLibfunc(id.clone())))\n    }\n}\n\n/// Creates the functions map.\nfn get_functions(program: &Program) -> Result<FunctionMap, Box<ProgramRegistryError>> {\n    let mut functions = FunctionMap::new();\n    for func in &program.funcs {\n        match functions.entry(func.id.clone()) {\n            Entry::Occupied(_) => {\n                Err(ProgramRegistryError::FunctionIdAlreadyExists(func.id.clone()))\n            }\n            Entry::Vacant(entry) => Ok(entry.insert(func.clone())),\n        }?;\n    }\n    Ok(functions)\n}\n\nstruct TypeSpecializationContextForRegistry<'a, TType: GenericType> {\n    pub concrete_types: &'a TypeMap<TType::Concrete>,\n    pub declared_type_info: &'a TypeMap<TypeInfo>,\n}\nimpl<TType: GenericType> TypeSpecializationContext\n    for TypeSpecializationContextForRegistry<'_, TType>\n{\n    fn try_get_type_info(&self, id: ConcreteTypeId) -> Option<TypeInfo> {\n        self.declared_type_info\n            .get(&id)\n            .or_else(|| self.concrete_types.get(&id).map(|ty| ty.info()))\n            .cloned()\n    }\n}\n\n/// Creates the type-id to concrete type map, and the reverse map from generic-id and arguments to\n/// concrete-id.\nfn get_concrete_types_maps<TType: GenericType>(\n    program: &Program,\n) -> Result<(TypeMap<TType::Concrete>, ConcreteTypeIdMap<'_>), Box<ProgramRegistryError>> {\n    let mut concrete_types = HashMap::new();\n    let mut concrete_type_ids = HashMap::<(GenericTypeId, &[GenericArg]), ConcreteTypeId>::new();\n    let declared_type_info = program\n        .type_declarations\n        .iter()\n        .filter_map(|declaration| {\n            let TypeDeclaration { id, long_id, declared_type_info } = declaration;\n            let DeclaredTypeInfo { storable, droppable, duplicatable, size } =\n                declared_type_info.as_ref().cloned()?;\n            Some((\n                id.clone(),\n                TypeInfo { long_id: long_id.clone(), storable, droppable, duplicatable, size },\n            ))\n        })\n        .collect();\n    for declaration in &program.type_declarations {\n        let concrete_type = TType::specialize_by_id(\n            &TypeSpecializationContextForRegistry::<TType> {\n                concrete_types: &concrete_types,\n                declared_type_info: &declared_type_info,\n            },\n            &declaration.long_id.generic_id,\n            &declaration.long_id.generic_args,\n        )\n        .map_err(|error| {\n            Box::new(ProgramRegistryError::TypeSpecialization {\n                concrete_id: declaration.id.clone(),\n                error,\n            })\n        })?;\n        // Check that the info is consistent wiht declaration.\n        if let Some(declared_info) = declared_type_info.get(&declaration.id) {\n            if concrete_type.info() != declared_info {\n                return Err(Box::new(ProgramRegistryError::TypeInfoDeclarationMismatch(\n                    declaration.id.clone(),\n                )));\n            }\n        }\n\n        match concrete_types.entry(declaration.id.clone()) {\n            Entry::Occupied(_) => Err(Box::new(ProgramRegistryError::TypeConcreteIdAlreadyExists(\n                declaration.id.clone(),\n            ))),\n            Entry::Vacant(entry) => Ok(entry.insert(concrete_type)),\n        }?;\n        match concrete_type_ids\n            .entry((declaration.long_id.generic_id.clone(), &declaration.long_id.generic_args[..]))\n        {\n            Entry::Occupied(_) => Err(Box::new(ProgramRegistryError::TypeAlreadyDeclared(\n                Box::new(declaration.clone()),\n            ))),\n            Entry::Vacant(entry) => Ok(entry.insert(declaration.id.clone())),\n        }?;\n    }\n    Ok((concrete_types, concrete_type_ids))\n}\n\n/// Context required for specialization process.\npub struct SpecializationContextForRegistry<'a, TType: GenericType> {\n    pub functions: &'a FunctionMap,\n    pub concrete_type_ids: &'a ConcreteTypeIdMap<'a>,\n    pub concrete_types: &'a TypeMap<TType::Concrete>,\n    /// AP changes information for Sierra user functions.\n    pub function_ap_change: OrderedHashMap<FunctionId, usize>,\n}\nimpl<TType: GenericType> TypeSpecializationContext for SpecializationContextForRegistry<'_, TType> {\n    fn try_get_type_info(&self, id: ConcreteTypeId) -> Option<TypeInfo> {\n        self.concrete_types.get(&id).map(|ty| ty.info().clone())\n    }\n}\nimpl<TType: GenericType> SignatureSpecializationContext\n    for SpecializationContextForRegistry<'_, TType>\n{\n    fn try_get_concrete_type(\n        &self,\n        id: GenericTypeId,\n        generic_args: &[GenericArg],\n    ) -> Option<ConcreteTypeId> {\n        self.concrete_type_ids.get(&(id, generic_args)).cloned()\n    }\n\n    fn try_get_function_signature(&self, function_id: &FunctionId) -> Option<FunctionSignature> {\n        self.try_get_function(function_id).map(|f| f.signature)\n    }\n\n    fn as_type_specialization_context(&self) -> &dyn TypeSpecializationContext {\n        self\n    }\n\n    fn try_get_function_ap_change(&self, function_id: &FunctionId) -> Option<SierraApChange> {\n        Some(if self.function_ap_change.contains_key(function_id) {\n            SierraApChange::Known { new_vars_only: false }\n        } else {\n            SierraApChange::Unknown\n        })\n    }\n}\nimpl<TType: GenericType> SpecializationContext for SpecializationContextForRegistry<'_, TType> {\n    fn try_get_function(&self, function_id: &FunctionId) -> Option<Function> {\n        self.functions.get(function_id).cloned()\n    }\n\n    fn upcast(&self) -> &dyn SignatureSpecializationContext {\n        self\n    }\n}\n\n/// Creates the libfuncs map.\nfn get_concrete_libfuncs<TType: GenericType, TLibfunc: GenericLibfunc>(\n    program: &Program,\n    context: &SpecializationContextForRegistry<'_, TType>,\n) -> Result<LibfuncMap<TLibfunc::Concrete>, Box<ProgramRegistryError>> {\n    let mut concrete_libfuncs = HashMap::new();\n    for declaration in &program.libfunc_declarations {\n        let concrete_libfunc = TLibfunc::specialize_by_id(\n            context,\n            &declaration.long_id.generic_id,\n            &declaration.long_id.generic_args,\n        )\n        .map_err(|error| ProgramRegistryError::LibfuncSpecialization {\n            concrete_id: declaration.id.clone(),\n            error,\n        })?;\n        match concrete_libfuncs.entry(declaration.id.clone()) {\n            Entry::Occupied(_) => {\n                Err(ProgramRegistryError::LibfuncConcreteIdAlreadyExists(declaration.id.clone()))\n            }\n            Entry::Vacant(entry) => Ok(entry.insert(concrete_libfunc)),\n        }?;\n    }\n    Ok(concrete_libfuncs)\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use indoc::indoc;\nuse test_log::test;\n\nuse crate::extensions::core::{CoreLibfunc, CoreType};\nuse crate::program::{ConcreteTypeLongId, TypeDeclaration};\nuse crate::program_registry::{ProgramRegistry, ProgramRegistryError};\nuse crate::ProgramParser;\n\n#[test]\nfn basic_insertion() {\n    assert_eq!(\n        ProgramRegistry::<CoreType, CoreLibfunc>::new(\n            &ProgramParser::new()\n                .parse(indoc! {\"\n                    type u128 = u128;\n                    type GasBuiltin = GasBuiltin;\n                    type NonZeroInt = NonZero<u128>;\n                    libfunc rename_u128 = rename<u128>;\n                    libfunc rename_gb = rename<GasBuiltin>;\n                    Func1@1(a: u128, gb: GasBuiltin) -> (GasBuiltin);\n                    Func2@6() -> ();\n                \"})\n                .unwrap()\n        )\n        .map(|_| ()),\n        Ok(())\n    );\n}\n\n#[test]\nfn function_id_double_declaration() {\n    assert_eq!(\n        ProgramRegistry::<CoreType, CoreLibfunc>::new(\n            &ProgramParser::new()\n                .parse(indoc! {\"\n                    used_id@1(a: int, gb: GasBuiltin) -> (GasBuiltin);\n                    used_id@6() -> ();\n                \"})\n                .unwrap()\n        )\n        .map(|_| ()),\n        Err(Box::new(ProgramRegistryError::FunctionIdAlreadyExists(\"used_id\".into())))\n    );\n}\n\n#[test]\nfn type_id_double_declaration() {\n    assert_eq!(\n        ProgramRegistry::<CoreType, CoreLibfunc>::new(\n            &ProgramParser::new()\n                .parse(indoc! {\"\n                    type used_id = u128;\n                    type used_id = GasBuiltin;\n                    \"})\n                .unwrap()\n        )\n        .map(|_| ()),\n        Err(Box::new(ProgramRegistryError::TypeConcreteIdAlreadyExists(\"used_id\".into())))\n    );\n}\n\n#[test]\nfn concrete_type_double_declaration() {\n    let long_id = ConcreteTypeLongId { generic_id: \"u128\".into(), generic_args: vec![] };\n    assert_eq!(\n        ProgramRegistry::<CoreType, CoreLibfunc>::new(\n            &ProgramParser::new()\n                .parse(indoc! {\"\n                    type int1 = u128;\n                    type int2 = u128;\n                \"})\n                .unwrap()\n        )\n        .map(|_| ()),\n        Err(Box::new(ProgramRegistryError::TypeAlreadyDeclared(Box::new(TypeDeclaration {\n            id: \"int2\".into(),\n            long_id,\n            declared_type_info: None\n        }))))\n    );\n}\n\n#[test]\nfn libfunc_id_double_declaration() {\n    assert_eq!(\n        ProgramRegistry::<CoreType, CoreLibfunc>::new(\n            &ProgramParser::new()\n                .parse(indoc! {\"\n                    type u128 = u128;\n                    type GasBuiltin = GasBuiltin;\n                    libfunc used_id = rename<u128>;\n                    libfunc used_id = rename<GasBuiltin>;\n                \"})\n                .unwrap()\n        )\n        .map(|_| ()),\n        Err(Box::new(ProgramRegistryError::LibfuncConcreteIdAlreadyExists(\"used_id\".into())))\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashMap;\nuse std::str::FromStr;\n\nuse cairo_lang_utils::extract_matches;\nuse num_bigint::{BigInt, ToBigInt};\nuse num_traits::{ToPrimitive, Zero};\n\nuse super::value::CoreValue;\nuse super::LibfuncSimulationError;\nuse crate::extensions::array::ArrayConcreteLibfunc;\nuse crate::extensions::boolean::BoolConcreteLibfunc;\nuse crate::extensions::core::CoreConcreteLibfunc::{\n    self, ApTracking, Array, Bitwise, Bool, BranchAlign, Drop, Dup, Ec, Enum, Felt252,\n    FunctionCall, Gas, Mem, Struct, Uint128, Uint16, Uint32, Uint64, Uint8, UnconditionalJump,\n    UnwrapNonZero,\n};\nuse crate::extensions::ec::EcConcreteLibfunc;\nuse crate::extensions::enm::{EnumConcreteLibfunc, EnumInitConcreteLibfunc};\nuse crate::extensions::felt252::{\n    Felt252BinaryOpConcreteLibfunc, Felt252BinaryOperationConcrete, Felt252BinaryOperator,\n    Felt252Concrete, Felt252ConstConcreteLibfunc, Felt252OperationWithConstConcreteLibfunc,\n};\nuse crate::extensions::felt252_dict::Felt252DictConcreteLibfunc;\nuse crate::extensions::function_call::FunctionCallConcreteLibfunc;\nuse crate::extensions::gas::GasConcreteLibfunc::{GetAvailableGas, RedepositGas, WithdrawGas};\nuse crate::extensions::mem::MemConcreteLibfunc::{\n    AllocLocal, FinalizeLocals, Rename, StoreLocal, StoreTemp,\n};\nuse crate::extensions::structure::StructConcreteLibfunc;\nuse crate::extensions::uint::{\n    IntOperator, Uint16Concrete, Uint32Concrete, Uint64Concrete, Uint8Concrete,\n    UintConstConcreteLibfunc,\n};\nuse crate::extensions::uint128::Uint128Concrete;\nuse crate::ids::FunctionId;\n\n// TODO(orizi): This def is duplicated.\n/// Returns the Beta value of the Starkware elliptic curve.\nfn get_beta() -> BigInt {\n    BigInt::from_str(\"3141592653589793238462643383279502884197169399375105820974944592307816406665\")\n        .unwrap()\n}\n\n// TODO(spapini): Proper errors when converting from bigint to u128.\n/// Simulates the run of a single libfunc. Returns the value representations of the outputs, and\n/// the chosen branch given the inputs.\n///\n/// `simulate_function` is a function that simulates running of a user function. It is provided here\n/// for the case where the extensions need to use it.\npub fn simulate<\n    GetStatementGasInfo: Fn() -> Option<i64>,\n    SimulateFunction: Fn(&FunctionId, Vec<CoreValue>) -> Result<Vec<CoreValue>, LibfuncSimulationError>,\n>(\n    libfunc: &CoreConcreteLibfunc,\n    inputs: Vec<CoreValue>,\n    get_statement_gas_info: GetStatementGasInfo,\n    simulate_function: SimulateFunction,\n) -> Result<(Vec<CoreValue>, usize), LibfuncSimulationError> {\n    match libfunc {\n        Bitwise(_) => match &inputs[..] {\n            [CoreValue::Uint128(a), CoreValue::Uint128(b)] => Ok((\n                vec![\n                    CoreValue::Uint128(a & b),\n                    CoreValue::Uint128(a | b),\n                    CoreValue::Uint128(a ^ b),\n                ],\n                0,\n            )),\n            [_, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Drop(_) => match &inputs[..] {\n            [_] => Ok((vec![], 0)),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Dup(_) => match &inputs[..] {\n            [value] => Ok((vec![value.clone(), value.clone()], 0)),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Ec(libfunc) => match libfunc {\n            EcConcreteLibfunc::TryNew(_) => match &inputs[..] {\n                [CoreValue::Felt252(x), CoreValue::Felt252(y)] => {\n                    // If the point is on the curve use the fallthrough branch and return the point.\n                    if y * y == x * x * x + x + get_beta() {\n                        Ok((vec![CoreValue::EcPoint(x.clone(), y.clone())], 0))\n                    } else {\n                        Ok((vec![], 1))\n                    }\n                }\n                [_, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n                _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n            },\n            EcConcreteLibfunc::UnwrapPoint(_) => match &inputs[..] {\n                [CoreValue::EcPoint(x, y)] => {\n                    Ok((vec![CoreValue::Felt252(x.clone()), CoreValue::Felt252(y.clone())], 0))\n                }\n                [_] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n                _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n            },\n            _ => unimplemented!(),\n        },\n        FunctionCall(FunctionCallConcreteLibfunc { function, .. }) => {\n            Ok((simulate_function(&function.id, inputs)?, 0))\n        }\n        Gas(WithdrawGas(_)) => {\n            let count = get_statement_gas_info()\n                .ok_or(LibfuncSimulationError::UnresolvedStatementGasInfo)?;\n            let gas_counter = match &inputs[..] {\n                [CoreValue::RangeCheck, CoreValue::GasBuiltin(value)] => Ok(value),\n                [_, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n                _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n            }?;\n            if *gas_counter >= count {\n                // Have enough gas - return reduced counter and jump to success branch.\n                Ok((vec![CoreValue::RangeCheck, CoreValue::GasBuiltin(gas_counter - count)], 0))\n            } else {\n                // Don't have enough gas - return the same counter and jump to failure branch.\n                Ok((vec![CoreValue::RangeCheck, CoreValue::GasBuiltin(*gas_counter)], 1))\n            }\n        }\n        Gas(RedepositGas(_)) => {\n            let count = get_statement_gas_info()\n                .ok_or(LibfuncSimulationError::UnresolvedStatementGasInfo)?;\n            let gas_counter = match &inputs[..] {\n                [CoreValue::GasBuiltin(value)] => Ok(value),\n                [_] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n                _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n            }?;\n            Ok((vec![CoreValue::GasBuiltin(gas_counter + count)], 0))\n        }\n        Gas(GetAvailableGas(_)) => {\n            let gas_counter = match &inputs[..] {\n                [CoreValue::GasBuiltin(value)] => Ok(value),\n                [_] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n                _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n            }?;\n            Ok((\n                vec![CoreValue::GasBuiltin(*gas_counter), CoreValue::Uint128(*gas_counter as u128)],\n                0,\n            ))\n        }\n        BranchAlign(_) => {\n            get_statement_gas_info().ok_or(LibfuncSimulationError::UnresolvedStatementGasInfo)?;\n            Ok((vec![], 0))\n        }\n        Array(ArrayConcreteLibfunc::New(_)) => {\n            if inputs.is_empty() {\n                Ok((vec![CoreValue::Array(vec![])], 0))\n            } else {\n                Err(LibfuncSimulationError::WrongNumberOfArgs)\n            }\n        }\n        Array(ArrayConcreteLibfunc::Append(_)) => match &inputs[..] {\n            [CoreValue::Array(_), _] => {\n                let mut iter = inputs.into_iter();\n                let mut arr = extract_matches!(iter.next().unwrap(), CoreValue::Array);\n                arr.push(iter.next().unwrap());\n                Ok((vec![CoreValue::Array(arr)], 0))\n            }\n            [_, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Array(ArrayConcreteLibfunc::PopFront(_)) => match &inputs[..] {\n            [CoreValue::Array(_)] => {\n                let mut iter = inputs.into_iter();\n                let mut arr = extract_matches!(iter.next().unwrap(), CoreValue::Array);\n                if arr.is_empty() {\n                    Ok((vec![CoreValue::Array(arr)], 1))\n                } else {\n                    let front = arr.remove(0);\n                    Ok((vec![CoreValue::Array(arr), front], 0))\n                }\n            }\n            [_] => Err(LibfuncSimulationError::WrongArgType),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Array(ArrayConcreteLibfunc::Get(_)) => match &inputs[..] {\n            [CoreValue::RangeCheck, CoreValue::Array(_), CoreValue::Uint64(_)] => {\n                let mut iter = inputs.into_iter();\n                iter.next(); // Ignore range check.\n                let arr = extract_matches!(iter.next().unwrap(), CoreValue::Array);\n                let idx = extract_matches!(iter.next().unwrap(), CoreValue::Uint64) as usize;\n                match arr.get(idx).cloned() {\n                    Some(element) => Ok((vec![CoreValue::RangeCheck, element], 0)),\n                    None => Ok((vec![CoreValue::RangeCheck], 1)),\n                }\n            }\n            [_, _, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Array(ArrayConcreteLibfunc::Len(_)) => match &inputs[..] {\n            [CoreValue::Array(_)] => {\n                let arr = extract_matches!(inputs.into_iter().next().unwrap(), CoreValue::Array);\n                let len = arr.len();\n                Ok((vec![CoreValue::Uint64(len as u64)], 0))\n            }\n            [_] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Array(ArrayConcreteLibfunc::SnapshotPopFront(_)) => todo!(),\n        Uint8(libfunc) => simulate_u8_libfunc(libfunc, &inputs),\n        Uint16(libfunc) => simulate_u16_libfunc(libfunc, &inputs),\n        Uint32(libfunc) => simulate_u32_libfunc(libfunc, &inputs),\n        Uint64(libfunc) => simulate_u64_libfunc(libfunc, &inputs),\n        Uint128(libfunc) => simulate_u128_libfunc(libfunc, &inputs),\n        Bool(libfunc) => simulate_bool_libfunc(libfunc, &inputs),\n        Felt252(libfunc) => simulate_felt252_libfunc(libfunc, &inputs),\n        UnwrapNonZero(_) => match &inputs[..] {\n            [CoreValue::NonZero(value)] => Ok((vec![*value.clone()], 0)),\n            [_] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Mem(Rename(_) | StoreTemp(_)) | CoreConcreteLibfunc::Box(_) => {\n            if inputs.len() == 1 {\n                Ok((inputs, 0))\n            } else {\n                Err(LibfuncSimulationError::WrongNumberOfArgs)\n            }\n        }\n        Mem(FinalizeLocals(_)) | UnconditionalJump(_) | ApTracking(_) => {\n            if inputs.is_empty() {\n                Ok((inputs, 0))\n            } else {\n                Err(LibfuncSimulationError::WrongNumberOfArgs)\n            }\n        }\n        Mem(StoreLocal(_)) => match &inputs[..] {\n            [CoreValue::Uninitialized, other] => Ok((vec![other.clone()], 0)),\n            [_, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Mem(AllocLocal(_)) => {\n            if inputs.is_empty() {\n                Ok((vec![CoreValue::Uninitialized], 0))\n            } else {\n                Err(LibfuncSimulationError::WrongNumberOfArgs)\n            }\n        }\n        Enum(EnumConcreteLibfunc::Init(EnumInitConcreteLibfunc { index, .. })) => {\n            match &inputs[..] {\n                [input] => {\n                    // We don't verify here that the input type matches the signature.\n                    Ok((vec![CoreValue::Enum { value: Box::new(input.clone()), index: *index }], 0))\n                }\n                _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n            }\n        }\n        Enum(EnumConcreteLibfunc::Match(_) | EnumConcreteLibfunc::SnapshotMatch(_)) => {\n            match &inputs[..] {\n                [CoreValue::Enum { value, index }] => Ok((vec![*value.clone()], *index)),\n                [_] => Err(LibfuncSimulationError::WrongArgType),\n                _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n            }\n        }\n        Struct(StructConcreteLibfunc::Construct(_)) => Ok((vec![CoreValue::Struct(inputs)], 0)),\n        Struct(\n            StructConcreteLibfunc::Deconstruct(_) | StructConcreteLibfunc::SnapshotDeconstruct(_),\n        ) => match &inputs[..] {\n            [CoreValue::Struct(_)] => {\n                // Extracting the values instead of cloning them, as the match is on a reference.\n                Ok((extract_matches!(inputs.into_iter().next().unwrap(), CoreValue::Struct), 0))\n            }\n            [_] => Err(LibfuncSimulationError::WrongArgType),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        CoreConcreteLibfunc::Felt252Dict(Felt252DictConcreteLibfunc::New(_)) => {\n            if inputs.is_empty() {\n                Ok((vec![CoreValue::Dict(HashMap::new())], 0))\n            } else {\n                Err(LibfuncSimulationError::WrongNumberOfArgs)\n            }\n        }\n        CoreConcreteLibfunc::Felt252Dict(Felt252DictConcreteLibfunc::Read(_)) => {\n            match &inputs[..] {\n                [CoreValue::Dict(map), CoreValue::Felt252(key)] => {\n                    // Returns 0 as a default value.\n                    // TODO(Gil): correct this behavior when dict behavior is decided on key not\n                    // found.\n                    Ok((vec![map.get(key).map_or(CoreValue::Felt252(0.into()), |x| x.clone())], 0))\n                }\n                [_, _] => Err(LibfuncSimulationError::WrongArgType),\n                _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n            }\n        }\n        CoreConcreteLibfunc::Felt252Dict(Felt252DictConcreteLibfunc::Write(_)) => match &inputs[..]\n        {\n            [CoreValue::Dict(_), CoreValue::Felt252(_), _] => {\n                let mut iter = inputs.into_iter();\n                let mut dict = extract_matches!(iter.next().unwrap(), CoreValue::Dict);\n                let key = extract_matches!(iter.next().unwrap(), CoreValue::Felt252);\n                dict.insert(key, iter.next().unwrap());\n                Ok((vec![CoreValue::Dict(dict)], 0))\n            }\n            [_, _, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        CoreConcreteLibfunc::Felt252Dict(Felt252DictConcreteLibfunc::Squash(_)) => {\n            match &inputs[..] {\n                [CoreValue::RangeCheck, CoreValue::Dict(_)] => {\n                    let mut iter = inputs.into_iter();\n                    iter.next();\n                    // Returning the same dict since it is exactly the same as the squashed one.\n                    let dict = extract_matches!(iter.next().unwrap(), CoreValue::Dict);\n                    Ok((vec![CoreValue::RangeCheck, CoreValue::Dict(dict)], 0))\n                }\n                [_, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n                _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n            }\n        }\n        CoreConcreteLibfunc::Pedersen(_) => {\n            unimplemented!(\"Simulation of the Pedersen hash function is not implemented yet.\");\n        }\n        CoreConcreteLibfunc::BuiltinCost(_) => {\n            unimplemented!(\"Simulation of the builtin cost functionality is not implemented yet.\")\n        }\n        CoreConcreteLibfunc::StarkNet(_) => {\n            unimplemented!(\"Simulation of the StarkNet functionalities is not implemented yet.\")\n        }\n        CoreConcreteLibfunc::Nullable(_) => {\n            unimplemented!(\"Simulation of nullable is not implemented yet.\")\n        }\n        CoreConcreteLibfunc::Debug(_) => {\n            if inputs.len() == 1 {\n                let arr = extract_matches!(&inputs[0], CoreValue::Array);\n                let mut bytes = Vec::new();\n                for limb in arr {\n                    let limb = extract_matches!(limb, CoreValue::Felt252);\n                    // TODO(spapini): What to do with the sign?\n                    let (_sign, limb_bytes) = limb.to_bytes_be();\n                    // Currently, we ignore leading zeros. That might need to change.\n                    bytes.extend(limb_bytes);\n                }\n                if let Ok(s) = String::from_utf8(bytes) {\n                    print!(\"{s}\");\n                } else {\n                    println!(\"Not utf8\");\n                }\n                Ok((vec![], 0))\n            } else {\n                Err(LibfuncSimulationError::WrongNumberOfArgs)\n            }\n        }\n        CoreConcreteLibfunc::SnapshotTake(_) => match &inputs[..] {\n            [value] => Ok((vec![value.clone(), value.clone()], 0)),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        CoreConcreteLibfunc::Cast(_) => unimplemented!(),\n    }\n}\n\n/// Simulate boolean library functions.\nfn simulate_bool_libfunc(\n    libfunc: &BoolConcreteLibfunc,\n    inputs: &[CoreValue],\n) -> Result<(Vec<CoreValue>, usize), LibfuncSimulationError> {\n    match libfunc {\n        BoolConcreteLibfunc::And(_) => match inputs {\n            [CoreValue::Enum { index: a_index, .. }, CoreValue::Enum { index: b_index, .. }] => {\n                // The variant index defines the true/false \"value\". Index zero is false.\n                Ok((\n                    vec![CoreValue::Enum {\n                        value: Box::new(CoreValue::Struct(vec![])),\n                        index: usize::from(*a_index == 1_usize && *b_index == 1_usize),\n                    }],\n                    0,\n                ))\n            }\n            [_, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        BoolConcreteLibfunc::Not(_) => match inputs {\n            [CoreValue::Enum { index, .. }] => {\n                // The variant index defines the true/false \"value\". Index zero is false.\n                Ok((\n                    vec![CoreValue::Enum {\n                        value: Box::new(CoreValue::Struct(vec![])),\n                        index: 1_usize - *index,\n                    }],\n                    0,\n                ))\n            }\n            [_] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        BoolConcreteLibfunc::Xor(_) => match inputs {\n            [CoreValue::Enum { index: a_index, .. }, CoreValue::Enum { index: b_index, .. }] => {\n                // The variant index defines the true/false \"value\". Index zero is false.\n                Ok((\n                    vec![CoreValue::Enum {\n                        value: Box::new(CoreValue::Struct(vec![])),\n                        index: usize::from(*a_index != *b_index),\n                    }],\n                    0,\n                ))\n            }\n            [_, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        BoolConcreteLibfunc::Or(_) => match inputs {\n            [CoreValue::Enum { index: a_index, .. }, CoreValue::Enum { index: b_index, .. }] => {\n                let (a, b) = (*a_index, *b_index);\n                // The variant index defines the true/false \"value\". Index zero is false.\n                Ok((\n                    vec![CoreValue::Enum {\n                        value: Box::new(CoreValue::Struct(vec![])),\n                        index: usize::from(a + b > 0),\n                    }],\n                    0,\n                ))\n            }\n            [_, _] => Err(LibfuncSimulationError::WrongArgType),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        BoolConcreteLibfunc::ToFelt252(_) => match inputs {\n            [CoreValue::Enum { index, .. }] => {\n                // The variant index defines the true/false \"value\". Index zero is false.\n                Ok((vec![CoreValue::Felt252(BigInt::from(*index))], 0))\n            }\n            [_, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n    }\n}\n\n/// Simulate u128 library functions.\nfn simulate_u128_libfunc(\n    libfunc: &Uint128Concrete,\n    inputs: &[CoreValue],\n) -> Result<(Vec<CoreValue>, usize), LibfuncSimulationError> {\n    match libfunc {\n        Uint128Concrete::Const(UintConstConcreteLibfunc { c, .. }) => {\n            if inputs.is_empty() {\n                Ok((vec![CoreValue::Uint128(*c)], 0))\n            } else {\n                Err(LibfuncSimulationError::WrongNumberOfArgs)\n            }\n        }\n        Uint128Concrete::FromFelt252(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Felt252(value)] => Ok(match u128::try_from(value) {\n                Ok(value) => (vec![CoreValue::RangeCheck, CoreValue::Uint128(value)], 0),\n                Err(_) => (vec![CoreValue::RangeCheck], 1),\n            }),\n            [_, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint128Concrete::ToFelt252(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint128(value)] => {\n                Ok((vec![CoreValue::Felt252(value.to_bigint().unwrap())], 0))\n            }\n            [_] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint128Concrete::Operation(libfunc) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint128(lhs), CoreValue::Uint128(rhs)] => {\n                let (value, overflow) = match libfunc.operator {\n                    IntOperator::OverflowingAdd => lhs.overflowing_add(*rhs),\n                    IntOperator::OverflowingSub => lhs.overflowing_sub(*rhs),\n                };\n                Ok((vec![CoreValue::RangeCheck, CoreValue::Uint128(value)], usize::from(overflow)))\n            }\n            [_, _, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint128Concrete::Divmod(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint128(lhs), CoreValue::NonZero(non_zero)] => {\n                if let CoreValue::Uint128(rhs) = **non_zero {\n                    Ok((\n                        vec![\n                            CoreValue::RangeCheck,\n                            CoreValue::Uint128(lhs / rhs),\n                            CoreValue::Uint128(lhs % rhs),\n                        ],\n                        0,\n                    ))\n                } else {\n                    Err(LibfuncSimulationError::MemoryLayoutMismatch)\n                }\n            }\n            [_, _, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint128Concrete::WideMul(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint128(lhs), CoreValue::Uint128(rhs)] => {\n                let result = BigInt::from(*lhs) * BigInt::from(*rhs);\n                let u128_limit = BigInt::from(u128::MAX) + BigInt::from(1);\n                Ok((\n                    vec![\n                        CoreValue::RangeCheck,\n                        CoreValue::Uint128(\n                            (result.clone() / u128_limit.clone()).to_u128().unwrap(),\n                        ),\n                        CoreValue::Uint128((result % u128_limit).to_u128().unwrap()),\n                    ],\n                    0,\n                ))\n            }\n            [_, _, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint128Concrete::IsZero(_) => {\n            match inputs {\n                [CoreValue::Uint128(value)] if *value == 0 => {\n                    // Zero - jumping to the failure branch.\n                    Ok((vec![], 0))\n                }\n                [CoreValue::Uint128(value)] if *value != 0 => {\n                    // Non-zero - jumping to the success branch and providing a NonZero wrap to the\n                    // given value.\n                    Ok((vec![CoreValue::NonZero(Box::new(CoreValue::Uint128(*value)))], 1))\n                }\n                [_] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n                _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n            }\n        }\n        Uint128Concrete::LessThan(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint128(a), CoreValue::Uint128(b)] => {\n                // \"False\" branch (branch 0) is the case a >= b.\n                // \"True\" branch (branch 1) is the case a < b.\n                Ok((vec![CoreValue::RangeCheck], usize::from(a < b)))\n            }\n            [_, _, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint128Concrete::SquareRoot(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint128(value)] => {\n                let root = BigInt::from(*value).sqrt();\n                Ok((vec![CoreValue::RangeCheck, CoreValue::Uint128(root.to_u128().unwrap())], 0))\n            }\n            [_, _] => Err(LibfuncSimulationError::WrongArgType),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint128Concrete::Equal(_) => match inputs {\n            [CoreValue::Uint128(a), CoreValue::Uint128(b)] => {\n                // \"False\" branch (branch 0) is the case a != b.\n                // \"True\" branch (branch 1) is the case a == b.\n                Ok((vec![], usize::from(a == b)))\n            }\n            [_, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint128Concrete::LessThanOrEqual(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint128(a), CoreValue::Uint128(b)] => {\n                // \"False\" branch (branch 0) is the case a > b.\n                // \"True\" branch (branch 1) is the case a <= b.\n                Ok((vec![CoreValue::RangeCheck], usize::from(a <= b)))\n            }\n            [_, _, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n    }\n}\n\n/// Simulate u8 library functions.\nfn simulate_u8_libfunc(\n    libfunc: &Uint8Concrete,\n    inputs: &[CoreValue],\n) -> Result<(Vec<CoreValue>, usize), LibfuncSimulationError> {\n    match libfunc {\n        Uint8Concrete::Const(UintConstConcreteLibfunc { c, .. }) => {\n            if inputs.is_empty() {\n                Ok((vec![CoreValue::Uint8(*c)], 0))\n            } else {\n                Err(LibfuncSimulationError::WrongNumberOfArgs)\n            }\n        }\n        Uint8Concrete::Operation(libfunc) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint8(lhs), CoreValue::Uint8(rhs)] => {\n                let (value, overflow) = match libfunc.operator {\n                    IntOperator::OverflowingAdd => lhs.overflowing_add(*rhs),\n                    IntOperator::OverflowingSub => lhs.overflowing_sub(*rhs),\n                };\n                Ok((vec![CoreValue::RangeCheck, CoreValue::Uint8(value)], usize::from(overflow)))\n            }\n            [_, _, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint8Concrete::LessThan(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint8(a), CoreValue::Uint8(b)] => {\n                // \"False\" branch (branch 0) is the case a >= b.\n                // \"True\" branch (branch 1) is the case a < b.\n                Ok((vec![CoreValue::RangeCheck], usize::from(a < b)))\n            }\n            [_, _, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint8Concrete::SquareRoot(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint8(value)] => {\n                let root = BigInt::from(*value).sqrt();\n                Ok((vec![CoreValue::RangeCheck, CoreValue::Uint8(root.to_u8().unwrap())], 0))\n            }\n            [_, _] => Err(LibfuncSimulationError::WrongArgType),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint8Concrete::Equal(_) => match inputs {\n            [CoreValue::Uint8(a), CoreValue::Uint8(b)] => {\n                // \"False\" branch (branch 0) is the case a != b.\n                // \"True\" branch (branch 1) is the case a == b.\n                Ok((vec![], usize::from(a == b)))\n            }\n            [_, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint8Concrete::LessThanOrEqual(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint8(a), CoreValue::Uint8(b)] => {\n                // \"False\" branch (branch 0) is the case a > b.\n                // \"True\" branch (branch 1) is the case a <= b.\n                Ok((vec![CoreValue::RangeCheck], usize::from(a <= b)))\n            }\n            [_, _, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint8Concrete::ToFelt252(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint8(value)] => {\n                Ok((vec![CoreValue::Felt252(value.to_bigint().unwrap())], 0))\n            }\n            [_] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint8Concrete::FromFelt252(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Felt252(value)] => Ok(match u8::try_from(value) {\n                Ok(value) => (vec![CoreValue::RangeCheck, CoreValue::Uint8(value)], 0),\n                Err(_) => (vec![CoreValue::RangeCheck], 1),\n            }),\n            [_, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint8Concrete::IsZero(_) => unimplemented!(),\n        Uint8Concrete::Divmod(_) => unimplemented!(),\n        Uint8Concrete::WideMul(_) => match inputs {\n            [CoreValue::Uint8(lhs), CoreValue::Uint8(rhs)] => {\n                Ok((vec![CoreValue::Uint16(u16::from(*lhs) * u16::from(*rhs))], 0))\n            }\n            [_, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n    }\n}\n\n/// Simulate u16 library functions.\nfn simulate_u16_libfunc(\n    libfunc: &Uint16Concrete,\n    inputs: &[CoreValue],\n) -> Result<(Vec<CoreValue>, usize), LibfuncSimulationError> {\n    match libfunc {\n        Uint16Concrete::Const(UintConstConcreteLibfunc { c, .. }) => {\n            if inputs.is_empty() {\n                Ok((vec![CoreValue::Uint16(*c)], 0))\n            } else {\n                Err(LibfuncSimulationError::WrongNumberOfArgs)\n            }\n        }\n        Uint16Concrete::Operation(libfunc) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint16(lhs), CoreValue::Uint16(rhs)] => {\n                let (value, overflow) = match libfunc.operator {\n                    IntOperator::OverflowingAdd => lhs.overflowing_add(*rhs),\n                    IntOperator::OverflowingSub => lhs.overflowing_sub(*rhs),\n                };\n                Ok((vec![CoreValue::RangeCheck, CoreValue::Uint16(value)], usize::from(overflow)))\n            }\n            [_, _, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint16Concrete::LessThan(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint16(a), CoreValue::Uint16(b)] => {\n                // \"False\" branch (branch 0) is the case a >= b.\n                // \"True\" branch (branch 1) is the case a < b.\n                Ok((vec![CoreValue::RangeCheck], usize::from(a < b)))\n            }\n            [_, _, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint16Concrete::SquareRoot(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint16(value)] => {\n                let root = BigInt::from(*value).sqrt();\n                Ok((vec![CoreValue::RangeCheck, CoreValue::Uint16(root.to_u16().unwrap())], 0))\n            }\n            [_, _] => Err(LibfuncSimulationError::WrongArgType),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint16Concrete::Equal(_) => match inputs {\n            [CoreValue::Uint16(a), CoreValue::Uint16(b)] => {\n                // \"False\" branch (branch 0) is the case a != b.\n                // \"True\" branch (branch 1) is the case a == b.\n                Ok((vec![], usize::from(a == b)))\n            }\n            [_, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint16Concrete::LessThanOrEqual(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint16(a), CoreValue::Uint16(b)] => {\n                // \"False\" branch (branch 0) is the case a > b.\n                // \"True\" branch (branch 1) is the case a <= b.\n                Ok((vec![CoreValue::RangeCheck], usize::from(a <= b)))\n            }\n            [_, _, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint16Concrete::ToFelt252(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint16(value)] => {\n                Ok((vec![CoreValue::Felt252(value.to_bigint().unwrap())], 0))\n            }\n            [_] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint16Concrete::FromFelt252(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Felt252(value)] => Ok(match u16::try_from(value) {\n                Ok(value) => (vec![CoreValue::RangeCheck, CoreValue::Uint16(value)], 0),\n                Err(_) => (vec![CoreValue::RangeCheck], 1),\n            }),\n            [_, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint16Concrete::IsZero(_) => unimplemented!(),\n        Uint16Concrete::Divmod(_) => unimplemented!(),\n        Uint16Concrete::WideMul(_) => match inputs {\n            [CoreValue::Uint16(lhs), CoreValue::Uint16(rhs)] => {\n                Ok((vec![CoreValue::Uint32(u32::from(*lhs) * u32::from(*rhs))], 0))\n            }\n            [_, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n    }\n}\n\n/// Simulate u32 library functions.\nfn simulate_u32_libfunc(\n    libfunc: &Uint32Concrete,\n    inputs: &[CoreValue],\n) -> Result<(Vec<CoreValue>, usize), LibfuncSimulationError> {\n    match libfunc {\n        Uint32Concrete::Const(UintConstConcreteLibfunc { c, .. }) => {\n            if inputs.is_empty() {\n                Ok((vec![CoreValue::Uint32(*c)], 0))\n            } else {\n                Err(LibfuncSimulationError::WrongNumberOfArgs)\n            }\n        }\n        Uint32Concrete::Operation(libfunc) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint32(lhs), CoreValue::Uint32(rhs)] => {\n                let (value, overflow) = match libfunc.operator {\n                    IntOperator::OverflowingAdd => lhs.overflowing_add(*rhs),\n                    IntOperator::OverflowingSub => lhs.overflowing_sub(*rhs),\n                };\n                Ok((vec![CoreValue::RangeCheck, CoreValue::Uint32(value)], usize::from(overflow)))\n            }\n            [_, _, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint32Concrete::LessThan(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint32(a), CoreValue::Uint32(b)] => {\n                // \"False\" branch (branch 0) is the case a >= b.\n                // \"True\" branch (branch 1) is the case a < b.\n                Ok((vec![CoreValue::RangeCheck], usize::from(a < b)))\n            }\n            [_, _, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint32Concrete::SquareRoot(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint32(value)] => {\n                let root = BigInt::from(*value).sqrt();\n                Ok((vec![CoreValue::RangeCheck, CoreValue::Uint32(root.to_u32().unwrap())], 0))\n            }\n            [_, _] => Err(LibfuncSimulationError::WrongArgType),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint32Concrete::Equal(_) => match inputs {\n            [CoreValue::Uint32(a), CoreValue::Uint32(b)] => {\n                // \"False\" branch (branch 0) is the case a != b.\n                // \"True\" branch (branch 1) is the case a == b.\n                Ok((vec![], usize::from(a == b)))\n            }\n            [_, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint32Concrete::LessThanOrEqual(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint32(a), CoreValue::Uint32(b)] => {\n                // \"False\" branch (branch 0) is the case a > b.\n                // \"True\" branch (branch 1) is the case a <= b.\n                Ok((vec![CoreValue::RangeCheck], usize::from(a <= b)))\n            }\n            [_, _, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint32Concrete::ToFelt252(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint32(value)] => {\n                Ok((vec![CoreValue::Felt252(value.to_bigint().unwrap())], 0))\n            }\n            [_] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint32Concrete::FromFelt252(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Felt252(value)] => Ok(match u32::try_from(value) {\n                Ok(value) => (vec![CoreValue::RangeCheck, CoreValue::Uint32(value)], 0),\n                Err(_) => (vec![CoreValue::RangeCheck], 1),\n            }),\n            [_, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint32Concrete::IsZero(_) => unimplemented!(),\n        Uint32Concrete::Divmod(_) => unimplemented!(),\n        Uint32Concrete::WideMul(_) => match inputs {\n            [CoreValue::Uint32(lhs), CoreValue::Uint32(rhs)] => {\n                Ok((vec![CoreValue::Uint64(u64::from(*lhs) * u64::from(*rhs))], 0))\n            }\n            [_, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n    }\n}\n\n/// Simulate u64 library functions.\nfn simulate_u64_libfunc(\n    libfunc: &Uint64Concrete,\n    inputs: &[CoreValue],\n) -> Result<(Vec<CoreValue>, usize), LibfuncSimulationError> {\n    match libfunc {\n        Uint64Concrete::Const(UintConstConcreteLibfunc { c, .. }) => {\n            if inputs.is_empty() {\n                Ok((vec![CoreValue::Uint64(*c)], 0))\n            } else {\n                Err(LibfuncSimulationError::WrongNumberOfArgs)\n            }\n        }\n        Uint64Concrete::Operation(libfunc) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint64(lhs), CoreValue::Uint64(rhs)] => {\n                let (value, overflow) = match libfunc.operator {\n                    IntOperator::OverflowingAdd => lhs.overflowing_add(*rhs),\n                    IntOperator::OverflowingSub => lhs.overflowing_sub(*rhs),\n                };\n                Ok((vec![CoreValue::RangeCheck, CoreValue::Uint64(value)], usize::from(overflow)))\n            }\n            [_, _, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint64Concrete::LessThan(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint64(a), CoreValue::Uint64(b)] => {\n                // \"False\" branch (branch 0) is the case a >= b.\n                // \"True\" branch (branch 1) is the case a < b.\n                Ok((vec![CoreValue::RangeCheck], usize::from(a < b)))\n            }\n            [_, _, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint64Concrete::SquareRoot(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint64(value)] => {\n                let root = BigInt::from(*value).sqrt();\n                Ok((vec![CoreValue::RangeCheck, CoreValue::Uint64(root.to_u64().unwrap())], 0))\n            }\n            [_, _] => Err(LibfuncSimulationError::WrongArgType),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint64Concrete::Equal(_) => match inputs {\n            [CoreValue::Uint64(a), CoreValue::Uint64(b)] => {\n                // \"False\" branch (branch 0) is the case a != b.\n                // \"True\" branch (branch 1) is the case a == b.\n                Ok((vec![], usize::from(a == b)))\n            }\n            [_, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint64Concrete::LessThanOrEqual(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint64(a), CoreValue::Uint64(b)] => {\n                // \"False\" branch (branch 0) is the case a > b.\n                // \"True\" branch (branch 1) is the case a <= b.\n                Ok((vec![CoreValue::RangeCheck], usize::from(a <= b)))\n            }\n            [_, _, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint64Concrete::ToFelt252(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Uint64(value)] => {\n                Ok((vec![CoreValue::Felt252(value.to_bigint().unwrap())], 0))\n            }\n            [_] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint64Concrete::FromFelt252(_) => match inputs {\n            [CoreValue::RangeCheck, CoreValue::Felt252(value)] => Ok(match u64::try_from(value) {\n                Ok(value) => (vec![CoreValue::RangeCheck, CoreValue::Uint64(value)], 0),\n                Err(_) => (vec![CoreValue::RangeCheck], 1),\n            }),\n            [_, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Uint64Concrete::IsZero(_) => unimplemented!(),\n        Uint64Concrete::Divmod(_) => unimplemented!(),\n        Uint64Concrete::WideMul(_) => match inputs {\n            [CoreValue::Uint64(lhs), CoreValue::Uint64(rhs)] => {\n                Ok((vec![CoreValue::Uint128(u128::from(*lhs) * u128::from(*rhs))], 0))\n            }\n            [_, _] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n    }\n}\n\n/// Simulate felt252 library functions.\nfn simulate_felt252_libfunc(\n    libfunc: &Felt252Concrete,\n    inputs: &[CoreValue],\n) -> Result<(Vec<CoreValue>, usize), LibfuncSimulationError> {\n    match libfunc {\n        Felt252Concrete::Const(Felt252ConstConcreteLibfunc { c, .. }) => {\n            if inputs.is_empty() {\n                Ok((vec![CoreValue::Felt252(c.to_bigint().unwrap())], 0))\n            } else {\n                Err(LibfuncSimulationError::WrongNumberOfArgs)\n            }\n        }\n        Felt252Concrete::BinaryOperation(Felt252BinaryOperationConcrete::WithVar(\n            Felt252BinaryOpConcreteLibfunc { operator, .. },\n        )) => match (inputs, operator) {\n            (\n                [CoreValue::Felt252(lhs), CoreValue::Felt252(rhs)],\n                Felt252BinaryOperator::Add\n                | Felt252BinaryOperator::Sub\n                | Felt252BinaryOperator::Mul,\n            ) => Ok((\n                vec![CoreValue::Felt252(match operator {\n                    Felt252BinaryOperator::Add => lhs + rhs,\n                    Felt252BinaryOperator::Sub => lhs - rhs,\n                    Felt252BinaryOperator::Mul => lhs * rhs,\n                    _ => unreachable!(\"Arm only handles these cases.\"),\n                })],\n                0,\n            )),\n            (\n                [CoreValue::Felt252(_lhs), CoreValue::NonZero(non_zero)],\n                Felt252BinaryOperator::Div,\n            ) => {\n                if let CoreValue::Felt252(_rhs) = *non_zero.clone() {\n                    todo!(\"Support felt252_div operation.\")\n                } else {\n                    Err(LibfuncSimulationError::MemoryLayoutMismatch)\n                }\n            }\n            ([_, _], _) => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Felt252Concrete::BinaryOperation(Felt252BinaryOperationConcrete::WithConst(\n            Felt252OperationWithConstConcreteLibfunc { operator, c, .. },\n        )) => match inputs {\n            [CoreValue::Felt252(value)] => Ok((\n                vec![CoreValue::Felt252(match operator {\n                    Felt252BinaryOperator::Add => value + c.clone(),\n                    Felt252BinaryOperator::Sub => value - c.clone(),\n                    Felt252BinaryOperator::Mul => value * c.clone(),\n                    Felt252BinaryOperator::Div => todo!(\"Support full felt252 operations.\"),\n                })],\n                0,\n            )),\n            [_] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n            _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n        },\n        Felt252Concrete::IsZero(_) => {\n            match inputs {\n                [CoreValue::Felt252(value)] if value.is_zero() => {\n                    // Zero - jumping to the failure branch.\n                    Ok((vec![], 0))\n                }\n                [CoreValue::Felt252(value)] if !value.is_zero() => {\n                    // Non-zero - jumping to the success branch and providing a NonZero wrap to the\n                    // given value.\n                    Ok((vec![CoreValue::NonZero(Box::new(CoreValue::Felt252(value.clone())))], 1))\n                }\n                [_] => Err(LibfuncSimulationError::MemoryLayoutMismatch),\n                _ => Err(LibfuncSimulationError::WrongNumberOfArgs),\n            }\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashMap;\n\nuse itertools::izip;\nuse thiserror::Error;\n\nuse self::value::CoreValue;\nuse crate::edit_state::{put_results, take_args, EditStateError};\nuse crate::extensions::core::{CoreConcreteLibfunc, CoreLibfunc, CoreType};\nuse crate::ids::{FunctionId, VarId};\nuse crate::program::{Program, Statement, StatementIdx};\nuse crate::program_registry::{ProgramRegistry, ProgramRegistryError};\n\npub mod core;\n#[cfg(test)]\nmod test;\npub mod value;\n\n/// Error occurring while simulating a libfunc.\n#[derive(Error, Debug, Eq, PartialEq)]\npub enum LibfuncSimulationError {\n    #[error(\"Expected different number of arguments\")]\n    WrongNumberOfArgs,\n    #[error(\"Expected a different type of an argument\")]\n    WrongArgType,\n    #[error(\"Expected a different memory layout\")]\n    MemoryLayoutMismatch,\n    #[error(\"Could not resolve requested symbol value\")]\n    UnresolvedStatementGasInfo,\n    #[error(\"Error occurred during user function call\")]\n    FunctionSimulationError(FunctionId, Box<SimulationError>),\n}\n\n/// Error occurring while simulating a program function.\n#[derive(Error, Debug, Eq, PartialEq)]\npub enum SimulationError {\n    #[error(\"error from the program registry\")]\n    ProgramRegistryError(#[from] Box<ProgramRegistryError>),\n    #[error(\"error from editing a variable state\")]\n    EditStateError(EditStateError, StatementIdx),\n    #[error(\"error from simulating a libfunc\")]\n    LibfuncSimulationError(LibfuncSimulationError, StatementIdx),\n    #[error(\"jumped out of bounds during simulation\")]\n    StatementOutOfBounds(StatementIdx),\n    #[error(\"unexpected number of arguments to function\")]\n    FunctionArgumentCountMismatch { function_id: FunctionId, expected: usize, actual: usize },\n    #[error(\"identifiers left at function return\")]\n    FunctionDidNotConsumeAllArgs(FunctionId, StatementIdx),\n}\n\n/// Runs a function from the program with the given inputs.\npub fn run(\n    program: &Program,\n    statement_gas_info: &HashMap<StatementIdx, i64>,\n    function_id: &FunctionId,\n    inputs: Vec<CoreValue>,\n) -> Result<Vec<CoreValue>, SimulationError> {\n    let context = SimulationContext {\n        program,\n        statement_gas_info,\n        registry: &ProgramRegistry::new(program)?,\n    };\n    context.simulate_function(function_id, inputs)\n}\n\n/// Helper class for runing the simulation.\nstruct SimulationContext<'a> {\n    pub program: &'a Program,\n    pub statement_gas_info: &'a HashMap<StatementIdx, i64>,\n    pub registry: &'a ProgramRegistry<CoreType, CoreLibfunc>,\n}\nimpl SimulationContext<'_> {\n    /// Simulates the run of a function, even recursively.\n    fn simulate_function(\n        &self,\n        function_id: &FunctionId,\n        inputs: Vec<CoreValue>,\n    ) -> Result<Vec<CoreValue>, SimulationError> {\n        let func = self.registry.get_function(function_id)?;\n        let mut current_statement_id = func.entry_point;\n        if func.params.len() != inputs.len() {\n            return Err(SimulationError::FunctionArgumentCountMismatch {\n                function_id: func.id.clone(),\n                expected: func.params.len(),\n                actual: inputs.len(),\n            });\n        }\n        let mut state = HashMap::<VarId, CoreValue>::from_iter(\n            izip!(func.params.iter(), inputs.into_iter())\n                .map(|(param, input)| (param.id.clone(), input)),\n        );\n        loop {\n            let statement = self\n                .program\n                .get_statement(&current_statement_id)\n                .ok_or(SimulationError::StatementOutOfBounds(current_statement_id))?;\n            match statement {\n                Statement::Return(ids) => {\n                    let (remaining, outputs) = take_args(state, ids.iter()).map_err(|error| {\n                        SimulationError::EditStateError(error, current_statement_id)\n                    })?;\n                    return if remaining.is_empty() {\n                        Ok(outputs)\n                    } else {\n                        Err(SimulationError::FunctionDidNotConsumeAllArgs(\n                            func.id.clone(),\n                            current_statement_id,\n                        ))\n                    };\n                }\n                Statement::Invocation(invocation) => {\n                    let (remaining, inputs) =\n                        take_args(state, invocation.args.iter()).map_err(|error| {\n                            SimulationError::EditStateError(error, current_statement_id)\n                        })?;\n                    let libfunc = self.registry.get_libfunc(&invocation.libfunc_id)?;\n                    let (outputs, chosen_branch) = self.simulate_libfunc(\n                        &current_statement_id,\n                        libfunc,\n                        inputs,\n                        current_statement_id,\n                    )?;\n                    let branch_info = &invocation.branches[chosen_branch];\n                    state = put_results(\n                        remaining,\n                        izip!(branch_info.results.iter(), outputs.into_iter()),\n                    )\n                    .map_err(|error| {\n                        SimulationError::EditStateError(error, current_statement_id)\n                    })?;\n                    current_statement_id = current_statement_id.next(&branch_info.target);\n                }\n            }\n        }\n    }\n    /// Simulates the run of libfuncs. Returns the memory reperesentations of the outputs given the\n    /// inputs.\n    fn simulate_libfunc(\n        &self,\n        idx: &StatementIdx,\n        libfunc: &CoreConcreteLibfunc,\n        inputs: Vec<CoreValue>,\n        current_statement_id: StatementIdx,\n    ) -> Result<(Vec<CoreValue>, usize), SimulationError> {\n        core::simulate(\n            libfunc,\n            inputs,\n            || self.statement_gas_info.get(idx).copied(),\n            |function_id, inputs| {\n                self.simulate_function(function_id, inputs).map_err(|error| {\n                    LibfuncSimulationError::FunctionSimulationError(\n                        function_id.clone(),\n                        Box::new(error),\n                    )\n                })\n            },\n        )\n        .map_err(|error| SimulationError::LibfuncSimulationError(error, current_statement_id))\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use bimap::BiMap;\nuse num_bigint::BigInt;\nuse test_case::test_case;\n\nuse super::value::CoreValue::{\n    self, Array, GasBuiltin, NonZero, RangeCheck, Uint128, Uint64, Uninitialized,\n};\nuse super::LibfuncSimulationError::{\n    self, FunctionSimulationError, MemoryLayoutMismatch, WrongNumberOfArgs,\n};\nuse super::{core, SimulationError};\nuse crate::extensions::core::CoreLibfunc;\nuse crate::extensions::lib_func::{\n    SierraApChange, SignatureSpecializationContext, SpecializationContext,\n};\nuse crate::extensions::type_specialization_context::TypeSpecializationContext;\nuse crate::extensions::types::TypeInfo;\nuse crate::extensions::GenericLibfunc;\nuse crate::ids::{ConcreteTypeId, FunctionId, GenericTypeId};\nuse crate::program::{ConcreteTypeLongId, Function, FunctionSignature, GenericArg, StatementIdx};\nuse crate::test_utils::build_bijective_mapping;\n\nfn type_arg(name: &str) -> GenericArg {\n    GenericArg::Type(name.into())\n}\n\nfn value_arg(v: i64) -> GenericArg {\n    GenericArg::Value(BigInt::from(v))\n}\n\nfn user_func_arg(name: &str) -> GenericArg {\n    GenericArg::UserFunc(name.into())\n}\n\nstruct MockSpecializationContext {\n    mapping: BiMap<ConcreteTypeId, ConcreteTypeLongId>,\n}\nimpl MockSpecializationContext {\n    pub fn new() -> Self {\n        Self { mapping: build_bijective_mapping() }\n    }\n}\n\nimpl SpecializationContext for MockSpecializationContext {\n    fn upcast(&self) -> &dyn SignatureSpecializationContext {\n        self\n    }\n\n    fn try_get_function(&self, function_id: &FunctionId) -> Option<Function> {\n        [\"drop_all_inputs\", \"identity\", \"unimplemented\"]\n            .into_iter()\n            .map(|name| -> FunctionId { name.into() })\n            .find(|id: &FunctionId| id == function_id)\n            .map(|_| Function::new(function_id.clone(), vec![], vec![], StatementIdx(0)))\n    }\n}\nimpl TypeSpecializationContext for MockSpecializationContext {\n    fn try_get_type_info(&self, id: ConcreteTypeId) -> Option<TypeInfo> {\n        if id == \"u128\".into() || id == \"u64\".into() || id == \"NonZeroInt\".into() {\n            Some(TypeInfo {\n                long_id: self.mapping.get_by_left(&id)?.clone(),\n                storable: true,\n                droppable: true,\n                duplicatable: true,\n                size: 1,\n            })\n        } else if id == \"UninitializedInt\".into() {\n            Some(TypeInfo {\n                long_id: self.mapping.get_by_left(&id)?.clone(),\n                storable: false,\n                droppable: true,\n                duplicatable: false,\n                size: 0,\n            })\n        } else if id == \"ArrayU128\".into() {\n            Some(TypeInfo {\n                long_id: self.mapping.get_by_left(&id)?.clone(),\n                storable: true,\n                droppable: true,\n                duplicatable: false,\n                size: 2,\n            })\n        } else {\n            None\n        }\n    }\n}\nimpl SignatureSpecializationContext for MockSpecializationContext {\n    fn try_get_concrete_type(\n        &self,\n        id: GenericTypeId,\n        generic_args: &[GenericArg],\n    ) -> Option<ConcreteTypeId> {\n        self.mapping\n            .get_by_right(&ConcreteTypeLongId {\n                generic_id: id,\n                generic_args: generic_args.to_vec(),\n            })\n            .cloned()\n    }\n\n    fn try_get_function_signature(&self, function_id: &FunctionId) -> Option<FunctionSignature> {\n        self.try_get_function(function_id).map(|f| f.signature)\n    }\n\n    fn as_type_specialization_context(&self) -> &dyn TypeSpecializationContext {\n        self\n    }\n\n    fn try_get_function_ap_change(&self, _function_id: &FunctionId) -> Option<SierraApChange> {\n        Some(SierraApChange::Unknown)\n    }\n}\n\n/// Expects to find a libfunc and simulate it.\nfn simulate(\n    id: &str,\n    generic_args: Vec<GenericArg>,\n    inputs: Vec<CoreValue>,\n) -> Result<(Vec<CoreValue>, usize), LibfuncSimulationError> {\n    core::simulate(\n        &CoreLibfunc::by_id(&id.into())\n            .unwrap()\n            .specialize(&MockSpecializationContext::new(), &generic_args)\n            .unwrap(),\n        inputs,\n        || Some(4),\n        |id, inputs| {\n            if id == &\"drop_all_inputs\".into() {\n                Ok(vec![])\n            } else if id == &\"identity\".into() {\n                Ok(inputs)\n            } else {\n                Err(FunctionSimulationError(\n                    id.clone(),\n                    Box::new(SimulationError::StatementOutOfBounds(StatementIdx(0))),\n                ))\n            }\n        },\n    )\n}\n\n#[test_case(\"withdraw_gas\", vec![], vec![RangeCheck, GasBuiltin(5)]\n             => Ok((vec![RangeCheck, GasBuiltin(1)], 0)); \"withdraw_gas(5)\")]\n#[test_case(\"withdraw_gas\", vec![], vec![RangeCheck, GasBuiltin(2)]\n             => Ok((vec![RangeCheck, GasBuiltin(2)], 1)); \"withdraw_gas(2)\")]\n#[test_case(\"u128_is_zero\", vec![], vec![Uint128(2)]\n             => Ok((vec![NonZero(Box::new(Uint128(2)))], 1)); \"u128_is_zero(2)\")]\n#[test_case(\"u128_is_zero\", vec![], vec![Uint128(0)] => Ok((vec![], 0)); \"u128_is_zero(0)\")]\n#[test_case(\"jump\", vec![], vec![] => Ok((vec![], 0)); \"jump()\")]\n#[test_case(\"u128_overflowing_add\", vec![], vec![RangeCheck, Uint128(2), Uint128(3)]\n             => Ok((vec![RangeCheck, Uint128(5)], 0));\n            \"u128_overflowing_add(2, 3)\")]\n#[test_case(\"u128_overflowing_sub\", vec![], vec![RangeCheck, Uint128(5), Uint128(3)]\n             => Ok((vec![RangeCheck, Uint128(2)], 0));\n            \"u128_overflowing_sub(5, 3)\")]\n#[test_case(\"u128_overflowing_sub\", vec![], vec![RangeCheck, Uint128(3), Uint128(5)]\n             => Ok((vec![RangeCheck, Uint128(u128::MAX - 1)], 1));\n            \"u128_overflowing_sub(3, 5)\")]\nfn simulate_branch(\n    id: &str,\n    generic_args: Vec<GenericArg>,\n    inputs: Vec<CoreValue>,\n) -> Result<(Vec<CoreValue>, usize), LibfuncSimulationError> {\n    simulate(id, generic_args, inputs)\n}\n\n/// Tests for simulation of a non branch invocations.\n#[test_case(\"redeposit_gas\", vec![], vec![GasBuiltin(2)] => Ok(vec![GasBuiltin(6)]); \"redeposit_gas(2)\")]\n#[test_case(\"array_new\", vec![type_arg(\"u128\")], vec![] => Ok(vec![Array(vec![])]); \"array_new()\")]\n#[test_case(\"array_append\", vec![type_arg(\"u128\")], vec![Array(vec![]), Uint128(4)] =>\n            Ok(vec![Array(vec![Uint128(4)])]); \"array_append([], 4)\")]\n#[test_case(\"array_get\", vec![type_arg(\"u128\")], vec![RangeCheck, Array(vec![Uint128(5)]), Uint64(0)]\n             => Ok(vec![RangeCheck, Uint128(5)]); \"array_get([5], 0)\")]\n#[test_case(\"array_len\", vec![type_arg(\"u128\")], vec![Array(vec![])] =>\n            Ok(vec![Uint64(0)]); \"array_len([])\")]\n#[test_case(\"u128_safe_divmod\", vec![], vec![RangeCheck, Uint128(32), NonZero(Box::new(Uint128(5)))]\n             => Ok(vec![RangeCheck, Uint128(6), Uint128(2)]); \"u128_safe_divmod(32, 5)\")]\n#[test_case(\"u128_const\", vec![value_arg(3)], vec![] => Ok(vec![Uint128(3)]);\n            \"u128_const<3>()\")]\n#[test_case(\"dup\", vec![type_arg(\"u128\")], vec![Uint128(24)]\n             => Ok(vec![Uint128(24), Uint128(24)]); \"dup<u128>(24)\")]\n#[test_case(\"drop\", vec![type_arg(\"u128\")], vec![Uint128(2)] => Ok(vec![]); \"drop<u128>(2)\")]\n#[test_case(\"unwrap_non_zero\", vec![type_arg(\"u128\")], vec![NonZero(Box::new(Uint128(6)))]\n             => Ok(vec![Uint128(6)]); \"unwrap_non_zero<u128>(6)\")]\n#[test_case(\"store_temp\", vec![type_arg(\"u128\")], vec![Uint128(6)] => Ok(vec![Uint128(6)]);\n            \"store_temp<u128>(6)\")]\n#[test_case(\"store_local\", vec![type_arg(\"u128\")], vec![Uninitialized, Uint128(6)]\n             => Ok(vec![Uint128(6)]); \"store_local<u128>(_, 6)\")]\n#[test_case(\"finalize_locals\", vec![], vec![] => Ok(vec![]); \"finalize_locals()\")]\n#[test_case(\"rename\", vec![type_arg(\"u128\")], vec![Uint128(6)] => Ok(vec![Uint128(6)]);\n            \"rename<u128>(6)\")]\n#[test_case(\"function_call\", vec![user_func_arg(\"drop_all_inputs\")], vec![Uint128(3), Uint128(5)]\n             => Ok(vec![]); \"function_call<drop_all_inputs>()\")]\n#[test_case(\"function_call\", vec![user_func_arg(\"identity\")], vec![Uint128(3), Uint128(5)]\n             => Ok(vec![Uint128(3), Uint128(5)]); \"function_call<identity>()\")]\nfn simulate_none_branch(\n    id: &str,\n    generic_args: Vec<GenericArg>,\n    inputs: Vec<CoreValue>,\n) -> Result<Vec<CoreValue>, LibfuncSimulationError> {\n    simulate(id, generic_args, inputs).map(|(outputs, chosen_branch)| {\n        assert_eq!(chosen_branch, 0);\n        outputs\n    })\n}\n\n#[test_case(\"withdraw_gas\", vec![], vec![RangeCheck, Uninitialized] => MemoryLayoutMismatch;\n            \"withdraw_gas(empty)\")]\n#[test_case(\"withdraw_gas\", vec![], vec![] => WrongNumberOfArgs; \"withdraw_gas()\")]\n#[test_case(\"redeposit_gas\", vec![], vec![Uninitialized] => MemoryLayoutMismatch;\n            \"redeposit_gas(empty)\")]\n#[test_case(\"redeposit_gas\", vec![], vec![] => WrongNumberOfArgs; \"redeposit_gas()\")]\n#[test_case(\"u128_overflowing_add\", vec![], vec![RangeCheck, Uint128(1)] => WrongNumberOfArgs;\n            \"u128_overflowing_add(1)\")]\n#[test_case(\"u128_overflowing_sub\", vec![], vec![RangeCheck, Uint128(1)] => WrongNumberOfArgs;\n            \"u128_overflowing_sub(1)\")]\n#[test_case(\"u128_safe_divmod\", vec![], vec![RangeCheck, Uint128(1)] => WrongNumberOfArgs;\n            \"u128_safe_divmod(1)\")]\n#[test_case(\"u128_const\", vec![value_arg(3)], vec![Uint128(1)] => WrongNumberOfArgs;\n            \"u128_const<3>(1)\")]\n#[test_case(\"dup\", vec![type_arg(\"u128\")], vec![] => WrongNumberOfArgs; \"dup<u128>()\")]\n#[test_case(\"drop\", vec![type_arg(\"u128\")], vec![] => WrongNumberOfArgs; \"drop<u128>()\")]\n#[test_case(\"u128_is_zero\", vec![], vec![] => WrongNumberOfArgs; \"u128_is_zero()\")]\n#[test_case(\"unwrap_non_zero\", vec![type_arg(\"u128\")], vec![] => WrongNumberOfArgs;\n            \"unwrap_non_zero<u128>()\")]\n#[test_case(\"store_temp\", vec![type_arg(\"u128\")], vec![] => WrongNumberOfArgs;\n            \"store_temp<u128>()\")]\n#[test_case(\"store_local\", vec![type_arg(\"u128\")], vec![] => WrongNumberOfArgs;\n            \"store_local<u128>()\")]\n#[test_case(\"finalize_locals\", vec![], vec![Uint128(4)] => WrongNumberOfArgs; \"finalize_locals(4)\")]\n#[test_case(\"rename\", vec![type_arg(\"u128\")], vec![] => WrongNumberOfArgs; \"rename<u128>()\")]\n#[test_case(\"jump\", vec![], vec![Uint128(4)] => WrongNumberOfArgs; \"jump(4)\")]\n#[test_case(\"function_call\", vec![user_func_arg(\"unimplemented\")], vec![] =>\n            FunctionSimulationError(\n                \"unimplemented\".into(),\n                Box::new(SimulationError::StatementOutOfBounds(StatementIdx(0))));\n            \"function_call<unimplemented>()\")]\nfn simulate_error(\n    id: &str,\n    generic_args: Vec<GenericArg>,\n    inputs: Vec<CoreValue>,\n) -> LibfuncSimulationError {\n    simulate(id, generic_args, inputs).err().unwrap()\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashMap;\n\nuse num_bigint::BigInt;\n\n/// The logical value of a variable for Sierra simulation.\n#[derive(Clone, Debug, Eq, PartialEq)]\npub enum CoreValue {\n    EcPoint(BigInt, BigInt),\n    // TODO(orizi): Use actual felt252 object.\n    Felt252(BigInt),\n    GasBuiltin(i64),\n    RangeCheck,\n    Uint8(u8),\n    Uint16(u16),\n    Uint32(u32),\n    Uint64(u64),\n    Uint128(u128),\n    NonZero(Box<CoreValue>),\n    Ref(Box<CoreValue>),\n    Array(Vec<CoreValue>),\n    Dict(HashMap<BigInt, CoreValue>),\n    Enum {\n        value: Box<CoreValue>,\n        /// The index of the relevant variant.\n        index: usize,\n    },\n    Struct(Vec<CoreValue>),\n    Uninitialized,\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use bimap::BiMap;\nuse itertools::chain;\n\nuse crate::ids::ConcreteTypeId;\nuse crate::program::{ConcreteTypeLongId, GenericArg};\n\npub fn build_bijective_mapping() -> BiMap<ConcreteTypeId, ConcreteTypeLongId> {\n    let mut elements = BiMap::new();\n    elements.insert(\"T\".into(), as_type_long_id(\"T\", &[]));\n    elements.insert(\"u32\".into(), as_type_long_id(\"u32\", &[]));\n    elements.insert(\"u64\".into(), as_type_long_id(\"u64\", &[]));\n    elements.insert(\"u128\".into(), as_type_long_id(\"u128\", &[]));\n    elements.insert(\"felt252\".into(), as_type_long_id(\"felt252\", &[]));\n    elements.insert(\"Tuple<>\".into(), as_named_type_long_id(\"Struct\", \"Tuple\", &[]));\n    elements.insert(\n        \"U128AndFelt252\".into(),\n        as_named_type_long_id(\"Struct\", \"U128AndFelt252\", &[\"u128\", \"felt252\"]),\n    );\n    elements\n        .insert(\"Option\".into(), as_named_type_long_id(\"Enum\", \"Option\", &[\"felt252\", \"Tuple<>\"]));\n    elements.insert(\"NonZeroFelt252\".into(), as_type_long_id(\"NonZero\", &[\"felt252\"]));\n    elements.insert(\"NonZeroU128\".into(), as_type_long_id(\"NonZero\", &[\"u128\"]));\n    elements.insert(\"ArrayFelt252\".into(), as_type_long_id(\"Array\", &[\"felt252\"]));\n    elements.insert(\"ArrayU128\".into(), as_type_long_id(\"Array\", &[\"u128\"]));\n    elements.insert(\"BoxU128\".into(), as_type_long_id(\"Box\", &[\"u128\"]));\n    elements.insert(\"UninitializedFelt252\".into(), as_type_long_id(\"Uninitialized\", &[\"felt252\"]));\n    elements.insert(\"Uninitializedu128\".into(), as_type_long_id(\"Uninitialized\", &[\"u128\"]));\n    elements.insert(\"GasBuiltin\".into(), as_type_long_id(\"GasBuiltin\", &[]));\n    elements.insert(\"RangeCheck\".into(), as_type_long_id(\"RangeCheck\", &[]));\n    elements.insert(\"System\".into(), as_type_long_id(\"System\", &[]));\n    elements.insert(\"StorageBaseAddress\".into(), as_type_long_id(\"StorageBaseAddress\", &[]));\n    elements.insert(\"StorageAddress\".into(), as_type_long_id(\"StorageAddress\", &[]));\n    elements.insert(\"ContractAddress\".into(), as_type_long_id(\"ContractAddress\", &[]));\n    elements.insert(\"SnapshotRangeCheck\".into(), as_type_long_id(\"Snapshot\", &[\"RangeCheck\"]));\n    elements.insert(\"SnapshotArrayU128\".into(), as_type_long_id(\"Snapshot\", &[\"ArrayU128\"]));\n    elements.insert(\"SnapshotU128\".into(), as_type_long_id(\"Snapshot\", &[\"u128\"]));\n    elements.insert(\n        \"NonDupStruct\".into(),\n        as_named_type_long_id(\"Struct\", \"NonDupStruct\", &[\"felt252\", \"RangeCheck\"]),\n    );\n    elements.insert(\"SnapshotNonDupStruct\".into(), as_type_long_id(\"Snapshot\", &[\"NonDupStruct\"]));\n    elements.insert(\n        \"NonDupEnum\".into(),\n        as_named_type_long_id(\"Enum\", \"NonDupEnum\", &[\"felt252\", \"RangeCheck\"]),\n    );\n    elements.insert(\"SnapshotNonDupEnum\".into(), as_type_long_id(\"Snapshot\", &[\"NonDupEnum\"]));\n    elements\n}\n\nfn as_type_long_id(name: &str, args: &[&str]) -> ConcreteTypeLongId {\n    ConcreteTypeLongId {\n        generic_id: name.into(),\n        generic_args: args.iter().map(|s| GenericArg::Type(ConcreteTypeId::from(*s))).collect(),\n    }\n}\n\nfn as_named_type_long_id(genetic_name: &str, user_name: &str, args: &[&str]) -> ConcreteTypeLongId {\n    ConcreteTypeLongId {\n        generic_id: genetic_name.into(),\n        generic_args: chain!(\n            [GenericArg::UserType(user_name.into())],\n            args.iter().map(|s| GenericArg::Type(ConcreteTypeId::from(*s)))\n        )\n        .collect(),\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashMap;\nuse std::fs;\nuse std::path::PathBuf;\n\nuse cairo_lang_sierra::extensions::core::{CoreLibfunc, CoreType};\nuse cairo_lang_sierra::program::{Program, StatementIdx};\nuse cairo_lang_sierra::program_registry::ProgramRegistry;\nuse cairo_lang_sierra::simulation::value::CoreValue;\nuse cairo_lang_sierra::simulation::{self};\nuse num_bigint::ToBigInt;\nuse pretty_assertions::assert_eq;\nuse test_case::test_case;\n\n/// Returns a parsed example program from the example directory.\nfn get_example_program(name: &str) -> Program {\n    let path: PathBuf =\n        [env!(\"CARGO_MANIFEST_DIR\"), \"examples\", &format!(\"{name}.sierra\")].into_iter().collect();\n    cairo_lang_sierra::ProgramParser::new().parse(&fs::read_to_string(path).unwrap()).unwrap()\n}\n\n#[test_case(\"fib_jumps\")]\n#[test_case(\"fib_no_gas\")]\nfn parse(name: &str) {\n    get_example_program(name);\n}\n\n#[test_case(\"fib_jumps\")]\n#[test_case(\"fib_no_gas\")]\nfn create_registry(name: &str) {\n    ProgramRegistry::<CoreType, CoreLibfunc>::new(&get_example_program(name)).unwrap();\n}\n\n#[test_case((1000, 0), (1000, 1); \"0 => 1\")]\n#[test_case((1000, 1), (989, 1); \"1 => 1\")]\n#[test_case((1000, 2), (978, 2); \"2 => 2\")]\n#[test_case((1000, 3), (967, 3); \"3 => 3\")]\n#[test_case((1000, 4), (956, 5); \"4 => 5\")]\n#[test_case((1000, 5), (945, 8); \"5 => 8\")]\n#[test_case((1000, 6), (934, 13); \"6 => 13\")]\n#[test_case((1000, 7), (923, 21); \"7 => 21\")]\n#[test_case((1000, 8), (912, 34); \"8 => 34\")]\n#[test_case((100, 80), (1, -1); \"Out of gas.\")]\nfn simulate_fib_jumps((gb, n): (i64, i128), (new_gb, fib): (i64, i128)) {\n    assert_eq!(\n        simulation::run(\n            &get_example_program(\"fib_jumps\"),\n            &HashMap::from([\n                (StatementIdx(28), 11),\n                (StatementIdx(29), 0),\n                (StatementIdx(40), 0),\n                (StatementIdx(45), 0),\n                (StatementIdx(19), 5),\n                (StatementIdx(22), 0),\n                (StatementIdx(26), 0),\n                (StatementIdx(2), 14),\n                (StatementIdx(4), 0),\n                (StatementIdx(9), 0),\n            ]),\n            &\"Fibonacci\".into(),\n            vec![\n                CoreValue::RangeCheck,\n                CoreValue::GasBuiltin(gb),\n                CoreValue::Felt252(n.to_bigint().unwrap())\n            ]\n        ),\n        Ok(vec![\n            CoreValue::RangeCheck,\n            CoreValue::GasBuiltin(new_gb),\n            CoreValue::Felt252(fib.to_bigint().unwrap())\n        ])\n    );\n}\n\n#[test_case(0, 1; \"0 => 1\")]\n#[test_case(1, 1; \"1 => 1\")]\n#[test_case(2, 2; \"2 => 2\")]\n#[test_case(3, 3; \"3 => 3\")]\n#[test_case(4, 5; \"4 => 5\")]\n#[test_case(5, 8; \"5 => 8\")]\n#[test_case(6, 13; \"6 => 13\")]\n#[test_case(7, 21; \"7 => 21\")]\n#[test_case(8, 34; \"8 => 34\")]\nfn simulate_fib_no_gas(n: i128, fib: i128) {\n    assert_eq!(\n        simulation::run(\n            &get_example_program(\"fib_no_gas\"),\n            &HashMap::from([(StatementIdx(1), 0), (StatementIdx(5), 0),]),\n            &\"Fibonacci\".into(),\n            vec![\n                // a=\n                CoreValue::Felt252(1.to_bigint().unwrap()),\n                // b=\n                CoreValue::Felt252(1.to_bigint().unwrap()),\n                CoreValue::Felt252(n.to_bigint().unwrap())\n            ]\n        ),\n        Ok(vec![CoreValue::Felt252(fib.to_bigint().unwrap())])\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use indoc::indoc;\nuse test_log::test;\n\n// Testing by parsing code and printing its display, making sure we get back the formatted code.\n#[test]\nfn format_test() {\n    let parser = cairo_lang_sierra::ProgramParser::new();\n    assert_eq!(\n        parser\n            .parse(indoc! {\"\n                // Some comment.\n                type ConcreteTypeId =  TypeId; // Other comment.\n                type ConcreteTypeId  = TypeId<arg>;\n                type  ConcreteTypeId = TypeId<arg1, 4>;\n                type [123] = TypeId<[12],  4>;\n                type [4]= Enum<ut@core::option ::Option:: <core::felt252>, [3],[2]>;\n                type Complex = Struct<ut@Complex:: <core::felt252, @core::felt252>,[8],[9]>;\n                libfunc CalleeId = LibfuncId ;\n                // Additional comment.\n                libfunc OtherCalleeId = LibfuncId <arg, 4>;\n                libfunc [5642] = LibfuncId<[22 ], 4>;\n                libfunc CallFunction = Call<user@Function>;\n                libfunc LibDependent = LibDependent<lib@[124]>;\n                callee() -> ();\n                callee(arg1) -> (res1);\n                callee( arg1, arg2) -> ( res1, res2);\n                callee() { 5( ) };\n                callee(arg1 , arg2) { fallthrough() 7(res1 ) 5(res1, res2) };\n                [12345]([12]) { 2([37]) fallthrough() };\n                return();\n                return ( r);\n                return(r1 , r2);\n                return ([1], [45], [0]);\n\n                Name@5() -> ();\n                Other@3([5]: T1) -> (T2);\n                [343]@3([5]: [6343]) -> ([341]);\n            \"},)\n            .map(|p| p.to_string()),\n        Ok(indoc! {\"\n            type ConcreteTypeId = TypeId;\n            type ConcreteTypeId = TypeId<arg>;\n            type ConcreteTypeId = TypeId<arg1, 4>;\n            type [123] = TypeId<[12], 4>;\n            type [4] = Enum<ut@core::option::Option::<core::felt252>, [3], [2]>;\n            type Complex = Struct<ut@Complex::<core::felt252, @core::felt252>, [8], [9]>;\n\n            libfunc CalleeId = LibfuncId;\n            libfunc OtherCalleeId = LibfuncId<arg, 4>;\n            libfunc [5642] = LibfuncId<[22], 4>;\n            libfunc CallFunction = Call<user@Function>;\n            libfunc LibDependent = LibDependent<lib@[124]>;\n\n            callee() -> ();\n            callee(arg1) -> (res1);\n            callee(arg1, arg2) -> (res1, res2);\n            callee() { 5() };\n            callee(arg1, arg2) { fallthrough() 7(res1) 5(res1, res2) };\n            [12345]([12]) { 2([37]) fallthrough() };\n            return();\n            return(r);\n            return(r1, r2);\n            return([1], [45], [0]);\n\n            Name@5() -> ();\n            Other@3([5]: T1) -> (T2);\n            [343]@3([5]: [6343]) -> ([341]);\n        \"}\n        .to_string())\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_sierra::ids::FunctionId;\nuse cairo_lang_sierra::program::StatementIdx;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\n\n/// Ap change information for a Sierra program.\n#[derive(Debug, Eq, PartialEq)]\npub struct ApChangeInfo {\n    /// The values of variables at matching libfuncs at given statements indices.\n    pub variable_values: OrderedHashMap<StatementIdx, usize>,\n    /// The ap_change of calling the given function.\n    pub function_ap_change: OrderedHashMap<FunctionId, usize>,\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_sierra::extensions::ap_tracking::ApTrackingConcreteLibfunc;\nuse cairo_lang_sierra::extensions::array::ArrayConcreteLibfunc;\nuse cairo_lang_sierra::extensions::boolean::BoolConcreteLibfunc;\nuse cairo_lang_sierra::extensions::boxing::BoxConcreteLibfunc;\nuse cairo_lang_sierra::extensions::builtin_cost::{\n    BuiltinCostConcreteLibfunc, BuiltinCostWithdrawGasLibfunc, CostTokenType,\n};\nuse cairo_lang_sierra::extensions::casts::CastConcreteLibfunc;\nuse cairo_lang_sierra::extensions::core::CoreConcreteLibfunc;\nuse cairo_lang_sierra::extensions::ec::EcConcreteLibfunc;\nuse cairo_lang_sierra::extensions::enm::EnumConcreteLibfunc;\nuse cairo_lang_sierra::extensions::felt252::{\n    Felt252BinaryOperationConcrete, Felt252BinaryOperator, Felt252Concrete,\n};\nuse cairo_lang_sierra::extensions::felt252_dict::Felt252DictConcreteLibfunc;\nuse cairo_lang_sierra::extensions::gas::GasConcreteLibfunc;\nuse cairo_lang_sierra::extensions::mem::MemConcreteLibfunc;\nuse cairo_lang_sierra::extensions::nullable::NullableConcreteLibfunc;\nuse cairo_lang_sierra::extensions::pedersen::PedersenConcreteLibfunc;\nuse cairo_lang_sierra::extensions::starknet::StarkNetConcreteLibfunc;\nuse cairo_lang_sierra::extensions::structure::StructConcreteLibfunc;\nuse cairo_lang_sierra::extensions::uint::{\n    IntOperator, Uint16Concrete, Uint32Concrete, Uint64Concrete, Uint8Concrete,\n};\nuse cairo_lang_sierra::extensions::uint128::Uint128Concrete;\nuse cairo_lang_sierra::ids::ConcreteTypeId;\n\nuse crate::ApChange;\n\n/// Trait for providing extra information required for AP changes for a specific libfunc invocation.\npub trait InvocationApChangeInfoProvider {\n    /// Provides the sizes of types.\n    fn type_size(&self, ty: &ConcreteTypeId) -> usize;\n    /// Number of tokens provided by the libfunc invocation (currently only relevant for\n    /// `withdraw_gas_all`).\n    fn token_usages(&self, token_type: CostTokenType) -> usize;\n}\n\n/// Returns the ap change for a core libfunc.\n/// Values with unknown values will return as None.\npub fn core_libfunc_ap_change<InfoProvider: InvocationApChangeInfoProvider>(\n    libfunc: &CoreConcreteLibfunc,\n    info_provider: &InfoProvider,\n) -> Vec<ApChange> {\n    match libfunc {\n        CoreConcreteLibfunc::ApTracking(ApTrackingConcreteLibfunc::Revoke(_)) => {\n            vec![ApChange::Unknown]\n        }\n        CoreConcreteLibfunc::ApTracking(ApTrackingConcreteLibfunc::Enable(_)) => {\n            vec![ApChange::EnableApTracking]\n        }\n        CoreConcreteLibfunc::ApTracking(ApTrackingConcreteLibfunc::Disable(_)) => {\n            vec![ApChange::DisableApTracking]\n        }\n        CoreConcreteLibfunc::Array(libfunc) => match libfunc {\n            ArrayConcreteLibfunc::New(_) => vec![ApChange::Known(1)],\n            ArrayConcreteLibfunc::Append(_) => vec![ApChange::Known(0)],\n            ArrayConcreteLibfunc::PopFront(_) | ArrayConcreteLibfunc::SnapshotPopFront(_) => {\n                vec![ApChange::Known(1), ApChange::Known(1)]\n            }\n            ArrayConcreteLibfunc::Get(libfunc) => {\n                if info_provider.type_size(&libfunc.ty) == 1 { [4, 3] } else { [5, 4] }\n                    .map(ApChange::Known)\n                    .to_vec()\n            }\n            ArrayConcreteLibfunc::Len(libfunc) => {\n                vec![ApChange::Known(if info_provider.type_size(&libfunc.ty) == 1 { 0 } else { 1 })]\n            }\n        },\n        CoreConcreteLibfunc::Bitwise(_) => vec![ApChange::Known(0)],\n        CoreConcreteLibfunc::BranchAlign(_) => vec![ApChange::FromMetadata],\n        CoreConcreteLibfunc::Bool(libfunc) => match libfunc {\n            BoolConcreteLibfunc::And(_) => vec![ApChange::Known(0)],\n            BoolConcreteLibfunc::Not(_) => vec![ApChange::Known(1)],\n            BoolConcreteLibfunc::Xor(_) => vec![ApChange::Known(1)],\n            BoolConcreteLibfunc::Or(_) => vec![ApChange::Known(2)],\n            BoolConcreteLibfunc::ToFelt252(_) => vec![ApChange::Known(0)],\n        },\n        CoreConcreteLibfunc::Box(libfunc) => match libfunc {\n            BoxConcreteLibfunc::Into(_) => vec![ApChange::Known(1)],\n            BoxConcreteLibfunc::Unbox(_) => vec![ApChange::Known(0)],\n        },\n        CoreConcreteLibfunc::BuiltinCost(libfunc) => match libfunc {\n            BuiltinCostConcreteLibfunc::BuiltinWithdrawGas(_) => {\n                let cost_computation_ap_change: usize =\n                    BuiltinCostWithdrawGasLibfunc::cost_computation_steps(|token_type| {\n                        info_provider.token_usages(token_type)\n                    });\n                vec![\n                    ApChange::Known(cost_computation_ap_change + 2),\n                    ApChange::Known(cost_computation_ap_change + 3),\n                ]\n            }\n            BuiltinCostConcreteLibfunc::GetBuiltinCosts(_) => vec![ApChange::Known(3)],\n        },\n        CoreConcreteLibfunc::Cast(libfunc) => match libfunc {\n            CastConcreteLibfunc::Downcast(_) => vec![ApChange::Known(2), ApChange::Known(2)],\n            CastConcreteLibfunc::Upcast(_) => vec![ApChange::Known(0)],\n        },\n        CoreConcreteLibfunc::Ec(libfunc) => match libfunc {\n            EcConcreteLibfunc::IsZero(_) => vec![ApChange::Known(0), ApChange::Known(0)],\n            EcConcreteLibfunc::Neg(_) => vec![ApChange::Known(0)],\n            EcConcreteLibfunc::StateAdd(_) => vec![ApChange::Known(9)],\n            EcConcreteLibfunc::TryNew(_) => vec![ApChange::Known(6), ApChange::Known(6)],\n            EcConcreteLibfunc::StateFinalize(_) => vec![ApChange::Known(11), ApChange::Known(3)],\n            EcConcreteLibfunc::StateInit(_) => vec![ApChange::Known(8)],\n            EcConcreteLibfunc::StateAddMul(_) => vec![ApChange::Known(0)],\n            EcConcreteLibfunc::PointFromX(_) => vec![ApChange::Known(11), ApChange::Known(7)],\n            EcConcreteLibfunc::UnwrapPoint(_) => vec![ApChange::Known(0)],\n            EcConcreteLibfunc::Zero(_) => vec![ApChange::Known(0)],\n        },\n        CoreConcreteLibfunc::Drop(_) | CoreConcreteLibfunc::Dup(_) => vec![ApChange::Known(0)],\n        CoreConcreteLibfunc::Felt252(libfunc) => match libfunc {\n            Felt252Concrete::Const(_) => {\n                vec![ApChange::Known(0)]\n            }\n            Felt252Concrete::BinaryOperation(bin_op) => {\n                let op = match bin_op {\n                    Felt252BinaryOperationConcrete::WithVar(op) => op.operator,\n                    Felt252BinaryOperationConcrete::WithConst(op) => op.operator,\n                };\n                vec![ApChange::Known(if op == Felt252BinaryOperator::Div { 1 } else { 0 })]\n            }\n            Felt252Concrete::IsZero(_) => vec![ApChange::Known(0), ApChange::Known(0)],\n        },\n        CoreConcreteLibfunc::FunctionCall(libfunc) => {\n            vec![ApChange::FunctionCall(libfunc.function.id.clone())]\n        }\n        CoreConcreteLibfunc::Gas(libfunc) => match libfunc {\n            GasConcreteLibfunc::WithdrawGas(_) => vec![ApChange::Known(2), ApChange::Known(2)],\n            GasConcreteLibfunc::RedepositGas(_) => vec![ApChange::Known(0)],\n            GasConcreteLibfunc::GetAvailableGas(_) => vec![ApChange::Known(0)],\n        },\n        CoreConcreteLibfunc::Uint8(libfunc) => match libfunc {\n            Uint8Concrete::Const(_) | Uint8Concrete::ToFelt252(_) => vec![ApChange::Known(0)],\n            Uint8Concrete::Operation(libfunc) => match libfunc.operator {\n                IntOperator::OverflowingAdd => {\n                    vec![ApChange::Known(3), ApChange::Known(3)]\n                }\n                IntOperator::OverflowingSub => {\n                    vec![ApChange::Known(2), ApChange::Known(4)]\n                }\n            },\n            Uint8Concrete::LessThan(_) => vec![ApChange::Known(2), ApChange::Known(3)],\n            Uint8Concrete::SquareRoot(_) => vec![ApChange::Known(6)],\n            Uint8Concrete::Equal(_) => vec![ApChange::Known(1), ApChange::Known(1)],\n            Uint8Concrete::LessThanOrEqual(_) => vec![ApChange::Known(3), ApChange::Known(2)],\n            Uint8Concrete::FromFelt252(_) => vec![ApChange::Known(2), ApChange::Known(7)],\n            Uint8Concrete::IsZero(_) => vec![ApChange::Known(0), ApChange::Known(0)],\n            Uint8Concrete::Divmod(_) => vec![ApChange::Known(5)],\n            Uint8Concrete::WideMul(_) => vec![ApChange::Known(0)],\n        },\n        CoreConcreteLibfunc::Uint16(libfunc) => match libfunc {\n            Uint16Concrete::Const(_) | Uint16Concrete::ToFelt252(_) => vec![ApChange::Known(0)],\n            Uint16Concrete::Operation(libfunc) => match libfunc.operator {\n                IntOperator::OverflowingAdd => {\n                    vec![ApChange::Known(3), ApChange::Known(3)]\n                }\n                IntOperator::OverflowingSub => {\n                    vec![ApChange::Known(2), ApChange::Known(4)]\n                }\n            },\n            Uint16Concrete::LessThan(_) => vec![ApChange::Known(2), ApChange::Known(3)],\n            Uint16Concrete::SquareRoot(_) => vec![ApChange::Known(6)],\n            Uint16Concrete::Equal(_) => vec![ApChange::Known(1), ApChange::Known(1)],\n            Uint16Concrete::LessThanOrEqual(_) => vec![ApChange::Known(3), ApChange::Known(2)],\n            Uint16Concrete::FromFelt252(_) => vec![ApChange::Known(2), ApChange::Known(7)],\n            Uint16Concrete::IsZero(_) => vec![ApChange::Known(0), ApChange::Known(0)],\n            Uint16Concrete::Divmod(_) => vec![ApChange::Known(5)],\n            Uint16Concrete::WideMul(_) => vec![ApChange::Known(0)],\n        },\n        CoreConcreteLibfunc::Uint32(libfunc) => match libfunc {\n            Uint32Concrete::Const(_) | Uint32Concrete::ToFelt252(_) => vec![ApChange::Known(0)],\n            Uint32Concrete::Operation(libfunc) => match libfunc.operator {\n                IntOperator::OverflowingAdd => {\n                    vec![ApChange::Known(3), ApChange::Known(3)]\n                }\n                IntOperator::OverflowingSub => {\n                    vec![ApChange::Known(2), ApChange::Known(4)]\n                }\n            },\n            Uint32Concrete::LessThan(_) => vec![ApChange::Known(2), ApChange::Known(3)],\n            Uint32Concrete::SquareRoot(_) => vec![ApChange::Known(6)],\n            Uint32Concrete::Equal(_) => vec![ApChange::Known(1), ApChange::Known(1)],\n            Uint32Concrete::LessThanOrEqual(_) => vec![ApChange::Known(3), ApChange::Known(2)],\n            Uint32Concrete::FromFelt252(_) => vec![ApChange::Known(2), ApChange::Known(7)],\n            Uint32Concrete::IsZero(_) => vec![ApChange::Known(0), ApChange::Known(0)],\n            Uint32Concrete::Divmod(_) => vec![ApChange::Known(5)],\n            Uint32Concrete::WideMul(_) => vec![ApChange::Known(0)],\n        },\n        CoreConcreteLibfunc::Uint64(libfunc) => match libfunc {\n            Uint64Concrete::Const(_) | Uint64Concrete::ToFelt252(_) => vec![ApChange::Known(0)],\n            Uint64Concrete::Operation(libfunc) => match libfunc.operator {\n                IntOperator::OverflowingAdd => {\n                    vec![ApChange::Known(3), ApChange::Known(3)]\n                }\n                IntOperator::OverflowingSub => {\n                    vec![ApChange::Known(2), ApChange::Known(4)]\n                }\n            },\n            Uint64Concrete::LessThan(_) => vec![ApChange::Known(2), ApChange::Known(3)],\n            Uint64Concrete::SquareRoot(_) => vec![ApChange::Known(6)],\n            Uint64Concrete::Equal(_) => vec![ApChange::Known(1), ApChange::Known(1)],\n            Uint64Concrete::LessThanOrEqual(_) => vec![ApChange::Known(3), ApChange::Known(2)],\n            Uint64Concrete::FromFelt252(_) => vec![ApChange::Known(2), ApChange::Known(7)],\n            Uint64Concrete::IsZero(_) => vec![ApChange::Known(0), ApChange::Known(0)],\n            Uint64Concrete::Divmod(_) => vec![ApChange::Known(5)],\n            Uint64Concrete::WideMul(_) => vec![ApChange::Known(0)],\n        },\n        CoreConcreteLibfunc::Uint128(libfunc) => match libfunc {\n            Uint128Concrete::Operation(libfunc) => match libfunc.operator {\n                IntOperator::OverflowingAdd | IntOperator::OverflowingSub => {\n                    vec![ApChange::Known(2), ApChange::Known(3)]\n                }\n            },\n            Uint128Concrete::Divmod(_) => vec![ApChange::Known(7)],\n            Uint128Concrete::WideMul(_) => vec![ApChange::Known(17)],\n            Uint128Concrete::LessThan(_) => vec![ApChange::Known(2), ApChange::Known(3)],\n            Uint128Concrete::Equal(_) => vec![ApChange::Known(1), ApChange::Known(1)],\n            Uint128Concrete::SquareRoot(_) => vec![ApChange::Known(6)],\n            Uint128Concrete::LessThanOrEqual(_) => vec![ApChange::Known(3), ApChange::Known(2)],\n            Uint128Concrete::FromFelt252(_) => vec![ApChange::Known(1), ApChange::Known(6)],\n            Uint128Concrete::Const(_) | Uint128Concrete::ToFelt252(_) => {\n                vec![ApChange::Known(0)]\n            }\n            Uint128Concrete::IsZero(_) => vec![ApChange::Known(0), ApChange::Known(0)],\n        },\n        CoreConcreteLibfunc::Mem(libfunc) => match libfunc {\n            MemConcreteLibfunc::StoreTemp(libfunc) => {\n                vec![ApChange::Known(info_provider.type_size(&libfunc.ty))]\n            }\n            MemConcreteLibfunc::StoreLocal(_) => vec![ApChange::Known(0)],\n            MemConcreteLibfunc::FinalizeLocals(_) => vec![ApChange::FinalizeLocals],\n            MemConcreteLibfunc::AllocLocal(libfunc) => {\n                vec![ApChange::AtLocalsFinalization(info_provider.type_size(&libfunc.ty))]\n            }\n            MemConcreteLibfunc::Rename(_) => {\n                vec![ApChange::Known(0)]\n            }\n        },\n        CoreConcreteLibfunc::UnwrapNonZero(_) => vec![ApChange::Known(0)],\n        CoreConcreteLibfunc::UnconditionalJump(_) => vec![ApChange::Known(0)],\n        CoreConcreteLibfunc::Enum(libfunc) => match libfunc {\n            EnumConcreteLibfunc::Init(_) => vec![ApChange::Known(0)],\n            EnumConcreteLibfunc::Match(libfunc) | EnumConcreteLibfunc::SnapshotMatch(libfunc) => {\n                vec![ApChange::Known(0); libfunc.signature.branch_signatures.len()]\n            }\n        },\n        CoreConcreteLibfunc::Struct(libfunc) => match libfunc {\n            StructConcreteLibfunc::Construct(_)\n            | StructConcreteLibfunc::Deconstruct(_)\n            | StructConcreteLibfunc::SnapshotDeconstruct(_) => {\n                vec![ApChange::Known(0)]\n            }\n        },\n        CoreConcreteLibfunc::Felt252Dict(libfunc) => match libfunc {\n            Felt252DictConcreteLibfunc::New(_) => vec![ApChange::Known(6)],\n            Felt252DictConcreteLibfunc::Read(_) => vec![ApChange::Known(1)],\n            Felt252DictConcreteLibfunc::Write(_) => vec![ApChange::Known(0)],\n            Felt252DictConcreteLibfunc::Squash(_) => vec![ApChange::Unknown],\n        },\n        CoreConcreteLibfunc::Pedersen(libfunc) => match libfunc {\n            PedersenConcreteLibfunc::PedersenHash(_) => vec![ApChange::Known(0)],\n        },\n        CoreConcreteLibfunc::StarkNet(libfunc) => match libfunc {\n            StarkNetConcreteLibfunc::ClassHashConst(_)\n            | StarkNetConcreteLibfunc::ContractAddressConst(_) => vec![ApChange::Known(0)],\n\n            StarkNetConcreteLibfunc::ClassHashTryFromFelt252(_)\n            | StarkNetConcreteLibfunc::ContractAddressTryFromFelt252(_)\n            | StarkNetConcreteLibfunc::StorageAddressTryFromFelt252(_) => {\n                vec![ApChange::Known(5), ApChange::Known(6)]\n            }\n            StarkNetConcreteLibfunc::ClassHashToFelt252(_)\n            | StarkNetConcreteLibfunc::ContractAddressToFelt252(_)\n            | StarkNetConcreteLibfunc::StorageAddressToFelt252(_) => vec![ApChange::Known(0)],\n            StarkNetConcreteLibfunc::StorageBaseAddressConst(_) => vec![ApChange::Known(0)],\n            StarkNetConcreteLibfunc::StorageBaseAddressFromFelt252(_) => {\n                vec![ApChange::Known(7)]\n            }\n            StarkNetConcreteLibfunc::StorageAddressFromBase(_) => vec![ApChange::Known(0)],\n            StarkNetConcreteLibfunc::StorageAddressFromBaseAndOffset(_) => vec![ApChange::Known(0)],\n            StarkNetConcreteLibfunc::CallContract(_)\n            | StarkNetConcreteLibfunc::StorageRead(_)\n            | StarkNetConcreteLibfunc::StorageWrite(_)\n            | StarkNetConcreteLibfunc::EmitEvent(_)\n            | StarkNetConcreteLibfunc::GetExecutionInfo(_)\n            | StarkNetConcreteLibfunc::Deploy(_)\n            | StarkNetConcreteLibfunc::LibraryCall(_)\n            | StarkNetConcreteLibfunc::ReplaceClass(_)\n            | StarkNetConcreteLibfunc::SendMessageToL1(_) => {\n                vec![ApChange::Known(2), ApChange::Known(2)]\n            }\n            StarkNetConcreteLibfunc::Testing(_) => vec![ApChange::Known(0)],\n        },\n        CoreConcreteLibfunc::Nullable(libfunc) => match libfunc {\n            NullableConcreteLibfunc::Null(_) => vec![ApChange::Known(0)],\n            NullableConcreteLibfunc::NullableFromBox(_) => vec![ApChange::Known(0)],\n            NullableConcreteLibfunc::MatchNullable(_) => {\n                vec![ApChange::Known(0), ApChange::Known(0)]\n            }\n        },\n        CoreConcreteLibfunc::Debug(_) => vec![ApChange::Known(0)],\n        CoreConcreteLibfunc::SnapshotTake(_) => vec![ApChange::Known(0)],\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use core::fmt;\n\nuse cairo_lang_eq_solver::Expr;\nuse cairo_lang_sierra::ids::{ConcreteLibfuncId, FunctionId};\nuse cairo_lang_sierra::program::{Program, StatementIdx};\nuse itertools::zip_eq;\n\nuse crate::{ApChange, ApChangeError};\n\n/// Variable parts of an Ap change expression.\n#[derive(Clone, Debug, Hash, PartialEq, Eq)]\npub enum Var {\n    /// Variables supplied for a libfunc at statement id (e.g. branch_align).\n    LibfuncImplicitApChangeVariable(StatementIdx),\n    /// Variable marking on a statement's past ap change (any route from function start to it).\n    FunctionApChange(FunctionId),\n}\nimpl fmt::Display for Var {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            Var::LibfuncImplicitApChangeVariable(idx) => {\n                write!(f, \"libfunc@{idx}\")\n            }\n            Var::FunctionApChange(id) => write!(f, \"function@{id}\"),\n        }\n    }\n}\n\ntype ApChangeExpr = Expr<Var>;\n\n/// The effects of a libfunc.\npub struct Effects {\n    pub ap_change: ApChange,\n    pub locals: usize,\n}\n\n/// Base points to align ap from.\n#[derive(Clone, Debug, Hash, PartialEq, Eq)]\nenum ChangeBase {\n    FunctionStart(FunctionId),\n    EnableApTrackingPoint(StatementIdx),\n}\n\n/// Information per statement in the analyzed Sierra program.\n#[derive(Clone, Debug)]\nstruct StatementInfo {\n    /// The base point to align ap over.\n    base: ChangeBase,\n    /// The ap change up until the statement.\n    past_ap_change: Option<ApChangeExpr>,\n    /// The total size of allocated locals up until the statement.\n    past_locals: usize,\n}\n\n/// Generates a set of equations from a program, and a function to extract cost expressions from a\n/// library function id.\npub fn generate_equations<\n    GetApChange: Fn(StatementIdx, &ConcreteLibfuncId) -> Result<Vec<Effects>, ApChangeError>,\n>(\n    program: &Program,\n    get_effects: GetApChange,\n) -> Result<Vec<ApChangeExpr>, ApChangeError> {\n    let mut generator = EquationGenerator::new(program.statements.len());\n    for func in &program.funcs {\n        generator.set_or_add_constraint(\n            &func.entry_point,\n            StatementInfo {\n                base: ChangeBase::FunctionStart(func.id.clone()),\n                past_ap_change: Some(Expr::from_const(0)),\n                past_locals: 0,\n            },\n        )?;\n    }\n    for idx in (0..program.statements.len()).map(StatementIdx) {\n        let base_info = generator.get_info(&idx)?;\n        match &program.get_statement(&idx).unwrap() {\n            cairo_lang_sierra::program::Statement::Return(_) => {\n                if let ChangeBase::FunctionStart(func_id) = &base_info.base {\n                    generator.set_or_add_constraint(\n                        &idx,\n                        StatementInfo {\n                            base: base_info.base.clone(),\n                            past_ap_change: Some(Expr::from_var(Var::FunctionApChange(\n                                func_id.clone(),\n                            ))),\n                            past_locals: base_info.past_locals,\n                        },\n                    )?;\n                }\n            }\n            cairo_lang_sierra::program::Statement::Invocation(invocation) => {\n                let libfunc_effects = get_effects(idx, &invocation.libfunc_id)?;\n                if invocation.branches.len() != libfunc_effects.len() {\n                    return Err(ApChangeError::WrongNumApChangeBranches(idx));\n                }\n                for (branch, branch_effects) in zip_eq(&invocation.branches, libfunc_effects) {\n                    let enable_tracking =\n                        matches!(branch_effects.ap_change, ApChange::EnableApTracking);\n                    let branch_ap_change = match branch_effects.ap_change {\n                        ApChange::Unknown | ApChange::DisableApTracking => None,\n                        ApChange::Known(x) => Some(Expr::from_const(x as i32)),\n                        ApChange::FromMetadata => {\n                            Some(Expr::from_var(Var::LibfuncImplicitApChangeVariable(idx)))\n                        }\n                        ApChange::FunctionCall(func_id) => Some(\n                            Expr::from_var(Var::FunctionApChange(func_id)) + Expr::from_const(2),\n                        ),\n                        ApChange::FinalizeLocals => {\n                            Some(Expr::from_const(base_info.past_locals as i32))\n                        }\n                        ApChange::AtLocalsFinalization(_) => {\n                            unreachable!(\n                                \"These arms are translated to `ApChange::Known` in the \\\n                                 `get_effects` call.\"\n                            )\n                        }\n                        ApChange::EnableApTracking => Some(Expr::from_const(0)),\n                    };\n                    let next_idx = idx.next(&branch.target);\n                    let past_locals = base_info.past_locals + branch_effects.locals;\n                    generator.set_or_add_constraint(\n                        &next_idx,\n                        if enable_tracking {\n                            StatementInfo {\n                                base: ChangeBase::EnableApTrackingPoint(next_idx),\n                                past_ap_change: branch_ap_change,\n                                past_locals,\n                            }\n                        } else {\n                            StatementInfo {\n                                base: base_info.base.clone(),\n                                past_ap_change: if let (Some(a), Some(b)) =\n                                    (&base_info.past_ap_change, branch_ap_change)\n                                {\n                                    Some(a.clone() + b)\n                                } else {\n                                    None\n                                },\n                                past_locals,\n                            }\n                        },\n                    )?;\n                }\n            }\n        }\n    }\n    Ok(generator.equations)\n}\n\n/// Helper to generate the equations for calculating gas variables.\nstruct EquationGenerator {\n    pub statement_info: Vec<Option<StatementInfo>>,\n    pub equations: Vec<Expr<Var>>,\n}\nimpl EquationGenerator {\n    fn new(n_statements: usize) -> Self {\n        Self { statement_info: vec![None; n_statements], equations: vec![] }\n    }\n\n    /// Sets some future or adds a matching equation if already set.\n    fn set_or_add_constraint(\n        &mut self,\n        idx: &StatementIdx,\n        info: StatementInfo,\n    ) -> Result<(), ApChangeError> {\n        let entry =\n            self.statement_info.get_mut(idx.0).ok_or(ApChangeError::StatementOutOfBounds(*idx))?;\n        if let Some(other) = entry {\n            if other.past_locals != info.past_locals {\n                return Err(ApChangeError::BadMergeAllocatedLocalsMismatch(*idx));\n            }\n            if other.base != info.base {\n                return Err(ApChangeError::BadMergeBaseMismatch(*idx));\n            }\n            if let (Some(a), Some(b)) = (&other.past_ap_change, info.past_ap_change) {\n                self.equations.push(a.clone() - b);\n            }\n        } else {\n            *entry = Some(info);\n        }\n        Ok(())\n    }\n\n    /// Returns `StatementInfo` for statement, will additionally make sure this information was\n    /// initialized.\n    fn get_info(&mut self, idx: &StatementIdx) -> Result<StatementInfo, ApChangeError> {\n        self.statement_info[idx.0].clone().ok_or(ApChangeError::StatementOutOfOrder(*idx))\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Sierra AP change model.\nuse ap_change_info::ApChangeInfo;\nuse cairo_lang_sierra::extensions::builtin_cost::CostTokenType;\nuse cairo_lang_sierra::extensions::core::{CoreLibfunc, CoreType};\nuse cairo_lang_sierra::extensions::ConcreteType;\nuse cairo_lang_sierra::ids::{ConcreteTypeId, FunctionId};\nuse cairo_lang_sierra::program::{Program, StatementIdx};\nuse cairo_lang_sierra::program_registry::{ProgramRegistry, ProgramRegistryError};\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse core_libfunc_ap_change::InvocationApChangeInfoProvider;\nuse generate_equations::{Effects, Var};\nuse itertools::Itertools;\nuse thiserror::Error;\n\npub mod ap_change_info;\npub mod core_libfunc_ap_change;\nmod generate_equations;\n\n/// Describes the effect on the `ap` register in a given libfunc branch.\n#[derive(Clone, Debug, Eq, PartialEq)]\npub enum ApChange {\n    /// The libfunc changes `ap` in an unknown way.\n    Unknown,\n    /// The libfunc changes `ap` by a known size.\n    Known(usize),\n    /// The libfunc changes `ap` by a known size, provided in the metadata. Currently this only\n    /// includes `branch_align` libfunc.\n    FromMetadata,\n    /// The libfunc changes `ap` by a known size at locals finalization stage.\n    AtLocalsFinalization(usize),\n    /// The libfunc is a function call - it changes according to the given function and call cost.\n    FunctionCall(FunctionId),\n    /// The libfunc allocates locals, the `ap` change depends on the environment.\n    FinalizeLocals,\n    /// The libfunc is the ap tracking enabler.\n    EnableApTracking,\n    /// The libfunc is the ap tracking disabler.\n    DisableApTracking,\n}\n\n/// Error occurring while calculating the costing of a program's variables.\n#[derive(Error, Debug, Eq, PartialEq)]\npub enum ApChangeError {\n    #[error(\"error from the program registry\")]\n    ProgramRegistryError(#[from] Box<ProgramRegistryError>),\n    #[error(\"found an illegal statement index during ap change calculations\")]\n    StatementOutOfBounds(StatementIdx),\n    #[error(\"got a statement out of order during ap change calculations\")]\n    StatementOutOfOrder(StatementIdx),\n    #[error(\"Wrong number of libfunc branches in ap-change information\")]\n    WrongNumApChangeBranches(StatementIdx),\n    #[error(\"Attempted to merge branches with different number of allocated locals\")]\n    BadMergeAllocatedLocalsMismatch(StatementIdx),\n    #[error(\"Attempted to merge branches with different bases to align\")]\n    BadMergeBaseMismatch(StatementIdx),\n    #[error(\"failed solving the ap changes\")]\n    SolvingApChangeEquationFailed,\n}\n\n/// Helper to implement the `InvocationApChangeInfoProvider` for the equation generation.\nstruct InvocationApChangeInfoProviderForEqGen<'a, TokenUsages: Fn(CostTokenType) -> usize> {\n    /// Registry for providing the sizes of the types.\n    registry: &'a ProgramRegistry<CoreType, CoreLibfunc>,\n    /// Closure providing the token usages for the invocation.\n    token_usages: TokenUsages,\n}\n\nimpl<'a, TokenUsages: Fn(CostTokenType) -> usize> InvocationApChangeInfoProvider\n    for InvocationApChangeInfoProviderForEqGen<'a, TokenUsages>\n{\n    fn type_size(&self, ty: &ConcreteTypeId) -> usize {\n        self.registry.get_type(ty).unwrap().info().size as usize\n    }\n\n    fn token_usages(&self, token_type: CostTokenType) -> usize {\n        (self.token_usages)(token_type)\n    }\n}\n\n/// Calculates gas information for a given program.\npub fn calc_ap_changes<TokenUsages: Fn(StatementIdx, CostTokenType) -> usize>(\n    program: &Program,\n    token_usages: TokenUsages,\n) -> Result<ApChangeInfo, ApChangeError> {\n    let registry = ProgramRegistry::<CoreType, CoreLibfunc>::new(program)?;\n    let equations = generate_equations::generate_equations(program, |idx, libfunc_id| {\n        let libfunc = registry.get_libfunc(libfunc_id)?;\n        core_libfunc_ap_change::core_libfunc_ap_change(\n            libfunc,\n            &InvocationApChangeInfoProviderForEqGen {\n                registry: &registry,\n                token_usages: |token_type| token_usages(idx, token_type),\n            },\n        )\n        .into_iter()\n        .map(|ap_change| {\n            Ok(match ap_change {\n                ApChange::AtLocalsFinalization(known) => {\n                    Effects { ap_change: ApChange::Known(0), locals: known }\n                }\n                _ => Effects { ap_change, locals: 0 },\n            })\n        })\n        .collect::<Result<Vec<_>, _>>()\n    })?;\n    let minimization_vars =\n        equations.iter().flat_map(|eq| eq.var_to_coef.keys()).unique().cloned().collect();\n    let solution = cairo_lang_eq_solver::try_solve_equations(equations, vec![minimization_vars])\n        .ok_or(ApChangeError::SolvingApChangeEquationFailed)?;\n\n    let mut variable_values = OrderedHashMap::default();\n    let mut function_ap_change = OrderedHashMap::default();\n    for (var, value) in solution {\n        match var {\n            Var::LibfuncImplicitApChangeVariable(idx) => {\n                variable_values.insert(idx, value as usize)\n            }\n            Var::FunctionApChange(func_id) => function_ap_change.insert(func_id, value as usize),\n        };\n    }\n    Ok(ApChangeInfo { variable_values, function_ap_change })\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_sierra::extensions::builtin_cost::CostTokenType;\nuse cairo_lang_sierra::extensions::core::CoreConcreteLibfunc;\nuse cairo_lang_sierra::program::StatementIdx;\nuse cairo_lang_utils::collection_arithmetics::{add_maps, sub_maps};\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse itertools::zip_eq;\n\nuse crate::core_libfunc_cost_base::{core_libfunc_postcost, core_libfunc_precost, CostOperations};\npub use crate::core_libfunc_cost_base::{\n    ConstCost, InvocationCostInfoProvider, DICT_SQUASH_ACCESS_COST, DICT_SQUASH_FIXED_COST,\n    DICT_SQUASH_REPEATED_ACCESS_COST, DICT_SQUASH_UNIQUE_KEY_COST,\n};\nuse crate::gas_info::GasInfo;\npub use crate::starknet_libfunc_cost_base::SYSTEM_CALL_COST;\n\n/// Cost operations for getting `Option<i64>` costs values.\nstruct Ops<'a> {\n    gas_info: &'a GasInfo,\n    idx: StatementIdx,\n}\nimpl CostOperations for Ops<'_> {\n    type CostType = Option<OrderedHashMap<CostTokenType, i64>>;\n\n    fn cost_token(&self, value: i32, token_type: CostTokenType) -> Self::CostType {\n        Some(OrderedHashMap::from_iter([(token_type, value as i64)]))\n    }\n\n    fn function_token_cost(\n        &mut self,\n        function: &cairo_lang_sierra::program::Function,\n        token_type: CostTokenType,\n    ) -> Self::CostType {\n        let function_cost = self.gas_info.function_costs.get(&function.id)?;\n        Some(OrderedHashMap::from_iter([(\n            token_type,\n            function_cost.get(&token_type).copied().unwrap_or_default(),\n        )]))\n    }\n\n    fn statement_var_cost(&self, token_type: CostTokenType) -> Self::CostType {\n        Some(OrderedHashMap::from_iter([(\n            token_type,\n            *self.gas_info.variable_values.get(&(self.idx, token_type))?,\n        )]))\n    }\n\n    fn add(&self, lhs: Self::CostType, rhs: Self::CostType) -> Self::CostType {\n        Some(add_maps(lhs?, rhs?))\n    }\n\n    fn sub(&self, lhs: Self::CostType, rhs: Self::CostType) -> Self::CostType {\n        Some(sub_maps(lhs?, rhs?))\n    }\n}\n\n/// Returns the gas cost for a core libfunc.\n/// Values with unknown values will return as None.\npub fn core_libfunc_cost<InfoProvider: InvocationCostInfoProvider>(\n    gas_info: &GasInfo,\n    idx: &StatementIdx,\n    libfunc: &CoreConcreteLibfunc,\n    info_provider: &InfoProvider,\n) -> Vec<Option<OrderedHashMap<CostTokenType, i64>>> {\n    let precost = core_libfunc_precost(&mut Ops { gas_info, idx: *idx }, libfunc);\n    let postcost = core_libfunc_postcost(&mut Ops { gas_info, idx: *idx }, libfunc, info_provider);\n    zip_eq(precost, postcost)\n        .map(|(precost, postcost)| {\n            let precost = precost?;\n            let postcost = postcost?;\n            Some(\n                CostTokenType::iter()\n                    .map(|token| {\n                        (\n                            *token,\n                            precost.get(token).copied().unwrap_or_default()\n                                + postcost.get(token).copied().unwrap_or_default(),\n                        )\n                    })\n                    .collect(),\n            )\n        })\n        .collect()\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::iter;\n\nuse cairo_lang_sierra::extensions::array::ArrayConcreteLibfunc;\nuse cairo_lang_sierra::extensions::boolean::BoolConcreteLibfunc;\nuse cairo_lang_sierra::extensions::boxing::BoxConcreteLibfunc;\nuse cairo_lang_sierra::extensions::builtin_cost::{\n    BuiltinCostConcreteLibfunc, BuiltinCostWithdrawGasLibfunc, CostTokenType,\n};\nuse cairo_lang_sierra::extensions::casts::CastConcreteLibfunc;\nuse cairo_lang_sierra::extensions::core::CoreConcreteLibfunc::{\n    self, ApTracking, Array, Bitwise, Bool, Box, BranchAlign, BuiltinCost, Cast, Drop, Dup, Ec,\n    Enum, Felt252, Felt252Dict, FunctionCall, Gas, Mem, Pedersen, Struct, Uint128, Uint16, Uint32,\n    Uint64, Uint8, UnconditionalJump, UnwrapNonZero,\n};\nuse cairo_lang_sierra::extensions::ec::EcConcreteLibfunc;\nuse cairo_lang_sierra::extensions::enm::EnumConcreteLibfunc;\nuse cairo_lang_sierra::extensions::felt252::{\n    Felt252BinaryOperationConcrete, Felt252BinaryOperator, Felt252Concrete,\n};\nuse cairo_lang_sierra::extensions::felt252_dict::Felt252DictConcreteLibfunc;\nuse cairo_lang_sierra::extensions::function_call::FunctionCallConcreteLibfunc;\nuse cairo_lang_sierra::extensions::gas::GasConcreteLibfunc::{\n    GetAvailableGas, RedepositGas, WithdrawGas,\n};\nuse cairo_lang_sierra::extensions::mem::MemConcreteLibfunc::{\n    AllocLocal, FinalizeLocals, Rename, StoreLocal, StoreTemp,\n};\nuse cairo_lang_sierra::extensions::nullable::NullableConcreteLibfunc;\nuse cairo_lang_sierra::extensions::pedersen::PedersenConcreteLibfunc;\nuse cairo_lang_sierra::extensions::structure::StructConcreteLibfunc;\nuse cairo_lang_sierra::extensions::uint::{\n    IntOperator, Uint16Concrete, Uint32Concrete, Uint64Concrete, Uint8Concrete,\n};\nuse cairo_lang_sierra::extensions::uint128::Uint128Concrete;\nuse cairo_lang_sierra::extensions::ConcreteLibfunc;\nuse cairo_lang_sierra::ids::ConcreteTypeId;\nuse cairo_lang_sierra::program::Function;\nuse itertools::{chain, Itertools};\n\nuse crate::starknet_libfunc_cost_base::starknet_libfunc_cost_base;\n\n#[derive(Default, Debug)]\npub struct ConstCost {\n    pub steps: i32,\n    pub holes: i32,\n    pub range_checks: i32,\n}\nimpl ConstCost {\n    pub const fn cost(&self) -> i32 {\n        self.steps * 100 + self.holes * 10 + self.range_checks * 70\n    }\n}\n\n// The costs of the dict_squash libfunc, divided into different parts.\n/// The cost per each unique key in the dictionary.\npub const DICT_SQUASH_UNIQUE_KEY_COST: i32 =\n    ConstCost { steps: 55, holes: 0, range_checks: 6 }.cost();\n/// The cost per each access to a key after the first access.\npub const DICT_SQUASH_REPEATED_ACCESS_COST: i32 =\n    ConstCost { steps: 9, holes: 0, range_checks: 1 }.cost();\n/// The cost not dependent on the number of keys and access.\npub const DICT_SQUASH_FIXED_COST: i32 = ConstCost { steps: 75, holes: 0, range_checks: 3 }.cost();\n/// The cost to charge per each read/write access. `DICT_SQUASH_UNIQUE_KEY_COST` is refunded for\n/// each repeated access in dict_squash.\npub const DICT_SQUASH_ACCESS_COST: i32 =\n    DICT_SQUASH_UNIQUE_KEY_COST + DICT_SQUASH_REPEATED_ACCESS_COST;\n\n/// The operation required for extracting a libfunc's cost.\npub trait CostOperations {\n    type CostType: Clone;\n\n    /// Gets a cost from a constant value (of type [CostTokenType::Const]).\n    fn const_cost(&self, value: ConstCost) -> Self::CostType {\n        self.cost_token(value.cost(), CostTokenType::Const)\n    }\n\n    /// Gets a cost from step count.\n    fn steps(&self, steps: i32) -> Self::CostType {\n        self.const_cost(ConstCost { steps, ..ConstCost::default() })\n    }\n\n    /// Gets a cost from hole count.\n    fn holes(&self, holes: i32) -> Self::CostType {\n        self.const_cost(ConstCost { holes, ..ConstCost::default() })\n    }\n\n    /// Gets a cost from range check count.\n    fn range_checks(&self, range_checks: i32) -> Self::CostType {\n        self.const_cost(ConstCost { range_checks, ..ConstCost::default() })\n    }\n\n    /// Gets a cost of the given token type.\n    fn cost_token(&self, count: i32, token_type: CostTokenType) -> Self::CostType;\n    /// Gets a cost for the content of a function.\n    fn function_token_cost(\n        &mut self,\n        function: &Function,\n        token_type: CostTokenType,\n    ) -> Self::CostType;\n    /// Gets a cost for a variable for the current statement.\n    fn statement_var_cost(&self, token_type: CostTokenType) -> Self::CostType;\n    /// Adds costs.\n    fn add(&self, lhs: Self::CostType, rhs: Self::CostType) -> Self::CostType;\n    /// Subtracts costs.\n    fn sub(&self, lhs: Self::CostType, rhs: Self::CostType) -> Self::CostType;\n}\n\n/// Trait for providing extra information required for calculating costs for a specific libfunc\n/// invocation.\npub trait InvocationCostInfoProvider {\n    /// Provides the sizes of types.\n    fn type_size(&self, ty: &ConcreteTypeId) -> usize;\n    /// Number of tokens provided by the libfunc invocation (currently only relevant for\n    /// `withdraw_gas_all`).\n    fn token_usages(&self, token_type: CostTokenType) -> usize;\n    /// Provides the ap change variable value of the current statement.\n    fn ap_change_var_value(&self) -> usize;\n}\n\n/// Returns a precost value for a libfunc - the cost of non-step tokens.\n/// This is a helper function to implement costing both for creating\n/// gas equations and getting actual gas cost after having a solution.\npub fn core_libfunc_precost<Ops: CostOperations>(\n    ops: &mut Ops,\n    libfunc: &CoreConcreteLibfunc,\n) -> Vec<Ops::CostType> {\n    match libfunc {\n        FunctionCall(FunctionCallConcreteLibfunc { function, .. }) => {\n            let func_content_cost = CostTokenType::iter_precost()\n                .map(|token| ops.function_token_cost(function, *token))\n                .collect_vec()\n                .into_iter()\n                .reduce(|x, y| ops.add(x, y));\n            vec![func_content_cost.unwrap()]\n        }\n        Bitwise(_) => {\n            vec![ops.cost_token(1, CostTokenType::Bitwise)]\n        }\n        Ec(EcConcreteLibfunc::StateAddMul(_)) => {\n            vec![ops.cost_token(1, CostTokenType::EcOp)]\n        }\n        BranchAlign(_) => {\n            vec![statement_vars_cost(ops, CostTokenType::iter_precost())]\n        }\n        Pedersen(libfunc) => match libfunc {\n            PedersenConcreteLibfunc::PedersenHash(_) => {\n                vec![ops.cost_token(1, CostTokenType::Pedersen)]\n            }\n        },\n        BuiltinCost(BuiltinCostConcreteLibfunc::BuiltinWithdrawGas(_)) => {\n            vec![\n                ops.sub(ops.steps(0), statement_vars_cost(ops, CostTokenType::iter_precost())),\n                ops.steps(0),\n            ]\n        }\n        _ => libfunc.branch_signatures().iter().map(|_| ops.steps(0)).collect(),\n    }\n}\n\n/// Returns a postcost value for a libfunc - the cost of step token.\n/// This is a helper function to implement costing both for creating\n/// gas equations and getting actual gas cost after having a solution.\npub fn core_libfunc_postcost<Ops: CostOperations, InfoProvider: InvocationCostInfoProvider>(\n    ops: &mut Ops,\n    libfunc: &CoreConcreteLibfunc,\n    info_provider: &InfoProvider,\n) -> Vec<Ops::CostType> {\n    match libfunc {\n        // For the case of function calls - assumes a variable for the cost of running from a\n        // function entry point and on - while also adding the call cost.\n        FunctionCall(FunctionCallConcreteLibfunc { function, .. }) => {\n            let func_content_cost = ops.function_token_cost(function, CostTokenType::Const);\n            vec![ops.add(ops.steps(2), func_content_cost)]\n        }\n        Bitwise(_) => {\n            vec![ops.steps(2)]\n        }\n        Bool(BoolConcreteLibfunc::And(_)) => vec![ops.steps(0)],\n        Bool(BoolConcreteLibfunc::Not(_)) => vec![ops.steps(1)],\n        Bool(BoolConcreteLibfunc::Xor(_)) => vec![ops.steps(1)],\n        Bool(BoolConcreteLibfunc::Or(_)) => vec![ops.steps(2)],\n\n        Bool(BoolConcreteLibfunc::ToFelt252(_)) => vec![ops.steps(0)],\n        Cast(libfunc) => match libfunc {\n            CastConcreteLibfunc::Downcast(_) => {\n                vec![\n                    ops.add(ops.steps(3), ops.range_checks(1)),\n                    ops.add(ops.steps(4), ops.range_checks(1)),\n                ]\n            }\n            CastConcreteLibfunc::Upcast(_) => vec![ops.steps(0)],\n        },\n        Ec(libfunc) => match libfunc {\n            EcConcreteLibfunc::IsZero(_) => vec![ops.steps(1), ops.steps(1)],\n            EcConcreteLibfunc::Neg(_) => vec![ops.steps(0)],\n            EcConcreteLibfunc::StateAdd(_) => vec![ops.steps(10)],\n            EcConcreteLibfunc::TryNew(_) => vec![ops.steps(7), ops.steps(7)],\n            EcConcreteLibfunc::StateFinalize(_) => vec![ops.steps(12), ops.steps(6)],\n            EcConcreteLibfunc::StateInit(_) => vec![ops.steps(8)],\n            EcConcreteLibfunc::StateAddMul(_) => {\n                vec![ops.steps(5)]\n            }\n            EcConcreteLibfunc::PointFromX(_) => vec![\n                ops.add(ops.steps(14), ops.range_checks(3)), // Success.\n                ops.steps(9),                                // Failure.\n            ],\n            EcConcreteLibfunc::UnwrapPoint(_) => vec![ops.steps(0)],\n            EcConcreteLibfunc::Zero(_) => vec![ops.steps(0)],\n        },\n        Gas(WithdrawGas(_)) => {\n            vec![\n                ops.sub(\n                    ops.const_cost(ConstCost { steps: 3, holes: 0, range_checks: 1 }),\n                    ops.statement_var_cost(CostTokenType::Const),\n                ),\n                ops.const_cost(ConstCost { steps: 4, holes: 0, range_checks: 1 }),\n            ]\n        }\n        Gas(RedepositGas(_)) => vec![ops.statement_var_cost(CostTokenType::Const)],\n        Gas(GetAvailableGas(_)) => vec![ops.steps(0)],\n        BranchAlign(_) => {\n            let ap_change = info_provider.ap_change_var_value();\n            let burnt_cost = ops.statement_var_cost(CostTokenType::Const);\n            vec![if ap_change == 0 {\n                burnt_cost\n            } else {\n                ops.add(\n                    burnt_cost,\n                    ops.const_cost(ConstCost {\n                        steps: 1,\n                        holes: ap_change as i32,\n                        range_checks: 0,\n                    }),\n                )\n            }]\n        }\n        Array(ArrayConcreteLibfunc::New(_)) => vec![ops.steps(1)],\n        Array(ArrayConcreteLibfunc::Append(libfunc)) => {\n            vec![ops.steps(info_provider.type_size(&libfunc.ty) as i32)]\n        }\n\n        Array(ArrayConcreteLibfunc::PopFront(_))\n        | Array(ArrayConcreteLibfunc::SnapshotPopFront(_)) => vec![ops.steps(2), ops.steps(3)],\n        Array(ArrayConcreteLibfunc::Get(libfunc)) => {\n            if info_provider.type_size(&libfunc.ty) == 1 {\n                vec![\n                    ops.const_cost(ConstCost { steps: 5, holes: 0, range_checks: 1 }),\n                    ops.const_cost(ConstCost { steps: 5, holes: 0, range_checks: 1 }),\n                ]\n            } else {\n                vec![\n                    ops.const_cost(ConstCost { steps: 6, holes: 0, range_checks: 1 }),\n                    ops.const_cost(ConstCost { steps: 6, holes: 0, range_checks: 1 }),\n                ]\n            }\n        }\n        Array(ArrayConcreteLibfunc::Len(libfunc)) => {\n            vec![ops.steps(if info_provider.type_size(&libfunc.ty) == 1 { 0 } else { 1 })]\n        }\n        Uint128(libfunc) => u128_libfunc_cost(ops, libfunc),\n        Uint8(libfunc) => u8_libfunc_cost(ops, libfunc),\n        Uint16(libfunc) => u16_libfunc_cost(ops, libfunc),\n        Uint32(libfunc) => u32_libfunc_cost(ops, libfunc),\n        Uint64(libfunc) => u64_libfunc_cost(ops, libfunc),\n        Felt252(libfunc) => felt252_libfunc_cost(ops, libfunc),\n        Drop(_) | Dup(_) | ApTracking(_) | UnwrapNonZero(_) | Mem(Rename(_)) => {\n            vec![ops.steps(0)]\n        }\n        Box(libfunc) => match libfunc {\n            BoxConcreteLibfunc::Into(libfunc) => {\n                vec![ops.steps(std::cmp::max(\n                    1,\n                    info_provider.type_size(&libfunc.ty).try_into().unwrap(),\n                ))]\n            }\n            BoxConcreteLibfunc::Unbox(_) => vec![ops.steps(0)],\n        },\n        Mem(StoreTemp(libfunc)) => {\n            vec![ops.steps(info_provider.type_size(&libfunc.ty) as i32)]\n        }\n        Mem(StoreLocal(libfunc)) => {\n            let size = info_provider.type_size(&libfunc.ty) as i32;\n            vec![ops.const_cost(ConstCost { steps: size, holes: -size, range_checks: 0 })]\n        }\n        Mem(AllocLocal(libfunc)) => {\n            vec![ops.holes(info_provider.type_size(&libfunc.ty) as i32)]\n        }\n\n        Mem(FinalizeLocals(_)) | UnconditionalJump(_) => {\n            vec![ops.steps(1)]\n        }\n        Enum(EnumConcreteLibfunc::Init(_)) => vec![ops.steps(0)],\n        Enum(EnumConcreteLibfunc::Match(sig) | EnumConcreteLibfunc::SnapshotMatch(sig)) => {\n            let n = sig.signature.branch_signatures.len();\n            match n {\n                0 => unreachable!(),\n                1 => vec![ops.steps(0)],\n                2 => vec![ops.steps(1); 2],\n                _ => chain!(iter::once(ops.steps(1)), itertools::repeat_n(ops.steps(2), n - 1),)\n                    .collect_vec(),\n            }\n        }\n        Struct(\n            StructConcreteLibfunc::Construct(_)\n            | StructConcreteLibfunc::Deconstruct(_)\n            | StructConcreteLibfunc::SnapshotDeconstruct(_),\n        ) => {\n            vec![ops.steps(0)]\n        }\n        Felt252Dict(Felt252DictConcreteLibfunc::New(_)) => {\n            vec![ops.steps(9)]\n        }\n        Felt252Dict(Felt252DictConcreteLibfunc::Read(_)) => {\n            vec![\n                ops.add(\n                    ops.steps(3),\n                    ops.cost_token(DICT_SQUASH_ACCESS_COST, CostTokenType::Const),\n                ),\n            ]\n        }\n        Felt252Dict(Felt252DictConcreteLibfunc::Write(_)) => {\n            vec![\n                ops.add(\n                    ops.steps(2),\n                    ops.cost_token(DICT_SQUASH_ACCESS_COST, CostTokenType::Const),\n                ),\n            ]\n        }\n        Felt252Dict(Felt252DictConcreteLibfunc::Squash(_)) => {\n            // Dict squash have a fixed cost of 'DICT_SQUASH_CONST_COST' + `DICT_SQUASH_ACCESS_COST`\n            // for each dict access. Only the fixed cost is charged here, so that we\n            // would alway be able to call squash even if running out of gas. The cost\n            // of the proccesing of the first key is `DICT_SQUASH_ACCESS_COST`, and each\n            // access for an existing key costs only 'DICT_SQUASH_REPEATED_ACCESS_COST'.\n            // In each read/write we charge `DICT_SQUASH_ACCESS_COST` gas and\n            // `DICT_SQUASH_ACCESS_COST - DICT_SQUASH_REPEATED_ACCESS_COST` gas are refunded per\n            // each succesive access in dict squash.\n            vec![ops.cost_token(DICT_SQUASH_FIXED_COST, CostTokenType::Const)]\n        }\n        Pedersen(libfunc) => match libfunc {\n            PedersenConcreteLibfunc::PedersenHash(_) => vec![ops.steps(2)],\n        },\n        BuiltinCost(builtin_libfunc) => match builtin_libfunc {\n            BuiltinCostConcreteLibfunc::BuiltinWithdrawGas(_) => {\n                let cost_computation =\n                    BuiltinCostWithdrawGasLibfunc::cost_computation_steps(|token_type| {\n                        info_provider.token_usages(token_type)\n                    }) as i32;\n                vec![\n                    ops.sub(\n                        ops.const_cost(ConstCost {\n                            steps: cost_computation + 3,\n                            holes: 0,\n                            range_checks: 1,\n                        }),\n                        ops.statement_var_cost(CostTokenType::Const),\n                    ),\n                    ops.const_cost(ConstCost {\n                        steps: cost_computation + 5,\n                        holes: 0,\n                        range_checks: 1,\n                    }),\n                ]\n            }\n            BuiltinCostConcreteLibfunc::GetBuiltinCosts(_) => vec![ops.steps(3)],\n        },\n        CoreConcreteLibfunc::StarkNet(libfunc) => starknet_libfunc_cost_base(ops, libfunc),\n        CoreConcreteLibfunc::Nullable(libfunc) => match libfunc {\n            NullableConcreteLibfunc::Null(_) => vec![ops.steps(0)],\n            NullableConcreteLibfunc::NullableFromBox(_) => vec![ops.steps(0)],\n            NullableConcreteLibfunc::MatchNullable(_) => vec![ops.steps(1), ops.steps(1)],\n        },\n        CoreConcreteLibfunc::Debug(_) => vec![ops.steps(1)],\n        CoreConcreteLibfunc::SnapshotTake(_) => vec![ops.steps(0)],\n    }\n}\n\n/// Returns the sum of statement variables for all the requested tokens.\nfn statement_vars_cost<'a, Ops: CostOperations, TokenTypes: Iterator<Item = &'a CostTokenType>>(\n    ops: &Ops,\n    token_types: TokenTypes,\n) -> Ops::CostType {\n    token_types\n        .map(|token_type| ops.statement_var_cost(*token_type))\n        .reduce(|x, y| ops.add(x, y))\n        .unwrap()\n}\n\n/// Returns costs for u8 libfuncs.\nfn u8_libfunc_cost<Ops: CostOperations>(ops: &Ops, libfunc: &Uint8Concrete) -> Vec<Ops::CostType> {\n    match libfunc {\n        Uint8Concrete::Const(_) | Uint8Concrete::ToFelt252(_) | Uint8Concrete::WideMul(_) => {\n            vec![ops.steps(0)]\n        }\n        Uint8Concrete::Operation(libfunc) => match libfunc.operator {\n            IntOperator::OverflowingAdd => {\n                vec![\n                    ops.const_cost(ConstCost { steps: 4, holes: 0, range_checks: 1 }),\n                    ops.const_cost(ConstCost { steps: 5, holes: 0, range_checks: 1 }),\n                ]\n            }\n            IntOperator::OverflowingSub => {\n                vec![\n                    ops.const_cost(ConstCost { steps: 3, holes: 0, range_checks: 1 }),\n                    ops.const_cost(ConstCost { steps: 6, holes: 0, range_checks: 1 }),\n                ]\n            }\n        },\n        Uint8Concrete::LessThan(_) => {\n            vec![\n                ops.const_cost(ConstCost { steps: 3, holes: 0, range_checks: 1 }),\n                ops.const_cost(ConstCost { steps: 5, holes: 0, range_checks: 1 }),\n            ]\n        }\n        Uint8Concrete::SquareRoot(_) => {\n            vec![ops.const_cost(ConstCost { steps: 9, holes: 0, range_checks: 4 })]\n        }\n        Uint8Concrete::Equal(_) => {\n            vec![ops.steps(2), ops.steps(3)]\n        }\n        Uint8Concrete::LessThanOrEqual(_) => {\n            vec![\n                ops.const_cost(ConstCost { steps: 4, holes: 0, range_checks: 1 }),\n                ops.const_cost(ConstCost { steps: 4, holes: 0, range_checks: 1 }),\n            ]\n        }\n        Uint8Concrete::FromFelt252(_) => {\n            vec![\n                ops.const_cost(ConstCost { steps: 4, holes: 0, range_checks: 2 }),\n                ops.const_cost(ConstCost { steps: 10, holes: 0, range_checks: 3 }),\n            ]\n        }\n        Uint8Concrete::IsZero(_) => vec![ops.steps(1), ops.steps(1)],\n        Uint8Concrete::Divmod(_) => {\n            vec![ops.const_cost(ConstCost { steps: 7, holes: 0, range_checks: 3 })]\n        }\n    }\n}\n\n/// Returns costs for u16 libfuncs.\nfn u16_libfunc_cost<Ops: CostOperations>(\n    ops: &Ops,\n    libfunc: &Uint16Concrete,\n) -> Vec<Ops::CostType> {\n    match libfunc {\n        Uint16Concrete::Const(_) | Uint16Concrete::ToFelt252(_) | Uint16Concrete::WideMul(_) => {\n            vec![ops.steps(0)]\n        }\n        Uint16Concrete::Operation(libfunc) => match libfunc.operator {\n            IntOperator::OverflowingAdd => {\n                vec![\n                    ops.const_cost(ConstCost { steps: 4, holes: 0, range_checks: 1 }),\n                    ops.const_cost(ConstCost { steps: 5, holes: 0, range_checks: 1 }),\n                ]\n            }\n            IntOperator::OverflowingSub => {\n                vec![\n                    ops.const_cost(ConstCost { steps: 3, holes: 0, range_checks: 1 }),\n                    ops.const_cost(ConstCost { steps: 6, holes: 0, range_checks: 1 }),\n                ]\n            }\n        },\n        Uint16Concrete::LessThan(_) => {\n            vec![\n                ops.const_cost(ConstCost { steps: 3, holes: 0, range_checks: 1 }),\n                ops.const_cost(ConstCost { steps: 5, holes: 0, range_checks: 1 }),\n            ]\n        }\n        Uint16Concrete::SquareRoot(_) => {\n            vec![ops.const_cost(ConstCost { steps: 9, holes: 0, range_checks: 4 })]\n        }\n        Uint16Concrete::Equal(_) => {\n            vec![ops.steps(2), ops.steps(3)]\n        }\n        Uint16Concrete::LessThanOrEqual(_) => {\n            vec![\n                ops.const_cost(ConstCost { steps: 4, holes: 0, range_checks: 1 }),\n                ops.const_cost(ConstCost { steps: 4, holes: 0, range_checks: 1 }),\n            ]\n        }\n        Uint16Concrete::FromFelt252(_) => {\n            vec![\n                ops.const_cost(ConstCost { steps: 4, holes: 0, range_checks: 2 }),\n                ops.const_cost(ConstCost { steps: 10, holes: 0, range_checks: 3 }),\n            ]\n        }\n        Uint16Concrete::IsZero(_) => vec![ops.steps(1), ops.steps(1)],\n        Uint16Concrete::Divmod(_) => {\n            vec![ops.const_cost(ConstCost { steps: 7, holes: 0, range_checks: 3 })]\n        }\n    }\n}\n\n/// Returns costs for u32 libfuncs.\nfn u32_libfunc_cost<Ops: CostOperations>(\n    ops: &Ops,\n    libfunc: &Uint32Concrete,\n) -> Vec<Ops::CostType> {\n    match libfunc {\n        Uint32Concrete::Const(_) | Uint32Concrete::ToFelt252(_) | Uint32Concrete::WideMul(_) => {\n            vec![ops.steps(0)]\n        }\n        Uint32Concrete::Operation(libfunc) => match libfunc.operator {\n            IntOperator::OverflowingAdd => {\n                vec![\n                    ops.const_cost(ConstCost { steps: 4, holes: 0, range_checks: 1 }),\n                    ops.const_cost(ConstCost { steps: 5, holes: 0, range_checks: 1 }),\n                ]\n            }\n            IntOperator::OverflowingSub => {\n                vec![\n                    ops.const_cost(ConstCost { steps: 3, holes: 0, range_checks: 1 }),\n                    ops.const_cost(ConstCost { steps: 6, holes: 0, range_checks: 1 }),\n                ]\n            }\n        },\n        Uint32Concrete::LessThan(_) => {\n            vec![\n                ops.const_cost(ConstCost { steps: 3, holes: 0, range_checks: 1 }),\n                ops.const_cost(ConstCost { steps: 5, holes: 0, range_checks: 1 }),\n            ]\n        }\n        Uint32Concrete::SquareRoot(_) => {\n            vec![ops.const_cost(ConstCost { steps: 9, holes: 0, range_checks: 4 })]\n        }\n        Uint32Concrete::Equal(_) => {\n            vec![ops.steps(2), ops.steps(3)]\n        }\n        Uint32Concrete::LessThanOrEqual(_) => {\n            vec![\n                ops.const_cost(ConstCost { steps: 4, holes: 0, range_checks: 1 }),\n                ops.const_cost(ConstCost { steps: 4, holes: 0, range_checks: 1 }),\n            ]\n        }\n        Uint32Concrete::FromFelt252(_) => {\n            vec![\n                ops.const_cost(ConstCost { steps: 4, holes: 0, range_checks: 2 }),\n                ops.const_cost(ConstCost { steps: 10, holes: 0, range_checks: 3 }),\n            ]\n        }\n        Uint32Concrete::IsZero(_) => vec![ops.steps(1), ops.steps(1)],\n        Uint32Concrete::Divmod(_) => {\n            vec![ops.const_cost(ConstCost { steps: 7, holes: 0, range_checks: 3 })]\n        }\n    }\n}\n\n/// Returns costs for u64 libfuncs.\nfn u64_libfunc_cost<Ops: CostOperations>(\n    ops: &Ops,\n    libfunc: &Uint64Concrete,\n) -> Vec<Ops::CostType> {\n    match libfunc {\n        Uint64Concrete::Const(_) | Uint64Concrete::ToFelt252(_) | Uint64Concrete::WideMul(_) => {\n            vec![ops.steps(0)]\n        }\n        Uint64Concrete::Operation(libfunc) => match libfunc.operator {\n            IntOperator::OverflowingAdd => {\n                vec![\n                    ops.const_cost(ConstCost { steps: 4, holes: 0, range_checks: 1 }),\n                    ops.const_cost(ConstCost { steps: 5, holes: 0, range_checks: 1 }),\n                ]\n            }\n            IntOperator::OverflowingSub => {\n                vec![\n                    ops.const_cost(ConstCost { steps: 3, holes: 0, range_checks: 1 }),\n                    ops.const_cost(ConstCost { steps: 6, holes: 0, range_checks: 1 }),\n                ]\n            }\n        },\n        Uint64Concrete::LessThan(_) => {\n            vec![\n                ops.const_cost(ConstCost { steps: 3, holes: 0, range_checks: 1 }),\n                ops.const_cost(ConstCost { steps: 5, holes: 0, range_checks: 1 }),\n            ]\n        }\n        Uint64Concrete::SquareRoot(_) => {\n            vec![ops.const_cost(ConstCost { steps: 9, holes: 0, range_checks: 4 })]\n        }\n        Uint64Concrete::Equal(_) => {\n            vec![ops.steps(2), ops.steps(3)]\n        }\n        Uint64Concrete::LessThanOrEqual(_) => {\n            vec![\n                ops.const_cost(ConstCost { steps: 4, holes: 0, range_checks: 1 }),\n                ops.const_cost(ConstCost { steps: 4, holes: 0, range_checks: 1 }),\n            ]\n        }\n        Uint64Concrete::FromFelt252(_) => {\n            vec![\n                ops.const_cost(ConstCost { steps: 4, holes: 0, range_checks: 2 }),\n                ops.const_cost(ConstCost { steps: 10, holes: 0, range_checks: 3 }),\n            ]\n        }\n        Uint64Concrete::IsZero(_) => vec![ops.steps(1), ops.steps(1)],\n        Uint64Concrete::Divmod(_) => {\n            vec![ops.const_cost(ConstCost { steps: 7, holes: 0, range_checks: 3 })]\n        }\n    }\n}\n\n/// Returns costs for u128 libfuncs.\nfn u128_libfunc_cost<Ops: CostOperations>(\n    ops: &Ops,\n    libfunc: &Uint128Concrete,\n) -> Vec<Ops::CostType> {\n    match libfunc {\n        Uint128Concrete::Operation(libfunc) => match libfunc.operator {\n            IntOperator::OverflowingAdd | IntOperator::OverflowingSub => {\n                vec![\n                    ops.const_cost(ConstCost { steps: 3, holes: 0, range_checks: 1 }),\n                    ops.const_cost(ConstCost { steps: 5, holes: 0, range_checks: 1 }),\n                ]\n            }\n        },\n        Uint128Concrete::Divmod(_) => {\n            vec![ops.const_cost(ConstCost { steps: 11, holes: 0, range_checks: 4 })]\n        }\n        Uint128Concrete::WideMul(_) => {\n            vec![ops.const_cost(ConstCost { steps: 23, holes: 0, range_checks: 9 })]\n        }\n        Uint128Concrete::Const(_) | Uint128Concrete::ToFelt252(_) => {\n            vec![ops.steps(0)]\n        }\n        Uint128Concrete::FromFelt252(_) => {\n            vec![\n                ops.const_cost(ConstCost { steps: 2, holes: 0, range_checks: 1 }),\n                ops.const_cost(ConstCost { steps: 11, holes: 0, range_checks: 3 }),\n            ]\n        }\n        Uint128Concrete::IsZero(_) => {\n            vec![ops.steps(1), ops.steps(1)]\n        }\n        Uint128Concrete::LessThan(_) => {\n            vec![\n                ops.const_cost(ConstCost { steps: 3, holes: 0, range_checks: 1 }),\n                ops.const_cost(ConstCost { steps: 5, holes: 0, range_checks: 1 }),\n            ]\n        }\n        Uint128Concrete::Equal(_) => {\n            vec![ops.steps(2), ops.steps(3)]\n        }\n        Uint128Concrete::SquareRoot(_) => {\n            vec![ops.const_cost(ConstCost { steps: 9, holes: 0, range_checks: 4 })]\n        }\n        Uint128Concrete::LessThanOrEqual(_) => {\n            vec![\n                ops.const_cost(ConstCost { steps: 4, holes: 0, range_checks: 1 }),\n                ops.const_cost(ConstCost { steps: 4, holes: 0, range_checks: 1 }),\n            ]\n        }\n    }\n}\n\n/// Returns costs for felt252 libfuncs.\nfn felt252_libfunc_cost<Ops: CostOperations>(\n    ops: &Ops,\n    libfunc: &Felt252Concrete,\n) -> Vec<Ops::CostType> {\n    match libfunc {\n        Felt252Concrete::BinaryOperation(bin_op) => {\n            let op = match bin_op {\n                Felt252BinaryOperationConcrete::WithVar(op) => op.operator,\n                Felt252BinaryOperationConcrete::WithConst(op) => op.operator,\n            };\n            if op == Felt252BinaryOperator::Div { vec![ops.steps(5)] } else { vec![ops.steps(0)] }\n        }\n        Felt252Concrete::Const(_) => vec![ops.steps(0)],\n        Felt252Concrete::IsZero(_) => {\n            vec![ops.steps(1), ops.steps(1)]\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_sierra::extensions::builtin_cost::CostTokenType;\nuse cairo_lang_sierra::extensions::core::CoreConcreteLibfunc;\nuse cairo_lang_sierra::program::StatementIdx;\nuse cairo_lang_utils::collection_arithmetics::{add_maps, sub_maps};\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\n\nuse crate::core_libfunc_cost_base::{\n    core_libfunc_postcost, core_libfunc_precost, CostOperations, InvocationCostInfoProvider,\n};\nuse crate::cost_expr::{CostExpr, Var};\nuse crate::generate_equations::StatementFutureCost;\n\npub type CostExprMap = OrderedHashMap<CostTokenType, CostExpr>;\n\n/// Cost operations for getting `CostExpr` costs values.\nstruct Ops<'a> {\n    statement_future_cost: &'a mut dyn StatementFutureCost,\n    idx: StatementIdx,\n}\nimpl CostOperations for Ops<'_> {\n    type CostType = CostExprMap;\n\n    fn cost_token(&self, value: i32, token_type: CostTokenType) -> Self::CostType {\n        Self::CostType::from_iter([(token_type, CostExpr::from_const(value))])\n    }\n\n    fn function_token_cost(\n        &mut self,\n        function: &cairo_lang_sierra::program::Function,\n        token_type: CostTokenType,\n    ) -> Self::CostType {\n        Self::CostType::from_iter([(\n            token_type,\n            self.statement_future_cost.get_future_cost(&function.entry_point)[token_type].clone(),\n        )])\n    }\n\n    fn statement_var_cost(&self, token_type: CostTokenType) -> Self::CostType {\n        Self::CostType::from_iter([(\n            token_type,\n            CostExpr::from_var(Var::LibfuncImplicitGasVariable(self.idx, token_type)),\n        )])\n    }\n\n    fn add(&self, lhs: Self::CostType, rhs: Self::CostType) -> Self::CostType {\n        add_maps(lhs, rhs)\n    }\n\n    fn sub(&self, lhs: Self::CostType, rhs: Self::CostType) -> Self::CostType {\n        sub_maps(lhs, rhs)\n    }\n}\n\n/// Returns an expression for the gas cost for core libfuncs.\npub fn core_libfunc_precost_expr(\n    statement_future_cost: &mut dyn StatementFutureCost,\n    idx: &StatementIdx,\n    libfunc: &CoreConcreteLibfunc,\n) -> Vec<CostExprMap> {\n    core_libfunc_precost(&mut Ops { statement_future_cost, idx: *idx }, libfunc)\n}\n\n/// Returns an expression for the gas cost for core libfuncs.\npub fn core_libfunc_postcost_expr<InfoProvider: InvocationCostInfoProvider>(\n    statement_future_cost: &mut dyn StatementFutureCost,\n    idx: &StatementIdx,\n    libfunc: &CoreConcreteLibfunc,\n    info_provider: &InfoProvider,\n) -> Vec<CostExprMap> {\n    core_libfunc_postcost(&mut Ops { statement_future_cost, idx: *idx }, libfunc, info_provider)\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use core::fmt;\n\nuse cairo_lang_eq_solver::Expr;\nuse cairo_lang_sierra::extensions::builtin_cost::CostTokenType;\nuse cairo_lang_sierra::program::StatementIdx;\n\n/// Variable parts of a cost expression.\n#[derive(Clone, Debug, Hash, PartialEq, Eq)]\npub enum Var {\n    /// Variables supplied for a libfunc at statement id (e.g. withdraw_gas, redeposit_gas).\n    LibfuncImplicitGasVariable(StatementIdx, CostTokenType),\n    /// Variable marking on a statement's future cost (any route from it to a return).\n    StatementFuture(StatementIdx, CostTokenType),\n}\nimpl fmt::Display for Var {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            Var::LibfuncImplicitGasVariable(idx, token_type) => {\n                write!(f, \"libfunc@{token_type:?}{idx}\")\n            }\n            Var::StatementFuture(idx, token_type) => write!(f, \"future@{token_type:?}{idx}\"),\n        }\n    }\n}\n\n/// An expression of a full cost.\npub type CostExpr = Expr<Var>;\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::fmt::Display;\n\nuse cairo_lang_sierra::extensions::builtin_cost::CostTokenType;\nuse cairo_lang_sierra::ids::FunctionId;\nuse cairo_lang_sierra::program::StatementIdx;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse itertools::{chain, Itertools};\n\n/// Gas information for a Sierra program.\n#[derive(Debug, Eq, PartialEq)]\npub struct GasInfo {\n    /// The values of variables at matching libfuncs at given statements indices.\n    pub variable_values: OrderedHashMap<(StatementIdx, CostTokenType), i64>,\n    /// The costs of calling the given function.\n    pub function_costs: OrderedHashMap<FunctionId, OrderedHashMap<CostTokenType, i64>>,\n}\nimpl GasInfo {\n    pub fn combine(mut self, mut other: GasInfo) -> GasInfo {\n        let variable_values = chain!(self.variable_values.keys(), other.variable_values.keys())\n            .unique()\n            .copied()\n            .map(|i| {\n                (\n                    i,\n                    self.variable_values.get(&i).copied().unwrap_or_default()\n                        + other.variable_values.get(&i).copied().unwrap_or_default(),\n                )\n            })\n            .collect();\n        let function_costs = chain!(self.function_costs.keys(), other.function_costs.keys())\n            .unique()\n            .cloned()\n            .collect_vec()\n            .into_iter()\n            .map(|i| {\n                let costs0 = self.function_costs.swap_remove(&i).unwrap_or_default();\n                let costs1 = other.function_costs.swap_remove(&i).unwrap_or_default();\n                (\n                    i,\n                    chain!(costs0.keys(), costs1.keys())\n                        .unique()\n                        .copied()\n                        .map(|i| {\n                            (\n                                i,\n                                costs0.get(&i).copied().unwrap_or_default()\n                                    + costs1.get(&i).copied().unwrap_or_default(),\n                            )\n                        })\n                        .collect(),\n                )\n            })\n            .collect();\n\n        GasInfo { variable_values, function_costs }\n    }\n}\n\nimpl Display for GasInfo {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        for ((statement_idx, cost_type), value) in self.variable_values.iter() {\n            writeln!(f, \"#{statement_idx}: {}({value})\", cost_type.name())?;\n        }\n        writeln!(f)?;\n        for (function_id, costs) in self.function_costs.iter() {\n            writeln!(f, \"{function_id}:\")?;\n            for (cost_type, value) in costs.iter() {\n                writeln!(f, \"{}({value})\", cost_type.name())?;\n            }\n        }\n        Ok(())\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_sierra::extensions::builtin_cost::CostTokenType;\nuse cairo_lang_sierra::ids::ConcreteLibfuncId;\nuse cairo_lang_sierra::program::{Program, StatementIdx};\nuse cairo_lang_utils::collection_arithmetics::{add_maps, sub_maps};\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse itertools::zip_eq;\n\nuse super::CostError;\nuse crate::core_libfunc_cost_expr::CostExprMap;\nuse crate::cost_expr::{CostExpr, Var};\n\n#[cfg(test)]\n#[path = \"generate_equations_test.rs\"]\nmod test;\n\n/// Trait for getting the future cost expressions of statements.\npub trait StatementFutureCost {\n    /// Returns the future cost starting from a statement.\n    fn get_future_cost(&mut self, idx: &StatementIdx) -> &CostExprMap;\n}\n\n/// Generates a set of equations from a program, and a function to extract cost expressions from a\n/// library function id.\npub fn generate_equations<\n    GetCost: Fn(&mut dyn StatementFutureCost, &StatementIdx, &ConcreteLibfuncId) -> Vec<CostExprMap>,\n>(\n    program: &Program,\n    get_cost: GetCost,\n) -> Result<OrderedHashMap<CostTokenType, Vec<CostExpr>>, CostError> {\n    // Calculating first to fail early.\n    let statement_topological_ordering = get_reverse_topological_ordering(program)?;\n    // Vector containing the cost from a statement until the end of the function in some path (may\n    // be a variable).\n    let mut generator = EquationGenerator::new(vec![None; program.statements.len()]);\n    // Adding a variable for every function entry point.\n    for func in &program.funcs {\n        generator.get_future_cost(&func.entry_point);\n    }\n    // Using reverse topological order to go over the program statement so that we'd use less\n    // variables (since we create variables in any case where we don't already have a cost\n    // expression).\n    for idx in statement_topological_ordering {\n        match &program.get_statement(&idx).unwrap() {\n            cairo_lang_sierra::program::Statement::Return(_) => {\n                generator.set_or_add_constraint(&idx, CostExprMap::default());\n            }\n            cairo_lang_sierra::program::Statement::Invocation(invocation) => {\n                let libfunc_cost = get_cost(&mut generator, &idx, &invocation.libfunc_id);\n                for (branch, branch_cost) in zip_eq(&invocation.branches, libfunc_cost) {\n                    let next_future_cost =\n                        generator.get_future_cost(&idx.next(&branch.target)).clone();\n                    generator.set_or_add_constraint(&idx, add_maps(branch_cost, next_future_cost));\n                }\n            }\n        }\n    }\n    Ok(generator.equations)\n}\n\n/// Helper to generate the equations for calculating gas variables.\nstruct EquationGenerator {\n    pub future_costs: Vec<Option<CostExprMap>>,\n    pub equations: OrderedHashMap<CostTokenType, Vec<CostExpr>>,\n}\nimpl EquationGenerator {\n    fn new(future_costs: Vec<Option<CostExprMap>>) -> Self {\n        Self {\n            future_costs,\n            equations: OrderedHashMap::from_iter(\n                CostTokenType::iter().map(|token_type| (*token_type, vec![])),\n            ),\n        }\n    }\n\n    /// Sets some future or adds a matching equation if already set.\n    fn set_or_add_constraint(&mut self, idx: &StatementIdx, cost: CostExprMap) {\n        let entry = &mut self.future_costs[idx.0];\n        if let Some(other) = entry {\n            for (token_type, val) in sub_maps(other.clone(), cost) {\n                self.equations[token_type].push(val);\n            }\n        } else {\n            *entry = Some(cost);\n        }\n    }\n}\nimpl StatementFutureCost for EquationGenerator {\n    /// Returns the future cost starting from a statement, will additionally make sure this\n    /// statement actually exists.\n    fn get_future_cost(&mut self, idx: &StatementIdx) -> &CostExprMap {\n        let entry = &mut self.future_costs[idx.0];\n        if let Some(other) = entry {\n            other\n        } else {\n            entry.insert(CostExprMap::from_iter(CostTokenType::iter().map(|token_type| {\n                (*token_type, CostExpr::from_var(Var::StatementFuture(*idx, *token_type)))\n            })))\n        }\n    }\n}\n\n/// Returns the reverse topological ordering of the program statements.\nfn get_reverse_topological_ordering(program: &Program) -> Result<Vec<StatementIdx>, CostError> {\n    let mut ordering = vec![];\n    let mut visited = vec![false; program.statements.len()];\n    for f in &program.funcs {\n        calculate_reverse_topological_ordering(\n            program,\n            &mut ordering,\n            &mut visited,\n            &f.entry_point,\n        )?;\n    }\n    Ok(ordering)\n}\n\n/// Recursively calculates the topological ordering of the program.\nfn calculate_reverse_topological_ordering(\n    program: &Program,\n    ordering: &mut Vec<StatementIdx>,\n    visited: &mut Vec<bool>,\n    idx: &StatementIdx,\n) -> Result<(), CostError> {\n    match visited.get(idx.0) {\n        Some(true) => {\n            return Ok(());\n        }\n        Some(false) => {}\n        None => {\n            return Err(CostError::StatementOutOfBounds(*idx));\n        }\n    }\n    visited[idx.0] = true;\n    match program.get_statement(idx).unwrap() {\n        cairo_lang_sierra::program::Statement::Invocation(invocation) => {\n            for branch in &invocation.branches {\n                calculate_reverse_topological_ordering(\n                    program,\n                    ordering,\n                    visited,\n                    &idx.next(&branch.target),\n                )?;\n            }\n        }\n        cairo_lang_sierra::program::Statement::Return(_) => {}\n    }\n    // Adding element to ordering after visiting all children - therefore we have reverse\n    // topological ordering.\n    ordering.push(*idx);\n    Ok(())\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashMap;\n\nuse cairo_lang_sierra::extensions::builtin_cost::CostTokenType;\nuse cairo_lang_sierra::ids::ConcreteLibfuncId;\nuse cairo_lang_sierra::program::StatementIdx;\nuse indoc::indoc;\nuse test_case::test_case;\n\nuse super::generate_equations;\nuse crate::core_libfunc_cost_expr::CostExprMap;\nuse crate::cost_expr::{CostExpr, Var};\nuse crate::CostError;\n\n/// Returns a cost expression for a statement future variable.\nfn future_statement_cost(idx: usize) -> CostExpr {\n    CostExpr::from_var(Var::StatementFuture(StatementIdx(idx), CostTokenType::Const))\n}\n\n/// Returns a cost expression for a libfunc variable.\nfn libfunc_cost(idx: usize) -> CostExpr {\n    CostExpr::from_var(Var::LibfuncImplicitGasVariable(StatementIdx(idx), CostTokenType::Const))\n}\n\n#[test_case(indoc! {\"\n                return();\n                test_program@0() -> ();\n            \"},\n            HashMap::new() =>\n            Ok(vec![(future_statement_cost(0))]);\n            \"return only\")]\n#[test_case(indoc! {\"\n                cost1() -> ();\n                cost2() -> ();\n                return();\n                test_program@0() -> ();\n            \"},\n            HashMap::from([\n                (\"cost1\".into(), vec![CostExpr::from_const(1)]),\n                (\"cost2\".into(), vec![CostExpr::from_const(2)]),\n            ]) =>\n            Ok(vec![(future_statement_cost(0) - CostExpr::from_const(3))]);\n            \"simple cost sum\")]\n#[test_case(indoc! {\"\n                var_x() -> ();\n                cost1() -> ();\n                return();\n                test_program@0() -> ();\n            \"},\n            HashMap::from([\n                (\"var_x\".into(), vec![libfunc_cost(0)]),\n                (\"cost1\".into(), vec![CostExpr::from_const(1)]),\n            ]) =>\n            Ok(vec![\n                (future_statement_cost(0) - (CostExpr::from_const(1) + libfunc_cost(0)))\n            ]);\n            \"single var\")]\n#[test_case(indoc! {\"\n                // Traversal index = 3 - future_next = Var::Statement(0) - due to function.\n                cost1() -> ();\n                // Traversal index = 2 - future_next = Var::Statement(1) - due to cycle.\n                cost2() -> ();\n                // Traversal index = 1 - future_next = Var::Statement(1) + 4 - first branch + step.\n                jump_back() { 1() fallthrough() };\n                // Traversal index = 0 - future_next = 0 - since it is a return.\n                return();\n                test_program@0() -> ();\n            \"},\n            HashMap::from([\n                (\"cost1\".into(), vec![CostExpr::from_const(1)]),\n                (\"cost2\".into(), vec![CostExpr::from_const(2)]),\n                (\"jump_back\".into(), vec![CostExpr::from_const(3), CostExpr::from_const(4)]),\n            ]) =>\n            Ok(vec![\n                // Since 'jump_back' is the first non trivial traversed statement, a variable\n                // for statement 1 would be created, and this value add with the cost of the step\n                // to it would be equal to the cost of the other step.\n                (future_statement_cost(1) - CostExpr::from_const(1)),\n                // Next 'cost2' is used, so the equation is the variable of the line, equals to the\n                // cost of the next line + the step cost.\n                (CostExpr::from_const(-(3 + 2))),\n                // The equation for the function and the step to the following cycle variable.\n                (future_statement_cost(0) -future_statement_cost(1) - CostExpr::from_const(1)),\n            ]);\n            \"simple cycle\")]\n#[test_case(indoc! {\"\n                return();\n                test_program@1() -> ();\n            \"},\n            HashMap::new() =>\n            Err(CostError::StatementOutOfBounds(StatementIdx(1)));\n            \"handle bad function entry point\")]\n#[test_case(indoc! {\"\n                jump() { 4() };\n                return();\n                test_program@0() -> ();\n            \"},\n            HashMap::new() =>\n            Err(CostError::StatementOutOfBounds(StatementIdx(4)));\n            \"handle bad jump target\")]\nfn generate(\n    code: &str,\n    costs: HashMap<ConcreteLibfuncId, Vec<CostExpr>>,\n) -> Result<Vec<CostExpr>, CostError> {\n    Ok(generate_equations(\n        &cairo_lang_sierra::ProgramParser::new().parse(code).unwrap(),\n        |_, _idx, libfunc_id| {\n            costs\n                .get(libfunc_id)\n                .unwrap()\n                .iter()\n                .map(|x| CostExprMap::from_iter([(CostTokenType::Const, x.clone())]))\n                .collect()\n        },\n    )?[CostTokenType::Const]\n        .clone())\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Sierra gas computation.\n//!\n//! This crate provides the gas computation for the Cairo programs.\n\nuse cairo_lang_eq_solver::Expr;\nuse cairo_lang_sierra::extensions::builtin_cost::CostTokenType;\nuse cairo_lang_sierra::extensions::core::{CoreLibfunc, CoreType};\nuse cairo_lang_sierra::extensions::ConcreteType;\nuse cairo_lang_sierra::ids::{ConcreteLibfuncId, ConcreteTypeId, FunctionId};\nuse cairo_lang_sierra::program::{Program, StatementIdx};\nuse cairo_lang_sierra::program_registry::{ProgramRegistry, ProgramRegistryError};\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse core_libfunc_cost_base::InvocationCostInfoProvider;\nuse core_libfunc_cost_expr::CostExprMap;\nuse cost_expr::Var;\nuse gas_info::GasInfo;\nuse generate_equations::StatementFutureCost;\nuse itertools::Itertools;\nuse thiserror::Error;\n\npub mod core_libfunc_cost;\nmod core_libfunc_cost_base;\nmod core_libfunc_cost_expr;\nmod cost_expr;\npub mod gas_info;\nmod generate_equations;\nmod starknet_libfunc_cost_base;\n\n#[cfg(test)]\nmod test;\n\n/// Error occurring while calculating the costing of a program's variables.\n#[derive(Error, Debug, Eq, PartialEq)]\npub enum CostError {\n    #[error(\"error from the program registry\")]\n    ProgramRegistryError(#[from] Box<ProgramRegistryError>),\n    #[error(\"found an illegal statement index during cost calculations\")]\n    StatementOutOfBounds(StatementIdx),\n    #[error(\"failed solving the symbol tables\")]\n    SolvingGasEquationFailed,\n}\n\n/// Helper to implement the `InvocationCostInfoProvider` for the equation generation.\nstruct InvocationCostInfoProviderForEqGen<\n    'a,\n    TokenUsages: Fn(CostTokenType) -> usize,\n    ApChangeVarValue: Fn() -> usize,\n> {\n    /// Registry for providing the sizes of the types.\n    registry: &'a ProgramRegistry<CoreType, CoreLibfunc>,\n    /// Closure providing the token usages for the invocation.\n    token_usages: TokenUsages,\n    /// Closure providing the ap changes for the invocation.\n    ap_change_var_value: ApChangeVarValue,\n}\n\nimpl<'a, TokenUsages: Fn(CostTokenType) -> usize, ApChangeVarValue: Fn() -> usize>\n    InvocationCostInfoProvider\n    for InvocationCostInfoProviderForEqGen<'a, TokenUsages, ApChangeVarValue>\n{\n    fn type_size(&self, ty: &ConcreteTypeId) -> usize {\n        self.registry.get_type(ty).unwrap().info().size as usize\n    }\n\n    fn token_usages(&self, token_type: CostTokenType) -> usize {\n        (self.token_usages)(token_type)\n    }\n\n    fn ap_change_var_value(&self) -> usize {\n        (self.ap_change_var_value)()\n    }\n}\n\n/// Calculates gas precost information for a given program - the gas costs of non-step tokens.\npub fn calc_gas_precost_info(\n    program: &Program,\n    function_set_costs: OrderedHashMap<FunctionId, OrderedHashMap<CostTokenType, i32>>,\n) -> Result<GasInfo, CostError> {\n    let registry = ProgramRegistry::<CoreType, CoreLibfunc>::new(program)?;\n    calc_gas_info_inner(\n        program,\n        |statement_future_cost, idx, libfunc_id| -> Vec<OrderedHashMap<CostTokenType, Expr<Var>>> {\n            let libfunc = registry\n                .get_libfunc(libfunc_id)\n                .expect(\"Program registery creation would have already failed.\");\n            core_libfunc_cost_expr::core_libfunc_precost_expr(statement_future_cost, idx, libfunc)\n        },\n        function_set_costs,\n        &registry,\n    )\n}\n\n/// Calculates gas postcost information for a given program - the gas costs of step token.\npub fn calc_gas_postcost_info<ApChangeVarValue: Fn(StatementIdx) -> usize>(\n    program: &Program,\n    function_set_costs: OrderedHashMap<FunctionId, OrderedHashMap<CostTokenType, i32>>,\n    precost_gas_info: &GasInfo,\n    ap_change_var_value: ApChangeVarValue,\n) -> Result<GasInfo, CostError> {\n    let registry = ProgramRegistry::<CoreType, CoreLibfunc>::new(program)?;\n    calc_gas_info_inner(\n        program,\n        |statement_future_cost, idx, libfunc_id| {\n            let libfunc = registry\n                .get_libfunc(libfunc_id)\n                .expect(\"Program registery creation would have already failed.\");\n            core_libfunc_cost_expr::core_libfunc_postcost_expr(\n                statement_future_cost,\n                idx,\n                libfunc,\n                &InvocationCostInfoProviderForEqGen {\n                    registry: &registry,\n                    token_usages: |token_type| {\n                        precost_gas_info.variable_values[(*idx, token_type)] as usize\n                    },\n                    ap_change_var_value: || ap_change_var_value(*idx),\n                },\n            )\n        },\n        function_set_costs,\n        &registry,\n    )\n}\n\n/// Calculates gas information. Used for both precost and postcost.\nfn calc_gas_info_inner<\n    GetCost: Fn(&mut dyn StatementFutureCost, &StatementIdx, &ConcreteLibfuncId) -> Vec<CostExprMap>,\n>(\n    program: &Program,\n    get_cost: GetCost,\n    function_set_costs: OrderedHashMap<FunctionId, OrderedHashMap<CostTokenType, i32>>,\n    registry: &ProgramRegistry<CoreType, CoreLibfunc>,\n) -> Result<GasInfo, CostError> {\n    let mut equations = generate_equations::generate_equations(program, get_cost)?;\n    for (func_id, cost_terms) in function_set_costs {\n        for token_type in CostTokenType::iter() {\n            equations[*token_type].push(\n                Expr::from_var(Var::StatementFuture(\n                    registry.get_function(&func_id)?.entry_point,\n                    *token_type,\n                )) - Expr::from_const(cost_terms.get(token_type).copied().unwrap_or_default()),\n            );\n        }\n    }\n\n    let mut variable_values = OrderedHashMap::default();\n    let mut function_costs = OrderedHashMap::default();\n    for (token_type, token_equations) in equations {\n        let all_vars = token_equations.iter().flat_map(|eq| eq.var_to_coef.keys());\n        let function_vars = all_vars\n            .clone()\n            .filter(|v| matches!(v, Var::StatementFuture(_, _)))\n            .unique()\n            .cloned()\n            .collect();\n        let gas_vars = all_vars\n            .filter(|v| matches!(v, Var::LibfuncImplicitGasVariable(_, _)))\n            .unique()\n            .cloned()\n            .collect();\n        let solution = cairo_lang_eq_solver::try_solve_equations(\n            token_equations,\n            vec![function_vars, gas_vars],\n        )\n        .ok_or(CostError::SolvingGasEquationFailed)?;\n        for func in &program.funcs {\n            let id = &func.id;\n            if !function_costs.contains_key(id) {\n                function_costs.insert(id.clone(), OrderedHashMap::default());\n            }\n            let value = solution[Var::StatementFuture(func.entry_point, token_type)];\n            if value != 0 {\n                function_costs.get_mut(id).unwrap().insert(token_type, value);\n            }\n        }\n        for (var, value) in solution {\n            if let Var::LibfuncImplicitGasVariable(idx, var_token_type) = var {\n                assert_eq!(\n                    token_type, var_token_type,\n                    \"Unexpected variable of type {var_token_type:?} while handling {token_type:?}.\"\n                );\n                variable_values.insert((idx, var_token_type), value);\n            }\n        }\n    }\n    Ok(GasInfo { variable_values, function_costs })\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_sierra::extensions::starknet::StarkNetConcreteLibfunc;\n\nuse crate::core_libfunc_cost_base::{ConstCost, CostOperations};\n\nconst SYSTEM_CALL_STEPS: i32 = 100;\npub const SYSTEM_CALL_COST: i32 =\n    ConstCost { steps: SYSTEM_CALL_STEPS, holes: 0, range_checks: 0 }.cost();\n\n/// Returns some cost value for a StarkNet libfunc - a helper function to implement costing both for\n/// creating gas equations and getting actual gas cost after having a solution.\npub fn starknet_libfunc_cost_base<Ops: CostOperations>(\n    ops: &mut Ops,\n    libfunc: &StarkNetConcreteLibfunc,\n) -> Vec<Ops::CostType> {\n    match libfunc {\n        StarkNetConcreteLibfunc::CallContract(_) => syscall_cost(ops, 9, 9),\n        StarkNetConcreteLibfunc::ClassHashConst(_)\n        | StarkNetConcreteLibfunc::ContractAddressConst(_) => vec![ops.steps(0)],\n        StarkNetConcreteLibfunc::ClassHashTryFromFelt252(_)\n        | StarkNetConcreteLibfunc::ContractAddressTryFromFelt252(_)\n        | StarkNetConcreteLibfunc::StorageAddressTryFromFelt252(_) => {\n            vec![\n                ops.const_cost(ConstCost { steps: 7, holes: 0, range_checks: 3 }),\n                ops.const_cost(ConstCost { steps: 9, holes: 0, range_checks: 3 }),\n            ]\n        }\n        StarkNetConcreteLibfunc::ClassHashToFelt252(_)\n        | StarkNetConcreteLibfunc::ContractAddressToFelt252(_)\n        | StarkNetConcreteLibfunc::StorageAddressToFelt252(_) => vec![ops.steps(0)],\n        StarkNetConcreteLibfunc::StorageRead(_) => syscall_cost(ops, 7, 7),\n        StarkNetConcreteLibfunc::StorageWrite(_) => syscall_cost(ops, 8, 8),\n        StarkNetConcreteLibfunc::StorageBaseAddressConst(_) => vec![ops.steps(0)],\n        StarkNetConcreteLibfunc::StorageBaseAddressFromFelt252(_) => {\n            vec![ops.const_cost(ConstCost { steps: 10, holes: 0, range_checks: 3 })]\n        }\n        StarkNetConcreteLibfunc::StorageAddressFromBase(_) => vec![ops.steps(0)],\n        StarkNetConcreteLibfunc::StorageAddressFromBaseAndOffset(_) => vec![ops.steps(0)],\n        StarkNetConcreteLibfunc::EmitEvent(_) => syscall_cost(ops, 9, 9),\n        StarkNetConcreteLibfunc::GetExecutionInfo(_) => syscall_cost(ops, 5, 5),\n        StarkNetConcreteLibfunc::Deploy(_) => syscall_cost(ops, 10, 10),\n        StarkNetConcreteLibfunc::LibraryCall(_) => syscall_cost(ops, 9, 9),\n        StarkNetConcreteLibfunc::ReplaceClass(_) => syscall_cost(ops, 6, 6),\n        StarkNetConcreteLibfunc::SendMessageToL1(_) => syscall_cost(ops, 8, 8),\n        StarkNetConcreteLibfunc::Testing(_) => vec![ops.steps(1)],\n    }\n}\n\n/// Returns the costs for system calls.\nfn syscall_cost<Ops: CostOperations>(\n    ops: &mut Ops,\n    success: i32,\n    failure: i32,\n) -> Vec<Ops::CostType> {\n    [success, failure]\n        .map(|steps| {\n            ops.const_cost(ConstCost {\n                steps: SYSTEM_CALL_STEPS + steps,\n                holes: 0,\n                range_checks: 0,\n            })\n        })\n        .to_vec()\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::fs;\nuse std::path::PathBuf;\n\nuse cairo_lang_sierra::program::Program;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\n\nuse crate::{calc_gas_postcost_info, calc_gas_precost_info};\n\ncairo_lang_test_utils::test_file_test!(\n    test_solve_gas,\n    \"src/test_data\",\n    {\n        fib_jumps :\"fib_jumps\",\n    },\n    test_solve_gas\n);\n\n/// Returns a parsed example program from the example directory.\nfn get_example_program(name: &str) -> Program {\n    // Pop the \"/sierra_gas\" suffix.\n    let mut path = PathBuf::from(env!(\"CARGO_MANIFEST_DIR\")).parent().unwrap().to_owned();\n    path.extend([\"cairo-lang-sierra\", \"examples\", &format!(\"{name}.sierra\")].into_iter());\n    cairo_lang_sierra::ProgramParser::new().parse(&fs::read_to_string(path).unwrap()).unwrap()\n}\n\nfn test_solve_gas(inputs: &OrderedHashMap<String, String>) -> OrderedHashMap<String, String> {\n    let path = &inputs[\"test_file_name\"];\n    let program = get_example_program(path);\n\n    let gas_info0 = calc_gas_precost_info(&program, Default::default()).unwrap();\n    let gas_info1 =\n        calc_gas_postcost_info(&program, Default::default(), &gas_info0, |_| 0).unwrap();\n    let gas_info = gas_info0.combine(gas_info1);\n\n    OrderedHashMap::from([(\"gas_solution\".into(), format!(\"{gas_info}\"))])\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "#[cfg(test)]\n#[path = \"ap_change_test.rs\"]\nmod test;\n\nuse cairo_lang_diagnostics::Maybe;\nuse cairo_lang_semantic::items::functions::ConcreteFunctionWithBodyId;\nuse cairo_lang_sierra::extensions::lib_func::SierraApChange;\nuse cairo_lang_sierra::program::GenStatement;\n\nuse crate::db::SierraGenGroup;\nuse crate::pre_sierra;\nuse crate::utils::get_libfunc_signature;\n\n/// Query implementation of [SierraGenGroup::get_ap_change].\npub fn get_ap_change(\n    db: &dyn SierraGenGroup,\n    function_id: ConcreteFunctionWithBodyId,\n) -> Maybe<SierraApChange> {\n    // The implementation of get_ap_change() may call this function recursively. To guarantee no\n    // salsa query cycles are created, we first verify that there are no cycles.\n    if db.contains_cycle(function_id)? {\n        return Ok(SierraApChange::Unknown);\n    }\n\n    let function = &*db.function_with_body_sierra(function_id)?;\n    for statement in &function.body {\n        if let pre_sierra::Statement::Sierra(GenStatement::Invocation(invocation)) = statement {\n            let signature = get_libfunc_signature(db, invocation.libfunc_id.clone());\n            // Go over the branches.\n            for branch_signature in signature.branch_signatures {\n                if matches!(branch_signature.ap_change, SierraApChange::Unknown) {\n                    return Ok(SierraApChange::Unknown);\n                }\n            }\n        }\n    }\n    Ok(SierraApChange::Known { new_vars_only: false })\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_defs::db::DefsGroup;\nuse cairo_lang_lowering::db::LoweringGroup;\nuse cairo_lang_semantic::test_utils::setup_test_module;\nuse cairo_lang_semantic::ConcreteFunctionWithBodyId;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse itertools::Itertools;\n\nuse crate::db::SierraGenGroup;\nuse crate::test_utils::SierraGenDatabaseForTesting;\n\ncairo_lang_test_utils::test_file_test!(\n    ap_change,\n    \"src/ap_change_test_data\",\n    {tests: \"tests\"},\n    contains_cycles_test\n);\n\nfn contains_cycles_test(inputs: &OrderedHashMap<String, String>) -> OrderedHashMap<String, String> {\n    let db = &mut SierraGenDatabaseForTesting::default();\n    // Parse code and create semantic model.\n    let test_module = setup_test_module(db, inputs[\"module_code\"].as_str()).unwrap();\n\n    db.module_lowering_diagnostics(test_module.module_id)\n        .unwrap()\n        .expect_with_db(db, \"Unexpected diagnostics.\");\n\n    let result = db\n        .module_free_functions(test_module.module_id)\n        .unwrap()\n        .iter()\n        .map(|(free_function_id, _)| {\n            let function_id =\n                ConcreteFunctionWithBodyId::from_no_generics_free(db, *free_function_id).unwrap();\n            format!(\n                \"{}: ap_change={:?}, has_cycles={:?}\",\n                free_function_id.name(db),\n                db.get_ap_change(function_id),\n                db.contains_cycle(function_id),\n            )\n        })\n        .join(\"\\n\");\n\n    OrderedHashMap::from([(\"result\".into(), result)])\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "#[cfg(test)]\n#[path = \"block_generator_test.rs\"]\nmod test;\n\nuse cairo_lang_diagnostics::Maybe;\nuse cairo_lang_semantic::items::functions::GenericFunctionId;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse itertools::{chain, enumerate, zip_eq, Itertools};\nuse lowering::borrow_check::analysis::StatementLocation;\nuse lowering::MatchArm;\nuse sierra::program;\nuse {cairo_lang_lowering as lowering, cairo_lang_sierra as sierra};\n\nuse crate::expr_generator_context::ExprGeneratorContext;\nuse crate::lifetime::{DropLocation, SierraGenVar, UseLocation};\nuse crate::pre_sierra;\nuse crate::utils::{\n    branch_align_libfunc_id, const_libfunc_id_by_type, drop_libfunc_id, dup_libfunc_id,\n    enum_init_libfunc_id, get_concrete_libfunc_id, jump_libfunc_id, jump_statement,\n    match_enum_libfunc_id, rename_libfunc_id, return_statement, simple_statement,\n    snapshot_take_libfunc_id, struct_construct_libfunc_id, struct_deconstruct_libfunc_id,\n};\n\n/// Generates Sierra code for the body of the given [lowering::FlatBlock].\n/// Returns a list of Sierra statements.\npub fn generate_block_body_code(\n    context: &mut ExprGeneratorContext<'_>,\n    block_id: lowering::BlockId,\n    block: &lowering::FlatBlock,\n) -> Maybe<Vec<pre_sierra::Statement>> {\n    let mut statements: Vec<pre_sierra::Statement> = vec![];\n    let drops = context.get_drops();\n\n    add_drop_statements(\n        context,\n        drops,\n        &DropLocation::BeginningOfBlock(block_id),\n        &mut statements,\n    )?;\n\n    // Process the statements.\n    for (i, statement) in block.statements.iter().enumerate() {\n        let statement_location = (block_id, i);\n        statements.extend(generate_statement_code(context, statement, &statement_location)?);\n        let drop_location = &DropLocation::PostStatement(statement_location);\n        add_drop_statements(context, drops, drop_location, &mut statements)?;\n    }\n\n    add_drop_statements(\n        context,\n        drops,\n        &DropLocation::PostStatement((block_id, block.statements.len())),\n        &mut statements,\n    )?;\n\n    Ok(statements)\n}\n\n/// Adds calls to the `drop` libfunc for the given [DropLocation], according to the `drops`\n/// argument (computed by [find_variable_lifetime](crate::lifetime::find_variable_lifetime)).\nfn add_drop_statements(\n    context: &mut ExprGeneratorContext<'_>,\n    drops: &OrderedHashMap<DropLocation, Vec<SierraGenVar>>,\n    drop_location: &DropLocation,\n    statements: &mut Vec<pre_sierra::Statement>,\n) -> Maybe<()> {\n    let Some(vars) = drops.get(drop_location)  else { return Ok(()) };\n\n    for sierra_gen_var in vars {\n        let sierra_var = context.get_sierra_variable(*sierra_gen_var);\n        let ty = context.get_variable_sierra_type(*sierra_gen_var)?;\n        statements.push(simple_statement(\n            drop_libfunc_id(context.get_db(), ty),\n            &[sierra_var],\n            &[],\n        ));\n    }\n\n    Ok(())\n}\n\n/// Generates Sierra for a given [lowering::FlatBlock].\n///\n/// Returns a list of Sierra statements.\n/// Assumes `block_id` exists in `self.lowered.blocks`.\npub fn generate_block_code(\n    context: &mut ExprGeneratorContext<'_>,\n    block_id: lowering::BlockId,\n) -> Maybe<Vec<pre_sierra::Statement>> {\n    let block = context.get_lowered_block(block_id);\n    let statement_location: StatementLocation = (block_id, block.statements.len());\n\n    let mut statements = generate_block_body_code(context, block_id, block)?;\n    match &block.end {\n        lowering::FlatBlockEnd::Return(returned_variables) => {\n            statements.extend(generate_return_code(\n                context,\n                returned_variables,\n                &statement_location,\n            )?);\n        }\n        lowering::FlatBlockEnd::Panic(_) => {\n            unreachable!(\"Panics should have been stripped in a previous phase.\")\n        }\n        lowering::FlatBlockEnd::Goto(target_block_id, remapping) => {\n            statements.push(generate_push_values_statement_for_remapping(\n                context,\n                statement_location,\n                remapping,\n            )?);\n\n            if *target_block_id == block_id.next_block_id() {\n                statements.push(pre_sierra::Statement::Label(pre_sierra::Label {\n                    id: *context.block_label(*target_block_id),\n                }));\n\n                let code = generate_block_code(context, *target_block_id)?;\n                statements.extend(code);\n            } else {\n                statements.push(jump_statement(\n                    jump_libfunc_id(context.get_db()),\n                    *context.block_label(*target_block_id),\n                ));\n            }\n        }\n        lowering::FlatBlockEnd::NotSet => unreachable!(),\n        // Process the block end if it's a match.\n        lowering::FlatBlockEnd::Match { info } => {\n            let statement_location = (block_id, block.statements.len());\n            statements.extend(match info {\n                lowering::MatchInfo::Extern(s) => {\n                    generate_match_extern_code(context, s, &statement_location)?\n                }\n                lowering::MatchInfo::Enum(s) => {\n                    generate_match_enum_code(context, s, &statement_location)?\n                }\n            });\n        }\n    }\n    Ok(statements)\n}\n\n/// Generates a push_values statement that corresponds to `remapping`.\nfn generate_push_values_statement_for_remapping(\n    context: &mut ExprGeneratorContext<'_>,\n    _statement_location: (lowering::BlockId, usize),\n    remapping: &lowering::VarRemapping,\n) -> Maybe<pre_sierra::Statement> {\n    let mut push_values = Vec::<pre_sierra::PushValue>::new();\n    for (output, inner_output) in remapping.iter() {\n        let ty = context.get_variable_sierra_type(*inner_output)?;\n        let var_on_stack_ty = context.get_variable_sierra_type(*output)?;\n        assert_eq!(\n            ty, var_on_stack_ty,\n            \"Internal compiler error: Inconsistent types in generate_block_code().\"\n        );\n        push_values.push(pre_sierra::PushValue {\n            var: context.get_sierra_variable(*inner_output),\n            var_on_stack: context.get_sierra_variable(*output),\n            ty,\n            dup: false,\n        })\n    }\n    Ok(pre_sierra::Statement::PushValues(push_values))\n}\n\n/// Generates Sierra code for a `return` statement.\n/// Pushes the given returned values on the top of the stack, and returns from the function.\n///\n/// Returns a list of Sierra statements.\npub fn generate_return_code(\n    context: &mut ExprGeneratorContext<'_>,\n    returned_variables: &[id_arena::Id<lowering::Variable>],\n    statement_location: &StatementLocation,\n) -> Maybe<Vec<pre_sierra::Statement>> {\n    let mut statements: Vec<pre_sierra::Statement> = vec![];\n    // Copy the result to the top of the stack before returning.\n    let mut return_variables_on_stack = vec![];\n    let mut push_values = vec![];\n\n    for (idx, returned_variable) in returned_variables.iter().enumerate() {\n        let use_location = UseLocation { statement_location: *statement_location, idx };\n        let should_dup = should_dup(context, &use_location);\n\n        let return_variable_on_stack = context.allocate_sierra_variable();\n        return_variables_on_stack.push(return_variable_on_stack.clone());\n        push_values.push(pre_sierra::PushValue {\n            var: context.get_sierra_variable(*returned_variable),\n            var_on_stack: return_variable_on_stack,\n            ty: context.get_variable_sierra_type(*returned_variable)?,\n            dup: should_dup,\n        });\n    }\n\n    statements.push(pre_sierra::Statement::PushValues(push_values));\n    statements.push(return_statement(return_variables_on_stack));\n\n    Ok(statements)\n}\n\n/// Generates Sierra code for [lowering::Statement].\npub fn generate_statement_code(\n    context: &mut ExprGeneratorContext<'_>,\n    statement: &lowering::Statement,\n    statement_location: &StatementLocation,\n) -> Maybe<Vec<pre_sierra::Statement>> {\n    match statement {\n        lowering::Statement::Literal(statement_literal) => {\n            generate_statement_literal_code(context, statement_literal)\n        }\n        lowering::Statement::Call(statement_call) => {\n            generate_statement_call_code(context, statement_call, statement_location)\n        }\n        lowering::Statement::EnumConstruct(statement_enum_construct) => {\n            generate_statement_enum_construct(context, statement_enum_construct, statement_location)\n        }\n        lowering::Statement::StructConstruct(statement) => {\n            generate_statement_struct_construct_code(context, statement, statement_location)\n        }\n        lowering::Statement::StructDestructure(statement) => {\n            generate_statement_struct_destructure_code(context, statement, statement_location)\n        }\n        lowering::Statement::Snapshot(statement) => {\n            generate_statement_snapshot(context, statement, statement_location)\n        }\n        lowering::Statement::Desnap(statement) => {\n            generate_statement_desnap(context, statement, statement_location)\n        }\n    }\n}\n\n/// Generates Sierra code for [lowering::StatementLiteral].\nfn generate_statement_literal_code(\n    context: &mut ExprGeneratorContext<'_>,\n    statement: &lowering::StatementLiteral,\n) -> Maybe<Vec<pre_sierra::Statement>> {\n    let output_var = context.get_sierra_variable(statement.output);\n    Ok(vec![simple_statement(\n        const_libfunc_id_by_type(\n            context.get_db(),\n            context.get_var_type(statement.output),\n            statement.value.clone(),\n        ),\n        &[],\n        &[output_var],\n    )])\n}\n\n/// Generates Sierra code for [lowering::StatementCall].\nfn generate_statement_call_code(\n    context: &mut ExprGeneratorContext<'_>,\n    statement: &lowering::StatementCall,\n    statement_location: &StatementLocation,\n) -> Maybe<Vec<pre_sierra::Statement>> {\n    // Prepare the Sierra input and output variables.\n    let inputs = context.get_sierra_variables(&statement.inputs);\n    let outputs = context.get_sierra_variables(&statement.outputs);\n\n    // Check if this is a user defined function or a libfunc.\n    let (function_long_id, libfunc_id) =\n        get_concrete_libfunc_id(context.get_db(), statement.function);\n\n    match function_long_id.generic_function {\n        GenericFunctionId::Free(_) | GenericFunctionId::Impl(_) => {\n            // Create [pre_sierra::PushValue] instances for the arguments.\n            let mut args_on_stack: Vec<sierra::ids::VarId> = vec![];\n            let mut push_values_vec: Vec<pre_sierra::PushValue> = vec![];\n\n            for (idx, (var_id, var)) in zip_eq(&statement.inputs, inputs).enumerate() {\n                let use_location = UseLocation { statement_location: *statement_location, idx };\n                let should_dup = should_dup(context, &use_location);\n                // Allocate a temporary Sierra variable that represents the argument placed on the\n                // stack.\n                let arg_on_stack = context.allocate_sierra_variable();\n                push_values_vec.push(pre_sierra::PushValue {\n                    var,\n                    var_on_stack: arg_on_stack.clone(),\n                    ty: context.get_variable_sierra_type(*var_id)?,\n                    dup: should_dup,\n                });\n                args_on_stack.push(arg_on_stack);\n            }\n\n            Ok(vec![\n                // Push the arguments.\n                pre_sierra::Statement::PushValues(push_values_vec),\n                // Call the function.\n                simple_statement(libfunc_id, &args_on_stack, &outputs),\n            ])\n        }\n        GenericFunctionId::Extern(_) => {\n            // Dup variables as needed.\n            let mut statements: Vec<pre_sierra::Statement> = vec![];\n            let inputs_after_dup = maybe_add_dup_statements(\n                context,\n                statement_location,\n                &statement.inputs,\n                &mut statements,\n            )?;\n\n            statements.push(simple_statement(libfunc_id, &inputs_after_dup, &outputs));\n            Ok(statements)\n        }\n    }\n}\n\n/// Returns if the variable at the given location should be duplicated.\nfn should_dup(context: &mut ExprGeneratorContext<'_>, use_location: &UseLocation) -> bool {\n    !context.is_last_use(use_location)\n}\n\n/// Adds calls to the `dup` libfunc for the given [StatementLocation] and the given statement's\n/// inputs.\nfn maybe_add_dup_statements(\n    context: &mut ExprGeneratorContext<'_>,\n    statement_location: &StatementLocation,\n    lowering_vars: &[id_arena::Id<lowering::Variable>],\n    statements: &mut Vec<pre_sierra::Statement>,\n) -> Maybe<Vec<sierra::ids::VarId>> {\n    lowering_vars\n        .iter()\n        .enumerate()\n        .map(|(idx, lowering_var)| {\n            maybe_add_dup_statement(context, statement_location, idx, lowering_var, statements)\n        })\n        .collect()\n}\n\n/// If necessary, adds a call to the `dup` libfunc for the given [StatementLocation] and the given\n/// statement's input, and returns the duplicated copy. Otherwise, returns the original variable.\nfn maybe_add_dup_statement(\n    context: &mut ExprGeneratorContext<'_>,\n    statement_location: &StatementLocation,\n    idx: usize,\n    lowering_var: &id_arena::Id<lowering::Variable>,\n    statements: &mut Vec<pre_sierra::Statement>,\n) -> Maybe<sierra::ids::VarId> {\n    let sierra_var = context.get_sierra_variable(*lowering_var);\n\n    // Check whether the variable should be dupped.\n    if context.is_last_use(&UseLocation { statement_location: *statement_location, idx }) {\n        // Dup is not required.\n        Ok(sierra_var)\n    } else {\n        let ty = context.get_variable_sierra_type(*lowering_var)?;\n        let dup_var = context.allocate_sierra_variable();\n        statements.push(simple_statement(\n            dup_libfunc_id(context.get_db(), ty),\n            &[sierra_var.clone()],\n            &[sierra_var, dup_var.clone()],\n        ));\n        Ok(dup_var)\n    }\n}\n\n/// Generates Sierra code for [lowering::MatchExternInfo].\nfn generate_match_extern_code(\n    context: &mut ExprGeneratorContext<'_>,\n    match_info: &lowering::MatchExternInfo,\n    statement_location: &StatementLocation,\n) -> Maybe<Vec<pre_sierra::Statement>> {\n    let mut statements: Vec<pre_sierra::Statement> = vec![];\n\n    // Generate labels for all the arms, except for the first (which will be Fallthrough).\n    let arm_labels: Vec<(pre_sierra::Statement, pre_sierra::LabelId)> =\n        (1..match_info.arms.len()).map(|_i| context.new_label()).collect();\n    // Generate a label for the end of the match.\n    let (end_label, _) = context.new_label();\n\n    // Create the arm branches.\n    let arm_targets: Vec<program::GenBranchTarget<pre_sierra::LabelId>> = chain!(\n        [program::GenBranchTarget::Fallthrough],\n        arm_labels\n            .iter()\n            .map(|(_statement, label_id)| program::GenBranchTarget::Statement(*label_id)),\n    )\n    .collect();\n\n    let branches: Vec<_> = zip_eq(&match_info.arms, arm_targets)\n        .map(|(arm, target)| program::GenBranchInfo {\n            target,\n            results: context.get_sierra_variables(&arm.var_ids),\n        })\n        .collect();\n\n    // Prepare the Sierra input variables.\n    let args =\n        maybe_add_dup_statements(context, statement_location, &match_info.inputs, &mut statements)?;\n    // Get the [ConcreteLibfuncId].\n    let (_function_long_id, libfunc_id) =\n        get_concrete_libfunc_id(context.get_db(), match_info.function);\n    // Call the match libfunc.\n    statements.push(pre_sierra::Statement::Sierra(program::GenStatement::Invocation(\n        program::GenInvocation { libfunc_id, args, branches },\n    )));\n\n    // Generate the blocks.\n    for (i, MatchArm { variant_id: _, block_id, var_ids: _ }) in enumerate(&match_info.arms) {\n        // Add a label for each of the arm blocks, except for the first.\n        if i > 0 {\n            statements.push(arm_labels[i - 1].0.clone());\n        }\n        // Add branch_align to equalize gas costs across the merging paths.\n        statements.push(simple_statement(branch_align_libfunc_id(context.get_db()), &[], &[]));\n\n        let code = generate_block_code(context, *block_id)?;\n        statements.extend(code);\n    }\n\n    // Post match.\n    statements.push(end_label);\n\n    Ok(statements)\n}\n\n/// Generates Sierra code for [lowering::StatementEnumConstruct].\nfn generate_statement_enum_construct(\n    context: &mut ExprGeneratorContext<'_>,\n    statement: &lowering::StatementEnumConstruct,\n    statement_location: &StatementLocation,\n) -> Maybe<Vec<pre_sierra::Statement>> {\n    let mut statements: Vec<pre_sierra::Statement> = vec![];\n\n    let input =\n        maybe_add_dup_statement(context, statement_location, 0, &statement.input, &mut statements)?;\n\n    statements.push(simple_statement(\n        enum_init_libfunc_id(\n            context.get_db(),\n            context.get_variable_sierra_type(statement.output)?,\n            statement.variant.idx,\n        ),\n        &[input],\n        &[context.get_sierra_variable(statement.output)],\n    ));\n    Ok(statements)\n}\n\n/// Generates Sierra code for [lowering::StatementStructConstruct].\nfn generate_statement_struct_construct_code(\n    context: &mut ExprGeneratorContext<'_>,\n    statement: &lowering::StatementStructConstruct,\n    statement_location: &StatementLocation,\n) -> Maybe<Vec<pre_sierra::Statement>> {\n    let mut statements: Vec<pre_sierra::Statement> = vec![];\n\n    let inputs =\n        maybe_add_dup_statements(context, statement_location, &statement.inputs, &mut statements)?;\n\n    statements.push(simple_statement(\n        struct_construct_libfunc_id(\n            context.get_db(),\n            context.get_variable_sierra_type(statement.output)?,\n        ),\n        &inputs,\n        &[context.get_sierra_variable(statement.output)],\n    ));\n    Ok(statements)\n}\n\n/// Generates Sierra code for [lowering::StatementStructDestructure].\nfn generate_statement_struct_destructure_code(\n    context: &mut ExprGeneratorContext<'_>,\n    statement: &lowering::StatementStructDestructure,\n    statement_location: &StatementLocation,\n) -> Maybe<Vec<pre_sierra::Statement>> {\n    let mut statements: Vec<pre_sierra::Statement> = vec![];\n\n    let input =\n        maybe_add_dup_statement(context, statement_location, 0, &statement.input, &mut statements)?;\n\n    statements.push(simple_statement(\n        struct_deconstruct_libfunc_id(\n            context.get_db(),\n            context.get_variable_sierra_type(statement.input)?,\n        )?,\n        &[input],\n        &context.get_sierra_variables(&statement.outputs),\n    ));\n    Ok(statements)\n}\n\n/// Generates Sierra code for [lowering::MatchEnumInfo].\nfn generate_match_enum_code(\n    context: &mut ExprGeneratorContext<'_>,\n    match_info: &lowering::MatchEnumInfo,\n    statement_location: &StatementLocation,\n) -> Maybe<Vec<pre_sierra::Statement>> {\n    let mut statements: Vec<pre_sierra::Statement> = vec![];\n\n    // Generate labels for all the arms, except for the first (which will be Fallthrough).\n    let arm_labels: Vec<(pre_sierra::Statement, pre_sierra::LabelId)> =\n        (1..match_info.arms.len()).map(|_i| context.new_label()).collect_vec();\n    // Generate a label for the end of the match.\n    let (end_label, _) = context.new_label();\n\n    // Create the arm branches.\n    let arm_targets: Vec<program::GenBranchTarget<pre_sierra::LabelId>> = chain!(\n        [program::GenBranchTarget::Fallthrough],\n        arm_labels\n            .iter()\n            .map(|(_statement, label_id)| program::GenBranchTarget::Statement(*label_id)),\n    )\n    .collect();\n\n    let branches: Vec<_> = zip_eq(&match_info.arms, arm_targets)\n        .map(|(arm, target)| program::GenBranchInfo {\n            target,\n            results: context.get_sierra_variables(&arm.var_ids),\n        })\n        .collect();\n\n    // Prepare the Sierra input variables.\n    let matched_enum = maybe_add_dup_statement(\n        context,\n        statement_location,\n        0,\n        &match_info.input,\n        &mut statements,\n    )?;\n    // Get the [ConcreteLibfuncId].\n    let concrete_enum_type = context.get_variable_sierra_type(match_info.input)?;\n    let libfunc_id = match_enum_libfunc_id(context.get_db(), concrete_enum_type)?;\n    // Call the match libfunc.\n    statements.push(pre_sierra::Statement::Sierra(program::GenStatement::Invocation(\n        program::GenInvocation { libfunc_id, args: vec![matched_enum], branches },\n    )));\n\n    // Generate the blocks.\n    // TODO(Gil): Consider unifying with the similar logic in generate_statement_match_extern_code.\n    for (i, MatchArm { variant_id: _, block_id, var_ids: _ }) in enumerate(&match_info.arms) {\n        // Add a label for each of the arm blocks, except for the first.\n        if i > 0 {\n            statements.push(arm_labels[i - 1].0.clone());\n        }\n        // Add branch_align to equalize gas costs across the merging paths.\n        statements.push(simple_statement(branch_align_libfunc_id(context.get_db()), &[], &[]));\n\n        let code = generate_block_code(context, *block_id)?;\n        statements.extend(code);\n    }\n\n    // Post match.\n    statements.push(end_label);\n\n    Ok(statements)\n}\n\n/// Generates Sierra code for [lowering::StatementSnapshot].\nfn generate_statement_snapshot(\n    context: &mut ExprGeneratorContext<'_>,\n    statement: &lowering::StatementSnapshot,\n    _statement_location: &StatementLocation,\n) -> Maybe<Vec<pre_sierra::Statement>> {\n    let mut statements: Vec<pre_sierra::Statement> = vec![];\n\n    let input = context.get_sierra_variable(statement.input);\n\n    statements.push(simple_statement(\n        snapshot_take_libfunc_id(\n            context.get_db(),\n            context.get_variable_sierra_type(statement.input)?,\n        ),\n        &[input],\n        &[\n            context.get_sierra_variable(statement.output_original),\n            context.get_sierra_variable(statement.output_snapshot),\n        ],\n    ));\n    Ok(statements)\n}\n\n/// Generates Sierra code for [lowering::StatementDesnap].\nfn generate_statement_desnap(\n    context: &mut ExprGeneratorContext<'_>,\n    statement: &lowering::StatementDesnap,\n    _statement_location: &StatementLocation,\n) -> Maybe<Vec<pre_sierra::Statement>> {\n    let mut statements: Vec<pre_sierra::Statement> = vec![];\n\n    let input = context.get_sierra_variable(statement.input);\n\n    statements.push(simple_statement(\n        rename_libfunc_id(context.get_db(), context.get_variable_sierra_type(statement.input)?),\n        &[input],\n        &[context.get_sierra_variable(statement.output)],\n    ));\n    Ok(statements)\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_debug::DebugWithDb;\nuse cairo_lang_lowering as lowering;\nuse cairo_lang_lowering::db::LoweringGroup;\nuse cairo_lang_lowering::BlockId;\nuse cairo_lang_semantic::test_utils::setup_test_function;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse cairo_lang_utils::ordered_hash_set::OrderedHashSet;\nuse lowering::fmt::LoweredFormatter;\n\nuse super::generate_block_code;\nuse crate::expr_generator_context::ExprGeneratorContext;\nuse crate::lifetime::find_variable_lifetime;\nuse crate::replace_ids::replace_sierra_ids;\nuse crate::test_utils::SierraGenDatabaseForTesting;\n\ncairo_lang_test_utils::test_file_test!(\n    block_generator,\n    \"src/block_generator_test_data\",\n    {\n        function_call: \"function_call\",\n        inline: \"inline\",\n        literals: \"literals\",\n        match_: \"match\",\n        serialization: \"serialization\",\n        early_return: \"early_return\",\n    },\n    block_generator_test\n);\n\nfn block_generator_test(inputs: &OrderedHashMap<String, String>) -> OrderedHashMap<String, String> {\n    let db = &mut SierraGenDatabaseForTesting::default();\n    // Parse code and create semantic model.\n    let (test_function, semantic_diagnostics) = setup_test_function(\n        db,\n        inputs[\"function\"].as_str(),\n        inputs[\"function_name\"].as_str(),\n        inputs[\"module_code\"].as_str(),\n    )\n    .split();\n\n    // Lower code.\n    let lowering_diagnostics =\n        db.function_with_body_lowering_diagnostics(test_function.function_id).unwrap();\n    let lowered =\n        db.concrete_function_with_body_lowered(test_function.concrete_function_id).unwrap();\n\n    if lowered.blocks.is_empty() {\n        return OrderedHashMap::from([\n            (\"semantic_diagnostics\".into(), semantic_diagnostics),\n            (\"lowering_diagnostics\".into(), lowering_diagnostics.format(db)),\n            (\"sierra_gen_diagnostics\".into(), \"\".into()),\n            (\"sierra_code\".into(), \"\".into()),\n        ]);\n    };\n\n    // Generate (pre-)Sierra statements.\n    let lifetime = find_variable_lifetime(&lowered, &OrderedHashSet::default())\n        .expect(\"Failed to retrieve lifetime information.\");\n    let mut expr_generator_context =\n        ExprGeneratorContext::new(db, &lowered, test_function.concrete_function_id, &lifetime);\n\n    let mut expected_sierra_code = String::default();\n\n    let statements = generate_block_code(&mut expr_generator_context, BlockId::root()).unwrap();\n    for statement in &statements {\n        expected_sierra_code.push_str(&replace_sierra_ids(db, statement).to_string());\n        expected_sierra_code.push('\\n');\n    }\n\n    let lowered_formatter = LoweredFormatter { db, variables: &lowered.variables };\n    OrderedHashMap::from([\n        (\"semantic_diagnostics\".into(), semantic_diagnostics),\n        (\"lowering_diagnostics\".into(), lowering_diagnostics.format(db)),\n        (\"lowering_flat\".into(), format!(\"{:?}\", lowered.debug(&lowered_formatter))),\n        (\"sierra_code\".into(), expected_sierra_code),\n    ])\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "#[cfg(test)]\n#[path = \"canonical_id_replacer_test.rs\"]\nmod test;\n\nuse std::collections::HashMap;\n\nuse cairo_lang_sierra::ids::{ConcreteLibfuncId, ConcreteTypeId, FunctionId};\n\nuse crate::replace_ids::SierraIdReplacer;\n\n#[derive(Default)]\npub struct CanonicalReplacer {\n    type_ids: HashMap<ConcreteTypeId, u64>,\n    function_ids: HashMap<FunctionId, u64>,\n    libfunc_ids: HashMap<ConcreteLibfuncId, u64>,\n}\n\n/// A replacer that replace the Ids in the program with canonical onces.\n/// The canonical ids are defined by the order of the declaration in the program.\n/// The first type_id is 0, the second type id is 1, etc.\nimpl CanonicalReplacer {\n    /// Builds a replacer from a program.\n    pub fn from_program(program: &cairo_lang_sierra::program::Program) -> Self {\n        let mut type_ids = HashMap::default();\n\n        for type_declaration in &program.type_declarations {\n            type_ids.insert(type_declaration.id.clone(), type_ids.len() as u64);\n        }\n\n        let mut function_ids = HashMap::default();\n        for function in &program.funcs {\n            function_ids.insert(function.id.clone(), function_ids.len() as u64);\n        }\n\n        let mut libfunc_ids = HashMap::default();\n        for libfunc_declaration in &program.libfunc_declarations {\n            libfunc_ids.insert(libfunc_declaration.id.clone(), libfunc_ids.len() as u64);\n        }\n\n        Self { type_ids, function_ids, libfunc_ids }\n    }\n}\n\nimpl SierraIdReplacer for CanonicalReplacer {\n    fn replace_libfunc_id(\n        &self,\n        id: &cairo_lang_sierra::ids::ConcreteLibfuncId,\n    ) -> cairo_lang_sierra::ids::ConcreteLibfuncId {\n        cairo_lang_sierra::ids::ConcreteLibfuncId {\n            id: *self.libfunc_ids.get(id).expect(\"Unexpected libfunc id.\"),\n            debug_name: id.debug_name.clone(),\n        }\n    }\n\n    fn replace_type_id(\n        &self,\n        id: &cairo_lang_sierra::ids::ConcreteTypeId,\n    ) -> cairo_lang_sierra::ids::ConcreteTypeId {\n        cairo_lang_sierra::ids::ConcreteTypeId {\n            id: *self.type_ids.get(id).expect(\"Unexpected type id.\"),\n            debug_name: id.debug_name.clone(),\n        }\n    }\n\n    fn replace_function_id(\n        &self,\n        id: &cairo_lang_sierra::ids::FunctionId,\n    ) -> cairo_lang_sierra::ids::FunctionId {\n        cairo_lang_sierra::ids::FunctionId {\n            id: *self.function_ids.get(id).expect(\"Unexpected function id.\"),\n            debug_name: id.debug_name.clone(),\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_sierra::ProgramParser;\nuse indoc::indoc;\nuse pretty_assertions::assert_eq;\n\nuse super::CanonicalReplacer;\nuse crate::replace_ids::SierraIdReplacer;\n\n#[test]\nfn test_replacer() {\n    let input = ProgramParser::new()\n        .parse(indoc! {\"\n            type felt252 = felt252;\n            type NonZeroFelt252 = NonZero<felt252>;\n            type BoxFelt252 = Box<felt252>;\n\n            libfunc finalize_locals = finalize_locals;\n            libfunc felt252_add = felt252_add;\n            libfunc felt252_mul_2 = felt252_mul_const<2>;\n            libfunc felt252_sub = felt252_sub;\n            libfunc felt252_dup = dup<felt252>;\n            libfunc felt252_is_zero = felt252_is_zero;\n            libfunc store_temp_felt252 = store_temp<felt252>;\n            libfunc call_foo = function_call<user@foo>;\n\n            felt252_dup([2]) -> ([2], [5]);\n            felt252_add([1], [2]) -> ([3]);\n            store_temp_felt252([3]) -> ([4]);\n            store_temp_felt252([5]) -> ([5]);\n            store_temp_felt252([4]) -> ([4]);\n            call_foo([5], [4]) -> ([7], [8]);\n            felt252_dup([8]) -> ([4], [8]);\n            store_temp_felt252([4]) -> ([4]);\n            return([7], [8], [4]);\n            finalize_locals() -> ();\n\n            test_program@0([1]: felt252, [2]: felt252) -> (felt252, felt252, felt252);\n            foo@10([1]: felt252, [2]: felt252) -> (felt252, felt252);\n            box_and_back@26([1]: felt252) -> (felt252);\n            box_and_back_wrapper@31([1]: felt252) -> (felt252);\n        \"})\n        .unwrap();\n\n    let expected_output = ProgramParser::new()\n        .parse(indoc! {\"\n            type [0] = felt252;\n            type [1] = NonZero<[0]>;\n            type [2] = Box<[0]>;\n\n            libfunc [0] = finalize_locals;\n            libfunc [1] = felt252_add;\n            libfunc [2] = felt252_mul_const<2>;\n            libfunc [3] = felt252_sub;\n            libfunc [4] = dup<[0]>;\n            libfunc [5] = felt252_is_zero;\n            libfunc [6] = store_temp<[0]>;\n            libfunc [7] = function_call<user@[1]>;\n\n            [4]([2]) -> ([2], [5]);\n            [1]([1], [2]) -> ([3]);\n            [6]([3]) -> ([4]);\n            [6]([5]) -> ([5]);\n            [6]([4]) -> ([4]);\n            [7]([5], [4]) -> ([7], [8]);\n            [4]([8]) -> ([4], [8]);\n            [6]([4]) -> ([4]);\n            return([7], [8], [4]);\n            [0]() -> ();\n\n            [0]@0([1]: [0], [2]: [0]) -> ([0], [0], [0]);\n            [1]@10([1]: [0], [2]: [0]) -> ([0], [0]);\n            [2]@26([1]: [0]) -> ([0]);\n            [3]@31([1]: [0]) -> ([0]);\n        \"})\n        .unwrap();\n\n    let replacer = CanonicalReplacer::from_program(&input);\n\n    assert_eq!(replacer.apply(&input), expected_output);\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse cairo_lang_diagnostics::Maybe;\nuse cairo_lang_filesystem::ids::CrateId;\nuse cairo_lang_lowering::db::LoweringGroup;\nuse cairo_lang_lowering::panic::PanicSignatureInfo;\nuse cairo_lang_semantic as semantic;\nuse cairo_lang_semantic::ConcreteFunctionWithBodyId;\nuse cairo_lang_sierra::extensions::lib_func::SierraApChange;\nuse cairo_lang_sierra::extensions::{ConcreteType, GenericTypeEx};\nuse cairo_lang_sierra::ids::ConcreteTypeId;\nuse cairo_lang_utils::Upcast;\nuse semantic::Mutability;\n\nuse crate::program_generator::{self};\nuse crate::specialization_context::SierraSignatureSpecializationContext;\nuse crate::{ap_change, function_generator, pre_sierra};\n\n#[salsa::query_group(SierraGenDatabase)]\npub trait SierraGenGroup: LoweringGroup + Upcast<dyn LoweringGroup> {\n    #[salsa::interned]\n    fn intern_label_id(&self, id: pre_sierra::LabelLongId) -> pre_sierra::LabelId;\n\n    #[salsa::interned]\n    fn intern_concrete_lib_func(\n        &self,\n        id: cairo_lang_sierra::program::ConcreteLibfuncLongId,\n    ) -> cairo_lang_sierra::ids::ConcreteLibfuncId;\n\n    #[salsa::interned]\n    fn intern_concrete_type(\n        &self,\n        id: cairo_lang_sierra::program::ConcreteTypeLongId,\n    ) -> cairo_lang_sierra::ids::ConcreteTypeId;\n\n    /// Creates a Sierra function id for a function id of the semantic model.\n    // TODO(lior): Can we have the short and long ids in the same place? Currently, the short\n    //   id is defined in sierra and the long id is defined in semantic.\n    #[salsa::interned]\n    fn intern_sierra_function(\n        &self,\n        id: semantic::FunctionId,\n    ) -> cairo_lang_sierra::ids::FunctionId;\n\n    /// Returns the matching sierra concrete type id for a given semantic type id.\n    #[salsa::invoke(crate::types::get_concrete_type_id)]\n    fn get_concrete_type_id(\n        &self,\n        type_id: semantic::TypeId,\n    ) -> Maybe<cairo_lang_sierra::ids::ConcreteTypeId>;\n\n    /// Returns the [cairo_lang_sierra::program::FunctionSignature] object for the given function\n    /// id.\n    fn get_function_signature(\n        &self,\n        function_id: cairo_lang_sierra::ids::FunctionId,\n    ) -> Maybe<Arc<cairo_lang_sierra::program::FunctionSignature>>;\n\n    /// Returns the [cairo_lang_sierra::extensions::types::TypeInfo] object for the given type id.\n    fn get_type_info(\n        &self,\n        concrete_type_id: cairo_lang_sierra::ids::ConcreteTypeId,\n    ) -> Maybe<Arc<cairo_lang_sierra::extensions::types::TypeInfo>>;\n\n    /// Private query to compute Sierra data about a function with body.\n    #[salsa::invoke(function_generator::priv_function_with_body_sierra_data)]\n    fn priv_function_with_body_sierra_data(\n        &self,\n        function_id: ConcreteFunctionWithBodyId,\n    ) -> function_generator::SierraFunctionWithBodyData;\n    /// Returns the Sierra code (as [pre_sierra::Function]) for a given function with body.\n    #[salsa::invoke(function_generator::function_with_body_sierra)]\n    fn function_with_body_sierra(\n        &self,\n        function_id: ConcreteFunctionWithBodyId,\n    ) -> Maybe<Arc<pre_sierra::Function>>;\n\n    /// Returns the ap change of a given function if it is known at compile time or\n    /// [SierraApChange::Unknown] otherwise.\n    #[salsa::invoke(ap_change::get_ap_change)]\n    fn get_ap_change(&self, function_id: ConcreteFunctionWithBodyId) -> Maybe<SierraApChange>;\n\n    /// Returns the [cairo_lang_sierra::program::Program] object of the requested functions.\n    #[salsa::invoke(program_generator::get_sierra_program_for_functions)]\n    fn get_sierra_program_for_functions(\n        &self,\n        requested_function_ids: Vec<ConcreteFunctionWithBodyId>,\n    ) -> Maybe<Arc<cairo_lang_sierra::program::Program>>;\n\n    /// Returns the [cairo_lang_sierra::program::Program] object of the requested crates.\n    #[salsa::invoke(program_generator::get_sierra_program)]\n    fn get_sierra_program(\n        &self,\n        requested_crate_ids: Vec<CrateId>,\n    ) -> Maybe<Arc<cairo_lang_sierra::program::Program>>;\n}\n\nfn get_function_signature(\n    db: &dyn SierraGenGroup,\n    function_id: cairo_lang_sierra::ids::FunctionId,\n) -> Maybe<Arc<cairo_lang_sierra::program::FunctionSignature>> {\n    // TODO(yuval): add another version of this function that directly received semantic FunctionId.\n    // Call it from function_generators::get_function_code. Take ret_types from the result instead\n    // of only the explicit ret_type. Also use it for params instead of the current logic. Then use\n    // it in the end of program_generator::get_sierra_program instead of calling this function from\n    // there.\n    let semantic_function_id = db.lookup_intern_sierra_function(function_id);\n    let signature = db.concrete_function_signature(semantic_function_id)?;\n    let may_panic = db.function_may_panic(semantic_function_id)?;\n\n    let implicits = db\n        .function_all_implicits(semantic_function_id)?\n        .iter()\n        .map(|ty| db.get_concrete_type_id(*ty))\n        .collect::<Maybe<Vec<ConcreteTypeId>>>()?;\n\n    // TODO(spapini): Handle ret_types in lowering.\n    let mut all_params = implicits.clone();\n    let mut ref_types = vec![];\n    for param in &signature.params {\n        let concrete_type_id = db.get_concrete_type_id(param.ty)?;\n        all_params.push(concrete_type_id.clone());\n        if param.mutability == Mutability::Reference {\n            ref_types.push(concrete_type_id);\n        }\n    }\n\n    // TODO(ilya): Handle tuple and struct types.\n    let mut ret_types = implicits;\n    if may_panic {\n        let panic_info = PanicSignatureInfo::new(db.upcast(), &signature);\n        ret_types.push(db.get_concrete_type_id(panic_info.panic_ty)?);\n    } else {\n        ret_types.extend(ref_types.into_iter());\n        ret_types.push(db.get_concrete_type_id(signature.return_type)?);\n    }\n\n    Ok(Arc::new(cairo_lang_sierra::program::FunctionSignature {\n        param_types: all_params,\n        ret_types,\n    }))\n}\n\nfn get_type_info(\n    db: &dyn SierraGenGroup,\n    concrete_type_id: cairo_lang_sierra::ids::ConcreteTypeId,\n) -> Maybe<Arc<cairo_lang_sierra::extensions::types::TypeInfo>> {\n    let long_id = db.lookup_intern_concrete_type(concrete_type_id);\n    let concrete_ty = cairo_lang_sierra::extensions::core::CoreType::specialize_by_id(\n        &SierraSignatureSpecializationContext(db),\n        &long_id.generic_id,\n        &long_id.generic_args,\n    )\n    .expect(\"Got failure while specializing type.\");\n    Ok(Arc::new(concrete_ty.info().clone()))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_diagnostics::Maybe;\nuse cairo_lang_lowering as lowering;\nuse cairo_lang_semantic::{ConcreteFunctionWithBodyId, TypeId};\nuse cairo_lang_sierra::extensions::uninitialized::UninitializedType;\nuse cairo_lang_sierra::extensions::NamedType;\nuse cairo_lang_sierra::program::{ConcreteTypeLongId, GenericArg};\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse cairo_lang_utils::unordered_hash_map::UnorderedHashMap;\nuse lowering::{BlockId, FlatLowered, VariableId};\n\nuse crate::db::SierraGenGroup;\nuse crate::id_allocator::IdAllocator;\nuse crate::lifetime::{DropLocation, SierraGenVar, UseLocation, VariableLifetimeResult};\nuse crate::pre_sierra;\n\n/// Context for the methods that generate Sierra instructions for an expression.\npub struct ExprGeneratorContext<'a> {\n    db: &'a dyn SierraGenGroup,\n    lowered: &'a FlatLowered,\n    function_id: ConcreteFunctionWithBodyId,\n    lifetime: &'a VariableLifetimeResult,\n\n    var_id_allocator: IdAllocator,\n    label_id_allocator: IdAllocator,\n    variables: UnorderedHashMap<SierraGenVar, cairo_lang_sierra::ids::VarId>,\n    block_labels: OrderedHashMap<BlockId, pre_sierra::LabelId>,\n}\nimpl<'a> ExprGeneratorContext<'a> {\n    /// Constructs an empty [ExprGeneratorContext].\n    pub fn new(\n        db: &'a dyn SierraGenGroup,\n        lowered: &'a FlatLowered,\n        function_id: ConcreteFunctionWithBodyId,\n        lifetime: &'a VariableLifetimeResult,\n    ) -> Self {\n        ExprGeneratorContext {\n            db,\n            lowered,\n            function_id,\n            lifetime,\n            var_id_allocator: IdAllocator::default(),\n            label_id_allocator: IdAllocator::default(),\n            variables: UnorderedHashMap::default(),\n            block_labels: OrderedHashMap::default(),\n        }\n    }\n\n    /// Allocates a new Sierra variable.\n    pub fn allocate_sierra_variable(&mut self) -> cairo_lang_sierra::ids::VarId {\n        cairo_lang_sierra::ids::VarId::new(self.var_id_allocator.allocate() as u64)\n    }\n\n    /// Returns the SierraGenGroup salsa database.\n    pub fn get_db(&self) -> &'a dyn SierraGenGroup {\n        self.db\n    }\n\n    /// Returns the Sierra variable that corresponds to [lowering::VariableId].\n    /// Allocates a new Sierra variable on the first call (for each variable).\n    pub fn get_sierra_variable(\n        &mut self,\n        var: impl Into<SierraGenVar>,\n    ) -> cairo_lang_sierra::ids::VarId {\n        let var: SierraGenVar = var.into();\n        if let Some(sierra_var) = self.variables.get(&var) {\n            return sierra_var.clone();\n        }\n\n        let sierra_var = self.allocate_sierra_variable();\n        self.variables.insert(var, sierra_var.clone());\n        sierra_var\n    }\n\n    /// Same as [Self::get_sierra_variable] except that it operates of a list of variables.\n    pub fn get_sierra_variables(\n        &mut self,\n        vars: &[lowering::VariableId],\n    ) -> Vec<cairo_lang_sierra::ids::VarId> {\n        vars.iter().map(|var| self.get_sierra_variable(*var)).collect()\n    }\n\n    /// Allocates a label id inside the given function.\n    pub fn alloc_label_id(&mut self) -> pre_sierra::LabelId {\n        // TODO(lior): Consider using stable ids, instead of allocating sequential ids.\n        alloc_label_id(self.db, self.function_id, &mut self.label_id_allocator)\n    }\n\n    /// Generates a label id and a label statement.\n    pub fn new_label(&mut self) -> (pre_sierra::Statement, pre_sierra::LabelId) {\n        let id = self.alloc_label_id();\n        (pre_sierra::Statement::Label(pre_sierra::Label { id }), id)\n    }\n\n    /// Adds the block to pending_blocks and returns the label id of the block.\n    pub fn block_label(&mut self, block_id: BlockId) -> &pre_sierra::LabelId {\n        self.block_labels.entry(block_id).or_insert_with(|| {\n            alloc_label_id(self.db, self.function_id, &mut self.label_id_allocator)\n        })\n    }\n\n    /// Returns the [cairo_lang_sierra::ids::ConcreteTypeId] associated with\n    /// [lowering::VariableId].\n    pub fn get_variable_sierra_type(\n        &self,\n        var: impl Into<SierraGenVar>,\n    ) -> Maybe<cairo_lang_sierra::ids::ConcreteTypeId> {\n        Ok(match var.into() {\n            SierraGenVar::LoweringVar(lowering_var) => {\n                self.db.get_concrete_type_id(self.lowered.variables[lowering_var].ty)?\n            }\n            SierraGenVar::UninitializedLocal(lowering_var) => {\n                let inner_type =\n                    self.db.get_concrete_type_id(self.lowered.variables[lowering_var].ty)?;\n                self.db.intern_concrete_type(ConcreteTypeLongId {\n                    generic_id: UninitializedType::ID,\n                    generic_args: vec![GenericArg::Type(inner_type)],\n                })\n            }\n        })\n    }\n\n    /// Returns the block ([lowering::FlatBlock]) associated with\n    /// [lowering::BlockId].\n    /// Assumes `block_id` exists in `self.lowered.blocks`.\n    pub fn get_lowered_block(&self, block_id: lowering::BlockId) -> &'a lowering::FlatBlock {\n        &self.lowered.blocks[block_id]\n    }\n\n    /// Returns the places where variables should be dropped. See [VariableLifetimeResult::drops].\n    pub fn get_drops(&self) -> &'a OrderedHashMap<DropLocation, Vec<SierraGenVar>> {\n        &self.lifetime.drops\n    }\n\n    /// Returns `true` if the given [UseLocation] is the last time a variable is used (namely,\n    /// it will not be used after the current statement).\n    pub fn is_last_use(&self, use_location: &UseLocation) -> bool {\n        self.lifetime.last_use.contains(use_location)\n    }\n\n    /// Returns the type of the variable given by `var_id`.\n    pub fn get_var_type(&self, var_id: VariableId) -> TypeId {\n        self.lowered.variables[var_id].ty\n    }\n}\n\n/// A variant of ExprGeneratorContext::alloc_label_id that allows the caller to avoid\n/// allocate labels while parts of the context are borrowed.\npub fn alloc_label_id(\n    db: &dyn SierraGenGroup,\n    function_id: ConcreteFunctionWithBodyId,\n    label_id_allocator: &mut IdAllocator,\n) -> pre_sierra::LabelId {\n    db.intern_label_id(pre_sierra::LabelLongId {\n        parent: function_id,\n        id: label_id_allocator.allocate(),\n    })\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "#[cfg(test)]\n#[path = \"function_generator_test.rs\"]\nmod test;\n\nuse std::sync::Arc;\n\nuse cairo_lang_diagnostics::Maybe;\nuse cairo_lang_semantic::ConcreteFunctionWithBodyId;\nuse cairo_lang_sierra::ids::ConcreteLibfuncId;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse cairo_lang_utils::ordered_hash_set::OrderedHashSet;\nuse lowering::BlockId;\nuse {cairo_lang_lowering as lowering, cairo_lang_semantic as semantic};\n\nuse crate::block_generator::generate_block_code;\nuse crate::db::SierraGenGroup;\nuse crate::expr_generator_context::ExprGeneratorContext;\nuse crate::lifetime::{find_variable_lifetime, SierraGenVar};\nuse crate::local_variables::find_local_variables;\nuse crate::pre_sierra::{self, Statement};\nuse crate::store_variables::{add_store_statements, LibfuncInfo, LocalVariables};\nuse crate::utils::{\n    alloc_local_libfunc_id, finalize_locals_libfunc_id, get_libfunc_signature, simple_statement,\n};\n\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct SierraFunctionWithBodyData {\n    pub function: Maybe<Arc<pre_sierra::Function>>,\n}\n\n/// Query implementation of [SierraGenGroup::priv_function_with_body_sierra_data].\npub fn priv_function_with_body_sierra_data(\n    db: &dyn SierraGenGroup,\n    function_id: ConcreteFunctionWithBodyId,\n) -> SierraFunctionWithBodyData {\n    let function = get_function_code(db, function_id);\n    SierraFunctionWithBodyData { function }\n}\n\n/// Query implementation of [SierraGenGroup::function_with_body_sierra].\npub fn function_with_body_sierra(\n    db: &dyn SierraGenGroup,\n    function_id: ConcreteFunctionWithBodyId,\n) -> Maybe<Arc<pre_sierra::Function>> {\n    db.priv_function_with_body_sierra_data(function_id).function\n}\n\nfn get_function_code(\n    db: &dyn SierraGenGroup,\n    function_id: ConcreteFunctionWithBodyId,\n) -> Maybe<Arc<pre_sierra::Function>> {\n    let signature = db.concrete_function_signature(function_id.function_id(db.upcast())?)?;\n    let lowered_function = &*db.concrete_function_with_body_lowered(function_id)?;\n    lowered_function.blocks.has_root()?;\n\n    // Find the local variables.\n    let local_variables = find_local_variables(db, lowered_function)?;\n\n    // Get lifetime information.\n    let lifetime = find_variable_lifetime(lowered_function, &local_variables)?;\n\n    let mut context = ExprGeneratorContext::new(db, lowered_function, function_id, &lifetime);\n\n    // Generate a label for the function's body.\n    let (label, label_id) = context.new_label();\n\n    // Generate Sierra variables for the function parameters.\n    let mut parameters: Vec<cairo_lang_sierra::program::Param> = Vec::new();\n    for param_id in &lowered_function.parameters {\n        let var = &lowered_function.variables[*param_id];\n\n        parameters.push(cairo_lang_sierra::program::Param {\n            id: context.get_sierra_variable(*param_id),\n            ty: db.get_concrete_type_id(var.ty)?,\n        })\n    }\n\n    let ret_types = vec![db.get_concrete_type_id(signature.return_type)?];\n\n    let mut statements: Vec<pre_sierra::Statement> = vec![label];\n\n    let (sierra_local_variables, allocate_local_statements) =\n        allocate_local_variables(&mut context, &local_variables)?;\n    statements.extend(allocate_local_statements);\n\n    let prolog_size = statements.len();\n\n    // Generate the function's code.\n    statements.extend(generate_block_code(&mut context, BlockId::root())?);\n\n    let statements = add_store_statements(\n        context.get_db(),\n        statements,\n        &|concrete_lib_func_id: ConcreteLibfuncId| -> LibfuncInfo {\n            LibfuncInfo { signature: get_libfunc_signature(context.get_db(), concrete_lib_func_id) }\n        },\n        sierra_local_variables,\n    );\n\n    // TODO(spapini): Don't intern objects for the semantic model outside the crate. These should\n    // be regarded as private.\n    Ok(pre_sierra::Function {\n        id: db.intern_sierra_function(db.intern_function(semantic::FunctionLongId {\n            function: function_id.concrete(db.upcast())?,\n        })),\n        prolog_size,\n        body: statements,\n        entry_point: label_id,\n        parameters,\n        ret_types,\n    }\n    .into())\n}\n\n/// Allocates space for the local variables.\n/// Returns:\n/// * A map from a Sierra variable that should be stored as local variable to its allocated space\n///   (uninitialized local variable).\n/// * A list of Sierra statements.\nfn allocate_local_variables(\n    context: &mut ExprGeneratorContext<'_>,\n    local_variables: &OrderedHashSet<lowering::VariableId>,\n) -> Maybe<(LocalVariables, Vec<Statement>)> {\n    let mut statements: Vec<pre_sierra::Statement> = vec![];\n    let mut sierra_local_variables =\n        OrderedHashMap::<cairo_lang_sierra::ids::VarId, cairo_lang_sierra::ids::VarId>::default();\n    for lowering_var_id in local_variables.iter() {\n        let sierra_var_id = context.get_sierra_variable(*lowering_var_id);\n        let uninitialized_local_var_id =\n            context.get_sierra_variable(SierraGenVar::UninitializedLocal(*lowering_var_id));\n        statements.push(simple_statement(\n            alloc_local_libfunc_id(\n                context.get_db(),\n                context.get_variable_sierra_type(*lowering_var_id)?,\n            ),\n            &[],\n            &[uninitialized_local_var_id.clone()],\n        ));\n\n        sierra_local_variables.insert(sierra_var_id, uninitialized_local_var_id);\n    }\n\n    // Add finalize_locals() statement.\n    if !local_variables.is_empty() {\n        statements.push(simple_statement(finalize_locals_libfunc_id(context.get_db()), &[], &[]));\n    }\n\n    Ok((sierra_local_variables, statements))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use crate::function_generator_test_utils::test_function_generator;\n\ncairo_lang_test_utils::test_file_test!(\n    function_generator,\n    \"src/function_generator_test_data\",\n    {\n        inline: \"inline\",\n        struct_: \"struct\",\n        match_: \"match\",\n        simple: \"simple\",\n        literals: \"literals\",\n\n    },\n    test_function_generator\n);\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_lowering::db::LoweringGroup;\nuse cairo_lang_semantic::test_utils::setup_test_function;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\n\nuse crate::db::SierraGenGroup;\nuse crate::replace_ids::replace_sierra_ids;\nuse crate::test_utils::SierraGenDatabaseForTesting;\n\n/// Compiles a single function to Sierra and checks the generated code.\npub fn test_function_generator(\n    inputs: &OrderedHashMap<String, String>,\n) -> OrderedHashMap<String, String> {\n    let db = &mut SierraGenDatabaseForTesting::default();\n    // Parse code and create semantic model.\n    let (test_function, semantic_diagnostics) = setup_test_function(\n        db,\n        inputs[\"function\"].as_str(),\n        inputs[\"function_name\"].as_str(),\n        inputs[\"module_code\"].as_str(),\n    )\n    .split();\n\n    // Verify that there are no diagnostics.\n    let lowering_diagnostics = db.module_lowering_diagnostics(test_function.module_id);\n\n    // Compile the function.\n    let function = db.function_with_body_sierra(test_function.concrete_function_id);\n    let sierra_code: String = function.map_or(\"None\".into(), |func| {\n        func.body\n            .iter()\n            .map(|x| replace_sierra_ids(db, x).to_string())\n            .collect::<Vec<String>>()\n            .join(\"\\n\")\n    });\n\n    OrderedHashMap::from([\n        (\"semantic_diagnostics\".into(), semantic_diagnostics),\n        (\n            \"lowering_diagnostics\".into(),\n            lowering_diagnostics.map_or(\"\".into(), |diagnostics| diagnostics.format(db)),\n        ),\n        (\"sierra_code\".into(), sierra_code),\n    ])\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "/// Allocates unique sequential identifiers.\npub struct IdAllocator {\n    next_id: usize,\n}\nimpl IdAllocator {\n    pub fn default() -> Self {\n        Self { next_id: 0 }\n    }\n\n    pub fn allocate(&mut self) -> usize {\n        let cur_id = self.next_id;\n        self.next_id += 1;\n        cur_id\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Lowering from the semantic model down to Sierra. See [cairo_lang_semantic] and\n//! [cairo_lang_sierra].\n\nmod ap_change;\nmod block_generator;\npub mod canonical_id_replacer;\npub mod db;\nmod expr_generator_context;\nmod function_generator;\n#[cfg(any(feature = \"testing\", test))]\npub mod function_generator_test_utils;\nmod id_allocator;\nmod lifetime;\nmod local_variables;\nmod next_statement_index_fetch;\npub mod pre_sierra;\nmod program_generator;\npub mod replace_ids;\nmod resolve_labels;\nmod specialization_context;\nmod store_variables;\n#[cfg(any(feature = \"testing\", test))]\npub mod test_utils;\nmod types;\nmod utils;\n",
    "metadata": {}
  },
  {
    "pageContent": "#[cfg(test)]\n#[path = \"lifetime_test.rs\"]\nmod test;\n\nuse std::fmt::Debug;\n\nuse cairo_lang_diagnostics::Maybe;\nuse cairo_lang_lowering as lowering;\nuse cairo_lang_lowering::{BlockId, VariableId};\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse cairo_lang_utils::ordered_hash_set::OrderedHashSet;\nuse itertools::{zip_eq, Itertools};\nuse lowering::borrow_check::analysis::{Analyzer, BackAnalysis, StatementLocation};\nuse lowering::borrow_check::demand::DemandReporter;\nuse lowering::borrow_check::Demand;\nuse lowering::FlatLowered;\n\n/// Represents the location where a drop statement for a variable should be added.\n#[derive(Clone, Copy, Debug, Eq, Hash, PartialEq)]\npub enum DropLocation {\n    BeginningOfBlock(BlockId),\n    PostStatement(StatementLocation),\n}\n\n/// Represents a location where a variable is being used.\n/// Contains the statement location, and the index of the argument within this statement.\n#[derive(Clone, Copy, Eq, Hash, PartialEq)]\npub struct UseLocation {\n    /// The statement where the variable is used.\n    pub statement_location: StatementLocation,\n    /// The index of the argument within the statement.\n    pub idx: usize,\n}\n\nimpl Debug for UseLocation {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        write!(f, \"({:?}, {})\", self.statement_location, self.idx)\n    }\n}\n\n/// Represents a Sierra variable by its corresponding lowering [VariableId].\n///\n/// For example, uninitialized local variables do not have a representation as lowering\n/// [VariableId], since they are created in the sierra-generation phase.\n/// Instead, we refer to it as [SierraGenVar::UninitializedLocal] by the actual local variable\n/// (not the uninitialized version).\n#[derive(Clone, Copy, Eq, Hash, PartialEq)]\npub enum SierraGenVar {\n    /// Represents a regular variable.\n    LoweringVar(VariableId),\n    /// Represents an uninitialized local variable, by the corresponding local variable.\n    UninitializedLocal(VariableId),\n}\n\nimpl From<VariableId> for SierraGenVar {\n    fn from(var: VariableId) -> Self {\n        SierraGenVar::LoweringVar(var)\n    }\n}\n\nimpl Debug for SierraGenVar {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            Self::LoweringVar(var) => write!(f, \"v{}\", var.index()),\n            Self::UninitializedLocal(var) => write!(f, \"UninitializedLocal(v{})\", var.index()),\n        }\n    }\n}\n\n/// Information returned by [find_variable_lifetime] regarding the lifetime of variables.\n#[derive(Default)]\npub struct VariableLifetimeResult {\n    /// A set of [UseLocation] where a variable is used, but not required after.\n    ///\n    /// Note that a variable may be mentioned twice. For example, when it's last used within two\n    /// branches.\n    ///\n    /// StatementLocation may point to a nonexisting statement after the end of the block -\n    /// this means that the last use was in `block.end`.\n    pub last_use: OrderedHashSet<UseLocation>,\n    /// A map from [DropLocation] to the list of variables that should be dropped at this location.\n    pub drops: OrderedHashMap<DropLocation, Vec<SierraGenVar>>,\n}\nimpl VariableLifetimeResult {\n    /// Registers where a drop statement should appear.\n    fn add_drop(&mut self, var_id: SierraGenVar, drop_location: DropLocation) {\n        if let Some(vars) = self.drops.get_mut(&drop_location) {\n            vars.push(var_id);\n        } else {\n            self.drops.insert(drop_location, vec![var_id]);\n        }\n    }\n}\n\n/// Given the lowering of a function, returns lifetime information for all the variables.\n/// See [VariableLifetimeResult].\npub fn find_variable_lifetime(\n    lowered_function: &FlatLowered,\n    local_vars: &OrderedHashSet<VariableId>,\n) -> Maybe<VariableLifetimeResult> {\n    lowered_function.blocks.has_root()?;\n    let context = VariableLifetimeContext { local_vars, res: VariableLifetimeResult::default() };\n    let mut analysis =\n        BackAnalysis { lowered: lowered_function, cache: Default::default(), analyzer: context };\n\n    let mut root_demands = analysis.get_root_info();\n    analysis.analyzer.introduce(\n        &mut root_demands,\n        &lowered_function.parameters,\n        DropLocation::BeginningOfBlock(BlockId::root()),\n    );\n    for var in root_demands.vars {\n        assert!(matches!(var, SierraGenVar::UninitializedLocal(_)), \"Unexpected variable.\");\n    }\n    Ok(analysis.analyzer.res)\n}\n\n/// Context information for [find_variable_lifetime] and its helper functions.\nstruct VariableLifetimeContext<'a> {\n    local_vars: &'a OrderedHashSet<VariableId>,\n    res: VariableLifetimeResult,\n}\n\npub type SierraDemand = Demand<SierraGenVar>;\n\nimpl<'a> DemandReporter<SierraGenVar> for VariableLifetimeContext<'a> {\n    type IntroducePosition = DropLocation;\n    type UsePosition = StatementLocation;\n\n    fn drop(&mut self, position: DropLocation, var: SierraGenVar) {\n        self.res.add_drop(var, position)\n    }\n\n    fn last_use(\n        &mut self,\n        statement_location: StatementLocation,\n        var_index: usize,\n        _var: SierraGenVar,\n    ) {\n        self.res.last_use.insert(UseLocation { statement_location, idx: var_index });\n    }\n}\n\nimpl<'a> Analyzer for VariableLifetimeContext<'a> {\n    type Info = SierraDemand;\n\n    fn visit_stmt(\n        &mut self,\n        info: &mut Self::Info,\n        statement_location: StatementLocation,\n        stmt: &lowering::Statement,\n    ) {\n        self.introduce(info, &stmt.outputs(), DropLocation::PostStatement(statement_location));\n        info.variables_used(self, &stmt.inputs(), statement_location);\n    }\n\n    fn visit_remapping(\n        &mut self,\n        info: &mut Self::Info,\n        _block_id: BlockId,\n        _target_block_id: BlockId,\n        remapping: &lowering::VarRemapping,\n    ) {\n        info.apply_remapping(self, remapping.iter().map(|(dst, src)| (*dst, *src)));\n        for (dst, _src) in remapping.iter() {\n            if self.local_vars.contains(dst) {\n                assert!(\n                    info.vars.insert(SierraGenVar::UninitializedLocal(*dst)),\n                    \"Variable introduced multiple times.\"\n                );\n            }\n        }\n    }\n\n    fn merge_match(\n        &mut self,\n        statement_location: StatementLocation,\n        match_info: &lowering::MatchInfo,\n        infos: &[Self::Info],\n    ) -> Self::Info {\n        let arm_demands = zip_eq(match_info.arms(), infos)\n            .map(|(arm, demand)| {\n                let mut demand = demand.clone();\n                self.introduce(\n                    &mut demand,\n                    &arm.var_ids,\n                    DropLocation::BeginningOfBlock(arm.block_id),\n                );\n                (demand, DropLocation::BeginningOfBlock(arm.block_id))\n            })\n            .collect_vec();\n        let mut demand = SierraDemand::merge_demands(&arm_demands, self);\n        demand.variables_used(self, &match_info.inputs(), statement_location);\n        demand\n    }\n\n    fn info_from_return(\n        &mut self,\n        statement_location: StatementLocation,\n        vars: &[VariableId],\n    ) -> Self::Info {\n        let mut info = SierraDemand::default();\n        info.variables_used(self, vars, statement_location);\n        info\n    }\n\n    fn info_from_panic(\n        &mut self,\n        _statement_location: StatementLocation,\n        _var: &VariableId,\n    ) -> Self::Info {\n        unreachable!(\"Panics should have been stripped in a previous phase.\")\n    }\n}\nimpl<'a> VariableLifetimeContext<'a> {\n    fn introduce(&mut self, info: &mut SierraDemand, vars: &[VariableId], location: DropLocation) {\n        info.variables_introduced(self, vars, location);\n        for var_id in vars {\n            if self.local_vars.contains(var_id) {\n                assert!(\n                    info.vars.insert(SierraGenVar::UninitializedLocal(*var_id)),\n                    \"Variable introduced multiple times.\"\n                );\n            }\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_debug::DebugWithDb;\nuse cairo_lang_lowering as lowering;\nuse cairo_lang_lowering::db::LoweringGroup;\nuse cairo_lang_semantic::test_utils::setup_test_function;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse itertools::Itertools;\n\nuse super::find_variable_lifetime;\nuse crate::local_variables::find_local_variables;\nuse crate::test_utils::SierraGenDatabaseForTesting;\n\ncairo_lang_test_utils::test_file_test!(\n    variable_lifetime,\n    \"src/lifetime_test_data\",\n    {\n        block: \"block\",\n        early_return: \"early_return\",\n        enum_: \"enum\",\n        inline: \"inline\",\n        locals: \"locals\",\n        simple: \"simple\",\n        snapshot: \"snapshot\",\n        struct_: \"struct\",\n        match_: \"match\",\n    },\n    check_variable_lifetime\n);\n\nfn check_variable_lifetime(\n    inputs: &OrderedHashMap<String, String>,\n) -> OrderedHashMap<String, String> {\n    let db = &mut SierraGenDatabaseForTesting::default();\n    // Parse code and create semantic model.\n    let test_function = setup_test_function(\n        db,\n        inputs[\"function_code\"].as_str(),\n        inputs[\"function_name\"].as_str(),\n        inputs[\"module_code\"].as_str(),\n    )\n    .unwrap();\n\n    db.module_lowering_diagnostics(test_function.module_id)\n        .unwrap()\n        .expect_with_db(db, \"Unexpected diagnostics.\");\n\n    let lowered_function =\n        &*db.concrete_function_with_body_lowered(test_function.concrete_function_id).unwrap();\n\n    let lowered_formatter =\n        lowering::fmt::LoweredFormatter { db, variables: &lowered_function.variables };\n    let lowered_str = format!(\"{:?}\", lowered_function.debug(&lowered_formatter));\n\n    let local_variables = find_local_variables(db, lowered_function).unwrap();\n    let find_variable_lifetime_res = find_variable_lifetime(lowered_function, &local_variables)\n        .expect(\"find_variable_lifetime failed unexpectedly\");\n    let last_use_str = find_variable_lifetime_res\n        .last_use\n        .iter()\n        .map(|location| {\n            let block = &lowered_function.blocks[location.statement_location.0];\n            let statements = &block.statements;\n            let var_id = if location.statement_location.1 == statements.len() {\n                match &block.end {\n                    lowering::FlatBlockEnd::Goto(_, remapping) => {\n                        *remapping.values().nth(location.idx).unwrap()\n                    }\n                    lowering::FlatBlockEnd::Return(returns) => returns[location.idx],\n                    lowering::FlatBlockEnd::Panic(_) => {\n                        unreachable!(\"Panics should have been stripped in a previous phase.\")\n                    }\n                    lowering::FlatBlockEnd::NotSet => unreachable!(),\n                    lowering::FlatBlockEnd::Match { info } => info.inputs()[location.idx],\n                }\n            } else {\n                statements[location.statement_location.1].inputs()[location.idx]\n            };\n            format!(\"v{}: {location:?}\", var_id.index())\n        })\n        .join(\"\\n\");\n    let drop_str = find_variable_lifetime_res\n        .drops\n        .iter()\n        .map(|(location, vars)| {\n            format!(\"{location:?}: {}\", vars.iter().map(|var_id| format!(\"{var_id:?}\")).join(\", \"))\n        })\n        .join(\"\\n\");\n\n    OrderedHashMap::from([\n        (\"lowering_format\".into(), lowered_str),\n        (\"last_use\".into(), last_use_str),\n        (\"drops\".into(), drop_str),\n    ])\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "#[cfg(test)]\n#[path = \"local_variables_test.rs\"]\nmod test;\n\nuse std::collections::HashSet;\n\nuse cairo_lang_diagnostics::Maybe;\nuse cairo_lang_lowering as lowering;\nuse cairo_lang_lowering::{BlockId, VariableId};\nuse cairo_lang_sierra::extensions::lib_func::{BranchSignature, LibfuncSignature};\nuse cairo_lang_sierra::extensions::OutputVarReferenceInfo;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse cairo_lang_utils::ordered_hash_set::OrderedHashSet;\nuse cairo_lang_utils::unordered_hash_map::UnorderedHashMap;\nuse cairo_lang_utils::unordered_hash_set::UnorderedHashSet;\nuse itertools::{zip_eq, Itertools};\nuse lowering::borrow_check::analysis::{Analyzer, BackAnalysis, StatementLocation};\nuse lowering::borrow_check::demand::DemandReporter;\nuse lowering::borrow_check::Demand;\nuse lowering::{FlatLowered, MatchInfo, Statement, VarRemapping};\n\nuse crate::db::SierraGenGroup;\nuse crate::replace_ids::{DebugReplacer, SierraIdReplacer};\nuse crate::utils::{\n    enum_init_libfunc_id, get_concrete_libfunc_id, get_libfunc_signature, match_enum_libfunc_id,\n    struct_construct_libfunc_id, struct_deconstruct_libfunc_id,\n};\n\n/// Given the lowering of a function, returns the set of variables which should be stored as local\n/// variables.\npub fn find_local_variables(\n    db: &dyn SierraGenGroup,\n    lowered_function: &FlatLowered,\n) -> Maybe<OrderedHashSet<VariableId>> {\n    lowered_function.blocks.has_root()?;\n    let ctx = FindLocalsContext {\n        db,\n        lowered_function,\n        used_after_revoke: Default::default(),\n        block_callers: Default::default(),\n        prune_from_locals: Default::default(),\n        aliases: Default::default(),\n    };\n    let mut analysis =\n        BackAnalysis { lowered: lowered_function, cache: Default::default(), analyzer: ctx };\n    let mut root_info = analysis.get_root_info()?;\n    root_info.demand.variables_introduced(&mut analysis.analyzer, &lowered_function.parameters, ());\n\n    if !root_info.known_ap_change {\n        // Revoke all convergences.\n        for (block_id, callers) in analysis.analyzer.block_callers.clone() {\n            if callers.len() <= 1 {\n                continue;\n            }\n            let mut info = analysis.cache[&block_id].as_ref().map_err(|v| *v)?.clone();\n            let introducd_vars = callers[0].1.keys().cloned().collect_vec();\n            info.demand.variables_introduced(&mut analysis.analyzer, &introducd_vars, ());\n            analysis.analyzer.revoke_if_needed(&mut info, BranchInfo { known_ap_change: false });\n        }\n    }\n\n    let FindLocalsContext { used_after_revoke, prune_from_locals, aliases, .. } = analysis.analyzer;\n\n    let function_inputs: HashSet<_> = lowered_function.parameters.iter().copied().collect();\n\n    let mut locals = OrderedHashSet::default();\n    for mut var in used_after_revoke.iter() {\n        while let Some(alias) = aliases.get(var) {\n            var = alias;\n        }\n        if prune_from_locals.contains(var) {\n            continue;\n        }\n        if function_inputs.contains(var) {\n            continue;\n        }\n        locals.insert(*var);\n    }\n    Ok(locals)\n}\n\n/// Context for the find_local_variables logic.\nstruct FindLocalsContext<'a> {\n    db: &'a dyn SierraGenGroup,\n    lowered_function: &'a FlatLowered,\n    used_after_revoke: OrderedHashSet<VariableId>,\n    block_callers: OrderedHashMap<BlockId, Vec<(BlockId, VarRemapping)>>,\n    prune_from_locals: UnorderedHashSet<VariableId>,\n    aliases: UnorderedHashMap<VariableId, VariableId>,\n}\n\npub type LoweredDemand = Demand<VariableId>;\n#[derive(Clone)]\nstruct AnalysisInfo {\n    demand: LoweredDemand,\n    known_ap_change: bool,\n}\nimpl<'a> DemandReporter<VariableId> for FindLocalsContext<'a> {\n    type UsePosition = ();\n    type IntroducePosition = ();\n}\nimpl<'a> Analyzer for FindLocalsContext<'a> {\n    type Info = Maybe<AnalysisInfo>;\n\n    fn visit_stmt(\n        &mut self,\n        info: &mut Self::Info,\n        _statement_location: StatementLocation,\n        stmt: &Statement,\n    ) {\n        let Ok(info) = info else {return;};\n        let Ok(branch_info) = self.analyze_statement(stmt) else {return;};\n        info.demand.variables_introduced(self, &stmt.outputs(), ());\n        self.revoke_if_needed(info, branch_info);\n        info.demand.variables_used(self, &stmt.inputs(), ());\n    }\n\n    fn visit_remapping(\n        &mut self,\n        info: &mut Self::Info,\n        block_id: BlockId,\n        target_block_id: BlockId,\n        remapping: &VarRemapping,\n    ) {\n        let Ok(info) = info else {return;};\n        self.block_callers.entry(target_block_id).or_default().push((block_id, remapping.clone()));\n        info.demand.apply_remapping(self, remapping.iter().map(|(dst, src)| (*dst, *src)));\n    }\n\n    fn merge_match(\n        &mut self,\n        _statement_location: StatementLocation,\n        match_info: &MatchInfo,\n        infos: &[Self::Info],\n    ) -> Maybe<AnalysisInfo> {\n        let mut arm_demands = vec![];\n        let mut known_ap_change = true;\n        let inputs = match_info.inputs();\n\n        // Revoke if needed.\n        let libfunc_signature = self.get_match_libfunc_signature(match_info)?;\n        for (arm, (info, branch_signature)) in\n            zip_eq(match_info.arms(), zip_eq(infos, libfunc_signature.branch_signatures))\n        {\n            let mut info = info.clone()?;\n            info.demand.variables_introduced(self, &arm.var_ids, ());\n            let branch_info = self.analyze_branch(&branch_signature, &inputs, &arm.var_ids);\n            self.revoke_if_needed(&mut info, branch_info);\n            known_ap_change &= info.known_ap_change;\n            arm_demands.push((info.demand, ()));\n        }\n        let mut demand = LoweredDemand::merge_demands(&arm_demands, self);\n        demand.variables_used(self, &match_info.inputs(), ());\n        Ok(AnalysisInfo { demand, known_ap_change })\n    }\n\n    fn info_from_return(\n        &mut self,\n        _statement_location: StatementLocation,\n        vars: &[VariableId],\n    ) -> Self::Info {\n        let mut demand = LoweredDemand::default();\n        demand.variables_used(self, vars, ());\n        Ok(AnalysisInfo { demand, known_ap_change: true })\n    }\n\n    fn info_from_panic(\n        &mut self,\n        _statement_location: StatementLocation,\n        _var: &VariableId,\n    ) -> Self::Info {\n        unreachable!(\"Panics should have been stripped in a previous phase.\")\n    }\n}\n\nstruct BranchInfo {\n    known_ap_change: bool,\n}\n\nimpl<'a> FindLocalsContext<'a> {\n    fn analyze_call(\n        &mut self,\n        concrete_function_id: cairo_lang_sierra::ids::ConcreteLibfuncId,\n        input_vars: &[VariableId],\n        output_vars: &[VariableId],\n    ) -> BranchInfo {\n        let libfunc_signature = get_libfunc_signature(self.db, concrete_function_id.clone());\n        assert_eq!(\n            libfunc_signature.branch_signatures.len(),\n            1,\n            \"Unexpected branches in '{}'.\",\n            DebugReplacer { db: self.db }.replace_libfunc_id(&concrete_function_id)\n        );\n\n        self.analyze_branch(&libfunc_signature.branch_signatures[0], input_vars, output_vars)\n    }\n\n    fn analyze_branch(\n        &mut self,\n        branch_signature: &BranchSignature,\n        input_vars: &[VariableId],\n        output_vars: &[VariableId],\n    ) -> BranchInfo {\n        let var_output_infos = &branch_signature.vars;\n        for (var, output_info) in zip_eq(output_vars.iter(), var_output_infos.iter()) {\n            match output_info.ref_info {\n                OutputVarReferenceInfo::SameAsParam { param_idx } => {\n                    self.aliases.insert(*var, input_vars[param_idx]);\n                }\n                OutputVarReferenceInfo::NewTempVar { .. }\n                | OutputVarReferenceInfo::Deferred(_)\n                | OutputVarReferenceInfo::PartialParam { .. } => {}\n                OutputVarReferenceInfo::NewLocalVar => {\n                    self.prune_from_locals.insert(*var);\n                }\n            }\n        }\n\n        let known_ap_change = matches!(\n            branch_signature.ap_change,\n            cairo_lang_sierra::extensions::lib_func::SierraApChange::Known { .. }\n        );\n\n        BranchInfo { known_ap_change }\n    }\n\n    fn analyze_statement(&mut self, statement: &Statement) -> Maybe<BranchInfo> {\n        let inputs = statement.inputs();\n        let outputs = statement.outputs();\n        let branch_info = match statement {\n            lowering::Statement::Literal(statement_literal) => {\n                self.prune_from_locals.insert(statement_literal.output);\n                BranchInfo { known_ap_change: true }\n            }\n            lowering::Statement::Call(statement_call) => {\n                let (_, concrete_function_id) =\n                    get_concrete_libfunc_id(self.db, statement_call.function);\n\n                self.analyze_call(concrete_function_id, &inputs, &outputs)\n            }\n            lowering::Statement::StructConstruct(statement_struct_construct) => {\n                let ty = self.db.get_concrete_type_id(\n                    self.lowered_function.variables[statement_struct_construct.output].ty,\n                )?;\n                self.analyze_call(struct_construct_libfunc_id(self.db, ty), &inputs, &outputs)\n            }\n            lowering::Statement::StructDestructure(statement_struct_destructure) => {\n                let ty = self.db.get_concrete_type_id(\n                    self.lowered_function.variables[statement_struct_destructure.input].ty,\n                )?;\n                self.analyze_call(struct_deconstruct_libfunc_id(self.db, ty)?, &inputs, &outputs)\n            }\n            lowering::Statement::EnumConstruct(statement_enum_construct) => {\n                let ty = self.db.get_concrete_type_id(\n                    self.lowered_function.variables[statement_enum_construct.output].ty,\n                )?;\n                self.analyze_call(\n                    enum_init_libfunc_id(self.db, ty, statement_enum_construct.variant.idx),\n                    &inputs,\n                    &outputs,\n                )\n            }\n            lowering::Statement::Snapshot(statement_snapshot) => {\n                self.aliases.insert(statement_snapshot.output_original, statement_snapshot.input);\n                self.aliases.insert(statement_snapshot.output_snapshot, statement_snapshot.input);\n                BranchInfo { known_ap_change: true }\n            }\n            lowering::Statement::Desnap(statement_desnap) => {\n                self.aliases.insert(statement_desnap.output, statement_desnap.input);\n                BranchInfo { known_ap_change: true }\n            }\n        };\n        Ok(branch_info)\n    }\n\n    fn revoke_if_needed(&mut self, info: &mut AnalysisInfo, branch_info: BranchInfo) {\n        // Revoke if needed.\n        if !branch_info.known_ap_change {\n            info.known_ap_change = false;\n            // Revoke all demanded variables.\n            for var in info.demand.vars.iter() {\n                self.used_after_revoke.insert(*var);\n            }\n        }\n    }\n\n    fn get_match_libfunc_signature(&self, match_info: &MatchInfo) -> Maybe<LibfuncSignature> {\n        Ok(match match_info {\n            MatchInfo::Extern(s) => {\n                let (_, concrete_function_id) = get_concrete_libfunc_id(self.db, s.function);\n                get_libfunc_signature(self.db, concrete_function_id)\n            }\n            MatchInfo::Enum(s) => {\n                let concrete_enum_type =\n                    self.db.get_concrete_type_id(self.lowered_function.variables[s.input].ty)?;\n                let concrete_function_id = match_enum_libfunc_id(self.db, concrete_enum_type)?;\n                get_libfunc_signature(self.db, concrete_function_id)\n            }\n        })\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_debug::DebugWithDb;\nuse cairo_lang_lowering as lowering;\nuse cairo_lang_lowering::db::LoweringGroup;\nuse cairo_lang_semantic::test_utils::setup_test_function;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse itertools::Itertools;\n\nuse crate::function_generator_test_utils::test_function_generator;\nuse crate::test_utils::SierraGenDatabaseForTesting;\n\ncairo_lang_test_utils::test_file_test!(\n    find_local_variables,\n    \"src/local_variables_test_data\",\n    {\n        block: \"block\",\n        construct_enum: \"construct_enum\",\n        inline: \"inline\",\n        match_enum: \"match_enum\",\n        match_extern: \"match_extern\",\n        simple: \"simple\",\n        struct_: \"struct\",\n    },\n    check_find_local_variables\n);\n\nfn check_find_local_variables(\n    inputs: &OrderedHashMap<String, String>,\n) -> OrderedHashMap<String, String> {\n    let db = &mut SierraGenDatabaseForTesting::default();\n    // Parse code and create semantic model.\n    let test_function = setup_test_function(\n        db,\n        inputs[\"function_code\"].as_str(),\n        inputs[\"function_name\"].as_str(),\n        inputs[\"module_code\"].as_str(),\n    )\n    .unwrap();\n\n    db.module_lowering_diagnostics(test_function.module_id)\n        .unwrap()\n        .expect_with_db(db, \"Unexpected diagnostics.\");\n\n    let lowered_function =\n        &*db.concrete_function_with_body_lowered(test_function.concrete_function_id).unwrap();\n\n    let lowered_formatter =\n        lowering::fmt::LoweredFormatter { db, variables: &lowered_function.variables };\n    let lowered_str = format!(\"{:?}\", lowered_function.debug(&lowered_formatter));\n\n    let locals = super::find_local_variables(db, lowered_function).unwrap();\n\n    let local_variables_str =\n        locals.iter().map(|var_id| format!(\"{:?}\", var_id.debug(&lowered_formatter))).join(\", \");\n\n    OrderedHashMap::from([\n        (\"lowering_format\".into(), lowered_str),\n        (\"local_variables\".into(), local_variables_str),\n    ])\n}\n\ncairo_lang_test_utils::test_file_test!(\n    e2e,\n    \"src/local_variables_test_data\",\n    {e2e: \"e2e\"},\n    test_function_generator\n);\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_utils::unordered_hash_map::UnorderedHashMap;\n\nuse crate::pre_sierra::{LabelId, Statement};\n\n/// Helper to fetch the next statement index from a branch target, and get the statement indices\n/// for labels.\npub struct NextStatementIndexFetch {\n    label_to_statement: UnorderedHashMap<LabelId, usize>,\n}\nimpl NextStatementIndexFetch {\n    /// Creates the mapping to fetch statement indices.\n    ///\n    /// If `include_label_indices` is `true`, indices will include label statements.\n    /// Otherwise, those statements will be skipped.\n    pub fn new(statements: &[Statement], include_label_indices: bool) -> Self {\n        let mut index = 0;\n        let mut label_to_statement = UnorderedHashMap::default();\n        for statement in statements {\n            match statement {\n                Statement::Sierra(_) => {\n                    index += 1;\n                }\n                Statement::Label(label) => {\n                    if label_to_statement.insert(label.id, index).is_some() {\n                        panic!(\"Label {} was already declared.\", label.id);\n                    }\n                    if include_label_indices {\n                        index += 1;\n                    }\n                }\n                Statement::PushValues(_) => panic!(\n                    \"Unexpected pre_sierra::Statement::PushValues in \\\n                     NextStatementIndexFetch::new().\"\n                ),\n            }\n        }\n        Self { label_to_statement }\n    }\n\n    /// Returns the index of a statement pointed by the given label.\n    pub fn resolve_label(&self, label: &LabelId) -> usize {\n        // TODO(lior): handle missing labels.\n        *self.label_to_statement.get(label).unwrap()\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_semantic::ConcreteFunctionWithBodyId;\nuse cairo_lang_sierra as sierra;\nuse cairo_lang_sierra::ids::ConcreteTypeId;\nuse cairo_lang_sierra::program;\nuse cairo_lang_utils::{define_short_id, write_comma_separated};\n\nuse crate::db::SierraGenGroup;\n\n/// Represents the long id of a pre-sierra label.\n/// The long id consists of the parent function and a unique identifier inside the function.\n// TODO(lior): Make sure this struct can only be constructed by expr_generator_context.\n#[derive(Clone, Debug, Eq, PartialEq, Hash)]\npub struct LabelLongId {\n    pub parent: ConcreteFunctionWithBodyId,\n    // A unique identifier inside the function\n    pub id: usize,\n}\ndefine_short_id!(LabelId, LabelLongId, SierraGenGroup, lookup_intern_label_id);\n\nimpl std::fmt::Display for LabelId {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        write!(f, \"label{}\", self.0)\n    }\n}\n\n/// Represents a compiled function before the label-resolution phase (pre-sierra).\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct Function {\n    /// The source function which was compiled.\n    pub id: sierra::ids::FunctionId,\n    /// Number of statements in the body that are the function prolog, including the label and the\n    /// local variables definition.\n    pub prolog_size: usize,\n    /// The body of the function.\n    pub body: Vec<Statement>,\n    /// A label pointing to the first instruction of the function.\n    pub entry_point: LabelId,\n    /// The parameters for the function.\n    pub parameters: Vec<program::Param>,\n    /// The return types from the function.\n    pub ret_types: Vec<sierra::ids::ConcreteTypeId>,\n}\n\n/// Represents a pre-sierra statement - a statement before label-resolution.\n#[derive(Clone, Debug, Eq, PartialEq)]\npub enum Statement {\n    /// A compiled Sierra statement (before label resolution).\n    Sierra(program::GenStatement<LabelId>),\n    /// A label.\n    Label(Label),\n    /// An instruction to push variables onto the stack. For example, used before calling functions\n    /// and returning.\n    ///\n    /// Note that push values does not guarantee that new copies of the values will be pushed.\n    /// If a prefix of the values is already on the stack, they will not be re-pushed.\n    PushValues(Vec<PushValue>),\n}\nimpl std::fmt::Display for Statement {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            Statement::Sierra(value) => write!(f, \"{value}\"),\n            Statement::Label(Label { id }) => write!(f, \"{id}:\"),\n            Statement::PushValues(values) => {\n                write!(f, \"PushValues(\")?;\n                write_comma_separated(\n                    f,\n                    values.iter().map(|PushValue { var, ty, .. }| format!(\"{var}: {ty}\")),\n                )?;\n                write!(f, \") -> (\")?;\n                write_comma_separated(\n                    f,\n                    values.iter().map(|PushValue { var_on_stack, dup, .. }| {\n                        if *dup { format!(\"{var_on_stack}*\") } else { format!(\"{var_on_stack}\") }\n                    }),\n                )?;\n                write!(f, \")\")\n            }\n        }\n    }\n}\n\n/// Represents a single element that should be pushed onto the stack as part of\n/// [Statement::PushValues].\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct PushValue {\n    /// The variable id to push.\n    pub var: sierra::ids::VarId,\n    /// The variable id on the stack (e.g., the result of `store_temp()`).\n    pub var_on_stack: sierra::ids::VarId,\n    /// The type of the variable.\n    pub ty: ConcreteTypeId,\n    /// Indicates whether the variable should be duplicated before it is pushed.\n    pub dup: bool,\n}\n\n/// Represents a pre-sierra label.\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct Label {\n    pub id: LabelId,\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::{HashSet, VecDeque};\nuse std::sync::Arc;\n\nuse cairo_lang_diagnostics::{skip_diagnostic, Maybe, ToMaybe};\nuse cairo_lang_filesystem::ids::CrateId;\nuse cairo_lang_semantic::ConcreteFunctionWithBodyId;\nuse cairo_lang_sierra::extensions::core::CoreLibfunc;\nuse cairo_lang_sierra::extensions::lib_func::SierraApChange;\nuse cairo_lang_sierra::extensions::GenericLibfuncEx;\nuse cairo_lang_sierra::ids::{ConcreteLibfuncId, ConcreteTypeId};\nuse cairo_lang_sierra::program;\nuse cairo_lang_utils::ordered_hash_set::OrderedHashSet;\nuse cairo_lang_utils::try_extract_matches;\nuse cairo_lang_utils::unordered_hash_set::UnorderedHashSet;\nuse itertools::chain;\n\nuse crate::db::SierraGenGroup;\nuse crate::pre_sierra::{self};\nuse crate::replace_ids::{DebugReplacer, SierraIdReplacer};\nuse crate::resolve_labels::{resolve_labels, LabelReplacer};\nuse crate::specialization_context::SierraSignatureSpecializationContext;\nuse crate::utils::{\n    disable_ap_tracking_libfunc_id, revoke_ap_tracking_libfunc_id, simple_statement,\n};\n\n#[cfg(test)]\n#[path = \"program_generator_test.rs\"]\nmod test;\n\n/// Generates the list of [cairo_lang_sierra::program::LibfuncDeclaration] for the given list of\n/// [ConcreteLibfuncId].\nfn generate_libfunc_declarations<'a>(\n    db: &dyn SierraGenGroup,\n    libfuncs: impl Iterator<Item = &'a ConcreteLibfuncId>,\n) -> Vec<program::LibfuncDeclaration> {\n    libfuncs\n        .into_iter()\n        .map(|libfunc_id| program::LibfuncDeclaration {\n            id: libfunc_id.clone(),\n            long_id: db.lookup_intern_concrete_lib_func(libfunc_id.clone()),\n        })\n        .collect()\n}\n\n/// Collects the set of all [ConcreteLibfuncId] used in the given list of [pre_sierra::Statement].\nfn collect_used_libfuncs(\n    statements: &[pre_sierra::Statement],\n) -> OrderedHashSet<ConcreteLibfuncId> {\n    statements\n        .iter()\n        .filter_map(|statement| match statement {\n            pre_sierra::Statement::Sierra(program::GenStatement::Invocation(invocation)) => {\n                Some(invocation.libfunc_id.clone())\n            }\n            pre_sierra::Statement::Sierra(program::GenStatement::Return(_))\n            | pre_sierra::Statement::Label(_) => None,\n            pre_sierra::Statement::PushValues(_) => {\n                panic!(\"Unexpected pre_sierra::Statement::PushValues in collect_used_libfuncs().\")\n            }\n        })\n        .collect()\n}\n\n/// Generates the list of [cairo_lang_sierra::program::TypeDeclaration] for the given list of\n/// [ConcreteTypeId].\nfn generate_type_declarations<'a>(\n    db: &dyn SierraGenGroup,\n    types: impl Iterator<Item = &'a ConcreteTypeId>,\n) -> Vec<program::TypeDeclaration> {\n    let mut declarations = vec![];\n    let mut already_declared = HashSet::new();\n    for ty in types {\n        generate_type_declarations_helper(db, ty, &mut declarations, &mut already_declared);\n    }\n    declarations\n}\n\n/// Helper to ensure declaring types ordered in such a way that no type appears before types it\n/// depends on.\nfn generate_type_declarations_helper(\n    db: &dyn SierraGenGroup,\n    ty: &ConcreteTypeId,\n    declarations: &mut Vec<program::TypeDeclaration>,\n    already_declared: &mut HashSet<ConcreteTypeId>,\n) {\n    if already_declared.contains(ty) {\n        return;\n    }\n    let long_id = db.lookup_intern_concrete_type(ty.clone());\n    for generic_arg in &long_id.generic_args {\n        if let program::GenericArg::Type(inner_ty) = generic_arg {\n            generate_type_declarations_helper(db, inner_ty, declarations, already_declared);\n        }\n    }\n    declarations.push(program::TypeDeclaration {\n        id: ty.clone(),\n        long_id,\n        declared_type_info: None,\n    });\n    already_declared.insert(ty.clone());\n}\n\n/// Collects the set of all [ConcreteTypeId] that are used in the given list of\n/// [program::LibfuncDeclaration].\nfn collect_used_types(\n    db: &dyn SierraGenGroup,\n    libfunc_declarations: &[program::LibfuncDeclaration],\n) -> OrderedHashSet<ConcreteTypeId> {\n    libfunc_declarations\n        .iter()\n        .flat_map(|libfunc| {\n            // TODO(orizi): replace expect() with a diagnostic (unless this can never happen).\n            let signature = CoreLibfunc::specialize_signature_by_id(\n                &SierraSignatureSpecializationContext(db),\n                &libfunc.long_id.generic_id,\n                &libfunc.long_id.generic_args,\n            )\n            // If panic happens here, make sure the specified libfunc name is in one of the STR_IDs of\n            // the libfuncs in the [`CoreLibfunc`] structured enum.\n            .unwrap_or_else(|err| panic!(\"Failed to specialize: `{}`. Error: {err}\",\n                DebugReplacer { db }.replace_libfunc_id(&libfunc.id)));\n            chain!(\n                signature.param_signatures.into_iter().map(|param_signature| param_signature.ty),\n                signature\n                    .branch_signatures\n                    .into_iter()\n                    .flat_map(|info| info.vars)\n                    .map(|var| var.ty)\n            )\n        })\n        .collect()\n}\n\npub fn get_sierra_program_for_functions(\n    db: &dyn SierraGenGroup,\n    requested_function_ids: Vec<ConcreteFunctionWithBodyId>,\n) -> Maybe<Arc<cairo_lang_sierra::program::Program>> {\n    let mut functions: Vec<Arc<pre_sierra::Function>> = vec![];\n    let mut statements: Vec<pre_sierra::Statement> = vec![];\n    let mut processed_function_ids = UnorderedHashSet::<ConcreteFunctionWithBodyId>::default();\n    let mut function_id_queue: VecDeque<ConcreteFunctionWithBodyId> =\n        requested_function_ids.into_iter().collect();\n    while let Some(function_id) = function_id_queue.pop_front() {\n        if !processed_function_ids.insert(function_id) {\n            continue;\n        }\n        let function: Arc<pre_sierra::Function> = db.function_with_body_sierra(function_id)?;\n        functions.push(function.clone());\n        statements.extend_from_slice(&function.body[0..function.prolog_size]);\n        if !matches!(db.get_ap_change(function_id), Ok(SierraApChange::Known { .. })) {\n            // If AP change is unknown for the function, adding a disable so that AP balancing would\n            // not occur.\n            if function.body.get(function.prolog_size)\n                != Some(&simple_statement(revoke_ap_tracking_libfunc_id(db), &[], &[]))\n            {\n                statements.push(simple_statement(disable_ap_tracking_libfunc_id(db), &[], &[]));\n            }\n        }\n        statements.extend_from_slice(&function.body[function.prolog_size..]);\n        for statement in &function.body {\n            if let Ok(related_function_id) = try_get_function_with_body_id(db, statement) {\n                function_id_queue.push_back(related_function_id);\n            }\n        }\n    }\n\n    let libfunc_declarations =\n        generate_libfunc_declarations(db, collect_used_libfuncs(&statements).iter());\n    let type_declarations =\n        generate_type_declarations(db, collect_used_types(db, &libfunc_declarations).iter());\n    // Resolve labels.\n    let label_replacer = LabelReplacer::from_statements(&statements);\n    let resolved_statements = resolve_labels(statements, &label_replacer);\n\n    Ok(Arc::new(program::Program {\n        type_declarations,\n        libfunc_declarations,\n        statements: resolved_statements,\n        funcs: functions\n            .into_iter()\n            .map(|function| {\n                let sierra_signature = db.get_function_signature(function.id.clone()).unwrap();\n                program::Function::new(\n                    function.id.clone(),\n                    function.parameters.clone(),\n                    sierra_signature.ret_types.clone(),\n                    label_replacer.handle_label_id(function.entry_point),\n                )\n            })\n            .collect(),\n    }))\n}\n\n/// Tries extracting a ConcreteFunctionWithBodyId from a pre-Sierra statement.\nfn try_get_function_with_body_id(\n    db: &dyn SierraGenGroup,\n    statement: &pre_sierra::Statement,\n) -> Maybe<ConcreteFunctionWithBodyId> {\n    let invc = try_extract_matches!(\n        try_extract_matches!(statement, pre_sierra::Statement::Sierra).to_maybe()?,\n        program::GenStatement::Invocation\n    )\n    .to_maybe()?;\n    let libfunc = db.lookup_intern_concrete_lib_func(invc.libfunc_id.clone());\n    if libfunc.generic_id != \"function_call\".into() {\n        return Err(skip_diagnostic());\n    }\n    let function = db\n        .lookup_intern_function(\n            db.lookup_intern_sierra_function(\n                try_extract_matches!(\n                    libfunc.generic_args.get(0).to_maybe()?,\n                    cairo_lang_sierra::program::GenericArg::UserFunc\n                )\n                .to_maybe()?\n                .clone(),\n            ),\n        )\n        .function;\n    function.get_body(db.upcast())?.ok_or_else(skip_diagnostic)\n}\n\npub fn get_sierra_program(\n    db: &dyn SierraGenGroup,\n    requested_crate_ids: Vec<CrateId>,\n) -> Maybe<Arc<cairo_lang_sierra::program::Program>> {\n    let mut requested_function_ids = vec![];\n    for crate_id in requested_crate_ids {\n        for module_id in db.crate_modules(crate_id).iter() {\n            for (free_func_id, _) in db.module_free_functions(*module_id)? {\n                // TODO(spapini): Search Impl functions.\n                if let Some(function) =\n                    ConcreteFunctionWithBodyId::from_no_generics_free(db.upcast(), free_func_id)\n                {\n                    requested_function_ids.push(function)\n                }\n            }\n        }\n    }\n    db.get_sierra_program_for_functions(requested_function_ids)\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_defs::db::DefsGroup;\nuse cairo_lang_defs::ids::ModuleItemId;\nuse cairo_lang_semantic::db::SemanticGroup;\nuse cairo_lang_semantic::ConcreteFunctionWithBodyId;\nuse cairo_lang_utils::try_extract_matches;\nuse indoc::indoc;\nuse itertools::Itertools;\nuse pretty_assertions::assert_eq;\nuse test_case::test_case;\nuse test_log::test;\n\nuse crate::db::SierraGenGroup;\nuse crate::replace_ids::replace_sierra_ids_in_program;\nuse crate::test_utils::{checked_compile_to_sierra, setup_db_and_get_crate_id};\n\n#[test]\nfn test_program_generator() {\n    // TODO(lior): Make bar return something like felt252_add(5, bar()).\n    let program = checked_compile_to_sierra(indoc! {\"\n                fn foo(a: felt252) -> felt252 {\n                    bar(5)\n                }\n\n                fn bar(a: felt252) -> felt252 {\n                    felt252_add(felt252_add(a, a), a)\n                }\n            \"});\n\n    // TODO(lior): Remove the unnecessary store_temp()s at the end.\n    assert_eq!(\n        program.to_string(),\n        indoc! {\"\n            type felt252 = felt252;\n\n            libfunc drop<felt252> = drop<felt252>;\n            libfunc felt252_const<5> = felt252_const<5>;\n            libfunc store_temp<felt252> = store_temp<felt252>;\n            libfunc function_call<user@test::bar> = function_call<user@test::bar>;\n            libfunc rename<felt252> = rename<felt252>;\n            libfunc dup<felt252> = dup<felt252>;\n            libfunc felt252_add = felt252_add;\n\n            drop<felt252>([0]) -> ();\n            felt252_const<5>() -> ([1]);\n            store_temp<felt252>([1]) -> ([3]);\n            function_call<user@test::bar>([3]) -> ([2]);\n            rename<felt252>([2]) -> ([4]);\n            return([4]);\n            dup<felt252>([0]) -> ([0], [2]);\n            dup<felt252>([0]) -> ([0], [3]);\n            felt252_add([2], [3]) -> ([1]);\n            store_temp<felt252>([1]) -> ([1]);\n            felt252_add([1], [0]) -> ([4]);\n            store_temp<felt252>([4]) -> ([5]);\n            return([5]);\n\n            test::foo@0([0]: felt252) -> (felt252);\n            test::bar@6([0]: felt252) -> (felt252);\n        \"},\n    );\n}\n\n#[test]\nfn test_type_dependency() {\n    let program = checked_compile_to_sierra(indoc! {\"\n                use box::BoxTrait;\n                fn unbox_twice(a: Box::<Box::<Box::<felt252>>>) -> Box::<felt252> {\n                    a.unbox().unbox()\n                }\n            \"});\n\n    assert_eq!(\n        program.to_string(),\n        indoc! {\"\n            type felt252 = felt252;\n            type Box<felt252> = Box<felt252>;\n            type Box<Box<felt252>> = Box<Box<felt252>>;\n            type Box<Box<Box<felt252>>> = Box<Box<Box<felt252>>>;\n\n            libfunc unbox<Box<Box<felt252>>> = unbox<Box<Box<felt252>>>;\n            libfunc store_temp<Box<Box<felt252>>> = store_temp<Box<Box<felt252>>>;\n            libfunc unbox<Box<felt252>> = unbox<Box<felt252>>;\n            libfunc store_temp<Box<felt252>> = store_temp<Box<felt252>>;\n\n            unbox<Box<Box<felt252>>>([0]) -> ([1]);\n            store_temp<Box<Box<felt252>>>([1]) -> ([1]);\n            unbox<Box<felt252>>([1]) -> ([2]);\n            store_temp<Box<felt252>>([2]) -> ([3]);\n            return([3]);\n\n            test::unbox_twice@0([0]: Box<Box<Box<felt252>>>) -> (Box<felt252>);\n        \"},\n    );\n}\n\n#[test_case(\n    \"f1\",\n    &[\n        \"test::f1\", \"test::f2\", \"test::f3\",\n        \"test::f4\", \"test::f5\", \"test::f6\",\n    ];\n    \"finds all\"\n)]\n#[test_case(\n    \"f2\",\n    &[\n        \"test::f2\", \"test::f3\", \"test::f4\", \"test::f5\", \"test::f6\",\n    ];\n    \"all but first\"\n)]\n#[test_case(\"f3\", &[\"test::f3\", \"test::f5\", \"test::f6\"]; \"f3 -> f5 -> f6\")]\n#[test_case(\"f4\", &[\"test::f4\", \"test::f5\", \"test::f6\"]; \"f4 -> (f5 -> f6, f6)\")]\n#[test_case(\"f5\", &[\"test::f5\", \"test::f6\"]; \"f5 -> f6\")]\n#[test_case(\"f6\", &[\"test::f6\"]; \"self loop\")]\nfn test_only_include_dependecies(func_name: &str, sierra_used_funcs: &[&str]) {\n    let (db, crate_id) = setup_db_and_get_crate_id(indoc! {\"\n        fn f1() { f2(); f3(); }\n        fn f2() { f3(); f4(); f5(); }\n        fn f3() { f5(); }\n        fn f4() { f5(); f6(); }\n        fn f5() { f6(); }\n        fn f6() { f6(); }\n    \"});\n    let func_id = ConcreteFunctionWithBodyId::from_no_generics_free(\n        &db,\n        db.crate_modules(crate_id)\n            .iter()\n            .find_map(|module_id| {\n                try_extract_matches!(\n                    db.module_item_by_name(*module_id, func_name.into()).unwrap().unwrap(),\n                    ModuleItemId::FreeFunction\n                )\n            })\n            .unwrap(),\n    )\n    .unwrap();\n    let program = db.get_sierra_program_for_functions(vec![func_id]).unwrap();\n    assert_eq!(\n        replace_sierra_ids_in_program(&db, &program)\n            .funcs\n            .into_iter()\n            .map(|f| f.id.to_string())\n            .collect_vec(),\n        sierra_used_funcs\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_debug::DebugWithDb;\nuse cairo_lang_sierra::program;\nuse cairo_lang_utils::extract_matches;\n\nuse crate::db::SierraGenGroup;\nuse crate::pre_sierra::{self, PushValue};\n\npub trait SierraIdReplacer {\n    /// Returns a new program where all the ids are replaced.\n    fn apply(\n        &self,\n        program: &cairo_lang_sierra::program::Program,\n    ) -> cairo_lang_sierra::program::Program {\n        let mut program = program.clone();\n        for statement in &mut program.statements {\n            if let cairo_lang_sierra::program::GenStatement::Invocation(p) = statement {\n                p.libfunc_id = self.replace_libfunc_id(&p.libfunc_id);\n            }\n        }\n        for type_declaration in &mut program.type_declarations {\n            type_declaration.id = self.replace_type_id(&type_declaration.id);\n            self.replace_generic_args(&mut type_declaration.long_id.generic_args);\n        }\n        for libfunc_declaration in &mut program.libfunc_declarations {\n            libfunc_declaration.id = self.replace_libfunc_id(&libfunc_declaration.id);\n            self.replace_generic_args(&mut libfunc_declaration.long_id.generic_args);\n        }\n        for function in &mut program.funcs {\n            function.id = self.replace_function_id(&function.id);\n            for param in &mut function.params {\n                param.ty = self.replace_type_id(&param.ty);\n            }\n            for ty in &mut function.signature.ret_types {\n                *ty = self.replace_type_id(ty);\n            }\n            for ty in &mut function.signature.param_types {\n                *ty = self.replace_type_id(ty);\n            }\n        }\n        program\n    }\n\n    // Replaces libfunc_ids\n    fn replace_libfunc_id(\n        &self,\n        id: &cairo_lang_sierra::ids::ConcreteLibfuncId,\n    ) -> cairo_lang_sierra::ids::ConcreteLibfuncId;\n\n    // Replace type_ids\n    fn replace_type_id(\n        &self,\n        id: &cairo_lang_sierra::ids::ConcreteTypeId,\n    ) -> cairo_lang_sierra::ids::ConcreteTypeId;\n\n    // Replace user function ids.\n    fn replace_function_id(\n        &self,\n        sierra_id: &cairo_lang_sierra::ids::FunctionId,\n    ) -> cairo_lang_sierra::ids::FunctionId;\n\n    fn replace_generic_args(&self, generic_args: &mut Vec<program::GenericArg>) {\n        for arg in generic_args {\n            match arg {\n                program::GenericArg::Type(id) => {\n                    *id = self.replace_type_id(id);\n                }\n                program::GenericArg::UserFunc(id) => {\n                    *id = self.replace_function_id(id);\n                }\n                program::GenericArg::Libfunc(id) => {\n                    *id = self.replace_libfunc_id(id);\n                }\n                program::GenericArg::Value(_) | program::GenericArg::UserType(_) => {}\n            }\n        }\n    }\n}\n\n/// Replaces `cairo_lang_sierra::ids::{ConcreteLibfuncId, ConcreteTypeId, FunctionId}` with a dummy\n/// ids whose debug string is the string representing the expanded information about the id.\n/// For Libfuncs and Types - that would be recursively opening their generic arguments, for\n/// functions - that would be getting their original name. For example, while the original debug\n/// string may be `[6]`, the resulting debug string may be:\n///  - For libfuncs: `felt252_const<2>` or `unbox<Box<Box<felt252>>>`.\n///  - For types: `felt252` or `Box<Box<felt252>>`.\n///  - For user functions: `test::foo`.\npub struct DebugReplacer<'a> {\n    pub db: &'a dyn SierraGenGroup,\n}\nimpl SierraIdReplacer for DebugReplacer<'_> {\n    fn replace_libfunc_id(\n        &self,\n        id: &cairo_lang_sierra::ids::ConcreteLibfuncId,\n    ) -> cairo_lang_sierra::ids::ConcreteLibfuncId {\n        let mut long_id = self.db.lookup_intern_concrete_lib_func(id.clone());\n        self.replace_generic_args(&mut long_id.generic_args);\n        cairo_lang_sierra::ids::ConcreteLibfuncId {\n            id: id.id,\n            debug_name: Some(long_id.to_string().into()),\n        }\n    }\n\n    fn replace_type_id(\n        &self,\n        id: &cairo_lang_sierra::ids::ConcreteTypeId,\n    ) -> cairo_lang_sierra::ids::ConcreteTypeId {\n        let mut long_id = self.db.lookup_intern_concrete_type(id.clone());\n        self.replace_generic_args(&mut long_id.generic_args);\n        if long_id.generic_id == \"Enum\".into() || long_id.generic_id == \"Struct\".into() {\n            long_id.generic_id =\n                extract_matches!(&long_id.generic_args[0], program::GenericArg::UserType)\n                    .to_string()\n                    .into();\n            if long_id.generic_id == \"Tuple\".into() {\n                long_id.generic_args = long_id.generic_args.into_iter().skip(1).collect();\n                if long_id.generic_args.is_empty() {\n                    long_id.generic_id = \"Unit\".into();\n                }\n            } else {\n                long_id.generic_args.clear();\n            }\n        }\n        cairo_lang_sierra::ids::ConcreteTypeId {\n            id: id.id,\n            debug_name: Some(long_id.to_string().into()),\n        }\n    }\n\n    /// Helper for [replace_sierra_ids] and [replace_sierra_ids_in_program] replacing function ids.\n    fn replace_function_id(\n        &self,\n        sierra_id: &cairo_lang_sierra::ids::FunctionId,\n    ) -> cairo_lang_sierra::ids::FunctionId {\n        let semantic_id = self.db.lookup_intern_sierra_function(sierra_id.clone());\n        cairo_lang_sierra::ids::FunctionId {\n            id: sierra_id.id,\n            debug_name: Some(\n                format!(\n                    \"{:?}\",\n                    self.db.lookup_intern_function(semantic_id).debug(self.db.upcast())\n                )\n                .into(),\n            ),\n        }\n    }\n}\n\npub fn replace_sierra_ids(\n    db: &dyn SierraGenGroup,\n    statement: &pre_sierra::Statement,\n) -> pre_sierra::Statement {\n    let replacer = DebugReplacer { db };\n    match statement {\n        pre_sierra::Statement::Sierra(cairo_lang_sierra::program::GenStatement::Invocation(p)) => {\n            pre_sierra::Statement::Sierra(cairo_lang_sierra::program::GenStatement::Invocation(\n                cairo_lang_sierra::program::GenInvocation {\n                    libfunc_id: replacer.replace_libfunc_id(&p.libfunc_id),\n                    ..p.clone()\n                },\n            ))\n        }\n        pre_sierra::Statement::PushValues(values) => pre_sierra::Statement::PushValues(\n            values\n                .iter()\n                .map(|value| PushValue { ty: replacer.replace_type_id(&value.ty), ..value.clone() })\n                .collect(),\n        ),\n        _ => statement.clone(),\n    }\n}\n\n/// Replaces `cairo_lang_sierra::ids::{ConcreteLibfuncId, ConcreteTypeId, FunctionId}` with a dummy\n/// ids whose debug string is the string representing the expanded information about the id.\n/// For Libfuncs and Types - that would be recursively opening their generic arguments, for\n/// functions - that would be getting their original name. For example, while the original debug\n/// string may be `[6]`, the resulting debug string may be:\n///  - For libfuncs: `felt252_const<2>` or `unbox<Box<Box<felt252>>>`.\n///  - For types: `felt252` or `Box<Box<felt252>>`.\n///  - For user functions: `test::foo`.\n///\n/// Similar to [replace_sierra_ids] except that it acts on [cairo_lang_sierra::program::Program].\npub fn replace_sierra_ids_in_program(\n    db: &dyn SierraGenGroup,\n    program: &cairo_lang_sierra::program::Program,\n) -> cairo_lang_sierra::program::Program {\n    DebugReplacer { db }.apply(program)\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "#[cfg(test)]\n#[path = \"resolve_labels_test.rs\"]\nmod test;\n\nuse cairo_lang_sierra::program;\n\nuse crate::next_statement_index_fetch::NextStatementIndexFetch;\nuse crate::pre_sierra;\n\n/// Replaces labels with their corresponding StatementIdx.\npub fn resolve_labels(\n    statements: Vec<pre_sierra::Statement>,\n    label_replacer: &LabelReplacer,\n) -> Vec<program::Statement> {\n    statements\n        .into_iter()\n        .filter_map(|statement| match statement {\n            pre_sierra::Statement::Sierra(sierra_statement) => {\n                Some(label_replacer.handle_statement(sierra_statement))\n            }\n            pre_sierra::Statement::Label(_) => None,\n            pre_sierra::Statement::PushValues(_) => {\n                panic!(\"Unexpected pre_sierra::Statement::PushValues in resolve_labels().\")\n            }\n        })\n        .collect()\n}\n\n/// Helper struct for resolve_labels.\npub struct LabelReplacer {\n    next_statement_index_fetch: NextStatementIndexFetch,\n}\nimpl LabelReplacer {\n    pub fn from_statements(statements: &[pre_sierra::Statement]) -> LabelReplacer {\n        Self { next_statement_index_fetch: NextStatementIndexFetch::new(statements, false) }\n    }\n\n    /// Replaces the pre-sierra labels in the given statement, and returns [program::Statement].\n    fn handle_statement(\n        &self,\n        statement: program::GenStatement<pre_sierra::LabelId>,\n    ) -> program::Statement {\n        match statement {\n            program::GenStatement::Invocation(invocation) => {\n                program::Statement::Invocation(self.handle_invocation(invocation))\n            }\n            program::GenStatement::Return(statement) => program::Statement::Return(statement),\n        }\n    }\n\n    /// Replaces the pre-sierra labels in the given invocation, and returns [program::Invocation].\n    fn handle_invocation(\n        &self,\n        invocation: program::GenInvocation<pre_sierra::LabelId>,\n    ) -> program::Invocation {\n        program::Invocation {\n            libfunc_id: invocation.libfunc_id,\n            args: invocation.args,\n            branches: invocation\n                .branches\n                .into_iter()\n                .map(|branch_info| self.handle_branch_info(branch_info))\n                .collect(),\n        }\n    }\n\n    /// Replaces the pre-sierra labels in the given branch info, and returns [program::BranchInfo].\n    fn handle_branch_info(\n        &self,\n        branch_info: program::GenBranchInfo<pre_sierra::LabelId>,\n    ) -> program::BranchInfo {\n        program::BranchInfo {\n            target: self.handle_branch_target(branch_info.target),\n            results: branch_info.results,\n        }\n    }\n\n    /// Replaces the pre-sierra labels in the given branch target, and returns\n    /// [program::BranchTarget].\n    fn handle_branch_target(\n        &self,\n        branch_target: program::GenBranchTarget<pre_sierra::LabelId>,\n    ) -> program::BranchTarget {\n        match branch_target {\n            program::GenBranchTarget::Fallthrough => program::GenBranchTarget::Fallthrough,\n            program::GenBranchTarget::Statement(label_id) => {\n                program::BranchTarget::Statement(self.handle_label_id(label_id))\n            }\n        }\n    }\n\n    /// Resolves the given pre-sierra label, and returns [program::StatementIdx].\n    pub fn handle_label_id(&self, label_id: pre_sierra::LabelId) -> program::StatementIdx {\n        program::StatementIdx(self.next_statement_index_fetch.resolve_label(&label_id))\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_sierra::ids::ConcreteLibfuncId;\nuse pretty_assertions::assert_eq;\nuse salsa::{InternId, InternKey};\nuse test_log::test;\n\nuse super::resolve_labels;\nuse crate::pre_sierra;\nuse crate::resolve_labels::LabelReplacer;\nuse crate::utils::{jump_statement, simple_statement};\n\nfn label(id: usize) -> pre_sierra::Statement {\n    pre_sierra::Statement::Label(pre_sierra::Label {\n        id: pre_sierra::LabelId::from_intern_id(InternId::from(id)),\n    })\n}\n\nfn jump(id: usize) -> pre_sierra::Statement {\n    jump_statement(\n        ConcreteLibfuncId::from_string(\"jump\"),\n        pre_sierra::LabelId::from_intern_id(InternId::from(id)),\n    )\n}\n\n#[test]\nfn test_resolve_labels() {\n    let statements: Vec<pre_sierra::Statement> = vec![\n        label(7),\n        label(5),\n        simple_statement(ConcreteLibfuncId::from_string(\"Instruction0\"), &[], &[]),\n        simple_statement(ConcreteLibfuncId::from_string(\"Instruction1\"), &[], &[]),\n        jump(8),\n        jump(7),\n        label(0),\n        jump(7),\n        jump(5),\n        simple_statement(ConcreteLibfuncId::from_string(\"Instruction2\"), &[], &[]),\n        jump(0),\n        label(8),\n        jump(8),\n        jump(9),\n        // Note: this label does not point to an actual instruction.\n        label(9),\n    ];\n    let label_replacer = LabelReplacer::from_statements(&statements);\n    assert_eq!(\n        resolve_labels(statements, &label_replacer)\n            .iter()\n            .map(|x| format!(\"{x}\"))\n            .collect::<Vec<String>>(),\n        vec![\n            // labels 7 and 5 (instruction index 0).\n            \"Instruction0() -> ()\",\n            \"Instruction1() -> ()\",\n            \"jump() { 8() }\",\n            \"jump() { 0() }\",\n            // label 0 (instruction index 5).\n            \"jump() { 0() }\",\n            \"jump() { 0() }\",\n            \"Instruction2() -> ()\",\n            \"jump() { 4() }\",\n            // label 8 (instruction index 8).\n            \"jump() { 8() }\",\n            \"jump() { 10() }\",\n            // label 9 (instruction index 10).\n        ]\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_diagnostics::ToOption;\nuse cairo_lang_sierra::extensions::lib_func::{SierraApChange, SignatureSpecializationContext};\nuse cairo_lang_sierra::extensions::type_specialization_context::TypeSpecializationContext;\nuse cairo_lang_sierra::program::ConcreteTypeLongId;\n\nuse crate::db::SierraGenGroup;\n\n/// A wrapper over the [SierraGenGroup] salsa database, that provides the\n/// [SignatureSpecializationContext] functionality.\n/// In particular, it can be used when calling\n/// [specialize_signature_by_id](cairo_lang_sierra::extensions::lib_func::GenericLibfuncEx::specialize_signature_by_id).\npub struct SierraSignatureSpecializationContext<'a>(pub &'a dyn SierraGenGroup);\n\nimpl TypeSpecializationContext for SierraSignatureSpecializationContext<'_> {\n    fn try_get_type_info(\n        &self,\n        id: cairo_lang_sierra::ids::ConcreteTypeId,\n    ) -> Option<cairo_lang_sierra::extensions::types::TypeInfo> {\n        self.0.get_type_info(id).map(|info| (*info).clone()).to_option()\n    }\n}\nimpl SignatureSpecializationContext for SierraSignatureSpecializationContext<'_> {\n    fn try_get_concrete_type(\n        &self,\n        id: cairo_lang_sierra::ids::GenericTypeId,\n        generic_args: &[cairo_lang_sierra::program::GenericArg],\n    ) -> Option<cairo_lang_sierra::ids::ConcreteTypeId> {\n        Some(self.0.intern_concrete_type(ConcreteTypeLongId {\n            generic_id: id,\n            generic_args: generic_args.to_vec(),\n        }))\n    }\n\n    fn try_get_function_signature(\n        &self,\n        function_id: &cairo_lang_sierra::ids::FunctionId,\n    ) -> Option<cairo_lang_sierra::program::FunctionSignature> {\n        self.0\n            .get_function_signature(function_id.clone())\n            .map(|signature| (*signature).clone())\n            .to_option()\n    }\n\n    fn as_type_specialization_context(&self) -> &dyn TypeSpecializationContext {\n        self\n    }\n\n    fn try_get_function_ap_change(\n        &self,\n        function_id: &cairo_lang_sierra::ids::FunctionId,\n    ) -> Option<SierraApChange> {\n        let concrete_function = self\n            .0\n            .lookup_intern_function(self.0.lookup_intern_sierra_function(function_id.clone()))\n            .function;\n        let function = concrete_function.get_body(self.0.upcast()).unwrap_or_default().expect(\n            \"Internal compiler error: get_function_ap_change() should only be used for user \\\n             defined functions.\",\n        );\n        self.0.get_ap_change(function).to_option()\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "#[cfg(test)]\n#[path = \"known_stack_test.rs\"]\nmod test;\n\nuse std::cmp::max;\n\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse cairo_lang_utils::unordered_hash_set::UnorderedHashSet;\n\nuse crate::pre_sierra;\n\n/// Represents the information known about the top of the stack at a given point in the code.\n#[derive(Clone, Debug, Default, Eq, PartialEq)]\npub struct KnownStack {\n    /// A map from [cairo_lang_sierra::ids::VarId] of variables that are located on the stack\n    /// (e.g., `[ap - 2]`) to their index on the stack, relative to `offset`.\n    ///\n    /// A variable with index `i` is at the (`offset-i`)-th slot from the top of the stack.\n    /// In particular, the top element has `i = offset - 1`.\n    variables_on_stack: OrderedHashMap<cairo_lang_sierra::ids::VarId, usize>,\n    offset: usize,\n}\nimpl KnownStack {\n    /// Clears the known information about the stack.\n    ///\n    /// This is called where the change in the value of `ap` is not known at compile time.\n    pub fn clear(&mut self) {\n        self.offset = 0;\n        self.variables_on_stack.clear();\n    }\n\n    /// Marks that the given variable appears on slot `idx` of the stack (note that `0` here means\n    /// that the address is `ap`, and other indices will have larger addresses).\n    pub fn insert(&mut self, var: cairo_lang_sierra::ids::VarId, idx: usize) {\n        self.insert_signed(var, idx.try_into().unwrap())\n    }\n\n    /// Same as [Self::insert], except that `idx` is `isize`.\n    pub fn insert_signed(&mut self, var: cairo_lang_sierra::ids::VarId, idx: isize) {\n        let ioffset: isize = self.offset.try_into().unwrap();\n        self.variables_on_stack.insert(var, (ioffset + idx).try_into().unwrap());\n    }\n\n    /// Returns the slot `idx` of the stack in which the given variable appears, or `None` if it is\n    /// not on the known stack.\n    pub fn get(&mut self, var: &cairo_lang_sierra::ids::VarId) -> Option<isize> {\n        let ioffset: isize = self.offset.try_into().unwrap();\n        let val: isize = (*self.variables_on_stack.get(var)?).try_into().unwrap();\n        Some(val - ioffset)\n    }\n\n    /// Adds a value to the top of the stack, and advances `ap` accordingly (more precisely,\n    /// `offset` is advanced by 1).\n    pub fn push(&mut self, var: &cairo_lang_sierra::ids::VarId) {\n        self.insert(var.clone(), 0);\n        self.offset += 1;\n    }\n\n    /// If `src` is on the known stack, marks `dst` as located in the same cell.\n    pub fn clone_if_on_stack(\n        &mut self,\n        src: &cairo_lang_sierra::ids::VarId,\n        dst: &cairo_lang_sierra::ids::VarId,\n    ) {\n        if let Some(index_on_stack) = self.variables_on_stack.get(src).cloned() {\n            self.variables_on_stack.insert(dst.clone(), index_on_stack);\n        }\n    }\n\n    /// Updates offset according to the maximal index in `variables_on_stack`.\n    /// This is the expected behavior after invoking a libfunc.\n    pub fn update_offset_by_max(&mut self) {\n        // `offset` is one more than the maximum of the indices in `variables_on_stack`\n        // (or 0 if empty).\n        self.offset = self.variables_on_stack.values().max().map(|idx| idx + 1).unwrap_or(0);\n    }\n\n    /// Removes the information known about the given variable.\n    pub fn remove_variable(&mut self, var: &cairo_lang_sierra::ids::VarId) {\n        self.variables_on_stack.swap_remove(var);\n    }\n\n    // Checks if there exists a prefix of `push_values`, that is already on the top of the stack.\n    // Returns the prefix size if exists, and 0 otherwise.\n    pub fn compute_on_stack_prefix_size(&self, push_values: &[pre_sierra::PushValue]) -> usize {\n        if let Some(index_on_stack) = self.variables_on_stack.get(&push_values[0].var) {\n            // Compute the prefix size, if exists.\n            let prefix_size = self.offset - index_on_stack;\n            if prefix_size > push_values.len() {\n                return 0;\n            }\n            // Check if this is indeed a prefix.\n            let is_prefix = (1..prefix_size).all(|i| {\n                self.variables_on_stack.get(&push_values[i].var).cloned()\n                    == Some(index_on_stack + i)\n            });\n            if is_prefix {\n                return prefix_size;\n            }\n        }\n        0\n    }\n\n    /// Merges two stacks.\n    ///\n    /// If a variable appears in both stacks in the same place (relative to the top of the two\n    /// stacks), it will appear in the new stack.\n    /// The resulting stack must be continuous (otherwise, one also needs to check that the sizes of\n    /// the \"holes\" are identical).\n    ///\n    /// For example, merging the stacks [0, 1, 2, 3, 4] and [1, 9, 3, 4] (where the last element in\n    /// the top) will yield [3, 4] (1 will not be included because of the hole).\n    #[allow(dead_code)]\n    pub fn merge_with(&self, other: &Self) -> Self {\n        // Choose the new offset to be the maximum of the input offsets. This is somewhat arbitrary.\n        let new_offset = max(self.offset, other.offset);\n\n        // Prepare a list of indices that may appear in the merged stack, relative to the top of the\n        // stack. Here, `1` means the top element.\n        let mut indices = UnorderedHashSet::<usize>::default();\n        // Prepares a temporary map of variables. This map will later be filtered when the actual\n        // size of the merged stack is known.\n        let mut tmp_variables_on_stack =\n            OrderedHashMap::<cairo_lang_sierra::ids::VarId, usize>::default();\n        for (var, self_index) in self.variables_on_stack.iter() {\n            if let Some(other_index) = other.variables_on_stack.get(var) {\n                assert!(\n                    *self_index < self.offset,\n                    \"Stack index ({self_index}) must be < offset ({})\",\n                    self.offset\n                );\n                let self_rel = self.offset - self_index;\n\n                assert!(\n                    *other_index < other.offset,\n                    \"Stack index ({other_index}) must be < offset ({})\",\n                    other.offset\n                );\n                let other_rel = other.offset - other_index;\n\n                if self_rel == other_rel {\n                    indices.insert(self_rel);\n                    tmp_variables_on_stack.insert(var.clone(), new_offset - self_rel);\n                }\n            }\n        }\n\n        // Find the longest continuous common suffix.\n        let suffix_size = if let Some(suffix_size) =\n            (0..new_offset + 1).find(|index| !indices.contains(&(index + 1)))\n        {\n            suffix_size\n        } else {\n            panic!(\"Internal compiler error.\");\n        };\n\n        KnownStack {\n            variables_on_stack: tmp_variables_on_stack\n                .into_iter()\n                .filter(|(_var, index)| new_offset - index <= suffix_size)\n                .collect(),\n            offset: new_offset,\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_utils::unordered_hash_set::UnorderedHashSet;\nuse pretty_assertions::assert_eq;\nuse test_log::test;\n\nuse super::KnownStack;\n\n/// Creates a [KnownStack] object that contains the given vars at the top (the last variable is the\n/// topmost one).\nfn dummy_stack(vars: &[u64]) -> KnownStack {\n    let variables_on_stack =\n        vars.iter().enumerate().map(|(i, x)| (cairo_lang_sierra::ids::VarId::new(*x), i)).collect();\n    KnownStack { variables_on_stack, offset: vars.len() }\n}\n\nfn assert_eq_stacks(a: &KnownStack, b: &KnownStack) {\n    // Make sure both stacks have the same set of variables.\n    assert_eq!(\n        a.variables_on_stack.keys().collect::<UnorderedHashSet<_>>(),\n        b.variables_on_stack.keys().collect::<UnorderedHashSet<_>>()\n    );\n    for (var, a_index) in a.variables_on_stack.iter() {\n        assert_eq!(\n            a.offset - *a_index,\n            b.offset - b.variables_on_stack[var.clone()],\n            \"Wrong value found for {var}.\\na: {a:?}\\nb: {b:?}\"\n        );\n    }\n}\n\n#[test]\nfn merge_stacks() {\n    // Same stack.\n    let a = dummy_stack(&[0, 1, 2, 3]);\n    let b = dummy_stack(&[0, 1, 2, 3]);\n    let res = dummy_stack(&[0, 1, 2, 3]);\n    assert_eq_stacks(&a.merge_with(&b), &res);\n    assert_eq_stacks(&b.merge_with(&a), &res);\n\n    // Prefix stack.\n    let a = dummy_stack(&[0, 1, 2, 3]);\n    let b = dummy_stack(&[2, 3]);\n    let res = dummy_stack(&[2, 3]);\n    assert_eq_stacks(&a.merge_with(&b), &res);\n    assert_eq_stacks(&b.merge_with(&a), &res);\n\n    // Inconsistent stacks.\n    let a = dummy_stack(&[0, 1, 2]);\n    let b = dummy_stack(&[0, 1, 3]);\n    let res = dummy_stack(&[]);\n    assert_eq_stacks(&a.merge_with(&b), &res);\n    assert_eq_stacks(&b.merge_with(&a), &res);\n\n    let a = dummy_stack(&[0, 1, 2, 3]);\n    let b = dummy_stack(&[0, 1, 2]);\n    let res = dummy_stack(&[]);\n    assert_eq_stacks(&a.merge_with(&b), &res);\n    assert_eq_stacks(&b.merge_with(&a), &res);\n\n    // Generic.\n    let a = dummy_stack(&[0, 1, 2, 3]);\n    let b = dummy_stack(&[4, 2, 3]);\n    let res = dummy_stack(&[2, 3]);\n    assert_eq_stacks(&a.merge_with(&b), &res);\n    assert_eq_stacks(&b.merge_with(&a), &res);\n\n    // \"Holes\" (e.g., the first item is consistent, but the second is not).\n    let a = dummy_stack(&[0, 1, 2, 3]);\n    let b = dummy_stack(&[0, 4, 2, 3]);\n    let res = dummy_stack(&[2, 3]);\n    assert_eq_stacks(&a.merge_with(&b), &res);\n    assert_eq_stacks(&b.merge_with(&a), &res);\n\n    let a = dummy_stack(&[0, 1, 2, 3]);\n    let b = dummy_stack(&[0, 1, 4, 3]);\n    let res = dummy_stack(&[3]);\n    assert_eq_stacks(&a.merge_with(&b), &res);\n    assert_eq_stacks(&b.merge_with(&a), &res);\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Handles the automatic addition of store_temp() and store_local() statements.\n\nmod known_stack;\nmod state;\n\n#[cfg(test)]\nmod test;\n\nuse cairo_lang_sierra as sierra;\nuse cairo_lang_sierra::extensions::lib_func::{LibfuncSignature, ParamSignature, SierraApChange};\nuse cairo_lang_sierra::ids::ConcreteLibfuncId;\nuse cairo_lang_sierra::program::{GenBranchInfo, GenBranchTarget, GenStatement};\nuse cairo_lang_utils::extract_matches;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse itertools::zip_eq;\nuse state::{merge_optional_states, State};\n\nuse self::state::{DeferredVariableInfo, DeferredVariableKind};\nuse crate::db::SierraGenGroup;\nuse crate::pre_sierra;\nuse crate::store_variables::known_stack::KnownStack;\nuse crate::utils::{\n    dup_libfunc_id, rename_libfunc_id, simple_statement, store_local_libfunc_id,\n    store_temp_libfunc_id,\n};\n\n/// A map from variables that should be stored as local to their allocated\n/// space.\npub type LocalVariables = OrderedHashMap<sierra::ids::VarId, sierra::ids::VarId>;\n\n/// Information about a libfunc, required by the `store_variables` module.\npub struct LibfuncInfo {\n    pub signature: LibfuncSignature,\n}\n\n/// Automatically adds store_temp() statements to the given list of [pre_sierra::Statement].\n/// For example, a deferred reference (e.g., `[ap] + [fp - 3]`) needs to be stored as a temporary\n/// or local variable before being included in additional computation.\n/// The function will add the necessary `store_temp()` instruction before the first use of the\n/// deferred reference.\n///\n/// `local_variables` is a map from variables that should be stored as local to their allocated\n/// space.\npub fn add_store_statements<GetLibfuncSignature>(\n    db: &dyn SierraGenGroup,\n    statements: Vec<pre_sierra::Statement>,\n    get_lib_func_signature: &GetLibfuncSignature,\n    local_variables: LocalVariables,\n) -> Vec<pre_sierra::Statement>\nwhere\n    GetLibfuncSignature: Fn(ConcreteLibfuncId) -> LibfuncInfo,\n{\n    let mut handler = AddStoreVariableStatements::new(db, local_variables);\n    // Go over the statements, restarting whenever we see a branch or a label.\n    for statement in statements.into_iter() {\n        handler.handle_statement(statement, get_lib_func_signature);\n    }\n    handler.finalize()\n}\n\nstruct AddStoreVariableStatements<'a> {\n    db: &'a dyn SierraGenGroup,\n    local_variables: LocalVariables,\n    /// A list of output statements (the original statement, together with the added statements,\n    /// such as \"store_temp\").\n    result: Vec<pre_sierra::Statement>,\n    /// The current information known about the state of the variables. None means the statement is\n    /// not reachable from the previous statement.\n    state_opt: Option<State>,\n    /// A map from [LabelId](pre_sierra::LabelId) to the known state (so far).\n    ///\n    /// For every branch that does not continue to the next statement, the current known state is\n    /// added to the map. When the label is visited, it is merged with the known state, and removed\n    /// from the map.\n    future_states: OrderedHashMap<pre_sierra::LabelId, State>,\n}\nimpl<'a> AddStoreVariableStatements<'a> {\n    /// Constructs a new [AddStoreVariableStatements] object.\n    fn new(db: &'a dyn SierraGenGroup, local_variables: LocalVariables) -> Self {\n        AddStoreVariableStatements {\n            db,\n            local_variables,\n            result: Vec::new(),\n            state_opt: Some(State::default()),\n            future_states: OrderedHashMap::default(),\n        }\n    }\n\n    /// Handles a single statement, including adding required store statements and the statement\n    /// itself.\n    fn handle_statement<GetLibfuncInfo>(\n        &mut self,\n        statement: pre_sierra::Statement,\n        get_lib_func_signature: &GetLibfuncInfo,\n    ) where\n        GetLibfuncInfo: Fn(ConcreteLibfuncId) -> LibfuncInfo,\n    {\n        match &statement {\n            pre_sierra::Statement::Sierra(GenStatement::Invocation(invocation)) => {\n                let libfunc_info = get_lib_func_signature(invocation.libfunc_id.clone());\n                let signature = libfunc_info.signature;\n                let deferred_args =\n                    self.prepare_libfunc_arguments(&invocation.args, &signature.param_signatures);\n                match &invocation.branches[..] {\n                    [GenBranchInfo { target: GenBranchTarget::Fallthrough, results }] => {\n                        // A simple invocation.\n                        let branch_signature = &signature.branch_signatures[0];\n                        match branch_signature.ap_change {\n                            SierraApChange::Unknown => {\n                                // If the ap-change is unknown, variables that will be revoked\n                                // otherwise should be stored as locals.\n                                self.store_variables_as_locals();\n                            }\n                            SierraApChange::BranchAlign | SierraApChange::Known { .. } => {}\n                        }\n\n                        self.state().register_outputs(\n                            results,\n                            branch_signature,\n                            &invocation.args,\n                            &deferred_args,\n                        );\n                    }\n                    _ => {\n                        // This starts a branch. Store all deferred variables.\n                        if invocation.branches.len() > 1 {\n                            self.store_all_possibly_lost_variables();\n                            self.store_temporary_variables_as_locals();\n                        }\n\n                        // Go over the branches. The state of a branch that points to `Fallthrough`\n                        // is merged into `fallthrough_state`.\n                        let mut fallthrough_state: Option<State> = None;\n                        for (branch, branch_signature) in\n                            zip_eq(&invocation.branches, signature.branch_signatures)\n                        {\n                            let mut state_at_branch = self.state().clone();\n                            state_at_branch.register_outputs(\n                                &branch.results,\n                                &branch_signature,\n                                &invocation.args,\n                                &deferred_args,\n                            );\n\n                            self.add_future_state(\n                                &branch.target,\n                                state_at_branch,\n                                &mut fallthrough_state,\n                            );\n                        }\n                        self.state_opt = fallthrough_state;\n                    }\n                }\n                self.result.push(statement);\n            }\n            pre_sierra::Statement::Sierra(GenStatement::Return(_return_statement)) => {\n                self.result.push(statement);\n                // `return` statements are preceded by `PushValues` which takes care of pushing\n                // the return values onto the stack. The rest of the deferred variables are not\n                // needed.\n                self.clear_deffered_variables();\n                // The next statement is not reachable from this one. Set `state` to `None`.\n                self.state_opt = None;\n            }\n            pre_sierra::Statement::Label(pre_sierra::Label { id: label_id }) => {\n                // Merge self.known_stack with the future_stack that corresponds to the label, if\n                // any.\n                self.state_opt = merge_optional_states(\n                    std::mem::take(&mut self.state_opt),\n                    self.future_states.swap_remove(label_id),\n                );\n\n                self.result.push(statement);\n            }\n            pre_sierra::Statement::PushValues(push_values) => {\n                self.push_values(push_values);\n            }\n        }\n    }\n\n    /// Prepares the given `args` to be used as arguments for a libfunc.\n    ///\n    /// Returns a map from arguments' [sierra::ids::VarId] to [DeferredVariableInfo] for arguments\n    /// that have a deferred value after the function (that is, they were not stored as\n    /// temp/local by the function).\n    fn prepare_libfunc_arguments(\n        &mut self,\n        args: &[sierra::ids::VarId],\n        param_signatures: &[ParamSignature],\n    ) -> OrderedHashMap<sierra::ids::VarId, DeferredVariableInfo> {\n        let mut deferred_args =\n            OrderedHashMap::<sierra::ids::VarId, DeferredVariableInfo>::default();\n        for (arg, param_signature) in zip_eq(args, param_signatures) {\n            let (_, deferred) = self.prepare_libfunc_argument(\n                arg,\n                param_signature.allow_deferred,\n                param_signature.allow_add_const,\n                param_signature.allow_const,\n            );\n\n            if let Some(deferred) = deferred {\n                deferred_args.insert(arg.clone(), deferred);\n            }\n        }\n        deferred_args\n    }\n\n    /// Prepares the given `arg` to be used as an argument for a libfunc.\n    ///\n    /// Returns:\n    /// * whether the variable was copied to the stack.\n    /// * The [DeferredVariableInfo] if the variable has a deferred value after the function (that\n    ///   is, it was not stored as temp/local by the function).\n    fn prepare_libfunc_argument(\n        &mut self,\n        arg: &sierra::ids::VarId,\n        allow_deferred: bool,\n        allow_add_const: bool,\n        allow_const: bool,\n    ) -> (bool, Option<DeferredVariableInfo>) {\n        let mut res_deferred_info: Option<DeferredVariableInfo> = None;\n\n        if let Some(deferred_info) = self.state().deferred_variables.swap_remove(arg) {\n            match deferred_info.kind {\n                state::DeferredVariableKind::Const => {\n                    if !allow_const {\n                        return (self.store_deferred(arg, deferred_info), None);\n                    }\n                }\n                state::DeferredVariableKind::AddConst => {\n                    if !allow_add_const {\n                        return (self.store_deferred(arg, deferred_info), None);\n                    }\n                }\n                state::DeferredVariableKind::Generic => {\n                    if !allow_deferred {\n                        return (self.store_deferred(arg, deferred_info), None);\n                    }\n                }\n            };\n\n            res_deferred_info = Some(deferred_info);\n        }\n\n        if self.state().temporary_variables.get(arg).is_some() {\n            self.store_temp_as_local(arg);\n        }\n\n        (false, res_deferred_info)\n    }\n\n    /// Adds a store_temp() or store_local() instruction for the given deferred variable.\n    /// The variable should be removed from the `deferred_variables` map prior to this call.\n    ///\n    /// Returns `true` if the variable was copied to the stack.\n    fn store_deferred(\n        &mut self,\n        var: &sierra::ids::VarId,\n        deferred_info: DeferredVariableInfo,\n    ) -> bool {\n        self.store_deferred_ex(var, var, deferred_info)\n    }\n\n    /// Same as `store_deferred` only allows the `store_temp` case to use a different variable.\n    fn store_deferred_ex(\n        &mut self,\n        var: &sierra::ids::VarId,\n        var_on_stack: &sierra::ids::VarId,\n        deferred_info: DeferredVariableInfo,\n    ) -> bool {\n        // Check if this variable should be a local variable.\n        if let Some(uninitialized_local_var_id) = self.local_variables.get(var).cloned() {\n            self.store_local(var, &uninitialized_local_var_id, &deferred_info.ty);\n            false\n        } else {\n            self.store_temp(var, var_on_stack, &deferred_info.ty);\n            true\n        }\n    }\n\n    fn push_values(&mut self, push_values: &Vec<pre_sierra::PushValue>) {\n        if push_values.is_empty() {\n            return;\n        }\n\n        // Optimization: check if there is a prefix of `push_values` that is already on the stack.\n        let prefix_size = self.known_stack().compute_on_stack_prefix_size(push_values);\n\n        for (i, pre_sierra::PushValue { var, var_on_stack, ty, dup }) in\n            push_values.iter().enumerate()\n        {\n            let is_on_stack = if let Some(deferred_info) =\n                self.state().deferred_variables.swap_remove(var)\n            {\n                if let DeferredVariableKind::Const = deferred_info.kind {\n                    // TODO(orizi): This is an ugly fix for case of literals. Fix properly.\n                    if *dup {\n                        self.dup(var, var_on_stack, ty);\n                        self.state().deferred_variables.insert(var.clone(), deferred_info.clone());\n                        self.store_temp(var_on_stack, var_on_stack, ty);\n                    } else {\n                        self.store_temp(var, var_on_stack, ty);\n                    }\n                    continue;\n                } else if self.store_deferred_ex(var, var_on_stack, deferred_info) {\n                    if *dup {\n                        // In the dup case we dup `var_on_stack` that is ready for push into\n                        // `var` that should still be available.\n                        self.dup(var_on_stack, var, ty);\n                    }\n                    continue;\n                } else {\n                    false\n                }\n            } else {\n                // Check if this is part of the prefix. If it is, rename instead of adding\n                // `store_temp`.\n                i < prefix_size\n            };\n\n            if is_on_stack {\n                if *dup {\n                    self.dup(var, var_on_stack, ty);\n                } else {\n                    self.rename_var(var, var_on_stack, ty);\n                }\n            } else {\n                let src = if *dup {\n                    self.dup(var, var_on_stack, ty);\n                    var_on_stack\n                } else {\n                    var\n                };\n                self.store_temp(src, var_on_stack, ty);\n            }\n        }\n    }\n\n    /// Stores all the variables that may possibly get misaligned due to branches and removes them\n    /// from [State::deferred_variables].\n    /// The variables will be added according to the order of creation.\n    fn store_all_possibly_lost_variables(&mut self) {\n        for (var, deferred_info) in self.state().deferred_variables.clone() {\n            if deferred_info.kind != DeferredVariableKind::Const {\n                self.store_temp(&var, &var, &deferred_info.ty);\n                self.state().deferred_variables.swap_remove(&var);\n            }\n        }\n    }\n\n    /// Copies all the temporary variables that are marked as locals into local variables,\n    /// and removes them from [State::temporary_variables].\n    fn store_temporary_variables_as_locals(&mut self) {\n        for (var, _) in self.state().temporary_variables.clone() {\n            self.store_temp_as_local(&var);\n        }\n    }\n\n    /// Copies the given variable into a local variable if it is marked as local.\n    /// Removes it from [State::temporary_variables].\n    fn store_temp_as_local(&mut self, var: &sierra::ids::VarId) {\n        if let Some(uninitialized_local_var_id) = self.local_variables.get(var).cloned() {\n            let ty = self.state().temporary_variables.swap_remove(var).unwrap();\n            self.store_local(var, &uninitialized_local_var_id, &ty);\n        }\n    }\n\n    /// Stores all the deffered and temporary variables as local variables.\n    fn store_variables_as_locals(&mut self) {\n        let mut vars_to_store: Vec<(\n            sierra::ids::VarId,\n            sierra::ids::VarId,\n            sierra::ids::ConcreteTypeId,\n        )> = vec![];\n        for (var, deferred_info) in self.state_ref().deferred_variables.iter() {\n            if let Some(uninitialized_local_var_id) = self.local_variables.get(var).cloned() {\n                vars_to_store.push((\n                    var.clone(),\n                    uninitialized_local_var_id,\n                    deferred_info.ty.clone(),\n                ));\n            }\n        }\n\n        for (var, uninitialized_local_var_id, ty) in vars_to_store {\n            self.store_local(&var, &uninitialized_local_var_id, &ty);\n            assert!(self.state().deferred_variables.swap_remove(&var).is_some());\n        }\n\n        self.store_temporary_variables_as_locals();\n    }\n\n    /// Clears all the deferred variables.\n    fn clear_deffered_variables(&mut self) {\n        self.state().deferred_variables.clear();\n    }\n\n    fn finalize(self) -> Vec<pre_sierra::Statement> {\n        assert!(\n            self.state_opt.is_none(),\n            \"Internal compiler error: Found a reachable statement at the end of the function.\"\n        );\n        assert!(\n            self.future_states.is_empty(),\n            \"Internal compiler error: Unhandled label in 'store_variables'.\"\n        );\n        self.result\n    }\n\n    /// Adds a `store_temp` command storing `var` into `var_on_stack`.\n    fn store_temp(\n        &mut self,\n        var: &sierra::ids::VarId,\n        var_on_stack: &sierra::ids::VarId,\n        ty: &sierra::ids::ConcreteTypeId,\n    ) {\n        self.result.push(simple_statement(\n            store_temp_libfunc_id(self.db, ty.clone()),\n            &[var.clone()],\n            &[var_on_stack.clone()],\n        ));\n\n        self.known_stack().push(var_on_stack);\n        self.state().temporary_variables.insert(var_on_stack.clone(), ty.clone());\n    }\n\n    /// Adds a `store_local` command storing `var` into itself using the preallocated\n    /// `uninitialized_local_var_id`.\n    fn store_local(\n        &mut self,\n        var: &sierra::ids::VarId,\n        uninitialized_local_var_id: &sierra::ids::VarId,\n        ty: &sierra::ids::ConcreteTypeId,\n    ) {\n        self.result.push(simple_statement(\n            store_local_libfunc_id(self.db, ty.clone()),\n            &[uninitialized_local_var_id.clone(), var.clone()],\n            &[var.clone()],\n        ));\n    }\n\n    /// Adds a call to the dup() libfunc, duplicating `var` into `dup_var`.\n    fn dup(\n        &mut self,\n        var: &sierra::ids::VarId,\n        dup_var: &sierra::ids::VarId,\n        ty: &sierra::ids::ConcreteTypeId,\n    ) {\n        self.result.push(simple_statement(\n            dup_libfunc_id(self.db, ty.clone()),\n            &[var.clone()],\n            &[var.clone(), dup_var.clone()],\n        ));\n    }\n\n    /// Adds a call to the rename() libfunc, renaming `src` to `dst`.\n    fn rename_var(\n        &mut self,\n        src: &sierra::ids::VarId,\n        dst: &sierra::ids::VarId,\n        ty: &sierra::ids::ConcreteTypeId,\n    ) {\n        self.result.push(simple_statement(\n            rename_libfunc_id(self.db, ty.clone()),\n            &[src.clone()],\n            &[dst.clone()],\n        ));\n\n        self.state().rename_var(src, dst);\n    }\n\n    /// Returns the current state, assuming the current statement is reachable.\n    /// Fails otherwise.\n    fn state(&mut self) -> &mut State {\n        if matches!(self.state_opt.as_mut(), None) {\n            return self.state_opt.as_mut().unwrap();\n        }\n        self.state_opt.as_mut().unwrap()\n    }\n\n    /// Same as [Self::state], except that the result is not `mut`.\n    fn state_ref(&self) -> &State {\n        if matches!(self.state_opt.as_ref(), None) {\n            return self.state_opt.as_ref().unwrap();\n        }\n        self.state_opt.as_ref().unwrap()\n    }\n\n    /// Returns the current known stack, assuming the current statement is reachable.\n    /// Fails otherwise.\n    fn known_stack(&mut self) -> &mut KnownStack {\n        &mut self.state().known_stack\n    }\n\n    /// Merges the given `state` into the future state that corresponds to `target`.\n    /// If `target` refers to `Fallthrough`, `state` is merged into the input-output argument\n    /// `fallthrough_state`.\n    /// If it refers to a label, `state` is merged into `future_states`.\n    fn add_future_state(\n        &mut self,\n        target: &GenBranchTarget<pre_sierra::LabelId>,\n        state: State,\n        fallthrough_state: &mut Option<State>,\n    ) {\n        match target {\n            GenBranchTarget::Fallthrough => {\n                let new_state =\n                    merge_optional_states(std::mem::take(fallthrough_state), Some(state));\n                *fallthrough_state = new_state;\n            }\n            GenBranchTarget::Statement(label_id) => {\n                let new_state =\n                    merge_optional_states(self.future_states.swap_remove(label_id), Some(state));\n                self.future_states.insert(*label_id, extract_matches!(new_state, Some));\n            }\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_sierra as sierra;\nuse cairo_lang_sierra::extensions::lib_func::{\n    BranchSignature, DeferredOutputKind, OutputVarInfo, SierraApChange,\n};\nuse cairo_lang_sierra::extensions::OutputVarReferenceInfo;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\n\nuse super::known_stack::KnownStack;\n\n/// Represents the known information about a Sierra variable which contains a deferred value.\n/// For example, `[ap - 1] + [ap - 2]`.\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct DeferredVariableInfo {\n    /// The type of the variable.\n    pub ty: sierra::ids::ConcreteTypeId,\n    /// The deferred type.\n    pub kind: DeferredVariableKind,\n}\n\n/// The type of a deferred variable.\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum DeferredVariableKind {\n    /// See [DeferredOutputKind::Const].\n    Const,\n    /// See [DeferredOutputKind::AddConst].\n    AddConst,\n    /// See [DeferredOutputKind::Generic].\n    Generic,\n}\n\n/// Represents information known about the state of the variables.\n/// For example, which variable contains a deferred value and which variable is on the stack.\n#[derive(Clone, Debug, Default)]\npub struct State {\n    /// A map from [sierra::ids::VarId] of a deferred reference\n    /// (for example, `[ap - 1] + [ap - 2]`) to [DeferredVariableInfo].\n    pub deferred_variables: OrderedHashMap<sierra::ids::VarId, DeferredVariableInfo>,\n    /// A map from [sierra::ids::VarId] of temporary variables to their type.\n    pub temporary_variables: OrderedHashMap<sierra::ids::VarId, sierra::ids::ConcreteTypeId>,\n    /// The information known about the top of the stack.\n    pub known_stack: KnownStack,\n}\nimpl State {\n    /// Registers output variables of a libfunc. See [Self::register_outputs].\n    /// Clears the stack if needed.\n    pub fn register_outputs(\n        &mut self,\n        results: &[sierra::ids::VarId],\n        branch_signature: &BranchSignature,\n        args: &[sierra::ids::VarId],\n        deferred_args: &OrderedHashMap<sierra::ids::VarId, DeferredVariableInfo>,\n    ) {\n        // Clear the stack if needed.\n        match branch_signature.ap_change {\n            SierraApChange::BranchAlign\n            | SierraApChange::Unknown\n            | SierraApChange::Known { new_vars_only: false } => {\n                // Clear the stack in this case since it's possible that undeclared (not part of the\n                // output) temporary variables are created by the libfunc.\n                self.clear_known_stack();\n            }\n            SierraApChange::Known { new_vars_only: true } => {}\n        }\n\n        for (var, var_info) in itertools::zip_eq(results, &branch_signature.vars) {\n            self.register_output(var.clone(), var_info, args, deferred_args);\n        }\n\n        // Update `known_stack_size`. It is one more than the maximum of the indices in\n        // `variables_on_stack` (or 0 if empty).\n        self.known_stack.update_offset_by_max();\n    }\n\n    /// Register an output variable of a libfunc.\n    ///\n    /// If the variable is marked as Deferred output by the libfunc, it is added to\n    /// [Self::deferred_variables]. Similarly for [Self::temporary_variables].\n    fn register_output(\n        &mut self,\n        res: sierra::ids::VarId,\n        output_info: &OutputVarInfo,\n        args: &[sierra::ids::VarId],\n        deferred_args: &OrderedHashMap<sierra::ids::VarId, DeferredVariableInfo>,\n    ) {\n        let mut is_deferred: Option<DeferredVariableKind> = None;\n        let mut is_temp_var: bool = false;\n        let mut add_to_known_stack: Option<isize> = None;\n\n        match &output_info.ref_info {\n            OutputVarReferenceInfo::Deferred(kind) => {\n                is_deferred = Some(match kind {\n                    DeferredOutputKind::Const => DeferredVariableKind::Const,\n                    DeferredOutputKind::AddConst { .. } => DeferredVariableKind::AddConst,\n                    DeferredOutputKind::Generic => DeferredVariableKind::Generic,\n                });\n            }\n            OutputVarReferenceInfo::NewTempVar { idx } => {\n                add_to_known_stack = idx.map(|idx| idx.try_into().unwrap());\n                is_temp_var = true;\n            }\n            OutputVarReferenceInfo::SameAsParam { param_idx }\n            | OutputVarReferenceInfo::PartialParam { param_idx } => {\n                let arg = &args[*param_idx];\n                if let Some(deferred_info) = deferred_args.get(arg) {\n                    is_deferred = Some(deferred_info.kind);\n                }\n                is_temp_var = self.temporary_variables.get(arg).is_some();\n                if matches!(output_info.ref_info, OutputVarReferenceInfo::SameAsParam { .. }) {\n                    add_to_known_stack = self.known_stack.get(arg);\n                }\n            }\n            OutputVarReferenceInfo::NewLocalVar => {}\n        }\n\n        self.deferred_variables.swap_remove(&res);\n        self.temporary_variables.swap_remove(&res);\n        self.known_stack.remove_variable(&res);\n\n        if let Some(deferred_variable_info_kind) = is_deferred {\n            self.deferred_variables.insert(\n                res.clone(),\n                DeferredVariableInfo {\n                    ty: output_info.ty.clone(),\n                    kind: deferred_variable_info_kind,\n                },\n            );\n        }\n\n        if is_temp_var {\n            self.temporary_variables.insert(res.clone(), output_info.ty.clone());\n        }\n\n        if let Some(idx) = add_to_known_stack {\n            self.known_stack.insert_signed(res, idx);\n        }\n    }\n\n    /// Clears the known information about the stack.\n    ///\n    /// This is called where the change in the value of `ap` is not known at compile time.\n    fn clear_known_stack(&mut self) {\n        self.known_stack.clear();\n    }\n\n    /// Marks `dst` as a rename of `src`.\n    ///\n    /// Updates [Self::known_stack] and [Self::temporary_variables] if necessary.\n    pub fn rename_var(&mut self, src: &sierra::ids::VarId, dst: &sierra::ids::VarId) {\n        self.known_stack.clone_if_on_stack(src, dst);\n        if let Some(uninitialized_local_var_id) = self.temporary_variables.get(src) {\n            self.temporary_variables.insert(dst.clone(), uninitialized_local_var_id.clone());\n        }\n    }\n}\n\n/// Merges the information from two [State]s.\n/// Used to determine the state at the merge of two code branches.\n///\n/// If one of the given states is None, the second is returned.\npub fn merge_optional_states(a_opt: Option<State>, b_opt: Option<State>) -> Option<State> {\n    match (a_opt, b_opt) {\n        (None, None) => None,\n        (None, Some(b)) => Some(b),\n        (Some(a), None) => Some(a),\n        (Some(a), Some(b)) => {\n            // Merge the lists of deferred variables.\n            let mut deferred_variables = OrderedHashMap::default();\n            for (var, info_a) in a.deferred_variables {\n                if let Some(info_b) = b.deferred_variables.get(&var) {\n                    assert_eq!(\n                        info_a, *info_b,\n                        \"Internal compiler error: Found different deferred variables.\"\n                    );\n                    deferred_variables.insert(var, info_a);\n                }\n            }\n\n            // Merge the lists of temporary variables.\n            let mut temporary_variables = OrderedHashMap::default();\n            for (var, ty_a) in a.temporary_variables {\n                if let Some(ty_b) = b.temporary_variables.get(&var) {\n                    assert_eq!(\n                        ty_a, *ty_b,\n                        \"Internal compiler error: Found different types for the same variable: \\\n                         {var}.\"\n                    );\n                    temporary_variables.insert(var, ty_a);\n                }\n            }\n\n            Some(State {\n                deferred_variables,\n                temporary_variables,\n                known_stack: a.known_stack.merge_with(&b.known_stack),\n            })\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_semantic::corelib::get_core_ty_by_name;\nuse cairo_lang_semantic::GenericArgumentId;\nuse cairo_lang_sierra::extensions::lib_func::{\n    BranchSignature, DeferredOutputKind, LibfuncSignature, OutputVarInfo, ParamSignature,\n    SierraApChange,\n};\nuse cairo_lang_sierra::extensions::OutputVarReferenceInfo;\nuse cairo_lang_sierra::ids::ConcreteLibfuncId;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse pretty_assertions::assert_eq;\n\nuse super::{LibfuncInfo, LocalVariables};\nuse crate::db::SierraGenGroup;\nuse crate::pre_sierra;\nuse crate::replace_ids::replace_sierra_ids;\nuse crate::store_variables::add_store_statements;\nuse crate::test_utils::{\n    dummy_jump_statement, dummy_label, dummy_push_values, dummy_push_values_ex,\n    dummy_return_statement, dummy_simple_branch, dummy_simple_statement,\n    SierraGenDatabaseForTesting,\n};\n\n/// Returns the [OutputVarReferenceInfo] information for a given libfunc.\n/// All libfuncs inputs and outputs are felt252s, since [dummy_push_values] is currently with\n/// felt252s.\nfn get_lib_func_signature(db: &dyn SierraGenGroup, libfunc: ConcreteLibfuncId) -> LibfuncSignature {\n    let libfunc_long_id = db.lookup_intern_concrete_lib_func(libfunc);\n    let felt252_ty =\n        db.get_concrete_type_id(db.core_felt252_ty()).expect(\"Can't find core::felt252.\");\n    let array_ty = db\n        .get_concrete_type_id(get_core_ty_by_name(\n            db.upcast(),\n            \"Array\".into(),\n            vec![GenericArgumentId::Type(db.core_felt252_ty())],\n        ))\n        .expect(\"Can't find core::Array<core::felt252>.\");\n    let name = libfunc_long_id.generic_id.0;\n    match name.as_str() {\n        \"felt252_add\" => {\n            let vars = vec![OutputVarInfo {\n                ty: felt252_ty.clone(),\n                ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Generic),\n            }];\n            LibfuncSignature {\n                param_signatures: vec![\n                    ParamSignature::new(felt252_ty.clone()),\n                    ParamSignature {\n                        ty: felt252_ty,\n                        allow_deferred: false,\n                        allow_add_const: false,\n                        allow_const: true,\n                    },\n                ],\n                branch_signatures: vec![BranchSignature {\n                    vars,\n                    ap_change: SierraApChange::Known { new_vars_only: true },\n                }],\n                fallthrough: Some(0),\n            }\n        }\n        \"felt252_add3\" => LibfuncSignature {\n            param_signatures: vec![ParamSignature {\n                ty: felt252_ty.clone(),\n                allow_deferred: false,\n                allow_add_const: true,\n                allow_const: false,\n            }],\n            branch_signatures: vec![BranchSignature {\n                vars: vec![OutputVarInfo {\n                    ty: felt252_ty,\n                    ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::AddConst {\n                        param_idx: 0,\n                    }),\n                }],\n                ap_change: SierraApChange::Known { new_vars_only: true },\n            }],\n            fallthrough: Some(0),\n        },\n        \"felt252_const\" => LibfuncSignature {\n            param_signatures: vec![],\n            branch_signatures: vec![BranchSignature {\n                vars: vec![OutputVarInfo {\n                    ty: felt252_ty,\n                    ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::Const),\n                }],\n                ap_change: SierraApChange::Known { new_vars_only: true },\n            }],\n            fallthrough: Some(0),\n        },\n        \"array_append\" => LibfuncSignature {\n            param_signatures: vec![\n                ParamSignature {\n                    ty: array_ty.clone(),\n                    allow_deferred: false,\n                    allow_add_const: true,\n                    allow_const: false,\n                },\n                ParamSignature::new(felt252_ty),\n            ],\n            branch_signatures: vec![BranchSignature {\n                vars: vec![OutputVarInfo {\n                    ty: array_ty,\n                    ref_info: OutputVarReferenceInfo::Deferred(DeferredOutputKind::AddConst {\n                        param_idx: 0,\n                    }),\n                }],\n                ap_change: SierraApChange::Known { new_vars_only: true },\n            }],\n            fallthrough: Some(0),\n        },\n        \"nope\" => LibfuncSignature {\n            param_signatures: vec![],\n            branch_signatures: vec![BranchSignature {\n                vars: vec![],\n                ap_change: SierraApChange::Known { new_vars_only: true },\n            }],\n            fallthrough: Some(0),\n        },\n        \"revoke_ap\" => LibfuncSignature {\n            param_signatures: vec![],\n            branch_signatures: vec![BranchSignature {\n                vars: vec![],\n                ap_change: SierraApChange::Unknown,\n            }],\n            fallthrough: Some(0),\n        },\n        \"function_call4\" => {\n            let vars: Vec<_> = (0..4)\n                .map(|idx| OutputVarInfo {\n                    ty: felt252_ty.clone(),\n                    ref_info: OutputVarReferenceInfo::NewTempVar { idx: Some(idx) },\n                })\n                .collect();\n            LibfuncSignature {\n                param_signatures: vec![],\n                branch_signatures: vec![BranchSignature {\n                    vars,\n                    ap_change: SierraApChange::Known { new_vars_only: false },\n                }],\n                fallthrough: Some(0),\n            }\n        }\n        \"jump\" => LibfuncSignature {\n            param_signatures: vec![],\n            branch_signatures: vec![BranchSignature {\n                vars: vec![],\n                ap_change: SierraApChange::Known { new_vars_only: true },\n            }],\n            fallthrough: None,\n        },\n        \"branch\" => LibfuncSignature {\n            param_signatures: vec![],\n            branch_signatures: vec![\n                BranchSignature {\n                    vars: vec![],\n                    ap_change: SierraApChange::Known { new_vars_only: true },\n                },\n                BranchSignature {\n                    vars: vec![],\n                    ap_change: SierraApChange::Known { new_vars_only: true },\n                },\n            ],\n            fallthrough: Some(1),\n        },\n        \"branch_with_param\" => LibfuncSignature {\n            param_signatures: vec![ParamSignature::new(felt252_ty)],\n            branch_signatures: vec![\n                BranchSignature {\n                    vars: vec![],\n                    ap_change: SierraApChange::Known { new_vars_only: true },\n                },\n                BranchSignature {\n                    vars: vec![],\n                    ap_change: SierraApChange::Known { new_vars_only: true },\n                },\n            ],\n            fallthrough: Some(1),\n        },\n        \"store_temp<felt252>\" => LibfuncSignature {\n            param_signatures: vec![ParamSignature {\n                ty: felt252_ty.clone(),\n                allow_deferred: true,\n                allow_add_const: true,\n                allow_const: true,\n            }],\n            branch_signatures: vec![BranchSignature {\n                vars: vec![OutputVarInfo {\n                    ty: felt252_ty,\n                    ref_info: OutputVarReferenceInfo::NewTempVar { idx: Some(0) },\n                }],\n                ap_change: SierraApChange::Known { new_vars_only: true },\n            }],\n            fallthrough: Some(0),\n        },\n        \"temp_not_on_top\" => LibfuncSignature::new_non_branch(\n            vec![],\n            vec![OutputVarInfo {\n                ty: felt252_ty,\n                // Simulate the case where the returned value is not on the top of the stack.\n                ref_info: OutputVarReferenceInfo::NewTempVar { idx: None },\n            }],\n            SierraApChange::Known { new_vars_only: false },\n        ),\n        \"dup\" => LibfuncSignature::new_non_branch_ex(\n            vec![ParamSignature {\n                ty: felt252_ty.clone(),\n                allow_deferred: true,\n                allow_add_const: true,\n                allow_const: true,\n            }],\n            vec![\n                OutputVarInfo {\n                    ty: felt252_ty.clone(),\n                    ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 0 },\n                },\n                OutputVarInfo {\n                    ty: felt252_ty,\n                    ref_info: OutputVarReferenceInfo::SameAsParam { param_idx: 0 },\n                },\n            ],\n            SierraApChange::Known { new_vars_only: true },\n        ),\n        _ => panic!(\"get_branch_signatures() is not implemented for '{name}'.\"),\n    }\n}\n\n/// Helper function for tests of [add_store_statements].\n///\n/// Calls [add_store_statements] on the given `statements` and returns the result as a vector of\n/// strings.\nfn test_add_store_statements(\n    db: &SierraGenDatabaseForTesting,\n    statements: Vec<pre_sierra::Statement>,\n    local_variables: LocalVariables,\n) -> Vec<String> {\n    add_store_statements(\n        db,\n        statements,\n        &(|libfunc| LibfuncInfo { signature: get_lib_func_signature(db, libfunc) }),\n        local_variables,\n    )\n    .iter()\n    .map(|statement| replace_sierra_ids(db, statement).to_string())\n    .collect()\n}\n\n#[test]\nfn store_temp_simple() {\n    let db = SierraGenDatabaseForTesting::default();\n    let statements: Vec<pre_sierra::Statement> = vec![\n        dummy_simple_statement(&db, \"felt252_add\", &[\"0\", \"1\"], &[\"2\"]),\n        dummy_simple_statement(&db, \"nope\", &[], &[]),\n        dummy_simple_statement(&db, \"felt252_add\", &[\"2\", \"3\"], &[\"4\"]),\n        dummy_simple_statement(&db, \"nope\", &[], &[]),\n        dummy_simple_statement(&db, \"felt252_add\", &[\"2\", \"4\"], &[\"5\"]),\n        dummy_simple_statement(&db, \"nope\", &[], &[]),\n        dummy_label(0),\n        dummy_simple_statement(&db, \"felt252_add\", &[\"5\", \"5\"], &[\"6\"]),\n        dummy_return_statement(&[]),\n    ];\n\n    assert_eq!(\n        test_add_store_statements(&db, statements, LocalVariables::default()),\n        vec![\n            \"felt252_add(0, 1) -> (2)\",\n            \"nope() -> ()\",\n            \"store_temp<felt252>(2) -> (2)\",\n            \"felt252_add(2, 3) -> (4)\",\n            \"nope() -> ()\",\n            \"store_temp<felt252>(4) -> (4)\",\n            \"felt252_add(2, 4) -> (5)\",\n            \"nope() -> ()\",\n            \"label0:\",\n            \"store_temp<felt252>(5) -> (5)\",\n            \"felt252_add(5, 5) -> (6)\",\n            \"return()\",\n        ]\n    );\n}\n\n#[test]\nfn store_temp_for_branch_command() {\n    let db = SierraGenDatabaseForTesting::default();\n    let statements: Vec<pre_sierra::Statement> = vec![\n        dummy_simple_statement(&db, \"felt252_add\", &[\"0\", \"1\"], &[\"2\"]),\n        dummy_simple_branch(&db, \"branch_with_param\", &[\"2\"], 0),\n        dummy_label(0),\n        dummy_return_statement(&[]),\n    ];\n\n    assert_eq!(\n        test_add_store_statements(&db, statements, LocalVariables::default()),\n        vec![\n            \"felt252_add(0, 1) -> (2)\",\n            \"store_temp<felt252>(2) -> (2)\",\n            \"branch_with_param(2) { label0() fallthrough() }\",\n            \"label0:\",\n            \"return()\",\n        ]\n    );\n}\n\n#[test]\nfn store_local_simple() {\n    let db = SierraGenDatabaseForTesting::default();\n    let statements: Vec<pre_sierra::Statement> = vec![\n        dummy_simple_statement(&db, \"felt252_add\", &[\"0\", \"1\"], &[\"2\"]),\n        dummy_simple_statement(&db, \"nope\", &[], &[]),\n        // Case I: local added instead of tempvar, when first used.\n        dummy_simple_statement(&db, \"felt252_add\", &[\"2\", \"3\"], &[\"4\"]),\n        dummy_simple_statement(&db, \"nope\", &[], &[]),\n        // Case II: deferred computed into local before revoke_ap().\n        dummy_simple_statement(&db, \"revoke_ap\", &[], &[]),\n        dummy_simple_statement(&db, \"function_call4\", &[], &[\"5\", \"6\", \"7\", \"8\"]),\n        dummy_simple_statement(&db, \"nope\", &[], &[]),\n        // Case III: tempvar copied into local before revoke_ap().\n        dummy_simple_statement(&db, \"revoke_ap\", &[], &[]),\n        dummy_simple_statement(&db, \"store_temp<felt252>\", &[\"9\"], &[\"9\"]),\n        // Don't store as local due to a simple jump.\n        dummy_jump_statement(&db, 0),\n        dummy_label(0),\n        dummy_simple_statement(&db, \"nope\", &[], &[]),\n        // Case IV: tempvar copied into local before branches.\n        dummy_simple_branch(&db, \"branch\", &[], 1),\n        dummy_label(1),\n        dummy_return_statement(&[]),\n    ];\n\n    assert_eq!(\n        test_add_store_statements(\n            &db,\n            statements,\n            OrderedHashMap::from_iter(vec![\n                (\"2\".into(), \"102\".into()),\n                (\"4\".into(), \"104\".into()),\n                (\"7\".into(), \"107\".into()),\n                (\"9\".into(), \"109\".into())\n            ])\n        ),\n        vec![\n            \"felt252_add(0, 1) -> (2)\",\n            \"nope() -> ()\",\n            \"store_local<felt252>(102, 2) -> (2)\",\n            \"felt252_add(2, 3) -> (4)\",\n            \"nope() -> ()\",\n            \"store_local<felt252>(104, 4) -> (4)\",\n            \"revoke_ap() -> ()\",\n            \"function_call4() -> (5, 6, 7, 8)\",\n            \"nope() -> ()\",\n            \"store_local<felt252>(107, 7) -> (7)\",\n            \"revoke_ap() -> ()\",\n            \"store_temp<felt252>(9) -> (9)\",\n            \"jump() { label0() }\",\n            \"label0:\",\n            \"nope() -> ()\",\n            \"store_local<felt252>(109, 9) -> (9)\",\n            \"branch() { label1() fallthrough() }\",\n            \"label1:\",\n            \"return()\",\n        ],\n    );\n}\n\n#[test]\nfn same_as_param() {\n    let db = SierraGenDatabaseForTesting::default();\n    let statements: Vec<pre_sierra::Statement> = vec![\n        dummy_simple_statement(&db, \"felt252_add3\", &[\"0\"], &[\"1\"]),\n        dummy_simple_statement(&db, \"dup\", &[\"1\"], &[\"2\", \"3\"]),\n        dummy_simple_statement(&db, \"felt252_add3\", &[\"2\"], &[\"4\"]),\n        dummy_simple_statement(&db, \"felt252_add\", &[\"3\", \"4\"], &[\"5\"]),\n        dummy_return_statement(&[]),\n    ];\n\n    assert_eq!(\n        test_add_store_statements(&db, statements, LocalVariables::default()),\n        vec![\n            \"felt252_add3(0) -> (1)\",\n            \"dup(1) -> (2, 3)\",\n            \"felt252_add3(2) -> (4)\",\n            \"store_temp<felt252>(3) -> (3)\",\n            \"store_temp<felt252>(4) -> (4)\",\n            \"felt252_add(3, 4) -> (5)\",\n            \"return()\",\n        ]\n    );\n}\n\n#[test]\nfn same_as_param_push_value_optimization() {\n    let db = SierraGenDatabaseForTesting::default();\n    let statements: Vec<pre_sierra::Statement> = vec![\n        dummy_simple_statement(&db, \"store_temp<felt252>\", &[\"0\"], &[\"1\"]),\n        dummy_simple_statement(&db, \"dup\", &[\"1\"], &[\"2\", \"3\"]),\n        dummy_push_values(&db, &[(\"2\", \"102\"), (\"4\", \"104\")]),\n        dummy_return_statement(&[]),\n    ];\n\n    assert_eq!(\n        test_add_store_statements(&db, statements, LocalVariables::default()),\n        vec![\n            \"store_temp<felt252>(0) -> (1)\",\n            \"dup(1) -> (2, 3)\",\n            \"rename<felt252>(2) -> (102)\",\n            \"store_temp<felt252>(4) -> (104)\",\n            \"return()\",\n        ]\n    );\n}\n\n/// Tests that storing the result of an if as a local variable works correctly.\n///\n/// For example:\n///     let y = if cond { 1 } else { 2 }\n///     revoke_ap()\n///     // Use y.\n#[test]\nfn store_local_result_of_if() {\n    let db = SierraGenDatabaseForTesting::default();\n    let statements: Vec<pre_sierra::Statement> = vec![\n        dummy_simple_branch(&db, \"branch\", &[], 0),\n        // If part.\n        dummy_simple_statement(&db, \"store_temp<felt252>\", &[\"100\"], &[\"100\"]),\n        dummy_jump_statement(&db, 1),\n        // Else part.\n        dummy_label(0),\n        dummy_push_values(&db, &[(\"0\", \"100\")]),\n        // Post-if.\n        dummy_label(1),\n        dummy_simple_statement(&db, \"nope\", &[], &[]),\n        dummy_simple_statement(&db, \"revoke_ap\", &[], &[]),\n        dummy_return_statement(&[]),\n    ];\n\n    assert_eq!(\n        test_add_store_statements(\n            &db,\n            statements,\n            OrderedHashMap::from_iter(vec![(\"100\".into(), \"200\".into()),])\n        ),\n        vec![\n            \"branch() { label0() fallthrough() }\",\n            \"store_temp<felt252>(100) -> (100)\",\n            \"jump() { label1() }\",\n            \"label0:\",\n            \"store_temp<felt252>(0) -> (100)\",\n            \"label1:\",\n            \"nope() -> ()\",\n            \"store_local<felt252>(200, 100) -> (100)\",\n            \"revoke_ap() -> ()\",\n            \"return()\",\n        ],\n    );\n}\n\n/// Tests the behavior of the [PushValues](pre_sierra::Statement::PushValues) statement.\n#[test]\nfn store_temp_push_values() {\n    let db = SierraGenDatabaseForTesting::default();\n    let statements: Vec<pre_sierra::Statement> = vec![\n        dummy_simple_statement(&db, \"felt252_add\", &[\"0\", \"1\"], &[\"2\"]),\n        dummy_simple_statement(&db, \"nope\", &[], &[]),\n        dummy_simple_statement(&db, \"felt252_add\", &[\"3\", \"4\"], &[\"5\"]),\n        dummy_simple_statement(&db, \"felt252_add\", &[\"5\", \"5\"], &[\"6\"]),\n        dummy_simple_statement(&db, \"store_temp<felt252>\", &[\"7\"], &[\"7\"]),\n        dummy_push_values(&db, &[(\"5\", \"100\"), (\"2\", \"101\"), (\"6\", \"102\"), (\"6\", \"103\")]),\n        dummy_simple_statement(&db, \"nope\", &[], &[]),\n        dummy_return_statement(&[\"6\"]),\n    ];\n\n    assert_eq!(\n        test_add_store_statements(&db, statements, LocalVariables::default()),\n        vec![\n            \"felt252_add(0, 1) -> (2)\",\n            \"nope() -> ()\",\n            \"felt252_add(3, 4) -> (5)\",\n            \"store_temp<felt252>(5) -> (5)\",\n            \"felt252_add(5, 5) -> (6)\",\n            \"store_temp<felt252>(7) -> (7)\",\n            \"store_temp<felt252>(5) -> (100)\",\n            \"store_temp<felt252>(2) -> (101)\",\n            \"store_temp<felt252>(6) -> (102)\",\n            \"store_temp<felt252>(6) -> (103)\",\n            \"nope() -> ()\",\n            \"return(6)\",\n        ]\n    );\n}\n\n/// Tests the behavior of the [PushValues](pre_sierra::Statement::PushValues) statement with\n/// [dup_var](pre_sierra::Statement::PushValues::dup_var).\n#[test]\nfn store_temp_push_values_with_dup() {\n    let db = SierraGenDatabaseForTesting::default();\n    let statements: Vec<pre_sierra::Statement> = vec![\n        dummy_simple_statement(&db, \"felt252_add\", &[\"0\", \"1\"], &[\"2\"]),\n        dummy_simple_statement(&db, \"nope\", &[], &[]),\n        dummy_push_values_ex(\n            &db,\n            &[\n                // Deferred with dup.\n                (\"2\", \"102\", true),\n                // Temporary variable with dup.\n                (\"0\", \"100\", true),\n            ],\n        ),\n        dummy_return_statement(&[]),\n    ];\n\n    assert_eq!(\n        test_add_store_statements(&db, statements, LocalVariables::default()),\n        vec![\n            \"felt252_add(0, 1) -> (2)\",\n            \"nope() -> ()\",\n            \"store_temp<felt252>(2) -> (102)\",\n            \"dup<felt252>(102) -> (102, 2)\",\n            \"dup<felt252>(0) -> (0, 100)\",\n            \"store_temp<felt252>(100) -> (100)\",\n            \"return()\",\n        ]\n    );\n}\n\n/// Tests the [PushValues](pre_sierra::Statement::PushValues) optimization.\n#[test]\nfn push_values_optimization() {\n    let db = SierraGenDatabaseForTesting::default();\n    let statements: Vec<pre_sierra::Statement> = vec![\n        dummy_simple_statement(&db, \"function_call4\", &[], &[\"0\", \"1\", \"2\", \"3\"]),\n        dummy_push_values(&db, &[(\"2\", \"102\"), (\"3\", \"103\"), (\"0\", \"100\")]),\n        dummy_push_values(&db, &[(\"102\", \"202\")]),\n        dummy_return_statement(&[\"0\"]),\n    ];\n\n    assert_eq!(\n        test_add_store_statements(&db, statements, LocalVariables::default()),\n        vec![\n            \"function_call4() -> (0, 1, 2, 3)\",\n            \"rename<felt252>(2) -> (102)\",\n            \"rename<felt252>(3) -> (103)\",\n            \"store_temp<felt252>(0) -> (100)\",\n            \"store_temp<felt252>(102) -> (202)\",\n            \"return(0)\",\n        ]\n    );\n}\n\n/// Tests that the known stack is cleared after change to ap.\n#[test]\nfn push_values_clear_known_stack() {\n    let db = SierraGenDatabaseForTesting::default();\n    let statements: Vec<pre_sierra::Statement> = vec![\n        dummy_push_values(&db, &[(\"0\", \"100\")]),\n        // The explicit call to store_temp() will clear the known stack.\n        dummy_simple_statement(&db, \"store_temp<felt252>\", &[\"1\"], &[\"101\"]),\n        dummy_push_values(&db, &[(\"100\", \"200\"), (\"101\", \"201\")]),\n        dummy_simple_statement(&db, \"nope\", &[], &[]),\n        dummy_push_values(&db, &[(\"200\", \"300\"), (\"201\", \"301\")]),\n        dummy_return_statement(&[\"0\"]),\n    ];\n\n    assert_eq!(\n        test_add_store_statements(&db, statements, LocalVariables::default()),\n        vec![\n            \"store_temp<felt252>(0) -> (100)\",\n            \"store_temp<felt252>(1) -> (101)\",\n            \"rename<felt252>(100) -> (200)\",\n            \"rename<felt252>(101) -> (201)\",\n            \"nope() -> ()\",\n            \"rename<felt252>(200) -> (300)\",\n            \"rename<felt252>(201) -> (301)\",\n            \"return(0)\",\n        ]\n    );\n}\n\n#[test]\nfn push_values_temp_not_on_top() {\n    let db = SierraGenDatabaseForTesting::default();\n    let statements: Vec<pre_sierra::Statement> = vec![\n        dummy_simple_statement(&db, \"temp_not_on_top\", &[], &[\"0\"]),\n        dummy_push_values(&db, &[(\"0\", \"100\")]),\n        dummy_return_statement(&[\"0\"]),\n    ];\n\n    assert_eq!(\n        test_add_store_statements(&db, statements, LocalVariables::default()),\n        vec![\"temp_not_on_top() -> (0)\", \"store_temp<felt252>(0) -> (100)\", \"return(0)\",]\n    );\n}\n\n/// Tests a few consecutive invocations of [PushValues](pre_sierra::Statement::PushValues).\n#[test]\nfn consecutive_push_values() {\n    let db = SierraGenDatabaseForTesting::default();\n    let statements: Vec<pre_sierra::Statement> = vec![\n        dummy_push_values(&db, &[(\"0\", \"100\"), (\"1\", \"101\")]),\n        dummy_push_values(&db, &[(\"100\", \"200\"), (\"101\", \"201\"), (\"2\", \"202\"), (\"3\", \"203\")]),\n        dummy_push_values(&db, &[(\"101\", \"301\"), (\"202\", \"302\"), (\"203\", \"303\"), (\"4\", \"304\")]),\n        dummy_push_values(&db, &[(\"304\", \"404\")]),\n        dummy_return_statement(&[\"0\"]),\n    ];\n\n    assert_eq!(\n        test_add_store_statements(&db, statements, LocalVariables::default()),\n        vec![\n            // First statement. Push [0] and [1].\n            \"store_temp<felt252>(0) -> (100)\",\n            \"store_temp<felt252>(1) -> (101)\",\n            // Second statement. Reuse [100] and [101]. Push [2] and [3].\n            \"rename<felt252>(100) -> (200)\",\n            \"rename<felt252>(101) -> (201)\",\n            \"store_temp<felt252>(2) -> (202)\",\n            \"store_temp<felt252>(3) -> (203)\",\n            // Third statement. Reuse [101], [202] and [203]. Push [4].\n            \"rename<felt252>(101) -> (301)\",\n            \"rename<felt252>(202) -> (302)\",\n            \"rename<felt252>(203) -> (303)\",\n            \"store_temp<felt252>(4) -> (304)\",\n            // Third statement. Reuse [304].\n            \"rename<felt252>(304) -> (404)\",\n            // Return.\n            \"return(0)\",\n        ]\n    );\n}\n\n/// Tests a few consecutive invocations of [PushValues](pre_sierra::Statement::PushValues).\n#[test]\nfn push_values_after_branch_merge() {\n    let db = SierraGenDatabaseForTesting::default();\n    let statements: Vec<pre_sierra::Statement> = vec![\n        dummy_simple_branch(&db, \"branch\", &[], 0),\n        dummy_push_values(&db, &[(\"0\", \"100\"), (\"1\", \"101\"), (\"2\", \"102\")]),\n        dummy_jump_statement(&db, 1),\n        dummy_label(0),\n        dummy_push_values(&db, &[(\"1\", \"101\"), (\"2\", \"102\")]),\n        dummy_label(1),\n        dummy_push_values(&db, &[(\"101\", \"201\"), (\"102\", \"202\"), (\"3\", \"203\")]),\n        dummy_return_statement(&[\"0\"]),\n    ];\n\n    assert_eq!(\n        test_add_store_statements(&db, statements, LocalVariables::default()),\n        vec![\n            \"branch() { label0() fallthrough() }\",\n            // Push [0], [1] and [2].\n            \"store_temp<felt252>(0) -> (100)\",\n            \"store_temp<felt252>(1) -> (101)\",\n            \"store_temp<felt252>(2) -> (102)\",\n            \"jump() { label1() }\",\n            \"label0:\",\n            // Push [1] and [2].\n            \"store_temp<felt252>(1) -> (101)\",\n            \"store_temp<felt252>(2) -> (102)\",\n            \"label1:\",\n            // Here the two branches merge and the merged stack is [1], [2].\n            // Reuse [101] and [102]. Push [3].\n            \"rename<felt252>(101) -> (201)\",\n            \"rename<felt252>(102) -> (202)\",\n            \"store_temp<felt252>(3) -> (203)\",\n            // Return.\n            \"return(0)\",\n        ]\n    );\n}\n\n/// Tests a few consecutive invocations of [PushValues](pre_sierra::Statement::PushValues).\n#[test]\nfn push_values_early_return() {\n    let db = SierraGenDatabaseForTesting::default();\n    let statements: Vec<pre_sierra::Statement> = vec![\n        dummy_push_values(&db, &[(\"0\", \"100\"), (\"1\", \"101\")]),\n        dummy_simple_branch(&db, \"branch\", &[], 0),\n        dummy_push_values(&db, &[(\"101\", \"201\"), (\"2\", \"202\"), (\"3\", \"203\")]),\n        dummy_return_statement(&[\"0\"]),\n        dummy_label(0),\n        dummy_push_values(&db, &[(\"101\", \"201\"), (\"2\", \"202\")]),\n        dummy_return_statement(&[\"0\"]),\n    ];\n\n    assert_eq!(\n        test_add_store_statements(&db, statements, LocalVariables::default()),\n        vec![\n            // Push [0] and [1].\n            \"store_temp<felt252>(0) -> (100)\",\n            \"store_temp<felt252>(1) -> (101)\",\n            \"branch() { label0() fallthrough() }\",\n            // Reuse [101]. Push [2] and [3].\n            \"rename<felt252>(101) -> (201)\",\n            \"store_temp<felt252>(2) -> (202)\",\n            \"store_temp<felt252>(3) -> (203)\",\n            \"return(0)\",\n            // This is not a merge of branches because of the \"return\" statement.\n            // The stack contains [0] and [1].\n            \"label0:\",\n            // Reuse [101]. Push [2].\n            \"rename<felt252>(101) -> (201)\",\n            \"store_temp<felt252>(2) -> (202)\",\n            \"return(0)\",\n        ]\n    );\n}\n\n/// Tests a few consecutive invocations of [PushValues](pre_sierra::Statement::PushValues).\n#[test]\nfn consecutive_const_additions() {\n    let db = SierraGenDatabaseForTesting::default();\n    let statements: Vec<pre_sierra::Statement> = vec![\n        dummy_simple_statement(&db, \"felt252_add\", &[\"0\", \"1\"], &[\"2\"]),\n        dummy_simple_statement(&db, \"felt252_add3\", &[\"2\"], &[\"3\"]),\n        dummy_simple_statement(&db, \"felt252_add3\", &[\"3\"], &[\"4\"]),\n        dummy_simple_statement(&db, \"felt252_add\", &[\"0\", \"4\"], &[\"5\"]),\n        dummy_simple_statement(&db, \"felt252_add\", &[\"0\", \"5\"], &[\"6\"]),\n        dummy_simple_statement(&db, \"felt252_add3\", &[\"6\"], &[\"7\"]),\n        dummy_simple_statement(&db, \"felt252_add3\", &[\"7\"], &[\"8\"]),\n        dummy_push_values(&db, &[(\"8\", \"9\")]),\n        dummy_return_statement(&[\"9\"]),\n    ];\n\n    assert_eq!(\n        test_add_store_statements(&db, statements, LocalVariables::default()),\n        vec![\n            \"felt252_add(0, 1) -> (2)\",\n            \"store_temp<felt252>(2) -> (2)\",\n            \"felt252_add3(2) -> (3)\",\n            // There is no need to add a store_temp() instruction between two `felt252_add3()`.\n            \"felt252_add3(3) -> (4)\",\n            \"store_temp<felt252>(4) -> (4)\",\n            \"felt252_add(0, 4) -> (5)\",\n            \"store_temp<felt252>(5) -> (5)\",\n            \"felt252_add(0, 5) -> (6)\",\n            \"store_temp<felt252>(6) -> (6)\",\n            \"felt252_add3(6) -> (7)\",\n            // There is no need to add a store_temp() instruction between two `felt252_add3()`.\n            \"felt252_add3(7) -> (8)\",\n            // Return.\n            \"store_temp<felt252>(8) -> (9)\",\n            \"return(9)\",\n        ]\n    );\n}\n\n/// Tests a few consecutive invocations of [PushValues](pre_sierra::Statement::PushValues).\n#[test]\nfn consecutive_const_additions_with_branch() {\n    let db = SierraGenDatabaseForTesting::default();\n    let statements: Vec<pre_sierra::Statement> = vec![\n        dummy_simple_statement(&db, \"felt252_add\", &[\"0\", \"1\"], &[\"2\"]),\n        dummy_simple_statement(&db, \"felt252_add3\", &[\"2\"], &[\"3\"]),\n        dummy_simple_statement(&db, \"felt252_add3\", &[\"3\"], &[\"4\"]),\n        dummy_simple_branch(&db, \"branch\", &[], 0),\n        dummy_label(0),\n        dummy_push_values(&db, &[(\"4\", \"5\")]),\n        dummy_return_statement(&[\"5\"]),\n    ];\n\n    assert_eq!(\n        test_add_store_statements(&db, statements, LocalVariables::default()),\n        vec![\n            \"felt252_add(0, 1) -> (2)\",\n            \"store_temp<felt252>(2) -> (2)\",\n            \"felt252_add3(2) -> (3)\",\n            // There is no need to add a store_temp() instruction between two `felt252_add3()`.\n            \"felt252_add3(3) -> (4)\",\n            \"store_temp<felt252>(4) -> (4)\",\n            \"branch() { label0() fallthrough() }\",\n            \"label0:\",\n            // Return.\n            \"rename<felt252>(4) -> (5)\",\n            \"return(5)\",\n        ]\n    );\n}\n\n/// Tests a few consecutive invocations of [PushValues](pre_sierra::Statement::PushValues).\n#[test]\nfn consecutive_appends_with_branch() {\n    let db = SierraGenDatabaseForTesting::default();\n    let statements: Vec<pre_sierra::Statement> = vec![\n        dummy_simple_statement(&db, \"array_append\", &[\"0\", \"1\"], &[\"2\"]),\n        dummy_simple_statement(&db, \"array_append\", &[\"2\", \"3\"], &[\"4\"]),\n        dummy_simple_statement(&db, \"array_append\", &[\"4\", \"5\"], &[\"6\"]),\n        dummy_simple_branch(&db, \"branch\", &[], 0),\n        dummy_label(0),\n        dummy_push_values(&db, &[(\"6\", \"7\")]),\n        dummy_return_statement(&[\"7\"]),\n    ];\n\n    assert_eq!(\n        test_add_store_statements(&db, statements, LocalVariables::default()),\n        vec![\n            \"array_append(0, 1) -> (2)\",\n            \"array_append(2, 3) -> (4)\",\n            \"array_append(4, 5) -> (6)\",\n            \"store_temp<Array<felt252>>(6) -> (6)\",\n            \"branch() { label0() fallthrough() }\",\n            \"label0:\",\n            // Return.\n            \"rename<felt252>(6) -> (7)\",\n            \"return(7)\",\n        ]\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse cairo_lang_defs::db::{DefsDatabase, DefsGroup, HasMacroPlugins};\nuse cairo_lang_defs::ids::ModuleId;\nuse cairo_lang_defs::plugin::MacroPlugin;\nuse cairo_lang_filesystem::db::{\n    init_dev_corelib, init_files_group, AsFilesGroupMut, FilesDatabase, FilesGroup,\n};\nuse cairo_lang_filesystem::detect::detect_corelib;\nuse cairo_lang_lowering::db::{init_lowering_group, LoweringDatabase, LoweringGroup};\nuse cairo_lang_parser::db::ParserDatabase;\nuse cairo_lang_plugins::get_default_plugins;\nuse cairo_lang_semantic::db::{SemanticDatabase, SemanticGroup, SemanticGroupEx};\nuse cairo_lang_semantic::test_utils::setup_test_crate;\nuse cairo_lang_sierra::ids::{ConcreteLibfuncId, GenericLibfuncId};\nuse cairo_lang_sierra::program;\nuse cairo_lang_syntax::node::db::{SyntaxDatabase, SyntaxGroup};\nuse cairo_lang_utils::Upcast;\nuse salsa::{InternId, InternKey};\nuse {cairo_lang_defs as defs, cairo_lang_lowering as lowering, cairo_lang_semantic as semantic};\n\nuse crate::db::{SierraGenDatabase, SierraGenGroup};\nuse crate::pre_sierra;\nuse crate::replace_ids::replace_sierra_ids_in_program;\nuse crate::utils::{jump_statement, return_statement, simple_statement};\n\n#[salsa::database(\n    DefsDatabase,\n    FilesDatabase,\n    LoweringDatabase,\n    ParserDatabase,\n    SemanticDatabase,\n    SierraGenDatabase,\n    SyntaxDatabase\n)]\npub struct SierraGenDatabaseForTesting {\n    storage: salsa::Storage<SierraGenDatabaseForTesting>,\n}\nimpl salsa::Database for SierraGenDatabaseForTesting {}\nimpl Default for SierraGenDatabaseForTesting {\n    fn default() -> Self {\n        let mut res = Self { storage: Default::default() };\n        init_files_group(&mut res);\n        init_lowering_group(&mut res);\n        res.set_semantic_plugins(get_default_plugins());\n        let corelib_path = detect_corelib().expect(\"Corelib not found in default location.\");\n        init_dev_corelib(&mut res, corelib_path);\n        res\n    }\n}\nimpl AsFilesGroupMut for SierraGenDatabaseForTesting {\n    fn as_files_group_mut(&mut self) -> &mut (dyn FilesGroup + 'static) {\n        self\n    }\n}\nimpl Upcast<dyn FilesGroup> for SierraGenDatabaseForTesting {\n    fn upcast(&self) -> &(dyn FilesGroup + 'static) {\n        self\n    }\n}\nimpl Upcast<dyn SyntaxGroup> for SierraGenDatabaseForTesting {\n    fn upcast(&self) -> &(dyn SyntaxGroup + 'static) {\n        self\n    }\n}\nimpl Upcast<dyn DefsGroup> for SierraGenDatabaseForTesting {\n    fn upcast(&self) -> &(dyn defs::db::DefsGroup + 'static) {\n        self\n    }\n}\nimpl Upcast<dyn SemanticGroup> for SierraGenDatabaseForTesting {\n    fn upcast(&self) -> &(dyn semantic::db::SemanticGroup + 'static) {\n        self\n    }\n}\nimpl Upcast<dyn LoweringGroup> for SierraGenDatabaseForTesting {\n    fn upcast(&self) -> &(dyn lowering::db::LoweringGroup + 'static) {\n        self\n    }\n}\nimpl HasMacroPlugins for SierraGenDatabaseForTesting {\n    fn macro_plugins(&self) -> Vec<Arc<dyn MacroPlugin>> {\n        self.get_macro_plugins()\n    }\n}\n\n/// Compiles `content` to sierra and replaces the sierra ids to make it readable.\npub fn checked_compile_to_sierra(content: &str) -> cairo_lang_sierra::program::Program {\n    let (db, crate_id) = setup_db_and_get_crate_id(content);\n\n    let program = db.get_sierra_program(vec![crate_id]).unwrap();\n    replace_sierra_ids_in_program(&db, &program)\n}\n\n/// Adds `content` to a salsa db and returns the crate id that points to it.\npub fn setup_db_and_get_crate_id(\n    content: &str,\n) -> (SierraGenDatabaseForTesting, cairo_lang_filesystem::ids::CrateId) {\n    let mut db_val = SierraGenDatabaseForTesting::default();\n    let db = &mut db_val;\n    let crate_id = setup_test_crate(db, content);\n    let module_id = ModuleId::CrateRoot(crate_id);\n    db.module_semantic_diagnostics(module_id)\n        .unwrap()\n        .expect_with_db(db, \"Unexpected semantic diagnostics\");\n    db.module_lowering_diagnostics(module_id)\n        .unwrap()\n        .expect_with_db(db, \"Unexpected lowering diagnostics.\");\n    (db_val, crate_id)\n}\n\n/// Generates a dummy statement with the given name, inputs and outputs.\npub fn dummy_simple_statement(\n    db: &dyn SierraGenGroup,\n    name: &str,\n    inputs: &[&str],\n    outputs: &[&str],\n) -> pre_sierra::Statement {\n    simple_statement(\n        dummy_concrete_lib_func_id(db, name),\n        &as_var_id_vec(inputs),\n        &as_var_id_vec(outputs),\n    )\n}\n\nfn dummy_concrete_lib_func_id(db: &dyn SierraGenGroup, name: &str) -> ConcreteLibfuncId {\n    db.intern_concrete_lib_func(program::ConcreteLibfuncLongId {\n        generic_id: GenericLibfuncId::from_string(name),\n        generic_args: vec![],\n    })\n}\n\n/// Returns a vector of variable ids based on the inputs mapped into variable ids.\npub fn as_var_id_vec(ids: &[&str]) -> Vec<cairo_lang_sierra::ids::VarId> {\n    ids.iter().map(|id| (*id).into()).collect()\n}\n\n/// Generates a dummy statement with two branches. One branch is Fallthrough and the other is to the\n/// given label.\npub fn dummy_simple_branch(\n    db: &dyn SierraGenGroup,\n    name: &str,\n    args: &[&str],\n    target: usize,\n) -> pre_sierra::Statement {\n    pre_sierra::Statement::Sierra(program::GenStatement::Invocation(program::GenInvocation {\n        libfunc_id: dummy_concrete_lib_func_id(db, name),\n        args: as_var_id_vec(args),\n        branches: vec![\n            program::GenBranchInfo {\n                target: program::GenBranchTarget::Statement(label_id_from_usize(target)),\n                results: vec![],\n            },\n            program::GenBranchInfo {\n                target: program::GenBranchTarget::Fallthrough,\n                results: vec![],\n            },\n        ],\n    }))\n}\n\n/// Generates a dummy return statement.\npub fn dummy_return_statement(args: &[&str]) -> pre_sierra::Statement {\n    return_statement(as_var_id_vec(args))\n}\n\n/// Generates a dummy label.\npub fn dummy_label(id: usize) -> pre_sierra::Statement {\n    pre_sierra::Statement::Label(pre_sierra::Label { id: label_id_from_usize(id) })\n}\n\n/// Generates a dummy jump to label statement.\npub fn dummy_jump_statement(db: &dyn SierraGenGroup, id: usize) -> pre_sierra::Statement {\n    jump_statement(dummy_concrete_lib_func_id(db, \"jump\"), label_id_from_usize(id))\n}\n\n/// Returns the [pre_sierra::LabelId] for the given `id`.\npub fn label_id_from_usize(id: usize) -> pre_sierra::LabelId {\n    pre_sierra::LabelId::from_intern_id(InternId::from(id))\n}\n\n/// Generates a dummy [PushValues](pre_sierra::Statement::PushValues) statement.\n///\n/// values is a list of pairs (src, dst) where src refers to a variable that should be pushed onto\n/// the stack, and dst is the variable after placing it on the stack.\npub fn dummy_push_values(\n    db: &dyn SierraGenGroup,\n    values: &[(&str, &str)],\n) -> pre_sierra::Statement {\n    dummy_push_values_ex(\n        db,\n        &values.iter().map(|(src, dst)| (*src, *dst, false)).collect::<Vec<_>>(),\n    )\n}\n\n/// Same as [dummy_push_values] except that it also accepts a value for `dup`.\npub fn dummy_push_values_ex(\n    db: &dyn SierraGenGroup,\n    values: &[(&str, &str, bool)],\n) -> pre_sierra::Statement {\n    let felt252_ty =\n        db.get_concrete_type_id(db.core_felt252_ty()).expect(\"Can't find core::felt252.\");\n    pre_sierra::Statement::PushValues(\n        values\n            .iter()\n            .map(|(src, dst, dup)| pre_sierra::PushValue {\n                var: (*src).into(),\n                var_on_stack: (*dst).into(),\n                ty: felt252_ty.clone(),\n                dup: *dup,\n            })\n            .collect(),\n    )\n}\n\n/// Creates a test for a given function that reads test files.\n/// filenames - a vector of tests files the test will apply to.\n/// db - the salsa DB to use for the test.\n/// func - the function to be applied on the test params to generate the tested result.\n/// params - the function parameters. For functions specialized here the parameters can be omitted.\n#[macro_export]\nmacro_rules! diagnostics_test {\n    ($test_name:ident, $filenames:expr, $db:expr, $func:expr, $($param:expr),*) => {\n        #[test]\n        fn $test_name() -> Result<(), std::io::Error> {\n            let mut db = $db;\n            for filename in $filenames{\n                let tests = cairo_lang_utils::parse_test_file::parse_test_file(\n                    std::path::Path::new(filename)\n                )?;\n                for (name, test) in tests {\n                    let test_expr = $func(\n                        &mut db,\n                        $(&test.attributes[$param],)*\n                    )\n                    .unwrap();\n                    verify_exception(&db, test_expr, &test.attributes[\"Expected Result\"], &name);\n                }\n            }\n            Ok(())\n        }\n    };\n\n    ($test_name:ident, $filenames:expr, $db:expr, setup_test_block) => {\n        diagnostics_test!(\n            $test_name,\n            $filenames,\n            $db,\n            setup_test_block,\n            \"Expr Code\",\n            \"Module Code\",\n            \"Function Body\"\n        );\n    };\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_diagnostics::Maybe;\nuse cairo_lang_semantic as semantic;\nuse cairo_lang_semantic::items::enm::SemanticEnumEx;\nuse cairo_lang_semantic::items::structure::SemanticStructEx;\nuse cairo_lang_sierra::extensions::snapshot::snapshot_ty;\nuse cairo_lang_sierra::program::ConcreteTypeLongId;\nuse itertools::chain;\n\nuse crate::db::SierraGenGroup;\nuse crate::specialization_context::SierraSignatureSpecializationContext;\n\n/// Interns and returns the Sierra concrete type id for a user defined struct or enum.\nfn get_user_type_concrete_type_id<GenericArgTyIter: Iterator<Item = semantic::TypeId>>(\n    db: &dyn SierraGenGroup,\n    ty: semantic::ConcreteTypeId,\n    generic_id: cairo_lang_sierra::ids::GenericTypeId,\n    generic_arg_tys: GenericArgTyIter,\n) -> Maybe<cairo_lang_sierra::ids::ConcreteTypeId> {\n    Ok(db.intern_concrete_type(ConcreteTypeLongId {\n        generic_id,\n        generic_args: chain!(\n            [Ok(cairo_lang_sierra::program::GenericArg::UserType(ty.format(db.upcast()).into()))],\n            generic_arg_tys.map(|generic_arg_ty| {\n                Ok(cairo_lang_sierra::program::GenericArg::Type(\n                    db.get_concrete_type_id(generic_arg_ty)?,\n                ))\n            })\n        )\n        .collect::<Maybe<_>>()?,\n    }))\n}\n\n/// See [SierraGenGroup::get_concrete_type_id] for documentation.\npub fn get_concrete_type_id(\n    db: &dyn SierraGenGroup,\n    type_id: semantic::TypeId,\n) -> Maybe<cairo_lang_sierra::ids::ConcreteTypeId> {\n    match db.lookup_intern_type(type_id) {\n        semantic::TypeLongId::Concrete(ty) => {\n            match ty {\n                semantic::ConcreteTypeId::Struct(structure) => get_user_type_concrete_type_id(\n                    db,\n                    ty,\n                    \"Struct\".into(),\n                    db.concrete_struct_members(structure)?.into_iter().map(|(_, member)| member.ty),\n                ),\n                semantic::ConcreteTypeId::Enum(enm) => get_user_type_concrete_type_id(\n                    db,\n                    ty,\n                    \"Enum\".into(),\n                    db.concrete_enum_variants(enm)?.into_iter().map(|variant| variant.ty),\n                ),\n                semantic::ConcreteTypeId::Extern(extrn) => {\n                    Ok(db.intern_concrete_type(ConcreteTypeLongId {\n                        generic_id: cairo_lang_sierra::ids::GenericTypeId::from_string(\n                            // TODO(Gil): Implement name for semantic::ConcreteTypeId\n                            extrn.extern_type_id(db.upcast()).name(db.upcast()),\n                        ),\n                        generic_args: ty\n                            .generic_args(db.upcast())\n                            .into_iter()\n                            .map(|arg| match arg {\n                                semantic::GenericArgumentId::Type(ty) => {\n                                    cairo_lang_sierra::program::GenericArg::Type(\n                                        db.get_concrete_type_id(ty).unwrap(),\n                                    )\n                                }\n                                semantic::GenericArgumentId::Literal(literal_id) => {\n                                    cairo_lang_sierra::program::GenericArg::Value(\n                                        db.lookup_intern_literal(literal_id).value,\n                                    )\n                                }\n                                semantic::GenericArgumentId::Impl(_) => {\n                                    panic!(\"Extern function with impl generics are not supported.\")\n                                }\n                            })\n                            .collect(),\n                    }))\n                }\n            }\n        }\n        semantic::TypeLongId::Tuple(inner_types) => {\n            Ok(db.intern_concrete_type(ConcreteTypeLongId {\n                generic_id: \"Struct\".into(),\n                generic_args: chain!(\n                    [cairo_lang_sierra::program::GenericArg::UserType(\"Tuple\".into())],\n                    inner_types.into_iter().map(|ty| cairo_lang_sierra::program::GenericArg::Type(\n                        db.get_concrete_type_id(ty).unwrap()\n                    ))\n                )\n                .collect(),\n            }))\n        }\n        semantic::TypeLongId::Snapshot(ty) => {\n            let inner_ty = db.get_concrete_type_id(ty).unwrap();\n            Ok(snapshot_ty(&SierraSignatureSpecializationContext(db), inner_ty).unwrap())\n        }\n        semantic::TypeLongId::GenericParameter(_)\n        | semantic::TypeLongId::Var(_)\n        | semantic::TypeLongId::Missing(_) => {\n            panic!(\n                \"Types should be fully resolved at this point. Got: `{}`.\",\n                type_id.format(db.upcast())\n            )\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_debug::DebugWithDb;\nuse cairo_lang_diagnostics::Maybe;\nuse cairo_lang_sierra::extensions::core::CoreLibfunc;\nuse cairo_lang_sierra::extensions::lib_func::LibfuncSignature;\nuse cairo_lang_sierra::extensions::snapshot::SnapshotType;\nuse cairo_lang_sierra::extensions::{\n    ExtensionError, GenericLibfuncEx, NamedType, SpecializationError,\n};\nuse cairo_lang_sierra::ids::{ConcreteLibfuncId, GenericLibfuncId};\nuse cairo_lang_sierra::program;\nuse cairo_lang_utils::extract_matches;\nuse num_bigint::BigInt;\nuse semantic::corelib::get_const_libfunc_name_by_type;\nuse semantic::items::functions::GenericFunctionId;\nuse smol_str::SmolStr;\nuse {cairo_lang_defs as defs, cairo_lang_semantic as semantic};\n\nuse crate::db::SierraGenGroup;\nuse crate::pre_sierra;\nuse crate::replace_ids::{DebugReplacer, SierraIdReplacer};\nuse crate::specialization_context::SierraSignatureSpecializationContext;\n\npub fn simple_statement(\n    libfunc_id: ConcreteLibfuncId,\n    args: &[cairo_lang_sierra::ids::VarId],\n    results: &[cairo_lang_sierra::ids::VarId],\n) -> pre_sierra::Statement {\n    pre_sierra::Statement::Sierra(program::GenStatement::Invocation(program::GenInvocation {\n        libfunc_id,\n        args: args.into(),\n        branches: vec![program::GenBranchInfo {\n            target: program::GenBranchTarget::Fallthrough,\n            results: results.into(),\n        }],\n    }))\n}\n\npub fn jump_statement(\n    jump: ConcreteLibfuncId,\n    label: pre_sierra::LabelId,\n) -> pre_sierra::Statement {\n    pre_sierra::Statement::Sierra(program::GenStatement::Invocation(program::GenInvocation {\n        libfunc_id: jump,\n        args: vec![],\n        branches: vec![program::GenBranchInfo {\n            target: program::GenBranchTarget::Statement(label),\n            results: vec![],\n        }],\n    }))\n}\n\npub fn return_statement(res: Vec<cairo_lang_sierra::ids::VarId>) -> pre_sierra::Statement {\n    pre_sierra::Statement::Sierra(program::GenStatement::Return(res))\n}\n\npub fn get_libfunc_id_with_generic_arg(\n    db: &dyn SierraGenGroup,\n    name: impl Into<SmolStr>,\n    ty: cairo_lang_sierra::ids::ConcreteTypeId,\n) -> cairo_lang_sierra::ids::ConcreteLibfuncId {\n    db.intern_concrete_lib_func(cairo_lang_sierra::program::ConcreteLibfuncLongId {\n        generic_id: cairo_lang_sierra::ids::GenericLibfuncId::from_string(name),\n        generic_args: vec![cairo_lang_sierra::program::GenericArg::Type(ty)],\n    })\n}\n\n/// Returns the [cairo_lang_sierra::program::ConcreteLibfuncLongId] associated with `store_temp`.\npub fn store_temp_libfunc_id(\n    db: &dyn SierraGenGroup,\n    ty: cairo_lang_sierra::ids::ConcreteTypeId,\n) -> cairo_lang_sierra::ids::ConcreteLibfuncId {\n    get_libfunc_id_with_generic_arg(db, \"store_temp\", ty)\n}\n\n/// Returns the [cairo_lang_sierra::program::ConcreteLibfuncLongId] associated with `store_local`.\npub fn store_local_libfunc_id(\n    db: &dyn SierraGenGroup,\n    ty: cairo_lang_sierra::ids::ConcreteTypeId,\n) -> cairo_lang_sierra::ids::ConcreteLibfuncId {\n    get_libfunc_id_with_generic_arg(db, \"store_local\", ty)\n}\n\npub fn struct_construct_libfunc_id(\n    db: &dyn SierraGenGroup,\n    ty: cairo_lang_sierra::ids::ConcreteTypeId,\n) -> cairo_lang_sierra::ids::ConcreteLibfuncId {\n    get_libfunc_id_with_generic_arg(db, \"struct_construct\", ty)\n}\n\npub fn struct_deconstruct_libfunc_id(\n    db: &dyn SierraGenGroup,\n    ty: cairo_lang_sierra::ids::ConcreteTypeId,\n) -> Maybe<cairo_lang_sierra::ids::ConcreteLibfuncId> {\n    let long_id = &db.get_type_info(ty.clone())?.long_id;\n    let is_snapshot = long_id.generic_id == SnapshotType::id();\n    Ok(if is_snapshot {\n        let concrete_enum_type = extract_matches!(\n            &long_id.generic_args[0],\n            cairo_lang_sierra::program::GenericArg::Type\n        )\n        .clone();\n        get_libfunc_id_with_generic_arg(db, \"struct_snapshot_deconstruct\", concrete_enum_type)\n    } else {\n        get_libfunc_id_with_generic_arg(db, \"struct_deconstruct\", ty)\n    })\n}\n\npub fn enum_init_libfunc_id(\n    db: &dyn SierraGenGroup,\n    ty: cairo_lang_sierra::ids::ConcreteTypeId,\n    variant_idx: usize,\n) -> cairo_lang_sierra::ids::ConcreteLibfuncId {\n    db.intern_concrete_lib_func(cairo_lang_sierra::program::ConcreteLibfuncLongId {\n        generic_id: cairo_lang_sierra::ids::GenericLibfuncId::from_string(\"enum_init\"),\n        generic_args: vec![\n            cairo_lang_sierra::program::GenericArg::Type(ty),\n            cairo_lang_sierra::program::GenericArg::Value(variant_idx.into()),\n        ],\n    })\n}\n\n/// Returns the [cairo_lang_sierra::program::ConcreteLibfuncLongId] associated with `snapshot_take`.\npub fn snapshot_take_libfunc_id(\n    db: &dyn SierraGenGroup,\n    ty: cairo_lang_sierra::ids::ConcreteTypeId,\n) -> cairo_lang_sierra::ids::ConcreteLibfuncId {\n    db.intern_concrete_lib_func(cairo_lang_sierra::program::ConcreteLibfuncLongId {\n        generic_id: cairo_lang_sierra::ids::GenericLibfuncId::from_string(\"snapshot_take\"),\n        generic_args: vec![cairo_lang_sierra::program::GenericArg::Type(ty)],\n    })\n}\n\n/// Returns the [cairo_lang_sierra::program::ConcreteLibfuncLongId] associated with `rename`.\npub fn rename_libfunc_id(\n    db: &dyn SierraGenGroup,\n    ty: cairo_lang_sierra::ids::ConcreteTypeId,\n) -> cairo_lang_sierra::ids::ConcreteLibfuncId {\n    db.intern_concrete_lib_func(cairo_lang_sierra::program::ConcreteLibfuncLongId {\n        generic_id: cairo_lang_sierra::ids::GenericLibfuncId::from_string(\"rename\"),\n        generic_args: vec![cairo_lang_sierra::program::GenericArg::Type(ty)],\n    })\n}\n\nfn get_libfunc_id_without_generics(\n    db: &dyn SierraGenGroup,\n    name: impl Into<SmolStr>,\n) -> cairo_lang_sierra::ids::ConcreteLibfuncId {\n    db.intern_concrete_lib_func(cairo_lang_sierra::program::ConcreteLibfuncLongId {\n        generic_id: cairo_lang_sierra::ids::GenericLibfuncId::from_string(name),\n        generic_args: vec![],\n    })\n}\n\npub fn const_libfunc_id_by_type(\n    db: &dyn SierraGenGroup,\n    ty: semantic::TypeId,\n    value: BigInt,\n) -> cairo_lang_sierra::ids::ConcreteLibfuncId {\n    db.intern_concrete_lib_func(cairo_lang_sierra::program::ConcreteLibfuncLongId {\n        generic_id: cairo_lang_sierra::ids::GenericLibfuncId::from_string(\n            get_const_libfunc_name_by_type(db.upcast(), ty),\n        ),\n        generic_args: vec![cairo_lang_sierra::program::GenericArg::Value(value)],\n    })\n}\n\npub fn match_enum_libfunc_id(\n    db: &dyn SierraGenGroup,\n    ty: cairo_lang_sierra::ids::ConcreteTypeId,\n) -> Maybe<cairo_lang_sierra::ids::ConcreteLibfuncId> {\n    let long_id = &db.get_type_info(ty.clone())?.long_id;\n    let is_snapshot = long_id.generic_id == SnapshotType::id();\n    Ok(if is_snapshot {\n        let concrete_enum_type = extract_matches!(\n            &long_id.generic_args[0],\n            cairo_lang_sierra::program::GenericArg::Type\n        )\n        .clone();\n        get_libfunc_id_with_generic_arg(db, \"enum_snapshot_match\", concrete_enum_type)\n    } else {\n        get_libfunc_id_with_generic_arg(db, \"enum_match\", ty)\n    })\n}\n\npub fn drop_libfunc_id(\n    db: &dyn SierraGenGroup,\n    ty: cairo_lang_sierra::ids::ConcreteTypeId,\n) -> cairo_lang_sierra::ids::ConcreteLibfuncId {\n    get_libfunc_id_with_generic_arg(db, \"drop\", ty)\n}\n\npub fn dup_libfunc_id(\n    db: &dyn SierraGenGroup,\n    ty: cairo_lang_sierra::ids::ConcreteTypeId,\n) -> cairo_lang_sierra::ids::ConcreteLibfuncId {\n    get_libfunc_id_with_generic_arg(db, \"dup\", ty)\n}\n\npub fn branch_align_libfunc_id(\n    db: &dyn SierraGenGroup,\n) -> cairo_lang_sierra::ids::ConcreteLibfuncId {\n    get_libfunc_id_without_generics(db, \"branch_align\")\n}\n\npub fn jump_libfunc_id(db: &dyn SierraGenGroup) -> cairo_lang_sierra::ids::ConcreteLibfuncId {\n    get_libfunc_id_without_generics(db, \"jump\")\n}\n\npub fn revoke_ap_tracking_libfunc_id(\n    db: &dyn SierraGenGroup,\n) -> cairo_lang_sierra::ids::ConcreteLibfuncId {\n    get_libfunc_id_without_generics(db, \"revoke_ap_tracking\")\n}\n\npub fn disable_ap_tracking_libfunc_id(\n    db: &dyn SierraGenGroup,\n) -> cairo_lang_sierra::ids::ConcreteLibfuncId {\n    get_libfunc_id_without_generics(db, \"disable_ap_tracking\")\n}\n\npub fn alloc_local_libfunc_id(\n    db: &dyn SierraGenGroup,\n    ty: cairo_lang_sierra::ids::ConcreteTypeId,\n) -> cairo_lang_sierra::ids::ConcreteLibfuncId {\n    get_libfunc_id_with_generic_arg(db, \"alloc_local\", ty)\n}\n\npub fn finalize_locals_libfunc_id(\n    db: &dyn SierraGenGroup,\n) -> cairo_lang_sierra::ids::ConcreteLibfuncId {\n    get_libfunc_id_without_generics(db, \"finalize_locals\")\n}\n\n/// Returns the [LibfuncSignature] of the given function.\npub fn get_libfunc_signature(\n    db: &dyn SierraGenGroup,\n    concrete_lib_func_id: ConcreteLibfuncId,\n) -> LibfuncSignature {\n    let libfunc_long_id = db.lookup_intern_concrete_lib_func(concrete_lib_func_id.clone());\n    CoreLibfunc::specialize_signature_by_id(\n        &SierraSignatureSpecializationContext(db),\n        &libfunc_long_id.generic_id,\n        &libfunc_long_id.generic_args,\n    )\n    .unwrap_or_else(|err| {\n        if let ExtensionError::LibfuncSpecialization {\n            error: SpecializationError::MissingFunction(function),\n            ..\n        } = err\n        {\n            let function = db.lookup_intern_sierra_function(function);\n            panic!(\"Missing function {:?}\", function.debug(db.elongate()));\n        }\n        // If panic happens here, make sure the specified libfunc name is in one of the STR_IDs of\n        // the libfuncs in the [`CoreLibfunc`] structured enum.\n        panic!(\n            \"Failed to specialize: `{}`. Error: {err}\",\n            DebugReplacer { db }.replace_libfunc_id(&concrete_lib_func_id)\n        )\n    })\n}\n\n/// Returns the [ConcreteLibfuncId] for calling a user-defined function.\npub fn function_call_libfunc_id(\n    db: &dyn SierraGenGroup,\n    func: semantic::FunctionId,\n) -> ConcreteLibfuncId {\n    db.intern_concrete_lib_func(cairo_lang_sierra::program::ConcreteLibfuncLongId {\n        generic_id: GenericLibfuncId::from_string(\"function_call\"),\n        generic_args: vec![cairo_lang_sierra::program::GenericArg::UserFunc(\n            db.intern_sierra_function(func),\n        )],\n    })\n}\n\n/// Returns the [ConcreteLibfuncId] used for calling a libfunc.\npub fn generic_libfunc_id(\n    db: &dyn SierraGenGroup,\n    extern_id: defs::ids::ExternFunctionId,\n    generic_args: Vec<cairo_lang_sierra::program::GenericArg>,\n) -> ConcreteLibfuncId {\n    db.intern_concrete_lib_func(cairo_lang_sierra::program::ConcreteLibfuncLongId {\n        generic_id: GenericLibfuncId::from_string(extern_id.name(db.upcast())),\n        generic_args,\n    })\n}\n\n/// Returns the [ConcreteLibfuncId] used for calling a function (either user-defined or libfunc).\npub fn get_concrete_libfunc_id(\n    db: &dyn SierraGenGroup,\n    function: semantic::FunctionId,\n) -> (semantic::ConcreteFunction, ConcreteLibfuncId) {\n    // Check if this is a user-defined function or a libfunc.\n    let concrete_function = db.lookup_intern_function(function).function;\n    match concrete_function.generic_function {\n        GenericFunctionId::Free(_) | GenericFunctionId::Impl(_) => {\n            (concrete_function, function_call_libfunc_id(db, function))\n        }\n        GenericFunctionId::Extern(extern_id) => {\n            let mut generic_args = vec![];\n            for generic_arg in &concrete_function.generic_args {\n                generic_args.push(match generic_arg {\n                    semantic::GenericArgumentId::Type(ty) => {\n                        // TODO(lior): How should the following unwrap() be handled?\n                        cairo_lang_sierra::program::GenericArg::Type(\n                            db.get_concrete_type_id(*ty).unwrap(),\n                        )\n                    }\n                    semantic::GenericArgumentId::Literal(literal_id) => {\n                        cairo_lang_sierra::program::GenericArg::Value(\n                            db.lookup_intern_literal(*literal_id).value,\n                        )\n                    }\n                    semantic::GenericArgumentId::Impl(_) => {\n                        panic!(\"Extern function with impl generics are not supported.\")\n                    }\n                });\n            }\n\n            (concrete_function, generic_libfunc_id(db, extern_id, generic_args))\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashMap;\nuse std::iter;\n\nuse cairo_lang_casm::ap_change::{ApChange, ApChangeError, ApplyApChange};\nuse cairo_lang_sierra::edit_state::{put_results, take_args};\nuse cairo_lang_sierra::ids::{FunctionId, VarId};\nuse cairo_lang_sierra::program::{BranchInfo, Function, StatementIdx};\nuse cairo_lang_utils::unordered_hash_set::UnorderedHashSet;\nuse itertools::zip_eq;\nuse thiserror::Error;\n\nuse crate::environment::ap_tracking::update_ap_tracking;\nuse crate::environment::frame_state::FrameStateError;\nuse crate::environment::gas_wallet::{GasWallet, GasWalletError};\nuse crate::environment::{\n    validate_environment_equality, validate_final_environment, Environment, EnvironmentError,\n};\nuse crate::invocations::{ApTrackingChange, BranchChanges};\nuse crate::metadata::Metadata;\nuse crate::references::{\n    build_function_arguments_refs, check_types_match, IntroductionPoint,\n    OutputReferenceValueIntroductionPoint, ReferenceValue, ReferencesError, StatementRefs,\n};\nuse crate::type_sizes::TypeSizeMap;\n\n#[derive(Error, Debug, Eq, PartialEq)]\npub enum AnnotationError {\n    #[error(\"#{0}: Inconsistent references annotations.\")]\n    InconsistentReferencesAnnotation(StatementIdx),\n    #[error(\"#{source_statement_idx}->#{destination_statement_idx}: Annotation was already set.\")]\n    AnnotationAlreadySet {\n        source_statement_idx: StatementIdx,\n        destination_statement_idx: StatementIdx,\n    },\n    #[error(\"#{statement_idx}: {error}\")]\n    InconsistentEnvironments { statement_idx: StatementIdx, error: EnvironmentError },\n    #[error(\"#{statement_idx}: Belongs to two different functions.\")]\n    InconsistentFunctionId { statement_idx: StatementIdx },\n    #[error(\"#{statement_idx}: Invalid convergence.\")]\n    InvalidConvergence { statement_idx: StatementIdx },\n    #[error(\"InvalidStatementIdx\")]\n    InvalidStatementIdx,\n    #[error(\"MissingAnnotationsForStatement\")]\n    MissingAnnotationsForStatement(StatementIdx),\n    #[error(\"#{statement_idx}: {var_id} is undefined.\")]\n    MissingReferenceError { statement_idx: StatementIdx, var_id: VarId },\n    #[error(\"#{source_statement_idx}->#{destination_statement_idx}: {var_id} was overridden.\")]\n    OverrideReferenceError {\n        source_statement_idx: StatementIdx,\n        destination_statement_idx: StatementIdx,\n        var_id: VarId,\n    },\n    #[error(transparent)]\n    FrameStateError(#[from] FrameStateError),\n    #[error(\"#{source_statement_idx}->#{destination_statement_idx}: {error}\")]\n    GasWalletError {\n        source_statement_idx: StatementIdx,\n        destination_statement_idx: StatementIdx,\n        error: GasWalletError,\n    },\n    #[error(\"#{statement_idx}: {error}\")]\n    ReferencesError { statement_idx: StatementIdx, error: ReferencesError },\n    #[error(\"#{statement_idx}: Attempting to enable ap tracking when already enabled.\")]\n    ApTrackingAlreadyEnabled { statement_idx: StatementIdx },\n    #[error(\n        \"#{source_statement_idx}->#{destination_statement_idx}: Got '{error}' error while moving \\\n         {var_id}.\"\n    )]\n    ApChangeError {\n        var_id: VarId,\n        source_statement_idx: StatementIdx,\n        destination_statement_idx: StatementIdx,\n        error: ApChangeError,\n    },\n    #[error(\"#{source_statement_idx} -> #{destination_statement_idx}: Ap tracking error\")]\n    ApTrackingError {\n        source_statement_idx: StatementIdx,\n        destination_statement_idx: StatementIdx,\n        error: ApChangeError,\n    },\n    #[error(\"#{statement_idx}: Invalid Ap change annotation. expected: {expected} got: {actual}.\")]\n    InvalidApChangeAnnotation { statement_idx: StatementIdx, expected: ApChange, actual: ApChange },\n}\n\n/// Annotation that represent the state at each program statement.\n#[derive(Clone, Debug)]\npub struct StatementAnnotations {\n    pub refs: StatementRefs,\n    /// The function id that the statement belongs to.\n    pub function_id: FunctionId,\n    /// Indicates whether convergence in allowed in the given statement.\n    pub convergence_allowed: bool,\n    pub environment: Environment,\n}\n\n/// Annotations of the program statements.\n/// See StatementAnnotations.\npub struct ProgramAnnotations {\n    /// Optional per statement annotation.\n    per_statement_annotations: Vec<Option<StatementAnnotations>>,\n}\nimpl ProgramAnnotations {\n    fn new(n_statements: usize) -> Self {\n        ProgramAnnotations {\n            per_statement_annotations: iter::repeat_with(|| None).take(n_statements).collect(),\n        }\n    }\n\n    /// Creates a ProgramAnnotations object based on 'n_statements', a given functions list\n    /// and metadata for the program.\n    pub fn create(\n        n_statements: usize,\n        functions: &[Function],\n        metadata: &Metadata,\n        gas_usage_check: bool,\n        type_sizes: &TypeSizeMap,\n    ) -> Result<Self, AnnotationError> {\n        let mut annotations = ProgramAnnotations::new(n_statements);\n        for func in functions {\n            annotations.set_or_assert(\n                func.entry_point,\n                StatementAnnotations {\n                    refs: build_function_arguments_refs(func, type_sizes).map_err(|error| {\n                        AnnotationError::ReferencesError { statement_idx: func.entry_point, error }\n                    })?,\n                    function_id: func.id.clone(),\n                    convergence_allowed: false,\n                    environment: Environment::new(\n                        if gas_usage_check {\n                            GasWallet::Value(\n                                metadata.gas_info.function_costs[func.id.clone()].clone(),\n                            )\n                        } else {\n                            GasWallet::Disabled\n                        },\n                        func.entry_point,\n                    ),\n                },\n            )?\n        }\n\n        Ok(annotations)\n    }\n\n    /// Sets the annotations at 'statement_idx' to 'annotations'\n    /// If the annotations for this statement were set previously asserts that the previous\n    /// assignment is consistent with the new assignment and verifies that convergence_allowed\n    /// is true.\n    pub fn set_or_assert(\n        &mut self,\n        statement_idx: StatementIdx,\n        annotations: StatementAnnotations,\n    ) -> Result<(), AnnotationError> {\n        let idx = statement_idx.0;\n        match self.per_statement_annotations.get(idx).ok_or(AnnotationError::InvalidStatementIdx)? {\n            None => self.per_statement_annotations[idx] = Some(annotations),\n            Some(expected_annotations) => {\n                if expected_annotations.function_id != annotations.function_id {\n                    return Err(AnnotationError::InconsistentFunctionId { statement_idx });\n                }\n                validate_environment_equality(\n                    &expected_annotations.environment,\n                    &annotations.environment,\n                )\n                .map_err(|error| AnnotationError::InconsistentEnvironments {\n                    statement_idx,\n                    error,\n                })?;\n                if !self.test_references_consistency(&annotations, expected_annotations) {\n                    return Err(AnnotationError::InconsistentReferencesAnnotation(statement_idx));\n                }\n\n                // Note that we ignore annotations here.\n                // a flow cannot converge with a branch target.\n                if !expected_annotations.convergence_allowed {\n                    return Err(AnnotationError::InvalidConvergence { statement_idx });\n                }\n            }\n        };\n        Ok(())\n    }\n\n    /// Returns whether or not `actual` and `expected` references are consistent.\n    fn test_references_consistency(\n        &self,\n        actual: &StatementAnnotations,\n        expected: &StatementAnnotations,\n    ) -> bool {\n        // Check if there is a mismatch at the number of variables.\n        if actual.refs.len() != expected.refs.len() {\n            return false;\n        }\n        for (var_id, ReferenceValue { expression, ty, stack_idx, introduction_point }) in\n            actual.refs.iter()\n        {\n            // Check if var exists in just one of the branches.\n            let Some(expected_ref) = expected.refs.get(var_id) else {\n                return false;\n            };\n            // Check if var don't match on type, expression or stack information.\n            if *ty != expected_ref.ty\n                || *expression != expected_ref.expression\n                || *stack_idx != expected_ref.stack_idx\n            {\n                return false;\n            }\n            // If the variable is not on stack.\n            if stack_idx.is_none()\n                // And is either empty, or somewhat ap-dependent.\n                && (expression.cells.is_empty() || !expression.can_apply_unknown())\n                // Check that the introduction point the variable matches in both branches - so it\n                // must have appeared before the divergence point.\n                && (*introduction_point != expected_ref.introduction_point)\n            {\n                return false;\n            }\n        }\n        true\n    }\n\n    /// Returns the result of applying take_args to the StatementAnnotations at statement_idx.\n    pub fn get_annotations_after_take_args<'a>(\n        &self,\n        statement_idx: StatementIdx,\n        ref_ids: impl Iterator<Item = &'a VarId>,\n    ) -> Result<(StatementAnnotations, Vec<ReferenceValue>), AnnotationError> {\n        let statement_annotations = self.per_statement_annotations[statement_idx.0]\n            .as_ref()\n            .ok_or(AnnotationError::MissingAnnotationsForStatement(statement_idx))?\n            .clone();\n\n        let (statement_refs, taken_refs) =\n            take_args(statement_annotations.refs, ref_ids).map_err(|error| {\n                AnnotationError::MissingReferenceError { statement_idx, var_id: error.var_id() }\n            })?;\n        Ok((StatementAnnotations { refs: statement_refs, ..statement_annotations }, taken_refs))\n    }\n\n    /// Propagates the annotations from `statement_idx` to 'destination_statement_idx'.\n\n    /// `annotations` is the result of calling get_annotations_after_take_args at\n    /// `source_statement_idx` and `branch_changes` are the reference changes at each branch.\n    ///  if `must_set` is true, asserts that destination_statement_idx wasn't annotated before.\n    pub fn propagate_annotations(\n        &mut self,\n        source_statement_idx: StatementIdx,\n        destination_statement_idx: StatementIdx,\n        annotations: &StatementAnnotations,\n        branch_info: &BranchInfo,\n        branch_changes: BranchChanges,\n        must_set: bool,\n    ) -> Result<(), AnnotationError> {\n        if must_set && self.per_statement_annotations[destination_statement_idx.0].is_some() {\n            return Err(AnnotationError::AnnotationAlreadySet {\n                source_statement_idx,\n                destination_statement_idx,\n            });\n        }\n\n        let mut new_refs: StatementRefs =\n            HashMap::with_capacity(annotations.refs.len() + branch_changes.refs.len());\n        for (var_id, ref_value) in &annotations.refs {\n            new_refs.insert(\n                var_id.clone(),\n                ReferenceValue {\n                    expression: ref_value\n                        .expression\n                        .clone()\n                        .apply_ap_change(branch_changes.ap_change)\n                        .map_err(|error| AnnotationError::ApChangeError {\n                            var_id: var_id.clone(),\n                            source_statement_idx,\n                            destination_statement_idx,\n                            error,\n                        })?,\n                    ty: ref_value.ty.clone(),\n                    stack_idx: if branch_changes.clear_old_stack {\n                        None\n                    } else {\n                        ref_value.stack_idx\n                    },\n                    introduction_point: ref_value.introduction_point.clone(),\n                },\n            );\n        }\n        let mut refs = put_results(\n            new_refs,\n            zip_eq(\n                &branch_info.results,\n                branch_changes.refs.into_iter().map(|value| ReferenceValue {\n                    expression: value.expression,\n                    ty: value.ty,\n                    stack_idx: value.stack_idx,\n                    introduction_point: match value.introduction_point {\n                        OutputReferenceValueIntroductionPoint::New(output_idx) => {\n                            IntroductionPoint {\n                                statement_idx: destination_statement_idx,\n                                output_idx,\n                            }\n                        }\n                        OutputReferenceValueIntroductionPoint::Existing(introduction_point) => {\n                            introduction_point\n                        }\n                    },\n                }),\n            ),\n        )\n        .map_err(|error| AnnotationError::OverrideReferenceError {\n            source_statement_idx,\n            destination_statement_idx,\n            var_id: error.var_id(),\n        })?;\n        let available_stack_indices: UnorderedHashSet<_> =\n            refs.values().flat_map(|r| r.stack_idx).collect();\n        let stack_size = if let Some(new_stack_size) = (0..branch_changes.new_stack_size)\n            .find(|i| !available_stack_indices.contains(&(branch_changes.new_stack_size - 1 - i)))\n        {\n            let stack_removal = branch_changes.new_stack_size - new_stack_size;\n            for r in refs.values_mut() {\n                r.stack_idx =\n                    r.stack_idx.and_then(|stack_idx| stack_idx.checked_sub(stack_removal));\n            }\n            new_stack_size\n        } else {\n            branch_changes.new_stack_size\n        };\n        let ap_tracking = match branch_changes.ap_tracking_change {\n            ApTrackingChange::Disable => ApChange::Unknown,\n            ApTrackingChange::Enable => {\n                if !matches!(annotations.environment.ap_tracking, ApChange::Unknown) {\n                    return Err(AnnotationError::ApTrackingAlreadyEnabled {\n                        statement_idx: source_statement_idx,\n                    });\n                }\n                ApChange::Known(0)\n            }\n            _ => update_ap_tracking(annotations.environment.ap_tracking, branch_changes.ap_change)\n                .map_err(|error| AnnotationError::ApTrackingError {\n                    source_statement_idx,\n                    destination_statement_idx,\n                    error,\n                })?,\n        };\n        let ap_tracking_base = if matches!(ap_tracking, ApChange::Unknown) {\n            // Unknown ap tracking - we don't have a base.\n            None\n        } else if matches!(annotations.environment.ap_tracking, ApChange::Unknown) {\n            // Ap tracking was changed from unknown to known; meaning ap tracking was just enabled -\n            // the new destination is the base.\n            Some(destination_statement_idx)\n        } else {\n            // Was previously enabled but still is - keeping the same base.\n            annotations.environment.ap_tracking_base\n        };\n        self.set_or_assert(\n            destination_statement_idx,\n            StatementAnnotations {\n                refs,\n                function_id: annotations.function_id.clone(),\n                convergence_allowed: !must_set,\n                environment: Environment {\n                    ap_tracking,\n                    ap_tracking_base,\n                    stack_size,\n                    frame_state: annotations.environment.frame_state.clone(),\n                    gas_wallet: annotations\n                        .environment\n                        .gas_wallet\n                        .update(branch_changes.gas_change)\n                        .map_err(|error| AnnotationError::GasWalletError {\n                            source_statement_idx,\n                            destination_statement_idx,\n                            error,\n                        })?,\n                },\n            },\n        )\n    }\n\n    /// Validates the ap change and return types in a return statement.\n    pub fn validate_return_properties(\n        &self,\n        statement_idx: StatementIdx,\n        annotations: &StatementAnnotations,\n        functions: &[Function],\n        metadata: &Metadata,\n        return_refs: &[ReferenceValue],\n    ) -> Result<(), AnnotationError> {\n        // TODO(ilya): Don't use linear search.\n        let func = &functions.iter().find(|func| func.id == annotations.function_id).unwrap();\n\n        let expected_ap_change = match metadata.ap_change_info.function_ap_change.get(&func.id) {\n            Some(x) => ApChange::Known(*x),\n            _ => ApChange::Unknown,\n        };\n\n        if expected_ap_change != ApChange::Unknown\n            && expected_ap_change != annotations.environment.ap_tracking\n        {\n            return Err(AnnotationError::InvalidApChangeAnnotation {\n                statement_idx,\n                expected: expected_ap_change,\n                actual: annotations.environment.ap_tracking,\n            });\n        }\n\n        // Checks that the list of return reference contains has the expected types.\n        check_types_match(return_refs, &func.signature.ret_types)\n            .map_err(|error| AnnotationError::ReferencesError { statement_idx, error })?;\n        Ok(())\n    }\n\n    /// Validates the final annotation in a return statement.\n    pub fn validate_final_annotations(\n        &self,\n        statement_idx: StatementIdx,\n        annotations: &StatementAnnotations,\n        functions: &[Function],\n        metadata: &Metadata,\n        return_refs: &[ReferenceValue],\n    ) -> Result<(), AnnotationError> {\n        self.validate_return_properties(\n            statement_idx,\n            annotations,\n            functions,\n            metadata,\n            return_refs,\n        )?;\n        validate_final_environment(&annotations.environment)\n            .map_err(|error| AnnotationError::InconsistentEnvironments { statement_idx, error })\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::fs;\n\nuse anyhow::Context;\nuse cairo_lang_sierra::ProgramParser;\nuse cairo_lang_sierra_to_casm::metadata::calc_metadata;\nuse cairo_lang_utils::logging::init_logging;\nuse clap::Parser;\nuse indoc::indoc;\n\n/// Command line args parser.\n/// Exits with 0/1 if the input is formatted correctly/incorrectly.\n#[derive(Parser, Debug)]\n#[clap(version, verbatim_doc_comment)]\nstruct Args {\n    /// The file to compile\n    file: String,\n    output: String,\n}\n\nfn main() -> anyhow::Result<()> {\n    init_logging(log::LevelFilter::Off);\n    log::info!(\"Starting Sierra compilation.\");\n\n    let args = Args::parse();\n\n    let sierra_code = fs::read_to_string(args.file).with_context(|| \"Could not read file!\")?;\n    let Ok(program) = ProgramParser::new().parse(&sierra_code) else {\n        anyhow::bail!(indoc!{\"\n            Failed to parse sierra program.\n            Note: StarkNet contracts should be compiled with `starknet-sierra-compile`.\"\n    })};\n\n    let gas_usage_check = true;\n    let cairo_program = cairo_lang_sierra_to_casm::compiler::compile(\n        &program,\n        &calc_metadata(&program, Default::default())\n            .with_context(|| \"Failed calculating Sierra variables.\")?,\n        gas_usage_check,\n    )\n    .with_context(|| \"Compilation failed.\")?;\n\n    fs::write(args.output, format!(\"{cairo_program}\")).with_context(|| \"Failed to write output.\")\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::fmt::Display;\n\nuse cairo_lang_casm::instructions::{Instruction, InstructionBody, RetInstruction};\nuse cairo_lang_sierra::extensions::core::{CoreConcreteLibfunc, CoreLibfunc, CoreType};\nuse cairo_lang_sierra::extensions::lib_func::SierraApChange;\nuse cairo_lang_sierra::extensions::ConcreteLibfunc;\nuse cairo_lang_sierra::ids::VarId;\nuse cairo_lang_sierra::program::{BranchTarget, Invocation, Program, Statement, StatementIdx};\nuse cairo_lang_sierra::program_registry::{ProgramRegistry, ProgramRegistryError};\nuse itertools::zip_eq;\nuse thiserror::Error;\n\nuse crate::annotations::{AnnotationError, ProgramAnnotations, StatementAnnotations};\nuse crate::invocations::{\n    check_references_on_stack, compile_invocation, InvocationError, ProgramInfo,\n};\nuse crate::metadata::Metadata;\nuse crate::references::{check_types_match, ReferencesError};\nuse crate::relocations::{relocate_instructions, RelocationEntry};\nuse crate::type_sizes::get_type_size_map;\n\n#[cfg(test)]\n#[path = \"compiler_test.rs\"]\nmod test;\n\n#[derive(Error, Debug, Eq, PartialEq)]\npub enum CompilationError {\n    #[error(\"Failed building type information\")]\n    FailedBuildingTypeInformation,\n    #[error(\"Error from program registry\")]\n    ProgramRegistryError(Box<ProgramRegistryError>),\n    #[error(transparent)]\n    AnnotationError(#[from] AnnotationError),\n    #[error(\"#{statement_idx}: {error}\")]\n    InvocationError { statement_idx: StatementIdx, error: InvocationError },\n    #[error(\"#{statement_idx}: Return arguments are not on the stack.\")]\n    ReturnArgumentsNotOnStack { statement_idx: StatementIdx },\n    #[error(\"#{statement_idx}: {error}\")]\n    ReferencesError { statement_idx: StatementIdx, error: ReferencesError },\n    #[error(\"#{statement_idx}: Invocation mismatched to libfunc\")]\n    LibfuncInvocationMismatch { statement_idx: StatementIdx },\n    #[error(\"{var_id} is dangling at #{statement_idx}.\")]\n    DanglingReferences { statement_idx: StatementIdx, var_id: VarId },\n\n    #[error(\"#{source_statement_idx}->#{destination_statement_idx}: Expected branch align\")]\n    ExpectedBranchAlign {\n        source_statement_idx: StatementIdx,\n        destination_statement_idx: StatementIdx,\n    },\n}\n\n/// The casm program representation.\n#[derive(Debug, Eq, PartialEq)]\npub struct CairoProgram {\n    pub instructions: Vec<Instruction>,\n    pub debug_info: CairoProgramDebugInfo,\n}\nimpl Display for CairoProgram {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        for instruction in &self.instructions {\n            writeln!(f, \"{instruction};\")?\n        }\n        Ok(())\n    }\n}\n\n/// The debug information of a compilation from Sierra to casm.\n#[derive(Debug, Eq, PartialEq)]\npub struct SierraStatementDebugInfo {\n    /// The offset of the sierra statement within the bytecode.\n    pub code_offset: usize,\n}\n\n/// The debug information of a compilation from Sierra to casm.\n#[derive(Debug, Eq, PartialEq)]\npub struct CairoProgramDebugInfo {\n    /// The debug information per Sierra statement.\n    pub sierra_statement_info: Vec<SierraStatementDebugInfo>,\n}\n\n/// Ensure the basic structure of the invocation is the same as the library function.\npub fn check_basic_structure(\n    statement_idx: StatementIdx,\n    invocation: &Invocation,\n    libfunc: &CoreConcreteLibfunc,\n) -> Result<(), CompilationError> {\n    if invocation.args.len() != libfunc.param_signatures().len()\n        || !itertools::equal(\n            invocation.branches.iter().map(|branch| branch.results.len()),\n            libfunc.output_types().iter().map(|types| types.len()),\n        )\n        || match libfunc.fallthrough() {\n            Some(expected_fallthrough) => {\n                invocation.branches[expected_fallthrough].target != BranchTarget::Fallthrough\n            }\n            None => false,\n        }\n    {\n        Err(CompilationError::LibfuncInvocationMismatch { statement_idx })\n    } else {\n        Ok(())\n    }\n}\n\npub fn compile(\n    program: &Program,\n    metadata: &Metadata,\n    gas_usage_check: bool,\n) -> Result<CairoProgram, Box<CompilationError>> {\n    let mut instructions = Vec::new();\n    let mut relocations: Vec<RelocationEntry> = Vec::new();\n\n    // Maps statement_idx to program_offset. The last value (for statement_idx=number-of-statements)\n    // contains the final offset (the size of the program code segment).\n    let mut statement_offsets = Vec::with_capacity(program.statements.len());\n\n    let registry = ProgramRegistry::<CoreType, CoreLibfunc>::with_ap_change(\n        program,\n        metadata.ap_change_info.function_ap_change.clone(),\n    )\n    .map_err(CompilationError::ProgramRegistryError)?;\n    let type_sizes = get_type_size_map(program, &registry)\n        .ok_or(CompilationError::FailedBuildingTypeInformation)?;\n    let mut program_annotations = ProgramAnnotations::create(\n        program.statements.len(),\n        &program.funcs,\n        metadata,\n        gas_usage_check,\n        &type_sizes,\n    )\n    .map_err(|err| Box::new(err.into()))?;\n\n    let mut program_offset: usize = 0;\n\n    for (statement_id, statement) in program.statements.iter().enumerate() {\n        let statement_idx = StatementIdx(statement_id);\n        statement_offsets.push(program_offset);\n        match statement {\n            Statement::Return(ref_ids) => {\n                let (annotations, return_refs) = program_annotations\n                    .get_annotations_after_take_args(statement_idx, ref_ids.iter())\n                    .map_err(|err| Box::new(err.into()))?;\n\n                if let Some(var_id) = annotations.refs.keys().next() {\n                    return Err(Box::new(CompilationError::DanglingReferences {\n                        statement_idx,\n                        var_id: var_id.clone(),\n                    }));\n                };\n\n                program_annotations\n                    .validate_final_annotations(\n                        statement_idx,\n                        &annotations,\n                        &program.funcs,\n                        metadata,\n                        &return_refs,\n                    )\n                    .map_err(|err| Box::new(err.into()))?;\n                check_references_on_stack(&return_refs).map_err(|error| match error {\n                    InvocationError::InvalidReferenceExpressionForArgument => {\n                        CompilationError::ReturnArgumentsNotOnStack { statement_idx }\n                    }\n                    _ => CompilationError::InvocationError { statement_idx, error },\n                })?;\n\n                let ret_instruction = RetInstruction {};\n                program_offset += ret_instruction.op_size();\n                instructions.push(Instruction::new(InstructionBody::Ret(ret_instruction), false));\n            }\n            Statement::Invocation(invocation) => {\n                let (annotations, invoke_refs) = program_annotations\n                    .get_annotations_after_take_args(statement_idx, invocation.args.iter())\n                    .map_err(|err| Box::new(err.into()))?;\n\n                let libfunc = registry\n                    .get_libfunc(&invocation.libfunc_id)\n                    .map_err(CompilationError::ProgramRegistryError)?;\n                check_basic_structure(statement_idx, invocation, libfunc)?;\n\n                let param_types: Vec<_> = libfunc\n                    .param_signatures()\n                    .iter()\n                    .map(|param_signature| param_signature.ty.clone())\n                    .collect();\n                check_types_match(&invoke_refs, &param_types).map_err(|error| {\n                    Box::new(AnnotationError::ReferencesError { statement_idx, error }.into())\n                })?;\n                let compiled_invocation = compile_invocation(\n                    ProgramInfo { metadata, type_sizes: &type_sizes },\n                    invocation,\n                    libfunc,\n                    statement_idx,\n                    &invoke_refs,\n                    annotations.environment,\n                )\n                .map_err(|error| CompilationError::InvocationError { statement_idx, error })?;\n\n                for instruction in &compiled_invocation.instructions {\n                    program_offset += instruction.body.op_size();\n                }\n\n                for entry in compiled_invocation.relocations {\n                    relocations.push(RelocationEntry {\n                        instruction_idx: instructions.len() + entry.instruction_idx,\n                        relocation: entry.relocation,\n                    });\n                }\n                instructions.extend(compiled_invocation.instructions);\n\n                let updated_annotations = StatementAnnotations {\n                    environment: compiled_invocation.environment,\n                    ..annotations\n                };\n\n                let branching_libfunc = compiled_invocation.results.len() > 1;\n\n                for (branch_info, branch_changes) in\n                    zip_eq(&invocation.branches, compiled_invocation.results)\n                {\n                    let destination_statement_idx = statement_idx.next(&branch_info.target);\n                    if branching_libfunc\n                        && !is_branch_align(\n                            &registry,\n                            &program.statements[destination_statement_idx.0],\n                        )?\n                    {\n                        return Err(Box::new(CompilationError::ExpectedBranchAlign {\n                            source_statement_idx: statement_idx,\n                            destination_statement_idx,\n                        }));\n                    }\n\n                    program_annotations\n                        .propagate_annotations(\n                            statement_idx,\n                            destination_statement_idx,\n                            &updated_annotations,\n                            branch_info,\n                            branch_changes,\n                            branching_libfunc,\n                        )\n                        .map_err(|err| Box::new(err.into()))?;\n                }\n            }\n        }\n    }\n\n    // Push the final offset at the end of `statement_offsets`.\n    statement_offsets.push(program_offset);\n\n    relocate_instructions(&relocations, &statement_offsets, &mut instructions);\n\n    Ok(CairoProgram {\n        instructions,\n        debug_info: CairoProgramDebugInfo {\n            sierra_statement_info: statement_offsets\n                .into_iter()\n                .map(|code_offset| SierraStatementDebugInfo { code_offset })\n                .collect(),\n        },\n    })\n}\n\n/// Returns true if `statement` is an invocation of the branch_align libfunc.\nfn is_branch_align(\n    registry: &ProgramRegistry<CoreType, CoreLibfunc>,\n    statement: &Statement,\n) -> Result<bool, CompilationError> {\n    if let Statement::Invocation(invocation) = statement {\n        let libfunc = registry\n            .get_libfunc(&invocation.libfunc_id)\n            .map_err(CompilationError::ProgramRegistryError)?;\n        if let [branch_signature] = libfunc.branch_signatures() {\n            if branch_signature.ap_change == SierraApChange::BranchAlign {\n                return Ok(true);\n            }\n        }\n    }\n\n    Ok(false)\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_sierra::ProgramParser;\nuse indoc::indoc;\nuse pretty_assertions;\nuse test_case::test_case;\n\nuse crate::compiler::compile;\nuse crate::test_utils::{build_metadata, read_sierra_example_file, strip_comments_and_linebreaks};\n\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n                type NonZeroFelt252 = NonZero<felt252>;\n                type BoxFelt252 = Box<felt252>;\n\n                libfunc branch_align = branch_align;\n                libfunc finalize_locals = finalize_locals;\n                libfunc felt252_add = felt252_add;\n                libfunc felt252_mul_2 = felt252_mul_const<2>;\n                libfunc felt252_sub = felt252_sub;\n                libfunc felt252_dup = dup<felt252>;\n                libfunc felt252_is_zero = felt252_is_zero;\n                libfunc felt252_into_box = into_box<felt252>;\n                libfunc felt252_unbox = unbox<felt252>;\n                libfunc jump = jump;\n                libfunc felt252_unwrap_non_zero = unwrap_non_zero<felt252>;\n                libfunc store_temp_felt252 = store_temp<felt252>;\n                libfunc store_temp_box_felt252 = store_temp<BoxFelt252>;\n                libfunc rename_felt252 = rename<felt252>;\n                libfunc call_foo = function_call<user@foo>;\n\n                libfunc call_box_and_back = function_call<user@box_and_back>;\n\n                rename_felt252([1]) -> ([1]);                      // #0\n                felt252_dup([2]) -> ([2], [5]);                    // #1\n                felt252_add([1], [2]) -> ([3]);                    // #2\n                store_temp_felt252([3]) -> ([4]);                  // #3\n                store_temp_felt252([5]) -> ([5]);                  // #4\n                store_temp_felt252([4]) -> ([4]);                  // #5\n                call_foo([5], [4]) -> ([7], [8]);                  // #6\n                felt252_dup([8]) -> ([4], [8]);                    // #7\n                store_temp_felt252([4]) -> ([4]);                  // #8\n                return([7], [8], [4]);                             // #9\n\n                finalize_locals() -> ();                           // #10\n                felt252_is_zero([1]) { fallthrough() 17([1]) };    // #11\n                branch_align() -> ();                              // #12\n                felt252_dup([2]) -> ([1], [2]);                    // #13\n                store_temp_felt252([1]) -> ([1]);                  // #14\n                store_temp_felt252([2]) -> ([2]);                  // #15\n                return ([1], [2]);                                 // #16\n\n                branch_align() -> ();                              // #17\n                jump() { 19() };                                   // #18\n                felt252_unwrap_non_zero([1]) -> ([1]);                   // #19\n                felt252_dup([2]) -> ([2], [3]);                    // #20\n                felt252_sub([1], [3]) -> ([1]);                    // #21\n                store_temp_felt252([1]) -> ([1]);                  // #22\n                felt252_mul_2([1]) -> ([1]);                       // #23\n                store_temp_felt252([1]) -> ([1]);                  // #24\n                store_temp_felt252([2]) -> ([2]);                  // #25\n                call_foo([1], [2]) -> ([1], [2]);                  // #26\n                return ([1], [2]);                                 // #27\n\n                felt252_into_box([1]) -> ([2]);                    // #28\n                store_temp_box_felt252([2]) -> ([2]);              // #29\n                felt252_unbox([2]) -> ([3]);                       // #30\n                store_temp_felt252([3]) -> ([3]);                  // #31\n                return ([3]);                                      // #32\n\n                store_temp_felt252([1]) -> ([1]);                  // #33\n                call_box_and_back([1]) -> ([1]);                   // #34\n                return ([1]);                                      // #35\n\n                test_program@0([1]: felt252, [2]: felt252) -> (felt252, felt252, felt252);\n                foo@10([1]: felt252, [2]: felt252) -> (felt252, felt252);\n                box_and_back@28([1]: felt252) -> (felt252);\n                box_and_back_wrapper@33([1]: felt252) -> (felt252);\n            \"},\n            false,\n            indoc! {\"\n                // test_program:\n                [ap + 0] = [fp + -4] + [fp + -3], ap++;\n                [ap + 0] = [fp + -3], ap++;\n                [ap + 0] = [ap + -2], ap++;\n                // call foo\n                call rel 4;\n                [ap + 0] = [ap + -1], ap++;\n                ret;\n\n                // foo:\n                ap += 0;\n                jmp rel 5 if [fp + -4] != 0;\n                [ap + 0] = [fp + -3], ap++;\n                [ap + 0] = [fp + -3], ap++;\n                ret;\n                jmp rel 2;\n                [fp + -4] = [ap + 0] + [fp + -3], ap++;\n                [ap + 0] = [ap + -1] * 2, ap++;\n                [ap + 0] = [fp + -3], ap++;\n                call rel -13;\n                ret;\n\n                // box_and_back:\n                %{\n                if '__boxed_segment' not in globals():\n                    __boxed_segment = segments.add()\n                memory[ap + 0] = __boxed_segment\n                __boxed_segment += 1\n                %}\n                [fp + -3] = [[ap + 0] + 0], ap++;\n                [ap + 0] = [ap + -1], ap++;\n                [ap + 0] = [[ap + -1] + 0], ap++;\n                ret;\n\n                // box_and_back_wrapper:\n                [ap + 0] = [fp + -3], ap++;\n                call rel -5;\n                ret;\n            \"};\n            \"good_flow\")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n                type UninitializedFelt252 = Uninitialized<felt252>;\n                type ArrayFelt252 = Array<felt252>;\n                type UninitializedArrayFelt252 = Uninitialized<ArrayFelt252>;\n\n                libfunc finalize_locals = finalize_locals;\n                libfunc alloc_local_felt252 = alloc_local<felt252>;\n                libfunc store_local_felt252 = store_local<felt252>;\n                libfunc alloc_local_array_felt252 = alloc_local<ArrayFelt252>;\n                libfunc store_local_array_felt252 = store_local<ArrayFelt252>;\n                libfunc store_temp_felt252 = store_temp<felt252>;\n                libfunc store_temp_array_felt252 = store_temp<ArrayFelt252>;\n\n                store_temp_felt252([1]) -> ([1]);\n                alloc_local_felt252() -> ([4]);\n                alloc_local_felt252() -> ([5]);\n                alloc_local_array_felt252() -> ([6]);\n                store_local_felt252([4], [1]) -> ([4]);\n                finalize_locals() -> ();\n                store_local_felt252([5], [2]) -> ([5]);\n                store_local_array_felt252([6], [3]) -> ([6]);\n                store_temp_felt252([4]) -> ([4]);\n                store_temp_felt252([5]) -> ([5]);\n                store_temp_array_felt252([6]) -> ([6]);\n                return ([4], [5], [6]);\n\n                test_program@0([1]: felt252, [2]: felt252, [3]: ArrayFelt252) -> (felt252, felt252, ArrayFelt252);\n            \"},\n            false,\n            indoc! {\"\n                [ap + 0] = [fp + -6], ap++;\n                [fp + 1] = [ap + -1];\n                ap += 4;\n                [fp + 2] = [fp + -5];\n                [fp + 3] = [fp + -4];\n                [fp + 4] = [fp + -3];\n                [ap + 0] = [fp + 1], ap++;\n                [ap + 0] = [fp + 2], ap++;\n                [ap + 0] = [fp + 3], ap++;\n                [ap + 0] = [fp + 4], ap++;\n                ret;\n            \"};\n            \"alloc_local and store_local\")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n                type NonZeroFelt252 = NonZero<felt252>;\n\n                libfunc branch_align = branch_align;\n                libfunc jump = jump;\n                libfunc store_temp_nz_felt252 = store_temp<NonZeroFelt252>;\n                libfunc nz_felt252_drop = drop<NonZeroFelt252>;\n                libfunc felt252_is_zero = felt252_is_zero;\n\n                felt252_is_zero([1]) { fallthrough() 3([1]) };\n                branch_align() -> ();\n                return ();\n                branch_align() -> ();\n                store_temp_nz_felt252([1]) -> ([1]);\n                nz_felt252_drop([1]) -> ();\n                return ();\n\n                test_program@0([1]: felt252) -> ();\n            \"},\n            true,\n            indoc! {\"\n                jmp rel 5 if [fp + -3] != 0;\n                ap += 1;\n                ret;\n                [ap + 0] = [fp + -3], ap++;\n                ret;\n            \"};\n            \"branch align\")]\n#[test_case(indoc!{\"\n                type RangeCheck = RangeCheck;\n                type u128 = u128;\n\n                libfunc revoke_ap_tracking = revoke_ap_tracking;\n                libfunc branch_align = branch_align;\n                libfunc jump = jump;\n                libfunc u128_lt = u128_lt;\n                libfunc store_u128 = store_temp<u128>;\n                libfunc store_rc = store_temp<RangeCheck>;\n\n                revoke_ap_tracking() -> ();\n                u128_lt([1], [2], [3]) {fallthrough([1]) 4([1]) };\n                branch_align() -> ();\n                jump() { 5() };\n                branch_align() -> ();\n\n                store_rc([1]) -> ([1]);\n                return ([1]);\n\n                test_program@0([1]: RangeCheck, [2]: u128, [3]: u128) -> (RangeCheck);\n            \"}, true, indoc!{\"\n                [fp + -4] = [ap + 1] + [fp + -3], ap++;\n                %{ memory[ap + -1] = memory[ap + 0] < 340282366920938463463374607431768211456 %}\n                jmp rel 7 if [ap + -1] != 0, ap++;\n                // a < b.\n                [ap + 0] = [ap + -1] + 340282366920938463463374607431768211456, ap++;\n                [ap + -1] = [[fp + -5] + 0];\n                jmp rel 5;\n                // a < b.\n                [ap + -1] = [[fp + -5] + 0];\n                jmp rel 2;\n                // Store range_check and return.\n                [ap + 0] = [fp + -5] + 1, ap++;\n                ret;\n            \"}; \"u128_lt\")]\n#[test_case(indoc! {\"\n                type u128 = u128;\n                type RangeCheck = RangeCheck;\n\n                libfunc branch_align = branch_align;\n                libfunc revoke_ap_tracking = revoke_ap_tracking;\n                libfunc u128_overflowing_add = u128_overflowing_add;\n                libfunc drop<u128> = drop<u128>;\n                libfunc store_temp<RangeCheck> = store_temp<RangeCheck>;\n\n                revoke_ap_tracking() -> ();\n                u128_overflowing_add([1], [2], [3]) {fallthrough([1], [2]) 6([1], [2]) };\n                branch_align() -> ();\n                drop<u128>([2]) -> ();\n                store_temp<RangeCheck>([1]) -> ([1]);\n                return ([1]);\n                branch_align() -> ();\n                drop<u128>([2]) -> ();\n                store_temp<RangeCheck>([1]) -> ([1]);\n                return ([1]);\n\n                test_program@0([1]: RangeCheck, [2]: u128, [3]: u128) -> (RangeCheck);\n            \"},\n            false,\n            indoc! {\"\n                [ap + 1] = [fp + -4] + [fp + -3], ap++;\n                %{ memory[ap + -1] = memory[ap + 0] < 340282366920938463463374607431768211456 %}\n                jmp rel 7 if [ap + -1] != 0, ap++;\n                [ap + -1] = [ap + 0] + 340282366920938463463374607431768211456, ap++;\n                [ap + -1] = [[fp + -5] + 0];\n                jmp rel 6;\n                [ap + -1] = [[fp + -5] + 0];\n                [ap + 0] = [fp + -5] + 1, ap++;\n                ret;\n                [ap + 0] = [fp + -5] + 1, ap++;\n                ret;\n            \"};\n            \"u128\")]\n#[test_case(read_sierra_example_file(\"fib_no_gas\").as_str(),\n            false,\n            indoc! {\"\n                jmp rel 4 if [fp + -3] != 0;\n                [ap + 0] = [fp + -5], ap++;\n                ret;\n                [ap + 0] = [fp + -4], ap++;\n                [ap + 0] = [fp + -5] + [fp + -4], ap++;\n                [ap + 0] = [fp + -3] + -1, ap++;\n                call rel -8;\n                ret;\n            \"};\n            \"fib_no_gas\")]\n#[test_case(read_sierra_example_file(\"fib_jumps\").as_str(),\n            true,\n            indoc! {\"\n                jmp rel 7 if [fp + -3] != 0;\n                [ap + 0] = [fp + -5], ap++;\n                [ap + 0] = [fp + -4], ap++;\n                [ap + 0] = 1, ap++;\n                ret;\n\n                // Statement # 9\n                // Setting up the latest memory to be of the form [n, rc, gb, a=1, b=0].\n                [ap + 0] = [fp + -3], ap++;\n                [ap + 0] = [fp + -5], ap++;\n                [ap + 0] = [fp + -4], ap++;\n                [ap + 0] = 1, ap++;\n                [ap + 0] = 0, ap++;\n\n                // Statement #18, check n.\n                jmp rel 6 if [ap + -5] != 0;\n                // Statement # 19 - n == 0, so we can return the latest a.\n                [ap + 0] = [ap + -4], ap++;\n                [ap + 0] = [ap + -4], ap++;\n                [ap + 0] = [ap + -4], ap++;\n                ret;\n\n                // Statement # 28 - withdrawing gas for the main loop.\n                %{ memory[ap + 0] = 1070 <= memory[ap + -3] %}\n\n                jmp rel 7 if [ap + 0] != 0, ap++;\n                [ap + 0] = [ap + -4] + 340282366920938463463374607431768210386, ap++;\n                [ap + -1] = [[ap + -6] + 0];\n                jmp rel 14;\n\n                // Statement # 30\n                // The main loop - given [n, rc, gb, a, b, _, _] - adds [n-1, updated_rc, updated_gb, a+b, a]\n                // Memory cells form is now [n'=n-1, rc'=updated_rc, gb'=updated_gb, a'=a+b, b'=a]\n                [ap + -4] = [ap + 0] + 1070, ap++;\n                [ap + -1] = [[ap + -6] + 0];\n                [ap + -7] = [ap + 0] + 1, ap++;\n                [ap + 0] = [ap + -7] + 1, ap++;\n                [ap + 0] = [ap + -3], ap++;\n                [ap + 0] = [ap + -7] + [ap + -6], ap++;\n                [ap + 0] = [ap + -8], ap++;\n                jmp rel -23;\n\n                // Statement # 40  - Ran out of gas - returning updated gb and -1.\n                [ap + 0] = [ap + -6] + 1, ap++;\n                [ap + 0] = [ap + -6], ap++;\n                [ap + 0] = -1, ap++;\n                ret;\n            \"};\n            \"fib_jumps\")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n                type Unit = Struct<ut@Tuple>;\n\n                libfunc felt252_add_3 = felt252_add_const<3>;\n                libfunc drop<felt252> = drop<felt252>;\n                libfunc struct_construct<Unit> = struct_construct<Unit>;\n                libfunc store_temp<Unit> = store_temp<Unit>;\n\n                felt252_add_3([0]) -> ([2]);\n                drop<felt252>([2]) -> ();\n                struct_construct<Unit>() -> ([3]);\n                store_temp<Unit>([3]) -> ([4]);\n                return([4]);\n\n                test::foo@0([0]: felt252) -> (Unit);\n            \"},\n            false,\n            indoc! {\"\n                ret;\n            \"};\n            \"felt252_add_const\")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n                type Unit = Struct<ut@Tuple>;\n\n                libfunc felt252_div_3 = felt252_div_const<3>;\n                libfunc drop<felt252> = drop<felt252>;\n                libfunc struct_construct<Unit> = struct_construct<Unit>;\n                libfunc store_temp<Unit> = store_temp<Unit>;\n\n                felt252_div_3([0]) -> ([2]);\n                drop<felt252>([2]) -> ();\n                struct_construct<Unit>() -> ([3]);\n                store_temp<Unit>([3]) -> ([4]);\n                return([4]);\n\n                test::foo@0([0]: felt252) -> (Unit);\n            \"},\n            false,\n            indoc! {\"\n                [fp + -3] = [ap + 0] * 3, ap++;\n                ret;\n            \"};\n            \"felt252_div_const\")]\nfn sierra_to_casm(sierra_code: &str, check_gas_usage: bool, expected_casm: &str) {\n    let program = ProgramParser::new().parse(sierra_code).unwrap();\n    pretty_assertions::assert_eq!(\n        compile(&program, &build_metadata(&program, check_gas_usage), check_gas_usage)\n            .expect(\"Compilation failed.\")\n            .to_string(),\n        strip_comments_and_linebreaks(expected_casm)\n    );\n}\n\n// TODO(ilya, 10/10/2022): Improve error messages.\n#[test_case(indoc! {\"\n                return([2]);\n\n                test_program@0() -> (felt252);\n            \"},\n            \"#0: [2] is undefined.\";\n            \"Missing reference\")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n                libfunc felt252_dup = dup<felt252>;\n\n                felt252_dup([1]) -> ([1], [2]);\n                felt252_dup([2]) -> ([1], [2]);\n                return();\n\n                test_program@0([1]: felt252) -> ();\n            \"},\n            \"#1->#2: [1] was overridden.\";\n            \"Reference override\")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n\n                return([2]);\n\n                test_program@0([2]: felt252) -> (felt252);\n            \"},\n            \"#0: Return arguments are not on the stack.\";\n            \"Invalid return reference\")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n\n                store_temp_felt252([1]) -> ([1]);\n\n                test_program@0([1]: felt252) -> ();\n            \"},\n            \"Error from program registry\";\n            \"undeclared libfunc\")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n\n                libfunc store_temp_felt252 = store_temp<felt252>;\n                libfunc store_temp_felt252 = store_temp<felt252>;\n            \"},\n            \"Error from program registry\";\n            \"Concrete libfunc Id used twice\")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n                libfunc felt252_add = felt252_add;\n\n                felt252_add([1], [2]) -> ([4]);\n                felt252_add([3], [4]) -> ([5]);\n\n                test_program@0([1]: felt252, [2]: felt252, [3]: felt252) -> ();\n            \"},\n            \"#1: One of the arguments does not satisfy the requirements of the libfunc.\";\n            \"Invalid reference expression for felt252_add\")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n                type u128 = u128;\n                libfunc felt252_add = felt252_add;\n                felt252_add([1], [2]) -> ([3]);\n                return([3]);\n\n                test_program@0([1]: u128, [2]: u128) -> (felt252);\n            \"},\n            \"#0: One of the arguments does not match the expected type of the libfunc or return \\\n statement.\";\n            \"Types mismatch\")]\n#[test_case(indoc! {\"\n                test_program@25() -> ();\n            \"}, \"InvalidStatementIdx\";\n            \"Invalid entry point\")]\n#[test_case(indoc! {\"\n                return();\n\n                foo@0([1]: felt252, [1]: felt252) -> ();\n            \"}, \"#0: Invalid function declaration.\";\n            \"Bad Declaration\")]\n#[test_case(indoc! {\"\n            return();\n            \"}, \"MissingAnnotationsForStatement\";\n            \"Missing references for statement\")]\n#[test_case(indoc! {\"\n                type NonZeroFelt252 = NonZero<felt252>;\n                type felt252 = felt252;\n            \"}, \"Error from program registry\";\n            \"type ordering bad for building size map\")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n                libfunc felt252_add = felt252_add;\n                felt252_add([1], [2], [3]) -> ([4]);\n                return();\n                test_program@0([1]: felt252, [2]: felt252, [3]: felt252) -> ();\n            \"}, \"#0: Invocation mismatched to libfunc\";\n            \"input count mismatch\")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n                libfunc felt252_add = felt252_add;\n                felt252_add([1], [2]) -> ([3], [4]);\n                test_program@0([1]: felt252, [2]: felt252) -> ();\n            \"}, \"#0: Invocation mismatched to libfunc\";\n            \"output type mismatch\")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n                libfunc felt252_add = felt252_add;\n                felt252_add([1], [2]) { 0([3]) 1([3]) };\n                test_program@0([1]: felt252, [2]: felt252) -> ();\n            \"}, \"#0: Invocation mismatched to libfunc\";\n            \"branch count mismatch\")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n                libfunc felt252_add = felt252_add;\n                felt252_add([1], [2]) { 0([3]) };\n                test_program@0([1]: felt252, [2]: felt252) -> ();\n            \"}, \"#0: Invocation mismatched to libfunc\";\n            \"fallthrough mismatch\")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n                libfunc felt252_dup = dup<felt252>;\n\n                felt252_dup([1]) -> ([1], [2]);\n                return ([1]);\n                test_program@0([1]: felt252) -> ();\n            \"}, \"[2] is dangling at #1.\";\n            \"Dangling references\")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n                type NonZeroFelt252 = NonZero<felt252>;\n\n                libfunc branch_align = branch_align;\n                libfunc felt252_dup = dup<felt252>;\n                libfunc jump = jump;\n                libfunc felt252_is_zero = felt252_is_zero;\n                libfunc store_temp_felt252 = store_temp<felt252>;\n                libfunc drop_nz_felt252 = drop<NonZeroFelt252>;\n\n                felt252_dup([1]) -> ([1], [2]);\n                felt252_dup([1]) -> ([1], [3]);\n                felt252_is_zero([1]) { fallthrough() 7([1]) };\n                branch_align() -> ();\n                store_temp_felt252([2]) -> ([2]);\n                store_temp_felt252([3]) -> ([3]);\n                jump() { 11() };\n                branch_align() -> ();\n                drop_nz_felt252([1]) -> ();\n                store_temp_felt252([3]) -> ([3]);\n                store_temp_felt252([2]) -> ([2]);\n                return ([2], [3]);\n\n                test_program@0([1]: felt252) -> (felt252, felt252);\n            \"}, \"#11: Inconsistent references annotations.\";\n            \"Inconsistent references - different locations on stack\")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n                type unit = Struct<ut@unit>;\n                type unit_pair = Struct<ut@unit_pair, unit, unit>;\n                type NonZeroFelt252 = NonZero<felt252>;\n\n                libfunc branch_align = branch_align;\n                libfunc felt252_dup = dup<felt252>;\n                libfunc jump = jump;\n                libfunc felt252_is_zero = felt252_is_zero;\n                libfunc store_temp_felt252 = store_temp<felt252>;\n                libfunc store_temp_unit_pair = store_temp<unit_pair>;\n                libfunc drop_nz_felt252 = drop<NonZeroFelt252>;\n                libfunc drop_unit = drop<unit>;\n                libfunc rename_unit = rename<unit>;\n                libfunc unit_pair_deconstruct = struct_deconstruct<unit_pair>;\n\n                store_temp_unit_pair([2]) -> ([2]);\n                unit_pair_deconstruct([2]) -> ([3], [4]);\n                felt252_is_zero([1]) { fallthrough() 7([1]) };\n                branch_align() -> ();\n                drop_unit([4]) -> ();\n                rename_unit([3]) -> ([4]);\n                jump() { 10() };\n                branch_align() -> (); // statement #7.\n                drop_nz_felt252([1]) -> ();\n                drop_unit([3]) -> ();\n                return ([4]); // The failed merge statement #10.\n\n                test_program@0([1]: felt252, [2]: unit_pair) -> (unit);\n            \"}, \"#10: Inconsistent references annotations.\";\n            \"Inconsistent references - merge on old variable not created at the same point\")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n                type NonZeroFelt252 = NonZero<felt252>;\n\n                libfunc branch_align = branch_align;\n                libfunc felt252_dup = dup<felt252>;\n                libfunc felt252_drop = drop<felt252>;\n                libfunc jump = jump;\n                libfunc felt252_is_zero = felt252_is_zero;\n                libfunc store_temp_felt252 = store_temp<felt252>;\n                libfunc drop_nz_felt252 = drop<NonZeroFelt252>;\n\n                felt252_dup([1]) -> ([1], [2]);\n                felt252_dup([1]) -> ([1], [3]);\n                felt252_is_zero([1]) { fallthrough() 8([1]) };\n                branch_align() -> ();\n                store_temp_felt252([2]) -> ([2]);\n                // Store and drop to break the stack so it can't be tracked.\n                store_temp_felt252([3]) -> ([3]);\n                felt252_drop([3]) -> ();\n                jump() { 13() };\n                branch_align() -> ();\n                drop_nz_felt252([1]) -> ();\n                store_temp_felt252([2]) -> ([2]);\n                // Store and drop to break the stack so it can't be tracked.\n                store_temp_felt252([3]) -> ([3]);\n                felt252_drop([3]) -> ();\n                return ([2]); // The failed merge statement #13.\n\n                test_program@0([1]: felt252) -> (felt252);\n            \"}, \"#13: Inconsistent references annotations.\";\n            \"Inconsistent references - unaligned area\")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n                type NonZeroFelt252 = NonZero<felt252>;\n\n                libfunc branch_align = branch_align;\n                libfunc disable_ap_tracking = disable_ap_tracking;\n                libfunc enable_ap_tracking = enable_ap_tracking;\n                libfunc jump = jump;\n                libfunc felt252_is_zero = felt252_is_zero;\n                libfunc drop_nz_felt252 = drop<NonZeroFelt252>;\n\n                disable_ap_tracking() -> ();\n                felt252_is_zero([1]) { fallthrough() 5([1]) };\n                branch_align() -> ();\n                enable_ap_tracking() -> ();\n                jump() { 8() };\n                branch_align() -> ();\n                drop_nz_felt252([1]) -> ();\n                enable_ap_tracking() -> ();\n                return (); // The failed merge statement #8.\n\n                test_program@0([1]: felt252) -> ();\n            \"}, \"#8: Inconsistent ap tracking base.\";\n            \"Inconsistent ap tracking base.\")]\n#[test_case(indoc! {\"\n                libfunc enable_ap_tracking = enable_ap_tracking;\n\n                enable_ap_tracking() -> ();\n                return ();\n\n                test_program@0() -> ();\n            \"}, \"#0: Attempting to enable ap tracking when already enabled.\";\n            \"Enabling ap tracking when already enabled.\")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n                type NonZeroFelt252 = NonZero<felt252>;\n\n                libfunc branch_align = branch_align;\n                libfunc felt252_dup = dup<felt252>;\n                libfunc felt252_drop = drop<felt252>;\n                libfunc felt252_is_zero = felt252_is_zero;\n                libfunc store_temp_felt252 = store_temp<felt252>;\n                libfunc store_temp_nz_felt252 = store_temp<NonZeroFelt252>;\n\n                felt252_is_zero([1]) { fallthrough() 4([1]) };\n                branch_align() -> ();\n                store_temp_felt252([2]) -> ([2]);\n                return ([2]);\n                branch_align() -> ();\n                felt252_drop([2]) -> ();\n                store_temp_nz_felt252([1]) -> ([1]);\n                return ([1]);\n\n                test_program@0([1]: felt252, [2]: felt252) -> (felt252);\n            \"}, \"#7: One of the arguments does not match the expected type \\\nof the libfunc or return statement.\";\n            \"Invalid return type\")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n\n                libfunc felt252_dup = dup<felt252>;\n                libfunc felt252_drop = drop<felt252>;\n                libfunc store_temp_felt252 = store_temp<felt252>;\n                libfunc call_foo = function_call<user@foo>;\n\n                store_temp_felt252([1]) -> ([1]);\n                felt252_dup([1]) -> ([1], [2]);\n                call_foo([2]) -> ();\n                store_temp_felt252([1]) -> ([1]);\n                felt252_drop([1]) -> ();\n                return();\n\n                foo@0([1]: felt252) -> ();\n            \"}, \"#2->#3: Got 'Unknown ap change' error while moving [1].\";\n            \"Ap change error\")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n                type NonZeroFelt252 = NonZero<felt252>;\n\n                libfunc revoke_ap_tracking = revoke_ap_tracking;\n                libfunc branch_align = branch_align;\n                libfunc felt252_drop = drop<felt252>;\n                libfunc felt252_is_zero = felt252_is_zero;\n                libfunc felt252_unwrap_non_zero = unwrap_non_zero<felt252>;\n                libfunc jump = jump;\n\n                felt252_is_zero([1]) { fallthrough() 4([1]) };\n                branch_align() -> ();\n                revoke_ap_tracking() -> ();\n                jump() { 7() };\n                branch_align() -> ();\n                felt252_unwrap_non_zero([1]) -> ([1]);\n                felt252_drop([1]) -> ();\n                return ();\n\n                foo@0([1]: felt252) -> ();\n            \"}, \"#7: Inconsistent ap tracking base.\";\n            \"Inconsistent ap tracking.\")]\n#[test_case(indoc! {\"\n                libfunc finalize_locals = finalize_locals;\n\n                finalize_locals () -> ();\n                finalize_locals () -> ();\n                return ();\n\n                test_program@0() -> ();\n            \"}, \"#1: finalize_locals is not allowed at this point.\";\n            \"Invalid finalize_locals 1\")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n\n                libfunc finalize_locals = finalize_locals;\n                libfunc store_temp_felt252 = store_temp<felt252>;\n                libfunc call_foo = function_call<user@foo>;\n\n                store_temp_felt252([1]) -> ([1]);\n                call_foo([1]) -> ();\n                finalize_locals() -> ();\n                return ();\n\n                foo@0([1]: felt252) -> ();\n            \"}, \"#2: finalize_locals is not allowed at this point.\";\n            \"Invalid finalize_locals 2\")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n                type UninitializedFelt252 = Uninitialized<felt252>;\n\n                libfunc alloc_local_felt252 = alloc_local<felt252>;\n                libfunc store_temp_felt252 = store_temp<felt252>;\n\n                alloc_local_felt252() -> ([2]);\n                store_temp_felt252([1]) -> ([1]);\n                alloc_local_felt252() -> ([3]);\n                return ();\n\n                foo@0([1]: felt252) -> ();\n            \"}, \"#2: alloc_local is not allowed at this point.\";\n            \"Invalid alloc_local \")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n                type UninitializedFelt252 = Uninitialized<felt252>;\n\n                libfunc alloc_local_felt252 = alloc_local<felt252>;\n                libfunc store_local_felt252 = store_local<felt252>;\n                libfunc felt252_drop = drop<felt252>;\n\n                alloc_local_felt252() -> ([2]);\n                store_local_felt252([2], [1]) -> ([2]);\n                felt252_drop([2]) -> ();\n                return ();\n\n                foo@0([1]: felt252) -> ();\n            \"}, \"#3: locals were allocated but finalize_locals was not called.\";\n            \"missing finalize_locals \")]\n#[test_case(indoc! {\"\n                type felt252 = felt252;\n                type UninitializedFelt252 = Uninitialized<felt252>;\n\n                libfunc alloc_local_felt252 = alloc_local<felt252>;\n                libfunc store_temp_felt252 = store_temp<UninitializedFelt252>;\n\n                alloc_local_felt252() -> ([1]);\n                store_temp_felt252([1]) -> ([1]);\n                return ();\n\n                foo@0() -> ();\n            \"}, \"#1: The functionality is supported only for sized types.\";\n            \"store_temp<Uninitialized<felt252>()\")]\n#[test_case(indoc! {\"\n                return ();\n\n                foo@0() -> ();\n                bar@0() -> ();\n            \"}, \"#0: Belongs to two different functions.\";\n            \"Statement in two functions\")]\nfn compiler_errors(sierra_code: &str, expected_result: &str) {\n    let program = ProgramParser::new().parse(sierra_code).unwrap();\n    pretty_assertions::assert_eq!(\n        compile(&program, &build_metadata(&program, false), false)\n            .expect_err(\"Compilation is expected to fail.\")\n            .to_string(),\n        expected_result\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_casm::ap_change::{ApChange, ApChangeError};\n\n/// Updates the function level ap_tracking based on ap_change.\npub fn update_ap_tracking(\n    ap_tracking: ApChange,\n    ap_change: ApChange,\n) -> Result<ApChange, ApChangeError> {\n    Ok(match (ap_tracking, ap_change) {\n        (ApChange::Known(current), ApChange::Known(change)) => {\n            ApChange::Known(current.checked_add(change).ok_or(ApChangeError::OffsetOverflow)?)\n        }\n        _ => ApChange::Unknown,\n    })\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_casm::ap_change::ApChange;\nuse thiserror::Error;\n\n#[derive(Error, Debug, Eq, PartialEq)]\npub enum FrameStateError {\n    #[error(\"InvalidTransition\")]\n    InvalidTransition,\n    #[error(\"alloc_local is not allowed at this point.\")]\n    InvalidAllocLocal(FrameState),\n    #[error(\"finalize_locals is not allowed at this point.\")]\n    InvalidFinalizeLocals(FrameState),\n    #[error(\"locals were allocated but finalize_locals was not called.\")]\n    FinalizeLocalsMissing(FrameState),\n}\n\n/// The frame state of the current function.\n/// This state keeps track of how many locals have been allocated and whether the\n/// frame has been finalized.\n#[derive(Clone, Debug, Eq, PartialEq)]\npub enum FrameState {\n    /// finalize_locals was called and the frame has been finalized.\n    Finalized { allocated: usize },\n    /// `finalize_locals` wasn't called yet.\n    /// `allocated` is the number of stack slot that were already allocated for local variables.\n    /// `last_ap_tracking` is the ap_tracking that was passed to the most recent call of\n    ///  `handle_alloc_local`. It is used to validate that there were no ap changes between\n    ///  the allocations and the call to `handle_finalize_locals`.\n    Allocating { allocated: usize, last_ap_tracking: ApChange },\n}\n\n/// Checks that there were no ap changes between allocations of locals.\nfn is_valid_transition(\n    allocated: usize,\n    current_ap_tracking: ApChange,\n    last_ap_tracking: ApChange,\n) -> bool {\n    if allocated == 0 {\n        // If no locals were allocated the transition is always valid.\n        return true;\n    }\n\n    // ap changes are forbidden between the allocations of locals and the finalization, so the\n    // transition is valid if and only if the ap_tracking didn't change.\n    current_ap_tracking == last_ap_tracking\n}\n\n/// Returns the number of slots that were allocated for locals and the new frame state.\npub fn handle_finalize_locals(\n    frame_state: FrameState,\n    ap_tracking: ApChange,\n) -> Result<(usize, FrameState), FrameStateError> {\n    match frame_state {\n        FrameState::Finalized { .. } => Err(FrameStateError::InvalidFinalizeLocals(frame_state)),\n        FrameState::Allocating { allocated, last_ap_tracking } => {\n            match ap_tracking {\n                // TODO(ilya, 10/10/2022): Do we want to support allocating 0 locals?\n                ApChange::Known(_)\n                    if is_valid_transition(allocated, ap_tracking, last_ap_tracking) =>\n                {\n                    Ok((allocated, FrameState::Finalized { allocated }))\n                }\n                _ => Err(FrameStateError::InvalidFinalizeLocals(frame_state)),\n            }\n        }\n    }\n}\n\n/// Returns the offset of the newly allocated variable and the new frame state.\npub fn handle_alloc_local(\n    frame_state: FrameState,\n    ap_tracking: ApChange,\n    allocation_size: usize,\n) -> Result<(usize, FrameState), FrameStateError> {\n    match frame_state {\n        FrameState::Finalized { .. } => Err(FrameStateError::InvalidAllocLocal(frame_state)),\n        FrameState::Allocating { allocated, last_ap_tracking } => match ap_tracking {\n            ApChange::Known(offset)\n                if is_valid_transition(allocated, ap_tracking, last_ap_tracking) =>\n            {\n                Ok((\n                    offset + allocated,\n                    FrameState::Allocating {\n                        allocated: allocated + allocation_size,\n                        last_ap_tracking: ap_tracking,\n                    },\n                ))\n            }\n            _ => Err(FrameStateError::InvalidAllocLocal(frame_state)),\n        },\n    }\n}\n\n/// Validates that the state at the end of a function is valid.\npub fn validate_final_frame_state(frame_state: &FrameState) -> Result<(), FrameStateError> {\n    match frame_state {\n        FrameState::Allocating { allocated, .. } if *allocated > 0 => {\n            Err(FrameStateError::FinalizeLocalsMissing(frame_state.clone()))\n        }\n        _ => Ok(()),\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::fmt::Display;\n\nuse cairo_lang_sierra::extensions::builtin_cost::CostTokenType;\nuse cairo_lang_utils::collection_arithmetics::add_maps;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse thiserror::Error;\n\n#[derive(Error, Debug, Eq, PartialEq)]\npub enum GasWalletError {\n    #[error(\n        \"Ran out of gas ({token_type:?}) in the wallet, requested {request:?} while state is \\\n         {state}.\"\n    )]\n    OutOfGas {\n        state: GasWallet,\n        request: Box<OrderedHashMap<CostTokenType, i64>>,\n        token_type: CostTokenType,\n    },\n}\n\n/// Enviroment tracking the amount of gas available in a statement's context.\n#[derive(Clone, Debug, Eq, PartialEq)]\npub enum GasWallet {\n    /// A known value.\n    Value(OrderedHashMap<CostTokenType, i64>),\n    /// If gas tracking is disabled, this value should be used for all the statements.\n    Disabled,\n}\nimpl GasWallet {\n    /// Updates the value in the wallet by `request`. Can be both negative (for most libfuncs) and\n    /// positive (for gas acquisition libfuncs).\n    pub fn update(\n        &self,\n        request: OrderedHashMap<CostTokenType, i64>,\n    ) -> Result<Self, GasWalletError> {\n        match &self {\n            Self::Value(existing) => {\n                let new_value = add_maps(existing.clone(), request.clone());\n                for (token_type, val) in new_value.iter() {\n                    if *val < 0 {\n                        return Err(GasWalletError::OutOfGas {\n                            state: self.clone(),\n                            request: Box::new(request),\n                            token_type: *token_type,\n                        });\n                    }\n                }\n                Ok(GasWallet::Value(new_value))\n            }\n            Self::Disabled => Ok(Self::Disabled),\n        }\n    }\n}\n\nimpl Display for GasWallet {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            Self::Value(value) => write!(f, \"GasWallet::Value({value:?})\"),\n            Self::Disabled => write!(f, \"GasWallet::Disabled\"),\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_casm::ap_change::ApChange;\nuse cairo_lang_sierra::program::StatementIdx;\nuse frame_state::{FrameState, FrameStateError};\nuse thiserror::Error;\n\nuse self::frame_state::validate_final_frame_state;\nuse self::gas_wallet::GasWallet;\n\npub mod ap_tracking;\npub mod frame_state;\npub mod gas_wallet;\n\n#[derive(Error, Debug, Eq, PartialEq)]\npub enum EnvironmentError {\n    #[error(\"Inconsistent ap tracking.\")]\n    InconsistentApTracking,\n    #[error(\"Inconsistent ap tracking base.\")]\n    InconsistentApTrackingBase,\n    #[error(\"Inconsistent frame state.\")]\n    InconsistentFrameState,\n    #[error(\"Inconsistent gas wallet state.\")]\n    InconsistentGasWallet,\n    #[error(\"{0}\")]\n    InvalidFinalFrameState(FrameStateError),\n}\n\n/// Part of the program annotations that libfuncs may access as part of their run.\n#[derive(Clone, Debug)]\npub struct Environment {\n    /// The ap change starting from `ap_tracking_base`.\n    /// Once it changes to ApChange::Unknown it remains in that state, unless it is reenabled.\n    pub ap_tracking: ApChange,\n    pub ap_tracking_base: Option<StatementIdx>,\n    /// The size of the continuous known stack.\n    pub stack_size: usize,\n    pub frame_state: FrameState,\n    pub gas_wallet: GasWallet,\n}\nimpl Environment {\n    pub fn new(gas_wallet: GasWallet, ap_tracking_base: StatementIdx) -> Self {\n        let ap_tracking = ApChange::Known(0);\n        Self {\n            ap_tracking,\n            ap_tracking_base: Some(ap_tracking_base),\n            stack_size: 0,\n            frame_state: FrameState::Allocating { allocated: 0, last_ap_tracking: ap_tracking },\n            gas_wallet,\n        }\n    }\n}\n\n// Validates that the environments match and returns appropriate error if not.\npub fn validate_environment_equality(\n    a: &Environment,\n    b: &Environment,\n) -> Result<(), EnvironmentError> {\n    if a.ap_tracking_base != b.ap_tracking_base {\n        Err(EnvironmentError::InconsistentApTrackingBase)\n    } else if a.ap_tracking != b.ap_tracking {\n        Err(EnvironmentError::InconsistentApTracking)\n    } else if a.frame_state != b.frame_state {\n        Err(EnvironmentError::InconsistentFrameState)\n    } else if a.gas_wallet != b.gas_wallet {\n        Err(EnvironmentError::InconsistentGasWallet)\n    } else {\n        Ok(())\n    }\n}\n\n// Validates that the state at the end of a function is valid.\npub fn validate_final_environment(env: &Environment) -> Result<(), EnvironmentError> {\n    validate_final_frame_state(&env.frame_state).map_err(EnvironmentError::InvalidFinalFrameState)\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_casm::builder::CasmBuilder;\nuse cairo_lang_casm::casm_build_extend;\nuse cairo_lang_sierra::extensions::array::ArrayConcreteLibfunc;\nuse cairo_lang_sierra::ids::ConcreteTypeId;\n\nuse super::{CompiledInvocation, CompiledInvocationBuilder, InvocationError};\nuse crate::invocations::{\n    add_input_variables, get_non_fallthrough_statement_id, CostValidationInfo,\n};\n\n/// Builds instructions for Sierra array operations.\npub fn build(\n    libfunc: &ArrayConcreteLibfunc,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    match libfunc {\n        ArrayConcreteLibfunc::New(_) => build_array_new(builder),\n        ArrayConcreteLibfunc::Append(_) => build_array_append(builder),\n        ArrayConcreteLibfunc::PopFront(libfunc)\n        | ArrayConcreteLibfunc::SnapshotPopFront(libfunc) => build_pop_front(&libfunc.ty, builder),\n        ArrayConcreteLibfunc::Get(libfunc) => build_array_get(&libfunc.ty, builder),\n        ArrayConcreteLibfunc::Len(libfunc) => build_array_len(&libfunc.ty, builder),\n    }\n}\n\n/// Handles a Sierra statement for creating a new array.\nfn build_array_new(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    builder.try_get_refs::<0>()?;\n    let mut casm_builder = CasmBuilder::default();\n    casm_build_extend! {casm_builder,\n        tempvar arr_start;\n        hint AllocSegment {} into {dst: arr_start};\n        ap += 1;\n    };\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[arr_start, arr_start]], None)],\n        Default::default(),\n    ))\n}\n\n/// Handles a Sierra statement for appending an element to an array.\nfn build_array_append(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [expr_arr, elem] = builder.try_get_refs()?;\n    let [arr_start, arr_end] = expr_arr.try_unpack()?;\n\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        buffer(0) arr_start;\n        buffer(elem.cells.len() as i16) arr_end;\n    };\n    for cell in &elem.cells {\n        add_input_variables!(casm_builder, deref cell;);\n        casm_build_extend!(casm_builder, assert cell = *(arr_end++););\n    }\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[arr_start, arr_end]], None)],\n        Default::default(),\n    ))\n}\n\n/// Handles a Sierra statement for popping an element from the beginning of an array.\nfn build_pop_front(\n    elem_ty: &ConcreteTypeId,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [arr_start, arr_end] = builder.try_get_refs::<1>()?[0].try_unpack()?;\n    let element_size = builder.program_info.type_sizes[elem_ty];\n\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        deref arr_start;\n        deref arr_end;\n    };\n    casm_build_extend! {casm_builder,\n        tempvar is_non_empty = arr_end - arr_start;\n        jump NonEmpty if is_non_empty != 0;\n        jump Failure;\n        NonEmpty:\n        const element_size_imm = element_size;\n        let new_start = arr_start + element_size_imm;\n    };\n    let failure_handle = get_non_fallthrough_statement_id(&builder);\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [\n            (\"Fallthrough\", &[&[new_start, arr_end], &[arr_start]], None),\n            (\"Failure\", &[&[arr_start, arr_end]], Some(failure_handle)),\n        ],\n        Default::default(),\n    ))\n}\n\n/// Handles a Sierra statement for fetching an array element at a specific index.\nfn build_array_get(\n    elem_ty: &ConcreteTypeId,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [expr_range_check, expr_arr, expr_index] = builder.try_get_refs()?;\n    let range_check = expr_range_check.try_unpack_single()?;\n    let [arr_start, arr_end] = expr_arr.try_unpack()?;\n    let index = expr_index.try_unpack_single()?;\n\n    let element_size = builder.program_info.type_sizes[elem_ty];\n\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        deref_or_immediate index;\n        deref arr_start;\n        deref arr_end;\n        deref range_check;\n    };\n    casm_build_extend! {casm_builder,\n        let orig_range_check = range_check;\n        // Compute the length of the array (in cells).\n        tempvar array_length_in_cells = arr_end - arr_start;\n    };\n    let element_offset_in_cells = if element_size == 1 {\n        index\n    } else {\n        casm_build_extend! {casm_builder,\n            const element_size = element_size;\n            // Compute the offset of the element (in cells).\n            tempvar element_offset = index * element_size;\n        };\n        element_offset\n    };\n    casm_build_extend! {casm_builder,\n        // Check that offset is in range.\n        // Note that the offset may be as large as `(2^15 - 1) * (2^32 - 1)`.\n        tempvar is_in_range;\n        hint TestLessThan {lhs: element_offset_in_cells, rhs: array_length_in_cells} into {dst: is_in_range};\n        jump InRange if is_in_range != 0;\n        // Index out of bounds. Compute offset - length.\n        tempvar offset_length_diff = element_offset_in_cells - array_length_in_cells;\n        // Assert offset - length >= 0. Note that offset_length_diff is smaller than 2^128 as the index type is u32.\n        assert offset_length_diff  = *(range_check++);\n        jump FailureHandle;\n\n        InRange:\n        // Assert offset < length, or that length - (offset + 1) is in [0, 2^128).\n        // Compute offset + 1.\n        const one = 1;\n        tempvar element_offset_in_cells_plus_1 = element_offset_in_cells + one;\n        // Compute length - (offset + 1).\n        tempvar offset_length_diff = array_length_in_cells - element_offset_in_cells_plus_1;\n        // Assert length - (offset + 1) is in [0, 2^128).\n        assert offset_length_diff = *(range_check++);\n         // The start address of target cells.\n        let target_cell = arr_start + element_offset_in_cells;\n    };\n    let failure_handle = get_non_fallthrough_statement_id(&builder);\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [\n            (\"Fallthrough\", &[&[range_check], &[target_cell]], None),\n            (\"FailureHandle\", &[&[range_check]], Some(failure_handle)),\n        ],\n        CostValidationInfo {\n            range_check_info: Some((orig_range_check, range_check)),\n            extra_costs: None,\n        },\n    ))\n}\n\n/// Handles a Sierra statement for getting the length of an array.\nfn build_array_len(\n    elem_ty: &ConcreteTypeId,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [arr_start, arr_end] = builder.try_get_refs::<1>()?[0].try_unpack()?;\n    let element_size = builder.program_info.type_sizes[elem_ty];\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        deref arr_start;\n        deref arr_end;\n    };\n    let length = if element_size == 1 {\n        casm_build_extend! {casm_builder,\n            let length = arr_end - arr_start;\n        };\n        length\n    } else {\n        casm_build_extend! {casm_builder,\n            tempvar end_total_offset = arr_end - arr_start;\n            const element_size = element_size;\n            let length = end_total_offset / element_size;\n        };\n        length\n    };\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[length]], None)],\n        Default::default(),\n    ))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_casm::builder::CasmBuilder;\nuse cairo_lang_casm::casm_build_extend;\n\nuse super::{CompiledInvocation, CompiledInvocationBuilder, InvocationError};\nuse crate::invocations::add_input_variables;\n\n#[cfg(test)]\n#[path = \"bitwise_test.rs\"]\nmod test;\n\n/// Builds instructions for Sierra bitwise operations.\npub fn build(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    build_bitwise(builder)\n}\n\n/// Handles instruction for invoking the bitwise builtin.\nfn build_bitwise(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [bitwise, x, y] = builder.try_get_single_cells()?;\n\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        deref x;\n        deref y;\n        buffer(4) bitwise;\n    };\n    casm_build_extend! {casm_builder,\n        assert x = *(bitwise++);\n        assert y = *(bitwise++);\n        let and = *(bitwise++);\n        let xor = *(bitwise++);\n        let or = *(bitwise++);\n    };\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[bitwise], &[and], &[xor], &[or]], None)],\n        Default::default(),\n    ))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_casm::ap_change::ApChange;\nuse cairo_lang_casm::casm;\nuse pretty_assertions::assert_eq;\nuse test_log::test;\n\nuse crate::invocations::test_utils::{\n    compile_libfunc, ReducedBranchChanges, ReducedCompiledInvocation,\n};\nuse crate::ref_expr;\n\n#[test]\nfn test_bitwise() {\n    assert_eq!(\n        compile_libfunc(\n            \"bitwise\",\n            vec![ref_expr!([fp + 1] + (i16::MAX - 4)), ref_expr!([fp + 2]), ref_expr!([ap + 5])]\n        ),\n        ReducedCompiledInvocation {\n            instructions: casm! {\n                [fp + 2] = [[fp + 1] + 32763];\n                [ap + 5] = [[fp + 1] + 32764];\n            }\n            .instructions,\n            relocations: vec![],\n            results: vec![ReducedBranchChanges {\n                refs: vec![\n                    ref_expr!([fp + 1] + 32768),\n                    ref_expr!([[fp + 1] + 32765]),\n                    ref_expr!([[fp + 1] + 32766]),\n                    ref_expr!([[fp + 1] + 32767])\n                ],\n                ap_change: ApChange::Known(0)\n            }]\n        }\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_casm::builder::CasmBuilder;\nuse cairo_lang_casm::casm_build_extend;\nuse cairo_lang_sierra::extensions::boolean::BoolConcreteLibfunc;\n\nuse super::{misc, CompiledInvocation, CompiledInvocationBuilder, InvocationError};\nuse crate::invocations::add_input_variables;\n\n/// Builds instructions for Sierra bool operations.\npub fn build(\n    libfunc: &BoolConcreteLibfunc,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    match libfunc {\n        BoolConcreteLibfunc::And(_) => build_bool_and(builder),\n        BoolConcreteLibfunc::Not(_) => build_bool_not(builder),\n        BoolConcreteLibfunc::Xor(_) => build_bool_xor(builder),\n        BoolConcreteLibfunc::Or(_) => build_bool_or(builder),\n        BoolConcreteLibfunc::ToFelt252(_) => misc::build_identity(builder),\n    }\n}\n\n/// Handles instructions for boolean AND.\nfn build_bool_and(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [a, b] = builder.try_get_single_cells()?;\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        deref a;\n        deref b;\n    };\n    casm_build_extend!(casm_builder, let res = a * b;);\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[res]], None)],\n        Default::default(),\n    ))\n}\n\n/// Handles instructions for boolean NOT.\nfn build_bool_not(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [a] = builder.try_get_single_cells()?;\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder, deref a; };\n    casm_build_extend! {casm_builder,\n        const one_imm = 1;\n        tempvar one = one_imm;\n        let res = one - a;\n    };\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[res]], None)],\n        Default::default(),\n    ))\n}\n\n/// Handles instructions for boolean XOR.\nfn build_bool_xor(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [a, b] = builder.try_get_single_cells()?;\n\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        deref a;\n        deref b;\n    };\n\n    // Outputs `(a - b)^2`.\n    casm_build_extend! {casm_builder,\n        tempvar diff = a - b;\n        let res = diff * diff;\n    }\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[res]], None)],\n        Default::default(),\n    ))\n}\n\n/// Handles instructions for boolean OR.\nfn build_bool_or(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [a, b] = builder.try_get_single_cells()?;\n\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        deref a;\n        deref b;\n    };\n\n    // Outputs 'a + b - ab'.\n    casm_build_extend! {casm_builder,\n        tempvar sum = a + b;\n        tempvar prod = a * b;\n        let res = sum - prod;\n    }\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[res]], None)],\n        Default::default(),\n    ))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_casm::builder::CasmBuilder;\nuse cairo_lang_casm::casm_build_extend;\nuse cairo_lang_casm::cell_expression::CellExpression;\nuse cairo_lang_sierra::extensions::boxing::BoxConcreteLibfunc;\nuse cairo_lang_sierra::ids::ConcreteTypeId;\nuse num_bigint::ToBigInt;\n\nuse super::{CompiledInvocation, CompiledInvocationBuilder, InvocationError};\nuse crate::invocations::add_input_variables;\nuse crate::references::ReferenceExpression;\n\n/// Builds instructions for Sierra box operations.\npub fn build(\n    libfunc: &BoxConcreteLibfunc,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    match libfunc {\n        BoxConcreteLibfunc::Into(_) => build_into_box(builder),\n        BoxConcreteLibfunc::Unbox(libfunc) => build_unbox(&libfunc.ty, builder),\n    }\n}\n\n/// Handles instruction for creating a box.\nfn build_into_box(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [operand] = builder.try_get_refs()?;\n    let mut casm_builder = CasmBuilder::default();\n    let addr = if operand.cells.is_empty() {\n        // In cases of a zero-sized variable, we just simulate a non-zero address.\n        casm_build_extend!(casm_builder,\n            const one = 1;\n            tempvar addr = one;\n        );\n        addr\n    } else {\n        casm_build_extend!(casm_builder,\n            const operand_size = operand.cells.len().to_bigint().unwrap();\n            tempvar addr;\n            hint AllocConstantSize { size: operand_size } into { dst: addr };\n        );\n        for (index, cell) in operand.cells.iter().enumerate() {\n            add_input_variables!(casm_builder, deref cell;);\n            casm_build_extend!(casm_builder, assert cell = addr[index as i16];);\n        }\n        addr\n    };\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[addr]], None)],\n        Default::default(),\n    ))\n}\n\n/// Handles instruction for unboxing a box.\nfn build_unbox(\n    ty: &ConcreteTypeId,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let size = builder.program_info.type_sizes[ty];\n    let operand = builder.try_get_single_cells::<1>()?[0]\n        .to_deref()\n        .ok_or(InvocationError::InvalidReferenceExpressionForArgument)?;\n    Ok(builder.build_only_reference_changes(\n        [ReferenceExpression {\n            cells: (0..size).map(|idx| CellExpression::DoubleDeref(operand, idx)).collect(),\n        }]\n        .into_iter(),\n    ))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_casm::builder::CasmBuilder;\nuse cairo_lang_casm::cell_expression::CellExpression;\nuse cairo_lang_casm::operand::{CellRef, Register};\nuse cairo_lang_casm::{casm, casm_build_extend};\nuse cairo_lang_sierra::extensions::builtin_cost::{BuiltinCostConcreteLibfunc, CostTokenType};\nuse num_bigint::BigInt;\n\nuse super::{CompiledInvocation, CompiledInvocationBuilder, InvocationError};\nuse crate::invocations::{\n    add_input_variables, get_non_fallthrough_statement_id, CostValidationInfo,\n};\nuse crate::references::ReferenceExpression;\nuse crate::relocations::{Relocation, RelocationEntry};\n\n/// Builds instructions for Sierra gas operations.\npub fn build(\n    libfunc: &BuiltinCostConcreteLibfunc,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    match libfunc {\n        BuiltinCostConcreteLibfunc::BuiltinWithdrawGas(_) => build_builtin_withdraw_gas(builder),\n        BuiltinCostConcreteLibfunc::GetBuiltinCosts(_) => build_get_builtin_costs(builder),\n    }\n}\n\n/// Handles the withdraw_gas invocation.\nfn build_builtin_withdraw_gas(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [range_check, gas_counter, builtin_cost] = builder.try_get_single_cells()?;\n\n    let failure_handle_statement_id = get_non_fallthrough_statement_id(&builder);\n\n    let variable_values = &builder.program_info.metadata.gas_info.variable_values;\n    if !CostTokenType::iter().all(|token| variable_values.contains_key(&(builder.idx, *token))) {\n        return Err(InvocationError::UnknownVariableData);\n    }\n\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        buffer(1) range_check;\n        deref gas_counter;\n        deref builtin_cost;\n    };\n    let requested_count: i64 = variable_values[(builder.idx, CostTokenType::Const)];\n    let mut total_requested_count =\n        casm_builder.add_var(CellExpression::Immediate(BigInt::from(requested_count)));\n    for token_type in CostTokenType::iter_precost() {\n        let requested_count = variable_values[(builder.idx, *token_type)];\n        if requested_count == 0 {\n            continue;\n        }\n        let offset = token_type.offset_in_builtin_costs();\n        // Fetch the cost of a single instance.\n        casm_build_extend! {casm_builder,\n            tempvar single_cost = builtin_cost[offset];\n        };\n\n        // If necessary, multiply by the number of instances.\n        let multi_cost = if requested_count != 1 {\n            casm_build_extend! {casm_builder,\n                const requested_count = requested_count;\n                tempvar multi_cost = single_cost * requested_count;\n            };\n            multi_cost\n        } else {\n            single_cost\n        };\n        // Add to the cumulative sum.\n        casm_build_extend! {casm_builder,\n            tempvar updated_total_requested_count = multi_cost + total_requested_count;\n        };\n        total_requested_count = updated_total_requested_count;\n    }\n\n    casm_build_extend! {casm_builder,\n        let orig_range_check = range_check;\n        tempvar has_enough_gas;\n        hint TestLessThanOrEqual {\n            lhs: total_requested_count,\n            rhs: gas_counter\n        } into {dst: has_enough_gas};\n        jump HasEnoughGas if has_enough_gas != 0;\n        // In this case amount > gas_counter_value, so amount - gas_counter_value - 1 >= 0.\n        tempvar gas_diff = gas_counter - total_requested_count;\n        const uint128_limit = (BigInt::from(u128::MAX) + 1) as BigInt;\n        tempvar fixed_gas_diff = gas_diff + uint128_limit;\n        assert fixed_gas_diff = *(range_check++);\n        jump Failure;\n        HasEnoughGas:\n        tempvar updated_gas = gas_counter - total_requested_count;\n        assert updated_gas = *(range_check++);\n    };\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [\n            (\"Fallthrough\", &[&[range_check], &[updated_gas]], None),\n            (\"Failure\", &[&[range_check], &[gas_counter]], Some(failure_handle_statement_id)),\n        ],\n        CostValidationInfo {\n            range_check_info: Some((orig_range_check, range_check)),\n            extra_costs: Some([-requested_count as i32, 0]),\n        },\n    ))\n}\n\n/// Handles the get_builtin_costs invocation.\nfn build_get_builtin_costs(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let code = casm! {\n        // The relocation table will point the `call` to the end of the program where there will\n        // be a `ret` instruction.\n        call rel 0;\n        // After calling an empty function, `[ap - 1]` contains the current `pc`.\n        // Using the relocations below, the immediate value (`1`) will be changed so that it will\n        // compute a pointer to the second cell after the end of the program, which will contain\n        // the pointer to the builtin cost array.\n        [ap] = [ap - 1] + 1, ap++;\n    };\n    let relocations = vec![\n        RelocationEntry { instruction_idx: 0, relocation: Relocation::EndOfProgram },\n        RelocationEntry { instruction_idx: 1, relocation: Relocation::EndOfProgram },\n    ];\n    Ok(builder.build(\n        code.instructions,\n        relocations,\n        [vec![ReferenceExpression::from_cell(CellExpression::DoubleDeref(\n            CellRef { register: Register::AP, offset: -1 },\n            0,\n        ))]\n        .into_iter()]\n        .into_iter(),\n    ))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_casm::builder::CasmBuilder;\nuse cairo_lang_casm::casm_build_extend;\nuse cairo_lang_sierra::extensions::casts::{CastConcreteLibfunc, DowncastConcreteLibfunc};\nuse num_bigint::BigUint;\nuse num_traits::Pow;\n\nuse super::misc::build_identity;\nuse super::{CompiledInvocation, CompiledInvocationBuilder, InvocationError};\nuse crate::invocations::{\n    add_input_variables, get_non_fallthrough_statement_id, CostValidationInfo,\n};\n\n/// Builds instructions for Sierra cast operations.\npub fn build(\n    libfunc: &CastConcreteLibfunc,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    match libfunc {\n        CastConcreteLibfunc::Downcast(libfunc) => build_downcast(builder, libfunc),\n        CastConcreteLibfunc::Upcast(_) => build_identity(builder),\n    }\n}\n\n/// Builds Casm instructions for [CastConcreteLibfunc::Downcast].\npub fn build_downcast(\n    builder: CompiledInvocationBuilder<'_>,\n    libfunc: &DowncastConcreteLibfunc,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [range_check, value] = builder.try_get_single_cells()?;\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables!(casm_builder,\n        buffer(0) range_check;\n        deref value;\n    );\n\n    // The casm code below assumes both types are at most 128 bits.\n    assert!(\n        libfunc.from_nbits <= 128 && libfunc.to_nbits <= 128,\n        \"Downcasting from types of size > 128 bit is not supported.\"\n    );\n\n    let two = BigUint::from(2u64);\n    let bound = two.clone().pow(libfunc.to_nbits);\n    let rc_bound = two.pow(128_usize);\n\n    casm_build_extend! {casm_builder,\n        let orig_range_check = range_check;\n\n        // Use a hint to guess whether the result is in range (is_valid=1) or overflows\n        // (is_valid=0).\n        tempvar is_valid;\n        const limit = bound.clone();\n        hint TestLessThan {lhs: value, rhs: limit} into {dst: is_valid};\n        jump Success if is_valid != 0;\n        // Failure.\n        // value >= bound  <=>  value - bound >= 0.\n        // Note that we know that 0 <= value < 2^128.\n        tempvar shifted_value = value - limit;\n        assert shifted_value = *(range_check++);\n        jump Failure;\n\n        // Success.\n        Success:\n        // Verify that the value is in range:\n        // value < limit  <=>  value + (rc_bound - bound) < rc_bound.\n        const pos_shift = rc_bound - bound;\n        tempvar shifted_value = value + pos_shift;\n        assert shifted_value = *(range_check++);\n    };\n\n    let target_statement_id = get_non_fallthrough_statement_id(&builder);\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [\n            (\"Fallthrough\", &[&[range_check], &[value]], None),\n            (\"Failure\", &[&[range_check]], Some(target_statement_id)),\n        ],\n        CostValidationInfo {\n            range_check_info: Some((orig_range_check, range_check)),\n            extra_costs: None,\n        },\n    ))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_casm::builder::CasmBuilder;\nuse cairo_lang_casm::casm_build_extend;\nuse cairo_lang_sierra::extensions::debug::DebugConcreteLibfunc;\n\nuse super::{CompiledInvocation, CompiledInvocationBuilder, InvocationError};\nuse crate::invocations::add_input_variables;\n\n/// Builds Casm instructions for Nullable operations.\npub fn build(\n    libfunc: &DebugConcreteLibfunc,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    match libfunc {\n        DebugConcreteLibfunc::Print(_) => build_print(builder),\n    }\n}\n\n/// Builds Casm instructions for the `print()` libfunc.\nfn build_print(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [arr_start, arr_end] = builder.try_get_refs::<1>()?[0].try_unpack()?;\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        buffer(0) arr_start;\n        buffer(0) arr_end;\n    };\n    casm_build_extend! {casm_builder,\n        hint DebugPrint {start: arr_start, end: arr_end} into {};\n        // Since we can't have hints not carried on actual instructions.\n        ap += 0;\n    };\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[], None)],\n        Default::default(),\n    ))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::str::FromStr;\n\nuse cairo_felt::Felt as Felt252;\nuse cairo_lang_casm::builder::{CasmBuilder, Var};\nuse cairo_lang_casm::casm_build_extend;\nuse cairo_lang_sierra::extensions::ec::EcConcreteLibfunc;\nuse num_bigint::{BigInt, ToBigInt};\n\nuse super::{CompiledInvocation, CompiledInvocationBuilder, InvocationError};\nuse crate::invocations::misc::validate_under_limit;\nuse crate::invocations::{\n    add_input_variables, get_non_fallthrough_statement_id, CostValidationInfo,\n};\n\n/// Returns the Beta value of the Starkware elliptic curve.\nfn get_beta() -> BigInt {\n    BigInt::from_str(\"3141592653589793238462643383279502884197169399375105820974944592307816406665\")\n        .unwrap()\n}\n\n/// Builds instructions for Sierra EC operations.\npub fn build(\n    libfunc: &EcConcreteLibfunc,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    match libfunc {\n        EcConcreteLibfunc::IsZero(_) => build_is_zero(builder),\n        EcConcreteLibfunc::Neg(_) => build_ec_neg(builder),\n        EcConcreteLibfunc::StateAdd(_) => build_ec_state_add(builder),\n        EcConcreteLibfunc::TryNew(_) => build_ec_point_try_new_nz(builder),\n        EcConcreteLibfunc::StateFinalize(_) => build_ec_state_finalize(builder),\n        EcConcreteLibfunc::StateInit(_) => build_ec_state_init(builder),\n        EcConcreteLibfunc::StateAddMul(_) => build_ec_state_add_mul(builder),\n        EcConcreteLibfunc::PointFromX(_) => build_ec_point_from_x_nz(builder),\n        EcConcreteLibfunc::UnwrapPoint(_) => build_ec_point_unwrap(builder),\n        EcConcreteLibfunc::Zero(_) => build_ec_zero(builder),\n    }\n}\n\n/// Extends the CASM builder to include computation of `y^2` and `x^3 + x + BETA` for the given\n/// pair (x, y). Populates the two \"output vars\" with the computed LHS and RHS of the EC equation.\nfn verify_ec_point(\n    casm_builder: &mut CasmBuilder,\n    x: Var,\n    y: Var,\n    computed_lhs: Var,\n    computed_rhs: Var,\n) {\n    compute_lhs(casm_builder, y, computed_lhs);\n    compute_rhs(casm_builder, x, computed_rhs);\n}\n\n/// Computes the left-hand side of the EC equation, namely `y^2`.\nfn compute_lhs(casm_builder: &mut CasmBuilder, y: Var, computed_lhs: Var) {\n    casm_build_extend! {casm_builder,\n        assert computed_lhs = y * y;\n    };\n}\n\n/// Computes the right-hand side of the EC equation, namely `x^3 + x + BETA`.\nfn compute_rhs(casm_builder: &mut CasmBuilder, x: Var, computed_rhs: Var) {\n    casm_build_extend! {casm_builder,\n        const beta = (get_beta());\n        tempvar x2 = x * x;\n        tempvar x3 = x2 * x;\n        tempvar alpha_x_plus_beta = x + beta; // Here we use the fact that Alpha is 1.\n        assert computed_rhs = x3 + alpha_x_plus_beta;\n    };\n}\n\n/// Extends the CASM builder to compute the sum - or difference - of two EC points, and store the\n/// result in the given variables.\n/// The inputs to the function are:\n/// 1. The first point (`p0`).\n/// 2. The X coordinate of the second point (`x1`).\n/// 3. The \"numerator\", which is either `y0 - y1` (for point addition) or `y0 + y1` (for point\n///    subtraction).\n/// 4. The computation of `x0 - x1` (called \"denominator\"). Assumed to be non-zero.\nfn add_ec_points(\n    casm_builder: &mut CasmBuilder,\n    p0: (Var, Var),\n    x1: Var,\n    numerator: Var,\n    denominator: Var,\n) -> (Var, Var) {\n    let (x0, y0) = p0;\n\n    casm_build_extend! {casm_builder,\n        tempvar slope = numerator / denominator;\n        tempvar slope2 = slope * slope;\n        tempvar sum_x = x0 + x1;\n        tempvar result_x = slope2 - sum_x;\n        tempvar x_change = x0 - result_x;\n        tempvar slope_times_x_change = slope * x_change;\n        tempvar result_y = slope_times_x_change - y0;\n    };\n\n    (result_x, result_y)\n}\n\n/// Generates casm instructions for `ec_point_zero()`.\nfn build_ec_zero(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let mut casm_builder = CasmBuilder::default();\n\n    casm_build_extend!(casm_builder,\n        const zero = 0;\n    );\n\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[zero, zero]], None)],\n        Default::default(),\n    ))\n}\n\n/// Handles instruction for creating an EC point.\nfn build_ec_point_try_new_nz(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [x, y] = builder.try_get_single_cells()?;\n\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        deref x;\n        deref y;\n    };\n\n    // Check if `(x, y)` is on the curve, by computing `y^2` and `x^3 + x + beta`.\n    casm_build_extend! {casm_builder,\n        tempvar y2;\n        tempvar expected_y2;\n    };\n    verify_ec_point(&mut casm_builder, x, y, y2, expected_y2);\n    casm_build_extend! {casm_builder,\n        tempvar diff = y2 - expected_y2;\n        jump NotOnCurve if diff != 0;\n    };\n\n    let failure_handle = get_non_fallthrough_statement_id(&builder);\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[x, y]], None), (\"NotOnCurve\", &[], Some(failure_handle))],\n        Default::default(),\n    ))\n}\n\n/// Handles instruction for creating an EC point.\nfn build_ec_point_from_x_nz(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [range_check, x] = builder.try_get_single_cells()?;\n\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        buffer(2) range_check;\n        deref x;\n    };\n\n    casm_build_extend! {casm_builder,\n        let orig_range_check = range_check;\n        tempvar rhs;\n    };\n    compute_rhs(&mut casm_builder, x, rhs);\n\n    // Guess y, by either computing the square root of `rhs`, or of `3 * rhs`.\n    casm_build_extend! {casm_builder,\n        tempvar y;\n        hint FieldSqrt {val: rhs} into {sqrt: y};\n        tempvar lhs;\n    };\n    compute_lhs(&mut casm_builder, y, lhs);\n\n    casm_build_extend! {casm_builder,\n        tempvar diff = lhs - rhs;\n        // If `(x, y)` is on the curve, return it.\n        jump VerifyNotOnCurve if diff != 0;\n        jump OnCurve;\n        VerifyNotOnCurve:\n        // Check that `y^2 = 3 * rhs`.\n        const three = (3);\n        assert lhs = rhs * three;\n        // Note that `rhs != 0`: otherwise `y^2 = 3 * rhs = 0` implies `y = 0` and we would have\n        // `y^2 = rhs` so this branch wouldn't have been chosen.\n        // Alternatively, note that `rhs = 0` is not possible in curves of odd order (such as this\n        // curve).\n        // Since 3 is not a quadratic residue in the field, it will follow that `rhs` is not a\n        // quadratic residue, which implies that there is no `y` such that `(x, y)` is on the curve.\n        jump NotOnCurve;\n\n        OnCurve:\n    };\n\n    // Check that y < PRIME / 2 to enforce a deterministic behavior (otherwise, the prover can\n    // choose either y or -y).\n    let auxiliary_vars: [_; 4] = std::array::from_fn(|_| casm_builder.alloc_var(false));\n    validate_under_limit::<1>(\n        &mut casm_builder,\n        // Note that `1/2 (mod PRIME) = (PRIME + 1) / 2 = ceil(PRIME / 2)`.\n        // Thus, `y < 1/2 (mod PRIME)` if and only if `y < PRIME / 2`.\n        &(Felt252::from(1) / Felt252::from(2)).to_biguint().to_bigint().unwrap(),\n        y,\n        range_check,\n        &auxiliary_vars,\n    );\n\n    // Fallthrough - success.\n\n    let not_on_curve = get_non_fallthrough_statement_id(&builder);\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [\n            (\"Fallthrough\", &[&[range_check], &[x, y]], None),\n            (\"NotOnCurve\", &[&[range_check]], Some(not_on_curve)),\n        ],\n        CostValidationInfo {\n            range_check_info: Some((orig_range_check, range_check)),\n            extra_costs: None,\n        },\n    ))\n}\n\n/// Handles instruction for unwrapping an EC point.\nfn build_ec_point_unwrap(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [x, y] = builder.try_get_refs::<1>()?[0].try_unpack()?;\n\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        deref x;\n        deref y;\n    };\n\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[x], &[y]], None)],\n        Default::default(),\n    ))\n}\n\n/// Generates casm instructions for `ec_point_is_zero()`.\nfn build_is_zero(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [x, y] = builder.try_get_refs::<1>()?[0].try_unpack()?;\n\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables!(casm_builder, deref x; deref y; );\n    casm_build_extend! {casm_builder,\n        // To check whether `(x, y) = (0, 0)` (the zero point), it is enough to check\n        // whether `y = 0`, since there is no point on the curve with y = 0.\n        jump Target if y != 0;\n    };\n\n    let target_statement_id = get_non_fallthrough_statement_id(&builder);\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[], None), (\"Target\", &[&[x, y]], Some(target_statement_id))],\n        Default::default(),\n    ))\n}\n\n/// Generates casm instructions for `ec_neg()`.\nfn build_ec_neg(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [x, y] = builder.try_get_refs::<1>()?[0].try_unpack()?;\n\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        deref x;\n        deref y;\n    };\n    casm_build_extend!(casm_builder,\n        const neg_one = -1;\n        let neg_y = y * neg_one;\n    );\n\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[x, neg_y]], None)],\n        Default::default(),\n    ))\n}\n\n/// Handles instruction for initializing an EC state.\nfn build_ec_state_init(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let mut casm_builder = CasmBuilder::default();\n\n    // Sample a random point on the curve.\n    casm_build_extend! {casm_builder,\n        tempvar random_x;\n        tempvar random_y;\n        hint RandomEcPoint {} into { x: random_x, y: random_y };\n        // Assert the random point is on the curve.\n        tempvar y2;\n        tempvar expected_y2;\n    }\n    verify_ec_point(&mut casm_builder, random_x, random_y, y2, expected_y2);\n    casm_build_extend! {casm_builder,\n        assert y2 = expected_y2;\n        // Create a pointer to the random EC point to return as part of the state.\n        tempvar random_ptr;\n        hint AllocSegment {} into {dst: random_ptr};\n        assert random_x = random_ptr[0];\n        assert random_y = random_ptr[1];\n    };\n\n    // The third entry in the EC state is a pointer to the sampled random EC point.\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[random_x, random_y, random_ptr]], None)],\n        Default::default(),\n    ))\n}\n\n/// Handles instruction for adding a point to an EC state.\nfn build_ec_state_add(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [expr_state, expr_point] = builder.try_get_refs()?;\n    let [sx, sy, random_ptr] = expr_state.try_unpack()?;\n    let [px, py] = expr_point.try_unpack()?;\n\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        deref px;\n        deref py;\n        deref sx;\n        deref sy;\n        deref random_ptr;\n    };\n\n    casm_build_extend! {casm_builder,\n        // If the X coordinate is the same, either the points are equal or their sum is the point at\n        // infinity. Either way, we can't compute the slope in this case.\n        tempvar denominator = px - sx;\n        jump NotSameX if denominator != 0;\n        // X coordinate is identical; either the sum of the points is the point at infinity (not\n        // allowed), or the points are equal, which is also not allowed (doubling).\n        fail;\n        NotSameX:\n        tempvar numerator = py - sy;\n    };\n\n    let (result_x, result_y) =\n        add_ec_points(&mut casm_builder, (px, py), sx, numerator, denominator);\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[result_x, result_y, random_ptr]], None)],\n        Default::default(),\n    ))\n}\n\n/// Handles instruction for finalizing an EC state.\nfn build_ec_state_finalize(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [x, y, random_ptr] = builder.try_get_refs::<1>()?[0].try_unpack()?;\n\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        deref x;\n        deref y;\n        deref random_ptr;\n    };\n\n    // We want to return the point `(x, y) - (random_x, random_y)`, or in other words,\n    // `(x, y) + (random_x, -random_y)`.\n    casm_build_extend! {casm_builder,\n        tempvar random_x = random_ptr[0];\n        tempvar random_y = random_ptr[1];\n        // If the X coordinate is the same, either the points are equal or their sum is the point at\n        // infinity. Either way, we can't compute the slope in this case.\n        // The result may be the point at infinity if the user called `ec_state_try_finalize_nz`\n        // immediately after ec_state_init.\n        tempvar denominator = x - random_x;\n        jump NotSameX if denominator != 0;\n        // Assert the result is the point at infinity (the other option is the points are the same,\n        // and doubling is not allowed).\n        assert y = random_y;\n        jump SumIsInfinity;\n        NotSameX:\n        // The numerator is the difference in Y coordinate values of the summed points, and the Y\n        // coordinate of the negated random point is `-random_y`.\n        tempvar numerator = y + random_y;\n    }\n\n    let (result_x, result_y) =\n        add_ec_points(&mut casm_builder, (x, y), random_x, numerator, denominator);\n\n    let failure_handle = get_non_fallthrough_statement_id(&builder);\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [\n            (\"Fallthrough\", &[&[result_x, result_y]], None),\n            (\"SumIsInfinity\", &[], Some(failure_handle)),\n        ],\n        Default::default(),\n    ))\n}\n\n/// Handles instruction for computing `S + M * Q` where `S` is an EC state, `M` is a scalar\n/// (felt252) and `Q` is an EC point.\nfn build_ec_state_add_mul(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [ec_builtin_expr, expr_state, expr_m, expr_point] = builder.try_get_refs()?;\n    let ec_builtin = ec_builtin_expr.try_unpack_single()?;\n    let [sx, sy, random_ptr] = expr_state.try_unpack()?;\n    let [m] = expr_m.try_unpack()?;\n    let [px, py] = expr_point.try_unpack()?;\n\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        buffer(6) ec_builtin;\n        deref sx;\n        deref sy;\n        deref random_ptr;\n        deref px;\n        deref py;\n        deref m;\n    };\n    casm_build_extend! {casm_builder,\n        assert sx = *(ec_builtin++);\n        assert sy = *(ec_builtin++);\n        assert px = *(ec_builtin++);\n        assert py = *(ec_builtin++);\n        assert m = *(ec_builtin++);\n        let result_x = *(ec_builtin++);\n        let result_y = *(ec_builtin++);\n    };\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[ec_builtin], &[result_x, result_y, random_ptr]], None)],\n        Default::default(),\n    ))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_casm::cell_expression::CellExpression;\nuse cairo_lang_casm::operand::CellRef;\nuse cairo_lang_casm::{casm, casm_extend};\nuse cairo_lang_sierra::extensions::enm::{EnumConcreteLibfunc, EnumInitConcreteLibfunc};\nuse cairo_lang_sierra::extensions::ConcreteLibfunc;\nuse cairo_lang_sierra::ids::ConcreteTypeId;\nuse cairo_lang_sierra::program::{BranchInfo, BranchTarget};\nuse cairo_lang_utils::try_extract_matches;\nuse itertools::{chain, repeat_n};\nuse num_bigint::BigInt;\n\nuse super::{\n    CompiledInvocation, CompiledInvocationBuilder, InvocationError, ReferenceExpressionView,\n};\nuse crate::invocations::ProgramInfo;\nuse crate::references::{ReferenceExpression, ReferencesError};\nuse crate::relocations::{Relocation, RelocationEntry};\n\n/// Builds instructions for Sierra enum operations.\npub fn build(\n    libfunc: &EnumConcreteLibfunc,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    match libfunc {\n        EnumConcreteLibfunc::Init(EnumInitConcreteLibfunc { index, num_variants, .. }) => {\n            build_enum_init(builder, *index, *num_variants)\n        }\n        EnumConcreteLibfunc::Match(_) | EnumConcreteLibfunc::SnapshotMatch(_) => {\n            build_enum_match(builder)\n        }\n    }\n}\n\n/// Handles statement for initializing an enum.\n/// For example, with this setup\n/// ```ignore\n/// type felt252_ty = felt252;\n/// type unit_ty = Tuple;\n/// type Option = Enum<felt252_ty, unit_ty>;\n/// libfunc init_option_some = enum_init<Option, 0>;\n/// felt252_const<8>() -> (felt8);\n/// ````\n/// this \"Sierra statement\"\n/// ```ignore\n/// init_option_some(felt8=[ap-5]) -> (some_id);\n/// ```\n/// translates to these casm instructions:\n/// ```ignore\n/// [ap] = 0; ap++\n/// [ap] = 8; ap++\n/// ```\nfn build_enum_init(\n    builder: CompiledInvocationBuilder<'_>,\n    index: usize,\n    num_variants: usize,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [expression] = builder.try_get_refs()?;\n    let init_arg_cells = &expression.cells;\n    let variant_selector = if num_variants <= 2 {\n        // For num_branches <= 2, we use the index as the variant_selector as the `match`\n        // implementation jumps to the index 0 statement on 0, and to the index 1 statement on\n        // 1.\n        index\n    } else {\n        // For num_branches > 2, the `enum_match` libfunc is implemented using a jump table. In\n        // order to optimize `enum_match`, we define the variant_selector as the relevant\n        // relative jump in case we match the actual variant.\n        //\n        // - To jump to the variant in index 0, we skip the jump table and directly jump to it. Its\n        //   location is (2 * n - 1) CASM steps ahead, where n is the number of variants in this\n        //   enum (2 per variant but the first variant, and 1 for the first jump with a deref\n        //   operand).\n        // - To jump to the variant in index k, we add \"jump rel (2 * (n - k) - 1)\" as the first\n        //   jump is of size 1 and the rest of the jump instructions are with an immediate operand,\n        //   which makes them of size 2.\n        match (num_variants - index).checked_mul(2) {\n            Some(double) => double - 1,\n            None => {\n                return Err(InvocationError::IntegerOverflow);\n            }\n        }\n    };\n\n    let variant_size = builder\n        .program_info\n        .type_sizes\n        .get(&builder.libfunc.param_signatures()[0].ty)\n        .ok_or(InvocationError::UnknownTypeData)?\n        .to_owned();\n    if init_arg_cells.len() != variant_size as usize {\n        return Err(InvocationError::InvalidReferenceExpressionForArgument);\n    }\n    // Pad the variant to match the size of the largest variant\n    let concrete_enum_type = &builder.libfunc.output_types()[0][0];\n    let enum_size = get_enum_size(&builder.program_info, concrete_enum_type)\n        .ok_or(InvocationError::UnknownTypeData)?;\n    let num_padding = enum_size - 1 - variant_size;\n    let inner_value = chain!(\n        repeat_n(CellExpression::Immediate(BigInt::from(0)), num_padding as usize),\n        init_arg_cells.clone(),\n    )\n    .collect();\n\n    let enum_val = EnumView {\n        variant_selector: CellExpression::Immediate(BigInt::from(variant_selector)),\n        inner_value,\n    };\n    let output_expressions = [enum_val.to_reference_expression()].into_iter();\n    Ok(builder.build_only_reference_changes(output_expressions))\n}\n\n/// Handles statement for matching an enum.\nfn build_enum_match(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let concrete_enum_type = &builder.libfunc.param_signatures()[0].ty;\n    let [expression] = builder.try_get_refs()?;\n    let matched_var = EnumView::try_get_view(expression, &builder.program_info, concrete_enum_type)\n        .map_err(|_| InvocationError::InvalidReferenceExpressionForArgument)?;\n    // Verify variant_selector is of type deref. This is the case with an enum_value\n    // that was validly created and then stored.\n    let variant_selector =\n        try_extract_matches!(matched_var.variant_selector, CellExpression::Deref)\n            .ok_or(InvocationError::InvalidReferenceExpressionForArgument)?;\n\n    let mut branch_output_sizes: Vec<usize> = Vec::new();\n    for branch_outputs in &builder.libfunc.output_types() {\n        // Each branch has a single output.\n        let branch_output = &branch_outputs[0];\n        let branch_output_size = builder\n            .program_info\n            .type_sizes\n            .get(branch_output)\n            .ok_or(InvocationError::UnknownTypeData)?;\n        branch_output_sizes.push(*branch_output_size as usize);\n    }\n    let output_expressions = branch_output_sizes.into_iter().map(|size| {\n        // The size of an output must be smaller than the size of `matched_var.inner_value` as the\n        // size of inner_value is fixed and is calculated as the max of the sizes of all the\n        // variants (which are the outputs in all the branches). Thus it is guaranteed that the\n        // iter we generate here is of size `size` (and not less).\n        let padding_size = matched_var.inner_value.len() - size;\n        vec![ReferenceExpression {\n            cells: matched_var.inner_value.iter().skip(padding_size).cloned().collect(),\n        }]\n        .into_iter()\n    });\n\n    let num_branches = builder.invocation.branches.len();\n    if num_branches <= 2 {\n        build_enum_match_short(builder, variant_selector, output_expressions)\n    } else {\n        build_enum_match_long(builder, variant_selector, output_expressions)\n    }\n}\n\n/// Handles statement for matching an enum with 1 or 2 variants.\n/// For example, with this setup\n/// ```ignore\n/// type felt252_ty = felt252;\n/// type unit_ty = Tuple;\n/// type Option = Enum<felt252_ty, unit_ty>;\n/// libfunc init_option_some = enum_init<Option, 0>;\n/// libfunc match_option = enum_match<Option>;\n/// felt252_const<8>() -> (felt8);\n/// init_option_some(felt8=[ap-5]) -> (enum_var);\n/// ````\n/// this \"Sierra statement\" (2-variants-enum)\n/// ```ignore\n/// match_option(enum_var=[ap-10]) {fallthrough(some=[ap-9]), 2000(none=[ap-9])};\n/// ```\n/// translates to these casm instructions:\n/// ```ignore\n/// jmp rel <jump_offset_2000> if [ap-10] != 0\n/// jmp rel <jump_offset_fallthrough>\n/// ```\n/// Or this \"Sierra statement\" (single-variant-enum)\n/// ```ignore\n/// match_option(enum_var=[ap-10]) {fallthrough(var=[ap-9])};\n/// ```\n/// translates to 0 casm instructions.\n///\n/// Assumes that builder.invocation.branches.len() == output_expressions.len() and that\n/// builder.invocation.branches.len() <= 2.\nfn build_enum_match_short(\n    builder: CompiledInvocationBuilder<'_>,\n    variant_selector: CellRef,\n    output_expressions: impl ExactSizeIterator<\n        Item = impl ExactSizeIterator<Item = ReferenceExpression>,\n    >,\n) -> Result<CompiledInvocation, InvocationError> {\n    let mut instructions = Vec::new();\n    let mut relocations = Vec::new();\n\n    // First branch is fallthrough. If there is only one branch, this `match` statement is\n    // translated to nothing in Casm.\n\n    // If we have 2 branches, add the jump_nz instruction to branch 1 if variant_selector != 0.\n    if let Some(branch) = builder.invocation.branches.get(1) {\n        let statement_id = match branch {\n            BranchInfo { target: BranchTarget::Statement(statement_id), .. } => *statement_id,\n            _ => panic!(\"malformed invocation\"),\n        };\n\n        instructions.extend(casm! { jmp rel 0 if variant_selector != 0; }.instructions);\n        relocations.push(RelocationEntry {\n            instruction_idx: 0,\n            relocation: Relocation::RelativeStatementId(statement_id),\n        });\n    }\n\n    Ok(builder.build(instructions, relocations, output_expressions))\n}\n\n/// Handles statement for matching an enum with 3+ variants.\n/// For example, with this setup\n/// ```ignore\n/// type felt252_ty = felt252;\n/// type Positivity = Enum<felt252_ty, felt252_ty, felt252_ty>;\n/// libfunc init_positive = enum_init<Positivity, 0>;\n/// libfunc match_positivity = enum_match<Positivity>;\n/// felt252_const<8>() -> (felt8);\n/// init_positive(felt8=[ap-5]) -> (enum_var);\n/// ````\n/// this \"Sierra statement\" (3-variants-enum)\n/// ```ignore\n/// match_positivity(enum_var=[ap-10]) {fallthrough(pos=[ap-9]), 2000(neg=[ap-9]), 3000(zero=[ap-9])};\n/// ```\n/// translates to these casm instructions:\n/// ```ignore\n/// jmp rel [ap-10]\n/// jmp rel <jump_offset_2000>\n/// jmp rel <jump_offset_3000>\n/// ```\n/// Where in the first location of the enum_var there will be the jmp_table_idx (2*n-1 for\n/// branch index 0 (where n is the number of variants of this enum), 1 for branch index 1, 3 for\n/// branch index 2 and so on: (2 * k - 1) for branch index k).\n///\n/// Assumes that self.invocation.branches.len() == output_expressions.len() > 2.\nfn build_enum_match_long(\n    builder: CompiledInvocationBuilder<'_>,\n    variant_selector: CellRef,\n    output_expressions: impl ExactSizeIterator<\n        Item = impl ExactSizeIterator<Item = ReferenceExpression>,\n    >,\n) -> Result<CompiledInvocation, InvocationError> {\n    let target_statement_ids = builder.invocation.branches[1..].iter().map(|b| match b {\n        BranchInfo { target: BranchTarget::Statement(stmnt_id), .. } => *stmnt_id,\n        _ => panic!(\"malformed invocation\"),\n    });\n\n    // The first instruction is the jmp to the relevant index in the jmp table.\n    let mut ctx = casm! { jmp rel variant_selector; };\n    let mut relocations = Vec::new();\n\n    // Add a jump-table entry for all the branches but the first one (we directly jump to it from\n    // the first jump above).\n    for (i, stmnt_id) in target_statement_ids.rev().enumerate() {\n        // Add the jump instruction to the relevant target.\n        casm_extend!(ctx, jmp rel 0;);\n        relocations.push(RelocationEntry {\n            instruction_idx: i + 1,\n            relocation: Relocation::RelativeStatementId(stmnt_id),\n        });\n    }\n\n    Ok(builder.build(ctx.instructions, relocations, output_expressions))\n}\n\n/// A struct representing an actual enum value in the Sierra program.\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct EnumView {\n    /// This would be ReferenceExpression::Immediate after enum_init, and would be\n    /// ReferenceExpression::Deref after store_*.\n    pub variant_selector: CellExpression,\n    /// The inner value of the enum (a flat vector of cell expressions), padded with\n    /// CellExpression::Padding to match the size of the largest variant.\n    pub inner_value: Vec<CellExpression>,\n}\n\nimpl ReferenceExpressionView for EnumView {\n    type Error = ReferencesError;\n\n    fn try_get_view(\n        expr: &ReferenceExpression,\n        program_info: &ProgramInfo<'_>,\n        enum_concrete_type: &ConcreteTypeId,\n    ) -> Result<Self, Self::Error> {\n        let enum_size = get_enum_size(program_info, enum_concrete_type)\n            .ok_or(ReferencesError::InvalidReferenceTypeForArgument)?\n            as usize;\n        // Verify the size.\n        if expr.cells.len() != enum_size {\n            return Err(ReferencesError::InvalidReferenceTypeForArgument);\n        }\n\n        let mut expr_cells_iter = expr.cells.iter();\n        let variant_selector =\n            expr_cells_iter.next().ok_or(ReferencesError::InvalidReferenceTypeForArgument)?.clone();\n\n        Ok(EnumView { variant_selector, inner_value: expr_cells_iter.cloned().collect() })\n    }\n\n    fn to_reference_expression(self) -> ReferenceExpression {\n        ReferenceExpression {\n            cells: chain!(\n                // Variant selector\n                vec![self.variant_selector].into_iter(),\n                // actual value's cells\n                self.inner_value.into_iter(),\n            )\n            .collect(),\n        }\n    }\n}\n\n/// Gets the size of the given concrete enum type.\nfn get_enum_size(\n    program_info: &ProgramInfo<'_>,\n    concrete_enum_type: &ConcreteTypeId,\n) -> Option<i16> {\n    Some(program_info.type_sizes.get(concrete_enum_type)?.to_owned())\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_casm::builder::{CasmBuilder, Var};\nuse cairo_lang_casm::casm_build_extend;\nuse cairo_lang_casm::cell_expression::{CellExpression, CellOperator};\nuse cairo_lang_sierra::extensions::felt252::{\n    Felt252BinaryOpConcreteLibfunc, Felt252BinaryOperationConcrete, Felt252BinaryOperator,\n    Felt252Concrete, Felt252OperationWithConstConcreteLibfunc,\n};\nuse num_bigint::BigInt;\n\nuse super::misc::build_is_zero;\nuse super::{CompiledInvocation, CompiledInvocationBuilder, InvocationError};\nuse crate::invocations::{add_input_variables, CostValidationInfo};\nuse crate::references::ReferenceExpression;\n\n#[cfg(test)]\n#[path = \"felt252_test.rs\"]\nmod test;\n\n/// Builds instructions for Sierra felt252 operations.\npub fn build(\n    libfunc: &Felt252Concrete,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    match libfunc {\n        Felt252Concrete::BinaryOperation(Felt252BinaryOperationConcrete::WithVar(\n            Felt252BinaryOpConcreteLibfunc { operator, .. },\n        )) => build_felt252_op_with_var(builder, *operator),\n        Felt252Concrete::BinaryOperation(Felt252BinaryOperationConcrete::WithConst(\n            Felt252OperationWithConstConcreteLibfunc { operator, c, .. },\n        )) => build_felt252_op_with_const(builder, *operator, c.clone()),\n        Felt252Concrete::IsZero(_) => build_is_zero(builder),\n        Felt252Concrete::Const(libfunc) => Ok(builder.build_only_reference_changes(\n            [ReferenceExpression::from_cell(CellExpression::Immediate(libfunc.c.clone()))]\n                .into_iter(),\n        )),\n    }\n}\n\n/// Handles a felt252 operation with a variable.\nfn build_felt252_op_with_var(\n    builder: CompiledInvocationBuilder<'_>,\n    op: Felt252BinaryOperator,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [a, b] = builder.try_get_single_cells()?;\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        deref a;\n        deref_or_immediate b;\n    };\n    let (res_var, extra_costs) = bin_op_helper(&mut casm_builder, a, b, op);\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[res_var]], None)],\n        CostValidationInfo { range_check_info: None, extra_costs: Some([extra_costs]) },\n    ))\n}\n\n/// Handles a felt252 operation with a const.\nfn build_felt252_op_with_const(\n    builder: CompiledInvocationBuilder<'_>,\n    op: Felt252BinaryOperator,\n    c: BigInt,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [a] = builder.try_get_single_cells()?;\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder, deref a; };\n    let c = casm_builder.add_var(CellExpression::Immediate(c));\n    let (res_var, extra_costs) = bin_op_helper(&mut casm_builder, a, c, op);\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[res_var]], None)],\n        CostValidationInfo { range_check_info: None, extra_costs: Some([extra_costs]) },\n    ))\n}\n\n/// Helper for the build felt252 binary op functions: returns the res Var and the extra costs for a\n/// binary operation.\nfn bin_op_helper(\n    casm_builder: &mut CasmBuilder,\n    a: Var,\n    b: Var,\n    op: Felt252BinaryOperator,\n) -> (Var, i32) {\n    if op == Felt252BinaryOperator::Div {\n        casm_build_extend! {casm_builder,\n            tempvar res = a / b;\n        };\n        (res, 400)\n    } else {\n        (casm_builder.bin_op(felt252_to_cell_operator(op), a, b), 0)\n    }\n}\n\n/// Converts a felt252 operator to the corresponding cell operator.\nfn felt252_to_cell_operator(op: Felt252BinaryOperator) -> CellOperator {\n    match op {\n        Felt252BinaryOperator::Add => CellOperator::Add,\n        Felt252BinaryOperator::Sub => CellOperator::Sub,\n        Felt252BinaryOperator::Mul => CellOperator::Mul,\n        Felt252BinaryOperator::Div => CellOperator::Div,\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::vec;\n\nuse cairo_lang_casm::builder::{CasmBuildResult, CasmBuilder, Var};\nuse cairo_lang_casm::casm_build_extend;\nuse cairo_lang_sierra::extensions::felt252_dict::Felt252DictConcreteLibfunc;\nuse cairo_lang_sierra_gas::core_libfunc_cost::{\n    ConstCost, DICT_SQUASH_ACCESS_COST, DICT_SQUASH_FIXED_COST, DICT_SQUASH_REPEATED_ACCESS_COST,\n    DICT_SQUASH_UNIQUE_KEY_COST,\n};\n\nuse super::{CompiledInvocation, CompiledInvocationBuilder, InvocationError};\nuse crate::invocations::CostValidationInfo;\nuse crate::references::ReferenceExpression;\n\nconst DICT_ACCESS_SIZE: i32 = 3;\n\n/// Builds instructions for Sierra single cell dict operations.\npub fn build(\n    libfunc: &Felt252DictConcreteLibfunc,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    match libfunc {\n        Felt252DictConcreteLibfunc::New(_) => build_felt252_dict_new(builder),\n        Felt252DictConcreteLibfunc::Read(_) => build_felt252_dict_read(builder),\n        Felt252DictConcreteLibfunc::Write(_) => build_felt252_dict_write(builder),\n        Felt252DictConcreteLibfunc::Squash(_) => build_felt252_dict_squash(builder),\n    }\n}\n\n/// Handles instruction for creating a new single cell dict.\nfn build_felt252_dict_new(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [segment_arena_ptr] = builder.try_get_single_cells()?;\n    let mut casm_builder = CasmBuilder::default();\n    super::add_input_variables! {casm_builder, buffer(2) segment_arena_ptr; };\n    casm_build_extend! {casm_builder,\n        hint AllocFelt252Dict {segment_arena_ptr: segment_arena_ptr};\n        // Previous SegmentArenaBuiltin.\n        tempvar infos_start = segment_arena_ptr[-3];\n        tempvar n_segments = segment_arena_ptr[-2];\n        tempvar n_finalized = segment_arena_ptr[-1];\n        // New SegmentArenaBuiltin.\n        assert infos_start = *(segment_arena_ptr++);\n        const imm_1 = 1;\n        tempvar new_n_segments = n_segments + imm_1;\n        assert new_n_segments = *(segment_arena_ptr++);\n        assert n_finalized = *(segment_arena_ptr++);\n        const imm_3 = 3;\n        tempvar offset = n_segments * imm_3;\n        tempvar new_dict_end_ptr = infos_start + offset;\n        let new_dict_end = *new_dict_end_ptr;\n    };\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[segment_arena_ptr], &[new_dict_end]], None)],\n        Default::default(),\n    ))\n}\n\n/// Handles instruction for reading from a single cell dict.\nfn build_felt252_dict_read(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [dict_ptr, key] = builder.try_get_single_cells()?;\n\n    let mut casm_builder = CasmBuilder::default();\n    super::add_input_variables! {casm_builder,\n        buffer(2) dict_ptr;\n        deref key;\n    };\n    casm_build_extend! {casm_builder,\n        tempvar value;\n        hint Felt252DictRead {dict_ptr: dict_ptr, key: key} into {value_dst: value};\n        // Write the new dict access.\n        assert key = *(dict_ptr++);\n        assert value = *(dict_ptr++);\n        assert value = *(dict_ptr++);\n    }\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[dict_ptr], &[value]], None)],\n        CostValidationInfo { range_check_info: None, extra_costs: Some([DICT_SQUASH_ACCESS_COST]) },\n    ))\n}\n\n/// Handles instruction for writing to a single cell dict.\nfn build_felt252_dict_write(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [dict_ptr, key, value] = builder.try_get_single_cells()?;\n\n    let mut casm_builder = CasmBuilder::default();\n    super::add_input_variables! {casm_builder,\n        buffer(2) dict_ptr;\n        deref key;\n        deref value;\n    };\n    casm_build_extend! {casm_builder,\n        hint Felt252DictWrite {dict_ptr: dict_ptr, key: key, value: value} into {};\n        // Write the new dict access.\n        assert key = *(dict_ptr++);\n        let _prev_value = *(dict_ptr++);\n        assert value = *(dict_ptr++);\n    }\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[dict_ptr]], None)],\n        CostValidationInfo { range_check_info: None, extra_costs: Some([DICT_SQUASH_ACCESS_COST]) },\n    ))\n}\n\n/// Handles the dict_squash instruction.\nfn build_felt252_dict_squash(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [range_check_ptr, gas_builtin, segment_arena_ptr, dict_end_address] =\n        builder.try_get_single_cells()?;\n    // Counters for the amount of steps in the generated code.\n    let mut fixed_steps: i32 = 0;\n    let mut unique_key_steps: i32 = 0;\n    let mut repeated_access_steps: i32 = 0;\n\n    let mut casm_builder = CasmBuilder::default();\n    super::add_input_variables! {casm_builder,\n        buffer(2) segment_arena_ptr;\n        buffer(0) range_check_ptr;\n        deref gas_builtin;\n        buffer(0) dict_end_address;\n    };\n    let (\n        dict_access_size,\n        one,\n        dict_squash_arg_range_check_ptr,\n        dict_squash_arg_dict_accesses_start,\n        dict_squash_arg_dict_accesses_end,\n        final_range_check_ptr,\n        final_gas_builtin,\n        final_segment_arena_ptr,\n        final_squashed_dict_start,\n        final_squashed_dict_end,\n    ) = {\n        casm_build_extend! {casm_builder,\n            #{ validate steps == 0; }\n            const dict_access_size = DICT_ACCESS_SIZE;\n            const dict_info_size = 3;\n            const one = 1;\n            const gas_refund_per_access = DICT_SQUASH_UNIQUE_KEY_COST;\n            // DestructDict is a wrapper that provides a clean scope for dict_squash where\n            // local variables can be allocated.\n            // Push DestructDict arguments.\n            tempvar dict_destruct_arg_range_check_ptr = range_check_ptr;\n            tempvar dict_destruct_arg_gas_builtin = gas_builtin;\n            tempvar dict_destruct_arg_segment_arena_ptr = segment_arena_ptr;\n            tempvar dict_destruct_arg_dict_end_address = dict_end_address;\n            let (final_range_check_ptr,\n                final_gas_builtin,\n                final_segment_arena_ptr,\n                final_squashed_dict_start,\n                final_squashed_dict_end) = call DestructDict;\n            jump DONE;\n        }\n\n        casm_build_extend! {casm_builder,\n            DestructDict:\n            // Allocates function local variables for data needed after the function calls.\n            localvar dict_index;\n            localvar dict_accesses_len;\n            localvar local_gas_builtin = dict_destruct_arg_gas_builtin;\n            ap += 3;\n            // Guess the index of the dictionary.\n            hint GetSegmentArenaIndex {\n                dict_end_ptr: dict_destruct_arg_dict_end_address\n            } into {dict_index: dict_index};\n            localvar infos = dict_destruct_arg_segment_arena_ptr[-3];\n            localvar n_dicts = dict_destruct_arg_segment_arena_ptr[-2];\n            localvar n_destructed = dict_destruct_arg_segment_arena_ptr[-1];\n            // Verify that dict_index < n_dicts.\n            // Range check use\n            assert dict_index = *(dict_destruct_arg_range_check_ptr++);\n            tempvar n_dicts_minus_1 = n_dicts - one;\n            tempvar n_dicts_minus_1_minus_index = n_dicts_minus_1 - dict_index;\n            // Range check use\n            assert n_dicts_minus_1_minus_index = *(dict_destruct_arg_range_check_ptr++);\n            // Write the missing data in the dict_info (destruction index and the end of the\n            // dict_segment).\n            tempvar info_offset = dict_index * dict_info_size;\n            tempvar info_ptr = infos + info_offset;\n            assert n_destructed = info_ptr[2];\n            assert dict_destruct_arg_dict_end_address = info_ptr[1];\n        }\n        // Split just to avoid recursion limit when the macro is parsed.\n        casm_build_extend! {casm_builder,\n            // Write a new dict_manager data to the dict_manager segment (same except for the\n            // n_destructed which is incremented).\n            assert infos = *(dict_destruct_arg_segment_arena_ptr++);\n            assert n_dicts = *(dict_destruct_arg_segment_arena_ptr++);\n            tempvar n_destructed_plus_1 = n_destructed + one;\n            assert n_destructed_plus_1 = *(dict_destruct_arg_segment_arena_ptr++);\n            // Find the len of the accesses segment.\n            tempvar dict_accesses_start = info_ptr[0];\n            assert dict_accesses_len = dict_destruct_arg_dict_end_address - dict_accesses_start;\n            // Push SquashDictWithAlloc arguments.\n            tempvar dict_squash_arg_range_check_ptr = dict_destruct_arg_range_check_ptr;\n            tempvar dict_squash_arg_dict_accesses_start = info_ptr[0];\n            tempvar dict_squash_arg_dict_accesses_end = dict_destruct_arg_dict_end_address;\n            let (range_check_ptr, squashed_dict_start, squashed_dict_end) = call SquashDictWithAlloc;\n            // Find the number of keys\n            tempvar squashed_dict_len = squashed_dict_end - squashed_dict_start;\n            // The number of refunded accesses is number_of_accesses - number_of_keys, which equals\n            // to dict_accesses_len / dict_access_size - squashed_dict_len / dict_access_size.\n            // Use distributivity to conserve one operation.\n            tempvar accesses_len_minus_squashed_len = dict_accesses_len - squashed_dict_len;\n            tempvar n_refunded_accesses = accesses_len_minus_squashed_len / dict_access_size;\n            tempvar gas_to_refund = n_refunded_accesses * gas_refund_per_access;\n            // Push the returned variables.\n            tempvar returned_range_check_ptr = range_check_ptr;\n            tempvar returned_gas_builtin = local_gas_builtin + gas_to_refund;\n            tempvar returned_segment_arena_ptr = dict_destruct_arg_segment_arena_ptr;\n            tempvar returned_squashed_dict_start = squashed_dict_start;\n            tempvar returned_squashed_dict_end = squashed_dict_end;\n            #{ fixed_steps += steps; steps = 0; }\n            ret;\n        };\n        (\n            dict_access_size,\n            one,\n            dict_squash_arg_range_check_ptr,\n            dict_squash_arg_dict_accesses_start,\n            dict_squash_arg_dict_accesses_end,\n            final_range_check_ptr,\n            final_gas_builtin,\n            final_segment_arena_ptr,\n            final_squashed_dict_start,\n            final_squashed_dict_end,\n        )\n    };\n\n    let (squash_dict_args, fixed_steps_) = build_squash_dict_with_alloc(\n        &mut casm_builder,\n        SquashDictWithAllocArgs {\n            dict_squash_arg_range_check_ptr,\n            dict_squash_arg_dict_accesses_start,\n            dict_squash_arg_dict_accesses_end,\n        },\n    );\n    fixed_steps += fixed_steps_;\n\n    let (squash_dict_inner_args, fixed_steps_) =\n        build_squash_dict(&mut casm_builder, dict_access_size, one, squash_dict_args);\n    fixed_steps += fixed_steps_;\n\n    let (fixed_steps_, unique_key_steps_, repeated_access_steps_) =\n        build_squash_dict_inner(&mut casm_builder, squash_dict_inner_args);\n    fixed_steps += fixed_steps_;\n    unique_key_steps += unique_key_steps_;\n    repeated_access_steps += repeated_access_steps_;\n\n    casm_build_extend! {casm_builder,\n        DONE:\n        #{ fixed_steps += steps; steps = 0; }\n    }\n    // Manually counted, range check uses are marked in the builder code.\n    let fixed_range_checks = 3;\n    let unique_key_range_checks = 6;\n    let repeated_access_range_checks = 1;\n    assert_eq!(\n        ConstCost { steps: fixed_steps, holes: 0, range_checks: fixed_range_checks }.cost(),\n        DICT_SQUASH_FIXED_COST\n    );\n    assert_eq!(\n        ConstCost {\n            steps: repeated_access_steps,\n            holes: 0,\n            range_checks: repeated_access_range_checks\n        }\n        .cost(),\n        DICT_SQUASH_REPEATED_ACCESS_COST\n    );\n    assert_eq!(\n        ConstCost { steps: unique_key_steps, holes: 0, range_checks: unique_key_range_checks }\n            .cost(),\n        DICT_SQUASH_UNIQUE_KEY_COST\n    );\n    let CasmBuildResult { instructions, branches: [(state, _)] } =\n        casm_builder.build([\"Fallthrough\"]);\n\n    Ok(builder.build(\n        instructions,\n        vec![],\n        [[\n            ReferenceExpression { cells: vec![state.get_adjusted(final_range_check_ptr)] },\n            ReferenceExpression { cells: vec![state.get_adjusted(final_gas_builtin)] },\n            ReferenceExpression { cells: vec![state.get_adjusted(final_segment_arena_ptr)] },\n            ReferenceExpression {\n                cells: vec![\n                    state.get_adjusted(final_squashed_dict_start),\n                    state.get_adjusted(final_squashed_dict_end),\n                ],\n            },\n        ]\n        .into_iter()]\n        .into_iter(),\n    ))\n}\n\nstruct SquashDictWithAllocArgs {\n    pub dict_squash_arg_range_check_ptr: Var,\n    pub dict_squash_arg_dict_accesses_start: Var,\n    pub dict_squash_arg_dict_accesses_end: Var,\n}\n\nstruct SquashDictArgs {\n    pub squash_dict_arg_range_check_ptr: Var,\n    pub squash_dict_arg_dict_accesses_start: Var,\n    pub squash_dict_arg_dict_accesses_end: Var,\n    pub squash_dict_arg_squashed_dict_start: Var,\n}\n\nstruct SquashDictInnerArgs {\n    pub squash_dict_inner_arg_range_check_ptr: Var,\n    pub squash_dict_inner_arg_dict_accesses_start: Var,\n    pub squash_dict_inner_arg_dict_accesses_end_minus1: Var,\n    pub squash_dict_inner_arg_key: Var,\n    pub squash_dict_inner_arg_remaining_accesses: Var,\n    pub squash_dict_inner_arg_squashed_dict_end: Var,\n    pub squash_dict_inner_arg_big_keys: Var,\n}\n\n/// Generates CASM code that allocates a segment for the result, and calls `SquashDict`.\nfn build_squash_dict_with_alloc(\n    casm_builder: &mut CasmBuilder,\n    args: SquashDictWithAllocArgs,\n) -> (SquashDictArgs, i32) {\n    let mut fixed_steps = 0;\n\n    let SquashDictWithAllocArgs {\n        dict_squash_arg_range_check_ptr,\n        dict_squash_arg_dict_accesses_start,\n        dict_squash_arg_dict_accesses_end,\n    } = args;\n\n    casm_build_extend! {casm_builder,\n        // Returns a new squashed_dict with one DictAccess instance per key\n        // (value before and value after) which summarizes all the changes to that key.\n        //\n        // Example:\n        //   Input: {(key1, 0, 2), (key1, 2, 7), (key2, 4, 1), (key1, 7, 5), (key2, 1, 2)}\n        //   Output: {(key1, 0, 5), (key2, 4, 2)}\n        //\n        // This is a wrapper of SquashDict.\n        SquashDictWithAlloc:\n        #{ validate steps == 0; }\n        localvar squashed_dict_start;\n        ap += 1;\n        hint AllocSegment {} into {dst: squashed_dict_start};\n        // Push SquashDict arguments.\n        tempvar squash_dict_arg_range_check_ptr = dict_squash_arg_range_check_ptr;\n        tempvar squash_dict_arg_dict_accesses_start = dict_squash_arg_dict_accesses_start;\n        tempvar squash_dict_arg_dict_accesses_end = dict_squash_arg_dict_accesses_end;\n        tempvar squash_dict_arg_squashed_dict_start = squashed_dict_start;\n        let (range_check_ptr, squashed_dict_end) = call SquashDict;\n        // Push the returned variables.\n        tempvar returned_range_check_ptr = range_check_ptr;\n        tempvar returned_squashed_dict_start = squashed_dict_start;\n        tempvar returned_squashed_dict_end = squashed_dict_end;\n        #{ fixed_steps += steps; steps = 0; }\n        ret;\n    };\n    (\n        SquashDictArgs {\n            squash_dict_arg_range_check_ptr,\n            squash_dict_arg_dict_accesses_start,\n            squash_dict_arg_dict_accesses_end,\n            squash_dict_arg_squashed_dict_start,\n        },\n        fixed_steps,\n    )\n}\n\nfn build_squash_dict(\n    casm_builder: &mut CasmBuilder,\n    dict_access_size: Var,\n    one: Var,\n    args: SquashDictArgs,\n) -> (SquashDictInnerArgs, i32) {\n    let mut fixed_steps = 0;\n    let SquashDictArgs {\n        squash_dict_arg_range_check_ptr,\n        squash_dict_arg_dict_accesses_start,\n        squash_dict_arg_dict_accesses_end,\n        squash_dict_arg_squashed_dict_start,\n    } = args;\n\n    casm_build_extend! {casm_builder,\n        // Verifies that dict_accesses lists valid chronological accesses (and updates) to a\n        // mutable dictionary and outputs a squashed dict with one DictAccess instance per key\n        // (value before and value after) which summarizes all the changes to that key.\n        SquashDict:\n        #{ validate steps == 0; }\n        localvar ptr_diff =\n            squash_dict_arg_dict_accesses_end - squash_dict_arg_dict_accesses_start;\n        localvar first_key;\n        localvar big_keys;\n        ap += 2;\n        jump SquashDictNotEmpty if ptr_diff != 0;\n        tempvar returned_range_check_ptr = squash_dict_arg_range_check_ptr;\n        tempvar returned_squashed_dict_end = squash_dict_arg_squashed_dict_start;\n        // SquashDict on empty dict is cheaper than not empty dict. Steps disregarded.\n        #{ steps = 0; }\n        ret;\n        SquashDictNotEmpty:\n        tempvar n_accesses = ptr_diff / dict_access_size;\n        hint InitSquashData {\n            dict_accesses: squash_dict_arg_dict_accesses_start,\n            ptr_diff: ptr_diff, n_accesses: n_accesses\n        } into {big_keys: big_keys, first_key: first_key};\n        let temp_range_check_ptr = squash_dict_arg_range_check_ptr;\n        tempvar squash_dict_inner_arg_range_check_ptr;\n        // Order of if branches is reversed w.r.t. the original code.\n        jump SquashDictIfBigKeys if big_keys != 0;\n        assert first_key = *(temp_range_check_ptr++); // Range check use\n        assert squash_dict_inner_arg_range_check_ptr = temp_range_check_ptr;\n        rescope {\n            squash_dict_inner_arg_range_check_ptr = squash_dict_inner_arg_range_check_ptr,\n            squash_dict_arg_dict_accesses_start = squash_dict_arg_dict_accesses_start,\n            squash_dict_arg_dict_accesses_end = squash_dict_arg_dict_accesses_end,\n            squash_dict_arg_squashed_dict_start = squash_dict_arg_squashed_dict_start,\n            one = one,\n            first_key = first_key,\n            n_accesses = n_accesses,\n            big_keys = big_keys\n        };\n        jump SquashDictEndIfBigKeys;\n        SquashDictIfBigKeys:\n        assert squash_dict_inner_arg_range_check_ptr = temp_range_check_ptr;\n        rescope {\n            squash_dict_inner_arg_range_check_ptr = squash_dict_inner_arg_range_check_ptr,\n            squash_dict_arg_dict_accesses_start = squash_dict_arg_dict_accesses_start,\n            squash_dict_arg_dict_accesses_end = squash_dict_arg_dict_accesses_end,\n            squash_dict_arg_squashed_dict_start = squash_dict_arg_squashed_dict_start,\n            one = one,\n            first_key = first_key,\n            n_accesses = n_accesses,\n            big_keys = big_keys\n        };\n        SquashDictEndIfBigKeys:\n        // Push SquashDictInner arguments.\n        tempvar squash_dict_inner_arg_dict_accesses_start = squash_dict_arg_dict_accesses_start;\n        tempvar squash_dict_inner_arg_dict_accesses_end_minus1 =\n            squash_dict_arg_dict_accesses_end - one;\n        tempvar squash_dict_inner_arg_key = first_key;\n        tempvar squash_dict_inner_arg_remaining_accesses = n_accesses;\n        tempvar squash_dict_inner_arg_squashed_dict_end = squash_dict_arg_squashed_dict_start;\n        tempvar squash_dict_inner_arg_big_keys = big_keys;\n        let (range_check_ptr, squashed_dict_end) = call SquashDictInner;\n        tempvar returned_range_check_ptr = range_check_ptr;\n        tempvar returned_squashed_dict_end = squashed_dict_end;\n        #{ fixed_steps += steps; steps = 0; }\n        ret;\n    };\n    (\n        SquashDictInnerArgs {\n            squash_dict_inner_arg_range_check_ptr,\n            squash_dict_inner_arg_dict_accesses_start,\n            squash_dict_inner_arg_dict_accesses_end_minus1,\n            squash_dict_inner_arg_key,\n            squash_dict_inner_arg_remaining_accesses,\n            squash_dict_inner_arg_squashed_dict_end,\n            squash_dict_inner_arg_big_keys,\n        },\n        fixed_steps,\n    )\n}\n\n/// Generates CASM code for the `SquashDictInner` function.\nfn build_squash_dict_inner(\n    casm_builder: &mut CasmBuilder,\n    args: SquashDictInnerArgs,\n) -> (i32, i32, i32) {\n    let mut fixed_steps = 0;\n    let mut unique_key_steps = 0;\n    let mut repeated_access_steps = 0;\n\n    let SquashDictInnerArgs {\n        squash_dict_inner_arg_range_check_ptr,\n        squash_dict_inner_arg_dict_accesses_start,\n        squash_dict_inner_arg_dict_accesses_end_minus1,\n        squash_dict_inner_arg_key,\n        squash_dict_inner_arg_remaining_accesses,\n        squash_dict_inner_arg_squashed_dict_end,\n        squash_dict_inner_arg_big_keys,\n    } = args;\n\n    casm_build_extend! {casm_builder,\n        // Inner tail-recursive function for squash_dict.\n        // Loops over a single key accesses and verify a valid order.\n        SquashDictInner:\n        #{ validate steps == 0; }\n        localvar aligned_range_check_ptr;\n        localvar aligned_dict_accesses;\n        localvar aligned_dict_accesses_end_minus1;\n        localvar aligned_next_key;\n        localvar aligned_remaining_accesses;\n        // These local vars are used only after the loop rescopes so me need to adjust the ap.\n        ap += 5;\n        const dict_access_size = DICT_ACCESS_SIZE;\n        const zero = 0;\n        const one = 1;\n        localvar next_key;\n        localvar new_remaining_accesses;\n        let dict_diff = squash_dict_inner_arg_squashed_dict_end;\n        // Prepare first loop iteration.\n        hint GetCurrentAccessIndex {\n            range_check_ptr: squash_dict_inner_arg_range_check_ptr\n        } into {};\n        // Range check use, once per unique key\n        tempvar current_access_index = *squash_dict_inner_arg_range_check_ptr;\n        tempvar ptr_delta = current_access_index * dict_access_size;\n        tempvar first_value;\n        tempvar should_skip_loop;\n        tempvar prev_loop_locals_access_ptr =\n            squash_dict_inner_arg_dict_accesses_start + ptr_delta;\n        let first_access = prev_loop_locals_access_ptr;\n        tempvar prev_loop_locals_value = first_access[2]; // The new_value index is 2.\n        tempvar prev_loop_locals_range_check_ptr = squash_dict_inner_arg_range_check_ptr + one;\n        assert squash_dict_inner_arg_key = first_access[0]; // The key index is 0.\n        assert squash_dict_inner_arg_key = dict_diff[0];\n        assert first_value = first_access[1]; // The prev_value index is 1\n        assert first_value = dict_diff[1];\n        assert first_value = zero;\n        hint ShouldSkipSquashLoop {} into {should_skip_loop: should_skip_loop};\n        rescope {\n            squash_dict_inner_arg_dict_accesses_start =\n                squash_dict_inner_arg_dict_accesses_start,\n            prev_loop_locals_access_ptr = prev_loop_locals_access_ptr,\n            prev_loop_locals_value = prev_loop_locals_value,\n            prev_loop_locals_range_check_ptr = prev_loop_locals_range_check_ptr,\n            should_skip_loop = should_skip_loop,\n            one = one,\n            dict_access_size = dict_access_size,\n            squash_dict_inner_arg_key = squash_dict_inner_arg_key,\n            squash_dict_inner_arg_dict_accesses_end_minus1 =\n                squash_dict_inner_arg_dict_accesses_end_minus1,\n            squash_dict_inner_arg_range_check_ptr = squash_dict_inner_arg_range_check_ptr,\n            dict_diff = dict_diff,\n            squash_dict_inner_arg_big_keys = squash_dict_inner_arg_big_keys,\n            squash_dict_inner_arg_remaining_accesses =\n                squash_dict_inner_arg_remaining_accesses,\n            squash_dict_inner_arg_squashed_dict_end = squash_dict_inner_arg_squashed_dict_end,\n            next_key = next_key,\n            new_remaining_accesses = new_remaining_accesses,\n            aligned_range_check_ptr = aligned_range_check_ptr,\n            aligned_dict_accesses = aligned_dict_accesses,\n            aligned_dict_accesses_end_minus1 = aligned_dict_accesses_end_minus1,\n            aligned_next_key = aligned_next_key,\n            aligned_remaining_accesses = aligned_remaining_accesses\n        };\n        #{ unique_key_steps += steps; steps = 0; }\n        // Skip loop nondeterministically if necessary.\n        // The verifier doesn't care if the loop is skipped or not. The only thing it checks\n        // is that the function iterated over remaining_accesses accesses in total\n        // with ascending keys and ascending indices for the same key.\n        // This guarantees that all the entries were visited exactly once.\n        jump SquashDictInnerSkipLoop if should_skip_loop != 0;\n    }\n    repeated_access_steps += build_squash_dict_inner_loop(\n        casm_builder,\n        args,\n        SquashDictInnerLoopArgs {\n            prev_loop_locals_range_check_ptr,\n            prev_loop_locals_access_ptr,\n            prev_loop_locals_value,\n            dict_diff,\n            next_key,\n            new_remaining_accesses,\n            aligned_range_check_ptr,\n            aligned_dict_accesses,\n            aligned_dict_accesses_end_minus1,\n            aligned_next_key,\n            aligned_remaining_accesses,\n        },\n    );\n    casm_build_extend! {casm_builder,\n        SquashDictInnerSkipLoop:\n        let last_loop_locals_access_ptr = prev_loop_locals_access_ptr;\n        let last_loop_locals_value = prev_loop_locals_value;\n        let last_loop_locals_range_check_ptr = prev_loop_locals_range_check_ptr;\n        hint AssertCurrentAccessIndicesIsEmpty {} into {};\n        tempvar dict_slack =\n            squash_dict_inner_arg_dict_accesses_end_minus1 - last_loop_locals_access_ptr;\n        // Range check use, once per unique key.\n        assert dict_slack = *last_loop_locals_range_check_ptr;\n        tempvar n_used_accesses =\n            last_loop_locals_range_check_ptr - squash_dict_inner_arg_range_check_ptr;\n        hint AssertAllAccessesUsed {} into {n_used_accesses: n_used_accesses};\n        assert last_loop_locals_value = dict_diff[2];\n        const one = 1;\n        let arg_range_check_ptr = last_loop_locals_range_check_ptr + one;\n        assert new_remaining_accesses =\n            squash_dict_inner_arg_remaining_accesses - n_used_accesses;\n        #{ unique_key_steps += steps; steps = 0; }\n        jump SquashDictInnerContinueRecursion if new_remaining_accesses != 0;\n        hint AssertAllKeysUsed {} into {};\n        // Return from squash_dict_inner, push values to the stack and return;\n        tempvar retuened_range_check_ptr = arg_range_check_ptr;\n        const dict_access_size = DICT_ACCESS_SIZE;\n        tempvar retuened_squashed_dict =\n            squash_dict_inner_arg_squashed_dict_end + dict_access_size;\n        #{ fixed_steps += steps; steps = 0; }\n        ret;\n    }\n    // Split just to avoid recursion limit when the macro is parsed.\n    casm_build_extend! {casm_builder,\n        SquashDictInnerContinueRecursion:\n        hint GetNextDictKey {} into {next_key: next_key};\n        // The if order is reversed w.r.t. the original code since the fallthrough case in the\n        // original code is the big_keys != 0 case.\n        jump SquashDictInnerIfBigKeys if squash_dict_inner_arg_big_keys != 0;\n        tempvar key_plus1 = squash_dict_inner_arg_key + one;\n        tempvar key_diff = next_key - key_plus1;\n        assert key_diff = *(arg_range_check_ptr++);\n        // Writing the needed invalidated variables because of the branch.\n        assert aligned_range_check_ptr = arg_range_check_ptr;\n        assert aligned_dict_accesses = squash_dict_inner_arg_dict_accesses_start;\n        assert aligned_dict_accesses_end_minus1 = squash_dict_inner_arg_dict_accesses_end_minus1;\n        assert aligned_next_key = next_key;\n        assert aligned_remaining_accesses = new_remaining_accesses;\n        rescope {\n            aligned_dict_accesses = aligned_dict_accesses,\n            aligned_dict_accesses_end_minus1 = aligned_dict_accesses_end_minus1,\n            aligned_next_key = aligned_next_key,\n            aligned_remaining_accesses = aligned_remaining_accesses,\n            aligned_range_check_ptr = aligned_range_check_ptr,\n            squash_dict_inner_arg_squashed_dict_end = squash_dict_inner_arg_squashed_dict_end,\n            squash_dict_inner_arg_big_keys = squash_dict_inner_arg_big_keys\n        };\n        jump SquashDictInnerEndIfBigKeys;\n        SquashDictInnerIfBigKeys:\n    }\n    validate_felt252_lt(\n        casm_builder,\n        squash_dict_inner_arg_range_check_ptr,\n        squash_dict_inner_arg_key,\n        next_key,\n    );\n    casm_build_extend! {casm_builder,\n        // Writing the needed invalidated variables because of the branch.\n        assert aligned_range_check_ptr = squash_dict_inner_arg_range_check_ptr;\n        assert aligned_dict_accesses = squash_dict_inner_arg_dict_accesses_start;\n        assert aligned_dict_accesses_end_minus1 = squash_dict_inner_arg_dict_accesses_end_minus1;\n        assert aligned_next_key = next_key;\n        assert aligned_remaining_accesses = new_remaining_accesses;\n        rescope {\n            aligned_dict_accesses = aligned_dict_accesses,\n            aligned_dict_accesses_end_minus1 = aligned_dict_accesses_end_minus1,\n            aligned_next_key = aligned_next_key,\n            aligned_remaining_accesses = aligned_remaining_accesses,\n            aligned_range_check_ptr = aligned_range_check_ptr,\n            squash_dict_inner_arg_squashed_dict_end = squash_dict_inner_arg_squashed_dict_end,\n            squash_dict_inner_arg_big_keys = squash_dict_inner_arg_big_keys\n        };\n        SquashDictInnerEndIfBigKeys:\n        tempvar rec_arg_range_check_ptr = aligned_range_check_ptr;\n        tempvar rec_arg_dict_accesses = aligned_dict_accesses;\n        tempvar rec_arg_dict_accesses_end_minus1 = aligned_dict_accesses_end_minus1;\n        tempvar rec_arg_key = aligned_next_key;\n        tempvar rec_arg_remaining_accesses = aligned_remaining_accesses;\n        const dict_access_size = DICT_ACCESS_SIZE;\n        tempvar rec_arg_squashed_dict =\n            squash_dict_inner_arg_squashed_dict_end + dict_access_size;\n        tempvar rec_arg_big_keys = squash_dict_inner_arg_big_keys;\n        let () = call SquashDictInner;\n        #{ unique_key_steps += steps; steps = 0; }\n        ret;\n    };\n    (fixed_steps, unique_key_steps, repeated_access_steps)\n}\n\nstruct SquashDictInnerLoopArgs {\n    prev_loop_locals_range_check_ptr: Var,\n    prev_loop_locals_access_ptr: Var,\n    prev_loop_locals_value: Var,\n    dict_diff: Var,\n    next_key: Var,\n    new_remaining_accesses: Var,\n    aligned_range_check_ptr: Var,\n    aligned_dict_accesses: Var,\n    aligned_dict_accesses_end_minus1: Var,\n    aligned_next_key: Var,\n    aligned_remaining_accesses: Var,\n}\n\nfn build_squash_dict_inner_loop(\n    casm_builder: &mut CasmBuilder,\n    args: SquashDictInnerArgs,\n    loop_args: SquashDictInnerLoopArgs,\n) -> i32 {\n    let mut repeated_access_steps = 0;\n    let SquashDictInnerArgs {\n        squash_dict_inner_arg_range_check_ptr,\n        squash_dict_inner_arg_dict_accesses_start,\n        squash_dict_inner_arg_dict_accesses_end_minus1,\n        squash_dict_inner_arg_key,\n        squash_dict_inner_arg_remaining_accesses,\n        squash_dict_inner_arg_squashed_dict_end,\n        squash_dict_inner_arg_big_keys,\n    } = args;\n    let SquashDictInnerLoopArgs {\n        prev_loop_locals_range_check_ptr,\n        prev_loop_locals_access_ptr,\n        prev_loop_locals_value,\n        dict_diff,\n        next_key,\n        new_remaining_accesses,\n        aligned_range_check_ptr,\n        aligned_dict_accesses,\n        aligned_dict_accesses_end_minus1,\n        aligned_next_key,\n        aligned_remaining_accesses,\n    } = loop_args;\n\n    casm_build_extend! {casm_builder,\n        const dict_access_size = DICT_ACCESS_SIZE;\n        const one = 1;\n        SquashDictInnerLoop:\n        tempvar loop_temps_index_delta_minus1;\n        tempvar loop_temps_index_delta;\n        tempvar loop_temps_ptr_delta;\n        tempvar loop_temps_should_continue;\n        tempvar loop_locals_access_ptr;\n        tempvar loop_locals_value;\n        tempvar loop_locals_range_check_ptr;\n        hint GetCurrentAccessDelta {} into {index_delta_minus1: loop_temps_index_delta_minus1};\n        // Check that the transition from the previous access to the current is valid.\n        // Range check use, once per access\n        assert loop_temps_index_delta_minus1 = *prev_loop_locals_range_check_ptr;\n        assert loop_temps_index_delta = loop_temps_index_delta_minus1 + one;\n        assert loop_temps_ptr_delta = loop_temps_index_delta * dict_access_size;\n        assert loop_locals_access_ptr = prev_loop_locals_access_ptr + loop_temps_ptr_delta;\n        assert prev_loop_locals_value = loop_locals_access_ptr[1];\n        assert loop_locals_value = loop_locals_access_ptr[2];\n        assert squash_dict_inner_arg_key = loop_locals_access_ptr[0];\n        assert loop_locals_range_check_ptr = prev_loop_locals_range_check_ptr + one;\n        hint ShouldContinueSquashLoop {} into {should_continue: loop_temps_should_continue};\n        rescope {\n            squash_dict_inner_arg_dict_accesses_start =\n                squash_dict_inner_arg_dict_accesses_start,\n            prev_loop_locals_access_ptr = loop_locals_access_ptr,\n            prev_loop_locals_value = loop_locals_value,\n            prev_loop_locals_range_check_ptr = loop_locals_range_check_ptr,\n            loop_temps_should_continue = loop_temps_should_continue,\n            squash_dict_inner_arg_key = squash_dict_inner_arg_key,\n            squash_dict_inner_arg_dict_accesses_end_minus1 =\n                squash_dict_inner_arg_dict_accesses_end_minus1,\n            squash_dict_inner_arg_range_check_ptr = squash_dict_inner_arg_range_check_ptr,\n            dict_diff = dict_diff,\n            squash_dict_inner_arg_squashed_dict_end = squash_dict_inner_arg_squashed_dict_end,\n            squash_dict_inner_arg_big_keys = squash_dict_inner_arg_big_keys,\n            squash_dict_inner_arg_remaining_accesses =\n                squash_dict_inner_arg_remaining_accesses,\n            next_key = next_key,\n            new_remaining_accesses = new_remaining_accesses,\n            aligned_range_check_ptr = aligned_range_check_ptr,\n            aligned_dict_accesses = aligned_dict_accesses,\n            aligned_dict_accesses_end_minus1 = aligned_dict_accesses_end_minus1,\n            aligned_next_key = aligned_next_key,\n            aligned_remaining_accesses = aligned_remaining_accesses\n        };\n        #{ repeated_access_steps += steps; steps = 0; }\n        jump SquashDictInnerLoop if loop_temps_should_continue != 0;\n    }\n\n    repeated_access_steps\n}\n\n/// Asserts that the unsigned integer lift (as a number in the range [0, PRIME)) of a is lower than\n/// to that of b.\nfn validate_felt252_lt(casm_builder: &mut CasmBuilder, range_check: Var, a: Var, b: Var) {\n    casm_build_extend! {casm_builder,\n        AssertLtFelt252:\n        const one = 1;\n        hint AssertLtAssertValidInput {a: a, b: b} into {};\n        tempvar a_minus_b = a - b;\n        tempvar assert_le_arg_a;\n        jump AssertLtFelt252NEQ if a_minus_b != 0;\n        assert assert_le_arg_a = a + one;\n        jump AssertLtFelt252End;\n        AssertLtFelt252NEQ:\n        assert assert_le_arg_a = a;\n        AssertLtFelt252End:\n    }\n    validate_felt252_le(casm_builder, range_check, assert_le_arg_a, b);\n}\n\n/// Asserts that the unsigned integer lift (as a number in the range [0, PRIME)) of a is lower than\n/// or equal to that of b.\n/// The numbers [0, a, b, PRIME - 1] should be ordered. To prove that, we show that two of the\n/// 3 arcs {0 -> a, a -> b, b -> PRIME - 1} are small:\n///   One is less than PRIME / 3 + 2 ** 129.\n///   Another is less than PRIME / 2 + 2 ** 129.\n/// Since the sum of the lengths of these two arcs is less than PRIME, there is no wrap-around.\nfn validate_felt252_le(casm_builder: &mut CasmBuilder, range_check: Var, a: Var, b: Var) {\n    casm_build_extend! {casm_builder,\n        const one = 1;\n        const minus_1 = -1;\n        // ceil((PRIME / 2) / 2 ** 128).\n        const prime_over_2_high = 3544607988759775765608368578435044694_u128;\n        // ceil((PRIME / 3) / 2 ** 128).\n        const prime_over_3_high = 5316911983139663648412552867652567041_u128;\n        // Guess two arc lengths.\n        hint AssertLeFindSmallArcs {range_check_ptr: range_check, a: a, b: b} into {};\n        // Calculate the arc lengths.\n        // Range check use, 4 times, once per unique key\n        tempvar arc_short_low = *(range_check++);\n        tempvar arc_short_high_temp = *(range_check++);\n        tempvar arc_short_high = arc_short_high_temp * prime_over_3_high;\n        tempvar arc_short = arc_short_low+arc_short_high;\n        tempvar arc_long_low = *(range_check++);\n        tempvar arc_long_high_temp = *(range_check++);\n        tempvar arc_long_high = arc_long_high_temp * prime_over_2_high;\n        tempvar arc_long = arc_long_low+arc_long_high;\n        tempvar arc_sum = arc_short + arc_long;\n        tempvar arc_prod = arc_short * arc_long;\n        // First, choose which arc to exclude from {0 -> a, a -> b, b -> PRIME - 1}.\n        // Then, to compare the set of two arc lengths, compare their sum and product.\n        tempvar skip_exclude_a_flag;\n        hint AssertLeIsFirstArcExcluded {} into {skip_exclude_a_flag: skip_exclude_a_flag};\n        jump AssertLeFelt252SkipExcludeA if skip_exclude_a_flag != 0;\n        // Exclude \"0 -> a\".\n        tempvar minus_arg_a = a*minus_1;\n        assert arc_sum = minus_arg_a + minus_1;\n        tempvar a_minus_b = a - b;\n        tempvar b_plus_1 = b + one;\n        assert arc_prod = a_minus_b * b_plus_1;\n        jump EndOfFelt252Le;\n        AssertLeFelt252SkipExcludeA:\n        tempvar skip_exclude_b_minus_a;\n        hint AssertLeIsSecondArcExcluded {} into {skip_exclude_b_minus_a: skip_exclude_b_minus_a};\n        jump AssertLeFelt252SkipExcludeBMinusA if skip_exclude_b_minus_a != 0;\n        // Exclude \"a -> b\".\n        tempvar minus_arg_b = b*minus_1;\n        tempvar minus_b_minus_1 = b + minus_1;\n        assert arc_sum = a + minus_b_minus_1;\n        assert arc_prod = a * minus_b_minus_1;\n        jump EndOfFelt252Le;\n        AssertLeFelt252SkipExcludeBMinusA:\n        tempvar _padding;\n        hint AssertLeAssertThirdArcExcluded {} into {};\n        // Exclude \"b -> PRIME - 1\".\n        assert arc_sum = b;\n        tempvar b_minus_a = b - a;\n        assert arc_prod = a * b_minus_a;\n        EndOfFelt252Le:\n    };\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_casm::ap_change::ApChange;\nuse cairo_lang_casm::casm;\nuse cairo_lang_sierra::program::StatementIdx;\nuse test_log::test;\n\nuse crate::invocations::test_utils::{\n    compile_libfunc, ReducedBranchChanges, ReducedCompiledInvocation,\n};\nuse crate::ref_expr;\nuse crate::relocations::{Relocation, RelocationEntry};\n\n#[test]\nfn test_felt252_add() {\n    assert_eq!(\n        compile_libfunc(\"felt252_add\", vec![ref_expr!([fp + 5]), ref_expr!([ap + 5])]),\n        ReducedCompiledInvocation {\n            instructions: vec![],\n            relocations: vec![],\n            results: vec![ReducedBranchChanges {\n                refs: vec![ref_expr!([fp + 5] + [ap + 5])],\n                ap_change: ApChange::Known(0)\n            }]\n        }\n    );\n}\n\n#[test]\nfn test_store_temp() {\n    assert_eq!(\n        compile_libfunc(\"store_temp<felt252>\", vec![ref_expr!([fp + 5] + [ap + 5])]),\n        ReducedCompiledInvocation {\n            instructions: casm! {[ap + 0] = [fp + 5] + [ap + 5], ap++;}.instructions,\n            relocations: vec![],\n            results: vec![ReducedBranchChanges {\n                refs: vec![ref_expr!([ap - 1])],\n                ap_change: ApChange::Known(1)\n            }]\n        }\n    );\n}\n\n#[test]\nfn test_jump_nz() {\n    assert_eq!(\n        compile_libfunc(\"felt252_is_zero\", vec![ref_expr!([ap - 5])]),\n        ReducedCompiledInvocation {\n            instructions: casm! {jmp rel 0 if [ap - 5] != 0;}.instructions,\n            relocations: vec![RelocationEntry {\n                instruction_idx: 0,\n                relocation: Relocation::RelativeStatementId(StatementIdx(1))\n            }],\n            results: vec![\n                ReducedBranchChanges { refs: vec![], ap_change: ApChange::Known(0) },\n                ReducedBranchChanges {\n                    refs: vec![ref_expr!([ap - 5])],\n                    ap_change: ApChange::Known(0)\n                }\n            ]\n        }\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::VecDeque;\n\nuse cairo_lang_casm::casm;\nuse cairo_lang_casm::cell_expression::CellExpression;\nuse cairo_lang_casm::operand::{CellRef, Register};\nuse cairo_lang_sierra::extensions::function_call::FunctionCallConcreteLibfunc;\nuse cairo_lang_sierra::extensions::ConcreteLibfunc;\n\nuse super::{\n    check_references_on_stack, CompiledInvocation, CompiledInvocationBuilder, InvocationError,\n};\nuse crate::references::ReferenceExpression;\nuse crate::relocations::{Relocation, RelocationEntry};\n\n/// Handles a function call.\npub fn build(\n    libfunc: &FunctionCallConcreteLibfunc,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    check_references_on_stack(builder.refs)?;\n\n    let output_types = libfunc.output_types();\n    let fallthrough_outputs = &output_types[0];\n\n    let mut refs = VecDeque::with_capacity(fallthrough_outputs.len());\n\n    let mut offset = -1;\n    for output_type in fallthrough_outputs.iter().rev() {\n        let size = builder\n            .program_info\n            .type_sizes\n            .get(output_type)\n            .ok_or(InvocationError::UnknownVariableData)?;\n        refs.push_front(ReferenceExpression {\n            cells: ((offset - size + 1)..(offset + 1))\n                .map(|i| CellExpression::Deref(CellRef { register: Register::AP, offset: i }))\n                .collect(),\n        });\n        offset -= size;\n    }\n\n    Ok(builder.build(\n        casm! { call rel 0; }.instructions,\n        vec![RelocationEntry {\n            instruction_idx: 0,\n            relocation: Relocation::RelativeStatementId(libfunc.function.entry_point),\n        }],\n        [refs.into_iter()].into_iter(),\n    ))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_casm::builder::CasmBuilder;\nuse cairo_lang_casm::casm_build_extend;\nuse cairo_lang_casm::cell_expression::{CellExpression, CellOperator};\nuse cairo_lang_casm::operand::DerefOrImmediate;\nuse cairo_lang_sierra::extensions::builtin_cost::CostTokenType;\nuse cairo_lang_sierra::extensions::gas::GasConcreteLibfunc;\nuse num_bigint::BigInt;\n\nuse super::{misc, CompiledInvocation, CompiledInvocationBuilder, InvocationError};\nuse crate::invocations::{\n    add_input_variables, get_non_fallthrough_statement_id, CostValidationInfo,\n};\nuse crate::references::ReferenceExpression;\n\n/// Builds instructions for Sierra gas operations.\npub fn build(\n    libfunc: &GasConcreteLibfunc,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    match libfunc {\n        GasConcreteLibfunc::WithdrawGas(_) => build_withdraw_gas(builder),\n        GasConcreteLibfunc::RedepositGas(_) => build_redeposit_gas(builder),\n        GasConcreteLibfunc::GetAvailableGas(_) => misc::build_dup(builder),\n    }\n}\n\n/// Handles the withdraw_gas invocation.\nfn build_withdraw_gas(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let variable_values = &builder.program_info.metadata.gas_info.variable_values;\n    let requested_count: i64 = variable_values\n        .get(&(builder.idx, CostTokenType::Const))\n        .copied()\n        .ok_or(InvocationError::UnknownVariableData)?;\n    let [range_check, gas_counter] = builder.try_get_single_cells()?;\n\n    let failure_handle_statement_id = get_non_fallthrough_statement_id(&builder);\n\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        buffer(1) range_check;\n        deref gas_counter;\n    };\n\n    casm_build_extend! {casm_builder,\n        let orig_range_check = range_check;\n        tempvar has_enough_gas;\n        const requested_count_imm = requested_count;\n        hint TestLessThanOrEqual {\n            lhs: requested_count_imm,\n            rhs: gas_counter\n        } into {dst: has_enough_gas};\n        jump HasEnoughGas if has_enough_gas != 0;\n        const gas_counter_fix = (BigInt::from(u128::MAX) + 1 - requested_count) as BigInt;\n        tempvar gas_diff = gas_counter + gas_counter_fix;\n        assert gas_diff = *(range_check++);\n        jump Failure;\n        HasEnoughGas:\n        tempvar updated_gas = gas_counter - requested_count_imm;\n        assert updated_gas = *(range_check++);\n    };\n\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [\n            (\"Fallthrough\", &[&[range_check], &[updated_gas]], None),\n            (\"Failure\", &[&[range_check], &[gas_counter]], Some(failure_handle_statement_id)),\n        ],\n        CostValidationInfo {\n            range_check_info: Some((orig_range_check, range_check)),\n            extra_costs: Some([-requested_count as i32, 0]),\n        },\n    ))\n}\n\n/// Handles the redeposit_gas invocation.\nfn build_redeposit_gas(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let variable_values = &builder.program_info.metadata.gas_info.variable_values;\n    let requested_count: i64 = variable_values\n        .get(&(builder.idx, CostTokenType::Const))\n        .copied()\n        .ok_or(InvocationError::UnknownVariableData)?;\n    let gas_counter_value = builder.try_get_single_cells::<1>()?[0]\n        .to_deref()\n        .ok_or(InvocationError::InvalidReferenceExpressionForArgument)?;\n\n    Ok(builder.build_only_reference_changes(\n        [if requested_count == 0 {\n            ReferenceExpression::from_cell(CellExpression::Deref(gas_counter_value))\n        } else {\n            ReferenceExpression::from_cell(CellExpression::BinOp {\n                op: CellOperator::Add,\n                a: gas_counter_value,\n                b: DerefOrImmediate::Immediate(requested_count.into()),\n            })\n        }]\n        .into_iter(),\n    ))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_casm::ap_change::{ApChange, ApplyApChange};\nuse cairo_lang_casm::cell_expression::{CellExpression, CellOperator};\nuse cairo_lang_casm::instructions::Instruction;\nuse cairo_lang_casm::operand::{CellRef, Register};\nuse cairo_lang_casm::{casm, casm_extend};\nuse cairo_lang_sierra::extensions::lib_func::SignatureAndTypeConcreteLibfunc;\nuse cairo_lang_sierra::extensions::mem::MemConcreteLibfunc;\nuse cairo_lang_sierra::ids::ConcreteTypeId;\nuse cairo_lang_utils::casts::usize_as_i16;\n\nuse super::{misc, CompiledInvocation, CompiledInvocationBuilder, InvocationError};\nuse crate::environment::frame_state;\nuse crate::references::ReferenceExpression;\n\n/// Builds instructions for Sierra memory operations.\npub fn build(\n    libfunc: &MemConcreteLibfunc,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    match libfunc {\n        MemConcreteLibfunc::StoreTemp(SignatureAndTypeConcreteLibfunc { ty, .. }) => {\n            build_store_temp(builder, ty)\n        }\n        MemConcreteLibfunc::Rename(_) => misc::build_identity(builder),\n        MemConcreteLibfunc::FinalizeLocals(_) => build_finalize_locals(builder),\n        MemConcreteLibfunc::AllocLocal(SignatureAndTypeConcreteLibfunc { ty, .. }) => {\n            build_alloc_local(builder, ty)\n        }\n        MemConcreteLibfunc::StoreLocal(SignatureAndTypeConcreteLibfunc { ty, .. }) => {\n            build_store_local(builder, ty)\n        }\n    }\n}\n\n/// Adds a single instruction to a casm context.\nmacro_rules! add_instruction {\n    ($ctx:ident, $($tok:tt)*) => {{\n        casm_extend! {$ctx, $($tok)* ;}\n    }}\n}\n\n/// Returns a store instruction. Helper function for store_temp and store_local.\nfn get_store_instructions(\n    builder: &CompiledInvocationBuilder<'_>,\n    src_type: &ConcreteTypeId,\n    mut dst: CellRef,\n    src_expr: &ReferenceExpression,\n) -> Result<Vec<Instruction>, InvocationError> {\n    if builder.program_info.type_sizes.get(src_type).is_none() {\n        return Err(InvocationError::NotSized(builder.invocation.clone()));\n    }\n    let mut ctx = casm!();\n    let mut ap_change = 0;\n    let inc_ap = match dst.register {\n        Register::AP => true,\n        Register::FP => false,\n    };\n    for cell_expr_orig in &src_expr.cells {\n        let cell_expr =\n            cell_expr_orig.clone().apply_ap_change(ApChange::Known(ap_change as usize)).unwrap();\n        match cell_expr {\n            CellExpression::Deref(operand) => add_instruction!(ctx, dst = operand),\n            CellExpression::DoubleDeref(operand, offset) => {\n                add_instruction!(ctx, dst = [[&operand] + offset])\n            }\n            CellExpression::Immediate(operand) => add_instruction!(ctx, dst = operand),\n            CellExpression::BinOp { op, a, b } => match op {\n                CellOperator::Add => add_instruction!(ctx, dst = a + b),\n                CellOperator::Mul => add_instruction!(ctx, dst = a * b),\n                // dst = a - b => a = dst + b\n                CellOperator::Sub => add_instruction!(ctx, a = dst + b),\n                // dst = a / b => a = dst * b\n                CellOperator::Div => add_instruction!(ctx, a = dst * b),\n            },\n        }\n        if inc_ap {\n            ap_change += 1;\n            ctx.instructions.last_mut().unwrap().inc_ap = true;\n        } else {\n            dst.offset += 1;\n        }\n    }\n    Ok(ctx.instructions)\n}\n\n/// Handles store_temp for the given type.\nfn build_store_temp(\n    builder: CompiledInvocationBuilder<'_>,\n    ty: &ConcreteTypeId,\n) -> Result<CompiledInvocation, InvocationError> {\n    let expression = builder.try_get_refs::<1>()?[0];\n\n    let instructions = get_store_instructions(\n        &builder,\n        ty,\n        CellRef { register: Register::AP, offset: 0 },\n        expression,\n    )?;\n    let type_size = builder.program_info.type_sizes[ty];\n    Ok(builder.build(\n        instructions,\n        vec![],\n        [[ReferenceExpression {\n            cells: (-type_size..0)\n                .map(|i| CellExpression::Deref(CellRef { register: Register::AP, offset: i }))\n                .collect(),\n        }]\n        .into_iter()]\n        .into_iter(),\n    ))\n}\n\n/// Handles store_local for the given type.\nfn build_store_local(\n    builder: CompiledInvocationBuilder<'_>,\n    ty: &ConcreteTypeId,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [dst_expr, src_expr] = builder.try_get_refs()?;\n    let dst = dst_expr\n        .try_unpack_single()?\n        .to_deref()\n        .ok_or(InvocationError::InvalidReferenceExpressionForArgument)?;\n    let instructions = get_store_instructions(&builder, ty, dst, src_expr)?;\n    let type_size = builder.program_info.type_sizes[ty];\n    Ok(builder.build(\n        instructions,\n        vec![],\n        [[ReferenceExpression {\n            cells: (0..type_size)\n                .map(|i| {\n                    CellExpression::Deref(CellRef {\n                        register: Register::FP,\n                        offset: dst.offset + i,\n                    })\n                })\n                .collect(),\n        }]\n        .into_iter()]\n        .into_iter(),\n    ))\n}\n\n/// Handles a locals allocation finalization instruction.\nfn build_finalize_locals(\n    mut builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let (n_slots, frame_state) = frame_state::handle_finalize_locals(\n        builder.environment.frame_state,\n        builder.environment.ap_tracking,\n    )?;\n    builder.environment.frame_state = frame_state;\n    Ok(builder.build(\n        casm! { ap += (n_slots as i128); }.instructions,\n        vec![],\n        [[].into_iter()].into_iter(),\n    ))\n}\n\n/// Handles the local variable allocation instruction.\nfn build_alloc_local(\n    mut builder: CompiledInvocationBuilder<'_>,\n    ty: &ConcreteTypeId,\n) -> Result<CompiledInvocation, InvocationError> {\n    let allocation_size = *builder\n        .program_info\n        .type_sizes\n        .get(ty)\n        .ok_or_else(|| InvocationError::NotSized(builder.invocation.clone()))?;\n\n    let (slot, frame_state) = frame_state::handle_alloc_local(\n        builder.environment.frame_state,\n        builder.environment.ap_tracking,\n        allocation_size as usize,\n    )?;\n    builder.environment.frame_state = frame_state;\n\n    Ok(builder.build_only_reference_changes(\n        [ReferenceExpression::from_cell(CellExpression::Deref(CellRef {\n            register: Register::FP,\n            offset: usize_as_i16(slot),\n        }))]\n        .into_iter(),\n    ))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_casm::builder::{CasmBuilder, Var};\nuse cairo_lang_casm::cell_expression::CellExpression;\nuse cairo_lang_casm::{casm, casm_build_extend};\nuse cairo_lang_sierra::program::{BranchInfo, BranchTarget};\nuse itertools::Itertools;\nuse num_bigint::BigInt;\n\nuse super::{\n    get_non_fallthrough_statement_id, CompiledInvocation, CompiledInvocationBuilder,\n    InvocationError,\n};\nuse crate::invocations::add_input_variables;\nuse crate::references::ReferenceExpression;\n\n/// Handles a revoke ap tracking instruction.\npub fn build_revoke_ap_tracking(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    Ok(builder.build(vec![], vec![], [[].into_iter()].into_iter()))\n}\n\n/// Handles a dup instruction.\npub fn build_dup(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let expression = builder.try_get_refs::<1>()?[0].clone();\n    Ok(builder.build_only_reference_changes([expression.clone(), expression].into_iter()))\n}\n\n/// Handles a drop instruction.\npub fn build_drop(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    Ok(builder.build_only_reference_changes([].into_iter()))\n}\n\n/// Handles a const single cell immediate value libfunc.\npub fn build_single_cell_const(\n    builder: CompiledInvocationBuilder<'_>,\n    value: BigInt,\n) -> Result<CompiledInvocation, InvocationError> {\n    Ok(builder.build_only_reference_changes(\n        [ReferenceExpression::from_cell(CellExpression::Immediate(value))].into_iter(),\n    ))\n}\n\n/// Handles a jump non zero statement.\n/// For example, this \"Sierra statement\"\n/// ```ignore\n/// felt252_is_zero(var=[ap-10]) { fallthrough() 1000(var) };\n/// ```\n/// translates to these casm instructions:\n/// ```ignore\n/// jmp rel <jump_offset_1000> if [ap-10] != 0\n/// ```\npub fn build_is_zero(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [value] = builder.try_get_single_cells()?;\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables!(casm_builder, deref value; );\n    casm_build_extend! {casm_builder,\n        jump Target if value != 0;\n    };\n    let target_statement_id = get_non_fallthrough_statement_id(&builder);\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[], None), (\"Target\", &[&[value]], Some(target_statement_id))],\n        Default::default(),\n    ))\n}\n\n/// Handles a jump instruction.\npub fn build_jump(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let target_statement_id = match builder.invocation.branches.as_slice() {\n        [BranchInfo { target: BranchTarget::Statement(statement_id), .. }] => statement_id,\n        _ => panic!(\"malformed invocation\"),\n    };\n    let mut casm_builder = CasmBuilder::default();\n    casm_build_extend! {casm_builder,\n        jump Target;\n    };\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Target\", &[], Some(*target_statement_id))],\n        Default::default(),\n    ))\n}\n\n/// Handles an operations that does no changes to the reference expressions.\npub fn build_identity(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let outputs = builder.refs.iter().map(|r| r.expression.clone());\n    Ok(builder.build_only_reference_changes(outputs))\n}\n\npub fn build_branch_align(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let ap_fix = builder\n        .program_info\n        .metadata\n        .ap_change_info\n        .variable_values\n        .get(&builder.idx)\n        .copied()\n        .unwrap_or(0);\n    Ok(builder.build(\n        if ap_fix > 0 { casm! {ap += ap_fix;}.instructions } else { vec![] },\n        vec![],\n        [vec![].into_iter()].into_iter(),\n    ))\n}\n\n// Handle single cell equality check, for types that have a single representation.\npub fn build_cell_eq(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let mut casm_builder = CasmBuilder::default();\n    let [a, b] = builder.try_get_single_cells()?;\n\n    // The target line to jump to if a != b.\n    let diff = if matches!(a, CellExpression::Deref(_)) {\n        add_input_variables! {casm_builder,\n            deref a;\n            deref_or_immediate b;\n        };\n        casm_build_extend!(casm_builder, tempvar diff = a - b;);\n        diff\n    } else if matches!(b, CellExpression::Deref(_)) {\n        // If `a` is an immediate the previous `a - b` wouldn't be a legal command, so we do `b - a`\n        // instead.\n        add_input_variables! {casm_builder,\n            deref b;\n            deref_or_immediate a;\n        };\n        casm_build_extend!(casm_builder, tempvar diff = b - a;);\n        diff\n    } else if let (CellExpression::Immediate(a), CellExpression::Immediate(b)) = (a, b) {\n        // If both `a` an `b` are immediates we do the diff calculation of code, but simulate the\n        // same flow to conform on AP changes.\n        casm_build_extend! {casm_builder,\n            const diff_imm = a - b;\n            tempvar diff = diff_imm;\n        };\n        diff\n    } else {\n        return Err(InvocationError::InvalidReferenceExpressionForArgument);\n    };\n    casm_build_extend! {casm_builder,\n        // diff = a - b => (diff == 0) <==> (a == b)\n        jump NotEqual if diff != 0;\n        jump Equal;\n    NotEqual:\n    };\n\n    let target_statement_id = get_non_fallthrough_statement_id(&builder);\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[], None), (\"Equal\", &[], Some(target_statement_id))],\n        Default::default(),\n    ))\n}\n\n/// Helper to add code that validates that variable `value` is smaller than `limit`, with `K`\n/// constant for checking this bound. `auxiliary_vars` are the variables already allocated used for\n/// execution of the algorithm, requires different sizes for different `K`s, for 1 requires 4, for 2\n/// requires 5.\n///\n/// We show that a number is in the range [0, `limit`) by writing it as:\n///   A * x + y,\n/// where:\n///   * K = low positive number (the lower the better, here we support only 1 or 2).\n///   * max_x = 2**128 - K.\n///   * A = `limit` / max_x.\n///   * B = `limit` % max_x.\n///   * x is in the range [0, max_x],\n///   * y is in the range [0, B):\n///     * y is in the range [0, 2**128).\n///     * y + 2**128 - B is in the range [0, 2**128).\n///\n/// Note that the minimal possible value of the expression A * x + y is min_val = 0 (where x = y\n/// = 0), and the maximal value is obtained where x = max_x and y = B - 1:\n///   max_val = (A * max_x + B) - 1 = `limit` - 1.\n///\n/// As long as A <= B, every number in the range can be represented.\n/// We assert that the A and B generated by the provided `K` parameter fit the constraint.\npub fn validate_under_limit<const K: u8>(\n    casm_builder: &mut CasmBuilder,\n    limit: &BigInt,\n    value: Var,\n    range_check: Var,\n    auxiliary_vars: &[Var],\n) {\n    let a_imm = limit / (u128::MAX - (K - 1) as u128);\n    let b_imm = limit % (u128::MAX - (K - 1) as u128);\n    assert!(a_imm <= b_imm, \"Must choose `K` such that `{a_imm} (`A`) <= {b_imm} (`B`)\");\n    casm_build_extend! {casm_builder,\n        const a_imm = a_imm;\n        // 2**128 - B.\n        const b_imm_fix = (BigInt::from(u128::MAX) - b_imm + 1) as BigInt;\n        const u128_limit_minus_1 = u128::MAX;\n    }\n    match K {\n        1 => {\n            let (x, y, x_part, y_fixed) =\n                auxiliary_vars.iter().cloned().collect_tuple().expect(\"Wrong amount of vars.\");\n            casm_build_extend! {casm_builder,\n                hint LinearSplit {\n                    value: value,\n                    scalar: a_imm, max_x: u128_limit_minus_1\n                } into {x: x, y: y};\n                assert x_part = x * a_imm;\n                assert value = x_part + y;\n                // x <= max_x = 2**128 - 1\n                assert x = *(range_check++);\n                // y < 2**128\n                assert y = *(range_check++);\n                // y + 2**128 - B < 2**128 ==> y < B\n                assert y_fixed = y + b_imm_fix;\n                assert y_fixed = *(range_check++);\n            };\n        }\n        2 => {\n            let (x, y, x_part, y_fixed, diff) =\n                auxiliary_vars.iter().cloned().collect_tuple().expect(\"Wrong amount of vars.\");\n            casm_build_extend! {casm_builder,\n                const u128_limit_minus_2 = u128::MAX - 1;\n                hint LinearSplit {\n                    value: value,\n                    scalar: a_imm, max_x: u128_limit_minus_2\n                } into {x: x, y: y};\n                assert x_part = x * a_imm;\n                assert value = x_part + y;\n                // y < 2**128\n                assert y = *(range_check++);\n                // y + 2**128 - B < 2**128 ==> y < B\n                assert y_fixed = y + b_imm_fix;\n                assert y_fixed = *(range_check++);\n                // x < 2**128 && x != 2**128 - 1 ==> x < 2**128 - 1\n                assert x = *(range_check++);\n                assert diff = x - u128_limit_minus_1;\n                jump Done if diff != 0;\n                fail;\n            };\n        }\n        _ => unreachable!(\"Only K value of 1 or 2 are supported.\"),\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use assert_matches::assert_matches;\nuse cairo_lang_casm::ap_change::ApChange;\nuse cairo_lang_casm::builder::{CasmBuildResult, CasmBuilder, Var};\nuse cairo_lang_casm::cell_expression::CellExpression;\nuse cairo_lang_casm::instructions::Instruction;\nuse cairo_lang_casm::operand::{CellRef, Register};\nuse cairo_lang_sierra::extensions::builtin_cost::CostTokenType;\nuse cairo_lang_sierra::extensions::core::CoreConcreteLibfunc;\nuse cairo_lang_sierra::extensions::lib_func::{BranchSignature, OutputVarInfo, SierraApChange};\nuse cairo_lang_sierra::extensions::{ConcreteLibfunc, OutputVarReferenceInfo};\nuse cairo_lang_sierra::ids::ConcreteTypeId;\nuse cairo_lang_sierra::program::{BranchInfo, BranchTarget, Invocation, StatementIdx};\nuse cairo_lang_sierra_ap_change::core_libfunc_ap_change::{\n    core_libfunc_ap_change, InvocationApChangeInfoProvider,\n};\nuse cairo_lang_sierra_gas::core_libfunc_cost::{\n    core_libfunc_cost, ConstCost, InvocationCostInfoProvider,\n};\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse itertools::{zip_eq, Itertools};\nuse thiserror::Error;\nuse {cairo_lang_casm, cairo_lang_sierra};\n\nuse crate::environment::frame_state::{FrameState, FrameStateError};\nuse crate::environment::Environment;\nuse crate::metadata::Metadata;\nuse crate::references::{\n    OutputReferenceValue, OutputReferenceValueIntroductionPoint, ReferenceExpression,\n    ReferenceValue,\n};\nuse crate::relocations::{Relocation, RelocationEntry};\nuse crate::type_sizes::TypeSizeMap;\n\nmod array;\nmod bitwise;\nmod boolean;\nmod boxing;\nmod builtin_cost;\nmod casts;\nmod debug;\nmod ec;\nmod enm;\nmod felt252;\nmod felt252_dict;\nmod function_call;\nmod gas;\nmod mem;\nmod misc;\nmod nullable;\nmod pedersen;\nmod starknet;\n\nmod structure;\nmod uint;\nmod uint128;\n\n#[cfg(test)]\nmod test_utils;\n\n#[derive(Error, Debug, Eq, PartialEq)]\npub enum InvocationError {\n    #[error(\"One of the arguments does not satisfy the requirements of the libfunc.\")]\n    InvalidReferenceExpressionForArgument,\n    #[error(\"Unexpected error - an unregistered type id used.\")]\n    UnknownTypeId(ConcreteTypeId),\n    #[error(\"Expected a different number of arguments.\")]\n    WrongNumberOfArguments { expected: usize, actual: usize },\n    #[error(\"The requested functionality is not implemented yet.\")]\n    NotImplemented(Invocation),\n    #[error(\"The requested functionality is not implemented yet: {message}\")]\n    NotImplementedStr { invocation: Invocation, message: String },\n    #[error(\"The functionality is supported only for sized types.\")]\n    NotSized(Invocation),\n    #[error(\"Expected type data not found.\")]\n    UnknownTypeData,\n    #[error(\"Expected variable data for statement not found.\")]\n    UnknownVariableData,\n    #[error(\"An integer overflow occurred.\")]\n    InvalidGenericArg,\n    #[error(\"Invalid generic argument for libfunc.\")]\n    IntegerOverflow,\n    #[error(transparent)]\n    FrameStateError(#[from] FrameStateError),\n}\n\n/// Describes a simple change in the ap tracking itself.\n#[derive(Clone, Debug, Eq, PartialEq)]\npub enum ApTrackingChange {\n    /// Enables the tracking if not already enabled.\n    Enable,\n    /// Disables the tracking.\n    Disable,\n    /// No changes.\n    None,\n}\n\n/// Describes the changes to the set of references at a single branch target, as well as changes to\n/// the environment.\n#[derive(Clone, Debug)]\npub struct BranchChanges {\n    /// New references defined at a given branch.\n    /// should correspond to BranchInfo.results.\n    pub refs: Vec<OutputReferenceValue>,\n    /// The change to AP caused by the libfunc in the branch.\n    pub ap_change: ApChange,\n    /// A change to the ap tracking status.\n    pub ap_tracking_change: ApTrackingChange,\n    /// The change to the remaing gas value in the wallet.\n    pub gas_change: OrderedHashMap<CostTokenType, i64>,\n    /// Should the stack be cleared due to a gap between stack items.\n    pub clear_old_stack: bool,\n    /// The expected size of the known stack after the change.\n    pub new_stack_size: usize,\n}\nimpl BranchChanges {\n    /// Creates a `BranchChanges` object.\n    /// `param_ref` is used to fetch the reference value of a param of the libfunc.\n    fn new<'a, ParamRef: Fn(usize) -> &'a ReferenceValue>(\n        ap_change: ApChange,\n        ap_tracking_change: ApTrackingChange,\n        gas_change: OrderedHashMap<CostTokenType, i64>,\n        expressions: impl ExactSizeIterator<Item = ReferenceExpression>,\n        branch_signature: &BranchSignature,\n        prev_env: &Environment,\n        param_ref: ParamRef,\n    ) -> Self {\n        assert_eq!(\n            expressions.len(),\n            branch_signature.vars.len(),\n            \"The number of expressions does not match the number of expected results in the \\\n             branch.\"\n        );\n        let clear_old_stack =\n            !matches!(&branch_signature.ap_change, SierraApChange::Known { new_vars_only: true });\n        let stack_base = if clear_old_stack { 0 } else { prev_env.stack_size };\n        let mut new_stack_size = stack_base;\n        Self {\n            refs: zip_eq(expressions, &branch_signature.vars)\n                .enumerate()\n                .map(|(output_idx, (expression, OutputVarInfo { ref_info, ty }))| {\n                    validate_output_var_refs(ref_info, &expression);\n                    let stack_idx = calc_output_var_stack_idx(\n                        ref_info,\n                        stack_base,\n                        clear_old_stack,\n                        &param_ref,\n                    );\n                    if let Some(stack_idx) = stack_idx {\n                        new_stack_size = new_stack_size.max(stack_idx + 1);\n                    }\n                    let introduction_point =\n                        if let OutputVarReferenceInfo::SameAsParam { param_idx } = ref_info {\n                            OutputReferenceValueIntroductionPoint::Existing(\n                                param_ref(*param_idx).introduction_point.clone(),\n                            )\n                        } else {\n                            // Marking the statement as unknown to be fixed later.\n                            OutputReferenceValueIntroductionPoint::New(output_idx)\n                        };\n                    OutputReferenceValue {\n                        expression,\n                        ty: ty.clone(),\n                        stack_idx,\n                        introduction_point,\n                    }\n                })\n                .collect(),\n            ap_change,\n            ap_tracking_change,\n            gas_change,\n            clear_old_stack,\n            new_stack_size,\n        }\n    }\n}\n\n/// Validates that a new temp or local var have valid references in their matching expression.\nfn validate_output_var_refs(ref_info: &OutputVarReferenceInfo, expression: &ReferenceExpression) {\n    match ref_info {\n        OutputVarReferenceInfo::NewTempVar { .. } => {\n            expression.cells.iter().for_each(|cell| {\n                assert_matches!(cell, CellExpression::Deref(CellRef { register: Register::AP, .. }))\n            });\n        }\n        OutputVarReferenceInfo::NewLocalVar => {\n            expression.cells.iter().for_each(|cell| {\n                assert_matches!(cell, CellExpression::Deref(CellRef { register: Register::FP, .. }))\n            });\n        }\n        OutputVarReferenceInfo::SameAsParam { .. }\n        | OutputVarReferenceInfo::PartialParam { .. }\n        | OutputVarReferenceInfo::Deferred(_) => {}\n    };\n}\n\n/// Calculates the continuous stack index for an output var of a branch.\n/// `param_ref` is used to fetch the reference value of a param of the libfunc.\nfn calc_output_var_stack_idx<'a, ParamRef: Fn(usize) -> &'a ReferenceValue>(\n    ref_info: &OutputVarReferenceInfo,\n    stack_base: usize,\n    clear_old_stack: bool,\n    param_ref: &ParamRef,\n) -> Option<usize> {\n    match ref_info {\n        OutputVarReferenceInfo::NewTempVar { idx } => idx.map(|idx| stack_base + idx),\n        OutputVarReferenceInfo::SameAsParam { param_idx } if !clear_old_stack => {\n            param_ref(*param_idx).stack_idx\n        }\n        OutputVarReferenceInfo::SameAsParam { .. }\n        | OutputVarReferenceInfo::NewLocalVar\n        | OutputVarReferenceInfo::PartialParam { .. }\n        | OutputVarReferenceInfo::Deferred(_) => None,\n    }\n}\n\n/// The result from a compilation of a single invocation statement.\n#[derive(Debug)]\npub struct CompiledInvocation {\n    /// A vector of instructions that implement the invocation.\n    pub instructions: Vec<Instruction>,\n    /// A vector of static relocations.\n    pub relocations: Vec<RelocationEntry>,\n    /// A vector of BranchRefChanges, should correspond to the branches of the invocation\n    /// statement.\n    pub results: Vec<BranchChanges>,\n    /// The environment after the invocation statement.\n    pub environment: Environment,\n}\n\n/// Checks that the list of reference is contiguous on the stack and ends at ap - 1.\n/// This is the requirement for function call and return statements.\npub fn check_references_on_stack(refs: &[ReferenceValue]) -> Result<(), InvocationError> {\n    let mut expected_offset: i16 = -1;\n    for return_ref in refs.iter().rev() {\n        for cell_expr in return_ref.expression.cells.iter().rev() {\n            match cell_expr {\n                CellExpression::Deref(CellRef { register: Register::AP, offset })\n                    if *offset == expected_offset =>\n                {\n                    expected_offset -= 1;\n                }\n                _ => return Err(InvocationError::InvalidReferenceExpressionForArgument),\n            }\n        }\n    }\n    Ok(())\n}\n\n/// The cells per returned Sierra variables, in casm-builder vars.\ntype VarCells = [Var];\n/// The configuration for all Sierra variables returned from a libfunc.\ntype AllVars<'a> = [&'a VarCells];\n\nimpl<'a> InvocationApChangeInfoProvider for CompiledInvocationBuilder<'a> {\n    fn type_size(&self, ty: &ConcreteTypeId) -> usize {\n        self.program_info.type_sizes[ty] as usize\n    }\n\n    fn token_usages(&self, token_type: CostTokenType) -> usize {\n        self.program_info\n            .metadata\n            .gas_info\n            .variable_values\n            .get(&(self.idx, token_type))\n            .copied()\n            .unwrap_or(0) as usize\n    }\n}\n\nimpl<'a> InvocationCostInfoProvider for CompiledInvocationBuilder<'a> {\n    fn type_size(&self, ty: &ConcreteTypeId) -> usize {\n        self.program_info.type_sizes[ty] as usize\n    }\n\n    fn ap_change_var_value(&self) -> usize {\n        self.program_info\n            .metadata\n            .ap_change_info\n            .variable_values\n            .get(&self.idx)\n            .copied()\n            .unwrap_or_default()\n    }\n\n    fn token_usages(&self, token_type: CostTokenType) -> usize {\n        InvocationApChangeInfoProvider::token_usages(self, token_type)\n    }\n}\n\n/// Information required for validating libfunc cost.\n#[derive(Default)]\nstruct CostValidationInfo<const BRANCH_COUNT: usize> {\n    /// Range check variables at start and end of the libfunc.\n    /// Assumes only directly used as buffer.\n    pub range_check_info: Option<(Var, Var)>,\n    /// Possible extra cost per branch.\n    /// Useful for amortized costs, as well as gas withdrawal libfuncs.\n    pub extra_costs: Option<[i32; BRANCH_COUNT]>,\n}\n\n/// Helper for building compiled invocations.\npub struct CompiledInvocationBuilder<'a> {\n    pub program_info: ProgramInfo<'a>,\n    pub invocation: &'a Invocation,\n    pub libfunc: &'a CoreConcreteLibfunc,\n    pub idx: StatementIdx,\n    pub refs: &'a [ReferenceValue],\n    pub environment: Environment,\n}\nimpl CompiledInvocationBuilder<'_> {\n    /// Creates a new invocation.\n    fn build(\n        self,\n        instructions: Vec<Instruction>,\n        relocations: Vec<RelocationEntry>,\n        output_expressions: impl ExactSizeIterator<\n            Item = impl ExactSizeIterator<Item = ReferenceExpression>,\n        >,\n    ) -> CompiledInvocation {\n        let gas_changes =\n            core_libfunc_cost(&self.program_info.metadata.gas_info, &self.idx, self.libfunc, &self);\n\n        let branch_signatures = self.libfunc.branch_signatures();\n        assert_eq!(\n            branch_signatures.len(),\n            output_expressions.len(),\n            \"The number of output expressions does not match signature.\"\n        );\n        let ap_changes = core_libfunc_ap_change(self.libfunc, &self);\n        assert_eq!(\n            branch_signatures.len(),\n            ap_changes.len(),\n            \"The number of ap changes does not match signature.\"\n        );\n        assert_eq!(\n            branch_signatures.len(),\n            gas_changes.len(),\n            \"The number of gas changes does not match signature.\"\n        );\n\n        CompiledInvocation {\n            instructions,\n            relocations,\n            results: zip_eq(\n                zip_eq(branch_signatures, gas_changes),\n                zip_eq(output_expressions, ap_changes),\n            )\n            .map(|((branch_signature, gas_change), (expressions, ap_change))| {\n                let ap_tracking_change = match ap_change {\n                    cairo_lang_sierra_ap_change::ApChange::EnableApTracking => {\n                        ApTrackingChange::Enable\n                    }\n                    cairo_lang_sierra_ap_change::ApChange::DisableApTracking => {\n                        ApTrackingChange::Disable\n                    }\n                    _ => ApTrackingChange::None,\n                };\n                let ap_change = match ap_change {\n                    cairo_lang_sierra_ap_change::ApChange::Known(x) => ApChange::Known(x),\n                    cairo_lang_sierra_ap_change::ApChange::AtLocalsFinalization(_)\n                    | cairo_lang_sierra_ap_change::ApChange::EnableApTracking\n                    | cairo_lang_sierra_ap_change::ApChange::DisableApTracking => {\n                        ApChange::Known(0)\n                    }\n                    cairo_lang_sierra_ap_change::ApChange::FinalizeLocals => {\n                        match self.environment.frame_state {\n                            FrameState::Finalized { allocated } => ApChange::Known(allocated),\n                            _ => panic!(\"Unexpected frame state.\"),\n                        }\n                    }\n                    cairo_lang_sierra_ap_change::ApChange::FunctionCall(id) => self\n                        .program_info\n                        .metadata\n                        .ap_change_info\n                        .function_ap_change\n                        .get(&id)\n                        .map_or(ApChange::Unknown, |x| ApChange::Known(x + 2)),\n                    cairo_lang_sierra_ap_change::ApChange::FromMetadata => ApChange::Known(\n                        *self\n                            .program_info\n                            .metadata\n                            .ap_change_info\n                            .variable_values\n                            .get(&self.idx)\n                            .unwrap_or(&0),\n                    ),\n                    cairo_lang_sierra_ap_change::ApChange::Unknown => ApChange::Unknown,\n                };\n\n                BranchChanges::new(\n                    ap_change,\n                    ap_tracking_change,\n                    gas_change\n                        .unwrap_or_default()\n                        .iter()\n                        .map(|(token_type, val)| (*token_type, -val))\n                        .collect(),\n                    expressions,\n                    branch_signature,\n                    &self.environment,\n                    |idx| &self.refs[idx],\n                )\n            })\n            .collect(),\n            environment: self.environment,\n        }\n    }\n\n    /// Builds a `CompiledInvocation` from a casm builder and branch extractions.\n    /// Per branch requires `(name, result_variables, target_statement_id)`.\n    fn build_from_casm_builder<const BRANCH_COUNT: usize>(\n        self,\n        casm_builder: CasmBuilder,\n        branch_extractions: [(&str, &AllVars<'_>, Option<StatementIdx>); BRANCH_COUNT],\n        cost_validation: CostValidationInfo<BRANCH_COUNT>,\n    ) -> CompiledInvocation {\n        let CasmBuildResult { instructions, branches } =\n            casm_builder.build(branch_extractions.map(|(name, _, _)| name));\n        itertools::assert_equal(\n            core_libfunc_ap_change(self.libfunc, &self),\n            branches\n                .iter()\n                .map(|(state, _)| cairo_lang_sierra_ap_change::ApChange::Known(state.ap_change)),\n        );\n        let gas_changes =\n            core_libfunc_cost(&self.program_info.metadata.gas_info, &self.idx, self.libfunc, &self)\n                .into_iter()\n                .map(|costs| {\n                    costs\n                        .and_then(|costs| costs.get(&CostTokenType::Const).copied())\n                        .unwrap_or_default()\n                });\n        let mut final_costs: [ConstCost; BRANCH_COUNT] =\n            std::array::from_fn(|_| Default::default());\n        for (cost, (state, _)) in final_costs.iter_mut().zip(branches.iter()) {\n            cost.steps += state.steps as i32;\n        }\n        if let Some((start, end)) = cost_validation.range_check_info {\n            for (cost, (state, _)) in final_costs.iter_mut().zip(branches.iter()) {\n                let (start_base, start_offset) =\n                    state.get_adjusted(start).to_deref_with_offset().unwrap();\n                let (end_base, end_offset) =\n                    state.get_adjusted(end).to_deref_with_offset().unwrap();\n                assert_eq!(start_base, end_base);\n                cost.range_checks += (end_offset - start_offset) as i32;\n            }\n        }\n        let extra_costs =\n            cost_validation.extra_costs.unwrap_or(std::array::from_fn(|_| Default::default()));\n        let final_costs_with_extra = final_costs\n            .iter()\n            .zip(extra_costs)\n            .map(|(final_cost, extra)| (final_cost.cost() + extra) as i64);\n        if !itertools::equal(gas_changes.clone(), final_costs_with_extra.clone()) {\n            panic!(\n                \"Wrong costs for {}. Expected: {gas_changes:?}, actual: \\\n                 {final_costs_with_extra:?}.\",\n                self.invocation\n            );\n        }\n        let relocations = branches\n            .iter()\n            .zip_eq(branch_extractions.iter())\n            .flat_map(|((_, relocations), (_, _, target))| {\n                assert_eq!(\n                    relocations.is_empty(),\n                    target.is_none(),\n                    \"No relocations if nowhere to relocate to.\"\n                );\n                relocations.iter().map(|idx| RelocationEntry {\n                    instruction_idx: *idx,\n                    relocation: Relocation::RelativeStatementId(target.unwrap()),\n                })\n            })\n            .collect();\n        let output_expressions = branches.into_iter().zip_eq(branch_extractions.into_iter()).map(\n            |((state, _), (_, vars, _))| {\n                vars.iter().map(move |var_cells| ReferenceExpression {\n                    cells: var_cells.iter().map(|cell| state.get_adjusted(*cell)).collect(),\n                })\n            },\n        );\n        self.build(instructions, relocations, output_expressions)\n    }\n\n    /// Creates a new invocation with only reference changes.\n    fn build_only_reference_changes(\n        self,\n        output_expressions: impl ExactSizeIterator<Item = ReferenceExpression>,\n    ) -> CompiledInvocation {\n        self.build(vec![], vec![], [output_expressions].into_iter())\n    }\n\n    /// Returns the reference expressions if the size is correct.\n    pub fn try_get_refs<const COUNT: usize>(\n        &self,\n    ) -> Result<[&ReferenceExpression; COUNT], InvocationError> {\n        if self.refs.len() == COUNT {\n            Ok(core::array::from_fn(|i| &self.refs[i].expression))\n        } else {\n            Err(InvocationError::WrongNumberOfArguments {\n                expected: COUNT,\n                actual: self.refs.len(),\n            })\n        }\n    }\n\n    /// Returns the reference expressions, assuming all contains one cell if the size is correct.\n    pub fn try_get_single_cells<const COUNT: usize>(\n        &self,\n    ) -> Result<[&CellExpression; COUNT], InvocationError> {\n        let refs = self.try_get_refs::<COUNT>()?;\n        let mut last_err = None;\n        const FAKE_CELL: CellExpression =\n            CellExpression::Deref(CellRef { register: Register::AP, offset: 0 });\n        // TODO(orizi): Use `refs.try_map` once it is a stable feature.\n        let result = refs.map(|r| match r.try_unpack_single() {\n            Ok(cell) => cell,\n            Err(err) => {\n                last_err = Some(err);\n                &FAKE_CELL\n            }\n        });\n        if let Some(err) = last_err { Err(err) } else { Ok(result) }\n    }\n}\n\n/// Information in the program level required for compiling an invocation.\npub struct ProgramInfo<'a> {\n    pub metadata: &'a Metadata,\n    pub type_sizes: &'a TypeSizeMap,\n}\n\n/// Given a Sierra invocation statement and concrete libfunc, creates a compiled casm representation\n/// of the Sierra statement.\npub fn compile_invocation(\n    program_info: ProgramInfo<'_>,\n    invocation: &Invocation,\n    libfunc: &CoreConcreteLibfunc,\n    idx: StatementIdx,\n    refs: &[ReferenceValue],\n    environment: Environment,\n) -> Result<CompiledInvocation, InvocationError> {\n    let builder =\n        CompiledInvocationBuilder { program_info, invocation, libfunc, idx, refs, environment };\n    match libfunc {\n        CoreConcreteLibfunc::Felt252(libfunc) => felt252::build(libfunc, builder),\n        CoreConcreteLibfunc::Bitwise(_) => bitwise::build(builder),\n        CoreConcreteLibfunc::Bool(libfunc) => boolean::build(libfunc, builder),\n        CoreConcreteLibfunc::Cast(libfunc) => casts::build(libfunc, builder),\n        CoreConcreteLibfunc::Ec(libfunc) => ec::build(libfunc, builder),\n        CoreConcreteLibfunc::Uint8(libfunc) => uint::build_u8(libfunc, builder),\n        CoreConcreteLibfunc::Uint16(libfunc) => uint::build_u16(libfunc, builder),\n        CoreConcreteLibfunc::Uint32(libfunc) => uint::build_u32(libfunc, builder),\n        CoreConcreteLibfunc::Uint64(libfunc) => uint::build_u64(libfunc, builder),\n        CoreConcreteLibfunc::Uint128(libfunc) => uint128::build(libfunc, builder),\n        CoreConcreteLibfunc::Gas(libfunc) => gas::build(libfunc, builder),\n        CoreConcreteLibfunc::BranchAlign(_) => misc::build_branch_align(builder),\n        CoreConcreteLibfunc::Array(libfunc) => array::build(libfunc, builder),\n        CoreConcreteLibfunc::Drop(_) => misc::build_drop(builder),\n        CoreConcreteLibfunc::Dup(_) => misc::build_dup(builder),\n        CoreConcreteLibfunc::Mem(libfunc) => mem::build(libfunc, builder),\n        CoreConcreteLibfunc::UnwrapNonZero(_) => misc::build_identity(builder),\n        CoreConcreteLibfunc::FunctionCall(libfunc) => function_call::build(libfunc, builder),\n        CoreConcreteLibfunc::UnconditionalJump(_) => misc::build_jump(builder),\n        CoreConcreteLibfunc::ApTracking(_) => misc::build_revoke_ap_tracking(builder),\n        CoreConcreteLibfunc::Box(libfunc) => boxing::build(libfunc, builder),\n        CoreConcreteLibfunc::Enum(libfunc) => enm::build(libfunc, builder),\n        CoreConcreteLibfunc::Struct(libfunc) => structure::build(libfunc, builder),\n        CoreConcreteLibfunc::Felt252Dict(libfunc) => felt252_dict::build(libfunc, builder),\n        CoreConcreteLibfunc::Pedersen(libfunc) => pedersen::build(libfunc, builder),\n        CoreConcreteLibfunc::BuiltinCost(libfunc) => builtin_cost::build(libfunc, builder),\n        CoreConcreteLibfunc::StarkNet(libfunc) => starknet::build(libfunc, builder),\n        CoreConcreteLibfunc::Nullable(libfunc) => nullable::build(libfunc, builder),\n        CoreConcreteLibfunc::Debug(libfunc) => debug::build(libfunc, builder),\n        CoreConcreteLibfunc::SnapshotTake(_) => misc::build_dup(builder),\n    }\n}\n\n/// A trait for views of the Complex ReferenceExpressions as specific data structures (e.g.\n/// enum/array).\ntrait ReferenceExpressionView: Sized {\n    type Error;\n    /// Extracts the specific view from the reference expressions. Can include validations and thus\n    /// returns a result.\n    /// `concrete_type_id` - the concrete type this view should represent.\n    fn try_get_view(\n        expr: &ReferenceExpression,\n        program_info: &ProgramInfo<'_>,\n        concrete_type_id: &ConcreteTypeId,\n    ) -> Result<Self, Self::Error>;\n    /// Converts the view into a ReferenceExpression.\n    fn to_reference_expression(self) -> ReferenceExpression;\n}\n\n/// Fetches the non-fallthrough jump target of the invocation, assuming this invocation is a\n/// conditional jump.\npub fn get_non_fallthrough_statement_id(builder: &CompiledInvocationBuilder<'_>) -> StatementIdx {\n    match builder.invocation.branches.as_slice() {\n        [\n            BranchInfo { target: BranchTarget::Fallthrough, results: _ },\n            BranchInfo { target: BranchTarget::Statement(target_statement_id), results: _ },\n        ] => *target_statement_id,\n        _ => panic!(\"malformed invocation\"),\n    }\n}\n\n/// Adds input variables into the builder while validating their type.\nmacro_rules! add_input_variables {\n    ($casm_builder:ident,) => {};\n    ($casm_builder:ident, deref $var:ident; $($tok:tt)*) => {\n        let $var = $casm_builder.add_var(cairo_lang_casm::cell_expression::CellExpression::Deref(\n            $var.to_deref().ok_or(InvocationError::InvalidReferenceExpressionForArgument)?,\n        ));\n        $crate::invocations::add_input_variables!($casm_builder, $($tok)*)\n    };\n    ($casm_builder:ident, deref_or_immediate $var:ident; $($tok:tt)*) => {\n        let $var = $casm_builder.add_var(\n            match $var\n                .to_deref_or_immediate()\n                .ok_or(InvocationError::InvalidReferenceExpressionForArgument)?\n            {\n                cairo_lang_casm::operand::DerefOrImmediate::Deref(cell) => {\n                    cairo_lang_casm::cell_expression::CellExpression::Deref(cell)\n                }\n                cairo_lang_casm::operand::DerefOrImmediate::Immediate(cell) => {\n                    cairo_lang_casm::cell_expression::CellExpression::Immediate(cell.value)\n                }\n            },\n        );\n        $crate::invocations::add_input_variables!($casm_builder, $($tok)*)\n    };\n    ($casm_builder:ident, buffer($slack:expr) $var:ident; $($tok:tt)*) => {\n        let $var = $casm_builder.add_var(\n            $var.to_buffer($slack).ok_or(InvocationError::InvalidReferenceExpressionForArgument)?,\n        );\n        $crate::invocations::add_input_variables!($casm_builder, $($tok)*)\n    };\n}\nuse add_input_variables;\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_casm::cell_expression::CellExpression;\nuse cairo_lang_sierra::extensions::nullable::NullableConcreteLibfunc;\n\nuse super::misc::build_identity;\nuse super::{CompiledInvocation, CompiledInvocationBuilder, InvocationError};\nuse crate::invocations::misc::build_is_zero;\nuse crate::references::ReferenceExpression;\n\n/// Builds Casm instructions for Nullable operations.\npub fn build(\n    libfunc: &NullableConcreteLibfunc,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    match libfunc {\n        NullableConcreteLibfunc::Null(_) => build_nullable_null(builder),\n        NullableConcreteLibfunc::NullableFromBox(_) => {\n            // Note that the pointer of the Box is never zero:\n            // 1. If the size of the inner type is nonnegative, then values are written to the\n            //    memory address pointed by the pointer.\n            //    It follows that this address cannot be zero, since the Cairo-AIR guarantees that\n            //    all memory accesses have address >= 1.\n            // 2. If the size of the inner type is zero, then the pointer is set to 1.\n            //    see `build_into_box`.\n            build_identity(builder)\n        }\n        NullableConcreteLibfunc::MatchNullable(_) => build_nullable_match_nullable(builder),\n    }\n}\n\n/// Builds Casm instructions for the `null()` libfunc.\nfn build_nullable_null(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    builder.try_get_refs::<0>()?;\n    Ok(builder.build_only_reference_changes(\n        [ReferenceExpression { cells: vec![CellExpression::Immediate(0.into())] }].into_iter(),\n    ))\n}\n\n/// Builds Casm instructions for the `null()` libfunc.\nfn build_nullable_match_nullable(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    builder.refs[0]\n        .expression\n        .try_unpack_single()?\n        .to_deref()\n        .ok_or(InvocationError::InvalidReferenceExpressionForArgument)?;\n\n    build_is_zero(builder)\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "#[cfg(test)]\n#[path = \"pedersen_test.rs\"]\nmod test;\n\nuse cairo_lang_casm::builder::CasmBuilder;\nuse cairo_lang_casm::casm_build_extend;\nuse cairo_lang_sierra::extensions::pedersen::PedersenConcreteLibfunc;\n\nuse super::{CompiledInvocation, CompiledInvocationBuilder, InvocationError};\nuse crate::invocations::add_input_variables;\n\n/// Builds instructions for Sierra pedersen operations.\npub fn build(\n    libfunc: &PedersenConcreteLibfunc,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    match libfunc {\n        PedersenConcreteLibfunc::PedersenHash(_) => build_pedersen_hash(builder),\n    }\n}\n\n/// Handles instruction for computing a pedersen hash on two felt252s.\nfn build_pedersen_hash(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [pedersen, x, y] = builder.try_get_single_cells()?;\n\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        deref x;\n        deref y;\n        buffer(2) pedersen;\n    };\n    casm_build_extend! {casm_builder,\n        assert x = *(pedersen++);\n        assert y = *(pedersen++);\n        let result = *(pedersen++);\n    };\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[pedersen], &[result]], None)],\n        Default::default(),\n    ))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_casm::ap_change::ApChange;\nuse cairo_lang_casm::casm;\nuse pretty_assertions::assert_eq;\nuse test_log::test;\n\nuse crate::invocations::test_utils::{\n    compile_libfunc, ReducedBranchChanges, ReducedCompiledInvocation,\n};\nuse crate::ref_expr;\n\n#[test]\nfn test_pedersen() {\n    assert_eq!(\n        compile_libfunc(\n            \"pedersen\",\n            vec![ref_expr!([fp + 1] + (i16::MAX - 2)), ref_expr!([fp + 2]), ref_expr!([ap + 5])]\n        ),\n        ReducedCompiledInvocation {\n            instructions: casm! {\n             [fp + 2] = [[fp + 1] + 32765];\n             [ap + 5] = [[fp + 1] + 32766];\n            }\n            .instructions,\n            relocations: vec![],\n            results: vec![ReducedBranchChanges {\n                refs: vec![ref_expr!([fp + 1] + 32768), ref_expr!([[fp + 1] + 32767])],\n                ap_change: ApChange::Known(0)\n            }]\n        }\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_felt::Felt as Felt252;\nuse cairo_lang_casm::builder::CasmBuilder;\nuse cairo_lang_casm::casm_build_extend;\nuse cairo_lang_sierra::extensions::consts::SignatureAndConstConcreteLibfunc;\nuse cairo_lang_sierra::extensions::starknet::StarkNetConcreteLibfunc;\nuse cairo_lang_sierra_gas::core_libfunc_cost::SYSTEM_CALL_COST;\nuse itertools::Itertools;\nuse num_bigint::{BigInt, ToBigInt};\nuse num_traits::Signed;\n\nuse self::storage::{\n    build_storage_address_from_base_and_offset, build_storage_base_address_const,\n    build_storage_base_address_from_felt252,\n};\nuse super::misc::{build_identity, build_single_cell_const};\nuse super::{misc, CompiledInvocation, CompiledInvocationBuilder};\nuse crate::invocations::misc::validate_under_limit;\nuse crate::invocations::{\n    add_input_variables, get_non_fallthrough_statement_id, CostValidationInfo, InvocationError,\n};\n\nmod testing;\n\nmod storage;\n\n/// Builds instructions for Sierra starknet operations.\npub fn build(\n    libfunc: &StarkNetConcreteLibfunc,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    match libfunc {\n        StarkNetConcreteLibfunc::ClassHashConst(libfunc)\n        | StarkNetConcreteLibfunc::ContractAddressConst(libfunc) => {\n            build_u251_const(builder, libfunc)\n        }\n        StarkNetConcreteLibfunc::ClassHashTryFromFelt252(_)\n        | StarkNetConcreteLibfunc::ContractAddressTryFromFelt252(_)\n        | StarkNetConcreteLibfunc::StorageAddressTryFromFelt252(_) => {\n            build_u251_try_from_felt252(builder)\n        }\n        StarkNetConcreteLibfunc::ClassHashToFelt252(_)\n        | StarkNetConcreteLibfunc::ContractAddressToFelt252(_)\n        | StarkNetConcreteLibfunc::StorageAddressToFelt252(_) => build_identity(builder),\n        StarkNetConcreteLibfunc::StorageBaseAddressConst(libfunc) => {\n            build_storage_base_address_const(builder, libfunc)\n        }\n        StarkNetConcreteLibfunc::StorageBaseAddressFromFelt252(_) => {\n            build_storage_base_address_from_felt252(builder)\n        }\n        StarkNetConcreteLibfunc::StorageAddressFromBase(_) => misc::build_identity(builder),\n        StarkNetConcreteLibfunc::StorageAddressFromBaseAndOffset(_) => {\n            build_storage_address_from_base_and_offset(builder)\n        }\n        StarkNetConcreteLibfunc::StorageRead(_) => {\n            build_syscalls(builder, \"StorageRead\", [1, 1], [1])\n        }\n        StarkNetConcreteLibfunc::StorageWrite(_) => {\n            build_syscalls(builder, \"StorageWrite\", [1, 1, 1], [])\n        }\n        StarkNetConcreteLibfunc::CallContract(_) => {\n            build_syscalls(builder, \"CallContract\", [1, 1, 2], [2])\n        }\n        StarkNetConcreteLibfunc::EmitEvent(_) => build_syscalls(builder, \"EmitEvent\", [2, 2], []),\n        StarkNetConcreteLibfunc::GetExecutionInfo(_) => {\n            build_syscalls(builder, \"GetExecutionInfo\", [], [1])\n        }\n        StarkNetConcreteLibfunc::Deploy(_) => {\n            build_syscalls(builder, \"Deploy\", [1, 1, 2, 1], [1, 2])\n        }\n        StarkNetConcreteLibfunc::LibraryCall(_) => {\n            build_syscalls(builder, \"LibraryCall\", [1, 1, 2], [2])\n        }\n        StarkNetConcreteLibfunc::ReplaceClass(_) => {\n            build_syscalls(builder, \"ReplaceClass\", [1], [])\n        }\n        StarkNetConcreteLibfunc::SendMessageToL1(_) => {\n            build_syscalls(builder, \"SendMessageToL1\", [1, 2], [])\n        }\n        StarkNetConcreteLibfunc::Testing(libfunc) => testing::build(libfunc, builder),\n    }\n}\n\n/// Handles the contract_address_const libfunc.\npub fn build_u251_const(\n    builder: CompiledInvocationBuilder<'_>,\n    libfunc: &SignatureAndConstConcreteLibfunc,\n) -> Result<CompiledInvocation, InvocationError> {\n    let addr_bound = BigInt::from(1) << 251;\n    if libfunc.c.is_negative() || libfunc.c >= addr_bound {\n        return Err(InvocationError::InvalidGenericArg);\n    }\n    build_single_cell_const(builder, libfunc.c.clone())\n}\n\n/// builts a libfunct that tries to convert a felt252 to type with values in the range[0,\n/// 2**251).\npub fn build_u251_try_from_felt252(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let addr_bound: BigInt = BigInt::from(1) << 251;\n    let [range_check, value] = builder.try_get_single_cells()?;\n    let failure_handle_statement_id = get_non_fallthrough_statement_id(&builder);\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        buffer(2) range_check;\n        deref value;\n    };\n    let auxiliary_vars: [_; 4] = std::array::from_fn(|_| casm_builder.alloc_var(false));\n    casm_build_extend! {casm_builder,\n        const limit = addr_bound.clone();\n        let orig_range_check = range_check;\n        tempvar is_valid_address;\n        hint TestLessThan {lhs: value, rhs: limit} into {dst: is_valid_address};\n        jump IsValidAddress if is_valid_address != 0;\n        tempvar shifted_value = value - limit;\n    }\n    validate_under_limit::<1>(\n        &mut casm_builder,\n        &(-Felt252::from(addr_bound.clone())).to_biguint().to_bigint().unwrap(),\n        shifted_value,\n        range_check,\n        &auxiliary_vars,\n    );\n    casm_build_extend! {casm_builder,\n        jump Failure;\n        IsValidAddress:\n    };\n    validate_under_limit::<1>(&mut casm_builder, &addr_bound, value, range_check, &auxiliary_vars);\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [\n            (\"Fallthrough\", &[&[range_check], &[value]], None),\n            (\"Failure\", &[&[range_check]], Some(failure_handle_statement_id)),\n        ],\n        CostValidationInfo {\n            range_check_info: Some((orig_range_check, range_check)),\n            extra_costs: None,\n        },\n    ))\n}\n\n/// Builds instructions for Starknet system calls.\npub fn build_syscalls<const INPUT_COUNT: usize, const OUTPUT_COUNT: usize>(\n    builder: CompiledInvocationBuilder<'_>,\n    selector: &str,\n    input_sizes: [i16; INPUT_COUNT],\n    output_sizes: [i16; OUTPUT_COUNT],\n) -> Result<CompiledInvocation, InvocationError> {\n    let selector_imm = BigInt::from_bytes_be(num_bigint::Sign::Plus, selector.as_bytes());\n    // +2 for Gas and System builtins.\n    if builder.refs.len() != INPUT_COUNT + 2 {\n        return Err(InvocationError::WrongNumberOfArguments {\n            expected: INPUT_COUNT + 2,\n            actual: builder.refs.len(),\n        });\n    }\n    let [gas_builtin] = builder.refs[0].expression.try_unpack()?;\n    let [system] = builder.refs[1].expression.try_unpack()?;\n    let mut casm_builder = CasmBuilder::default();\n    // +2 for Gas and Selector cells.\n    let total_input_size = input_sizes.iter().sum::<i16>() + 2;\n    let success_output_size = output_sizes.iter().sum::<i16>();\n    // Start and end of revert reason array.\n    let failure_output_size: i16 = 2;\n    add_input_variables! {casm_builder,\n        deref gas_builtin;\n        // +2 for Gas and failure flag.\n        buffer(total_input_size + success_output_size.max(failure_output_size) + 2) system;\n    };\n    casm_build_extend! {casm_builder,\n        let original_system = system;\n        const selector_imm = selector_imm;\n        tempvar selector = selector_imm;\n        assert selector = *(system++);\n        assert gas_builtin = *(system++);\n    };\n    for (i, input_size) in input_sizes.iter().enumerate() {\n        let cells = &builder.refs[i + 2].expression.cells;\n        if *input_size as usize != cells.len() {\n            return Err(InvocationError::InvalidReferenceExpressionForArgument);\n        }\n        for cell in cells {\n            add_input_variables!(casm_builder, deref cell;);\n            casm_build_extend!(casm_builder, assert cell = *(system++););\n        }\n    }\n    casm_build_extend! {casm_builder,\n        hint SystemCall { system: original_system };\n        let updated_gas_builtin = *(system++);\n        tempvar failure_flag = *(system++);\n    };\n    let mut success_final_system = None;\n    let mut failure_final_system = None;\n    let max_output_size = std::cmp::max(success_output_size, failure_output_size);\n    let response_vars = (0..max_output_size)\n        .map(|i| {\n            if i == success_output_size {\n                casm_build_extend!(casm_builder, let curr_system = system;);\n                success_final_system = Some(curr_system);\n            }\n            if i == failure_output_size {\n                casm_build_extend!(casm_builder, let curr_system = system;);\n                failure_final_system = Some(curr_system);\n            }\n            casm_build_extend!(casm_builder, let response = *(system++););\n            response\n        })\n        .collect_vec();\n    let updated_gas_builtin = [updated_gas_builtin];\n    let success_final_system = [success_final_system.unwrap_or(system)];\n    let failure_final_system = [failure_final_system.unwrap_or(system)];\n    let mut success_vars = vec![&updated_gas_builtin[..], &success_final_system[..]];\n    let mut offset = 0;\n    for output_size in output_sizes {\n        success_vars.push(&response_vars[offset..(offset + output_size as usize)]);\n        offset += output_size as usize;\n    }\n\n    casm_build_extend!(casm_builder, jump Failure if failure_flag != 0;);\n\n    let failure_handle_statement_id = get_non_fallthrough_statement_id(&builder);\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [\n            (\"Fallthrough\", &success_vars, None),\n            (\n                \"Failure\",\n                &[\n                    &updated_gas_builtin,\n                    &failure_final_system[..],\n                    &[response_vars[0], response_vars[1]],\n                ],\n                Some(failure_handle_statement_id),\n            ),\n        ],\n        CostValidationInfo {\n            range_check_info: None,\n            extra_costs: Some([SYSTEM_CALL_COST, SYSTEM_CALL_COST]),\n        },\n    ))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_felt::Felt as Felt252;\nuse cairo_lang_casm::builder::CasmBuilder;\nuse cairo_lang_casm::casm_build_extend;\nuse cairo_lang_sierra::extensions::consts::SignatureAndConstConcreteLibfunc;\nuse num_bigint::{BigInt, ToBigInt};\nuse num_traits::Signed;\n\nuse super::{CompiledInvocation, CompiledInvocationBuilder, InvocationError};\nuse crate::invocations::misc::{build_single_cell_const, validate_under_limit};\nuse crate::invocations::{add_input_variables, CostValidationInfo};\n\n/// Handles the storage_base_address_const libfunc.\npub fn build_storage_base_address_const(\n    builder: CompiledInvocationBuilder<'_>,\n    libfunc: &SignatureAndConstConcreteLibfunc,\n) -> Result<CompiledInvocation, InvocationError> {\n    let addr_bound = (BigInt::from(1) << 251) - 256;\n    if libfunc.c.is_negative() || libfunc.c >= addr_bound {\n        return Err(InvocationError::InvalidGenericArg);\n    }\n    build_single_cell_const(builder, libfunc.c.clone())\n}\n\n/// Handles the storage_address_from_base_and_offset libfunc.\npub fn build_storage_address_from_base_and_offset(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [base, offset] = builder.try_get_single_cells()?;\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        deref base;\n        deref_or_immediate offset;\n    };\n    casm_build_extend!(casm_builder, let res = base + offset;);\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[res]], None)],\n        Default::default(),\n    ))\n}\n\n/// Handles the storage_base_address_const libfunc.\npub fn build_storage_base_address_from_felt252(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let addr_bound: BigInt = (BigInt::from(1) << 251) - 256;\n    let [range_check, addr] = builder.try_get_single_cells()?;\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        buffer(2) range_check;\n        deref addr;\n    };\n    let auxiliary_vars: [_; 5] = std::array::from_fn(|_| casm_builder.alloc_var(false));\n    casm_build_extend! {casm_builder,\n        const limit = addr_bound.clone();\n        let orig_range_check = range_check;\n        // Allocating all vars in the beginning for easier AP-Alignment between the two branches,\n        // as well as making sure we use `res` as the last cell, making it the last on stack.\n        tempvar is_small;\n        tempvar res;\n        hint TestLessThan {lhs: addr, rhs: limit} into {dst: is_small};\n        jump IsSmall if is_small != 0;\n        assert res = addr - limit;\n    }\n    validate_under_limit::<1>(\n        &mut casm_builder,\n        // PRIME - addr_bound.\n        &(-Felt252::from(addr_bound.clone())).to_biguint().to_bigint().unwrap(),\n        res,\n        range_check,\n        &auxiliary_vars[..4],\n    );\n    casm_build_extend! {casm_builder,\n        jump Done;\n        IsSmall:\n        assert res = addr;\n    }\n    validate_under_limit::<2>(&mut casm_builder, &addr_bound, res, range_check, &auxiliary_vars);\n    casm_build_extend! {casm_builder,\n        Done:\n    };\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[range_check], &[res]], None)],\n        CostValidationInfo {\n            range_check_info: Some((orig_range_check, range_check)),\n            extra_costs: None,\n        },\n    ))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_casm::builder::CasmBuilder;\nuse cairo_lang_casm::casm_build_extend;\nuse cairo_lang_sierra::extensions::starknet::testing::TestingConcreteLibfunc;\n\nuse crate::invocations::{\n    add_input_variables, CompiledInvocation, CompiledInvocationBuilder, CostValidationInfo,\n    InvocationError,\n};\n\n/// Builds instructions for starknet test setup operations.\npub fn build(\n    libfunc: &TestingConcreteLibfunc,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [value] = builder.try_get_single_cells()?;\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        deref value;\n    };\n    match libfunc {\n        TestingConcreteLibfunc::SetBlockNumber(_) => {\n            casm_build_extend! {casm_builder, hint SetBlockNumber {value: value}; };\n        }\n        TestingConcreteLibfunc::SetBlockTimestamp(_) => {\n            casm_build_extend! {casm_builder, hint SetBlockTimestamp {value: value}; };\n        }\n        TestingConcreteLibfunc::SetCallerAddress(_) => {\n            casm_build_extend! {casm_builder, hint SetCallerAddress {value: value}; };\n        }\n        TestingConcreteLibfunc::SetContractAddress(_) => {\n            casm_build_extend! {casm_builder, hint SetContractAddress {value: value}; };\n        }\n        TestingConcreteLibfunc::SetSequencerAddress(_) => {\n            casm_build_extend! {casm_builder, hint SetSequencerAddress {value: value}; };\n        }\n    }\n    casm_build_extend! {casm_builder, ap += 0; };\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[], None)],\n        CostValidationInfo::default(),\n    ))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_sierra::extensions::structure::StructConcreteLibfunc;\nuse cairo_lang_sierra::extensions::ConcreteLibfunc;\n\nuse super::{CompiledInvocation, CompiledInvocationBuilder, InvocationError};\nuse crate::references::ReferenceExpression;\n\n/// Builds instructions for Sierra struct operations.\npub fn build(\n    libfunc: &StructConcreteLibfunc,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    match libfunc {\n        StructConcreteLibfunc::Construct(_) => {\n            let cells = builder\n                .refs\n                .iter()\n                .flat_map(|ref_value| &ref_value.expression.cells)\n                .cloned()\n                .collect();\n            Ok(builder.build_only_reference_changes([ReferenceExpression { cells }].into_iter()))\n        }\n        StructConcreteLibfunc::Deconstruct(libfunc)\n        | StructConcreteLibfunc::SnapshotDeconstruct(libfunc) => {\n            let struct_type = &libfunc.param_signatures()[0].ty;\n            let cells = &builder.try_get_refs::<1>()?[0].cells;\n            if cells.len() != builder.program_info.type_sizes[struct_type] as usize {\n                return Err(InvocationError::InvalidReferenceExpressionForArgument);\n            }\n            let output_types = libfunc.output_types();\n            assert_eq!(output_types.len(), 1, \"Wrong number of branches configured.\");\n            let mut offset = 0_usize;\n            let mut outputs = vec![];\n            for ty in &output_types[0] {\n                let size = builder.program_info.type_sizes[ty] as usize;\n                outputs\n                    .push(ReferenceExpression { cells: cells[offset..(offset + size)].to_vec() });\n                offset += size;\n            }\n            Ok(builder.build_only_reference_changes(outputs.into_iter()))\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashMap;\n\nuse cairo_lang_casm::ap_change::ApChange;\nuse cairo_lang_casm::instructions::Instruction;\nuse cairo_lang_sierra::extensions::core::{CoreLibfunc, CoreType};\nuse cairo_lang_sierra::extensions::lib_func::{\n    SignatureSpecializationContext, SpecializationContext,\n};\nuse cairo_lang_sierra::extensions::type_specialization_context::TypeSpecializationContext;\nuse cairo_lang_sierra::extensions::types::TypeInfo;\nuse cairo_lang_sierra::extensions::{\n    ConcreteLibfunc, ConcreteType, GenericLibfuncEx, GenericTypeEx,\n};\nuse cairo_lang_sierra::ids::{ConcreteTypeId, VarId};\nuse cairo_lang_sierra::program::{BranchInfo, BranchTarget, Invocation, StatementIdx};\nuse cairo_lang_sierra_ap_change::ap_change_info::ApChangeInfo;\nuse cairo_lang_sierra_gas::gas_info::GasInfo;\nuse itertools::{zip_eq, Itertools};\n\nuse super::{compile_invocation, CompiledInvocation, ProgramInfo};\nuse crate::environment::gas_wallet::GasWallet;\nuse crate::environment::Environment;\nuse crate::metadata::Metadata;\nuse crate::references::{IntroductionPoint, ReferenceExpression, ReferenceValue};\nuse crate::relocations::RelocationEntry;\n\n/// Creates a Felt252BinaryOperator from a token operator.\n#[macro_export]\nmacro_rules! cell_expr_operator {\n    (+) => {\n        cairo_lang_casm::cell_expression::CellOperator::Add\n    };\n    (-) => {\n        cairo_lang_casm::cell_expression::CellOperator::Sub\n    };\n    (*) => {\n        cairo_lang_casm::cell_expression::CellOperator::Mul\n    };\n    (/) => {\n        cairo_lang_casm::cell_expression::CellOperator::Div\n    };\n}\n\n/// Adds a cell expression to a ReferenceExpression cells vector.\n#[macro_export]\nmacro_rules! ref_expr_extend {\n    ($cells:ident) => {};\n    ($cells:ident, [$a:ident $($op:tt $offset:expr)?] $(, $tok:tt)*) => {\n        $cells.push(\n            cairo_lang_casm::cell_expression::CellExpression::Deref(cairo_lang_casm::deref!([$a $($op $offset)?]))\n        );\n        $crate::ref_expr_extend!($cells $(, $tok)*)\n    };\n    ($cells:ident, [$a:ident $($op:tt $offset:expr)?] $operator:tt $b:tt $(, $tok:tt)*) => {\n        $cells.push(\n            cairo_lang_casm::cell_expression::CellExpression::BinOp {\n                op: $crate::cell_expr_operator!($operator),\n                a: cairo_lang_casm::deref!([$a $($op $offset)?]),\n                b: cairo_lang_casm::deref_or_immediate!($b),\n        });\n        $crate::ref_expr_extend!($cells $(, $tok)*)\n    };\n    ($cells:ident, [[$a:ident $($op:tt $offset:expr)?]] $(, $tok:tt)*) => {\n        $cells.push(\n            cairo_lang_casm::cell_expression::CellExpression::DoubleDeref(cairo_lang_casm::deref!([$a $($op $offset)?]), 0)\n        );\n        $crate::ref_expr_extend!($cells $(, $tok)*)\n    };\n    ($cells:ident, [[$a:ident $($op:tt $offset:expr)?] + $offset2:expr] $(, $tok:tt)*) => {\n        $cells.push(\n            cairo_lang_casm::cell_expression::CellExpression::DoubleDeref(cairo_lang_casm::deref!([$a $($op $offset)?]), $offset2)\n        );\n        $crate::ref_expr_extend!($cells $(, $tok)*)\n    };\n    ($cells:ident, $a:expr $(, $tok:tt)*) => {\n        cells.push(\n            cairo_lang_casm::cell_expression::CellExpression::Immediate(num_bigint::BigInt::from($a))\n        );\n        $crate::ref_expr_extend!($cells $(, $tok)*)\n    };\n    ($cells:ident, _ $(, $tok:tt)*) => {\n        cells.push(cairo_lang_casm::cell_expression::CellExpression::Padding);\n        $crate::ref_expr_extend!($cells $(, $tok)*)\n    };\n}\n\n// TODO(orizi): Make this flexible enough to be used in outside of testing.\n/// Creates a reference expression.\n#[macro_export]\nmacro_rules! ref_expr {\n    {$($tok:tt)*} => {\n        {\n            let mut cells = Vec::new();\n            #[allow(clippy::vec_init_then_push)]\n            {\n                $crate::ref_expr_extend!(cells, $($tok)*);\n            }\n            $crate::references::ReferenceExpression { cells }\n        }\n    }\n}\n\n/// Specialization context for libfuncs and types, based on string names only, allows building\n/// libfuncs without salsa db or program registry.\nstruct MockSpecializationContext {}\nimpl TypeSpecializationContext for MockSpecializationContext {\n    fn try_get_type_info(&self, id: ConcreteTypeId) -> Option<TypeInfo> {\n        let long_id = cairo_lang_sierra::ConcreteTypeLongIdParser::new()\n            .parse(id.to_string().as_str())\n            .unwrap();\n        Some(\n            CoreType::specialize_by_id(self, &long_id.generic_id, &long_id.generic_args)\n                .ok()?\n                .info()\n                .clone(),\n        )\n    }\n}\nimpl SignatureSpecializationContext for MockSpecializationContext {\n    fn try_get_concrete_type(\n        &self,\n        id: cairo_lang_sierra::ids::GenericTypeId,\n        generic_args: &[cairo_lang_sierra::program::GenericArg],\n    ) -> Option<ConcreteTypeId> {\n        Some(if generic_args.is_empty() {\n            id.to_string().into()\n        } else {\n            format!(\n                \"{id}<{}>\",\n                generic_args\n                    .iter()\n                    .map(cairo_lang_sierra::program::GenericArg::to_string)\n                    .join(\", \")\n            )\n            .into()\n        })\n    }\n\n    fn try_get_function_signature(\n        &self,\n        _function_id: &cairo_lang_sierra::ids::FunctionId,\n    ) -> Option<cairo_lang_sierra::program::FunctionSignature> {\n        unreachable!(\"Function related specialization functionalities are not implemented.\")\n    }\n\n    fn try_get_function_ap_change(\n        &self,\n        _function_id: &cairo_lang_sierra::ids::FunctionId,\n    ) -> Option<cairo_lang_sierra::extensions::lib_func::SierraApChange> {\n        unreachable!(\"Function related specialization functionalities are not implemented.\")\n    }\n\n    fn as_type_specialization_context(&self) -> &dyn TypeSpecializationContext {\n        self\n    }\n}\nimpl SpecializationContext for MockSpecializationContext {\n    fn upcast(&self) -> &dyn SignatureSpecializationContext {\n        self\n    }\n\n    fn try_get_function(\n        &self,\n        _function_id: &cairo_lang_sierra::ids::FunctionId,\n    ) -> Option<cairo_lang_sierra::program::Function> {\n        unreachable!(\"Function related specialization functionalities are not implemented.\")\n    }\n}\n\n/// Information from [BranchChanges] we should test when only testing a libfunc lowering by itself.\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct ReducedBranchChanges {\n    /// New references defined at a given branch.\n    /// should correspond to BranchInfo.results.\n    pub refs: Vec<ReferenceExpression>,\n    /// The change to AP caused by the libfunc in the branch.\n    pub ap_change: ApChange,\n}\n\n/// Information from [CompiledInvocation] we should test when only testing a libfunc lowering by\n/// itself.\n#[derive(Eq, PartialEq)]\npub struct ReducedCompiledInvocation {\n    /// A vector of instructions that implement the invocation.\n    pub instructions: Vec<Instruction>,\n    /// A vector of static relocations.\n    pub relocations: Vec<RelocationEntry>,\n    /// A vector of ReducedBranchChanges, should correspond to the branches of the invocation\n    /// statement.\n    pub results: Vec<ReducedBranchChanges>,\n}\nimpl ReducedCompiledInvocation {\n    fn new(compiled_invocation: CompiledInvocation) -> ReducedCompiledInvocation {\n        ReducedCompiledInvocation {\n            instructions: compiled_invocation.instructions,\n            relocations: compiled_invocation.relocations,\n            results: compiled_invocation\n                .results\n                .into_iter()\n                .map(|result| ReducedBranchChanges {\n                    refs: result.refs.into_iter().map(|r| r.expression).collect(),\n                    ap_change: result.ap_change,\n                })\n                .collect(),\n        }\n    }\n}\nimpl std::fmt::Debug for ReducedCompiledInvocation {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        f.debug_struct(\"ReducedCompiledInvocation\")\n            .field(\n                \"instructions\",\n                &self.instructions.iter().map(|inst| format!(\"{inst};\")).collect_vec(),\n            )\n            .field(\"relocations\", &self.relocations)\n            .field(\"results\", &self.results)\n            .finish()\n    }\n}\n\n/// Compiles a libfunc into a [ReducedCompiledInvocation].\n/// the arguments are auto-filled according to the signature\n/// I.e. the libfunc is invoked by:\n/// libfunc(*refs) -> {\n///     0([0], [2],..., [n_0])\n///     1([0], [2],..., [n_1])\n///     ...\n///     Fallthrough([0], [2],..., [n_fallthrough_idx])\n///     ...\n///     k([0], [2],..., [n_k])\n/// }\npub fn compile_libfunc(libfunc: &str, refs: Vec<ReferenceExpression>) -> ReducedCompiledInvocation {\n    let long_id = cairo_lang_sierra::ConcreteLibfuncLongIdParser::new()\n        .parse(libfunc.to_string().as_str())\n        .unwrap();\n    let context = MockSpecializationContext {};\n    let libfunc =\n        CoreLibfunc::specialize_by_id(&context, &long_id.generic_id, &long_id.generic_args)\n            .unwrap();\n\n    let mut type_sizes = HashMap::default();\n    for param in libfunc.param_signatures() {\n        type_sizes\n            .insert(param.ty.clone(), context.try_get_type_info(param.ty.clone()).unwrap().size);\n    }\n    for branch_signature in libfunc.branch_signatures() {\n        for var in &branch_signature.vars {\n            type_sizes\n                .insert(var.ty.clone(), context.try_get_type_info(var.ty.clone()).unwrap().size);\n        }\n    }\n    let program_info = ProgramInfo {\n        metadata: &Metadata {\n            ap_change_info: ApChangeInfo {\n                variable_values: Default::default(),\n                function_ap_change: Default::default(),\n            },\n            gas_info: GasInfo {\n                variable_values: Default::default(),\n                function_costs: Default::default(),\n            },\n        },\n        type_sizes: &type_sizes,\n    };\n\n    let args: Vec<ReferenceValue> = zip_eq(refs.into_iter(), libfunc.param_signatures())\n        .map(|(expression, param)| ReferenceValue {\n            expression,\n            ty: param.ty.clone(),\n            stack_idx: None,\n            introduction_point: IntroductionPoint { statement_idx: StatementIdx(0), output_idx: 0 },\n        })\n        .collect();\n\n    let environment = Environment::new(GasWallet::Disabled, StatementIdx(0));\n    ReducedCompiledInvocation::new(\n        compile_invocation(\n            program_info,\n            &Invocation {\n                libfunc_id: \"\".into(),\n                args: (0..args.len() as u64).map(VarId::new).collect(),\n                branches: libfunc\n                    .branch_signatures()\n                    .iter()\n                    .enumerate()\n                    .map(|(i, branch)| BranchInfo {\n                        target: if libfunc.fallthrough() == Some(i) {\n                            BranchTarget::Fallthrough\n                        } else {\n                            BranchTarget::Statement(StatementIdx(i))\n                        },\n                        results: (0..branch.vars.len() as u64).map(VarId::new).collect(),\n                    })\n                    .collect(),\n            },\n            &libfunc,\n            StatementIdx(0),\n            &args,\n            environment,\n        )\n        .expect(\"Failed to compile invocation.\"),\n    )\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_felt::{Felt as Felt252, FIELD_HIGH, FIELD_LOW};\nuse cairo_lang_casm::builder::CasmBuilder;\nuse cairo_lang_casm::casm_build_extend;\nuse cairo_lang_casm::cell_expression::CellExpression;\nuse cairo_lang_sierra::extensions::uint::{\n    IntOperator, Uint16Concrete, Uint32Concrete, Uint64Concrete, Uint8Concrete,\n    UintConstConcreteLibfunc, UintTraits,\n};\nuse num_bigint::{BigInt, ToBigInt};\n\nuse super::{misc, CompiledInvocation, CompiledInvocationBuilder, InvocationError};\nuse crate::invocations::misc::validate_under_limit;\nuse crate::invocations::{\n    add_input_variables, get_non_fallthrough_statement_id, CostValidationInfo,\n};\nuse crate::references::ReferenceExpression;\n\n/// Builds invocations for uint const values.\npub fn build_const<TUintTraits: UintTraits>(\n    libfunc: &UintConstConcreteLibfunc<TUintTraits>,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    Ok(builder.build_only_reference_changes(\n        [ReferenceExpression::from_cell(CellExpression::Immediate(libfunc.c.into()))].into_iter(),\n    ))\n}\n\n/// Builds instructions for uint less than.\n/// Only assumes the original uints are bound by 128 bits.\npub fn build_less_than(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [range_check, a, b] = builder.try_get_single_cells()?;\n    let failure_handle_statement_id = get_non_fallthrough_statement_id(&builder);\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        buffer(0) range_check;\n        deref a;\n        deref b;\n    };\n    casm_build_extend! {casm_builder,\n            let orig_range_check = range_check;\n            tempvar a_ge_b;\n            tempvar a_minus_b = a - b;\n            const u128_limit = (BigInt::from(u128::MAX) + 1) as BigInt;\n            hint TestLessThan {lhs: a_minus_b, rhs: u128_limit} into {dst: a_ge_b};\n            jump False if a_ge_b != 0;\n            tempvar wrapping_a_minus_b = a_minus_b + u128_limit;\n            assert wrapping_a_minus_b = *(range_check++);\n            jump True;\n        False:\n            assert a_minus_b = *(range_check++);\n    };\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [\n            (\"Fallthrough\", &[&[range_check]], None),\n            (\"True\", &[&[range_check]], Some(failure_handle_statement_id)),\n        ],\n        CostValidationInfo {\n            range_check_info: Some((orig_range_check, range_check)),\n            extra_costs: None,\n        },\n    ))\n}\n\n/// Builds instructions for uint less than or equals.\n/// Only assumes the original uints are bound by 128 bits.\npub fn build_less_than_or_equal(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [range_check, a, b] = builder.try_get_single_cells()?;\n    let failure_handle_statement_id = get_non_fallthrough_statement_id(&builder);\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        buffer(0) range_check;\n        deref a;\n        deref b;\n    };\n    casm_build_extend! {casm_builder,\n            let orig_range_check = range_check;\n            tempvar a_gt_b;\n            tempvar b_minus_a = b - a;\n            const u128_limit = (BigInt::from(u128::MAX) + 1) as BigInt;\n            hint TestLessThanOrEqual {lhs: u128_limit, rhs: b_minus_a} into {dst: a_gt_b};\n            jump False if a_gt_b != 0;\n            assert b_minus_a = *(range_check++);\n            jump True;\n        False:\n            tempvar wrapping_a_minus_b = b_minus_a + u128_limit;\n            assert wrapping_a_minus_b = *(range_check++);\n    };\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [\n            (\"Fallthrough\", &[&[range_check]], None),\n            (\"True\", &[&[range_check]], Some(failure_handle_statement_id)),\n        ],\n        CostValidationInfo {\n            range_check_info: Some((orig_range_check, range_check)),\n            extra_costs: None,\n        },\n    ))\n}\n\n/// Handles a small uint overflowing add operation.\n/// All parameters values are smaller than `limit`.\nfn build_small_uint_overflowing_add(\n    builder: CompiledInvocationBuilder<'_>,\n    limit: u128,\n) -> Result<CompiledInvocation, InvocationError> {\n    let failure_handle_statement_id = get_non_fallthrough_statement_id(&builder);\n    let [range_check, a, b] = builder.try_get_single_cells()?;\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        buffer(0) range_check;\n        deref a;\n        deref b;\n    };\n    casm_build_extend! {casm_builder,\n            let orig_range_check = range_check;\n            tempvar no_overflow;\n            tempvar fixed_a_plus_b;\n            tempvar a_plus_b = a + b;\n            const limit_fixer = (u128::MAX - limit + 1);\n            const limit = limit;\n            hint TestLessThan {lhs: a_plus_b, rhs: limit} into {dst: no_overflow};\n            jump NoOverflow if no_overflow != 0;\n            // Overflow:\n            // Here we know that `limit <= a + b < 2 * limit - 1`.\n            assert fixed_a_plus_b = a_plus_b - limit;\n            assert fixed_a_plus_b = *(range_check++);\n            jump Target;\n        NoOverflow:\n            // Here we know that `0 <= a + b < limit`\n            // ==> `a + b + 2**128 - limit < limit + 2**128 - limit`\n            // ==> `a + b + 2**128 - limit < 2**128`.\n            assert fixed_a_plus_b = a_plus_b + limit_fixer;\n            assert fixed_a_plus_b = *(range_check++);\n    };\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [\n            (\"Fallthrough\", &[&[range_check], &[a_plus_b]], None),\n            (\"Target\", &[&[range_check], &[fixed_a_plus_b]], Some(failure_handle_statement_id)),\n        ],\n        CostValidationInfo {\n            range_check_info: Some((orig_range_check, range_check)),\n            extra_costs: None,\n        },\n    ))\n}\n\n/// Handles a small uint overflowing sub operation.\n/// All parameters values are smaller than `limit`.\nfn build_small_uint_overflowing_sub(\n    builder: CompiledInvocationBuilder<'_>,\n    limit: BigInt,\n) -> Result<CompiledInvocation, InvocationError> {\n    let failure_handle_statement_id = get_non_fallthrough_statement_id(&builder);\n    let [range_check, a, b] = builder.try_get_single_cells()?;\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        buffer(0) range_check;\n        deref a;\n        deref b;\n    };\n    casm_build_extend! {casm_builder,\n            let orig_range_check = range_check;\n            tempvar no_overflow;\n            tempvar a_minus_b = a - b;\n            const u128_limit = (BigInt::from(u128::MAX) + 1) as BigInt;\n            const limit = limit;\n            hint TestLessThan {lhs: a_minus_b, rhs: limit} into {dst: no_overflow};\n            jump NoOverflow if no_overflow != 0;\n            // Underflow:\n            // Here we know that 0 - (limit - 1) <= a - b < 0.\n            tempvar fixed_a_minus_b = a_minus_b + u128_limit;\n            assert fixed_a_minus_b = *(range_check++);\n            tempvar wrapping_a_minus_b = a_minus_b + limit;\n            jump Target;\n        NoOverflow:\n            assert a_minus_b = *(range_check++);\n    };\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [\n            (\"Fallthrough\", &[&[range_check], &[a_minus_b]], None),\n            (\"Target\", &[&[range_check], &[wrapping_a_minus_b]], Some(failure_handle_statement_id)),\n        ],\n        CostValidationInfo {\n            range_check_info: Some((orig_range_check, range_check)),\n            extra_costs: None,\n        },\n    ))\n}\n\n/// Handles a small uint conversion from felt252.\nfn build_small_uint_from_felt252<const LIMIT: u128, const K: u8>(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [range_check, value] = builder.try_get_single_cells()?;\n    let failure_handle_statement_id = get_non_fallthrough_statement_id(&builder);\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        buffer(2) range_check;\n        deref value;\n    };\n    casm_build_extend! {casm_builder,\n        let orig_range_check = range_check;\n        const limit = LIMIT;\n        tempvar is_small;\n        hint TestLessThan {lhs: value, rhs: limit} into {dst: is_small};\n        jump IsSmall if is_small != 0;\n        tempvar shifted_value = value - limit;\n    }\n    match K {\n        1 => {\n            let auxiliary_vars: [_; 4] = std::array::from_fn(|_| casm_builder.alloc_var(false));\n            validate_under_limit::<K>(\n                &mut casm_builder,\n                &(-Felt252::from(LIMIT)).to_biguint().to_bigint().unwrap(),\n                shifted_value,\n                range_check,\n                &auxiliary_vars,\n            );\n            casm_build_extend! {casm_builder, jump Done;};\n        }\n        2 => {\n            let auxiliary_vars: [_; 5] = std::array::from_fn(|_| casm_builder.alloc_var(false));\n            validate_under_limit::<K>(\n                &mut casm_builder,\n                &(-Felt252::from(LIMIT)).to_biguint().to_bigint().unwrap(),\n                shifted_value,\n                range_check,\n                &auxiliary_vars,\n            );\n        }\n        _ => unreachable!(\"Only K value of 1 or 2 are supported.\"),\n    }\n    casm_build_extend! {casm_builder,\n        IsSmall:\n        assert value = *(range_check++);\n        // value + 2**128 - limit < 2**128 ==> value < limit\n        const fixer_limit = (u128::MAX - LIMIT + 1);\n        tempvar value_upper_limit = value + fixer_limit;\n        assert value_upper_limit = *(range_check++);\n    };\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [\n            (\"Fallthrough\", &[&[range_check], &[value]], None),\n            (\"Done\", &[&[range_check]], Some(failure_handle_statement_id)),\n        ],\n        CostValidationInfo {\n            range_check_info: Some((orig_range_check, range_check)),\n            extra_costs: None,\n        },\n    ))\n}\n\n/// Handles a small uint conversion from felt252.\nfn build_divmod<const BOUND: u128>(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    // Sanity check: make sure BOUND is not too large.\n    let two128 = BigInt::from(2).pow(128);\n    assert!(\n        BigInt::from(BOUND) * two128.clone()\n            < BigInt::from(FIELD_HIGH) * two128 + BigInt::from(FIELD_LOW),\n    );\n\n    let [range_check, a, b] = builder.try_get_single_cells()?;\n\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        buffer(2) range_check;\n        deref a;\n        deref b;\n    };\n    casm_build_extend! {casm_builder,\n        let orig_range_check = range_check;\n        tempvar r_plus_1;\n        tempvar b_minus_r_minus_1;\n        tempvar bq;\n        tempvar q;\n        tempvar r;\n        hint DivMod { lhs: a, rhs: b } into { quotient: q, remainder: r };\n\n        // Verify `0 <= r`.\n        assert r = *(range_check++);\n\n        // Verify `r < b` by constraining `0 <= b - (r + 1)`.\n        const one = 1;\n        assert r_plus_1 = r + one;\n        assert b = b_minus_r_minus_1 + r_plus_1;\n        assert b_minus_r_minus_1 = *(range_check++);\n\n        // Check that `0 <= q < 2**128`.\n        assert q = *(range_check++);\n\n        // Check that `a = q * b + r`. Both hands are in the range [0, 2**128 * BOUND),\n        // since q < 2**128 and b < BOUND.\n        // Therefore, both hands are in the range [0, PRIME), and thus the equality\n        // is an equality as integers (rather than only as field elements).\n        assert bq = b * q;\n        assert a = bq + r;\n    }\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[range_check], &[q], &[r]], None)],\n        CostValidationInfo {\n            range_check_info: Some((orig_range_check, range_check)),\n            extra_costs: None,\n        },\n    ))\n}\n\n/// Handles a uint square root operation.\npub fn build_sqrt(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [range_check, value] = builder.try_get_single_cells()?;\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        buffer(3) range_check;\n        deref value;\n    };\n\n    casm_build_extend! {casm_builder,\n        let orig_range_check = range_check;\n        tempvar fixed_root;\n        tempvar root_squared;\n        tempvar value_minus_root_squared;\n        tempvar root_times_two;\n        tempvar diff;\n        tempvar root;\n\n        // Calculate the square root.\n        hint SquareRoot { value: value} into { dst: root };\n\n        // Assert root is in [0, 2**125) by asserting:\n        // (root + (2**128-1) - (2**125-1)) is in [0, 2**128) and root is in [0, 2**128).\n        // The second assertion is needed because if root is very large (e.g., P - 1) the first\n        // assertion may be true.\n        const u125_upper_fixer = BigInt::from(u128::MAX - (u128::pow(2, 125) - 1));\n        assert fixed_root = root + u125_upper_fixer;\n        assert root = *(range_check++);\n        assert fixed_root = *(range_check++);\n\n        // Assert root**2 is in [0, value] by asserting (value - root**2) is in [0, 2**128).\n        // Since we know root**2 is in [0, 2**250) (because we asserted root is in [0, 2**125))\n        // and that value is in [0, 2**250) this is enough.\n        assert root_squared = root * root;\n        assert value_minus_root_squared = value - root_squared;\n        assert value_minus_root_squared = *(range_check++);\n\n        // Assert value is in [0, (root + 1)**2 ) by asserting (2*root - (value - root**2)) is in\n        // [0, 2**128). this is equivalent because\n        // (root + 1)**2 - 1 - value = 2*root - (value - root**2) .\n        assert root_times_two = root + root;\n        assert diff = root_times_two - value_minus_root_squared;\n        assert diff = *(range_check++);\n    };\n\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[range_check], &[root]], None)],\n        CostValidationInfo {\n            range_check_info: Some((orig_range_check, range_check)),\n            extra_costs: None,\n        },\n    ))\n}\n\n/// Handles a small uint wide multiplication.\npub fn build_small_wide_mul(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [a, b] = builder.try_get_single_cells()?;\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        deref a;\n        deref_or_immediate b;\n    };\n\n    casm_build_extend! {casm_builder,\n        let res = a * b;\n    };\n\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[res]], None)],\n        CostValidationInfo::default(),\n    ))\n}\n\n/// Builds instructions for Sierra u8 operations.\npub fn build_u8(\n    libfunc: &Uint8Concrete,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    const LIMIT: u128 = u8::MAX as u128 + 1;\n    match libfunc {\n        Uint8Concrete::Const(libfunc) => build_const(libfunc, builder),\n        Uint8Concrete::LessThan(_) => build_less_than(builder),\n        Uint8Concrete::SquareRoot(_) => build_sqrt(builder),\n        Uint8Concrete::Equal(_) => misc::build_cell_eq(builder),\n        Uint8Concrete::LessThanOrEqual(_) => build_less_than_or_equal(builder),\n        Uint8Concrete::Operation(libfunc) => match libfunc.operator {\n            IntOperator::OverflowingAdd => build_small_uint_overflowing_add(builder, LIMIT),\n            IntOperator::OverflowingSub => {\n                build_small_uint_overflowing_sub(builder, BigInt::from(LIMIT))\n            }\n        },\n        Uint8Concrete::ToFelt252(_) => misc::build_identity(builder),\n        Uint8Concrete::FromFelt252(_) => build_small_uint_from_felt252::<LIMIT, 2>(builder),\n        Uint8Concrete::IsZero(_) => misc::build_is_zero(builder),\n        Uint8Concrete::Divmod(_) => build_divmod::<LIMIT>(builder),\n        Uint8Concrete::WideMul(_) => build_small_wide_mul(builder),\n    }\n}\n\n/// Builds instructions for Sierra u16 operations.\npub fn build_u16(\n    libfunc: &Uint16Concrete,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    const LIMIT: u128 = u16::MAX as u128 + 1;\n    match libfunc {\n        Uint16Concrete::Const(libfunc) => build_const(libfunc, builder),\n        Uint16Concrete::LessThan(_) => build_less_than(builder),\n        Uint16Concrete::SquareRoot(_) => build_sqrt(builder),\n        Uint16Concrete::Equal(_) => misc::build_cell_eq(builder),\n        Uint16Concrete::LessThanOrEqual(_) => build_less_than_or_equal(builder),\n        Uint16Concrete::Operation(libfunc) => match libfunc.operator {\n            IntOperator::OverflowingAdd => build_small_uint_overflowing_add(builder, LIMIT),\n            IntOperator::OverflowingSub => {\n                build_small_uint_overflowing_sub(builder, BigInt::from(LIMIT))\n            }\n        },\n        Uint16Concrete::ToFelt252(_) => misc::build_identity(builder),\n        Uint16Concrete::FromFelt252(_) => build_small_uint_from_felt252::<LIMIT, 2>(builder),\n        Uint16Concrete::IsZero(_) => misc::build_is_zero(builder),\n        Uint16Concrete::Divmod(_) => build_divmod::<LIMIT>(builder),\n        Uint16Concrete::WideMul(_) => build_small_wide_mul(builder),\n    }\n}\n\n/// Builds instructions for Sierra u32 operations.\npub fn build_u32(\n    libfunc: &Uint32Concrete,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    const LIMIT: u128 = u32::MAX as u128 + 1;\n    match libfunc {\n        Uint32Concrete::Const(libfunc) => build_const(libfunc, builder),\n        Uint32Concrete::LessThan(_) => build_less_than(builder),\n        Uint32Concrete::SquareRoot(_) => build_sqrt(builder),\n        Uint32Concrete::Equal(_) => misc::build_cell_eq(builder),\n        Uint32Concrete::LessThanOrEqual(_) => build_less_than_or_equal(builder),\n        Uint32Concrete::Operation(libfunc) => match libfunc.operator {\n            IntOperator::OverflowingAdd => build_small_uint_overflowing_add(builder, LIMIT),\n            IntOperator::OverflowingSub => {\n                build_small_uint_overflowing_sub(builder, BigInt::from(LIMIT))\n            }\n        },\n        Uint32Concrete::ToFelt252(_) => misc::build_identity(builder),\n        Uint32Concrete::FromFelt252(_) => build_small_uint_from_felt252::<LIMIT, 2>(builder),\n        Uint32Concrete::IsZero(_) => misc::build_is_zero(builder),\n        Uint32Concrete::Divmod(_) => build_divmod::<LIMIT>(builder),\n        Uint32Concrete::WideMul(_) => build_small_wide_mul(builder),\n    }\n}\n\n/// Builds instructions for Sierra u64 operations.\npub fn build_u64(\n    libfunc: &Uint64Concrete,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    const LIMIT: u128 = u64::MAX as u128 + 1;\n    match libfunc {\n        Uint64Concrete::Const(libfunc) => build_const(libfunc, builder),\n        Uint64Concrete::LessThan(_) => build_less_than(builder),\n        Uint64Concrete::SquareRoot(_) => build_sqrt(builder),\n        Uint64Concrete::Equal(_) => misc::build_cell_eq(builder),\n        Uint64Concrete::LessThanOrEqual(_) => build_less_than_or_equal(builder),\n        Uint64Concrete::Operation(libfunc) => match libfunc.operator {\n            IntOperator::OverflowingAdd => build_small_uint_overflowing_add(builder, LIMIT),\n            IntOperator::OverflowingSub => {\n                build_small_uint_overflowing_sub(builder, BigInt::from(LIMIT))\n            }\n        },\n        Uint64Concrete::ToFelt252(_) => misc::build_identity(builder),\n        Uint64Concrete::FromFelt252(_) => build_small_uint_from_felt252::<LIMIT, 2>(builder),\n        Uint64Concrete::IsZero(_) => misc::build_is_zero(builder),\n        Uint64Concrete::Divmod(_) => build_divmod::<LIMIT>(builder),\n        Uint64Concrete::WideMul(_) => build_small_wide_mul(builder),\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_casm::builder::CasmBuilder;\nuse cairo_lang_casm::casm_build_extend;\nuse cairo_lang_sierra::extensions::uint::IntOperator;\nuse cairo_lang_sierra::extensions::uint128::Uint128Concrete;\nuse num_bigint::BigInt;\n\nuse super::{misc, CompiledInvocation, CompiledInvocationBuilder, InvocationError};\nuse crate::invocations::{\n    add_input_variables, get_non_fallthrough_statement_id, CostValidationInfo,\n};\n\n/// Builds instructions for Sierra u128 operations.\npub fn build(\n    libfunc: &Uint128Concrete,\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    match libfunc {\n        Uint128Concrete::Operation(libfunc) => match libfunc.operator {\n            IntOperator::OverflowingAdd => build_u128_overflowing_add(builder),\n            IntOperator::OverflowingSub => build_u128_overflowing_sub(builder),\n        },\n        Uint128Concrete::Divmod(_) => build_u128_divmod(builder),\n        Uint128Concrete::WideMul(_) => build_u128_widemul(builder),\n        Uint128Concrete::IsZero(_) => misc::build_is_zero(builder),\n        Uint128Concrete::Const(libfunc) => super::uint::build_const(libfunc, builder),\n        Uint128Concrete::FromFelt252(_) => build_u128_from_felt252(builder),\n        Uint128Concrete::ToFelt252(_) => misc::build_identity(builder),\n        Uint128Concrete::LessThan(_) => super::uint::build_less_than(builder),\n        Uint128Concrete::Equal(_) => misc::build_cell_eq(builder),\n        Uint128Concrete::SquareRoot(_) => super::uint::build_sqrt(builder),\n        Uint128Concrete::LessThanOrEqual(_) => super::uint::build_less_than_or_equal(builder),\n    }\n}\n\n/// Handles a u128 overflowing add operation.\nfn build_u128_overflowing_add(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let failure_handle_statement_id = get_non_fallthrough_statement_id(&builder);\n    let [range_check, a, b] = builder.try_get_single_cells()?;\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        buffer(0) range_check;\n        deref a;\n        deref b;\n    };\n    casm_build_extend! {casm_builder,\n            let orig_range_check = range_check;\n            tempvar no_overflow;\n            tempvar a_plus_b = a + b;\n            const u128_limit = (BigInt::from(u128::MAX) + 1) as BigInt;\n            hint TestLessThan {lhs: a_plus_b, rhs: u128_limit} into {dst: no_overflow};\n            jump NoOverflow if no_overflow != 0;\n            // Overflow:\n            // Here we know that 2**128 <= a + b < 2 * (2**128 - 1).\n            tempvar wrapping_a_plus_b = a_plus_b - u128_limit;\n            assert wrapping_a_plus_b = *(range_check++);\n            jump Target;\n        NoOverflow:\n            assert a_plus_b = *(range_check++);\n    };\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [\n            (\"Fallthrough\", &[&[range_check], &[a_plus_b]], None),\n            (\"Target\", &[&[range_check], &[wrapping_a_plus_b]], Some(failure_handle_statement_id)),\n        ],\n        CostValidationInfo {\n            range_check_info: Some((orig_range_check, range_check)),\n            extra_costs: None,\n        },\n    ))\n}\n\n/// Handles a u128 overflowing sub operation.\nfn build_u128_overflowing_sub(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let failure_handle_statement_id = get_non_fallthrough_statement_id(&builder);\n    let [range_check, a, b] = builder.try_get_single_cells()?;\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        buffer(0) range_check;\n        deref a;\n        deref b;\n    };\n    casm_build_extend! {casm_builder,\n            let orig_range_check = range_check;\n            tempvar no_overflow;\n            tempvar a_minus_b = a - b;\n            const u128_limit = (BigInt::from(u128::MAX) + 1) as BigInt;\n            hint TestLessThan {lhs: a_minus_b, rhs: u128_limit} into {dst: no_overflow};\n            jump NoOverflow if no_overflow != 0;\n            // Underflow:\n            // Here we know that 0 - (2**128 - 1) <= a - b < 0.\n            tempvar wrapping_a_minus_b = a_minus_b + u128_limit;\n            assert wrapping_a_minus_b = *(range_check++);\n            jump Target;\n        NoOverflow:\n            assert a_minus_b = *(range_check++);\n    };\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [\n            (\"Fallthrough\", &[&[range_check], &[a_minus_b]], None),\n            (\"Target\", &[&[range_check], &[wrapping_a_minus_b]], Some(failure_handle_statement_id)),\n        ],\n        CostValidationInfo {\n            range_check_info: Some((orig_range_check, range_check)),\n            extra_costs: None,\n        },\n    ))\n}\n\n/// Handles a u128 divmod operation.\nfn build_u128_divmod(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [range_check, a, b] = builder.try_get_single_cells()?;\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        buffer(3) range_check;\n        deref a;\n        deref b;\n    };\n    casm_build_extend! {casm_builder,\n            let orig_range_check = range_check;\n            tempvar r_plus_1;\n            tempvar b_minus_r_minus_1;\n            tempvar q_is_small;\n            tempvar b_or_q_bound_rc_value;\n            tempvar bq;\n            tempvar q;\n            tempvar r;\n            hint DivMod { lhs: a, rhs: b } into { quotient: q, remainder: r };\n            // Both `q` and `r` must be uint128.\n            // We must check `r` explicitly: we later check that `0 <= b - (r + 1)` and\n            // `b * q + r = a`, however, if `r = -1` we may pass both of these checks (say, if\n            // `b = a + 1` and `q = 1`).\n            // We must also check `q` explicitly; the only arithmetic constraint on `q` is\n            // `b * q + r = a`, and if `b = 2`, `a = 1` and `r = 0`, we can take `q` to be the\n            // inverse of 2 (`(PRIME + 1) / 2`, much larger than 2^128) and pass this\n            // constraint.\n            assert q = *(range_check++);\n            assert r = *(range_check++);\n            // Verify `r < b` by constraining `0 <= b - (r + 1)`.\n            const one = 1;\n            assert r_plus_1 = r + one;\n            assert b = b_minus_r_minus_1 + r_plus_1;\n            assert b_minus_r_minus_1 = *(range_check++);\n            // Verify `b * q + r = a`.\n            // Since both `b` and `q` can be 2^128-1, we may overflow on `b * q`. To verify this\n            // is not the case, use the fact that `b * q` must be less than 2^128. We know\n            // `min(b, q)` must be less than 2^64. We guess which is less and verify.\n            const u64_bound = u64::MAX as u128 + 1;\n            hint TestLessThan {lhs: q, rhs: u64_bound} into {dst: q_is_small};\n            const u128_bound_minus_u64_bound = u128::MAX - u64::MAX as u128;\n            jump QIsSmall if q_is_small != 0;\n            // `q >= 2^64`, so to verify `b < 2^64` we assert `2^128 - 2^64 + b` is in the range\n            // check bound.\n            assert b_or_q_bound_rc_value = b + u128_bound_minus_u64_bound;\n            jump VerifyBQ;\n        QIsSmall:\n            // `q < 2^64`, compute `2^64 - q`.\n            assert b_or_q_bound_rc_value = q + u128_bound_minus_u64_bound;\n        VerifyBQ:\n            // Now, b_or_q_bound_rc_value contains either `2^128 - 2^64 + q` or\n            // `2^128 - 2^64 + b`. Verify this value is in [0, 2^128).\n            assert b_or_q_bound_rc_value = *(range_check++);\n            // Range validations done; verify `b * q + r = a` and that's it.\n            assert bq = b * q;\n            assert a = bq + r;\n    };\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[range_check], &[q], &[r]], None)],\n        CostValidationInfo {\n            range_check_info: Some((orig_range_check, range_check)),\n            extra_costs: None,\n        },\n    ))\n}\n\n/// Handles a u128 overflowing widemul operation.\nfn build_u128_widemul(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [range_check, a, b] = builder.try_get_single_cells()?;\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        buffer(8) range_check;\n        deref a;\n        deref b;\n    };\n    casm_build_extend! {casm_builder,\n        let orig_range_check = range_check;\n        tempvar a0;\n        tempvar a1;\n        const u64_limit = u64::MAX as u128 + 1;\n        // Break a into two 64bit halves s.t. a = a1 * 2**64 + a0.\n        hint DivMod { lhs: a, rhs: u64_limit } into { quotient: a1, remainder: a0 };\n\n        // Verify that a0 < 2**64 by constraining a0 + (2**128-1) - (2**64-1) < 2**128.\n        const u64_upper_fixer = u128::MAX - u64::MAX as u128;\n        tempvar fixed_a0 = a0 + u64_upper_fixer;\n        assert fixed_a0 = *(range_check++);\n        // Verify that a0, a1 are in [0, 2**128).\n        assert a0 = *(range_check++);\n        assert a1 = *(range_check++);\n        // Overall, we now have a0 in [0, 2**64) and a1 in [0, 2**128).\n\n        // Check the break: a = a1 * 2**64 + a0.\n        // Note: `a` is uint128, the assertion will fail if a1 >= 2**64.\n        tempvar a1_times_2_64 = a1 * u64_limit;\n        assert a = a1_times_2_64 + a0;\n\n\n        tempvar a0_b = a0 * b;\n        tempvar a1_b = a1 * b;\n        // An overview of the calculation to follow:\n        // The final 256 bits result should equal a1_b * 2 ** 64 + a0_b, where the lower 128\n        // bits are packed into `lower_uint128` and the higher bits go into `upper_uint128`.\n        //\n        // Since a0_b, a1_b are comprised of verified u64 * u128 => each fits within 192 bits.\n        // * The lower 128 bits of a0_b should go into the resulting `lower_uint128` and the\n        // upper 64 bits must carry over to the resulting `upper_uint128`.\n        // * Let's mark `b = b1 * 2**64 + b0` (same split as in `a`). Then\n        // a1_b = a1 * (b1 * 2**64 + b0) = a1b1 * (2**64) + a1b0. The bottom 64 bits of a1b0\n        // (which are also the lower 64 bits of a1_b) should be summed into the 64-msbs of\n        // `lower_uint128` and the remaining bits of a1b0 (which is u64*u64=>u128) as well\n        // as a1b1*(2**64) should fit into `upper_uint128`.\n\n        tempvar partial_upper_word;\n        tempvar a1_b0_bottom;\n        // Break a1_b into 128 and 64 bits parts, as explained above.\n        hint DivMod {\n            lhs: a1_b,\n            rhs: u64_limit\n        } into { quotient: partial_upper_word, remainder: a1_b0_bottom };\n\n        // Verify that a1_b0_bottom is in [0, 2**64) and partial_upper_word in [0, 2**128).\n        tempvar fixed_a1_b0_bottom = a1_b0_bottom + u64_upper_fixer;\n        assert fixed_a1_b0_bottom = *(range_check++);\n        assert a1_b0_bottom = *(range_check++);\n        assert partial_upper_word = *(range_check++);\n        // Check the break.\n        tempvar partial_upper_word_times_2_64 = partial_upper_word * u64_limit;\n        assert a1_b = partial_upper_word_times_2_64 + a1_b0_bottom;\n\n        // Build the resulting two uint128 words from the calculated parts:\n        tempvar shifted_a1_b0_bottom = a1_b0_bottom * u64_limit;\n        tempvar carry;\n        tempvar fixed_carry;\n        tempvar shifted_carry;\n        tempvar lower_uint128_with_carry;\n\n        tempvar upper_uint128;\n        tempvar lower_uint128;\n\n        // Lower uint128 word:\n        assert lower_uint128_with_carry = a0_b + shifted_a1_b0_bottom;\n        // Note that `lower_uint128_with_carry` is bounded by 193 bits, as `a0_b` is capped\n        // at 192 bits and `shifted_a1_b0_bottom` can contribute at most 1 additional bit,\n        // added to (the carry of) `lower_uint128_with_carry = a0_b + shifted_a1_b0_bottom`.\n        const u128_limit = (BigInt::from(u128::MAX) + 1) as BigInt;\n        hint DivMod {\n            lhs: lower_uint128_with_carry,\n            rhs: u128_limit\n        } into { quotient: carry, remainder: lower_uint128 };\n\n        // Verify that `carry` is in [0, 2**65) and `lower_uint128` is in [0, 2**128).\n        const carry_range_fixer = u128::MAX - (2u128.pow(65) - 1);\n        assert fixed_carry = carry + carry_range_fixer;\n        assert fixed_carry = *(range_check++);\n        assert carry = *(range_check++);\n        assert lower_uint128 = *(range_check++);\n        // Verify the outputted `lower_uint128` and `carry` from the DivMod hint.\n        assert shifted_carry = carry * u128_limit;\n        assert lower_uint128_with_carry = shifted_carry + lower_uint128;\n        // Note that reconstruction of the felt252 `lower_uint128_with_carry` is performed\n        // with no wrap-around: `carry` was capped at 65 bits and then shifted 128 bits.\n        // `lower_uint128` is range-checked for 128 bits. Overall, within 193 bits range.\n\n        // Upper uint128 word:\n        assert upper_uint128 = partial_upper_word + carry;\n    };\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [(\"Fallthrough\", &[&[range_check], &[upper_uint128], &[lower_uint128]], None)],\n        CostValidationInfo {\n            range_check_info: Some((orig_range_check, range_check)),\n            extra_costs: None,\n        },\n    ))\n}\n\n/// Handles a casting a felt252 into u128.\nfn build_u128_from_felt252(\n    builder: CompiledInvocationBuilder<'_>,\n) -> Result<CompiledInvocation, InvocationError> {\n    let [range_check_expression, expr_value] = builder.try_get_refs()?;\n    let range_check = range_check_expression.try_unpack_single()?;\n    let value = expr_value.try_unpack_single()?;\n\n    let failure_handle_statement_id = get_non_fallthrough_statement_id(&builder);\n    let u128_bound: BigInt = BigInt::from(u128::MAX) + 1; // = 2**128.\n    // Represent the maximal possible value (PRIME - 1) as 2**128 * max_x + max_y.\n    let max_x: i128 = 10633823966279327296825105735305134080;\n    let max_y: i128 = 0;\n    let mut casm_builder = CasmBuilder::default();\n    add_input_variables! {casm_builder,\n        buffer(3) range_check;\n        deref value;\n    };\n    casm_build_extend! {casm_builder,\n            let orig_range_check = range_check;\n            tempvar is_u128;\n            const u128_limit = u128_bound.clone();\n            hint TestLessThan { lhs: value, rhs: u128_limit } into { dst: is_u128 };\n            jump NoOverflow if is_u128 != 0;\n            // Allocating all values required so that `x` and `y` would be last.\n            tempvar x_2_128;\n            tempvar x_minus_max_x;\n            tempvar rced_value;\n            tempvar x;\n            tempvar y;\n            // Write value as 2**128 * x + y.\n            hint DivMod { lhs: value, rhs: u128_limit } into { quotient: x, remainder: y };\n            // Check x in [0, 2**128).\n            assert x = *(range_check++);\n            // Check y in [0, 2**128).\n            assert y = *(range_check++);\n            // Check that value = 2**128 * x + y (mod PRIME).\n            assert x_2_128 = x * u128_limit;\n            assert value = x_2_128 + y;\n            // Check that there is no overflow in the computation of 2**128 * x + y.\n            // Start by checking if x==max_x.\n            const minus_max_x = -max_x;\n            assert x_minus_max_x = x + minus_max_x;\n            jump XNotMaxX if x_minus_max_x != 0;\n            // If x == max_x, check that y <= max_y.\n            const le_max_y_fix = (u128_bound.clone() - max_y - 1) as BigInt;\n            assert rced_value = y + le_max_y_fix;\n            jump WriteRcedValue;\n        XNotMaxX:\n            // If x != max_x, check that x < max_x.\n            const lt_max_x_fix = (u128_bound - max_x) as BigInt;\n            assert rced_value = x + lt_max_x_fix;\n        WriteRcedValue:\n            // In both cases, range-check the calculated value.\n            assert rced_value = *(range_check++);\n            // If x != 0, jump to the end.\n            jump FailureHandle if x != 0;\n            // Otherwise, fail.\n            fail;\n        NoOverflow:\n            assert value = *(range_check++);\n    };\n    Ok(builder.build_from_casm_builder(\n        casm_builder,\n        [\n            (\"Fallthrough\", &[&[range_check], &[value]], None),\n            (\"FailureHandle\", &[&[range_check], &[x], &[y]], Some(failure_handle_statement_id)),\n        ],\n        CostValidationInfo {\n            range_check_info: Some((orig_range_check, range_check)),\n            extra_costs: None,\n        },\n    ))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! CASM backend. Compiles from Sierra down to CASM. See [cairo_lang_sierra] and [cairo_lang_casm]\n\npub mod annotations;\n// TODO(ilya): Reduce the size of CompilationError.\n#[allow(clippy::result_large_err)]\npub mod compiler;\npub mod environment;\npub mod invocations;\npub mod metadata;\npub mod references;\npub mod relocations;\n#[cfg(any(feature = \"testing\", test))]\npub mod test_utils;\npub mod type_sizes;\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_sierra::extensions::builtin_cost::CostTokenType;\nuse cairo_lang_sierra::ids::FunctionId;\nuse cairo_lang_sierra::program::Program;\nuse cairo_lang_sierra_ap_change::ap_change_info::ApChangeInfo;\nuse cairo_lang_sierra_ap_change::{calc_ap_changes, ApChangeError};\nuse cairo_lang_sierra_gas::gas_info::GasInfo;\nuse cairo_lang_sierra_gas::{calc_gas_postcost_info, calc_gas_precost_info, CostError};\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse thiserror::Error;\n\n/// Metadata provided with a Sierra program to simplify the compilation to casm.\npub struct Metadata {\n    /// AP changes information for Sierra user functions.\n    pub ap_change_info: ApChangeInfo,\n    /// Gas information for validating Sierra code and taking the apporiate amount of gas.\n    pub gas_info: GasInfo,\n}\n\n/// Error for metadata calculations.\n#[derive(Debug, Error, Eq, PartialEq)]\npub enum MetadataError {\n    #[error(transparent)]\n    ApChangeError(#[from] ApChangeError),\n    #[error(transparent)]\n    CostError(#[from] CostError),\n}\n\n/// Configuration for metadata computation.\n#[derive(Default)]\npub struct MetadataComputationConfig {\n    pub function_set_costs: OrderedHashMap<FunctionId, OrderedHashMap<CostTokenType, i32>>,\n}\n\n/// Calculates the metadata for a Sierra program.\npub fn calc_metadata(\n    program: &Program,\n    config: MetadataComputationConfig,\n) -> Result<Metadata, MetadataError> {\n    let pre_function_set_costs = config\n        .function_set_costs\n        .iter()\n        .map(|(func, costs)| {\n            (\n                func.clone(),\n                CostTokenType::iter_precost()\n                    .filter_map(|token| costs.get(token).map(|v| (*token, *v)))\n                    .collect(),\n            )\n        })\n        .collect();\n    let pre_gas_info = calc_gas_precost_info(program, pre_function_set_costs)?;\n\n    let ap_change_info = calc_ap_changes(program, |idx, token_type| {\n        pre_gas_info.variable_values[(idx, token_type)] as usize\n    })?;\n\n    let post_function_set_costs = config\n        .function_set_costs\n        .iter()\n        .map(|(func, costs)| {\n            (\n                func.clone(),\n                [CostTokenType::Const]\n                    .iter()\n                    .filter_map(|token| costs.get(token).map(|v| (*token, *v)))\n                    .collect(),\n            )\n        })\n        .collect();\n    let post_gas_info =\n        calc_gas_postcost_info(program, post_function_set_costs, &pre_gas_info, |idx| {\n            ap_change_info.variable_values.get(&idx).copied().unwrap_or_default()\n        })?;\n\n    Ok(Metadata { ap_change_info, gas_info: pre_gas_info.combine(post_gas_info) })\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashMap;\n\nuse cairo_lang_casm::ap_change::ApplyApChange;\nuse cairo_lang_casm::cell_expression::CellExpression;\nuse cairo_lang_casm::operand::{CellRef, Register};\nuse cairo_lang_sierra::ids::{ConcreteTypeId, VarId};\nuse cairo_lang_sierra::program::{Function, StatementIdx};\nuse thiserror::Error;\nuse {cairo_lang_casm, cairo_lang_sierra};\n\nuse crate::invocations::InvocationError;\nuse crate::type_sizes::TypeSizeMap;\n\n#[derive(Error, Debug, Eq, PartialEq)]\npub enum ReferencesError {\n    #[error(\"Invalid function declaration.\")]\n    InvalidFunctionDeclaration(Function),\n    #[error(\n        \"One of the arguments does not match the expected type of the libfunc or return statement.\"\n    )]\n    InvalidReferenceTypeForArgument,\n}\n\npub type StatementRefs = HashMap<VarId, ReferenceValue>;\n\n/// A Sierra reference to a value.\n/// Corresponds to an argument or return value of a Sierra statement.\n#[derive(Clone, Debug)]\npub struct ReferenceValue {\n    pub expression: ReferenceExpression,\n    pub ty: ConcreteTypeId,\n    /// The index of the variable on the continuous-stack.\n    pub stack_idx: Option<usize>,\n    /// The location the value was introduced.\n    pub introduction_point: IntroductionPoint,\n}\n\n/// The location where a value was introduced.\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct IntroductionPoint {\n    /// The statement index of the introduction.\n    pub statement_idx: StatementIdx,\n    /// The output index of the generating statement of the var.\n    pub output_idx: usize,\n}\n\n/// A Sierra reference to a value.\n/// Returned from a libfunc.\n#[derive(Clone, Debug)]\npub struct OutputReferenceValue {\n    pub expression: ReferenceExpression,\n    pub ty: ConcreteTypeId,\n    /// The index of the variable on the continuous-stack.\n    pub stack_idx: Option<usize>,\n    /// The statememt and output index where the value was introduced.\n    /// Statement may be None if it is to be populated later.\n    pub introduction_point: OutputReferenceValueIntroductionPoint,\n}\n\n/// The location where a value was introduced for output reference values.\n#[derive(Clone, Debug)]\npub enum OutputReferenceValueIntroductionPoint {\n    /// A new point introduced by a libfunc, the output index is the value.\n    New(usize),\n    /// Some other known value.\n    Existing(IntroductionPoint),\n}\n\n/// A collection of Cell Expression which represents one logical object.\n#[derive(Clone, Debug, Eq, PartialEq)]\npub struct ReferenceExpression {\n    pub cells: Vec<CellExpression>,\n}\n\nimpl ReferenceExpression {\n    /// Builds a reference expression containing only a single cell\n    pub fn from_cell(cell_expr: CellExpression) -> Self {\n        Self { cells: vec![cell_expr] }\n    }\n\n    /// If returns the cells as an array of the requested size if the size is correct.\n    pub fn try_unpack<const SIZE: usize>(\n        &self,\n    ) -> Result<&[CellExpression; SIZE], InvocationError> {\n        <&[CellExpression; SIZE]>::try_from(&self.cells[..])\n            .map_err(|_| InvocationError::InvalidReferenceExpressionForArgument)\n    }\n\n    /// If there is only one cell in the ReferenceExpression returns the contained CellExpression.\n    pub fn try_unpack_single(&self) -> Result<&CellExpression, InvocationError> {\n        Ok(&self.try_unpack::<1>()?[0])\n    }\n}\n\nimpl ApplyApChange for ReferenceExpression {\n    fn apply_known_ap_change(self, ap_change: usize) -> Option<Self> {\n        Some(ReferenceExpression {\n            cells: self\n                .cells\n                .into_iter()\n                .map(|cell_expr| cell_expr.apply_known_ap_change(ap_change))\n                .collect::<Option<Vec<_>>>()?,\n        })\n    }\n\n    fn can_apply_unknown(&self) -> bool {\n        self.cells.iter().all(|cell| cell.can_apply_unknown())\n    }\n}\n\n/// Builds the HashMap of references to the arguments of a function.\npub fn build_function_arguments_refs(\n    func: &Function,\n    type_sizes: &TypeSizeMap,\n) -> Result<StatementRefs, ReferencesError> {\n    let mut refs = HashMap::with_capacity(func.params.len());\n    let mut offset = -3_i16;\n    for (param_idx, param) in func.params.iter().rev().enumerate() {\n        let size = type_sizes\n            .get(&param.ty)\n            .ok_or_else(|| ReferencesError::InvalidFunctionDeclaration(func.clone()))?;\n        if refs\n            .insert(\n                param.id.clone(),\n                ReferenceValue {\n                    expression: ReferenceExpression {\n                        cells: ((offset - size + 1)..(offset + 1))\n                            .map(|i| {\n                                CellExpression::Deref(CellRef { register: Register::FP, offset: i })\n                            })\n                            .collect(),\n                    },\n                    ty: param.ty.clone(),\n                    stack_idx: None,\n                    introduction_point: IntroductionPoint {\n                        statement_idx: func.entry_point,\n                        output_idx: param_idx,\n                    },\n                },\n            )\n            .is_some()\n        {\n            return Err(ReferencesError::InvalidFunctionDeclaration(func.clone()));\n        }\n        offset -= size;\n    }\n    Ok(refs)\n}\n\n/// Checks that the list of references contains types matching the given types.\npub fn check_types_match(\n    refs: &[ReferenceValue],\n    types: &[ConcreteTypeId],\n) -> Result<(), ReferencesError> {\n    if itertools::equal(types.iter(), refs.iter().map(|r| &r.ty)) {\n        Ok(())\n    } else {\n        Err(ReferencesError::InvalidReferenceTypeForArgument)\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_casm::instructions::{\n    AssertEqInstruction, CallInstruction, Instruction, InstructionBody, JnzInstruction,\n    JumpInstruction,\n};\nuse cairo_lang_casm::operand::{BinOpOperand, DerefOrImmediate, ResOperand};\nuse cairo_lang_sierra::program::StatementIdx;\n\ntype CodeOffset = usize;\n\n#[derive(Debug, Eq, PartialEq)]\npub enum Relocation {\n    /// Adds program_offset(StatementIdx) and subtracts the program offset of the casm instruction\n    /// that is being relocated.\n    RelativeStatementId(StatementIdx),\n    /// Adds the offset between the current statement index and the end of the program code\n    /// segment.\n    EndOfProgram,\n}\n\nimpl Relocation {\n    pub fn apply(\n        &self,\n        instruction_offset: CodeOffset,\n        statement_offsets: &[CodeOffset],\n        instruction: &mut Instruction,\n    ) {\n        let target_pc = match self {\n            Relocation::RelativeStatementId(statement_idx) => statement_offsets[statement_idx.0],\n            Relocation::EndOfProgram => *statement_offsets.last().unwrap(),\n        };\n\n        match instruction {\n            Instruction {\n                body:\n                    InstructionBody::Call(CallInstruction {\n                        target: DerefOrImmediate::Immediate(value),\n                        relative: true,\n                    }),\n                inc_ap: false,\n                ..\n            }\n            | Instruction {\n                body:\n                    InstructionBody::Jnz(JnzInstruction {\n                        jump_offset: DerefOrImmediate::Immediate(value),\n                        condition: _,\n                    }),\n                ..\n            }\n            | Instruction {\n                body:\n                    InstructionBody::Jump(JumpInstruction {\n                        target: DerefOrImmediate::Immediate(value),\n                        relative: true,\n                    }),\n                inc_ap: false,\n                ..\n            }\n            | Instruction {\n                body:\n                    InstructionBody::AssertEq(AssertEqInstruction {\n                        b:\n                            ResOperand::BinOp(BinOpOperand {\n                                b: DerefOrImmediate::Immediate(value),\n                                ..\n                            }),\n                        ..\n                    }),\n                ..\n            } => {\n                value.value += target_pc as i128 - instruction_offset as i128;\n            }\n            _ => panic!(\"Bad relocation.\"),\n        }\n    }\n}\n\n#[derive(Debug, Eq, PartialEq)]\npub struct RelocationEntry {\n    /// The index of the casm instruction that needs to be relocated.\n    pub instruction_idx: CodeOffset,\n    /// The relocation the needs to be applied.\n    pub relocation: Relocation,\n}\n\n/// Applies 'relocations' to 'instructions'.\n///\n/// This is currently O(instruction.len()) rather then O(relocations.len()),\n/// But another pass is required anyhow to generate the bytecode and the relocations\n/// can be applied during that pass.\npub fn relocate_instructions(\n    relocations: &[RelocationEntry],\n    statement_offsets: &[usize],\n    instructions: &mut [Instruction],\n) {\n    let mut program_offset = 0;\n    let mut relocations_iter = relocations.iter();\n    let mut relocation_entry = relocations_iter.next();\n    for (instruction_idx, instruction) in instructions.iter_mut().enumerate() {\n        match relocation_entry {\n            Some(RelocationEntry { instruction_idx: relocation_idx, relocation })\n                if *relocation_idx == instruction_idx =>\n            {\n                relocation.apply(program_offset, statement_offsets, instruction);\n                relocation_entry = relocations_iter.next();\n            }\n            _ => (),\n        };\n\n        program_offset += instruction.body.op_size();\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::fs;\nuse std::path::PathBuf;\n\nuse cairo_lang_sierra::program::Program;\nuse cairo_lang_sierra_ap_change::ap_change_info::ApChangeInfo;\nuse cairo_lang_sierra_ap_change::calc_ap_changes;\nuse cairo_lang_sierra_gas::gas_info::GasInfo;\nuse itertools::Itertools;\n\nuse crate::metadata::{calc_metadata, Metadata, MetadataComputationConfig};\n\n/// Builds the metadata for a Sierra program.\npub fn build_metadata(program: &Program, calculate_gas_info: bool) -> Metadata {\n    if calculate_gas_info {\n        calc_metadata(program, MetadataComputationConfig::default())\n            .expect(\"Failed calculating gas or ap change.\")\n    } else {\n        Metadata {\n            ap_change_info: calc_ap_changes(program, |_, _| 0).unwrap_or(ApChangeInfo {\n                function_ap_change: Default::default(),\n                variable_values: Default::default(),\n            }),\n            gas_info: GasInfo {\n                variable_values: Default::default(),\n                function_costs: Default::default(),\n            },\n        }\n    }\n}\n\n/// Reads an example Sierra program that matches `name`.\npub fn read_sierra_example_file(name: &str) -> String {\n    // Pop the \"/sierra_to_casm\" suffix.\n    let mut path = PathBuf::from(env!(\"CARGO_MANIFEST_DIR\")).parent().unwrap().to_owned();\n    path.extend([\"cairo-lang-sierra\", \"examples\", &format!(\"{name}.sierra\")].into_iter());\n    fs::read_to_string(path).unwrap()\n}\n\n/// Removes all comments and empty lines from the given program.\npub fn strip_comments_and_linebreaks(program: &str) -> String {\n    return program\n        .split('\\n')\n        .filter(|line| !(line.is_empty() || line.starts_with(\"//\")))\n        .join(\"\\n\")\n        + \"\\n\";\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashMap;\n\nuse cairo_lang_sierra::extensions::core::{CoreLibfunc, CoreType, CoreTypeConcrete};\nuse cairo_lang_sierra::extensions::starknet::StarkNetTypeConcrete;\nuse cairo_lang_sierra::ids::ConcreteTypeId;\nuse cairo_lang_sierra::program::Program;\nuse cairo_lang_sierra::program_registry::ProgramRegistry;\n\npub type TypeSizeMap = HashMap<ConcreteTypeId, i16>;\n\n/// Returns a mapping for the sizes of all types for the given program.\npub fn get_type_size_map(\n    program: &Program,\n    registry: &ProgramRegistry<CoreType, CoreLibfunc>,\n) -> Option<TypeSizeMap> {\n    let mut type_sizes = TypeSizeMap::new();\n    for declaration in &program.type_declarations {\n        let ty = registry.get_type(&declaration.id).ok()?;\n        let size = match ty {\n            CoreTypeConcrete::Felt252(_)\n            | CoreTypeConcrete::GasBuiltin(_)\n            | CoreTypeConcrete::Bitwise(_)\n            | CoreTypeConcrete::BuiltinCosts(_)\n            | CoreTypeConcrete::EcOp(_)\n            | CoreTypeConcrete::Nullable(_)\n            | CoreTypeConcrete::Uint8(_)\n            | CoreTypeConcrete::Uint16(_)\n            | CoreTypeConcrete::Uint32(_)\n            | CoreTypeConcrete::Uint64(_)\n            | CoreTypeConcrete::Uint128(_)\n            | CoreTypeConcrete::RangeCheck(_)\n            | CoreTypeConcrete::Box(_)\n            | CoreTypeConcrete::StarkNet(StarkNetTypeConcrete::System(_))\n            | CoreTypeConcrete::StarkNet(StarkNetTypeConcrete::StorageBaseAddress(_))\n            | CoreTypeConcrete::StarkNet(StarkNetTypeConcrete::StorageAddress(_))\n            | CoreTypeConcrete::StarkNet(StarkNetTypeConcrete::ContractAddress(_))\n            | CoreTypeConcrete::StarkNet(StarkNetTypeConcrete::ClassHash(_))\n            | CoreTypeConcrete::Pedersen(_)\n            | CoreTypeConcrete::Felt252Dict(_)\n            | CoreTypeConcrete::SegmentArena(_) => Some(1),\n            CoreTypeConcrete::Array(_)\n            | CoreTypeConcrete::EcPoint(_)\n            | CoreTypeConcrete::SquashedFelt252Dict(_) => Some(2),\n            CoreTypeConcrete::NonZero(wrapped_ty) | CoreTypeConcrete::Snapshot(wrapped_ty) => {\n                type_sizes.get(&wrapped_ty.ty).cloned()\n            }\n            CoreTypeConcrete::EcState(_) => Some(3),\n            CoreTypeConcrete::Enum(enum_type) => {\n                Some(1 + enum_type.variants.iter().map(|variant| type_sizes[variant]).max()?)\n            }\n            CoreTypeConcrete::Struct(struct_type) => {\n                Some(struct_type.members.iter().map(|member| type_sizes[member]).sum())\n            }\n            CoreTypeConcrete::Uninitialized(_) => {\n                // Any size operations on `Uninitialized` are not supported, so we skip adding them\n                // to the map.\n                continue;\n            }\n        }?;\n        type_sizes.insert(declaration.id.clone(), size);\n    }\n    Some(type_sizes)\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashSet;\n\nuse cairo_lang_defs::ids::{LanguageElementId, TraitFunctionId, TraitId};\nuse cairo_lang_diagnostics::{DiagnosticAdded, Maybe};\nuse cairo_lang_semantic::db::SemanticGroup;\nuse cairo_lang_semantic::items::enm::SemanticEnumEx;\nuse cairo_lang_semantic::items::structure::SemanticStructEx;\nuse cairo_lang_semantic::{ConcreteTypeId, TypeId, TypeLongId};\nuse serde::{Deserialize, Serialize};\nuse thiserror::Error;\n\nuse crate::plugin::consts::{EVENT_ATTR, VIEW_ATTR};\n\n#[cfg(test)]\n#[path = \"abi_test.rs\"]\nmod test;\n\n/// Contract ABI.\n#[derive(Default, Debug, PartialEq, Eq, Serialize, Deserialize)]\n#[serde(transparent)]\npub struct Contract {\n    // TODO(spapini): Add storage variables.\n    pub items: Vec<Item>,\n}\nimpl Contract {\n    pub fn json(&self) -> String {\n        serde_json::to_string_pretty(&self).unwrap()\n    }\n}\n\npub struct AbiBuilder {\n    // The constructed ABI.\n    abi: Contract,\n\n    /// List of type that were included abi.\n    /// Used to avoid redendency.\n    types: HashSet<TypeId>,\n}\n\nimpl AbiBuilder {\n    /// Creates a Starknet contract ABI from a TraitId.\n    pub fn from_trait(db: &dyn SemanticGroup, trait_id: TraitId) -> Result<Contract, ABIError> {\n        if !db.trait_generic_params(trait_id).map_err(|_| ABIError::CompilationError)?.is_empty() {\n            return Err(ABIError::GenericTraitsUnsupported);\n        }\n\n        let mut builder = Self { abi: Contract::default(), types: HashSet::new() };\n\n        for trait_function_id in db.trait_functions(trait_id).unwrap_or_default().values() {\n            if trait_function_has_attr(db, *trait_function_id, EVENT_ATTR)? {\n                builder.add_event(db, *trait_function_id)?;\n            } else {\n                builder.add_function(db, *trait_function_id)?;\n            }\n        }\n\n        Ok(builder.abi)\n    }\n\n    /// Adds a function to the ABI from a TraitFunctionId.\n    fn add_function(\n        &mut self,\n        db: &dyn SemanticGroup,\n        trait_function_id: TraitFunctionId,\n    ) -> Result<(), ABIError> {\n        let state_mutability = if trait_function_has_attr(db, trait_function_id, VIEW_ATTR)? {\n            StateMutability::View\n        } else {\n            StateMutability::External\n        };\n        let defs_db = db.upcast();\n        let name = trait_function_id.name(defs_db).into();\n        let signature = db\n            .trait_function_signature(trait_function_id)\n            .map_err(|_| ABIError::CompilationError)?;\n\n        let mut inputs = vec![];\n        for param in signature.params.into_iter() {\n            self.add_type(db, param.ty)?;\n            inputs.push(Input { name: param.id.name(db.upcast()).into(), ty: param.ty.format(db) });\n        }\n\n        // TODO(spapini): output refs?\n        let outputs = if signature.return_type.is_unit(db) {\n            vec![]\n        } else {\n            self.add_type(db, signature.return_type)?;\n            vec![Output { ty: signature.return_type.format(db) }]\n        };\n\n        self.abi.items.push(Item::Function(Function { name, inputs, outputs, state_mutability }));\n\n        Ok(())\n    }\n\n    /// Adds an event to the ABI from a TraitFunctionId.\n    fn add_event(\n        &mut self,\n        db: &dyn SemanticGroup,\n        trait_function_id: TraitFunctionId,\n    ) -> Result<(), ABIError> {\n        let defs_db = db.upcast();\n        let name = trait_function_id.name(defs_db).into();\n        let signature = db\n            .trait_function_signature(trait_function_id)\n            .map_err(|_| ABIError::CompilationError)?;\n        self.abi.items.push(Item::Event(Event {\n            name,\n            inputs: signature\n                .params\n                .into_iter()\n                .map(|param| Input {\n                    name: param.id.name(db.upcast()).into(),\n                    ty: param.ty.format(db),\n                })\n                .collect(),\n        }));\n\n        Ok(())\n    }\n\n    /// Adds a type to the ABI from a TypeId.\n    fn add_type(&mut self, db: &dyn SemanticGroup, type_id: TypeId) -> Result<(), ABIError> {\n        if !self.types.insert(type_id) {\n            // The type was handled previously.\n            return Ok(());\n        }\n\n        match db.lookup_intern_type(type_id) {\n            TypeLongId::Concrete(concrete) => self.add_concrete_type(db, concrete),\n            TypeLongId::Tuple(inner_types) => {\n                for ty in inner_types {\n                    self.add_type(db, ty)?;\n                }\n                Ok(())\n            }\n            TypeLongId::Snapshot(ty) => self.add_type(db, ty),\n            TypeLongId::GenericParameter(_) | TypeLongId::Var(_) | TypeLongId::Missing(_) => {\n                Err(ABIError::UnexpectedType)\n            }\n        }\n    }\n\n    /// Adds a concrete type and all inner types that it depends on to ABI.\n    /// native types are skipped.\n    fn add_concrete_type(\n        &mut self,\n        db: &dyn SemanticGroup,\n        concrete: ConcreteTypeId,\n    ) -> Result<(), ABIError> {\n        if is_native_type(db, &concrete) {\n            return Ok(());\n        }\n\n        match concrete {\n            ConcreteTypeId::Struct(id) => self.abi.items.push(Item::Struct(Struct {\n                name: concrete.format(db),\n                members: get_struct_members(db, id).map_err(|_| ABIError::UnexpectedType)?,\n            })),\n            ConcreteTypeId::Enum(id) => self.abi.items.push(Item::Enum(Enum {\n                name: concrete.format(db),\n                variants: get_enum_variants(db, id).map_err(|_| ABIError::UnexpectedType)?,\n            })),\n            ConcreteTypeId::Extern(_) => {}\n        }\n        Ok(())\n    }\n}\n\nfn get_struct_members(\n    db: &dyn SemanticGroup,\n    id: cairo_lang_semantic::ConcreteStructId,\n) -> Maybe<Vec<StructMember>> {\n    Ok(db\n        .concrete_struct_members(id)?\n        .iter()\n        .map(|(name, member)| StructMember { name: name.to_string(), ty: member.ty.format(db) })\n        .collect())\n}\n\nfn get_enum_variants(\n    db: &dyn SemanticGroup,\n    id: cairo_lang_semantic::ConcreteEnumId,\n) -> Maybe<Vec<EnumVariant>> {\n    let generic_id = id.enum_id(db);\n\n    db.enum_variants(generic_id)?\n        .iter()\n        .map(|(name, variant_id)| {\n            Ok(EnumVariant {\n                name: name.to_string(),\n                ty: db\n                    .concrete_enum_variant(id, &db.variant_semantic(generic_id, *variant_id)?)?\n                    .ty\n                    .format(db),\n            })\n        })\n        .collect::<Result<Vec<_>, DiagnosticAdded>>()\n}\n\n/// Returns true if concrete is a native type.\n///\n/// native types are not added to the ABI.\nfn is_native_type(db: &dyn SemanticGroup, concrete: &ConcreteTypeId) -> bool {\n    let def_db = db.upcast();\n    concrete.generic_type(db).parent_module(def_db).owning_crate(def_db) == db.core_crate()\n}\n\n/// Checks whether the trait function has the given attribute.\nfn trait_function_has_attr(\n    db: &dyn SemanticGroup,\n    trait_function_id: TraitFunctionId,\n    attr: &str,\n) -> Result<bool, ABIError> {\n    Ok(db\n        .trait_function_attributes(trait_function_id)\n        .map_err(|_| ABIError::CompilationError)?\n        .iter()\n        .any(|a| a.id.to_string() == attr))\n}\n\n#[derive(Error, Debug)]\npub enum ABIError {\n    #[error(\"Generic traits are unsupported.\")]\n    GenericTraitsUnsupported,\n    #[error(\"Compilation error.\")]\n    CompilationError,\n    #[error(\"Got unexpected type.\")]\n    UnexpectedType,\n}\n\n/// Enum of contract item ABIs.\n#[derive(Debug, PartialEq, Eq, Serialize, Deserialize)]\n#[serde(tag = \"type\")]\npub enum Item {\n    #[serde(rename = \"function\")]\n    Function(Function),\n    #[serde(rename = \"event\")]\n    Event(Event),\n    #[serde(rename = \"struct\")]\n    Struct(Struct),\n    #[serde(rename = \"enum\")]\n    Enum(Enum),\n}\n\n#[derive(Debug, PartialEq, Eq, Serialize, Deserialize)]\npub enum StateMutability {\n    #[serde(rename = \"external\")]\n    External,\n    #[serde(rename = \"view\")]\n    View,\n}\n\n/// Contract function ABI.\n#[derive(Debug, PartialEq, Eq, Serialize, Deserialize)]\npub struct Function {\n    pub name: String,\n    pub inputs: Vec<Input>,\n\n    // TODO(ilya): Should the output be a vector or a single type?\n    pub outputs: Vec<Output>,\n    pub state_mutability: StateMutability,\n}\n\n/// Contract event.\n#[derive(Debug, PartialEq, Eq, Serialize, Deserialize)]\npub struct Event {\n    pub name: String,\n    pub inputs: Vec<Input>,\n}\n\n/// Function input ABI.\n#[derive(Debug, PartialEq, Eq, Serialize, Deserialize)]\npub struct Input {\n    pub name: String,\n    #[serde(rename = \"type\")]\n    pub ty: String,\n}\n\n/// Function Output ABI.\n#[derive(Debug, PartialEq, Eq, Serialize, Deserialize)]\npub struct Output {\n    #[serde(rename = \"type\")]\n    pub ty: String,\n}\n\n/// Struct ABI.\n#[derive(Debug, PartialEq, Eq, Serialize, Deserialize)]\npub struct Struct {\n    pub name: String,\n    pub members: Vec<StructMember>,\n}\n\n/// Struct member.\n#[derive(Debug, PartialEq, Eq, Serialize, Deserialize)]\npub struct StructMember {\n    pub name: String,\n    #[serde(rename = \"type\")]\n    pub ty: String,\n}\n\n/// Enum ABI.\n#[derive(Debug, PartialEq, Eq, Serialize, Deserialize)]\npub struct Enum {\n    pub name: String,\n    pub variants: Vec<EnumVariant>,\n}\n\n/// Enum variant.\n#[derive(Debug, PartialEq, Eq, Serialize, Deserialize)]\npub struct EnumVariant {\n    pub name: String,\n    #[serde(rename = \"type\")]\n    pub ty: String,\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_defs::ids::ModuleItemId;\nuse cairo_lang_semantic::db::SemanticGroup;\nuse cairo_lang_semantic::test_utils::{setup_test_module, SemanticDatabaseForTesting};\nuse cairo_lang_utils::extract_matches;\nuse indoc::indoc;\nuse pretty_assertions::assert_eq;\n\nuse crate::abi::AbiBuilder;\n\n#[test]\nfn test_abi() {\n    let mut db_val = SemanticDatabaseForTesting::default();\n    let module_id = setup_test_module(\n        &mut db_val,\n        indoc! {\"\n            struct MyStruct<T> {\n              a: T,\n              b: felt252\n            }\n\n            enum MyEnum<S> {\n              a: u256,\n              b: MyStruct::<S>\n            }\n\n            trait MyAbi {\n                fn foo(a: felt252, b: u128) -> Option::<()>;\n\n                #[external]\n                fn foo_external(a: felt252, b: u128) -> MyStruct::<u256>;\n\n                #[view]\n                fn foo_view(a: felt252, b: u128) -> MyEnum::<u128>;\n\n                #[external]\n                fn empty();\n\n                #[event]\n                fn foo_event(a: felt252, b: u128);\n            }\n        \"},\n    )\n    .unwrap()\n    .module_id;\n\n    let db = &db_val;\n    let trait_id = extract_matches!(\n        db.module_item_by_name(module_id, \"MyAbi\".into()).unwrap().unwrap(),\n        ModuleItemId::Trait\n    );\n    let abi = AbiBuilder::from_trait(db, trait_id).unwrap();\n    let actual_serialization = serde_json::to_string_pretty(&abi).unwrap();\n    assert_eq!(\n        actual_serialization,\n        indoc! {\n        r#\"[\n            {\n              \"type\": \"function\",\n              \"name\": \"foo\",\n              \"inputs\": [\n                {\n                  \"name\": \"a\",\n                  \"type\": \"core::felt252\"\n                },\n                {\n                  \"name\": \"b\",\n                  \"type\": \"core::integer::u128\"\n                }\n              ],\n              \"outputs\": [\n                {\n                  \"type\": \"core::option::Option::<()>\"\n                }\n              ],\n              \"state_mutability\": \"external\"\n            },\n            {\n              \"type\": \"struct\",\n              \"name\": \"test::MyStruct::<core::integer::u256>\",\n              \"members\": [\n                {\n                  \"name\": \"a\",\n                  \"type\": \"core::integer::u256\"\n                },\n                {\n                  \"name\": \"b\",\n                  \"type\": \"core::felt252\"\n                }\n              ]\n            },\n            {\n              \"type\": \"function\",\n              \"name\": \"foo_external\",\n              \"inputs\": [\n                {\n                  \"name\": \"a\",\n                  \"type\": \"core::felt252\"\n                },\n                {\n                  \"name\": \"b\",\n                  \"type\": \"core::integer::u128\"\n                }\n              ],\n              \"outputs\": [\n                {\n                  \"type\": \"test::MyStruct::<core::integer::u256>\"\n                }\n              ],\n              \"state_mutability\": \"external\"\n            },\n            {\n              \"type\": \"enum\",\n              \"name\": \"test::MyEnum::<core::integer::u128>\",\n              \"variants\": [\n                {\n                  \"name\": \"a\",\n                  \"type\": \"core::integer::u256\"\n                },\n                {\n                  \"name\": \"b\",\n                  \"type\": \"test::MyStruct::<core::integer::u128>\"\n                }\n              ]\n            },\n            {\n              \"type\": \"function\",\n              \"name\": \"foo_view\",\n              \"inputs\": [\n                {\n                  \"name\": \"a\",\n                  \"type\": \"core::felt252\"\n                },\n                {\n                  \"name\": \"b\",\n                  \"type\": \"core::integer::u128\"\n                }\n              ],\n              \"outputs\": [\n                {\n                  \"type\": \"test::MyEnum::<core::integer::u128>\"\n                }\n              ],\n              \"state_mutability\": \"view\"\n            },\n            {\n              \"type\": \"function\",\n              \"name\": \"empty\",\n              \"inputs\": [],\n              \"outputs\": [],\n              \"state_mutability\": \"external\"\n            },\n            {\n              \"type\": \"event\",\n              \"name\": \"foo_event\",\n              \"inputs\": [\n                {\n                  \"name\": \"a\",\n                  \"type\": \"core::felt252\"\n                },\n                {\n                  \"name\": \"b\",\n                  \"type\": \"core::integer::u128\"\n                }\n              ]\n            }\n          ]\"#}\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashSet;\nuse std::fmt::{Display, Formatter};\nuse std::fs;\n\nuse cairo_lang_sierra::ids::GenericLibfuncId;\nuse serde::Deserialize;\nuse smol_str::SmolStr;\nuse thiserror::Error;\n\nuse crate::contract_class::ContractClass;\nuse crate::felt252_serde::sierra_from_felt252s;\n\n#[cfg(test)]\n#[path = \"allowed_libfuncs_test.rs\"]\nmod test;\n\n#[derive(Error, Debug, Eq, PartialEq)]\npub enum AllowedLibfuncsError {\n    #[error(\"Invalid Sierra program.\")]\n    SierraProgramError,\n    #[error(\"No libfunc list named '{allowed_libfuncs_list_name}' is known.\")]\n    UnexpectedAllowedLibfuncsList { allowed_libfuncs_list_name: String },\n    #[error(\n        \"Libfunc {invalid_libfunc} is not allowed in the libfuncs list \\\n         '{allowed_libfuncs_list_name}'.\\n Run with '--allowed-libfuncs-list-name \\\n         {DEFAULT_EXPERIMENTAL_LIBFUNCS_LIST}' to allow all libfuncs.\"\n    )]\n    UnsupportedLibfunc { invalid_libfunc: String, allowed_libfuncs_list_name: String },\n}\n\n/// A selector for the allowed libfunc list.\npub enum ListSelector {\n    /// A list with one of the predfined names.\n    ListName(String),\n    /// A list to be read from a file.\n    ListFile(String),\n    DefaultList,\n}\n\nimpl ListSelector {\n    /// Gets the cli arguments of both the list name and list file and return a selector, or None if\n    /// both were supplied.\n    pub fn new(list_name: Option<String>, list_file: Option<String>) -> Option<ListSelector> {\n        match (list_name, list_file) {\n            // Both options supplied, can't decide.\n            (Some(_), Some(_)) => None,\n            (Some(list_name), None) => Some(ListSelector::ListName(list_name)),\n            (None, Some(list_file)) => Some(ListSelector::ListFile(list_file)),\n            (None, None) => Some(ListSelector::DefaultList),\n        }\n    }\n}\n\nimpl Display for ListSelector {\n    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {\n        match self {\n            ListSelector::ListName(s) => write!(f, \"{s}\"),\n            ListSelector::ListFile(s) => write!(f, \"{s}\"),\n            ListSelector::DefaultList => write!(f, \"Default libfunc list\"),\n        }\n    }\n}\n\n/// Represents a list of allowed sierra libfuncs.\n#[derive(Debug, PartialEq, Eq, Deserialize)]\npub struct AllowedLibfuncs {\n    #[serde(deserialize_with = \"deserialize_libfuncs_set::<_>\")]\n    pub allowed_libfuncs: HashSet<GenericLibfuncId>,\n}\n\nfn deserialize_libfuncs_set<'de, D: serde::Deserializer<'de>>(\n    deserializer: D,\n) -> Result<HashSet<GenericLibfuncId>, D::Error> {\n    Ok(HashSet::from_iter(\n        Vec::<SmolStr>::deserialize(deserializer)?.into_iter().map(GenericLibfuncId::from_string),\n    ))\n}\n\n/// The allowed libfuncs list to use if no list is supplied to the compiler.\npub const DEFAULT_AUDITED_LIBFUNCS_LIST: &str = \"audited_v0.1.0\";\n/// The allowed libfuncs list to use allowed on testnet.\npub const DEFAULT_TESTNET_LIBFUNCS_LIST: &str = \"testnet_v0.1.0\";\n/// The experimental list contains all the libfuncs and is currently used for development.\npub const DEFAULT_EXPERIMENTAL_LIBFUNCS_LIST: &str = \"experimental_v0.1.0\";\n\n/// Returns the sierra version corresponding to the given version id.\npub fn lookup_allowed_libfuncs_list(\n    list_selector: ListSelector,\n) -> Result<AllowedLibfuncs, AllowedLibfuncsError> {\n    let list_name = list_selector.to_string();\n    let allowed_libfuncs_str: String = match list_selector {\n        ListSelector::ListName(list_name) => match list_name.as_str() {\n            DEFAULT_EXPERIMENTAL_LIBFUNCS_LIST => {\n                include_str!(\"allowed_libfuncs_lists/experimental_v0.1.0.json\").to_string()\n            }\n            DEFAULT_TESTNET_LIBFUNCS_LIST => {\n                include_str!(\"allowed_libfuncs_lists/testnet_v0.1.0.json\").to_string()\n            }\n            DEFAULT_AUDITED_LIBFUNCS_LIST => {\n                include_str!(\"allowed_libfuncs_lists/audited_v0.1.0.json\").to_string()\n            }\n            _ => {\n                return Err(AllowedLibfuncsError::UnexpectedAllowedLibfuncsList {\n                    allowed_libfuncs_list_name: list_name.to_string(),\n                });\n            }\n        },\n        ListSelector::ListFile(file_path) => fs::read_to_string(&file_path).map_err(|_| {\n            AllowedLibfuncsError::UnexpectedAllowedLibfuncsList {\n                allowed_libfuncs_list_name: file_path,\n            }\n        })?,\n        ListSelector::DefaultList => {\n            include_str!(\"allowed_libfuncs_lists/testnet_v0.1.0.json\").to_string()\n        }\n    };\n    let allowed_libfuncs: Result<AllowedLibfuncs, serde_json::Error> =\n        serde_json::from_str(&allowed_libfuncs_str);\n    allowed_libfuncs.map_err(|_| AllowedLibfuncsError::UnexpectedAllowedLibfuncsList {\n        allowed_libfuncs_list_name: list_name,\n    })\n}\n\n/// Checks that all the used libfuncs in the contract class are allowed in the contract class\n/// sierra version.\npub fn validate_compatible_sierra_version(\n    contract: &ContractClass,\n    list_selector: ListSelector,\n) -> Result<(), AllowedLibfuncsError> {\n    let list_name = list_selector.to_string();\n    let allowed_libfuncs = lookup_allowed_libfuncs_list(list_selector)?;\n    let (_, sierra_program) = sierra_from_felt252s(&contract.sierra_program)\n        .map_err(|_| AllowedLibfuncsError::SierraProgramError)?;\n    for libfunc in sierra_program.libfunc_declarations.iter() {\n        if !allowed_libfuncs.allowed_libfuncs.contains(&libfunc.long_id.generic_id) {\n            return Err(AllowedLibfuncsError::UnsupportedLibfunc {\n                invalid_libfunc: libfunc.long_id.generic_id.to_string(),\n                allowed_libfuncs_list_name: list_name,\n            });\n        }\n    }\n    Ok(())\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::BTreeSet;\n\nuse cairo_lang_sierra::extensions::core::CoreLibfunc;\nuse cairo_lang_sierra::extensions::GenericLibfunc;\n\nuse super::{lookup_allowed_libfuncs_list, DEFAULT_EXPERIMENTAL_LIBFUNCS_LIST};\n\n#[test]\nfn experimenal_list_includes_all() {\n    let blocked_libfuncs = [\n        \"print\",\n        \"set_block_number\",\n        \"set_block_timestamp\",\n        \"set_caller_address\",\n        \"set_contract_address\",\n        \"set_sequencer_address\",\n        \"get_available_gas\",\n    ];\n    pretty_assertions::assert_eq!(\n        lookup_allowed_libfuncs_list(super::ListSelector::ListName(\n            DEFAULT_EXPERIMENTAL_LIBFUNCS_LIST.to_string()\n        ))\n        .unwrap()\n        .allowed_libfuncs\n        .into_iter()\n        .map(|id| id.0)\n        .collect::<BTreeSet<_>>(),\n        CoreLibfunc::supported_ids()\n            .into_iter()\n            .map(|id| id.0)\n            .filter(|id| !blocked_libfuncs.contains(&id.as_str()))\n            .collect()\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "#[cfg(test)]\n#[path = \"casm_contract_class_test.rs\"]\nmod test;\n\nuse cairo_lang_casm::hints::Hint;\nuse cairo_lang_sierra::extensions::builtin_cost::CostTokenType;\nuse cairo_lang_sierra::extensions::ec::EcOpType;\nuse cairo_lang_sierra::extensions::gas::GasBuiltinType;\nuse cairo_lang_sierra::extensions::pedersen::PedersenType;\nuse cairo_lang_sierra::extensions::range_check::RangeCheckType;\nuse cairo_lang_sierra::extensions::segment_arena::SegmentArenaType;\nuse cairo_lang_sierra::extensions::starknet::syscalls::SystemType;\nuse cairo_lang_sierra::extensions::NoGenericArgsGenericType;\nuse cairo_lang_sierra::ids::{ConcreteTypeId, GenericTypeId};\nuse cairo_lang_sierra::program::{ConcreteTypeLongId, TypeDeclaration};\nuse cairo_lang_sierra_to_casm::compiler::CompilationError;\nuse cairo_lang_sierra_to_casm::metadata::{\n    calc_metadata, MetadataComputationConfig, MetadataError,\n};\nuse cairo_lang_utils::bigint::{deserialize_big_uint, serialize_big_uint, BigUintAsHex};\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse cairo_lang_utils::unordered_hash_set::UnorderedHashSet;\nuse convert_case::{Case, Casing};\nuse itertools::{chain, Itertools};\nuse num_bigint::BigUint;\nuse num_integer::Integer;\nuse num_traits::{Num, Signed};\nuse serde::{Deserialize, Serialize};\nuse thiserror::Error;\n\nuse crate::allowed_libfuncs::AllowedLibfuncsError;\nuse crate::contract_class::{ContractClass, ContractEntryPoint};\nuse crate::felt252_serde::{sierra_from_felt252s, Felt252SerdeError};\n\n/// The expected gas cost of an entrypoint.\npub const ENTRY_POINT_COST: i32 = 10000;\n\n#[derive(Error, Debug, Eq, PartialEq)]\npub enum StarknetSierraCompilationError {\n    #[error(transparent)]\n    CompilationError(#[from] Box<CompilationError>),\n    #[error(transparent)]\n    Felt252SerdeError(#[from] Felt252SerdeError),\n    #[error(transparent)]\n    MetadataError(#[from] MetadataError),\n    #[error(transparent)]\n    AllowedLibfuncsError(#[from] AllowedLibfuncsError),\n    #[error(\"Invalid entry point.\")]\n    EntryPointError,\n    #[error(\"Missing arguments in the entry point.\")]\n    InvalidEntryPointSignatureMissingArgs,\n    #[error(\"{0} is not a supported builtin type.\")]\n    InvalidBuiltinType(ConcreteTypeId),\n    #[error(\"Invalid entry point signature - builtins are not in the expected order.\")]\n    InvalidEntryPointSignatureWrongBuiltinsOrder,\n    #[error(\"Entry points not sorted by selectors.\")]\n    EntryPointsOutOfOrder,\n    #[error(\"Out of range value in serialization.\")]\n    ValueOutOfRange,\n}\n\nfn skip_if_none<T>(opt_field: &Option<T>) -> bool {\n    opt_field.is_none()\n}\n\n/// Represents a contract in the Starknet network.\n#[derive(Default, Debug, PartialEq, Eq, Serialize, Deserialize)]\npub struct CasmContractClass {\n    #[serde(serialize_with = \"serialize_big_uint\", deserialize_with = \"deserialize_big_uint\")]\n    pub prime: BigUint,\n    pub compiler_version: String,\n    pub bytecode: Vec<BigUintAsHex>,\n    pub hints: Vec<(usize, Vec<Hint>)>,\n\n    // Optional pythonic hints in a format that can be executed by the python vm.\n    #[serde(skip_serializing_if = \"skip_if_none\")]\n    pub pythonic_hints: Option<Vec<(usize, Vec<String>)>>,\n    pub entry_points_by_type: CasmContractEntryPoints,\n}\n\n/// Context for resolving types.\npub struct TypeResolver<'a> {\n    type_decl: &'a [TypeDeclaration],\n}\n\nimpl TypeResolver<'_> {\n    fn get_long_id(&self, type_id: &ConcreteTypeId) -> &ConcreteTypeLongId {\n        &self.type_decl[type_id.id as usize].long_id\n    }\n\n    fn get_generic_id(&self, type_id: &ConcreteTypeId) -> &GenericTypeId {\n        &self.get_long_id(type_id).generic_id\n    }\n}\n\nimpl CasmContractClass {\n    // TODO(ilya): Reduce the size of CompilationError.\n    #[allow(clippy::result_large_err)]\n    pub fn from_contract_class(\n        contract_class: ContractClass,\n        add_pythonic_hints: bool,\n    ) -> Result<Self, StarknetSierraCompilationError> {\n        let prime = BigUint::from_str_radix(\n            \"800000000000011000000000000000000000000000000000000000000000001\",\n            16,\n        )\n        .unwrap();\n\n        for felt252 in &contract_class.sierra_program {\n            if felt252.value >= prime {\n                return Err(StarknetSierraCompilationError::ValueOutOfRange);\n            }\n        }\n\n        let (_, program) = sierra_from_felt252s(&contract_class.sierra_program)?;\n        for entry_points in [\n            &contract_class.entry_points_by_type.constructor,\n            &contract_class.entry_points_by_type.external,\n            &contract_class.entry_points_by_type.l1_handler,\n        ] {\n            // TODO(orizi): Use `is_sorted` when it becomes stable.\n            if (1..entry_points.len())\n                .any(|i| entry_points[i - 1].selector > entry_points[i].selector)\n            {\n                return Err(StarknetSierraCompilationError::EntryPointsOutOfOrder);\n            }\n        }\n\n        let entrypoint_ids = chain!(\n            &contract_class.entry_points_by_type.constructor,\n            &contract_class.entry_points_by_type.external,\n            &contract_class.entry_points_by_type.l1_handler,\n        )\n        .map(|entrypoint| program.funcs[entrypoint.function_idx].id.clone());\n        let metadata_computation_config = MetadataComputationConfig {\n            function_set_costs: entrypoint_ids\n                .map(|id| (id, [(CostTokenType::Const, ENTRY_POINT_COST)].into()))\n                .collect(),\n        };\n        let metadata = calc_metadata(&program, metadata_computation_config)?;\n\n        let gas_usage_check = true;\n        let cairo_program =\n            cairo_lang_sierra_to_casm::compiler::compile(&program, &metadata, gas_usage_check)?;\n\n        let mut bytecode = vec![];\n        let mut hints = vec![];\n        for instruction in cairo_program.instructions {\n            if !instruction.hints.is_empty() {\n                hints.push((bytecode.len(), instruction.hints.clone()))\n            }\n            bytecode.extend(instruction.assemble().encode().iter().map(|big_int| {\n                let (_q, reminder) = big_int.magnitude().div_rem(&prime);\n\n                BigUintAsHex {\n                    value: if big_int.is_negative() { &prime - reminder } else { reminder },\n                }\n            }))\n        }\n\n        let builtin_types = UnorderedHashSet::<GenericTypeId>::from_iter(\n            [\n                RangeCheckType::ID,\n                PedersenType::ID,\n                EcOpType::ID,\n                // TODO(lior): Uncomment the line below once Poseidon is supported.\n                //   PoseidonType::ID,\n                SegmentArenaType::ID,\n                GasBuiltinType::ID,\n                SystemType::ID,\n            ]\n            .into_iter(),\n        );\n\n        let as_casm_entry_point = |contract_entry_point: ContractEntryPoint| {\n            let Some(function) = program.funcs.get(contract_entry_point.function_idx) else {\n                return Err(StarknetSierraCompilationError::EntryPointError);\n            };\n            let statement_id = function.entry_point;\n\n            // The expected return types are [builtins.., gas_builtin, system, PanicResult].\n            if function.signature.ret_types.len() < 3 {\n                return Err(StarknetSierraCompilationError::InvalidEntryPointSignatureMissingArgs);\n            }\n            // TODO(ilya): Check that the last argument is PanicResult.\n            let (_panic_result, builtins) = function.signature.ret_types.split_last().unwrap();\n\n            let type_resolver = TypeResolver { type_decl: &program.type_declarations };\n\n            for type_id in builtins.iter() {\n                if !builtin_types.contains(type_resolver.get_generic_id(type_id)) {\n                    return Err(StarknetSierraCompilationError::InvalidBuiltinType(\n                        type_id.clone(),\n                    ));\n                }\n            }\n            let (system_ty, builtins) = builtins.split_last().unwrap();\n            let (gas_ty, builtins) = builtins.split_last().unwrap();\n\n            // Check that the last builtins are gas and system.\n            if *type_resolver.get_generic_id(system_ty) != SystemType::ID\n                || *type_resolver.get_generic_id(gas_ty) != GasBuiltinType::ID\n            {\n                return Err(\n                    StarknetSierraCompilationError::InvalidEntryPointSignatureWrongBuiltinsOrder,\n                );\n            }\n\n            let builtins = builtins\n                .iter()\n                .map(|type_id| {\n                    type_resolver.get_generic_id(type_id).0.as_str().to_case(Case::Snake)\n                })\n                .collect_vec();\n\n            let code_offset = cairo_program\n                .debug_info\n                .sierra_statement_info\n                .get(statement_id.0)\n                .ok_or(StarknetSierraCompilationError::EntryPointError)?\n                .code_offset;\n            assert_eq!(\n                metadata.gas_info.function_costs[function.id.clone()],\n                OrderedHashMap::from_iter([(CostTokenType::Const, ENTRY_POINT_COST as i64)]),\n                \"Unexpected entry point cost.\"\n            );\n            Ok::<CasmContractEntryPoint, StarknetSierraCompilationError>(CasmContractEntryPoint {\n                selector: contract_entry_point.selector,\n                offset: code_offset,\n                builtins,\n            })\n        };\n\n        let as_casm_entry_points = |contract_entry_points: Vec<ContractEntryPoint>| {\n            let mut entry_points = vec![];\n            for contract_entry_point in contract_entry_points.into_iter() {\n                entry_points.push(as_casm_entry_point(contract_entry_point)?);\n            }\n            Ok::<Vec<CasmContractEntryPoint>, StarknetSierraCompilationError>(entry_points)\n        };\n\n        let pythonic_hints = if add_pythonic_hints {\n            Some(\n                hints\n                    .iter()\n                    .map(|(pc, hints)| {\n                        (*pc, hints.iter().map(|hint| hint.to_string()).collect_vec())\n                    })\n                    .collect_vec(),\n            )\n        } else {\n            None\n        };\n\n        Ok(Self {\n            prime,\n            compiler_version: \"1.0.0\".to_string(),\n            bytecode,\n            hints,\n            pythonic_hints,\n            entry_points_by_type: CasmContractEntryPoints {\n                external: as_casm_entry_points(contract_class.entry_points_by_type.external)?,\n                l1_handler: as_casm_entry_points(contract_class.entry_points_by_type.l1_handler)?,\n                constructor: as_casm_entry_points(contract_class.entry_points_by_type.constructor)?,\n            },\n        })\n    }\n}\n\n#[derive(Default, Debug, PartialEq, Eq, Serialize, Deserialize)]\npub struct CasmContractEntryPoint {\n    /// A field element that encodes the signature of the called function.\n    #[serde(serialize_with = \"serialize_big_uint\", deserialize_with = \"deserialize_big_uint\")]\n    pub selector: BigUint,\n    /// The offset of the instruction that should be called within the contract bytecode.\n    pub offset: usize,\n    // list of builtins.\n    pub builtins: Vec<String>,\n}\n\n#[derive(Default, Debug, PartialEq, Eq, Serialize, Deserialize)]\npub struct CasmContractEntryPoints {\n    #[serde(rename = \"EXTERNAL\")]\n    pub external: Vec<CasmContractEntryPoint>,\n    #[serde(rename = \"L1_HANDLER\")]\n    pub l1_handler: Vec<CasmContractEntryPoint>,\n    #[serde(rename = \"CONSTRUCTOR\")]\n    pub constructor: Vec<CasmContractEntryPoint>,\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::io::BufReader;\n\nuse cairo_lang_test_utils::compare_contents_or_fix_with_path;\nuse num_bigint::BigUint;\nuse num_traits::Num;\nuse test_case::test_case;\n\nuse crate::casm_contract_class::{BigUintAsHex, CasmContractClass, StarknetSierraCompilationError};\nuse crate::contract_class::ContractClass;\nuse crate::test_utils::{get_example_file_path, get_test_contract};\n\n#[test_case(\"account\")]\n#[test_case(\"test_contract\")]\n#[test_case(\"minimal_contract\")]\n#[test_case(\"hello_starknet\")]\n#[test_case(\"erc20\")]\nfn test_casm_contract_from_contract_class(example_file_name: &str) {\n    let contract_class = get_test_contract(format!(\"{example_file_name}.cairo\").as_str());\n    let add_pythonic_hints = true;\n    let casm_contract =\n        CasmContractClass::from_contract_class(contract_class, add_pythonic_hints).unwrap();\n\n    compare_contents_or_fix_with_path(\n        &get_example_file_path(format!(\"{example_file_name}.casm.json\").as_str()),\n        serde_json::to_string_pretty(&casm_contract).unwrap() + \"\\n\",\n    );\n}\n\n#[test_case(\"test_contract\")]\nfn test_casm_contract_from_contract_class_failure(example_file_name: &str) {\n    let f =\n        std::fs::File::open(get_example_file_path(&format!(\"{example_file_name}.json\"))).unwrap();\n    let mut contract_class: ContractClass = serde_json::from_reader(BufReader::new(f)).unwrap();\n\n    let prime = BigUint::from_str_radix(\n        \"800000000000011000000000000000000000000000000000000000000000001\",\n        16,\n    )\n    .unwrap();\n\n    contract_class.sierra_program[17] = BigUintAsHex { value: prime };\n\n    let add_pythonic_hints = false;\n    assert_eq!(\n        CasmContractClass::from_contract_class(contract_class, add_pythonic_hints),\n        Err(StarknetSierraCompilationError::ValueOutOfRange)\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::fs;\nuse std::path::PathBuf;\n\nuse anyhow::Context;\nuse cairo_lang_compiler::CompilerConfig;\nuse cairo_lang_starknet::allowed_libfuncs::{validate_compatible_sierra_version, ListSelector};\nuse cairo_lang_starknet::contract_class::compile_path;\nuse clap::Parser;\n\n/// Command line args parser.\n/// Exits with 0/1 if the input is formatted correctly/incorrectly.\n#[derive(Parser, Debug)]\n#[clap(version, verbatim_doc_comment)]\nstruct Args {\n    /// The file to compile.\n    path: PathBuf,\n    /// The output file name (default: stdout).\n    output: Option<String>,\n    /// Replaces sierra ids with human-readable ones.\n    #[arg(short, long, default_value_t = false)]\n    replace_ids: bool,\n    /// The allowed libfuncs list to use (default: most recent audited list).\n    #[arg(long)]\n    allowed_libfuncs_list_name: Option<String>,\n    /// A file of the allowed libfuncs list to use.\n    #[arg(long)]\n    allowed_libfuncs_list_file: Option<String>,\n}\n\nfn main() -> anyhow::Result<()> {\n    let args = Args::parse();\n    let list_selector =\n        ListSelector::new(args.allowed_libfuncs_list_name, args.allowed_libfuncs_list_file)\n            .expect(\"Both allowed libfunc list name and file were supplied.\");\n    let contract = compile_path(\n        &args.path,\n        CompilerConfig { replace_ids: args.replace_ids, ..CompilerConfig::default() },\n    )?;\n    validate_compatible_sierra_version(&contract, list_selector)?;\n    let res = serde_json::to_string_pretty(&contract).with_context(|| \"Serialization failed.\")?;\n    match args.output {\n        Some(path) => fs::write(path, res).with_context(|| \"Failed to write output.\")?,\n        None => println!(\"{res}\"),\n    }\n\n    Ok(())\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use anyhow::Context;\nuse cairo_lang_defs::ids::{\n    FreeFunctionId, LanguageElementId, ModuleId, ModuleItemId, SubmoduleId, TraitId,\n};\nuse cairo_lang_diagnostics::ToOption;\nuse cairo_lang_filesystem::ids::CrateId;\nuse cairo_lang_semantic::db::SemanticGroup;\nuse cairo_lang_semantic::plugin::DynPluginAuxData;\nuse num_bigint::BigUint;\nuse sha3::{Digest, Keccak256};\n\nuse crate::plugin::aux_data::StarkNetContractAuxData;\nuse crate::plugin::consts::ABI_TRAIT;\n\n#[cfg(test)]\n#[path = \"contract_test.rs\"]\nmod test;\n\n/// Represents a declaration of a contract.\npub struct ContractDeclaration {\n    /// The id of the module that defines the contract.\n    pub submodule_id: SubmoduleId,\n}\n\nimpl ContractDeclaration {\n    pub fn module_id(&self) -> ModuleId {\n        ModuleId::Submodule(self.submodule_id)\n    }\n}\n\n/// A variant of eth-keccak that computes a value that fits in a Starknet field element.\npub fn starknet_keccak(data: &[u8]) -> BigUint {\n    let mut hasher = Keccak256::new();\n    hasher.update(data);\n    let mut result = hasher.finalize();\n\n    // Truncate result to 250 bits.\n    *result.first_mut().unwrap() &= 3;\n    BigUint::from_bytes_be(&result)\n}\n\n/// Finds the inline modules annotated as contracts in the given crate_ids and\n/// returns the corresponding ContractDeclarations.\npub fn find_contracts(db: &dyn SemanticGroup, crate_ids: &[CrateId]) -> Vec<ContractDeclaration> {\n    let mut contracts = vec![];\n    for crate_id in crate_ids {\n        let modules = db.crate_modules(*crate_id);\n        for module_id in modules.iter() {\n            let generated_file_infos =\n                db.module_generated_file_infos(*module_id).unwrap_or_default();\n\n            // When a module is generated by a plugin the same generated_file_info appears in two\n            // places:\n            //   a. db.module_generated_file_infos(*original_module_id)?[k] (with k > 0).\n            //   b. db.module_generated_file_infos(*generated_module_id)?[0].\n            // We are interested in modules that the plugin acted on and not modules that were\n            // created by the plugin, so we skip generated_file_infos[0].\n            // For example if we have\n            // mod A {\n            //    #[contract]\n            //    mod B {\n            //    }\n            // }\n            // Then we want lookup B inside A and not inside B.\n\n            for generated_file_info in generated_file_infos.iter().skip(1) {\n                let Some(generated_file_info) = generated_file_info else { continue; };\n                let Some(mapper) = generated_file_info.aux_data.0.as_any(\n                ).downcast_ref::<DynPluginAuxData>() else { continue; };\n                let Some(aux_data) = mapper.0.as_any(\n                ).downcast_ref::<StarkNetContractAuxData>() else { continue; };\n\n                for contract_name in &aux_data.contracts {\n                    if let Ok(Some(ModuleItemId::Submodule(submodule_id))) =\n                        db.module_item_by_name(*module_id, contract_name.clone())\n                    {\n                        contracts.push(ContractDeclaration { submodule_id });\n                    } else {\n                        panic!(\"Contract `{contract_name}` was not found.\");\n                    }\n                }\n            }\n        }\n    }\n    contracts\n}\n\n/// Returns the list of functions in a given module.\npub fn get_module_functions(\n    db: &(dyn SemanticGroup + 'static),\n    contract: &ContractDeclaration,\n    module_name: &str,\n) -> anyhow::Result<Vec<FreeFunctionId>> {\n    let generated_module_id = get_generated_contract_module(db, contract)?;\n    match db\n        .module_item_by_name(generated_module_id, module_name.into())\n        .to_option()\n        .with_context(|| \"Failed to initiate a lookup in the {module_name} module.\")?\n    {\n        Some(ModuleItemId::Submodule(external_module_id)) => Ok(db\n            .module_free_functions_ids(ModuleId::Submodule(external_module_id))\n            .to_option()\n            .with_context(|| \"Failed to get external module functions.\")?),\n        _ => anyhow::bail!(\"Failed to get the external module.\"),\n    }\n}\n\n/// Returns the ABI trait of the given contract.\npub fn get_abi(\n    db: &(dyn SemanticGroup + 'static),\n    contract: &ContractDeclaration,\n) -> anyhow::Result<TraitId> {\n    let generated_module_id = get_generated_contract_module(db, contract)?;\n    match db\n        .module_item_by_name(generated_module_id, ABI_TRAIT.into())\n        .to_option()\n        .with_context(|| \"Failed to initiate a lookup in the generated module.\")?\n    {\n        Some(ModuleItemId::Trait(trait_id)) => Ok(trait_id),\n        _ => anyhow::bail!(\"Failed to get the ABI trait.\"),\n    }\n}\n\n/// Returns the generated contract module.\nfn get_generated_contract_module(\n    db: &(dyn SemanticGroup + 'static),\n    contract: &ContractDeclaration,\n) -> anyhow::Result<ModuleId> {\n    let parent_module_id = contract.submodule_id.parent_module(db.upcast());\n    let contract_name = contract.submodule_id.name(db.upcast());\n\n    match db\n        .module_item_by_name(parent_module_id, contract_name.clone())\n        .to_option()\n        .with_context(|| \"Failed to initiate a lookup in the root module.\")?\n    {\n        Some(ModuleItemId::Submodule(generated_module_id)) => {\n            Ok(ModuleId::Submodule(generated_module_id))\n        }\n        _ => anyhow::bail!(format!(\"Failed to get generated module {contract_name}.\")),\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::path::Path;\nuse std::sync::Arc;\n\nuse anyhow::{ensure, Context, Result};\nuse cairo_lang_compiler::db::RootDatabase;\nuse cairo_lang_compiler::project::setup_project;\nuse cairo_lang_compiler::CompilerConfig;\nuse cairo_lang_diagnostics::ToOption;\nuse cairo_lang_filesystem::ids::CrateId;\nuse cairo_lang_semantic::db::SemanticGroup;\nuse cairo_lang_semantic::{ConcreteFunctionWithBodyId, FunctionLongId};\nuse cairo_lang_sierra_generator::canonical_id_replacer::CanonicalReplacer;\nuse cairo_lang_sierra_generator::db::SierraGenGroup;\nuse cairo_lang_sierra_generator::replace_ids::{replace_sierra_ids_in_program, SierraIdReplacer};\nuse cairo_lang_utils::bigint::{deserialize_big_uint, serialize_big_uint, BigUintAsHex};\nuse itertools::{chain, Itertools};\nuse num_bigint::BigUint;\nuse serde::{Deserialize, Serialize};\nuse thiserror::Error;\n\nuse crate::abi::{AbiBuilder, Contract};\nuse crate::allowed_libfuncs::AllowedLibfuncsError;\nuse crate::contract::{\n    find_contracts, get_abi, get_module_functions, starknet_keccak, ContractDeclaration,\n};\nuse crate::db::StarknetRootDatabaseBuilderEx;\nuse crate::felt252_serde::sierra_to_felt252s;\nuse crate::plugin::consts::{CONSTRUCTOR_MODULE, EXTERNAL_MODULE, L1_HANDLER_MODULE};\nuse crate::sierra_version::{self};\n\n#[cfg(test)]\n#[path = \"contract_class_test.rs\"]\nmod test;\n\n#[derive(Error, Debug, Eq, PartialEq)]\npub enum StarknetCompilationError {\n    #[error(\"Invalid entry point.\")]\n    EntryPointError,\n    #[error(transparent)]\n    AllowedLibfuncsError(#[from] AllowedLibfuncsError),\n}\n\n/// Represents a contract in the Starknet network.\n#[derive(Debug, PartialEq, Eq, Serialize, Deserialize)]\npub struct ContractClass {\n    pub sierra_program: Vec<BigUintAsHex>,\n    pub sierra_program_debug_info: Option<cairo_lang_sierra::debug_info::DebugInfo>,\n    pub contract_class_version: String,\n    pub entry_points_by_type: ContractEntryPoints,\n    pub abi: Option<Contract>,\n}\n\nconst DEFAULT_CONTRACT_CLASS_VERSION: &str = \"0.1.0\";\n\n#[derive(Default, Debug, PartialEq, Eq, Serialize, Deserialize)]\npub struct ContractEntryPoints {\n    #[serde(rename = \"EXTERNAL\")]\n    pub external: Vec<ContractEntryPoint>,\n    #[serde(rename = \"L1_HANDLER\")]\n    pub l1_handler: Vec<ContractEntryPoint>,\n    #[serde(rename = \"CONSTRUCTOR\")]\n    pub constructor: Vec<ContractEntryPoint>,\n}\n\n#[derive(Default, Debug, PartialEq, Eq, Serialize, Deserialize)]\npub struct ContractEntryPoint {\n    /// A field element that encodes the signature of the called function.\n    #[serde(serialize_with = \"serialize_big_uint\", deserialize_with = \"deserialize_big_uint\")]\n    pub selector: BigUint,\n    /// The idx of the user function declaration in the sierra program.\n    pub function_idx: usize,\n}\n\n/// Compile the contract given by path.\n///\n/// Errors if no contracts or more than 1 are found.\npub fn compile_path(path: &Path, compiler_config: CompilerConfig<'_>) -> Result<ContractClass> {\n    let mut db = RootDatabase::builder().detect_corelib().with_starknet().build()?;\n\n    let main_crate_ids = setup_project(&mut db, Path::new(&path))?;\n\n    compile_only_contract_in_prepared_db(&mut db, main_crate_ids, compiler_config)\n}\n\n/// Runs StarkNet contract compiler on the only contract defined in main crates.\n///\n/// This function will return an error if no, or more than 1 contract is found.\nfn compile_only_contract_in_prepared_db(\n    db: &mut RootDatabase,\n    main_crate_ids: Vec<CrateId>,\n    compiler_config: CompilerConfig<'_>,\n) -> Result<ContractClass> {\n    let contracts = find_contracts(db, &main_crate_ids);\n    ensure!(!contracts.is_empty(), \"Contract not found.\");\n    // TODO(ilya): Add contract names.\n    ensure!(contracts.len() == 1, \"Compilation unit must include only one contract.\");\n\n    let contracts = contracts.iter().collect::<Vec<_>>();\n    let mut classes = compile_prepared_db(db, &contracts, compiler_config)?;\n    assert_eq!(classes.len(), 1);\n    Ok(classes.remove(0))\n}\n\n/// Runs Starknet contracts compiler.\n///\n/// # Arguments\n/// * `db` - Preloaded compilation database.\n/// * `contracts` - [`ContractDeclaration`]s to compile. Use [`find_contracts`] to find contracts in\n///   `db`.\n/// * `compiler_config` - The compiler configuration.\n/// # Returns\n/// * `Ok(Vec<ContractClass>)` - List of all compiled contract classes found in main crates.\n/// * `Err(anyhow::Error)` - Compilation failed.\npub fn compile_prepared_db(\n    db: &mut RootDatabase,\n    contracts: &[&ContractDeclaration],\n    mut compiler_config: CompilerConfig<'_>,\n) -> Result<Vec<ContractClass>> {\n    compiler_config.diagnostics_reporter.ensure(db)?;\n\n    contracts\n        .iter()\n        .map(|contract| {\n            compile_contract_with_prepared_and_checked_db(db, contract, &compiler_config)\n        })\n        .try_collect()\n}\n\n/// Compile declared Starknet contract.\n///\n/// The `contract` value **must** come from `db`, for example as a result of calling\n/// [`find_contracts`]. Does not check diagnostics, it is expected that they are checked by caller\n/// of this function.\nfn compile_contract_with_prepared_and_checked_db(\n    db: &mut RootDatabase,\n    contract: &ContractDeclaration,\n    compiler_config: &CompilerConfig<'_>,\n) -> Result<ContractClass> {\n    let external_functions: Vec<_> = get_module_functions(db, contract, EXTERNAL_MODULE)?\n        .into_iter()\n        .flat_map(|f| ConcreteFunctionWithBodyId::from_no_generics_free(db, f))\n        .collect();\n    let l1_handler_functions: Vec<_> = get_module_functions(db, contract, L1_HANDLER_MODULE)?\n        .into_iter()\n        .flat_map(|f| ConcreteFunctionWithBodyId::from_no_generics_free(db, f))\n        .collect();\n    let constructor_functions: Vec<_> = get_module_functions(db, contract, CONSTRUCTOR_MODULE)?\n        .into_iter()\n        .flat_map(|f| ConcreteFunctionWithBodyId::from_no_generics_free(db, f))\n        .collect();\n    let mut sierra_program = db\n        .get_sierra_program_for_functions(\n            chain!(&external_functions, &l1_handler_functions, &constructor_functions)\n                .cloned()\n                .collect(),\n        )\n        .to_option()\n        .with_context(|| \"Compilation failed without any diagnostics.\")?;\n\n    if compiler_config.replace_ids {\n        sierra_program = Arc::new(replace_sierra_ids_in_program(db, &sierra_program));\n    }\n    let replacer = CanonicalReplacer::from_program(&sierra_program);\n    let sierra_program = replacer.apply(&sierra_program);\n\n    let entry_points_by_type = ContractEntryPoints {\n        external: get_entry_points(db, &external_functions, &replacer)?,\n        l1_handler: get_entry_points(db, &l1_handler_functions, &replacer)?,\n        /// TODO(orizi): Validate there is at most one constructor.\n        constructor: get_entry_points(db, &constructor_functions, &replacer)?,\n    };\n    let contract_class = ContractClass {\n        sierra_program: sierra_to_felt252s(\n            sierra_version::VersionId::current_version_id(),\n            &sierra_program,\n        )?,\n        sierra_program_debug_info: Some(cairo_lang_sierra::debug_info::DebugInfo::extract(\n            &sierra_program,\n        )),\n        contract_class_version: DEFAULT_CONTRACT_CLASS_VERSION.to_string(),\n        entry_points_by_type,\n        abi: Some(AbiBuilder::from_trait(db, get_abi(db, contract)?).with_context(|| \"ABI error\")?),\n    };\n    Ok(contract_class)\n}\n\n/// Returns the entry points given their IDs sorted by selectors.\nfn get_entry_points(\n    db: &mut RootDatabase,\n    entry_point_functions: &[ConcreteFunctionWithBodyId],\n    replacer: &CanonicalReplacer,\n) -> Result<Vec<ContractEntryPoint>> {\n    let mut entry_points = vec![];\n    for function_with_body_id in entry_point_functions {\n        let function_id = db.intern_function(FunctionLongId {\n            function: function_with_body_id\n                .concrete(db)\n                .to_option()\n                .with_context(|| \"Function error.\")?,\n        });\n\n        let sierra_id = db.intern_sierra_function(function_id);\n\n        entry_points.push(ContractEntryPoint {\n            selector: starknet_keccak(\n                function_with_body_id.function_with_body_id(db).name(db).as_bytes(),\n            ),\n            function_idx: replacer.replace_function_id(&sierra_id).id as usize,\n        });\n    }\n    entry_points.sort_by(|a, b| a.selector.cmp(&b.selector));\n    Ok(entry_points)\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_test_utils::compare_contents_or_fix_with_path;\nuse indoc::indoc;\nuse num_bigint::BigUint;\nuse pretty_assertions::assert_eq;\nuse test_case::test_case;\n\nuse crate::allowed_libfuncs::{validate_compatible_sierra_version, ListSelector};\nuse crate::contract_class::{\n    ContractClass, ContractEntryPoint, ContractEntryPoints, DEFAULT_CONTRACT_CLASS_VERSION,\n};\nuse crate::felt252_serde::sierra_from_felt252s;\nuse crate::sierra_version;\nuse crate::test_utils::{get_example_file_path, get_test_contract};\n\n#[test]\nfn test_serialization() {\n    let external = vec![ContractEntryPoint { selector: BigUint::from(u128::MAX), function_idx: 7 }];\n\n    let contract = ContractClass {\n        sierra_program: vec![],\n        sierra_program_debug_info: None,\n        contract_class_version: DEFAULT_CONTRACT_CLASS_VERSION.to_string(),\n        entry_points_by_type: ContractEntryPoints {\n            external,\n            l1_handler: vec![],\n            constructor: vec![],\n        },\n        abi: None,\n    };\n\n    let serialized = serde_json::to_string_pretty(&contract).unwrap();\n\n    assert_eq!(\n        &serialized,\n        indoc! {\n            r#\"\n        {\n          \"sierra_program\": [],\n          \"sierra_program_debug_info\": null,\n          \"contract_class_version\": \"0.1.0\",\n          \"entry_points_by_type\": {\n            \"EXTERNAL\": [\n              {\n                \"selector\": \"0xffffffffffffffffffffffffffffffff\",\n                \"function_idx\": 7\n              }\n            ],\n            \"L1_HANDLER\": [],\n            \"CONSTRUCTOR\": []\n          },\n          \"abi\": null\n        }\"#}\n    );\n\n    assert_eq!(contract, serde_json::from_str(&serialized).unwrap())\n}\n\n#[test_case(\"test_contract\")]\n#[test_case(\"hello_starknet\")]\n#[test_case(\"erc20\")]\nfn test_full_contract_deseralization(example_file_name: &str) {\n    let contract = get_test_contract(format!(\"{example_file_name}.cairo\").as_str());\n    let serialized = serde_json::to_string_pretty(&contract).unwrap();\n    assert_eq!(contract, serde_json::from_str(&serialized).unwrap())\n}\n\n#[test_case(\"account\")]\n#[test_case(\"test_contract\")]\n#[test_case(\"minimal_contract\")]\n#[test_case(\"hello_starknet\")]\n#[test_case(\"erc20\")]\nfn test_compile_path(example_file_name: &str) {\n    let contract = get_test_contract(format!(\"{example_file_name}.cairo\").as_str());\n\n    let list_selector = ListSelector::ListName(\"experimental_v0.1.0\".to_string());\n    validate_compatible_sierra_version(&contract, list_selector).unwrap();\n\n    compare_contents_or_fix_with_path(\n        &get_example_file_path(format!(\"{example_file_name}.json\").as_str()),\n        serde_json::to_string_pretty(&contract).unwrap() + \"\\n\",\n    );\n\n    let (version_id, mut sierra_program) = sierra_from_felt252s(&contract.sierra_program).unwrap();\n    assert_eq!(\n        version_id,\n        sierra_version::VersionId::current_version_id(),\n        \"Serialized Sierra version should be the current version.\"\n    );\n    contract.sierra_program_debug_info.unwrap().populate(&mut sierra_program);\n\n    // There is a separate file for the sierra code as it is hard to review inside the json.\n    compare_contents_or_fix_with_path(\n        &get_example_file_path(format!(\"{example_file_name}.sierra\").as_str()),\n        sierra_program.to_string(),\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_compiler::db::RootDatabase;\nuse cairo_lang_filesystem::db::FilesGroup;\nuse cairo_lang_semantic::test_utils::setup_test_crate;\nuse indoc::indoc;\nuse itertools::Itertools;\nuse pretty_assertions::assert_eq;\n\nuse crate::contract::{find_contracts, get_module_functions, starknet_keccak};\nuse crate::db::StarknetRootDatabaseBuilderEx;\nuse crate::plugin::consts::EXTERNAL_MODULE;\n\n#[test]\nfn test_contract_resolving() {\n    let db = &mut RootDatabase::builder().detect_corelib().with_starknet().build().unwrap();\n    let _crate_id = setup_test_crate(\n        db,\n        indoc! {\"\n            mod NotAContract {}\n\n            #[contract]\n            mod ERC20 {\n                fn internal_func(ref system: System) -> felt252 {\n                    1\n                }\n\n                #[external]\n                fn ep1() {}\n\n                #[external]\n                fn ep2() {}\n            }\n        \"},\n    );\n\n    let contracts = find_contracts(db, &db.crates());\n    assert_eq!(contracts.len(), 1);\n\n    assert_eq!(\n        get_module_functions(db, &contracts[0], EXTERNAL_MODULE)\n            .unwrap()\n            .into_iter()\n            .map(|func_id| func_id.name(db))\n            .collect_vec(),\n        vec![\"ep1\", \"ep2\"]\n    );\n}\n\n#[test]\nfn test_starknet_keccak() {\n    assert_eq!(\n        format!(\"0x{:x}\", starknet_keccak(\"__execute__\".as_bytes())),\n        \"0x15d40a3d6ca2ac30f4031e42be28da9b056fef9bb7357ac5e85627ee876e5ad\",\n    )\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse cairo_lang_compiler::db::RootDatabaseBuilder;\nuse cairo_lang_plugins::get_default_plugins;\n\nuse crate::plugin::StarkNetPlugin;\n\npub trait StarknetRootDatabaseBuilderEx {\n    /// Tunes a compiler database to Starknet (e.g. Starknet plugin).\n    fn with_starknet(&mut self) -> &mut Self;\n}\n\nimpl StarknetRootDatabaseBuilderEx for RootDatabaseBuilder {\n    fn with_starknet(&mut self) -> &mut Self {\n        // Override implicit precedence for compatibility with the Starknet OS.\n        let precedence = [\n            \"Pedersen\",\n            \"RangeCheck\",\n            \"Bitwise\",\n            \"EcOp\",\n            // TODO(lior): Uncomment the line below once Poseidon is supported.\n            //   \"Poseidon\",\n            \"SegmentArena\",\n            \"GasBuiltin\",\n            \"System\",\n        ];\n\n        let mut plugins = get_default_plugins();\n        plugins.push(Arc::new(StarkNetPlugin {}));\n\n        self.with_implicit_precedence(&precedence).with_plugins(plugins)\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_sierra::extensions::starknet::interoperability::ContractAddressTryFromFelt252Libfunc;\nuse cairo_lang_sierra::extensions::starknet::storage::{\n    StorageAddressFromBaseAndOffsetLibfunc, StorageBaseAddressFromFelt252Libfunc,\n};\nuse cairo_lang_sierra::extensions::try_from_felt252::TryFromFelt252;\nuse cairo_lang_sierra::extensions::NamedLibfunc;\nuse cairo_lang_sierra::ids::{\n    ConcreteLibfuncId, ConcreteTypeId, FunctionId, GenericLibfuncId, GenericTypeId, UserTypeId,\n    VarId,\n};\nuse cairo_lang_sierra::program::{\n    BranchInfo, BranchTarget, ConcreteLibfuncLongId, ConcreteTypeLongId, Function,\n    FunctionSignature, GenericArg, Invocation, LibfuncDeclaration, Param, Program, Statement,\n    StatementIdx, TypeDeclaration,\n};\nuse cairo_lang_utils::bigint::BigUintAsHex;\nuse cairo_lang_utils::ordered_hash_set::OrderedHashSet;\nuse cairo_lang_utils::unordered_hash_map::UnorderedHashMap;\nuse lazy_static::lazy_static;\nuse num_bigint::{BigInt, BigUint, ToBigInt};\nuse num_traits::ToPrimitive;\nuse thiserror::Error;\n\nuse crate::contract::starknet_keccak;\nuse crate::sierra_version::VersionId;\n\n#[cfg(test)]\n#[path = \"felt252_serde_test.rs\"]\nmod test;\n\n#[derive(Error, Debug, Eq, PartialEq)]\npub enum Felt252SerdeError {\n    #[error(\"Illegal bigint value during serialization.\")]\n    BigIntOutOfBounds,\n    #[error(\"Invalid input for deserialization.\")]\n    InvalidInputForDeserialization,\n    #[error(\n        \"Id `{0}` is too long for serialization. It is longer than {} characters. Consider adding \\\n         it in SERDE_SUPPORTED_LONG_IDS.\",\n        SHORT_STRING_BOUND\n    )]\n    GenericIdTooLong(String),\n    #[error(\"Invalid order of type declarations for serialization.\")]\n    OutOfOrderTypeDeclarationsForSerialization,\n    #[error(\"Invalid order of libfunc declarations for serialization.\")]\n    OutOfOrderLibfuncDeclarationsForSerialization,\n    #[error(\"Invalid order of user functions declarations for serialization.\")]\n    OutOfOrderUserFunctionDeclarationsForSerialization,\n    #[error(\"Invalid function declaration for serialization.\")]\n    FunctionArgumentsMismatchInSerialization,\n    #[error(\"The sierra version is too long and can not fit within a felt252.\")]\n    VersionIdTooLongForSerialization,\n}\n\n/// Serializes a Sierra program into a vector of felt252s.\npub fn sierra_to_felt252s(\n    sierra_version: VersionId,\n    program: &Program,\n) -> Result<Vec<BigUintAsHex>, Felt252SerdeError> {\n    let mut serialized = vec![];\n    sierra_version.serialize(&mut serialized)?;\n    program.serialize(&mut serialized)?;\n    Ok(serialized)\n}\n\n/// Deserializes a Sierra program from a slice of felt252s.\npub fn sierra_from_felt252s(\n    felts: &[BigUintAsHex],\n) -> Result<(VersionId, Program), Felt252SerdeError> {\n    let (version_id, program_part) = VersionId::deserialize(felts)?;\n    Ok((version_id, Program::deserialize(program_part)?.0))\n}\n\n/// Trait for serializing and deserializing into a felt252 vector.\ntrait Felt252Serde: Sized {\n    fn serialize(&self, output: &mut Vec<BigUintAsHex>) -> Result<(), Felt252SerdeError>;\n    fn deserialize(input: &[BigUintAsHex]) -> Result<(Self, &[BigUintAsHex]), Felt252SerdeError>;\n}\n\n// Impls for basic types.\n\nimpl Felt252Serde for usize {\n    fn serialize(&self, output: &mut Vec<BigUintAsHex>) -> Result<(), Felt252SerdeError> {\n        output.push(BigUintAsHex { value: (*self).into() });\n        Ok(())\n    }\n\n    fn deserialize(input: &[BigUintAsHex]) -> Result<(Self, &[BigUintAsHex]), Felt252SerdeError> {\n        let head = input\n            .first()\n            .and_then(|size| size.value.to_usize())\n            .ok_or(Felt252SerdeError::InvalidInputForDeserialization)?;\n        Ok((head, &input[1..]))\n    }\n}\n\nimpl Felt252Serde for u64 {\n    fn serialize(&self, output: &mut Vec<BigUintAsHex>) -> Result<(), Felt252SerdeError> {\n        output.push(BigUintAsHex { value: (*self).into() });\n        Ok(())\n    }\n\n    fn deserialize(input: &[BigUintAsHex]) -> Result<(Self, &[BigUintAsHex]), Felt252SerdeError> {\n        let head = input\n            .first()\n            .and_then(|size| size.value.to_u64())\n            .ok_or(Felt252SerdeError::InvalidInputForDeserialization)?;\n        Ok((head, &input[1..]))\n    }\n}\n\nimpl<T: Felt252Serde> Felt252Serde for Vec<T> {\n    fn serialize(&self, output: &mut Vec<BigUintAsHex>) -> Result<(), Felt252SerdeError> {\n        self.len().serialize(output)?;\n        for e in self {\n            e.serialize(output)?;\n        }\n        Ok(())\n    }\n\n    fn deserialize(input: &[BigUintAsHex]) -> Result<(Self, &[BigUintAsHex]), Felt252SerdeError> {\n        let (size, mut input) = usize::deserialize(input)?;\n        let mut result = Vec::with_capacity(size);\n        for _ in 0..size {\n            let (value, next) = T::deserialize(input)?;\n            result.push(value);\n            input = next;\n        }\n        Ok((result, input))\n    }\n}\n\nimpl Felt252Serde for BigInt {\n    fn serialize(&self, output: &mut Vec<BigUintAsHex>) -> Result<(), Felt252SerdeError> {\n        output.push(BigUintAsHex {\n            value: self.to_biguint().ok_or(Felt252SerdeError::BigIntOutOfBounds)?,\n        });\n        Ok(())\n    }\n    fn deserialize(input: &[BigUintAsHex]) -> Result<(Self, &[BigUintAsHex]), Felt252SerdeError> {\n        let first = input.first().ok_or(Felt252SerdeError::InvalidInputForDeserialization)?;\n        Ok((\n            first.value.to_bigint().expect(\"Unsigned should always be convertable to signed.\"),\n            &input[1..],\n        ))\n    }\n}\n\nimpl Felt252Serde for StatementIdx {\n    fn serialize(&self, output: &mut Vec<BigUintAsHex>) -> Result<(), Felt252SerdeError> {\n        self.0.serialize(output)\n    }\n    fn deserialize(input: &[BigUintAsHex]) -> Result<(Self, &[BigUintAsHex]), Felt252SerdeError> {\n        let (value, input) = usize::deserialize(input)?;\n        Ok((Self(value), input))\n    }\n}\n\n// Impls for generic ids.\nconst SHORT_STRING_BOUND: usize = 31;\nlazy_static! {\n    /// A set of all the supported long generic ids.\n    static ref SERDE_SUPPORTED_LONG_IDS: OrderedHashSet<&'static str> = {\n        OrderedHashSet::from_iter([\n                StorageAddressFromBaseAndOffsetLibfunc::STR_ID,\n                ContractAddressTryFromFelt252Libfunc::STR_ID,\n                StorageBaseAddressFromFelt252Libfunc::STR_ID\n            ].into_iter())\n    };\n    /// A mapping of all the long names when fixing them from the hashed keccak representation.\n    static ref LONG_NAME_FIX: UnorderedHashMap<BigUint, &'static str> = {\n        UnorderedHashMap::from_iter(SERDE_SUPPORTED_LONG_IDS.iter().map(|name|{\n            (starknet_keccak(name.as_bytes()), *name)\n        }))\n    };\n}\nmacro_rules! generic_id_serde {\n    ($Obj:ident) => {\n        impl Felt252Serde for $Obj {\n            fn serialize(&self, output: &mut Vec<BigUintAsHex>) -> Result<(), Felt252SerdeError> {\n                output.push(BigUintAsHex {\n                    value: if self.0.len() <= SHORT_STRING_BOUND {\n                        BigUint::from_bytes_be(self.0.as_bytes())\n                    } else {\n                        if !SERDE_SUPPORTED_LONG_IDS.contains(self.0.as_str()) {\n                            return Err(Felt252SerdeError::GenericIdTooLong(self.0.to_string()));\n                        }\n                        starknet_keccak(self.0.as_bytes())\n                    },\n                });\n                Ok(())\n            }\n            fn deserialize(\n                input: &[BigUintAsHex],\n            ) -> Result<(Self, &[BigUintAsHex]), Felt252SerdeError> {\n                let head = input\n                    .first()\n                    .and_then(|id| {\n                        LONG_NAME_FIX.get(&id.value).map(|s| Self(s.into())).or_else(|| {\n                            std::str::from_utf8(&id.value.to_bytes_be())\n                                .ok()\n                                .map(|s| Self(s.into()))\n                        })\n                    })\n                    .ok_or(Felt252SerdeError::InvalidInputForDeserialization)?;\n                Ok((head, &input[1..]))\n            }\n        }\n    };\n}\n\ngeneric_id_serde!(GenericTypeId);\ngeneric_id_serde!(GenericLibfuncId);\n\nimpl Felt252Serde for UserTypeId {\n    fn serialize(&self, output: &mut Vec<BigUintAsHex>) -> Result<(), Felt252SerdeError> {\n        output.push(BigUintAsHex { value: self.id.clone() });\n        Ok(())\n    }\n    fn deserialize(input: &[BigUintAsHex]) -> Result<(Self, &[BigUintAsHex]), Felt252SerdeError> {\n        let first = input.first().ok_or(Felt252SerdeError::InvalidInputForDeserialization)?;\n        Ok((Self { id: first.value.clone(), debug_name: None }, &input[1..]))\n    }\n}\n\n// Impls for other ids.\n\nmacro_rules! id_serde {\n    ($Obj:ident) => {\n        impl Felt252Serde for $Obj {\n            fn serialize(&self, output: &mut Vec<BigUintAsHex>) -> Result<(), Felt252SerdeError> {\n                self.id.serialize(output)\n            }\n            fn deserialize(\n                input: &[BigUintAsHex],\n            ) -> Result<(Self, &[BigUintAsHex]), Felt252SerdeError> {\n                let (id, input) = u64::deserialize(input)?;\n                Ok((Self::new(id), input))\n            }\n        }\n    };\n}\n\nid_serde!(ConcreteTypeId);\nid_serde!(ConcreteLibfuncId);\nid_serde!(VarId);\nid_serde!(FunctionId);\n\n// Impls for structs.\n\nmacro_rules! struct_serialize_impl {\n    ($obj:ident, $output:ident, { $($field_name:ident),* }) => {\n        {\n            let __obj = $obj;\n            let __output = $output;\n            $(Felt252Serde::serialize(&__obj. $field_name, __output)?;)*\n            Ok(())\n        }\n    };\n}\n\nmacro_rules! struct_deserialize_impl {\n    ($input:ident, { $($field_name:ident : $field_type:ty),* }) => {\n        let __input = $input;\n        $(\n            let ($field_name, __input) = <$field_type>::deserialize(__input)?;\n        )*\n        $input = __input;\n    };\n}\n\nmacro_rules! struct_serialize {\n    ($($field_name:ident),*) => {\n        fn serialize(&self, output: &mut Vec<BigUintAsHex>) -> Result<(), Felt252SerdeError> {\n            struct_serialize_impl!(self, output, { $($field_name),* })\n        }\n    };\n}\n\nmacro_rules! struct_deserialize {\n    ($Obj:ident { $($field_name:ident : $field_type:ty),* }) => {\n        fn deserialize(\n            mut input: &[BigUintAsHex],\n        ) -> Result<(Self, &[BigUintAsHex]), Felt252SerdeError> {\n            struct_deserialize_impl!(input, {$($field_name : $field_type),*});\n            Ok((Self {$($field_name),*}, input))\n        }\n    };\n}\n\nmacro_rules! struct_serde {\n    ($Obj:ident { $($field_name:ident : $field_type:ty),* $(,)? }) => {\n        impl Felt252Serde for $Obj {\n            struct_serialize! { $($field_name),* }\n            struct_deserialize! { $Obj { $($field_name : $field_type),* } }\n        }\n    }\n}\n\nimpl Felt252Serde for Program {\n    fn serialize(&self, output: &mut Vec<BigUintAsHex>) -> Result<(), Felt252SerdeError> {\n        // Type declarations.\n        self.type_declarations.len().serialize(output)?;\n        for (i, e) in self.type_declarations.iter().enumerate() {\n            if i as u64 != e.id.id {\n                return Err(Felt252SerdeError::OutOfOrderTypeDeclarationsForSerialization);\n            }\n            e.long_id.serialize(output)?;\n        }\n        // Libfunc declaration.\n        self.libfunc_declarations.len().serialize(output)?;\n        for (i, e) in self.libfunc_declarations.iter().enumerate() {\n            if i as u64 != e.id.id {\n                return Err(Felt252SerdeError::OutOfOrderLibfuncDeclarationsForSerialization);\n            }\n            e.long_id.serialize(output)?;\n        }\n        // Statements.\n        Felt252Serde::serialize(&self.statements, output)?;\n        // Function declaration.\n        self.funcs.len().serialize(output)?;\n        for (i, f) in self.funcs.iter().enumerate() {\n            if i as u64 != f.id.id {\n                return Err(Felt252SerdeError::OutOfOrderUserFunctionDeclarationsForSerialization);\n            }\n            f.signature.serialize(output)?;\n            if f.signature.param_types.len() != f.params.len() {\n                return Err(Felt252SerdeError::FunctionArgumentsMismatchInSerialization);\n            }\n            for (param, ty) in f.params.iter().zip(f.signature.param_types.iter()) {\n                if param.ty != *ty {\n                    return Err(Felt252SerdeError::FunctionArgumentsMismatchInSerialization);\n                }\n                param.id.serialize(output)?;\n            }\n            f.entry_point.serialize(output)?;\n        }\n        Ok(())\n    }\n\n    fn deserialize(input: &[BigUintAsHex]) -> Result<(Self, &[BigUintAsHex]), Felt252SerdeError> {\n        // Type declarations.\n        let (size, mut input) = usize::deserialize(input)?;\n        let mut type_declarations = Vec::with_capacity(size);\n        for i in 0..size {\n            let (long_id, next) = ConcreteTypeLongId::deserialize(input)?;\n            type_declarations.push(TypeDeclaration {\n                id: ConcreteTypeId::new(i as u64),\n                long_id,\n                declared_type_info: None,\n            });\n            input = next;\n        }\n        // Libfunc declaration.\n        let (size, mut input) = usize::deserialize(input)?;\n        let mut libfunc_declarations = Vec::with_capacity(size);\n        for i in 0..size {\n            let (long_id, next) = ConcreteLibfuncLongId::deserialize(input)?;\n            libfunc_declarations\n                .push(LibfuncDeclaration { id: ConcreteLibfuncId::new(i as u64), long_id });\n            input = next;\n        }\n        // Statements.\n        let (statements, input) = Felt252Serde::deserialize(input)?;\n        // Function declaration.\n        let (size, mut input) = usize::deserialize(input)?;\n        let mut funcs = Vec::with_capacity(size);\n        for i in 0..size {\n            let (signature, next) = FunctionSignature::deserialize(input)?;\n            input = next;\n            let params = signature\n                .param_types\n                .iter()\n                .cloned()\n                .map(|ty| -> Result<Param, Felt252SerdeError> {\n                    let (id, next) = VarId::deserialize(input)?;\n                    input = next;\n                    Ok(Param { id, ty })\n                })\n                .collect::<Result<Vec<_>, _>>()?;\n            let (entry_point, next) = StatementIdx::deserialize(input)?;\n            funcs.push(Function { id: FunctionId::new(i as u64), signature, params, entry_point });\n            input = next;\n        }\n        Ok((Self { type_declarations, libfunc_declarations, statements, funcs }, input))\n    }\n}\n\nstruct_serde! {\n    ConcreteTypeLongId {\n        generic_id: GenericTypeId,\n        generic_args: Vec<GenericArg>,\n    }\n}\n\nstruct_serde! {\n    ConcreteLibfuncLongId {\n        generic_id: GenericLibfuncId,\n        generic_args: Vec<GenericArg>,\n    }\n}\n\nstruct_serde! {\n    FunctionSignature {\n        param_types:  Vec<ConcreteTypeId>,\n        ret_types:  Vec<ConcreteTypeId>,\n    }\n}\n\nstruct_serde! {\n    Invocation {\n        libfunc_id: ConcreteLibfuncId,\n        args: Vec<VarId>,\n        branches: Vec<BranchInfo>,\n    }\n}\n\nstruct_serde! {\n    BranchInfo {\n        target: BranchTarget,\n        results: Vec<VarId>,\n    }\n}\n\n// Impls for enums.\n\nmacro_rules! enum_serialize_impl {\n    ($obj:ident, $output:ident, $Obj:ident { $($variant_name:ident = $variant_id:literal),* }) => {\n        {\n            let __output = $output;\n            match $obj {\n                $(\n                    $Obj::$variant_name(value) => {\n                        u64::serialize(&$variant_id, __output)?;\n                        Felt252Serde::serialize(value, __output)\n                    }\n                ),*\n            }\n        }\n    };\n}\n\nmacro_rules! enum_serialize {\n    ($($variant_name:ident = $variant_id:literal),*) => {\n        fn serialize(&self, output: &mut Vec<BigUintAsHex>) -> Result<(), Felt252SerdeError> {\n            enum_serialize_impl!(self, output, Self { $($variant_name = $variant_id),* })\n        }\n    };\n}\n\nmacro_rules! enum_deserialize {\n    ($($variant_name:ident ( $variant_type:ty ) = $variant_id:literal),*) => {\n        fn deserialize(\n            input: &[BigUintAsHex],\n        ) -> Result<(Self, &[BigUintAsHex]), Felt252SerdeError> {\n            let (id, input) = u64::deserialize(input)?;\n            match id {\n                $($variant_id => {\n                    let (value, input) = <$variant_type>::deserialize(input)?;\n                    Ok((Self::$variant_name(value), input))\n                },)*\n                _ => Err(Felt252SerdeError::InvalidInputForDeserialization),\n            }\n        }\n    };\n}\n\nmacro_rules! enum_serde {\n    ($Obj:ident { $($variant_name:ident ( $variant_type:ty ) = $variant_id:literal),* $(,)? }) => {\n        impl Felt252Serde for $Obj {\n            enum_serialize! { $($variant_name = $variant_id),* }\n            enum_deserialize! { $($variant_name($variant_type) = $variant_id),* }\n        }\n    }\n}\n\nenum_serde! {\n    Statement {\n        Invocation(Invocation) = 0,\n        Return(Vec::<VarId>) = 1,\n    }\n}\n\nenum_serde! {\n    GenericArg {\n        UserType(UserTypeId) = 0,\n        Type(ConcreteTypeId) = 1,\n        Value(BigInt) = 2,\n        UserFunc(FunctionId) = 3,\n        Libfunc(ConcreteLibfuncId) = 4,\n    }\n}\n\nimpl Felt252Serde for BranchTarget {\n    fn serialize(&self, output: &mut Vec<BigUintAsHex>) -> Result<(), Felt252SerdeError> {\n        match self {\n            Self::Fallthrough => usize::MAX.serialize(output),\n            Self::Statement(idx) => idx.serialize(output),\n        }\n    }\n\n    fn deserialize(input: &[BigUintAsHex]) -> Result<(Self, &[BigUintAsHex]), Felt252SerdeError> {\n        let (idx, input) = usize::deserialize(input)?;\n        Ok((\n            if idx == usize::MAX { Self::Fallthrough } else { Self::Statement(StatementIdx(idx)) },\n            input,\n        ))\n    }\n}\n\nimpl Felt252Serde for VersionId {\n    fn serialize(&self, output: &mut Vec<BigUintAsHex>) -> Result<(), Felt252SerdeError> {\n        if self.version.len() < SHORT_STRING_BOUND {\n            output.push(BigUintAsHex { value: BigUint::from_bytes_be(self.version.as_bytes()) });\n            Ok(())\n        } else {\n            Err(Felt252SerdeError::VersionIdTooLongForSerialization)\n        }\n    }\n    fn deserialize(input: &[BigUintAsHex]) -> Result<(Self, &[BigUintAsHex]), Felt252SerdeError> {\n        let head = input\n            .first()\n            .and_then(|id| {\n                std::str::from_utf8(&id.value.to_bytes_be())\n                    .ok()\n                    .map(|s| Self { version: s.into() })\n            })\n            .ok_or(Felt252SerdeError::InvalidInputForDeserialization)?;\n        Ok((head, &input[1..]))\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::fs::read_to_string;\n\nuse cairo_lang_sierra::ProgramParser;\nuse cairo_lang_sierra_generator::canonical_id_replacer::CanonicalReplacer;\nuse cairo_lang_sierra_generator::replace_ids::SierraIdReplacer;\nuse test_case::test_case;\n\nuse super::{sierra_from_felt252s, sierra_to_felt252s};\nuse crate::sierra_version;\nuse crate::test_utils::get_example_file_path;\n\n#[test_case(\"test_contract\")]\n#[test_case(\"hello_starknet\")]\nfn test_felt252_serde(example_file_name: &str) {\n    let sierra = ProgramParser::new()\n        .parse(\n            &read_to_string(get_example_file_path(format!(\"{example_file_name}.sierra\").as_str()))\n                .unwrap(),\n        )\n        .unwrap();\n    let replacer = CanonicalReplacer::from_program(&sierra);\n    let sierra = replacer.apply(&sierra);\n    pretty_assertions::assert_eq!(\n        sierra_from_felt252s(\n            &sierra_to_felt252s(sierra_version::VersionId::current_version_id(), &sierra)\n                .expect(\"Serialization failed.\")\n        )\n        .expect(\"Deserialization failed.\"),\n        (sierra_version::VersionId::current_version_id(), sierra)\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Starknet capabilities and utilities on top of Cairo.\n//!\n//! Starknet is a smart contract platform that enables developers to build and deploy smart\n//! contracts on a permissionless Layer 2 network, secured by Ethereum using validity proofs.\n//!\n//! Learn more at [starkware.io](http://starknet.io/).\npub mod abi;\npub mod allowed_libfuncs;\npub mod casm_contract_class;\npub mod contract;\npub mod contract_class;\npub mod db;\nmod felt252_serde;\npub mod plugin;\nmod sierra_version;\n\n#[cfg(test)]\nmod test_utils;\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_defs::plugin::GeneratedFileAuxData;\nuse cairo_lang_diagnostics::DiagnosticEntry;\nuse cairo_lang_semantic::db::SemanticGroup;\nuse cairo_lang_semantic::patcher::Patches;\nuse cairo_lang_semantic::plugin::{\n    AsDynGeneratedFileAuxData, PluginAuxData, PluginMappedDiagnostic,\n};\nuse cairo_lang_semantic::SemanticDiagnostic;\n\n/// Contract related auxiliary data of the Starknet plugin.\n#[derive(Debug, PartialEq, Eq)]\npub struct StarkNetContractAuxData {\n    /// Patches of code that need translation in case they have diagnostics.\n    pub patches: Patches,\n\n    /// A list of contracts that were processed by the plugin.\n    pub contracts: Vec<smol_str::SmolStr>,\n}\nimpl GeneratedFileAuxData for StarkNetContractAuxData {\n    fn as_any(&self) -> &dyn std::any::Any {\n        self\n    }\n    fn eq(&self, other: &dyn GeneratedFileAuxData) -> bool {\n        if let Some(other) = other.as_any().downcast_ref::<Self>() { self == other } else { false }\n    }\n}\nimpl AsDynGeneratedFileAuxData for StarkNetContractAuxData {\n    fn as_dyn_macro_token(&self) -> &(dyn GeneratedFileAuxData + 'static) {\n        self\n    }\n}\nimpl PluginAuxData for StarkNetContractAuxData {\n    fn map_diag(\n        &self,\n        db: &(dyn SemanticGroup + 'static),\n        diag: &dyn std::any::Any,\n    ) -> Option<PluginMappedDiagnostic> {\n        let Some(diag) = diag.downcast_ref::<SemanticDiagnostic>() else {return None;};\n        let span = self\n            .patches\n            .translate(db.upcast(), diag.stable_location.diagnostic_location(db.upcast()).span)?;\n        Some(PluginMappedDiagnostic { span, message: diag.format(db) })\n    }\n}\n\n/// Contract related auxiliary data of the Starknet plugin.\n#[derive(Debug, PartialEq, Eq)]\npub struct StarkNetABIAuxData {\n    /// Patches of code that need translation in case they have diagnostics.\n    pub patches: Patches,\n}\nimpl GeneratedFileAuxData for StarkNetABIAuxData {\n    fn as_any(&self) -> &dyn std::any::Any {\n        self\n    }\n    fn eq(&self, other: &dyn GeneratedFileAuxData) -> bool {\n        if let Some(other) = other.as_any().downcast_ref::<Self>() { self == other } else { false }\n    }\n}\nimpl AsDynGeneratedFileAuxData for StarkNetABIAuxData {\n    fn as_dyn_macro_token(&self) -> &(dyn GeneratedFileAuxData + 'static) {\n        self\n    }\n}\nimpl PluginAuxData for StarkNetABIAuxData {\n    fn map_diag(\n        &self,\n        db: &(dyn SemanticGroup + 'static),\n        diag: &dyn std::any::Any,\n    ) -> Option<PluginMappedDiagnostic> {\n        let Some(diag) = diag.downcast_ref::<SemanticDiagnostic>() else {return None;};\n        let span = self\n            .patches\n            .translate(db.upcast(), diag.stable_location.diagnostic_location(db.upcast()).span)?;\n        Some(PluginMappedDiagnostic { span, message: diag.format(db) })\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "pub const VIEW_ATTR: &str = \"view\";\npub const EVENT_ATTR: &str = \"event\";\npub const ABI_TRAIT: &str = \"__abi\";\npub const STORAGE_STRUCT_NAME: &str = \"Storage\";\npub const EXTERNAL_MODULE: &str = \"__external\";\npub const L1_HANDLER_MODULE: &str = \"__l1_handler\";\npub const CONSTRUCTOR_MODULE: &str = \"__constructor\";\n\npub(super) const ABI_ATTR: &str = \"abi\";\npub(super) const ACCOUNT_CONTRACT_ATTR: &str = \"account_contract\";\npub(super) const CONTRACT_ATTR: &str = \"contract\";\npub(super) const EXTERNAL_ATTR: &str = \"external\";\npub(super) const L1_HANDLER_ATTR: &str = \"l1_handler\";\npub(super) const CONSTRUCTOR_ATTR: &str = \"constructor\";\npub(super) const RAW_OUTPUT_ATTR: &str = \"raw_output\";\n\npub(super) const EXECUTE_ENTRY_POINT_NAME: &str = \"__execute__\";\npub(super) const VALIDATE_ENTRY_POINT_NAME: &str = \"__validate__\";\npub(super) const VALIDATE_DECLARE_ENTRY_POINT_NAME: &str = \"__validate_declare__\";\npub(super) const VALIDATE_DEPLOY_ENTRY_POINT_NAME: &str = \"__validate_deploy__\";\n\npub(super) const ACCOUNT_CONTRACT_ENTRY_POINTS: [&str; 4] = [\n    EXECUTE_ENTRY_POINT_NAME,\n    VALIDATE_ENTRY_POINT_NAME,\n    VALIDATE_DECLARE_ENTRY_POINT_NAME,\n    VALIDATE_DEPLOY_ENTRY_POINT_NAME,\n];\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashMap;\nuse std::vec;\n\nuse cairo_lang_defs::plugin::{\n    DynGeneratedFileAuxData, PluginDiagnostic, PluginGeneratedFile, PluginResult,\n};\nuse cairo_lang_semantic::patcher::{PatchBuilder, RewriteNode};\nuse cairo_lang_semantic::plugin::DynPluginAuxData;\nuse cairo_lang_syntax::node::ast::{MaybeModuleBody, OptionWrappedGenericParamList};\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::helpers::QueryAttrs;\nuse cairo_lang_syntax::node::{ast, Terminal, TypedSyntaxNode};\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse indoc::formatdoc;\n\nuse super::consts::{\n    ABI_TRAIT, ACCOUNT_CONTRACT_ATTR, ACCOUNT_CONTRACT_ENTRY_POINTS, CONSTRUCTOR_ATTR,\n    CONSTRUCTOR_MODULE, CONTRACT_ATTR, EVENT_ATTR, EXTERNAL_ATTR, EXTERNAL_MODULE, L1_HANDLER_ATTR,\n    L1_HANDLER_MODULE, STORAGE_STRUCT_NAME, VIEW_ATTR,\n};\nuse super::entry_point::generate_entry_point_wrapper;\nuse super::events::handle_event;\nuse super::storage::handle_storage_struct;\nuse super::utils::is_mut_param;\nuse crate::plugin::aux_data::StarkNetContractAuxData;\n\n/// If the module is annotated with CONTRACT_ATTR, generate the relevant contract logic.\npub fn handle_mod(db: &dyn SyntaxGroup, module_ast: ast::ItemModule) -> PluginResult {\n    let is_account_contract = module_ast.has_attr(db, ACCOUNT_CONTRACT_ATTR);\n\n    if !is_account_contract && !module_ast.has_attr(db, CONTRACT_ATTR) {\n        return PluginResult::default();\n    }\n\n    let body = match module_ast.body(db) {\n        MaybeModuleBody::Some(body) => body,\n        MaybeModuleBody::None(empty_body) => {\n            return PluginResult {\n                code: None,\n                diagnostics: vec![PluginDiagnostic {\n                    message: \"Contracts without body are not supported.\".to_string(),\n                    stable_ptr: empty_body.stable_ptr().untyped(),\n                }],\n                remove_original_item: false,\n            };\n        }\n    };\n    let mut diagnostics = vec![];\n    let mut kept_original_items = Vec::new();\n\n    // A maping from a 'use' item to its path.\n    let mut extra_uses = OrderedHashMap::default();\n    for item in body.items(db).elements(db) {\n        // Skipping elements that only generate other code, but their code itself is ignored.\n        if matches!(&item, ast::Item::FreeFunction(item) if item.has_attr(db, EVENT_ATTR))\n            || matches!(&item, ast::Item::Struct(item) if item.name(db).text(db) == STORAGE_STRUCT_NAME)\n        {\n            continue;\n        }\n        kept_original_items.push(RewriteNode::Copied(item.as_syntax_node()));\n        if let Some(ident) = match item {\n            ast::Item::Constant(item) => Some(item.name(db)),\n            ast::Item::Module(item) => Some(item.name(db)),\n            ast::Item::Use(item) => {\n                if let Some(ast::PathSegment::Simple(final_section)) =\n                    item.name(db).elements(db).last()\n                {\n                    Some(final_section.ident(db))\n                } else {\n                    None\n                }\n            }\n            ast::Item::Impl(item) => Some(item.name(db)),\n            ast::Item::Struct(item) => Some(item.name(db)),\n            ast::Item::Enum(item) => Some(item.name(db)),\n            ast::Item::TypeAlias(item) => Some(item.name(db)),\n            // Externs, trait declarations and free functions are not directly required in generated\n            // inner modules.\n            ast::Item::ExternFunction(_)\n            | ast::Item::ExternType(_)\n            | ast::Item::Trait(_)\n            | ast::Item::FreeFunction(_) => None,\n        } {\n            extra_uses\n                .entry(ident.text(db))\n                .or_insert_with_key(|ident| format!(\"super::{}\", ident));\n        }\n    }\n\n    for (use_item, path) in [\n        (\"ClassHashSerde\", \"starknet::class_hash::ClassHashSerde\"),\n        (\"ContractAddressSerde\", \"starknet::contract_address::ContractAddressSerde\"),\n        (\"StorageAddressSerde\", \"starknet::storage_access::StorageAddressSerde\"),\n    ]\n    .into_iter()\n    {\n        extra_uses.entry(use_item.into()).or_insert_with(|| path.to_string());\n    }\n\n    let extra_uses_node = RewriteNode::new_modified(\n        extra_uses\n            .values()\n            .map(|use_path| RewriteNode::Text(format!(\"\\n        use {use_path};\")))\n            .collect(),\n    );\n    let mut generated_external_functions = Vec::new();\n    let mut generated_constructor_functions = Vec::new();\n    let mut generated_l1_handler_functions = Vec::new();\n\n    let mut storage_code = RewriteNode::Text(\"\".to_string());\n    let mut abi_functions = Vec::new();\n    let mut event_functions = Vec::new();\n    let mut abi_events = Vec::new();\n    for item in body.items(db).elements(db) {\n        match &item {\n            ast::Item::FreeFunction(item_function)\n                if item_function.has_attr(db, EXTERNAL_ATTR)\n                    || item_function.has_attr(db, VIEW_ATTR)\n                    || item_function.has_attr(db, CONSTRUCTOR_ATTR)\n                    || item_function.has_attr(db, L1_HANDLER_ATTR) =>\n            {\n                let attr = if item_function.has_attr(db, EXTERNAL_ATTR) {\n                    EXTERNAL_ATTR\n                } else if item_function.has_attr(db, VIEW_ATTR) {\n                    VIEW_ATTR\n                } else if item_function.has_attr(db, CONSTRUCTOR_ATTR) {\n                    CONSTRUCTOR_ATTR\n                } else {\n                    L1_HANDLER_ATTR\n                };\n\n                let declaration = item_function.declaration(db);\n                if let OptionWrappedGenericParamList::WrappedGenericParamList(generic_params) =\n                    declaration.generic_params(db)\n                {\n                    diagnostics.push(PluginDiagnostic {\n                        message: \"Contract entry points cannot have generic arguments\".to_string(),\n                        stable_ptr: generic_params.stable_ptr().untyped(),\n                    })\n                }\n\n                let name = declaration.name(db);\n                let name_str = name.text(db);\n\n                if !is_account_contract {\n                    for account_contract_entry_point in ACCOUNT_CONTRACT_ENTRY_POINTS {\n                        if name_str == account_contract_entry_point {\n                            diagnostics.push(PluginDiagnostic {\n                                message: format!(\n                                    \"Only an account contract may implement `{name_str}`.\"\n                                ),\n\n                                stable_ptr: name.stable_ptr().untyped(),\n                            })\n                        }\n                    }\n                }\n                // TODO(ilya): Validate that an account contract has all the required functions.\n\n                let mut declaration_node = RewriteNode::new_trimmed(declaration.as_syntax_node());\n                let original_parameters = declaration_node\n                    .modify_child(db, ast::FunctionDeclaration::INDEX_SIGNATURE)\n                    .modify_child(db, ast::FunctionSignature::INDEX_PARAMETERS);\n                for (param_idx, param) in\n                    declaration.signature(db).parameters(db).elements(db).iter().enumerate()\n                {\n                    // This assumes `mut` can only appear alone.\n                    if is_mut_param(db, param) {\n                        original_parameters\n                            .modify_child(db, param_idx * 2)\n                            .modify_child(db, ast::Param::INDEX_MODIFIERS)\n                            .set_str(\"\".to_string());\n                    }\n                }\n                abi_functions.push(RewriteNode::new_modified(vec![\n                    RewriteNode::Text(format!(\"#[{attr}]\\n        \")),\n                    declaration_node,\n                    RewriteNode::Text(\";\\n        \".to_string()),\n                ]));\n\n                match generate_entry_point_wrapper(db, item_function) {\n                    Ok(generated_function) => {\n                        let generated = if item_function.has_attr(db, CONSTRUCTOR_ATTR) {\n                            &mut generated_constructor_functions\n                        } else if item_function.has_attr(db, L1_HANDLER_ATTR) {\n                            &mut generated_l1_handler_functions\n                        } else {\n                            &mut generated_external_functions\n                        };\n                        generated.push(generated_function);\n                        generated.push(RewriteNode::Text(\"\\n        \".to_string()));\n                    }\n                    Err(entry_point_diagnostics) => {\n                        diagnostics.extend(entry_point_diagnostics);\n                    }\n                }\n            }\n            ast::Item::FreeFunction(item_function) if item_function.has_attr(db, EVENT_ATTR) => {\n                let (rewrite_nodes, event_diagnostics) = handle_event(db, item_function.clone());\n                if let Some((event_function_rewrite, abi_event_rewrite)) = rewrite_nodes {\n                    event_functions.push(event_function_rewrite);\n                    // TODO(yuval): keep track in the ABI that these are events.\n                    abi_events.push(abi_event_rewrite);\n                }\n                diagnostics.extend(event_diagnostics);\n            }\n            ast::Item::Struct(item_struct)\n                if item_struct.name(db).text(db) == STORAGE_STRUCT_NAME =>\n            {\n                let (storage_rewrite_node, storage_diagnostics) =\n                    handle_storage_struct(db, item_struct.clone(), &extra_uses_node);\n                storage_code = storage_rewrite_node;\n                diagnostics.extend(storage_diagnostics);\n            }\n            _ => {}\n        }\n    }\n\n    let module_name_ast = module_ast.name(db);\n    let generated_contract_mod = RewriteNode::interpolate_patched(\n        formatdoc!(\n            \"\n            mod $contract_name$ {{\n                use starknet::SyscallResultTrait;\n                use starknet::SyscallResultTraitImpl;\n\n            $original_items$\n                $storage_code$\n\n                $event_functions$\n\n                trait {ABI_TRAIT} {{\n                    $abi_functions$\n                    $abi_events$\n                }}\n\n                mod {EXTERNAL_MODULE} {{$extra_uses$\n\n                    $generated_external_functions$\n                }}\n\n                mod {L1_HANDLER_MODULE} {{$extra_uses$\n\n                    $generated_l1_handler_functions$\n                }}\n\n                mod {CONSTRUCTOR_MODULE} {{$extra_uses$\n\n                    $generated_constructor_functions$\n                }}\n            }}\n        \"\n        )\n        .as_str(),\n        HashMap::from([\n            (\n                \"contract_name\".to_string(),\n                RewriteNode::new_trimmed(module_name_ast.as_syntax_node()),\n            ),\n            (\"original_items\".to_string(), RewriteNode::new_modified(kept_original_items)),\n            (\"storage_code\".to_string(), storage_code),\n            (\"event_functions\".to_string(), RewriteNode::new_modified(event_functions)),\n            (\"abi_functions\".to_string(), RewriteNode::new_modified(abi_functions)),\n            (\"abi_events\".to_string(), RewriteNode::new_modified(abi_events)),\n            (\"extra_uses\".to_string(), extra_uses_node),\n            (\n                \"generated_external_functions\".to_string(),\n                RewriteNode::new_modified(generated_external_functions),\n            ),\n            (\n                \"generated_l1_handler_functions\".to_string(),\n                RewriteNode::new_modified(generated_l1_handler_functions),\n            ),\n            (\n                \"generated_constructor_functions\".to_string(),\n                RewriteNode::new_modified(generated_constructor_functions),\n            ),\n        ]),\n    );\n\n    let mut builder = PatchBuilder::new(db);\n    builder.add_modified(generated_contract_mod);\n    PluginResult {\n        code: Some(PluginGeneratedFile {\n            name: \"contract\".into(),\n            content: builder.code,\n            aux_data: DynGeneratedFileAuxData::new(DynPluginAuxData::new(\n                StarkNetContractAuxData {\n                    patches: builder.patches,\n                    contracts: vec![module_name_ast.text(db)],\n                },\n            )),\n        }),\n        diagnostics,\n        remove_original_item: true,\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashMap;\n\nuse cairo_lang_defs::plugin::{\n    DynGeneratedFileAuxData, PluginDiagnostic, PluginGeneratedFile, PluginResult,\n};\nuse cairo_lang_semantic::patcher::{PatchBuilder, RewriteNode};\nuse cairo_lang_semantic::plugin::DynPluginAuxData;\nuse cairo_lang_syntax::node::ast::{self, MaybeTraitBody, OptionReturnTypeClause};\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::helpers::QueryAttrs;\nuse cairo_lang_syntax::node::{Terminal, TypedSyntaxNode};\nuse indoc::formatdoc;\n\nuse super::aux_data::StarkNetABIAuxData;\nuse super::consts::EVENT_ATTR;\nuse super::utils::is_ref_param;\nuse super::ABI_ATTR;\nuse crate::contract::starknet_keccak;\n\n/// If the trait is annotated with ABI_ATTR, generate the relevant dispatcher logic.\npub fn handle_trait(db: &dyn SyntaxGroup, trait_ast: ast::ItemTrait) -> PluginResult {\n    let attrs = trait_ast.attributes(db).elements(db);\n    if !attrs.iter().any(|attr| attr.attr(db).text(db) == ABI_ATTR) {\n        return PluginResult::default();\n    }\n    let body = match trait_ast.body(db) {\n        MaybeTraitBody::Some(body) => body,\n        MaybeTraitBody::None(empty_body) => {\n            return PluginResult {\n                code: None,\n                diagnostics: vec![PluginDiagnostic {\n                    message: \"ABIs without body are not supported.\".to_string(),\n                    stable_ptr: empty_body.stable_ptr().untyped(),\n                }],\n                remove_original_item: false,\n            };\n        }\n    };\n\n    let mut diagnostics = vec![];\n    let mut dispatcher_signatures = vec![];\n    let mut contract_caller_method_impls = vec![];\n    let mut library_caller_method_impls = vec![];\n    let base_name = trait_ast.name(db).text(db);\n    let dispatcher_name = format!(\"{base_name}DispatcherTrait\");\n    let contract_caller_name = format!(\"{base_name}Dispatcher\");\n    let library_caller_name = format!(\"{base_name}LibraryDispatcher\");\n    for item_ast in body.items(db).elements(db) {\n        match item_ast {\n            ast::TraitItem::Function(func) => {\n                // Ignore events.\n                if func.has_attr(db, EVENT_ATTR) {\n                    continue;\n                }\n\n                let declaration = func.declaration(db);\n\n                let mut skip_generation = false;\n                let mut serialization_code = vec![];\n                let signature = declaration.signature(db);\n                for param in signature.parameters(db).elements(db) {\n                    if is_ref_param(db, &param) {\n                        skip_generation = true;\n\n                        diagnostics.push(PluginDiagnostic {\n                            message: \"`ref` parameters are not supported in the ABI of a contract.\"\n                                .to_string(),\n                            stable_ptr: param.modifiers(db).stable_ptr().untyped(),\n                        })\n                    }\n\n                    let param_type = param.type_clause(db).ty(db);\n                    let type_name = &param_type.as_syntax_node().get_text(db);\n                    serialization_code.push(RewriteNode::interpolate_patched(\n                        &formatdoc!(\n                            \"        serde::Serde::<{type_name}>::serialize(ref calldata, \\\n                             $arg_name$);\\n\"\n                        ),\n                        HashMap::from([(\n                            \"arg_name\".to_string(),\n                            RewriteNode::new_trimmed(param.name(db).as_syntax_node()),\n                        )]),\n                    ));\n                }\n\n                if skip_generation {\n                    // TODO(ilya): Consider generating an empty wrapper to avoid:\n                    // Unknown function error.\n                    continue;\n                }\n\n                let ret_decode = match signature.ret_ty(db) {\n                    OptionReturnTypeClause::Empty(_) => \"\".to_string(),\n                    OptionReturnTypeClause::ReturnTypeClause(ty) => {\n                        let ret_type_ast = ty.ty(db);\n                        let type_name = ret_type_ast.as_syntax_node().get_text(db);\n                        format!(\n                            \"\n        option::OptionTrait::expect(\n            serde::Serde::<{type_name}>::deserialize(ref ret_data),\n            'Returned data too short',\n        )\"\n                        )\n                    }\n                };\n                dispatcher_signatures.push(RewriteNode::interpolate_patched(\n                    \"$func_decl$;\",\n                    HashMap::from([(\n                        \"func_decl\".to_string(),\n                        dispatcher_signature(db, &declaration, \"T\"),\n                    )]),\n                ));\n                let entry_point_selector = RewriteNode::Text(format!(\n                    \"0x{:x}\",\n                    starknet_keccak(declaration.name(db).text(db).as_bytes())\n                ));\n                contract_caller_method_impls.push(declaration_method_impl(\n                    dispatcher_signature(db, &declaration, &contract_caller_name),\n                    entry_point_selector.clone(),\n                    \"contract_address\",\n                    \"call_contract_syscall\",\n                    serialization_code.clone(),\n                    ret_decode.clone(),\n                ));\n                library_caller_method_impls.push(declaration_method_impl(\n                    dispatcher_signature(db, &declaration, &library_caller_name),\n                    entry_point_selector,\n                    \"class_hash\",\n                    \"syscalls::library_call_syscall\",\n                    serialization_code,\n                    ret_decode,\n                ));\n            }\n        }\n    }\n\n    let mut builder = PatchBuilder::new(db);\n    builder.add_modified(RewriteNode::interpolate_patched(\n        &formatdoc!(\n            \"trait {dispatcher_name}<T> {{\n            $dispatcher_signatures$\n            }}\n\n            #[derive(Copy, Drop)]\n            struct {contract_caller_name} {{\n                contract_address: starknet::ContractAddress,\n            }}\n\n            impl {contract_caller_name}Impl of {dispatcher_name}::<{contract_caller_name}> {{\n            $contract_caller_method_impls$\n            }}\n\n            #[derive(Copy, Drop)]\n            struct {library_caller_name} {{\n                class_hash: starknet::ClassHash,\n            }}\n\n            impl {library_caller_name}Impl of {dispatcher_name}::<{library_caller_name}> {{\n            $library_caller_method_impls$\n            }}\",\n        ),\n        HashMap::from([\n            (\"dispatcher_signatures\".to_string(), RewriteNode::new_modified(dispatcher_signatures)),\n            (\n                \"contract_caller_method_impls\".to_string(),\n                RewriteNode::new_modified(contract_caller_method_impls),\n            ),\n            (\n                \"library_caller_method_impls\".to_string(),\n                RewriteNode::new_modified(library_caller_method_impls),\n            ),\n        ]),\n    ));\n    PluginResult {\n        code: Some(PluginGeneratedFile {\n            name: dispatcher_name.into(),\n            content: builder.code,\n            aux_data: DynGeneratedFileAuxData::new(DynPluginAuxData::new(StarkNetABIAuxData {\n                patches: builder.patches,\n            })),\n        }),\n        diagnostics,\n        remove_original_item: false,\n    }\n}\n\n/// Returns the method implementation rewrite node for a declaration.\nfn declaration_method_impl(\n    func_declaration: RewriteNode,\n    entry_point_selector: RewriteNode,\n    member: &str,\n    syscall: &str,\n    serialization_code: Vec<RewriteNode>,\n    ret_decode: String,\n) -> RewriteNode {\n    RewriteNode::interpolate_patched(\n        \"$func_decl$ {\n        let mut calldata = array::ArrayTrait::new();\n$serialization_code$\n        let mut ret_data = starknet::SyscallResultTrait::unwrap_syscall(\n            starknet::$syscall$(\n                self.$member$,\n                $entry_point_selector$,\n                array::ArrayTrait::span(@calldata),\n            )\n        );\n$deserialization_code$\n    }\n\",\n        HashMap::from([\n            (\"func_decl\".to_string(), func_declaration),\n            (\"entry_point_selector\".to_string(), entry_point_selector),\n            (\"syscall\".to_string(), RewriteNode::Text(syscall.to_string())),\n            (\"member\".to_string(), RewriteNode::Text(member.to_string())),\n            (\"serialization_code\".to_string(), RewriteNode::new_modified(serialization_code)),\n            (\"deserialization_code\".to_string(), RewriteNode::Text(ret_decode)),\n        ]),\n    )\n}\n\n/// Returns the matching signature for a dispatcher implementation for the given declaration.\nfn dispatcher_signature(\n    db: &dyn SyntaxGroup,\n    declaration: &ast::FunctionDeclaration,\n    self_type_name: &str,\n) -> RewriteNode {\n    let mut func_declaration = RewriteNode::from_ast(declaration);\n    func_declaration\n        .modify_child(db, ast::FunctionDeclaration::INDEX_SIGNATURE)\n        .modify_child(db, ast::FunctionSignature::INDEX_PARAMETERS)\n        .modify(db)\n        .children\n        .as_mut()\n        .unwrap()\n        .splice(\n            0..0,\n            [\n                RewriteNode::Text(format!(\"self: {self_type_name}\")),\n                RewriteNode::Text(\", \".to_string()),\n            ],\n        );\n    func_declaration\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashMap;\n\nuse cairo_lang_defs::plugin::PluginDiagnostic;\nuse cairo_lang_semantic::patcher::RewriteNode;\nuse cairo_lang_syntax::node::ast::{self, FunctionWithBody, OptionReturnTypeClause};\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::helpers::QueryAttrs;\nuse cairo_lang_syntax::node::{Terminal, TypedSyntaxNode};\n\nuse super::consts::RAW_OUTPUT_ATTR;\nuse super::utils::is_ref_param;\n\n/// Generates Cairo code for an entry point wrapper.\npub fn generate_entry_point_wrapper(\n    db: &dyn SyntaxGroup,\n    function: &FunctionWithBody,\n) -> Result<RewriteNode, Vec<PluginDiagnostic>> {\n    let declaration = function.declaration(db);\n    let sig = declaration.signature(db);\n    let params = sig.parameters(db).elements(db);\n    let mut diagnostics = vec![];\n    let mut arg_names = Vec::new();\n    let mut arg_definitions = Vec::new();\n    let mut ref_appends = Vec::new();\n\n    let raw_output = function.has_attr(db, RAW_OUTPUT_ATTR);\n\n    let input_data_short_err = \"'Input too short for arguments'\";\n    for param in params {\n        let arg_name = format!(\"__arg_{}\", param.name(db).text(db));\n        let arg_type_ast = param.type_clause(db).ty(db);\n        let type_name = arg_type_ast.as_syntax_node().get_text_without_trivia(db);\n\n        let is_ref = is_ref_param(db, &param);\n        if raw_output && is_ref {\n            diagnostics.push(PluginDiagnostic {\n                message: format!(\"`{RAW_OUTPUT_ATTR}` functions cannot have `ref` parameters.\"),\n                stable_ptr: param.modifiers(db).stable_ptr().untyped(),\n            });\n        }\n\n        let ref_modifier = if is_ref { \"ref \" } else { \"\" };\n        arg_names.push(format!(\"{ref_modifier}{arg_name}\"));\n        let mut_modifier = if is_ref { \"mut \" } else { \"\" };\n        // TODO(yuval): use panicable version of deserializations when supported.\n        let arg_definition = format!(\n            \"\n            let {mut_modifier}{arg_name} =\n                match serde::Serde::<{type_name}>::deserialize(ref data) {{\n                    Option::Some(x) => x,\n                    Option::None(()) => {{\n                        let mut err_data = array::array_new();\n                        array::array_append(ref err_data, {input_data_short_err});\n                        panic(err_data)\n                    }},\n                }};\"\n        );\n        arg_definitions.push(arg_definition);\n\n        if is_ref {\n            ref_appends.push(RewriteNode::Text(format!(\n                \"\\n            serde::Serde::<{type_name}>::serialize(ref arr, {arg_name});\"\n            )));\n        }\n    }\n    let arg_names_str = arg_names.join(\", \");\n\n    let function_name = RewriteNode::new_trimmed(declaration.name(db).as_syntax_node());\n    let wrapped_name = RewriteNode::interpolate_patched(\n        \"super::$function_name$\",\n        HashMap::from([(\"function_name\".to_string(), function_name.clone())]),\n    );\n\n    let ret_ty = sig.ret_ty(db);\n    let (let_res, append_res, return_ty_is_felt252_span, ret_type_ptr) = match &ret_ty {\n        OptionReturnTypeClause::Empty(type_clause_ast) => {\n            (\"\", \"\".to_string(), false, type_clause_ast.stable_ptr().untyped())\n        }\n        OptionReturnTypeClause::ReturnTypeClause(ty) => {\n            let ret_type_ast = ty.ty(db);\n\n            let return_ty_is_felt252_span = is_felt252_span(db, &ret_type_ast);\n            let ret_type_name = ret_type_ast.as_syntax_node().get_text_without_trivia(db);\n            (\n                \"\\n            let res = \",\n                format!(\"\\n            serde::Serde::<{ret_type_name}>::serialize(ref arr, res);\"),\n                return_ty_is_felt252_span,\n                ret_type_ast.stable_ptr().untyped(),\n            )\n        }\n    };\n\n    if raw_output && !return_ty_is_felt252_span {\n        diagnostics.push(PluginDiagnostic {\n            message: format!(\"`{RAW_OUTPUT_ATTR}` functions must return `Span::<felt252>`.\"),\n            stable_ptr: ret_type_ptr,\n        });\n    }\n\n    if !diagnostics.is_empty() {\n        return Err(diagnostics);\n    }\n\n    let oog_err = \"'Out of gas'\";\n    let input_data_long_err = \"'Input too long for arguments'\";\n\n    let output_handling_string = if raw_output {\n        format!(\"$wrapped_name$({arg_names_str})\")\n    } else {\n        format!(\n            \"{let_res}$wrapped_name$({arg_names_str});\n            let mut arr = array::array_new();\n            // References.$ref_appends$\n            // Result.{append_res}\n            array::ArrayTrait::span(@arr)\"\n        )\n    };\n\n    let output_handling = RewriteNode::interpolate_patched(\n        &output_handling_string,\n        HashMap::from([\n            (\"wrapped_name\".to_string(), wrapped_name),\n            (\"ref_appends\".to_string(), RewriteNode::new_modified(ref_appends)),\n        ]),\n    );\n\n    let arg_definitions = arg_definitions.join(\"\\n\");\n    // TODO(yuval): use panicable version of `withdraw_gas` once inlining is supported.\n    Ok(RewriteNode::interpolate_patched(\n        format!(\n            \"fn $function_name$(mut data: Span::<felt252>) -> Span::<felt252> {{\n            internal::revoke_ap_tracking();\n            match gas::withdraw_gas() {{\n                Option::Some(_) => {{\n                }},\n                Option::None(_) => {{\n                    let mut err_data = array::array_new();\n                    array::array_append(ref err_data, {oog_err});\n                    panic(err_data)\n                }},\n            }}\n            {arg_definitions}\n            if !array::SpanTrait::is_empty(data) {{\n                // Force the inclusion of `System` in the list of implicits.\n                starknet::use_system_implicit();\n\n                let mut err_data = array::array_new();\n                array::array_append(ref err_data, {input_data_long_err});\n                panic(err_data);\n            }}\n            match gas::withdraw_gas_all(get_builtin_costs()) {{\n                Option::Some(_) => {{\n                }},\n                Option::None(_) => {{\n                    let mut err_data = array::array_new();\n                    array::array_append(ref err_data, {oog_err});\n                    panic(err_data)\n                }},\n            }}\n            $output_handling$\n        }}\"\n        )\n        .as_str(),\n        HashMap::from([\n            (\"function_name\".to_string(), function_name),\n            (\"output_handling\".to_string(), output_handling),\n        ]),\n    ))\n}\n\n/// Returns true if type_ast is `Array::<felt252>`.\n/// Does not resolve paths or type aliases.\nfn is_felt252_span(db: &dyn SyntaxGroup, type_ast: &ast::Expr) -> bool {\n    let ast::Expr::Path(type_path) = type_ast else {\n        return false;\n    };\n\n    let type_path_elements = type_path.elements(db);\n    let [ast::PathSegment::WithGenericArgs(path_segment_with_generics)\n        ] = type_path_elements.as_slice() else {\n        return false;\n    };\n\n    if path_segment_with_generics.ident(db).text(db) != \"Span\" {\n        return false;\n    }\n    let args = path_segment_with_generics.generic_args(db).generic_args(db).elements(db);\n    let [ast::GenericArg::Expr(arg_expr)] = args.as_slice() else {\n        return false;\n    };\n    let ast::Expr::Path(arg_path) = arg_expr.value(db) else {\n        return false;\n    };\n\n    let arg_path_elements = arg_path.elements(db);\n    let [ast::PathSegment::Simple(arg_segment)] = arg_path_elements.as_slice() else {\n        return false;\n    };\n\n    arg_segment.ident(db).text(db) == \"felt252\"\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashMap;\n\nuse cairo_lang_defs::plugin::PluginDiagnostic;\nuse cairo_lang_semantic::patcher::RewriteNode;\nuse cairo_lang_syntax::node::ast::{self, OptionReturnTypeClause, OptionWrappedGenericParamList};\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::{Terminal, TypedSyntaxNode};\n\nuse super::utils::is_ref_param;\nuse crate::contract::starknet_keccak;\n\n/// Generates a function to emit an event and the corresponding ABI item.\n/// On success, returns a RewriteNode for the event function and a RewriteNode for the ABI\n/// declaration. On failure returns None. In addition, returns diagnostics.\npub fn handle_event(\n    db: &dyn SyntaxGroup,\n    function_ast: ast::FunctionWithBody,\n) -> (Option<(RewriteNode, RewriteNode)>, Vec<PluginDiagnostic>) {\n    let mut diagnostics = vec![];\n    let declaration = function_ast.declaration(db);\n\n    if let OptionWrappedGenericParamList::WrappedGenericParamList(generic_params) =\n        declaration.generic_params(db)\n    {\n        diagnostics.push(PluginDiagnostic {\n            message: \"Event functions cannot have generic arguments\".to_string(),\n            stable_ptr: generic_params.stable_ptr().untyped(),\n        })\n    }\n\n    let signature = declaration.signature(db);\n    let ret_ty = declaration.signature(db).ret_ty(db);\n    if matches!(ret_ty, OptionReturnTypeClause::ReturnTypeClause(_)) {\n        diagnostics.push(PluginDiagnostic {\n            stable_ptr: ret_ty.stable_ptr().untyped(),\n            message: \"Event functions must not return a value.\".to_string(),\n        });\n    }\n\n    let mut param_serializations = Vec::new();\n    for param in signature.parameters(db).elements(db) {\n        // If we encounter errors with this parameter that don't allow us to serialize it, we skip\n        // the serialization of it in the generated code.\n        let mut skip_param_serialization = false;\n        if is_ref_param(db, &param) {\n            diagnostics.push(PluginDiagnostic {\n                stable_ptr: param.modifiers(db).stable_ptr().untyped(),\n                message: \"`ref` parameters are not supported in contract events.\".to_string(),\n            });\n            skip_param_serialization = true;\n        }\n\n        let param_name = param.name(db);\n        let param_type_ast = param.type_clause(db).ty(db);\n        let type_name = param_type_ast.as_syntax_node().get_text(db);\n        if skip_param_serialization {\n            continue;\n        }\n\n        // TODO(yuval): use panicable version of deserializations when supported.\n        let param_serialization = RewriteNode::interpolate_patched(\n            &format!(\"serde::Serde::<{type_name}>::serialize(ref __data, $param_name$);\\n        \"),\n            HashMap::from([(\n                \"param_name\".to_string(),\n                RewriteNode::new_trimmed(param_name.as_syntax_node()),\n            )]),\n        );\n        param_serializations.push(param_serialization);\n    }\n\n    if !function_ast.body(db).statements(db).elements(db).is_empty() {\n        diagnostics.push(PluginDiagnostic {\n            stable_ptr: function_ast.body(db).statements(db).stable_ptr().untyped(),\n            message: \"Event function body must be empty.\".to_string(),\n        });\n    }\n\n    if !diagnostics.is_empty() {\n        return (None, diagnostics);\n    }\n\n    let name = declaration.name(db).text(db);\n    let event_key = format!(\"0x{:x}\", starknet_keccak(name.as_bytes()));\n\n    (\n        Some((\n            // Event function\n            RewriteNode::interpolate_patched(\n                &format!(\n                    \"\n    $attrs$\n    $declaration$ {{\n        let mut __keys = array::array_new();\n        array::array_append(ref __keys, {event_key});\n        let mut __data = array::array_new();\n        $param_serializations$\n        starknet::syscalls::emit_event_syscall(\n            array::ArrayTrait::span(@__keys),\n            array::ArrayTrait::span(@__data),\n        ).unwrap_syscall()\n    }}\n            \"\n                ),\n                HashMap::from([\n                    // TODO(yuval): All the attributes are currently copied. Remove the #[event]\n                    // attr.\n                    (\n                        \"attrs\".to_string(),\n                        RewriteNode::new_trimmed(function_ast.attributes(db).as_syntax_node()),\n                    ),\n                    (\n                        \"declaration\".to_string(),\n                        RewriteNode::new_trimmed(declaration.as_syntax_node()),\n                    ),\n                    (\n                        \"param_serializations\".to_string(),\n                        RewriteNode::new_modified(param_serializations),\n                    ),\n                ]),\n            ),\n            // ABI event\n            RewriteNode::new_modified(vec![\n                RewriteNode::Text(\"#[event]\\n        \".to_string()),\n                RewriteNode::new_trimmed(function_ast.declaration(db).as_syntax_node()),\n                RewriteNode::Text(\";\\n        \".to_string()),\n            ]),\n        )),\n        diagnostics,\n    )\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "#[cfg(test)]\nmod test;\n\npub mod consts;\nuse std::sync::Arc;\n\nuse cairo_lang_defs::plugin::{MacroPlugin, PluginResult};\nuse cairo_lang_semantic::plugin::{AsDynMacroPlugin, SemanticPlugin};\nuse cairo_lang_syntax::node::ast;\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse consts::*;\n\npub mod aux_data;\nmod contract;\nmod dispatcher;\nmod entry_point;\nmod events;\nmod storage;\nmod utils;\n\nuse contract::handle_mod;\nuse dispatcher::handle_trait;\n\n#[derive(Debug)]\npub struct StarkNetPlugin {}\n\nimpl MacroPlugin for StarkNetPlugin {\n    fn generate_code(&self, db: &dyn SyntaxGroup, item_ast: ast::Item) -> PluginResult {\n        match item_ast {\n            ast::Item::Module(module_ast) => handle_mod(db, module_ast),\n            ast::Item::Trait(trait_ast) => handle_trait(db, trait_ast),\n            // Nothing to do for other items.\n            _ => PluginResult::default(),\n        }\n    }\n}\nimpl AsDynMacroPlugin for StarkNetPlugin {\n    fn as_dyn_macro_plugin<'a>(self: Arc<Self>) -> Arc<dyn MacroPlugin + 'a>\n    where\n        Self: 'a,\n    {\n        self\n    }\n}\nimpl SemanticPlugin for StarkNetPlugin {}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashMap;\n\nuse cairo_lang_defs::plugin::PluginDiagnostic;\nuse cairo_lang_semantic::patcher::RewriteNode;\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::{ast, Terminal, TypedSyntaxNode};\nuse cairo_lang_utils::try_extract_matches;\n\nuse crate::contract::starknet_keccak;\n\n/// Generate getters and setters for the variables in the storage struct.\npub fn handle_storage_struct(\n    db: &dyn SyntaxGroup,\n    struct_ast: ast::ItemStruct,\n    extra_uses_node: &RewriteNode,\n) -> (RewriteNode, Vec<PluginDiagnostic>) {\n    let mut members_code = Vec::new();\n    let mut diagnostics = vec![];\n\n    for member in struct_ast.members(db).elements(db) {\n        let name = member.name(db).text(db);\n        let address = format!(\"0x{:x}\", starknet_keccak(name.as_bytes()));\n        let type_ast = member.type_clause(db).ty(db);\n        match try_extract_mapping_types(db, &type_ast) {\n            Some((key_type_ast, value_type_ast, MappingType::Legacy)) => {\n                members_code.push(RewriteNode::interpolate_patched(\n                    handle_legacy_mapping_storage_var(&address).as_str(),\n                    HashMap::from([\n                        (\n                            \"storage_var_name\".to_string(),\n                            RewriteNode::new_trimmed(member.name(db).as_syntax_node()),\n                        ),\n                        (\"extra_uses\".to_string(), extra_uses_node.clone()),\n                        (\n                            \"key_type\".to_string(),\n                            RewriteNode::new_trimmed(key_type_ast.as_syntax_node()),\n                        ),\n                        (\n                            \"value_type\".to_string(),\n                            RewriteNode::new_trimmed(value_type_ast.as_syntax_node()),\n                        ),\n                    ]),\n                ));\n            }\n            Some((_, _, MappingType::NonLegacy)) => {\n                diagnostics.push(PluginDiagnostic {\n                    message: \"Non `LegacyMap` mapping is not yet supported.\".to_string(),\n                    stable_ptr: type_ast.stable_ptr().untyped(),\n                });\n            }\n            None => {\n                members_code.push(RewriteNode::interpolate_patched(\n                    handle_simple_storage_var(&address).as_str(),\n                    HashMap::from([\n                        (\n                            \"storage_var_name\".to_string(),\n                            RewriteNode::new_trimmed(member.name(db).as_syntax_node()),\n                        ),\n                        (\"extra_uses\".to_string(), extra_uses_node.clone()),\n                        (\n                            \"type_name\".to_string(),\n                            RewriteNode::new_trimmed(type_ast.as_syntax_node()),\n                        ),\n                    ]),\n                ));\n            }\n        }\n    }\n    (RewriteNode::new_modified(members_code), diagnostics)\n}\n\n/// The type of the mapping storage variable.\nenum MappingType {\n    /// Pedersen based.\n    Legacy,\n    /// Poseidon based.\n    NonLegacy,\n}\n\n/// Given a type, if it is of form `Map{Legacy,}::<K, V>`, returns `K` and `V` and the mapping type.\n/// Otherwise, returns None.\nfn try_extract_mapping_types(\n    db: &dyn SyntaxGroup,\n    type_ast: &ast::Expr,\n) -> Option<(ast::GenericArg, ast::GenericArg, MappingType)> {\n    let as_path = try_extract_matches!(type_ast, ast::Expr::Path)?;\n    let [ast::PathSegment::WithGenericArgs(segment)] = &as_path.elements(db)[..] else {\n        return None;\n    };\n    let ty = segment.ident(db).text(db);\n    if ty == \"LegacyMap\" || ty == \"Map\" {\n        let [key_ty, value_ty] = <[ast::GenericArg; 2]>::try_from(\n            segment.generic_args(db).generic_args(db).elements(db),\n        )\n        .ok()?;\n        Some((\n            key_ty,\n            value_ty,\n            if ty == \"LegacyMap\" { MappingType::Legacy } else { MappingType::NonLegacy },\n        ))\n    } else {\n        None\n    }\n}\n\n/// Generate getters and setters skeleton for a non-mapping member in the storage struct.\nfn handle_simple_storage_var(address: &str) -> String {\n    format!(\n        \"\n    mod $storage_var_name$ {{$extra_uses$\n        use starknet::SyscallResultTrait;\n        use starknet::SyscallResultTraitImpl;\n\n        fn address() -> starknet::StorageBaseAddress {{\n            starknet::storage_base_address_const::<{address}>()\n        }}\n        fn read() -> $type_name$ {{\n            // Only address_domain 0 is currently supported.\n            let address_domain = 0_u32;\n            starknet::StorageAccess::<$type_name$>::read(\n                address_domain,\n                address(),\n            ).unwrap_syscall()\n        }}\n        fn write(value: $type_name$) {{\n            // Only address_domain 0 is currently supported.\n            let address_domain = 0_u32;\n            starknet::StorageAccess::<$type_name$>::write(\n                address_domain,\n                address(),\n                value,\n            ).unwrap_syscall()\n        }}\n    }}\"\n    )\n}\n\n/// Generate getters and setters skeleton for a non-mapping member in the storage struct.\nfn handle_legacy_mapping_storage_var(address: &str) -> String {\n    format!(\n        \"\n    mod $storage_var_name$ {{$extra_uses$\n        use starknet::SyscallResultTrait;\n        use starknet::SyscallResultTraitImpl;\n\n        fn address(key: $key_type$) -> starknet::StorageBaseAddress {{\n            starknet::storage_base_address_from_felt252(\n                hash::LegacyHash::<$key_type$>::hash({address}, key))\n        }}\n        fn read(key: $key_type$) -> $value_type$ {{\n            // Only address_domain 0 is currently supported.\n            let address_domain = 0_u32;\n            starknet::StorageAccess::<$value_type$>::read(\n                address_domain,\n                address(key),\n            ).unwrap_syscall()\n        }}\n        fn write(key: $key_type$, value: $value_type$) {{\n            // Only address_domain 0 is currently supported.\n            let address_domain = 0_u32;\n            starknet::StorageAccess::<$value_type$>::write(\n                address_domain,\n                address(key),\n                value,\n            ).unwrap_syscall()\n        }}\n    }}\"\n    )\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_compiler::db::RootDatabase;\nuse cairo_lang_compiler::diagnostics::get_diagnostics_as_string;\nuse cairo_lang_defs::db::DefsGroup;\nuse cairo_lang_defs::plugin::{MacroPlugin, PluginGeneratedFile, PluginResult};\nuse cairo_lang_parser::db::ParserGroup;\nuse cairo_lang_semantic::test_utils::setup_test_module;\nuse cairo_lang_syntax::node::TypedSyntaxNode;\nuse cairo_lang_test_utils::parse_test_file::TestFileRunner;\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\n\nuse crate::db::StarknetRootDatabaseBuilderEx;\nuse crate::plugin::StarkNetPlugin;\n\nstruct ExpandContractTestRunner {\n    db: RootDatabase,\n}\nimpl Default for ExpandContractTestRunner {\n    fn default() -> Self {\n        Self { db: RootDatabase::builder().detect_corelib().with_starknet().build().unwrap() }\n    }\n}\nimpl TestFileRunner for ExpandContractTestRunner {\n    fn run(&mut self, inputs: &OrderedHashMap<String, String>) -> OrderedHashMap<String, String> {\n        let (test_module, _semantic_diagnostics) =\n            setup_test_module(&mut self.db, inputs[\"cairo_code\"].as_str()).split();\n\n        let file_id = self.db.module_main_file(test_module.module_id).unwrap();\n        let syntax_file = self.db.file_syntax(file_id).unwrap();\n\n        let plugin = StarkNetPlugin {};\n        let mut generated_items: Vec<String> = Vec::new();\n\n        for item in syntax_file.items(&self.db).elements(&self.db).into_iter() {\n            let PluginResult { code, diagnostics: _, remove_original_item } =\n                plugin.generate_code(&self.db, item.clone());\n\n            let content = match code {\n                Some(PluginGeneratedFile { content, .. }) => content,\n                None => continue,\n            };\n            if !remove_original_item {\n                generated_items.push(item.as_syntax_node().get_text(&self.db));\n            }\n            generated_items.push(content);\n        }\n\n        OrderedHashMap::from([\n            (\"generated_cairo_code\".into(), generated_items.join(\"\\n\")),\n            (\"expected_diagnostics\".into(), get_diagnostics_as_string(&mut self.db)),\n        ])\n    }\n}\n\ncairo_lang_test_utils::test_file_test_with_runner!(\n    expand_contract,\n    \"src/plugin/plugin_test_data\",\n    {\n        diagnostics: \"diagnostics\",\n        contract: \"contract\",\n        raw_output: \"raw_output\",\n        storage: \"storage\",\n        hello_starknet: \"hello_starknet\",\n        dispatcher: \"dispatcher\",\n        user_defined_types: \"user_defined_types\",\n    },\n    ExpandContractTestRunner\n);\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_syntax::node::ast::{self, Modifier};\nuse cairo_lang_syntax::node::db::SyntaxGroup;\n\n/// Checks if the parameter is defined as a ref parameter.\npub fn is_ref_param(db: &dyn SyntaxGroup, param: &ast::Param) -> bool {\n    let param_modifiers = param.modifiers(db).elements(db);\n    // TODO(yuval): This works only if \"ref\" is the only modifier. If the expansion was at the\n    // semantic level, we could just ask if it's a reference.\n    matches!(param_modifiers[..], [Modifier::Ref(_)])\n}\n\n/// Checks if the parameter is defined as a mut parameter.\npub fn is_mut_param(db: &dyn SyntaxGroup, param: &ast::Param) -> bool {\n    let param_modifiers = param.modifiers(db).elements(db);\n    // TODO(yuval): This works only if \"mut\" is the only modifier. If the expansion was at the\n    // semantic level, we could just ask if it's a reference.\n    matches!(param_modifiers[..], [Modifier::Mut(_)])\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "#[derive(Debug, PartialEq, Eq)]\npub struct VersionId {\n    pub version: String,\n}\n\nimpl VersionId {\n    pub fn current_version_id() -> Self {\n        Self { version: \"0.1.0\".into() }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::fs;\n\nuse anyhow::Context;\nuse cairo_lang_starknet::allowed_libfuncs::{validate_compatible_sierra_version, ListSelector};\nuse cairo_lang_starknet::casm_contract_class::CasmContractClass;\nuse cairo_lang_starknet::contract_class::ContractClass;\nuse clap::Parser;\n\n/// Command line args parser.\n/// Exits with 0/1 if the input is formatted correctly/incorrectly.\n#[derive(Parser, Debug)]\n#[clap(version, verbatim_doc_comment)]\nstruct Args {\n    /// The file to compile\n    file: String,\n    /// The output file name (default: stdout).\n    output: Option<String>,\n    /// The allowed libfuncs list to use (default: most recent audited list).\n    #[arg(long)]\n    allowed_libfuncs_list_name: Option<String>,\n    /// A file of the allowed libfuncs list to use.\n    #[arg(long)]\n    allowed_libfuncs_list_file: Option<String>,\n    /// Add pythonic hints.\n    #[arg(long, default_value_t = false)]\n    add_pythonic_hints: bool,\n}\n\nfn main() -> anyhow::Result<()> {\n    let args = Args::parse();\n    let list_selector =\n        ListSelector::new(args.allowed_libfuncs_list_name, args.allowed_libfuncs_list_file)\n            .expect(\"Both allowed libfunc list name and file were supplied.\");\n    let contract_class: ContractClass = serde_json::from_str(\n        &fs::read_to_string(&args.file)\n            .with_context(|| format!(\"Failed to read {}.\", &args.file))?,\n    )\n    .with_context(|| \"deserialization Failed.\")?;\n    validate_compatible_sierra_version(&contract_class, list_selector)?;\n    let casm_contract =\n        CasmContractClass::from_contract_class(contract_class, args.add_pythonic_hints)\n            .with_context(|| \"Compilation failed.\")?;\n\n    let res = serde_json::to_string_pretty(&casm_contract)\n        .with_context(|| \"Casm contract Serialization failed.\")?;\n\n    match args.output {\n        Some(path) => fs::write(path, res).with_context(|| \"Failed to write casm contract.\")?,\n        None => println!(\"{res}\"),\n    }\n    Ok(())\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::path::PathBuf;\n\nuse cairo_lang_compiler::CompilerConfig;\n\nuse crate::allowed_libfuncs::DEFAULT_EXPERIMENTAL_LIBFUNCS_LIST;\nuse crate::contract_class::compile_path;\n\n/// Returns a path to example contract that matches `name`.\npub fn get_example_file_path(file_name: &str) -> PathBuf {\n    let mut path = PathBuf::from(env!(\"CARGO_MANIFEST_DIR\"));\n    path.extend([\"test_data\", file_name].into_iter());\n    path\n}\n\n/// Returns the compiled test contract, with replaced ids.\npub fn get_test_contract(example_file_name: &str) -> crate::contract_class::ContractClass {\n    let path = get_example_file_path(example_file_name);\n    compile_path(\n        &path,\n        CompilerConfig {\n            replace_ids: true,\n            allowed_libfuncs_list_name: Some(DEFAULT_EXPERIMENTAL_LIBFUNCS_LIST.to_string()),\n            ..CompilerConfig::default()\n        },\n    )\n    .expect(\"compile_path failed\")\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Cairo syntax representation using green-red tree and AST abstraction.\n\npub mod node;\n",
    "metadata": {}
  },
  {
    "pageContent": "// Autogenerated file. To regenerate, please run `cargo run --bin generate-syntax`.\n#![allow(clippy::match_single_binding)]\n#![allow(clippy::too_many_arguments)]\n#![allow(dead_code)]\n#![allow(unused_variables)]\nuse std::ops::Deref;\n\nuse cairo_lang_filesystem::span::TextWidth;\nuse cairo_lang_utils::extract_matches;\nuse smol_str::SmolStr;\n\nuse super::element_list::ElementList;\nuse super::green::GreenNodeDetails;\nuse super::kind::SyntaxKind;\nuse super::{\n    GreenId, GreenNode, SyntaxGroup, SyntaxNode, SyntaxStablePtr, SyntaxStablePtrId, Terminal,\n    Token, TypedSyntaxNode,\n};\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct Trivia(ElementList<Trivium, 1>);\nimpl Deref for Trivia {\n    type Target = ElementList<Trivium, 1>;\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\nimpl Trivia {\n    pub fn new_green(db: &dyn SyntaxGroup, children: Vec<TriviumGreen>) -> TriviaGreen {\n        let width = children.iter().map(|id| db.lookup_intern_green(id.0).width()).sum();\n        TriviaGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::Trivia,\n            details: GreenNodeDetails::Node {\n                children: children.iter().map(|x| x.0).collect(),\n                width,\n            },\n        }))\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TriviaPtr(pub SyntaxStablePtrId);\nimpl TriviaPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TriviaGreen(pub GreenId);\nimpl TypedSyntaxNode for Trivia {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::Trivia);\n    type StablePtr = TriviaPtr;\n    type Green = TriviaGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TriviaGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::Trivia,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        Self(ElementList::new(node))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TriviaPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum Trivium {\n    SingleLineComment(TokenSingleLineComment),\n    Whitespace(TokenWhitespace),\n    Newline(TokenNewline),\n    Skipped(TokenSkipped),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TriviumPtr(pub SyntaxStablePtrId);\nimpl TriviumPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<TokenSingleLineCommentPtr> for TriviumPtr {\n    fn from(value: TokenSingleLineCommentPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TokenWhitespacePtr> for TriviumPtr {\n    fn from(value: TokenWhitespacePtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TokenNewlinePtr> for TriviumPtr {\n    fn from(value: TokenNewlinePtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TokenSkippedPtr> for TriviumPtr {\n    fn from(value: TokenSkippedPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TokenSingleLineCommentGreen> for TriviumGreen {\n    fn from(value: TokenSingleLineCommentGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TokenWhitespaceGreen> for TriviumGreen {\n    fn from(value: TokenWhitespaceGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TokenNewlineGreen> for TriviumGreen {\n    fn from(value: TokenNewlineGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TokenSkippedGreen> for TriviumGreen {\n    fn from(value: TokenSkippedGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TriviumGreen(pub GreenId);\nimpl TypedSyntaxNode for Trivium {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = TriviumPtr;\n    type Green = TriviumGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::TokenSingleLineComment => {\n                Trivium::SingleLineComment(TokenSingleLineComment::from_syntax_node(db, node))\n            }\n            SyntaxKind::TokenWhitespace => {\n                Trivium::Whitespace(TokenWhitespace::from_syntax_node(db, node))\n            }\n            SyntaxKind::TokenNewline => Trivium::Newline(TokenNewline::from_syntax_node(db, node)),\n            SyntaxKind::TokenSkipped => Trivium::Skipped(TokenSkipped::from_syntax_node(db, node)),\n            _ => panic!(\"Unexpected syntax kind {:?} when constructing {}.\", kind, \"Trivium\"),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            Trivium::SingleLineComment(x) => x.as_syntax_node(),\n            Trivium::Whitespace(x) => x.as_syntax_node(),\n            Trivium::Newline(x) => x.as_syntax_node(),\n            Trivium::Skipped(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TriviumPtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum Expr {\n    Path(ExprPath),\n    Literal(TerminalLiteralNumber),\n    ShortString(TerminalShortString),\n    False(TerminalFalse),\n    True(TerminalTrue),\n    Parenthesized(ExprParenthesized),\n    Unary(ExprUnary),\n    Binary(ExprBinary),\n    Tuple(ExprTuple),\n    FunctionCall(ExprFunctionCall),\n    StructCtorCall(ExprStructCtorCall),\n    Block(ExprBlock),\n    Match(ExprMatch),\n    If(ExprIf),\n    ErrorPropagate(ExprErrorPropagate),\n    FieldInitShorthand(ExprFieldInitShorthand),\n    Indexed(ExprIndexed),\n    Missing(ExprMissing),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprPtr(pub SyntaxStablePtrId);\nimpl ExprPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<ExprPathPtr> for ExprPtr {\n    fn from(value: ExprPathPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalLiteralNumberPtr> for ExprPtr {\n    fn from(value: TerminalLiteralNumberPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalShortStringPtr> for ExprPtr {\n    fn from(value: TerminalShortStringPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalFalsePtr> for ExprPtr {\n    fn from(value: TerminalFalsePtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalTruePtr> for ExprPtr {\n    fn from(value: TerminalTruePtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprParenthesizedPtr> for ExprPtr {\n    fn from(value: ExprParenthesizedPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprUnaryPtr> for ExprPtr {\n    fn from(value: ExprUnaryPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprBinaryPtr> for ExprPtr {\n    fn from(value: ExprBinaryPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprTuplePtr> for ExprPtr {\n    fn from(value: ExprTuplePtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprFunctionCallPtr> for ExprPtr {\n    fn from(value: ExprFunctionCallPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprStructCtorCallPtr> for ExprPtr {\n    fn from(value: ExprStructCtorCallPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprBlockPtr> for ExprPtr {\n    fn from(value: ExprBlockPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprMatchPtr> for ExprPtr {\n    fn from(value: ExprMatchPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprIfPtr> for ExprPtr {\n    fn from(value: ExprIfPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprErrorPropagatePtr> for ExprPtr {\n    fn from(value: ExprErrorPropagatePtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprFieldInitShorthandPtr> for ExprPtr {\n    fn from(value: ExprFieldInitShorthandPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprIndexedPtr> for ExprPtr {\n    fn from(value: ExprIndexedPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprMissingPtr> for ExprPtr {\n    fn from(value: ExprMissingPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprPathGreen> for ExprGreen {\n    fn from(value: ExprPathGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalLiteralNumberGreen> for ExprGreen {\n    fn from(value: TerminalLiteralNumberGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalShortStringGreen> for ExprGreen {\n    fn from(value: TerminalShortStringGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalFalseGreen> for ExprGreen {\n    fn from(value: TerminalFalseGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalTrueGreen> for ExprGreen {\n    fn from(value: TerminalTrueGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprParenthesizedGreen> for ExprGreen {\n    fn from(value: ExprParenthesizedGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprUnaryGreen> for ExprGreen {\n    fn from(value: ExprUnaryGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprBinaryGreen> for ExprGreen {\n    fn from(value: ExprBinaryGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprTupleGreen> for ExprGreen {\n    fn from(value: ExprTupleGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprFunctionCallGreen> for ExprGreen {\n    fn from(value: ExprFunctionCallGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprStructCtorCallGreen> for ExprGreen {\n    fn from(value: ExprStructCtorCallGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprBlockGreen> for ExprGreen {\n    fn from(value: ExprBlockGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprMatchGreen> for ExprGreen {\n    fn from(value: ExprMatchGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprIfGreen> for ExprGreen {\n    fn from(value: ExprIfGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprErrorPropagateGreen> for ExprGreen {\n    fn from(value: ExprErrorPropagateGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprFieldInitShorthandGreen> for ExprGreen {\n    fn from(value: ExprFieldInitShorthandGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprIndexedGreen> for ExprGreen {\n    fn from(value: ExprIndexedGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprMissingGreen> for ExprGreen {\n    fn from(value: ExprMissingGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprGreen(pub GreenId);\nimpl TypedSyntaxNode for Expr {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = ExprPtr;\n    type Green = ExprGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ExprGreen(ExprMissing::missing(db).0)\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::ExprPath => Expr::Path(ExprPath::from_syntax_node(db, node)),\n            SyntaxKind::TerminalLiteralNumber => {\n                Expr::Literal(TerminalLiteralNumber::from_syntax_node(db, node))\n            }\n            SyntaxKind::TerminalShortString => {\n                Expr::ShortString(TerminalShortString::from_syntax_node(db, node))\n            }\n            SyntaxKind::TerminalFalse => Expr::False(TerminalFalse::from_syntax_node(db, node)),\n            SyntaxKind::TerminalTrue => Expr::True(TerminalTrue::from_syntax_node(db, node)),\n            SyntaxKind::ExprParenthesized => {\n                Expr::Parenthesized(ExprParenthesized::from_syntax_node(db, node))\n            }\n            SyntaxKind::ExprUnary => Expr::Unary(ExprUnary::from_syntax_node(db, node)),\n            SyntaxKind::ExprBinary => Expr::Binary(ExprBinary::from_syntax_node(db, node)),\n            SyntaxKind::ExprTuple => Expr::Tuple(ExprTuple::from_syntax_node(db, node)),\n            SyntaxKind::ExprFunctionCall => {\n                Expr::FunctionCall(ExprFunctionCall::from_syntax_node(db, node))\n            }\n            SyntaxKind::ExprStructCtorCall => {\n                Expr::StructCtorCall(ExprStructCtorCall::from_syntax_node(db, node))\n            }\n            SyntaxKind::ExprBlock => Expr::Block(ExprBlock::from_syntax_node(db, node)),\n            SyntaxKind::ExprMatch => Expr::Match(ExprMatch::from_syntax_node(db, node)),\n            SyntaxKind::ExprIf => Expr::If(ExprIf::from_syntax_node(db, node)),\n            SyntaxKind::ExprErrorPropagate => {\n                Expr::ErrorPropagate(ExprErrorPropagate::from_syntax_node(db, node))\n            }\n            SyntaxKind::ExprFieldInitShorthand => {\n                Expr::FieldInitShorthand(ExprFieldInitShorthand::from_syntax_node(db, node))\n            }\n            SyntaxKind::ExprIndexed => Expr::Indexed(ExprIndexed::from_syntax_node(db, node)),\n            SyntaxKind::ExprMissing => Expr::Missing(ExprMissing::from_syntax_node(db, node)),\n            _ => panic!(\"Unexpected syntax kind {:?} when constructing {}.\", kind, \"Expr\"),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            Expr::Path(x) => x.as_syntax_node(),\n            Expr::Literal(x) => x.as_syntax_node(),\n            Expr::ShortString(x) => x.as_syntax_node(),\n            Expr::False(x) => x.as_syntax_node(),\n            Expr::True(x) => x.as_syntax_node(),\n            Expr::Parenthesized(x) => x.as_syntax_node(),\n            Expr::Unary(x) => x.as_syntax_node(),\n            Expr::Binary(x) => x.as_syntax_node(),\n            Expr::Tuple(x) => x.as_syntax_node(),\n            Expr::FunctionCall(x) => x.as_syntax_node(),\n            Expr::StructCtorCall(x) => x.as_syntax_node(),\n            Expr::Block(x) => x.as_syntax_node(),\n            Expr::Match(x) => x.as_syntax_node(),\n            Expr::If(x) => x.as_syntax_node(),\n            Expr::ErrorPropagate(x) => x.as_syntax_node(),\n            Expr::FieldInitShorthand(x) => x.as_syntax_node(),\n            Expr::Indexed(x) => x.as_syntax_node(),\n            Expr::Missing(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ExprPtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ExprList(ElementList<Expr, 2>);\nimpl Deref for ExprList {\n    type Target = ElementList<Expr, 2>;\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\nimpl ExprList {\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        children: Vec<ExprListElementOrSeparatorGreen>,\n    ) -> ExprListGreen {\n        let width = children.iter().map(|id| db.lookup_intern_green(id.id()).width()).sum();\n        ExprListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprList,\n            details: GreenNodeDetails::Node {\n                children: children.iter().map(|x| x.id()).collect(),\n                width,\n            },\n        }))\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprListPtr(pub SyntaxStablePtrId);\nimpl ExprListPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub enum ExprListElementOrSeparatorGreen {\n    Separator(TerminalCommaGreen),\n    Element(ExprGreen),\n}\nimpl From<TerminalCommaGreen> for ExprListElementOrSeparatorGreen {\n    fn from(value: TerminalCommaGreen) -> Self {\n        ExprListElementOrSeparatorGreen::Separator(value)\n    }\n}\nimpl From<ExprGreen> for ExprListElementOrSeparatorGreen {\n    fn from(value: ExprGreen) -> Self {\n        ExprListElementOrSeparatorGreen::Element(value)\n    }\n}\nimpl ExprListElementOrSeparatorGreen {\n    fn id(&self) -> GreenId {\n        match self {\n            ExprListElementOrSeparatorGreen::Separator(green) => green.0,\n            ExprListElementOrSeparatorGreen::Element(green) => green.0,\n        }\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprListGreen(pub GreenId);\nimpl TypedSyntaxNode for ExprList {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ExprList);\n    type StablePtr = ExprListPtr;\n    type Green = ExprListGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ExprListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprList,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        Self(ElementList::new(node))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ExprListPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ArgNameClause {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ArgNameClause {\n    pub const INDEX_NAME: usize = 0;\n    pub const INDEX_COLON: usize = 1;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        name: TerminalIdentifierGreen,\n        colon: TerminalColonGreen,\n    ) -> ArgNameClauseGreen {\n        let children: Vec<GreenId> = vec![name.0, colon.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ArgNameClauseGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ArgNameClause,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ArgNameClause {\n    pub fn name(&self, db: &dyn SyntaxGroup) -> TerminalIdentifier {\n        TerminalIdentifier::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn colon(&self, db: &dyn SyntaxGroup) -> TerminalColon {\n        TerminalColon::from_syntax_node(db, self.children[1].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ArgNameClausePtr(pub SyntaxStablePtrId);\nimpl ArgNameClausePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ArgNameClauseGreen(pub GreenId);\nimpl TypedSyntaxNode for ArgNameClause {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ArgNameClause);\n    type StablePtr = ArgNameClausePtr;\n    type Green = ArgNameClauseGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ArgNameClauseGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ArgNameClause,\n            details: GreenNodeDetails::Node {\n                children: vec![TerminalIdentifier::missing(db).0, TerminalColon::missing(db).0],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ArgNameClause,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ArgNameClause\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ArgNameClausePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum OptionArgNameClause {\n    Empty(OptionArgNameClauseEmpty),\n    ArgNameClause(ArgNameClause),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionArgNameClausePtr(pub SyntaxStablePtrId);\nimpl OptionArgNameClausePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<OptionArgNameClauseEmptyPtr> for OptionArgNameClausePtr {\n    fn from(value: OptionArgNameClauseEmptyPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ArgNameClausePtr> for OptionArgNameClausePtr {\n    fn from(value: ArgNameClausePtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<OptionArgNameClauseEmptyGreen> for OptionArgNameClauseGreen {\n    fn from(value: OptionArgNameClauseEmptyGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ArgNameClauseGreen> for OptionArgNameClauseGreen {\n    fn from(value: ArgNameClauseGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionArgNameClauseGreen(pub GreenId);\nimpl TypedSyntaxNode for OptionArgNameClause {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = OptionArgNameClausePtr;\n    type Green = OptionArgNameClauseGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::OptionArgNameClauseEmpty => {\n                OptionArgNameClause::Empty(OptionArgNameClauseEmpty::from_syntax_node(db, node))\n            }\n            SyntaxKind::ArgNameClause => {\n                OptionArgNameClause::ArgNameClause(ArgNameClause::from_syntax_node(db, node))\n            }\n            _ => panic!(\n                \"Unexpected syntax kind {:?} when constructing {}.\",\n                kind, \"OptionArgNameClause\"\n            ),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            OptionArgNameClause::Empty(x) => x.as_syntax_node(),\n            OptionArgNameClause::ArgNameClause(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        OptionArgNameClausePtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct OptionArgNameClauseEmpty {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl OptionArgNameClauseEmpty {\n    pub fn new_green(db: &dyn SyntaxGroup) -> OptionArgNameClauseEmptyGreen {\n        let children: Vec<GreenId> = vec![];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        OptionArgNameClauseEmptyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::OptionArgNameClauseEmpty,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl OptionArgNameClauseEmpty {}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionArgNameClauseEmptyPtr(pub SyntaxStablePtrId);\nimpl OptionArgNameClauseEmptyPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionArgNameClauseEmptyGreen(pub GreenId);\nimpl TypedSyntaxNode for OptionArgNameClauseEmpty {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::OptionArgNameClauseEmpty);\n    type StablePtr = OptionArgNameClauseEmptyPtr;\n    type Green = OptionArgNameClauseEmptyGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        OptionArgNameClauseEmptyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::OptionArgNameClauseEmpty,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::OptionArgNameClauseEmpty,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::OptionArgNameClauseEmpty\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        OptionArgNameClauseEmptyPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct Arg {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Arg {\n    pub const INDEX_MODIFIERS: usize = 0;\n    pub const INDEX_ARG_CLAUSE: usize = 1;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        modifiers: ModifierListGreen,\n        arg_clause: ArgClauseGreen,\n    ) -> ArgGreen {\n        let children: Vec<GreenId> = vec![modifiers.0, arg_clause.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ArgGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::Arg,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl Arg {\n    pub fn modifiers(&self, db: &dyn SyntaxGroup) -> ModifierList {\n        ModifierList::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn arg_clause(&self, db: &dyn SyntaxGroup) -> ArgClause {\n        ArgClause::from_syntax_node(db, self.children[1].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ArgPtr(pub SyntaxStablePtrId);\nimpl ArgPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ArgGreen(pub GreenId);\nimpl TypedSyntaxNode for Arg {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::Arg);\n    type StablePtr = ArgPtr;\n    type Green = ArgGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ArgGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::Arg,\n            details: GreenNodeDetails::Node {\n                children: vec![ModifierList::missing(db).0, ArgClause::missing(db).0],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::Arg,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::Arg\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ArgPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum ArgClause {\n    Unnamed(ArgClauseUnnamed),\n    Named(ArgClauseNamed),\n    FieldInitShorthand(ArgClauseFieldInitShorthand),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ArgClausePtr(pub SyntaxStablePtrId);\nimpl ArgClausePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<ArgClauseUnnamedPtr> for ArgClausePtr {\n    fn from(value: ArgClauseUnnamedPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ArgClauseNamedPtr> for ArgClausePtr {\n    fn from(value: ArgClauseNamedPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ArgClauseFieldInitShorthandPtr> for ArgClausePtr {\n    fn from(value: ArgClauseFieldInitShorthandPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ArgClauseUnnamedGreen> for ArgClauseGreen {\n    fn from(value: ArgClauseUnnamedGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ArgClauseNamedGreen> for ArgClauseGreen {\n    fn from(value: ArgClauseNamedGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ArgClauseFieldInitShorthandGreen> for ArgClauseGreen {\n    fn from(value: ArgClauseFieldInitShorthandGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ArgClauseGreen(pub GreenId);\nimpl TypedSyntaxNode for ArgClause {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = ArgClausePtr;\n    type Green = ArgClauseGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::ArgClauseUnnamed => {\n                ArgClause::Unnamed(ArgClauseUnnamed::from_syntax_node(db, node))\n            }\n            SyntaxKind::ArgClauseNamed => {\n                ArgClause::Named(ArgClauseNamed::from_syntax_node(db, node))\n            }\n            SyntaxKind::ArgClauseFieldInitShorthand => ArgClause::FieldInitShorthand(\n                ArgClauseFieldInitShorthand::from_syntax_node(db, node),\n            ),\n            _ => panic!(\"Unexpected syntax kind {:?} when constructing {}.\", kind, \"ArgClause\"),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            ArgClause::Unnamed(x) => x.as_syntax_node(),\n            ArgClause::Named(x) => x.as_syntax_node(),\n            ArgClause::FieldInitShorthand(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ArgClausePtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ArgClauseNamed {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ArgClauseNamed {\n    pub const INDEX_NAME: usize = 0;\n    pub const INDEX_COLON: usize = 1;\n    pub const INDEX_VALUE: usize = 2;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        name: TerminalIdentifierGreen,\n        colon: TerminalColonGreen,\n        value: ExprGreen,\n    ) -> ArgClauseNamedGreen {\n        let children: Vec<GreenId> = vec![name.0, colon.0, value.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ArgClauseNamedGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ArgClauseNamed,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ArgClauseNamed {\n    pub fn name(&self, db: &dyn SyntaxGroup) -> TerminalIdentifier {\n        TerminalIdentifier::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn colon(&self, db: &dyn SyntaxGroup) -> TerminalColon {\n        TerminalColon::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn value(&self, db: &dyn SyntaxGroup) -> Expr {\n        Expr::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ArgClauseNamedPtr(pub SyntaxStablePtrId);\nimpl ArgClauseNamedPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ArgClauseNamedGreen(pub GreenId);\nimpl TypedSyntaxNode for ArgClauseNamed {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ArgClauseNamed);\n    type StablePtr = ArgClauseNamedPtr;\n    type Green = ArgClauseNamedGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ArgClauseNamedGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ArgClauseNamed,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    TerminalIdentifier::missing(db).0,\n                    TerminalColon::missing(db).0,\n                    Expr::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ArgClauseNamed,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ArgClauseNamed\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ArgClauseNamedPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ArgClauseUnnamed {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ArgClauseUnnamed {\n    pub const INDEX_VALUE: usize = 0;\n    pub fn new_green(db: &dyn SyntaxGroup, value: ExprGreen) -> ArgClauseUnnamedGreen {\n        let children: Vec<GreenId> = vec![value.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ArgClauseUnnamedGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ArgClauseUnnamed,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ArgClauseUnnamed {\n    pub fn value(&self, db: &dyn SyntaxGroup) -> Expr {\n        Expr::from_syntax_node(db, self.children[0].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ArgClauseUnnamedPtr(pub SyntaxStablePtrId);\nimpl ArgClauseUnnamedPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ArgClauseUnnamedGreen(pub GreenId);\nimpl TypedSyntaxNode for ArgClauseUnnamed {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ArgClauseUnnamed);\n    type StablePtr = ArgClauseUnnamedPtr;\n    type Green = ArgClauseUnnamedGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ArgClauseUnnamedGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ArgClauseUnnamed,\n            details: GreenNodeDetails::Node {\n                children: vec![Expr::missing(db).0],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ArgClauseUnnamed,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ArgClauseUnnamed\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ArgClauseUnnamedPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ArgClauseFieldInitShorthand {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ArgClauseFieldInitShorthand {\n    pub const INDEX_COLON: usize = 0;\n    pub const INDEX_NAME: usize = 1;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        colon: TerminalColonGreen,\n        name: ExprFieldInitShorthandGreen,\n    ) -> ArgClauseFieldInitShorthandGreen {\n        let children: Vec<GreenId> = vec![colon.0, name.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ArgClauseFieldInitShorthandGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ArgClauseFieldInitShorthand,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ArgClauseFieldInitShorthand {\n    pub fn colon(&self, db: &dyn SyntaxGroup) -> TerminalColon {\n        TerminalColon::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn name(&self, db: &dyn SyntaxGroup) -> ExprFieldInitShorthand {\n        ExprFieldInitShorthand::from_syntax_node(db, self.children[1].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ArgClauseFieldInitShorthandPtr(pub SyntaxStablePtrId);\nimpl ArgClauseFieldInitShorthandPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ArgClauseFieldInitShorthandGreen(pub GreenId);\nimpl TypedSyntaxNode for ArgClauseFieldInitShorthand {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ArgClauseFieldInitShorthand);\n    type StablePtr = ArgClauseFieldInitShorthandPtr;\n    type Green = ArgClauseFieldInitShorthandGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ArgClauseFieldInitShorthandGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ArgClauseFieldInitShorthand,\n            details: GreenNodeDetails::Node {\n                children: vec![TerminalColon::missing(db).0, ExprFieldInitShorthand::missing(db).0],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ArgClauseFieldInitShorthand,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ArgClauseFieldInitShorthand\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ArgClauseFieldInitShorthandPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ExprFieldInitShorthand {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ExprFieldInitShorthand {\n    pub const INDEX_NAME: usize = 0;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        name: TerminalIdentifierGreen,\n    ) -> ExprFieldInitShorthandGreen {\n        let children: Vec<GreenId> = vec![name.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ExprFieldInitShorthandGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprFieldInitShorthand,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ExprFieldInitShorthand {\n    pub fn name(&self, db: &dyn SyntaxGroup) -> TerminalIdentifier {\n        TerminalIdentifier::from_syntax_node(db, self.children[0].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprFieldInitShorthandPtr(pub SyntaxStablePtrId);\nimpl ExprFieldInitShorthandPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprFieldInitShorthandGreen(pub GreenId);\nimpl TypedSyntaxNode for ExprFieldInitShorthand {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ExprFieldInitShorthand);\n    type StablePtr = ExprFieldInitShorthandPtr;\n    type Green = ExprFieldInitShorthandGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ExprFieldInitShorthandGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprFieldInitShorthand,\n            details: GreenNodeDetails::Node {\n                children: vec![TerminalIdentifier::missing(db).0],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ExprFieldInitShorthand,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ExprFieldInitShorthand\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ExprFieldInitShorthandPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ArgList(ElementList<Arg, 2>);\nimpl Deref for ArgList {\n    type Target = ElementList<Arg, 2>;\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\nimpl ArgList {\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        children: Vec<ArgListElementOrSeparatorGreen>,\n    ) -> ArgListGreen {\n        let width = children.iter().map(|id| db.lookup_intern_green(id.id()).width()).sum();\n        ArgListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ArgList,\n            details: GreenNodeDetails::Node {\n                children: children.iter().map(|x| x.id()).collect(),\n                width,\n            },\n        }))\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ArgListPtr(pub SyntaxStablePtrId);\nimpl ArgListPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub enum ArgListElementOrSeparatorGreen {\n    Separator(TerminalCommaGreen),\n    Element(ArgGreen),\n}\nimpl From<TerminalCommaGreen> for ArgListElementOrSeparatorGreen {\n    fn from(value: TerminalCommaGreen) -> Self {\n        ArgListElementOrSeparatorGreen::Separator(value)\n    }\n}\nimpl From<ArgGreen> for ArgListElementOrSeparatorGreen {\n    fn from(value: ArgGreen) -> Self {\n        ArgListElementOrSeparatorGreen::Element(value)\n    }\n}\nimpl ArgListElementOrSeparatorGreen {\n    fn id(&self) -> GreenId {\n        match self {\n            ArgListElementOrSeparatorGreen::Separator(green) => green.0,\n            ArgListElementOrSeparatorGreen::Element(green) => green.0,\n        }\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ArgListGreen(pub GreenId);\nimpl TypedSyntaxNode for ArgList {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ArgList);\n    type StablePtr = ArgListPtr;\n    type Green = ArgListGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ArgListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ArgList,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        Self(ElementList::new(node))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ArgListPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ExprMissing {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ExprMissing {\n    pub fn new_green(db: &dyn SyntaxGroup) -> ExprMissingGreen {\n        let children: Vec<GreenId> = vec![];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ExprMissingGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprMissing,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ExprMissing {}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprMissingPtr(pub SyntaxStablePtrId);\nimpl ExprMissingPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprMissingGreen(pub GreenId);\nimpl TypedSyntaxNode for ExprMissing {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ExprMissing);\n    type StablePtr = ExprMissingPtr;\n    type Green = ExprMissingGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ExprMissingGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprMissing,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ExprMissing,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ExprMissing\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ExprMissingPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum PathSegment {\n    WithGenericArgs(PathSegmentWithGenericArgs),\n    Simple(PathSegmentSimple),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct PathSegmentPtr(pub SyntaxStablePtrId);\nimpl PathSegmentPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<PathSegmentWithGenericArgsPtr> for PathSegmentPtr {\n    fn from(value: PathSegmentWithGenericArgsPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<PathSegmentSimplePtr> for PathSegmentPtr {\n    fn from(value: PathSegmentSimplePtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<PathSegmentWithGenericArgsGreen> for PathSegmentGreen {\n    fn from(value: PathSegmentWithGenericArgsGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<PathSegmentSimpleGreen> for PathSegmentGreen {\n    fn from(value: PathSegmentSimpleGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct PathSegmentGreen(pub GreenId);\nimpl TypedSyntaxNode for PathSegment {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = PathSegmentPtr;\n    type Green = PathSegmentGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        PathSegmentGreen(PathSegmentSimple::missing(db).0)\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::PathSegmentWithGenericArgs => {\n                PathSegment::WithGenericArgs(PathSegmentWithGenericArgs::from_syntax_node(db, node))\n            }\n            SyntaxKind::PathSegmentSimple => {\n                PathSegment::Simple(PathSegmentSimple::from_syntax_node(db, node))\n            }\n            _ => panic!(\"Unexpected syntax kind {:?} when constructing {}.\", kind, \"PathSegment\"),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            PathSegment::WithGenericArgs(x) => x.as_syntax_node(),\n            PathSegment::Simple(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        PathSegmentPtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct PathSegmentSimple {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl PathSegmentSimple {\n    pub const INDEX_IDENT: usize = 0;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        ident: TerminalIdentifierGreen,\n    ) -> PathSegmentSimpleGreen {\n        let children: Vec<GreenId> = vec![ident.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        PathSegmentSimpleGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::PathSegmentSimple,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl PathSegmentSimple {\n    pub fn ident(&self, db: &dyn SyntaxGroup) -> TerminalIdentifier {\n        TerminalIdentifier::from_syntax_node(db, self.children[0].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct PathSegmentSimplePtr(pub SyntaxStablePtrId);\nimpl PathSegmentSimplePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct PathSegmentSimpleGreen(pub GreenId);\nimpl TypedSyntaxNode for PathSegmentSimple {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::PathSegmentSimple);\n    type StablePtr = PathSegmentSimplePtr;\n    type Green = PathSegmentSimpleGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        PathSegmentSimpleGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::PathSegmentSimple,\n            details: GreenNodeDetails::Node {\n                children: vec![TerminalIdentifier::missing(db).0],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::PathSegmentSimple,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::PathSegmentSimple\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        PathSegmentSimplePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum OptionTerminalColonColon {\n    Empty(OptionTerminalColonColonEmpty),\n    TerminalColonColon(TerminalColonColon),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionTerminalColonColonPtr(pub SyntaxStablePtrId);\nimpl OptionTerminalColonColonPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<OptionTerminalColonColonEmptyPtr> for OptionTerminalColonColonPtr {\n    fn from(value: OptionTerminalColonColonEmptyPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalColonColonPtr> for OptionTerminalColonColonPtr {\n    fn from(value: TerminalColonColonPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<OptionTerminalColonColonEmptyGreen> for OptionTerminalColonColonGreen {\n    fn from(value: OptionTerminalColonColonEmptyGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalColonColonGreen> for OptionTerminalColonColonGreen {\n    fn from(value: TerminalColonColonGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionTerminalColonColonGreen(pub GreenId);\nimpl TypedSyntaxNode for OptionTerminalColonColon {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = OptionTerminalColonColonPtr;\n    type Green = OptionTerminalColonColonGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::OptionTerminalColonColonEmpty => OptionTerminalColonColon::Empty(\n                OptionTerminalColonColonEmpty::from_syntax_node(db, node),\n            ),\n            SyntaxKind::TerminalColonColon => OptionTerminalColonColon::TerminalColonColon(\n                TerminalColonColon::from_syntax_node(db, node),\n            ),\n            _ => panic!(\n                \"Unexpected syntax kind {:?} when constructing {}.\",\n                kind, \"OptionTerminalColonColon\"\n            ),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            OptionTerminalColonColon::Empty(x) => x.as_syntax_node(),\n            OptionTerminalColonColon::TerminalColonColon(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        OptionTerminalColonColonPtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct OptionTerminalColonColonEmpty {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl OptionTerminalColonColonEmpty {\n    pub fn new_green(db: &dyn SyntaxGroup) -> OptionTerminalColonColonEmptyGreen {\n        let children: Vec<GreenId> = vec![];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        OptionTerminalColonColonEmptyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::OptionTerminalColonColonEmpty,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl OptionTerminalColonColonEmpty {}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionTerminalColonColonEmptyPtr(pub SyntaxStablePtrId);\nimpl OptionTerminalColonColonEmptyPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionTerminalColonColonEmptyGreen(pub GreenId);\nimpl TypedSyntaxNode for OptionTerminalColonColonEmpty {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::OptionTerminalColonColonEmpty);\n    type StablePtr = OptionTerminalColonColonEmptyPtr;\n    type Green = OptionTerminalColonColonEmptyGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        OptionTerminalColonColonEmptyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::OptionTerminalColonColonEmpty,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::OptionTerminalColonColonEmpty,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::OptionTerminalColonColonEmpty\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        OptionTerminalColonColonEmptyPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct PathSegmentWithGenericArgs {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl PathSegmentWithGenericArgs {\n    pub const INDEX_IDENT: usize = 0;\n    pub const INDEX_SEPARATOR: usize = 1;\n    pub const INDEX_GENERIC_ARGS: usize = 2;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        ident: TerminalIdentifierGreen,\n        separator: OptionTerminalColonColonGreen,\n        generic_args: GenericArgsGreen,\n    ) -> PathSegmentWithGenericArgsGreen {\n        let children: Vec<GreenId> = vec![ident.0, separator.0, generic_args.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        PathSegmentWithGenericArgsGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::PathSegmentWithGenericArgs,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl PathSegmentWithGenericArgs {\n    pub fn ident(&self, db: &dyn SyntaxGroup) -> TerminalIdentifier {\n        TerminalIdentifier::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn separator(&self, db: &dyn SyntaxGroup) -> OptionTerminalColonColon {\n        OptionTerminalColonColon::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn generic_args(&self, db: &dyn SyntaxGroup) -> GenericArgs {\n        GenericArgs::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct PathSegmentWithGenericArgsPtr(pub SyntaxStablePtrId);\nimpl PathSegmentWithGenericArgsPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct PathSegmentWithGenericArgsGreen(pub GreenId);\nimpl TypedSyntaxNode for PathSegmentWithGenericArgs {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::PathSegmentWithGenericArgs);\n    type StablePtr = PathSegmentWithGenericArgsPtr;\n    type Green = PathSegmentWithGenericArgsGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        PathSegmentWithGenericArgsGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::PathSegmentWithGenericArgs,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    TerminalIdentifier::missing(db).0,\n                    OptionTerminalColonColon::missing(db).0,\n                    GenericArgs::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::PathSegmentWithGenericArgs,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::PathSegmentWithGenericArgs\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        PathSegmentWithGenericArgsPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ExprPath(ElementList<PathSegment, 2>);\nimpl Deref for ExprPath {\n    type Target = ElementList<PathSegment, 2>;\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\nimpl ExprPath {\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        children: Vec<ExprPathElementOrSeparatorGreen>,\n    ) -> ExprPathGreen {\n        let width = children.iter().map(|id| db.lookup_intern_green(id.id()).width()).sum();\n        ExprPathGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprPath,\n            details: GreenNodeDetails::Node {\n                children: children.iter().map(|x| x.id()).collect(),\n                width,\n            },\n        }))\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprPathPtr(pub SyntaxStablePtrId);\nimpl ExprPathPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub enum ExprPathElementOrSeparatorGreen {\n    Separator(TerminalColonColonGreen),\n    Element(PathSegmentGreen),\n}\nimpl From<TerminalColonColonGreen> for ExprPathElementOrSeparatorGreen {\n    fn from(value: TerminalColonColonGreen) -> Self {\n        ExprPathElementOrSeparatorGreen::Separator(value)\n    }\n}\nimpl From<PathSegmentGreen> for ExprPathElementOrSeparatorGreen {\n    fn from(value: PathSegmentGreen) -> Self {\n        ExprPathElementOrSeparatorGreen::Element(value)\n    }\n}\nimpl ExprPathElementOrSeparatorGreen {\n    fn id(&self) -> GreenId {\n        match self {\n            ExprPathElementOrSeparatorGreen::Separator(green) => green.0,\n            ExprPathElementOrSeparatorGreen::Element(green) => green.0,\n        }\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprPathGreen(pub GreenId);\nimpl TypedSyntaxNode for ExprPath {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ExprPath);\n    type StablePtr = ExprPathPtr;\n    type Green = ExprPathGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ExprPathGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprPath,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        Self(ElementList::new(node))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ExprPathPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ExprParenthesized {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ExprParenthesized {\n    pub const INDEX_LPAREN: usize = 0;\n    pub const INDEX_EXPR: usize = 1;\n    pub const INDEX_RPAREN: usize = 2;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        lparen: TerminalLParenGreen,\n        expr: ExprGreen,\n        rparen: TerminalRParenGreen,\n    ) -> ExprParenthesizedGreen {\n        let children: Vec<GreenId> = vec![lparen.0, expr.0, rparen.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ExprParenthesizedGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprParenthesized,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ExprParenthesized {\n    pub fn lparen(&self, db: &dyn SyntaxGroup) -> TerminalLParen {\n        TerminalLParen::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn expr(&self, db: &dyn SyntaxGroup) -> Expr {\n        Expr::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn rparen(&self, db: &dyn SyntaxGroup) -> TerminalRParen {\n        TerminalRParen::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprParenthesizedPtr(pub SyntaxStablePtrId);\nimpl ExprParenthesizedPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprParenthesizedGreen(pub GreenId);\nimpl TypedSyntaxNode for ExprParenthesized {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ExprParenthesized);\n    type StablePtr = ExprParenthesizedPtr;\n    type Green = ExprParenthesizedGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ExprParenthesizedGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprParenthesized,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    TerminalLParen::missing(db).0,\n                    Expr::missing(db).0,\n                    TerminalRParen::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ExprParenthesized,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ExprParenthesized\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ExprParenthesizedPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ExprUnary {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ExprUnary {\n    pub const INDEX_OP: usize = 0;\n    pub const INDEX_EXPR: usize = 1;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        op: UnaryOperatorGreen,\n        expr: ExprGreen,\n    ) -> ExprUnaryGreen {\n        let children: Vec<GreenId> = vec![op.0, expr.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ExprUnaryGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprUnary,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ExprUnary {\n    pub fn op(&self, db: &dyn SyntaxGroup) -> UnaryOperator {\n        UnaryOperator::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn expr(&self, db: &dyn SyntaxGroup) -> Expr {\n        Expr::from_syntax_node(db, self.children[1].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprUnaryPtr(pub SyntaxStablePtrId);\nimpl ExprUnaryPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprUnaryGreen(pub GreenId);\nimpl TypedSyntaxNode for ExprUnary {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ExprUnary);\n    type StablePtr = ExprUnaryPtr;\n    type Green = ExprUnaryGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ExprUnaryGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprUnary,\n            details: GreenNodeDetails::Node {\n                children: vec![UnaryOperator::missing(db).0, Expr::missing(db).0],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ExprUnary,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ExprUnary\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ExprUnaryPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum UnaryOperator {\n    Not(TerminalNot),\n    Minus(TerminalMinus),\n    At(TerminalAt),\n    Desnap(TerminalMul),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct UnaryOperatorPtr(pub SyntaxStablePtrId);\nimpl UnaryOperatorPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<TerminalNotPtr> for UnaryOperatorPtr {\n    fn from(value: TerminalNotPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalMinusPtr> for UnaryOperatorPtr {\n    fn from(value: TerminalMinusPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalAtPtr> for UnaryOperatorPtr {\n    fn from(value: TerminalAtPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalMulPtr> for UnaryOperatorPtr {\n    fn from(value: TerminalMulPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalNotGreen> for UnaryOperatorGreen {\n    fn from(value: TerminalNotGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalMinusGreen> for UnaryOperatorGreen {\n    fn from(value: TerminalMinusGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalAtGreen> for UnaryOperatorGreen {\n    fn from(value: TerminalAtGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalMulGreen> for UnaryOperatorGreen {\n    fn from(value: TerminalMulGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct UnaryOperatorGreen(pub GreenId);\nimpl TypedSyntaxNode for UnaryOperator {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = UnaryOperatorPtr;\n    type Green = UnaryOperatorGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::TerminalNot => UnaryOperator::Not(TerminalNot::from_syntax_node(db, node)),\n            SyntaxKind::TerminalMinus => {\n                UnaryOperator::Minus(TerminalMinus::from_syntax_node(db, node))\n            }\n            SyntaxKind::TerminalAt => UnaryOperator::At(TerminalAt::from_syntax_node(db, node)),\n            SyntaxKind::TerminalMul => {\n                UnaryOperator::Desnap(TerminalMul::from_syntax_node(db, node))\n            }\n            _ => panic!(\"Unexpected syntax kind {:?} when constructing {}.\", kind, \"UnaryOperator\"),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            UnaryOperator::Not(x) => x.as_syntax_node(),\n            UnaryOperator::Minus(x) => x.as_syntax_node(),\n            UnaryOperator::At(x) => x.as_syntax_node(),\n            UnaryOperator::Desnap(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        UnaryOperatorPtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ExprBinary {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ExprBinary {\n    pub const INDEX_LHS: usize = 0;\n    pub const INDEX_OP: usize = 1;\n    pub const INDEX_RHS: usize = 2;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        lhs: ExprGreen,\n        op: BinaryOperatorGreen,\n        rhs: ExprGreen,\n    ) -> ExprBinaryGreen {\n        let children: Vec<GreenId> = vec![lhs.0, op.0, rhs.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ExprBinaryGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprBinary,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ExprBinary {\n    pub fn lhs(&self, db: &dyn SyntaxGroup) -> Expr {\n        Expr::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn op(&self, db: &dyn SyntaxGroup) -> BinaryOperator {\n        BinaryOperator::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn rhs(&self, db: &dyn SyntaxGroup) -> Expr {\n        Expr::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprBinaryPtr(pub SyntaxStablePtrId);\nimpl ExprBinaryPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprBinaryGreen(pub GreenId);\nimpl TypedSyntaxNode for ExprBinary {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ExprBinary);\n    type StablePtr = ExprBinaryPtr;\n    type Green = ExprBinaryGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ExprBinaryGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprBinary,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Expr::missing(db).0,\n                    BinaryOperator::missing(db).0,\n                    Expr::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ExprBinary,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ExprBinary\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ExprBinaryPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum BinaryOperator {\n    Dot(TerminalDot),\n    Not(TerminalNot),\n    Mul(TerminalMul),\n    MulEq(TerminalMulEq),\n    Div(TerminalDiv),\n    DivEq(TerminalDivEq),\n    Mod(TerminalMod),\n    ModEq(TerminalModEq),\n    Plus(TerminalPlus),\n    PlusEq(TerminalPlusEq),\n    Minus(TerminalMinus),\n    MinusEq(TerminalMinusEq),\n    EqEq(TerminalEqEq),\n    Neq(TerminalNeq),\n    Eq(TerminalEq),\n    And(TerminalAnd),\n    Or(TerminalOr),\n    Xor(TerminalXor),\n    LE(TerminalLE),\n    GE(TerminalGE),\n    LT(TerminalLT),\n    GT(TerminalGT),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct BinaryOperatorPtr(pub SyntaxStablePtrId);\nimpl BinaryOperatorPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<TerminalDotPtr> for BinaryOperatorPtr {\n    fn from(value: TerminalDotPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalNotPtr> for BinaryOperatorPtr {\n    fn from(value: TerminalNotPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalMulPtr> for BinaryOperatorPtr {\n    fn from(value: TerminalMulPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalMulEqPtr> for BinaryOperatorPtr {\n    fn from(value: TerminalMulEqPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalDivPtr> for BinaryOperatorPtr {\n    fn from(value: TerminalDivPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalDivEqPtr> for BinaryOperatorPtr {\n    fn from(value: TerminalDivEqPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalModPtr> for BinaryOperatorPtr {\n    fn from(value: TerminalModPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalModEqPtr> for BinaryOperatorPtr {\n    fn from(value: TerminalModEqPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalPlusPtr> for BinaryOperatorPtr {\n    fn from(value: TerminalPlusPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalPlusEqPtr> for BinaryOperatorPtr {\n    fn from(value: TerminalPlusEqPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalMinusPtr> for BinaryOperatorPtr {\n    fn from(value: TerminalMinusPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalMinusEqPtr> for BinaryOperatorPtr {\n    fn from(value: TerminalMinusEqPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalEqEqPtr> for BinaryOperatorPtr {\n    fn from(value: TerminalEqEqPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalNeqPtr> for BinaryOperatorPtr {\n    fn from(value: TerminalNeqPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalEqPtr> for BinaryOperatorPtr {\n    fn from(value: TerminalEqPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalAndPtr> for BinaryOperatorPtr {\n    fn from(value: TerminalAndPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalOrPtr> for BinaryOperatorPtr {\n    fn from(value: TerminalOrPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalXorPtr> for BinaryOperatorPtr {\n    fn from(value: TerminalXorPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalLEPtr> for BinaryOperatorPtr {\n    fn from(value: TerminalLEPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalGEPtr> for BinaryOperatorPtr {\n    fn from(value: TerminalGEPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalLTPtr> for BinaryOperatorPtr {\n    fn from(value: TerminalLTPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalGTPtr> for BinaryOperatorPtr {\n    fn from(value: TerminalGTPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalDotGreen> for BinaryOperatorGreen {\n    fn from(value: TerminalDotGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalNotGreen> for BinaryOperatorGreen {\n    fn from(value: TerminalNotGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalMulGreen> for BinaryOperatorGreen {\n    fn from(value: TerminalMulGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalMulEqGreen> for BinaryOperatorGreen {\n    fn from(value: TerminalMulEqGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalDivGreen> for BinaryOperatorGreen {\n    fn from(value: TerminalDivGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalDivEqGreen> for BinaryOperatorGreen {\n    fn from(value: TerminalDivEqGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalModGreen> for BinaryOperatorGreen {\n    fn from(value: TerminalModGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalModEqGreen> for BinaryOperatorGreen {\n    fn from(value: TerminalModEqGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalPlusGreen> for BinaryOperatorGreen {\n    fn from(value: TerminalPlusGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalPlusEqGreen> for BinaryOperatorGreen {\n    fn from(value: TerminalPlusEqGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalMinusGreen> for BinaryOperatorGreen {\n    fn from(value: TerminalMinusGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalMinusEqGreen> for BinaryOperatorGreen {\n    fn from(value: TerminalMinusEqGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalEqEqGreen> for BinaryOperatorGreen {\n    fn from(value: TerminalEqEqGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalNeqGreen> for BinaryOperatorGreen {\n    fn from(value: TerminalNeqGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalEqGreen> for BinaryOperatorGreen {\n    fn from(value: TerminalEqGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalAndGreen> for BinaryOperatorGreen {\n    fn from(value: TerminalAndGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalOrGreen> for BinaryOperatorGreen {\n    fn from(value: TerminalOrGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalXorGreen> for BinaryOperatorGreen {\n    fn from(value: TerminalXorGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalLEGreen> for BinaryOperatorGreen {\n    fn from(value: TerminalLEGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalGEGreen> for BinaryOperatorGreen {\n    fn from(value: TerminalGEGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalLTGreen> for BinaryOperatorGreen {\n    fn from(value: TerminalLTGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalGTGreen> for BinaryOperatorGreen {\n    fn from(value: TerminalGTGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct BinaryOperatorGreen(pub GreenId);\nimpl TypedSyntaxNode for BinaryOperator {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = BinaryOperatorPtr;\n    type Green = BinaryOperatorGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::TerminalDot => BinaryOperator::Dot(TerminalDot::from_syntax_node(db, node)),\n            SyntaxKind::TerminalNot => BinaryOperator::Not(TerminalNot::from_syntax_node(db, node)),\n            SyntaxKind::TerminalMul => BinaryOperator::Mul(TerminalMul::from_syntax_node(db, node)),\n            SyntaxKind::TerminalMulEq => {\n                BinaryOperator::MulEq(TerminalMulEq::from_syntax_node(db, node))\n            }\n            SyntaxKind::TerminalDiv => BinaryOperator::Div(TerminalDiv::from_syntax_node(db, node)),\n            SyntaxKind::TerminalDivEq => {\n                BinaryOperator::DivEq(TerminalDivEq::from_syntax_node(db, node))\n            }\n            SyntaxKind::TerminalMod => BinaryOperator::Mod(TerminalMod::from_syntax_node(db, node)),\n            SyntaxKind::TerminalModEq => {\n                BinaryOperator::ModEq(TerminalModEq::from_syntax_node(db, node))\n            }\n            SyntaxKind::TerminalPlus => {\n                BinaryOperator::Plus(TerminalPlus::from_syntax_node(db, node))\n            }\n            SyntaxKind::TerminalPlusEq => {\n                BinaryOperator::PlusEq(TerminalPlusEq::from_syntax_node(db, node))\n            }\n            SyntaxKind::TerminalMinus => {\n                BinaryOperator::Minus(TerminalMinus::from_syntax_node(db, node))\n            }\n            SyntaxKind::TerminalMinusEq => {\n                BinaryOperator::MinusEq(TerminalMinusEq::from_syntax_node(db, node))\n            }\n            SyntaxKind::TerminalEqEq => {\n                BinaryOperator::EqEq(TerminalEqEq::from_syntax_node(db, node))\n            }\n            SyntaxKind::TerminalNeq => BinaryOperator::Neq(TerminalNeq::from_syntax_node(db, node)),\n            SyntaxKind::TerminalEq => BinaryOperator::Eq(TerminalEq::from_syntax_node(db, node)),\n            SyntaxKind::TerminalAnd => BinaryOperator::And(TerminalAnd::from_syntax_node(db, node)),\n            SyntaxKind::TerminalOr => BinaryOperator::Or(TerminalOr::from_syntax_node(db, node)),\n            SyntaxKind::TerminalXor => BinaryOperator::Xor(TerminalXor::from_syntax_node(db, node)),\n            SyntaxKind::TerminalLE => BinaryOperator::LE(TerminalLE::from_syntax_node(db, node)),\n            SyntaxKind::TerminalGE => BinaryOperator::GE(TerminalGE::from_syntax_node(db, node)),\n            SyntaxKind::TerminalLT => BinaryOperator::LT(TerminalLT::from_syntax_node(db, node)),\n            SyntaxKind::TerminalGT => BinaryOperator::GT(TerminalGT::from_syntax_node(db, node)),\n            _ => {\n                panic!(\"Unexpected syntax kind {:?} when constructing {}.\", kind, \"BinaryOperator\")\n            }\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            BinaryOperator::Dot(x) => x.as_syntax_node(),\n            BinaryOperator::Not(x) => x.as_syntax_node(),\n            BinaryOperator::Mul(x) => x.as_syntax_node(),\n            BinaryOperator::MulEq(x) => x.as_syntax_node(),\n            BinaryOperator::Div(x) => x.as_syntax_node(),\n            BinaryOperator::DivEq(x) => x.as_syntax_node(),\n            BinaryOperator::Mod(x) => x.as_syntax_node(),\n            BinaryOperator::ModEq(x) => x.as_syntax_node(),\n            BinaryOperator::Plus(x) => x.as_syntax_node(),\n            BinaryOperator::PlusEq(x) => x.as_syntax_node(),\n            BinaryOperator::Minus(x) => x.as_syntax_node(),\n            BinaryOperator::MinusEq(x) => x.as_syntax_node(),\n            BinaryOperator::EqEq(x) => x.as_syntax_node(),\n            BinaryOperator::Neq(x) => x.as_syntax_node(),\n            BinaryOperator::Eq(x) => x.as_syntax_node(),\n            BinaryOperator::And(x) => x.as_syntax_node(),\n            BinaryOperator::Or(x) => x.as_syntax_node(),\n            BinaryOperator::Xor(x) => x.as_syntax_node(),\n            BinaryOperator::LE(x) => x.as_syntax_node(),\n            BinaryOperator::GE(x) => x.as_syntax_node(),\n            BinaryOperator::LT(x) => x.as_syntax_node(),\n            BinaryOperator::GT(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        BinaryOperatorPtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ExprTuple {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ExprTuple {\n    pub const INDEX_LPAREN: usize = 0;\n    pub const INDEX_EXPRESSIONS: usize = 1;\n    pub const INDEX_RPAREN: usize = 2;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        lparen: TerminalLParenGreen,\n        expressions: ExprListGreen,\n        rparen: TerminalRParenGreen,\n    ) -> ExprTupleGreen {\n        let children: Vec<GreenId> = vec![lparen.0, expressions.0, rparen.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ExprTupleGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprTuple,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ExprTuple {\n    pub fn lparen(&self, db: &dyn SyntaxGroup) -> TerminalLParen {\n        TerminalLParen::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn expressions(&self, db: &dyn SyntaxGroup) -> ExprList {\n        ExprList::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn rparen(&self, db: &dyn SyntaxGroup) -> TerminalRParen {\n        TerminalRParen::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprTuplePtr(pub SyntaxStablePtrId);\nimpl ExprTuplePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprTupleGreen(pub GreenId);\nimpl TypedSyntaxNode for ExprTuple {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ExprTuple);\n    type StablePtr = ExprTuplePtr;\n    type Green = ExprTupleGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ExprTupleGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprTuple,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    TerminalLParen::missing(db).0,\n                    ExprList::missing(db).0,\n                    TerminalRParen::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ExprTuple,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ExprTuple\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ExprTuplePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ExprFunctionCall {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ExprFunctionCall {\n    pub const INDEX_PATH: usize = 0;\n    pub const INDEX_ARGUMENTS: usize = 1;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        path: ExprPathGreen,\n        arguments: ArgListParenthesizedGreen,\n    ) -> ExprFunctionCallGreen {\n        let children: Vec<GreenId> = vec![path.0, arguments.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ExprFunctionCallGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprFunctionCall,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ExprFunctionCall {\n    pub fn path(&self, db: &dyn SyntaxGroup) -> ExprPath {\n        ExprPath::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn arguments(&self, db: &dyn SyntaxGroup) -> ArgListParenthesized {\n        ArgListParenthesized::from_syntax_node(db, self.children[1].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprFunctionCallPtr(pub SyntaxStablePtrId);\nimpl ExprFunctionCallPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprFunctionCallGreen(pub GreenId);\nimpl TypedSyntaxNode for ExprFunctionCall {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ExprFunctionCall);\n    type StablePtr = ExprFunctionCallPtr;\n    type Green = ExprFunctionCallGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ExprFunctionCallGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprFunctionCall,\n            details: GreenNodeDetails::Node {\n                children: vec![ExprPath::missing(db).0, ArgListParenthesized::missing(db).0],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ExprFunctionCall,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ExprFunctionCall\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ExprFunctionCallPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ArgListParenthesized {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ArgListParenthesized {\n    pub const INDEX_LPAREN: usize = 0;\n    pub const INDEX_ARGS: usize = 1;\n    pub const INDEX_RPAREN: usize = 2;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        lparen: TerminalLParenGreen,\n        args: ArgListGreen,\n        rparen: TerminalRParenGreen,\n    ) -> ArgListParenthesizedGreen {\n        let children: Vec<GreenId> = vec![lparen.0, args.0, rparen.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ArgListParenthesizedGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ArgListParenthesized,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ArgListParenthesized {\n    pub fn lparen(&self, db: &dyn SyntaxGroup) -> TerminalLParen {\n        TerminalLParen::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn args(&self, db: &dyn SyntaxGroup) -> ArgList {\n        ArgList::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn rparen(&self, db: &dyn SyntaxGroup) -> TerminalRParen {\n        TerminalRParen::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ArgListParenthesizedPtr(pub SyntaxStablePtrId);\nimpl ArgListParenthesizedPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ArgListParenthesizedGreen(pub GreenId);\nimpl TypedSyntaxNode for ArgListParenthesized {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ArgListParenthesized);\n    type StablePtr = ArgListParenthesizedPtr;\n    type Green = ArgListParenthesizedGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ArgListParenthesizedGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ArgListParenthesized,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    TerminalLParen::missing(db).0,\n                    ArgList::missing(db).0,\n                    TerminalRParen::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ArgListParenthesized,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ArgListParenthesized\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ArgListParenthesizedPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ExprStructCtorCall {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ExprStructCtorCall {\n    pub const INDEX_PATH: usize = 0;\n    pub const INDEX_ARGUMENTS: usize = 1;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        path: ExprPathGreen,\n        arguments: ArgListBracedGreen,\n    ) -> ExprStructCtorCallGreen {\n        let children: Vec<GreenId> = vec![path.0, arguments.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ExprStructCtorCallGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprStructCtorCall,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ExprStructCtorCall {\n    pub fn path(&self, db: &dyn SyntaxGroup) -> ExprPath {\n        ExprPath::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn arguments(&self, db: &dyn SyntaxGroup) -> ArgListBraced {\n        ArgListBraced::from_syntax_node(db, self.children[1].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprStructCtorCallPtr(pub SyntaxStablePtrId);\nimpl ExprStructCtorCallPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprStructCtorCallGreen(pub GreenId);\nimpl TypedSyntaxNode for ExprStructCtorCall {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ExprStructCtorCall);\n    type StablePtr = ExprStructCtorCallPtr;\n    type Green = ExprStructCtorCallGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ExprStructCtorCallGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprStructCtorCall,\n            details: GreenNodeDetails::Node {\n                children: vec![ExprPath::missing(db).0, ArgListBraced::missing(db).0],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ExprStructCtorCall,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ExprStructCtorCall\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ExprStructCtorCallPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ExprBlock {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ExprBlock {\n    pub const INDEX_LBRACE: usize = 0;\n    pub const INDEX_STATEMENTS: usize = 1;\n    pub const INDEX_RBRACE: usize = 2;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        lbrace: TerminalLBraceGreen,\n        statements: StatementListGreen,\n        rbrace: TerminalRBraceGreen,\n    ) -> ExprBlockGreen {\n        let children: Vec<GreenId> = vec![lbrace.0, statements.0, rbrace.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ExprBlockGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprBlock,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ExprBlock {\n    pub fn lbrace(&self, db: &dyn SyntaxGroup) -> TerminalLBrace {\n        TerminalLBrace::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn statements(&self, db: &dyn SyntaxGroup) -> StatementList {\n        StatementList::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn rbrace(&self, db: &dyn SyntaxGroup) -> TerminalRBrace {\n        TerminalRBrace::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprBlockPtr(pub SyntaxStablePtrId);\nimpl ExprBlockPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprBlockGreen(pub GreenId);\nimpl TypedSyntaxNode for ExprBlock {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ExprBlock);\n    type StablePtr = ExprBlockPtr;\n    type Green = ExprBlockGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ExprBlockGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprBlock,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    TerminalLBrace::missing(db).0,\n                    StatementList::missing(db).0,\n                    TerminalRBrace::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ExprBlock,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ExprBlock\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ExprBlockPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ExprMatch {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ExprMatch {\n    pub const INDEX_MATCH_KW: usize = 0;\n    pub const INDEX_EXPR: usize = 1;\n    pub const INDEX_LBRACE: usize = 2;\n    pub const INDEX_ARMS: usize = 3;\n    pub const INDEX_RBRACE: usize = 4;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        match_kw: TerminalMatchGreen,\n        expr: ExprGreen,\n        lbrace: TerminalLBraceGreen,\n        arms: MatchArmsGreen,\n        rbrace: TerminalRBraceGreen,\n    ) -> ExprMatchGreen {\n        let children: Vec<GreenId> = vec![match_kw.0, expr.0, lbrace.0, arms.0, rbrace.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ExprMatchGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprMatch,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ExprMatch {\n    pub fn match_kw(&self, db: &dyn SyntaxGroup) -> TerminalMatch {\n        TerminalMatch::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn expr(&self, db: &dyn SyntaxGroup) -> Expr {\n        Expr::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn lbrace(&self, db: &dyn SyntaxGroup) -> TerminalLBrace {\n        TerminalLBrace::from_syntax_node(db, self.children[2].clone())\n    }\n    pub fn arms(&self, db: &dyn SyntaxGroup) -> MatchArms {\n        MatchArms::from_syntax_node(db, self.children[3].clone())\n    }\n    pub fn rbrace(&self, db: &dyn SyntaxGroup) -> TerminalRBrace {\n        TerminalRBrace::from_syntax_node(db, self.children[4].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprMatchPtr(pub SyntaxStablePtrId);\nimpl ExprMatchPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprMatchGreen(pub GreenId);\nimpl TypedSyntaxNode for ExprMatch {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ExprMatch);\n    type StablePtr = ExprMatchPtr;\n    type Green = ExprMatchGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ExprMatchGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprMatch,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    TerminalMatch::missing(db).0,\n                    Expr::missing(db).0,\n                    TerminalLBrace::missing(db).0,\n                    MatchArms::missing(db).0,\n                    TerminalRBrace::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ExprMatch,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ExprMatch\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ExprMatchPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct MatchArms(ElementList<MatchArm, 2>);\nimpl Deref for MatchArms {\n    type Target = ElementList<MatchArm, 2>;\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\nimpl MatchArms {\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        children: Vec<MatchArmsElementOrSeparatorGreen>,\n    ) -> MatchArmsGreen {\n        let width = children.iter().map(|id| db.lookup_intern_green(id.id()).width()).sum();\n        MatchArmsGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::MatchArms,\n            details: GreenNodeDetails::Node {\n                children: children.iter().map(|x| x.id()).collect(),\n                width,\n            },\n        }))\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct MatchArmsPtr(pub SyntaxStablePtrId);\nimpl MatchArmsPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub enum MatchArmsElementOrSeparatorGreen {\n    Separator(TerminalCommaGreen),\n    Element(MatchArmGreen),\n}\nimpl From<TerminalCommaGreen> for MatchArmsElementOrSeparatorGreen {\n    fn from(value: TerminalCommaGreen) -> Self {\n        MatchArmsElementOrSeparatorGreen::Separator(value)\n    }\n}\nimpl From<MatchArmGreen> for MatchArmsElementOrSeparatorGreen {\n    fn from(value: MatchArmGreen) -> Self {\n        MatchArmsElementOrSeparatorGreen::Element(value)\n    }\n}\nimpl MatchArmsElementOrSeparatorGreen {\n    fn id(&self) -> GreenId {\n        match self {\n            MatchArmsElementOrSeparatorGreen::Separator(green) => green.0,\n            MatchArmsElementOrSeparatorGreen::Element(green) => green.0,\n        }\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct MatchArmsGreen(pub GreenId);\nimpl TypedSyntaxNode for MatchArms {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::MatchArms);\n    type StablePtr = MatchArmsPtr;\n    type Green = MatchArmsGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        MatchArmsGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::MatchArms,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        Self(ElementList::new(node))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        MatchArmsPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct MatchArm {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl MatchArm {\n    pub const INDEX_PATTERN: usize = 0;\n    pub const INDEX_ARROW: usize = 1;\n    pub const INDEX_EXPRESSION: usize = 2;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        pattern: PatternGreen,\n        arrow: TerminalMatchArrowGreen,\n        expression: ExprGreen,\n    ) -> MatchArmGreen {\n        let children: Vec<GreenId> = vec![pattern.0, arrow.0, expression.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        MatchArmGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::MatchArm,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl MatchArm {\n    pub fn pattern(&self, db: &dyn SyntaxGroup) -> Pattern {\n        Pattern::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn arrow(&self, db: &dyn SyntaxGroup) -> TerminalMatchArrow {\n        TerminalMatchArrow::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn expression(&self, db: &dyn SyntaxGroup) -> Expr {\n        Expr::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct MatchArmPtr(pub SyntaxStablePtrId);\nimpl MatchArmPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct MatchArmGreen(pub GreenId);\nimpl TypedSyntaxNode for MatchArm {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::MatchArm);\n    type StablePtr = MatchArmPtr;\n    type Green = MatchArmGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        MatchArmGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::MatchArm,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Pattern::missing(db).0,\n                    TerminalMatchArrow::missing(db).0,\n                    Expr::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::MatchArm,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::MatchArm\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        MatchArmPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ExprIf {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ExprIf {\n    pub const INDEX_IF_KW: usize = 0;\n    pub const INDEX_CONDITION: usize = 1;\n    pub const INDEX_IF_BLOCK: usize = 2;\n    pub const INDEX_ELSE_CLAUSE: usize = 3;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        if_kw: TerminalIfGreen,\n        condition: ExprGreen,\n        if_block: ExprBlockGreen,\n        else_clause: OptionElseClauseGreen,\n    ) -> ExprIfGreen {\n        let children: Vec<GreenId> = vec![if_kw.0, condition.0, if_block.0, else_clause.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ExprIfGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprIf,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ExprIf {\n    pub fn if_kw(&self, db: &dyn SyntaxGroup) -> TerminalIf {\n        TerminalIf::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn condition(&self, db: &dyn SyntaxGroup) -> Expr {\n        Expr::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn if_block(&self, db: &dyn SyntaxGroup) -> ExprBlock {\n        ExprBlock::from_syntax_node(db, self.children[2].clone())\n    }\n    pub fn else_clause(&self, db: &dyn SyntaxGroup) -> OptionElseClause {\n        OptionElseClause::from_syntax_node(db, self.children[3].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprIfPtr(pub SyntaxStablePtrId);\nimpl ExprIfPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprIfGreen(pub GreenId);\nimpl TypedSyntaxNode for ExprIf {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ExprIf);\n    type StablePtr = ExprIfPtr;\n    type Green = ExprIfGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ExprIfGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprIf,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    TerminalIf::missing(db).0,\n                    Expr::missing(db).0,\n                    ExprBlock::missing(db).0,\n                    OptionElseClause::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ExprIf,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ExprIf\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ExprIfPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum BlockOrIf {\n    Block(ExprBlock),\n    If(ExprIf),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct BlockOrIfPtr(pub SyntaxStablePtrId);\nimpl BlockOrIfPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<ExprBlockPtr> for BlockOrIfPtr {\n    fn from(value: ExprBlockPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprIfPtr> for BlockOrIfPtr {\n    fn from(value: ExprIfPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprBlockGreen> for BlockOrIfGreen {\n    fn from(value: ExprBlockGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprIfGreen> for BlockOrIfGreen {\n    fn from(value: ExprIfGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct BlockOrIfGreen(pub GreenId);\nimpl TypedSyntaxNode for BlockOrIf {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = BlockOrIfPtr;\n    type Green = BlockOrIfGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::ExprBlock => BlockOrIf::Block(ExprBlock::from_syntax_node(db, node)),\n            SyntaxKind::ExprIf => BlockOrIf::If(ExprIf::from_syntax_node(db, node)),\n            _ => panic!(\"Unexpected syntax kind {:?} when constructing {}.\", kind, \"BlockOrIf\"),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            BlockOrIf::Block(x) => x.as_syntax_node(),\n            BlockOrIf::If(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        BlockOrIfPtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ElseClause {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ElseClause {\n    pub const INDEX_ELSE_KW: usize = 0;\n    pub const INDEX_ELSE_BLOCK_OR_IF: usize = 1;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        else_kw: TerminalElseGreen,\n        else_block_or_if: BlockOrIfGreen,\n    ) -> ElseClauseGreen {\n        let children: Vec<GreenId> = vec![else_kw.0, else_block_or_if.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ElseClauseGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ElseClause,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ElseClause {\n    pub fn else_kw(&self, db: &dyn SyntaxGroup) -> TerminalElse {\n        TerminalElse::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn else_block_or_if(&self, db: &dyn SyntaxGroup) -> BlockOrIf {\n        BlockOrIf::from_syntax_node(db, self.children[1].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ElseClausePtr(pub SyntaxStablePtrId);\nimpl ElseClausePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ElseClauseGreen(pub GreenId);\nimpl TypedSyntaxNode for ElseClause {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ElseClause);\n    type StablePtr = ElseClausePtr;\n    type Green = ElseClauseGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ElseClauseGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ElseClause,\n            details: GreenNodeDetails::Node {\n                children: vec![TerminalElse::missing(db).0, BlockOrIf::missing(db).0],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ElseClause,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ElseClause\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ElseClausePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum OptionElseClause {\n    Empty(OptionElseClauseEmpty),\n    ElseClause(ElseClause),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionElseClausePtr(pub SyntaxStablePtrId);\nimpl OptionElseClausePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<OptionElseClauseEmptyPtr> for OptionElseClausePtr {\n    fn from(value: OptionElseClauseEmptyPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ElseClausePtr> for OptionElseClausePtr {\n    fn from(value: ElseClausePtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<OptionElseClauseEmptyGreen> for OptionElseClauseGreen {\n    fn from(value: OptionElseClauseEmptyGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ElseClauseGreen> for OptionElseClauseGreen {\n    fn from(value: ElseClauseGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionElseClauseGreen(pub GreenId);\nimpl TypedSyntaxNode for OptionElseClause {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = OptionElseClausePtr;\n    type Green = OptionElseClauseGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::OptionElseClauseEmpty => {\n                OptionElseClause::Empty(OptionElseClauseEmpty::from_syntax_node(db, node))\n            }\n            SyntaxKind::ElseClause => {\n                OptionElseClause::ElseClause(ElseClause::from_syntax_node(db, node))\n            }\n            _ => panic!(\n                \"Unexpected syntax kind {:?} when constructing {}.\",\n                kind, \"OptionElseClause\"\n            ),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            OptionElseClause::Empty(x) => x.as_syntax_node(),\n            OptionElseClause::ElseClause(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        OptionElseClausePtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct OptionElseClauseEmpty {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl OptionElseClauseEmpty {\n    pub fn new_green(db: &dyn SyntaxGroup) -> OptionElseClauseEmptyGreen {\n        let children: Vec<GreenId> = vec![];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        OptionElseClauseEmptyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::OptionElseClauseEmpty,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl OptionElseClauseEmpty {}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionElseClauseEmptyPtr(pub SyntaxStablePtrId);\nimpl OptionElseClauseEmptyPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionElseClauseEmptyGreen(pub GreenId);\nimpl TypedSyntaxNode for OptionElseClauseEmpty {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::OptionElseClauseEmpty);\n    type StablePtr = OptionElseClauseEmptyPtr;\n    type Green = OptionElseClauseEmptyGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        OptionElseClauseEmptyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::OptionElseClauseEmpty,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::OptionElseClauseEmpty,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::OptionElseClauseEmpty\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        OptionElseClauseEmptyPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ExprErrorPropagate {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ExprErrorPropagate {\n    pub const INDEX_EXPR: usize = 0;\n    pub const INDEX_OP: usize = 1;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        expr: ExprGreen,\n        op: TerminalQuestionMarkGreen,\n    ) -> ExprErrorPropagateGreen {\n        let children: Vec<GreenId> = vec![expr.0, op.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ExprErrorPropagateGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprErrorPropagate,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ExprErrorPropagate {\n    pub fn expr(&self, db: &dyn SyntaxGroup) -> Expr {\n        Expr::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn op(&self, db: &dyn SyntaxGroup) -> TerminalQuestionMark {\n        TerminalQuestionMark::from_syntax_node(db, self.children[1].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprErrorPropagatePtr(pub SyntaxStablePtrId);\nimpl ExprErrorPropagatePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprErrorPropagateGreen(pub GreenId);\nimpl TypedSyntaxNode for ExprErrorPropagate {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ExprErrorPropagate);\n    type StablePtr = ExprErrorPropagatePtr;\n    type Green = ExprErrorPropagateGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ExprErrorPropagateGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprErrorPropagate,\n            details: GreenNodeDetails::Node {\n                children: vec![Expr::missing(db).0, TerminalQuestionMark::missing(db).0],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ExprErrorPropagate,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ExprErrorPropagate\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ExprErrorPropagatePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ExprIndexed {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ExprIndexed {\n    pub const INDEX_EXPR: usize = 0;\n    pub const INDEX_LBRACK: usize = 1;\n    pub const INDEX_INDEX_EXPR: usize = 2;\n    pub const INDEX_RBRACK: usize = 3;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        expr: ExprGreen,\n        lbrack: TerminalLBrackGreen,\n        index_expr: ExprGreen,\n        rbrack: TerminalRBrackGreen,\n    ) -> ExprIndexedGreen {\n        let children: Vec<GreenId> = vec![expr.0, lbrack.0, index_expr.0, rbrack.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ExprIndexedGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprIndexed,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ExprIndexed {\n    pub fn expr(&self, db: &dyn SyntaxGroup) -> Expr {\n        Expr::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn lbrack(&self, db: &dyn SyntaxGroup) -> TerminalLBrack {\n        TerminalLBrack::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn index_expr(&self, db: &dyn SyntaxGroup) -> Expr {\n        Expr::from_syntax_node(db, self.children[2].clone())\n    }\n    pub fn rbrack(&self, db: &dyn SyntaxGroup) -> TerminalRBrack {\n        TerminalRBrack::from_syntax_node(db, self.children[3].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprIndexedPtr(pub SyntaxStablePtrId);\nimpl ExprIndexedPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ExprIndexedGreen(pub GreenId);\nimpl TypedSyntaxNode for ExprIndexed {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ExprIndexed);\n    type StablePtr = ExprIndexedPtr;\n    type Green = ExprIndexedGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ExprIndexedGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ExprIndexed,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Expr::missing(db).0,\n                    TerminalLBrack::missing(db).0,\n                    Expr::missing(db).0,\n                    TerminalRBrack::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ExprIndexed,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ExprIndexed\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ExprIndexedPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct StructArgExpr {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl StructArgExpr {\n    pub const INDEX_COLON: usize = 0;\n    pub const INDEX_EXPR: usize = 1;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        colon: TerminalColonGreen,\n        expr: ExprGreen,\n    ) -> StructArgExprGreen {\n        let children: Vec<GreenId> = vec![colon.0, expr.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        StructArgExprGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::StructArgExpr,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl StructArgExpr {\n    pub fn colon(&self, db: &dyn SyntaxGroup) -> TerminalColon {\n        TerminalColon::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn expr(&self, db: &dyn SyntaxGroup) -> Expr {\n        Expr::from_syntax_node(db, self.children[1].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct StructArgExprPtr(pub SyntaxStablePtrId);\nimpl StructArgExprPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct StructArgExprGreen(pub GreenId);\nimpl TypedSyntaxNode for StructArgExpr {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::StructArgExpr);\n    type StablePtr = StructArgExprPtr;\n    type Green = StructArgExprGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        StructArgExprGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::StructArgExpr,\n            details: GreenNodeDetails::Node {\n                children: vec![TerminalColon::missing(db).0, Expr::missing(db).0],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::StructArgExpr,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::StructArgExpr\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        StructArgExprPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum OptionStructArgExpr {\n    Empty(OptionStructArgExprEmpty),\n    StructArgExpr(StructArgExpr),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionStructArgExprPtr(pub SyntaxStablePtrId);\nimpl OptionStructArgExprPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<OptionStructArgExprEmptyPtr> for OptionStructArgExprPtr {\n    fn from(value: OptionStructArgExprEmptyPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<StructArgExprPtr> for OptionStructArgExprPtr {\n    fn from(value: StructArgExprPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<OptionStructArgExprEmptyGreen> for OptionStructArgExprGreen {\n    fn from(value: OptionStructArgExprEmptyGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<StructArgExprGreen> for OptionStructArgExprGreen {\n    fn from(value: StructArgExprGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionStructArgExprGreen(pub GreenId);\nimpl TypedSyntaxNode for OptionStructArgExpr {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = OptionStructArgExprPtr;\n    type Green = OptionStructArgExprGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::OptionStructArgExprEmpty => {\n                OptionStructArgExpr::Empty(OptionStructArgExprEmpty::from_syntax_node(db, node))\n            }\n            SyntaxKind::StructArgExpr => {\n                OptionStructArgExpr::StructArgExpr(StructArgExpr::from_syntax_node(db, node))\n            }\n            _ => panic!(\n                \"Unexpected syntax kind {:?} when constructing {}.\",\n                kind, \"OptionStructArgExpr\"\n            ),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            OptionStructArgExpr::Empty(x) => x.as_syntax_node(),\n            OptionStructArgExpr::StructArgExpr(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        OptionStructArgExprPtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct OptionStructArgExprEmpty {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl OptionStructArgExprEmpty {\n    pub fn new_green(db: &dyn SyntaxGroup) -> OptionStructArgExprEmptyGreen {\n        let children: Vec<GreenId> = vec![];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        OptionStructArgExprEmptyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::OptionStructArgExprEmpty,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl OptionStructArgExprEmpty {}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionStructArgExprEmptyPtr(pub SyntaxStablePtrId);\nimpl OptionStructArgExprEmptyPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionStructArgExprEmptyGreen(pub GreenId);\nimpl TypedSyntaxNode for OptionStructArgExprEmpty {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::OptionStructArgExprEmpty);\n    type StablePtr = OptionStructArgExprEmptyPtr;\n    type Green = OptionStructArgExprEmptyGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        OptionStructArgExprEmptyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::OptionStructArgExprEmpty,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::OptionStructArgExprEmpty,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::OptionStructArgExprEmpty\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        OptionStructArgExprEmptyPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct StructArgSingle {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl StructArgSingle {\n    pub const INDEX_IDENTIFIER: usize = 0;\n    pub const INDEX_ARG_EXPR: usize = 1;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        identifier: TerminalIdentifierGreen,\n        arg_expr: OptionStructArgExprGreen,\n    ) -> StructArgSingleGreen {\n        let children: Vec<GreenId> = vec![identifier.0, arg_expr.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        StructArgSingleGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::StructArgSingle,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl StructArgSingle {\n    pub fn identifier(&self, db: &dyn SyntaxGroup) -> TerminalIdentifier {\n        TerminalIdentifier::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn arg_expr(&self, db: &dyn SyntaxGroup) -> OptionStructArgExpr {\n        OptionStructArgExpr::from_syntax_node(db, self.children[1].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct StructArgSinglePtr(pub SyntaxStablePtrId);\nimpl StructArgSinglePtr {\n    pub fn identifier_green(self, db: &dyn SyntaxGroup) -> TerminalIdentifierGreen {\n        let ptr = db.lookup_intern_stable_ptr(self.0);\n        if let SyntaxStablePtr::Child { key_fields, .. } = ptr {\n            TerminalIdentifierGreen(key_fields[0])\n        } else {\n            panic!(\"Unexpected key field query on root.\");\n        }\n    }\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct StructArgSingleGreen(pub GreenId);\nimpl TypedSyntaxNode for StructArgSingle {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::StructArgSingle);\n    type StablePtr = StructArgSinglePtr;\n    type Green = StructArgSingleGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        StructArgSingleGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::StructArgSingle,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    TerminalIdentifier::missing(db).0,\n                    OptionStructArgExpr::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::StructArgSingle,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::StructArgSingle\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        StructArgSinglePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct StructArgTail {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl StructArgTail {\n    pub const INDEX_DOTDOT: usize = 0;\n    pub const INDEX_EXPRESSION: usize = 1;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        dotdot: TerminalDotDotGreen,\n        expression: ExprGreen,\n    ) -> StructArgTailGreen {\n        let children: Vec<GreenId> = vec![dotdot.0, expression.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        StructArgTailGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::StructArgTail,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl StructArgTail {\n    pub fn dotdot(&self, db: &dyn SyntaxGroup) -> TerminalDotDot {\n        TerminalDotDot::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn expression(&self, db: &dyn SyntaxGroup) -> Expr {\n        Expr::from_syntax_node(db, self.children[1].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct StructArgTailPtr(pub SyntaxStablePtrId);\nimpl StructArgTailPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct StructArgTailGreen(pub GreenId);\nimpl TypedSyntaxNode for StructArgTail {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::StructArgTail);\n    type StablePtr = StructArgTailPtr;\n    type Green = StructArgTailGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        StructArgTailGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::StructArgTail,\n            details: GreenNodeDetails::Node {\n                children: vec![TerminalDotDot::missing(db).0, Expr::missing(db).0],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::StructArgTail,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::StructArgTail\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        StructArgTailPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum StructArg {\n    StructArgSingle(StructArgSingle),\n    StructArgTail(StructArgTail),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct StructArgPtr(pub SyntaxStablePtrId);\nimpl StructArgPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<StructArgSinglePtr> for StructArgPtr {\n    fn from(value: StructArgSinglePtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<StructArgTailPtr> for StructArgPtr {\n    fn from(value: StructArgTailPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<StructArgSingleGreen> for StructArgGreen {\n    fn from(value: StructArgSingleGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<StructArgTailGreen> for StructArgGreen {\n    fn from(value: StructArgTailGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct StructArgGreen(pub GreenId);\nimpl TypedSyntaxNode for StructArg {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = StructArgPtr;\n    type Green = StructArgGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::StructArgSingle => {\n                StructArg::StructArgSingle(StructArgSingle::from_syntax_node(db, node))\n            }\n            SyntaxKind::StructArgTail => {\n                StructArg::StructArgTail(StructArgTail::from_syntax_node(db, node))\n            }\n            _ => panic!(\"Unexpected syntax kind {:?} when constructing {}.\", kind, \"StructArg\"),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            StructArg::StructArgSingle(x) => x.as_syntax_node(),\n            StructArg::StructArgTail(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        StructArgPtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct StructArgList(ElementList<StructArg, 2>);\nimpl Deref for StructArgList {\n    type Target = ElementList<StructArg, 2>;\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\nimpl StructArgList {\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        children: Vec<StructArgListElementOrSeparatorGreen>,\n    ) -> StructArgListGreen {\n        let width = children.iter().map(|id| db.lookup_intern_green(id.id()).width()).sum();\n        StructArgListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::StructArgList,\n            details: GreenNodeDetails::Node {\n                children: children.iter().map(|x| x.id()).collect(),\n                width,\n            },\n        }))\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct StructArgListPtr(pub SyntaxStablePtrId);\nimpl StructArgListPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub enum StructArgListElementOrSeparatorGreen {\n    Separator(TerminalCommaGreen),\n    Element(StructArgGreen),\n}\nimpl From<TerminalCommaGreen> for StructArgListElementOrSeparatorGreen {\n    fn from(value: TerminalCommaGreen) -> Self {\n        StructArgListElementOrSeparatorGreen::Separator(value)\n    }\n}\nimpl From<StructArgGreen> for StructArgListElementOrSeparatorGreen {\n    fn from(value: StructArgGreen) -> Self {\n        StructArgListElementOrSeparatorGreen::Element(value)\n    }\n}\nimpl StructArgListElementOrSeparatorGreen {\n    fn id(&self) -> GreenId {\n        match self {\n            StructArgListElementOrSeparatorGreen::Separator(green) => green.0,\n            StructArgListElementOrSeparatorGreen::Element(green) => green.0,\n        }\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct StructArgListGreen(pub GreenId);\nimpl TypedSyntaxNode for StructArgList {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::StructArgList);\n    type StablePtr = StructArgListPtr;\n    type Green = StructArgListGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        StructArgListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::StructArgList,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        Self(ElementList::new(node))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        StructArgListPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ArgListBraced {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ArgListBraced {\n    pub const INDEX_LBRACE: usize = 0;\n    pub const INDEX_ARGUMENTS: usize = 1;\n    pub const INDEX_RBRACE: usize = 2;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        lbrace: TerminalLBraceGreen,\n        arguments: StructArgListGreen,\n        rbrace: TerminalRBraceGreen,\n    ) -> ArgListBracedGreen {\n        let children: Vec<GreenId> = vec![lbrace.0, arguments.0, rbrace.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ArgListBracedGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ArgListBraced,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ArgListBraced {\n    pub fn lbrace(&self, db: &dyn SyntaxGroup) -> TerminalLBrace {\n        TerminalLBrace::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn arguments(&self, db: &dyn SyntaxGroup) -> StructArgList {\n        StructArgList::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn rbrace(&self, db: &dyn SyntaxGroup) -> TerminalRBrace {\n        TerminalRBrace::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ArgListBracedPtr(pub SyntaxStablePtrId);\nimpl ArgListBracedPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ArgListBracedGreen(pub GreenId);\nimpl TypedSyntaxNode for ArgListBraced {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ArgListBraced);\n    type StablePtr = ArgListBracedPtr;\n    type Green = ArgListBracedGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ArgListBracedGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ArgListBraced,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    TerminalLBrace::missing(db).0,\n                    StructArgList::missing(db).0,\n                    TerminalRBrace::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ArgListBraced,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ArgListBraced\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ArgListBracedPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum Pattern {\n    Underscore(TerminalUnderscore),\n    Literal(TerminalLiteralNumber),\n    ShortString(TerminalShortString),\n    Identifier(PatternIdentifier),\n    Struct(PatternStruct),\n    Tuple(PatternTuple),\n    Enum(PatternEnum),\n    Path(ExprPath),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct PatternPtr(pub SyntaxStablePtrId);\nimpl PatternPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<TerminalUnderscorePtr> for PatternPtr {\n    fn from(value: TerminalUnderscorePtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalLiteralNumberPtr> for PatternPtr {\n    fn from(value: TerminalLiteralNumberPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalShortStringPtr> for PatternPtr {\n    fn from(value: TerminalShortStringPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<PatternIdentifierPtr> for PatternPtr {\n    fn from(value: PatternIdentifierPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<PatternStructPtr> for PatternPtr {\n    fn from(value: PatternStructPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<PatternTuplePtr> for PatternPtr {\n    fn from(value: PatternTuplePtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<PatternEnumPtr> for PatternPtr {\n    fn from(value: PatternEnumPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprPathPtr> for PatternPtr {\n    fn from(value: ExprPathPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalUnderscoreGreen> for PatternGreen {\n    fn from(value: TerminalUnderscoreGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalLiteralNumberGreen> for PatternGreen {\n    fn from(value: TerminalLiteralNumberGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalShortStringGreen> for PatternGreen {\n    fn from(value: TerminalShortStringGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<PatternIdentifierGreen> for PatternGreen {\n    fn from(value: PatternIdentifierGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<PatternStructGreen> for PatternGreen {\n    fn from(value: PatternStructGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<PatternTupleGreen> for PatternGreen {\n    fn from(value: PatternTupleGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<PatternEnumGreen> for PatternGreen {\n    fn from(value: PatternEnumGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprPathGreen> for PatternGreen {\n    fn from(value: ExprPathGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct PatternGreen(pub GreenId);\nimpl TypedSyntaxNode for Pattern {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = PatternPtr;\n    type Green = PatternGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::TerminalUnderscore => {\n                Pattern::Underscore(TerminalUnderscore::from_syntax_node(db, node))\n            }\n            SyntaxKind::TerminalLiteralNumber => {\n                Pattern::Literal(TerminalLiteralNumber::from_syntax_node(db, node))\n            }\n            SyntaxKind::TerminalShortString => {\n                Pattern::ShortString(TerminalShortString::from_syntax_node(db, node))\n            }\n            SyntaxKind::PatternIdentifier => {\n                Pattern::Identifier(PatternIdentifier::from_syntax_node(db, node))\n            }\n            SyntaxKind::PatternStruct => Pattern::Struct(PatternStruct::from_syntax_node(db, node)),\n            SyntaxKind::PatternTuple => Pattern::Tuple(PatternTuple::from_syntax_node(db, node)),\n            SyntaxKind::PatternEnum => Pattern::Enum(PatternEnum::from_syntax_node(db, node)),\n            SyntaxKind::ExprPath => Pattern::Path(ExprPath::from_syntax_node(db, node)),\n            _ => panic!(\"Unexpected syntax kind {:?} when constructing {}.\", kind, \"Pattern\"),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            Pattern::Underscore(x) => x.as_syntax_node(),\n            Pattern::Literal(x) => x.as_syntax_node(),\n            Pattern::ShortString(x) => x.as_syntax_node(),\n            Pattern::Identifier(x) => x.as_syntax_node(),\n            Pattern::Struct(x) => x.as_syntax_node(),\n            Pattern::Tuple(x) => x.as_syntax_node(),\n            Pattern::Enum(x) => x.as_syntax_node(),\n            Pattern::Path(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        PatternPtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct PatternIdentifier {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl PatternIdentifier {\n    pub const INDEX_MODIFIERS: usize = 0;\n    pub const INDEX_NAME: usize = 1;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        modifiers: ModifierListGreen,\n        name: TerminalIdentifierGreen,\n    ) -> PatternIdentifierGreen {\n        let children: Vec<GreenId> = vec![modifiers.0, name.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        PatternIdentifierGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::PatternIdentifier,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl PatternIdentifier {\n    pub fn modifiers(&self, db: &dyn SyntaxGroup) -> ModifierList {\n        ModifierList::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn name(&self, db: &dyn SyntaxGroup) -> TerminalIdentifier {\n        TerminalIdentifier::from_syntax_node(db, self.children[1].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct PatternIdentifierPtr(pub SyntaxStablePtrId);\nimpl PatternIdentifierPtr {\n    pub fn name_green(self, db: &dyn SyntaxGroup) -> TerminalIdentifierGreen {\n        let ptr = db.lookup_intern_stable_ptr(self.0);\n        if let SyntaxStablePtr::Child { key_fields, .. } = ptr {\n            TerminalIdentifierGreen(key_fields[0])\n        } else {\n            panic!(\"Unexpected key field query on root.\");\n        }\n    }\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct PatternIdentifierGreen(pub GreenId);\nimpl TypedSyntaxNode for PatternIdentifier {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::PatternIdentifier);\n    type StablePtr = PatternIdentifierPtr;\n    type Green = PatternIdentifierGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        PatternIdentifierGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::PatternIdentifier,\n            details: GreenNodeDetails::Node {\n                children: vec![ModifierList::missing(db).0, TerminalIdentifier::missing(db).0],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::PatternIdentifier,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::PatternIdentifier\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        PatternIdentifierPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct PatternStruct {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl PatternStruct {\n    pub const INDEX_PATH: usize = 0;\n    pub const INDEX_LBRACE: usize = 1;\n    pub const INDEX_PARAMS: usize = 2;\n    pub const INDEX_RBRACE: usize = 3;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        path: ExprPathGreen,\n        lbrace: TerminalLBraceGreen,\n        params: PatternStructParamListGreen,\n        rbrace: TerminalRBraceGreen,\n    ) -> PatternStructGreen {\n        let children: Vec<GreenId> = vec![path.0, lbrace.0, params.0, rbrace.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        PatternStructGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::PatternStruct,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl PatternStruct {\n    pub fn path(&self, db: &dyn SyntaxGroup) -> ExprPath {\n        ExprPath::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn lbrace(&self, db: &dyn SyntaxGroup) -> TerminalLBrace {\n        TerminalLBrace::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn params(&self, db: &dyn SyntaxGroup) -> PatternStructParamList {\n        PatternStructParamList::from_syntax_node(db, self.children[2].clone())\n    }\n    pub fn rbrace(&self, db: &dyn SyntaxGroup) -> TerminalRBrace {\n        TerminalRBrace::from_syntax_node(db, self.children[3].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct PatternStructPtr(pub SyntaxStablePtrId);\nimpl PatternStructPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct PatternStructGreen(pub GreenId);\nimpl TypedSyntaxNode for PatternStruct {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::PatternStruct);\n    type StablePtr = PatternStructPtr;\n    type Green = PatternStructGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        PatternStructGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::PatternStruct,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    ExprPath::missing(db).0,\n                    TerminalLBrace::missing(db).0,\n                    PatternStructParamList::missing(db).0,\n                    TerminalRBrace::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::PatternStruct,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::PatternStruct\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        PatternStructPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct PatternStructParamList(ElementList<PatternStructParam, 2>);\nimpl Deref for PatternStructParamList {\n    type Target = ElementList<PatternStructParam, 2>;\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\nimpl PatternStructParamList {\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        children: Vec<PatternStructParamListElementOrSeparatorGreen>,\n    ) -> PatternStructParamListGreen {\n        let width = children.iter().map(|id| db.lookup_intern_green(id.id()).width()).sum();\n        PatternStructParamListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::PatternStructParamList,\n            details: GreenNodeDetails::Node {\n                children: children.iter().map(|x| x.id()).collect(),\n                width,\n            },\n        }))\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct PatternStructParamListPtr(pub SyntaxStablePtrId);\nimpl PatternStructParamListPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub enum PatternStructParamListElementOrSeparatorGreen {\n    Separator(TerminalCommaGreen),\n    Element(PatternStructParamGreen),\n}\nimpl From<TerminalCommaGreen> for PatternStructParamListElementOrSeparatorGreen {\n    fn from(value: TerminalCommaGreen) -> Self {\n        PatternStructParamListElementOrSeparatorGreen::Separator(value)\n    }\n}\nimpl From<PatternStructParamGreen> for PatternStructParamListElementOrSeparatorGreen {\n    fn from(value: PatternStructParamGreen) -> Self {\n        PatternStructParamListElementOrSeparatorGreen::Element(value)\n    }\n}\nimpl PatternStructParamListElementOrSeparatorGreen {\n    fn id(&self) -> GreenId {\n        match self {\n            PatternStructParamListElementOrSeparatorGreen::Separator(green) => green.0,\n            PatternStructParamListElementOrSeparatorGreen::Element(green) => green.0,\n        }\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct PatternStructParamListGreen(pub GreenId);\nimpl TypedSyntaxNode for PatternStructParamList {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::PatternStructParamList);\n    type StablePtr = PatternStructParamListPtr;\n    type Green = PatternStructParamListGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        PatternStructParamListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::PatternStructParamList,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        Self(ElementList::new(node))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        PatternStructParamListPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct PatternTuple {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl PatternTuple {\n    pub const INDEX_LPAREN: usize = 0;\n    pub const INDEX_PATTERNS: usize = 1;\n    pub const INDEX_RPAREN: usize = 2;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        lparen: TerminalLParenGreen,\n        patterns: PatternListGreen,\n        rparen: TerminalRParenGreen,\n    ) -> PatternTupleGreen {\n        let children: Vec<GreenId> = vec![lparen.0, patterns.0, rparen.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        PatternTupleGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::PatternTuple,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl PatternTuple {\n    pub fn lparen(&self, db: &dyn SyntaxGroup) -> TerminalLParen {\n        TerminalLParen::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn patterns(&self, db: &dyn SyntaxGroup) -> PatternList {\n        PatternList::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn rparen(&self, db: &dyn SyntaxGroup) -> TerminalRParen {\n        TerminalRParen::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct PatternTuplePtr(pub SyntaxStablePtrId);\nimpl PatternTuplePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct PatternTupleGreen(pub GreenId);\nimpl TypedSyntaxNode for PatternTuple {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::PatternTuple);\n    type StablePtr = PatternTuplePtr;\n    type Green = PatternTupleGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        PatternTupleGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::PatternTuple,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    TerminalLParen::missing(db).0,\n                    PatternList::missing(db).0,\n                    TerminalRParen::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::PatternTuple,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::PatternTuple\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        PatternTuplePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct PatternList(ElementList<Pattern, 2>);\nimpl Deref for PatternList {\n    type Target = ElementList<Pattern, 2>;\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\nimpl PatternList {\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        children: Vec<PatternListElementOrSeparatorGreen>,\n    ) -> PatternListGreen {\n        let width = children.iter().map(|id| db.lookup_intern_green(id.id()).width()).sum();\n        PatternListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::PatternList,\n            details: GreenNodeDetails::Node {\n                children: children.iter().map(|x| x.id()).collect(),\n                width,\n            },\n        }))\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct PatternListPtr(pub SyntaxStablePtrId);\nimpl PatternListPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub enum PatternListElementOrSeparatorGreen {\n    Separator(TerminalCommaGreen),\n    Element(PatternGreen),\n}\nimpl From<TerminalCommaGreen> for PatternListElementOrSeparatorGreen {\n    fn from(value: TerminalCommaGreen) -> Self {\n        PatternListElementOrSeparatorGreen::Separator(value)\n    }\n}\nimpl From<PatternGreen> for PatternListElementOrSeparatorGreen {\n    fn from(value: PatternGreen) -> Self {\n        PatternListElementOrSeparatorGreen::Element(value)\n    }\n}\nimpl PatternListElementOrSeparatorGreen {\n    fn id(&self) -> GreenId {\n        match self {\n            PatternListElementOrSeparatorGreen::Separator(green) => green.0,\n            PatternListElementOrSeparatorGreen::Element(green) => green.0,\n        }\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct PatternListGreen(pub GreenId);\nimpl TypedSyntaxNode for PatternList {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::PatternList);\n    type StablePtr = PatternListPtr;\n    type Green = PatternListGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        PatternListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::PatternList,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        Self(ElementList::new(node))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        PatternListPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum PatternStructParam {\n    Single(PatternIdentifier),\n    WithExpr(PatternStructParamWithExpr),\n    Tail(TerminalDotDot),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct PatternStructParamPtr(pub SyntaxStablePtrId);\nimpl PatternStructParamPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<PatternIdentifierPtr> for PatternStructParamPtr {\n    fn from(value: PatternIdentifierPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<PatternStructParamWithExprPtr> for PatternStructParamPtr {\n    fn from(value: PatternStructParamWithExprPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalDotDotPtr> for PatternStructParamPtr {\n    fn from(value: TerminalDotDotPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<PatternIdentifierGreen> for PatternStructParamGreen {\n    fn from(value: PatternIdentifierGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<PatternStructParamWithExprGreen> for PatternStructParamGreen {\n    fn from(value: PatternStructParamWithExprGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalDotDotGreen> for PatternStructParamGreen {\n    fn from(value: TerminalDotDotGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct PatternStructParamGreen(pub GreenId);\nimpl TypedSyntaxNode for PatternStructParam {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = PatternStructParamPtr;\n    type Green = PatternStructParamGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::PatternIdentifier => {\n                PatternStructParam::Single(PatternIdentifier::from_syntax_node(db, node))\n            }\n            SyntaxKind::PatternStructParamWithExpr => {\n                PatternStructParam::WithExpr(PatternStructParamWithExpr::from_syntax_node(db, node))\n            }\n            SyntaxKind::TerminalDotDot => {\n                PatternStructParam::Tail(TerminalDotDot::from_syntax_node(db, node))\n            }\n            _ => panic!(\n                \"Unexpected syntax kind {:?} when constructing {}.\",\n                kind, \"PatternStructParam\"\n            ),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            PatternStructParam::Single(x) => x.as_syntax_node(),\n            PatternStructParam::WithExpr(x) => x.as_syntax_node(),\n            PatternStructParam::Tail(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        PatternStructParamPtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct PatternStructParamWithExpr {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl PatternStructParamWithExpr {\n    pub const INDEX_MODIFIERS: usize = 0;\n    pub const INDEX_NAME: usize = 1;\n    pub const INDEX_COLON: usize = 2;\n    pub const INDEX_PATTERN: usize = 3;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        modifiers: ModifierListGreen,\n        name: TerminalIdentifierGreen,\n        colon: TerminalColonGreen,\n        pattern: PatternGreen,\n    ) -> PatternStructParamWithExprGreen {\n        let children: Vec<GreenId> = vec![modifiers.0, name.0, colon.0, pattern.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        PatternStructParamWithExprGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::PatternStructParamWithExpr,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl PatternStructParamWithExpr {\n    pub fn modifiers(&self, db: &dyn SyntaxGroup) -> ModifierList {\n        ModifierList::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn name(&self, db: &dyn SyntaxGroup) -> TerminalIdentifier {\n        TerminalIdentifier::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn colon(&self, db: &dyn SyntaxGroup) -> TerminalColon {\n        TerminalColon::from_syntax_node(db, self.children[2].clone())\n    }\n    pub fn pattern(&self, db: &dyn SyntaxGroup) -> Pattern {\n        Pattern::from_syntax_node(db, self.children[3].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct PatternStructParamWithExprPtr(pub SyntaxStablePtrId);\nimpl PatternStructParamWithExprPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct PatternStructParamWithExprGreen(pub GreenId);\nimpl TypedSyntaxNode for PatternStructParamWithExpr {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::PatternStructParamWithExpr);\n    type StablePtr = PatternStructParamWithExprPtr;\n    type Green = PatternStructParamWithExprGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        PatternStructParamWithExprGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::PatternStructParamWithExpr,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    ModifierList::missing(db).0,\n                    TerminalIdentifier::missing(db).0,\n                    TerminalColon::missing(db).0,\n                    Pattern::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::PatternStructParamWithExpr,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::PatternStructParamWithExpr\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        PatternStructParamWithExprPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct PatternEnum {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl PatternEnum {\n    pub const INDEX_PATH: usize = 0;\n    pub const INDEX_LPAREN: usize = 1;\n    pub const INDEX_PATTERN: usize = 2;\n    pub const INDEX_RPAREN: usize = 3;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        path: ExprPathGreen,\n        lparen: TerminalLParenGreen,\n        pattern: PatternGreen,\n        rparen: TerminalRParenGreen,\n    ) -> PatternEnumGreen {\n        let children: Vec<GreenId> = vec![path.0, lparen.0, pattern.0, rparen.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        PatternEnumGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::PatternEnum,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl PatternEnum {\n    pub fn path(&self, db: &dyn SyntaxGroup) -> ExprPath {\n        ExprPath::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn lparen(&self, db: &dyn SyntaxGroup) -> TerminalLParen {\n        TerminalLParen::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn pattern(&self, db: &dyn SyntaxGroup) -> Pattern {\n        Pattern::from_syntax_node(db, self.children[2].clone())\n    }\n    pub fn rparen(&self, db: &dyn SyntaxGroup) -> TerminalRParen {\n        TerminalRParen::from_syntax_node(db, self.children[3].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct PatternEnumPtr(pub SyntaxStablePtrId);\nimpl PatternEnumPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct PatternEnumGreen(pub GreenId);\nimpl TypedSyntaxNode for PatternEnum {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::PatternEnum);\n    type StablePtr = PatternEnumPtr;\n    type Green = PatternEnumGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        PatternEnumGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::PatternEnum,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    ExprPath::missing(db).0,\n                    TerminalLParen::missing(db).0,\n                    Pattern::missing(db).0,\n                    TerminalRParen::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::PatternEnum,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::PatternEnum\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        PatternEnumPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TypeClause {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl TypeClause {\n    pub const INDEX_COLON: usize = 0;\n    pub const INDEX_TY: usize = 1;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        colon: TerminalColonGreen,\n        ty: ExprGreen,\n    ) -> TypeClauseGreen {\n        let children: Vec<GreenId> = vec![colon.0, ty.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TypeClauseGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TypeClause,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl TypeClause {\n    pub fn colon(&self, db: &dyn SyntaxGroup) -> TerminalColon {\n        TerminalColon::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn ty(&self, db: &dyn SyntaxGroup) -> Expr {\n        Expr::from_syntax_node(db, self.children[1].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TypeClausePtr(pub SyntaxStablePtrId);\nimpl TypeClausePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TypeClauseGreen(pub GreenId);\nimpl TypedSyntaxNode for TypeClause {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TypeClause);\n    type StablePtr = TypeClausePtr;\n    type Green = TypeClauseGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TypeClauseGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TypeClause,\n            details: GreenNodeDetails::Node {\n                children: vec![TerminalColon::missing(db).0, Expr::missing(db).0],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TypeClause,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TypeClause\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TypeClausePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum OptionTypeClause {\n    Empty(OptionTypeClauseEmpty),\n    TypeClause(TypeClause),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionTypeClausePtr(pub SyntaxStablePtrId);\nimpl OptionTypeClausePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<OptionTypeClauseEmptyPtr> for OptionTypeClausePtr {\n    fn from(value: OptionTypeClauseEmptyPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TypeClausePtr> for OptionTypeClausePtr {\n    fn from(value: TypeClausePtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<OptionTypeClauseEmptyGreen> for OptionTypeClauseGreen {\n    fn from(value: OptionTypeClauseEmptyGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TypeClauseGreen> for OptionTypeClauseGreen {\n    fn from(value: TypeClauseGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionTypeClauseGreen(pub GreenId);\nimpl TypedSyntaxNode for OptionTypeClause {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = OptionTypeClausePtr;\n    type Green = OptionTypeClauseGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::OptionTypeClauseEmpty => {\n                OptionTypeClause::Empty(OptionTypeClauseEmpty::from_syntax_node(db, node))\n            }\n            SyntaxKind::TypeClause => {\n                OptionTypeClause::TypeClause(TypeClause::from_syntax_node(db, node))\n            }\n            _ => panic!(\n                \"Unexpected syntax kind {:?} when constructing {}.\",\n                kind, \"OptionTypeClause\"\n            ),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            OptionTypeClause::Empty(x) => x.as_syntax_node(),\n            OptionTypeClause::TypeClause(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        OptionTypeClausePtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct OptionTypeClauseEmpty {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl OptionTypeClauseEmpty {\n    pub fn new_green(db: &dyn SyntaxGroup) -> OptionTypeClauseEmptyGreen {\n        let children: Vec<GreenId> = vec![];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        OptionTypeClauseEmptyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::OptionTypeClauseEmpty,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl OptionTypeClauseEmpty {}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionTypeClauseEmptyPtr(pub SyntaxStablePtrId);\nimpl OptionTypeClauseEmptyPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionTypeClauseEmptyGreen(pub GreenId);\nimpl TypedSyntaxNode for OptionTypeClauseEmpty {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::OptionTypeClauseEmpty);\n    type StablePtr = OptionTypeClauseEmptyPtr;\n    type Green = OptionTypeClauseEmptyGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        OptionTypeClauseEmptyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::OptionTypeClauseEmpty,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::OptionTypeClauseEmpty,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::OptionTypeClauseEmpty\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        OptionTypeClauseEmptyPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ReturnTypeClause {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ReturnTypeClause {\n    pub const INDEX_ARROW: usize = 0;\n    pub const INDEX_TY: usize = 1;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        arrow: TerminalArrowGreen,\n        ty: ExprGreen,\n    ) -> ReturnTypeClauseGreen {\n        let children: Vec<GreenId> = vec![arrow.0, ty.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ReturnTypeClauseGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ReturnTypeClause,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ReturnTypeClause {\n    pub fn arrow(&self, db: &dyn SyntaxGroup) -> TerminalArrow {\n        TerminalArrow::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn ty(&self, db: &dyn SyntaxGroup) -> Expr {\n        Expr::from_syntax_node(db, self.children[1].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ReturnTypeClausePtr(pub SyntaxStablePtrId);\nimpl ReturnTypeClausePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ReturnTypeClauseGreen(pub GreenId);\nimpl TypedSyntaxNode for ReturnTypeClause {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ReturnTypeClause);\n    type StablePtr = ReturnTypeClausePtr;\n    type Green = ReturnTypeClauseGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ReturnTypeClauseGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ReturnTypeClause,\n            details: GreenNodeDetails::Node {\n                children: vec![TerminalArrow::missing(db).0, Expr::missing(db).0],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ReturnTypeClause,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ReturnTypeClause\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ReturnTypeClausePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum OptionReturnTypeClause {\n    Empty(OptionReturnTypeClauseEmpty),\n    ReturnTypeClause(ReturnTypeClause),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionReturnTypeClausePtr(pub SyntaxStablePtrId);\nimpl OptionReturnTypeClausePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<OptionReturnTypeClauseEmptyPtr> for OptionReturnTypeClausePtr {\n    fn from(value: OptionReturnTypeClauseEmptyPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ReturnTypeClausePtr> for OptionReturnTypeClausePtr {\n    fn from(value: ReturnTypeClausePtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<OptionReturnTypeClauseEmptyGreen> for OptionReturnTypeClauseGreen {\n    fn from(value: OptionReturnTypeClauseEmptyGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ReturnTypeClauseGreen> for OptionReturnTypeClauseGreen {\n    fn from(value: ReturnTypeClauseGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionReturnTypeClauseGreen(pub GreenId);\nimpl TypedSyntaxNode for OptionReturnTypeClause {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = OptionReturnTypeClausePtr;\n    type Green = OptionReturnTypeClauseGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::OptionReturnTypeClauseEmpty => OptionReturnTypeClause::Empty(\n                OptionReturnTypeClauseEmpty::from_syntax_node(db, node),\n            ),\n            SyntaxKind::ReturnTypeClause => OptionReturnTypeClause::ReturnTypeClause(\n                ReturnTypeClause::from_syntax_node(db, node),\n            ),\n            _ => panic!(\n                \"Unexpected syntax kind {:?} when constructing {}.\",\n                kind, \"OptionReturnTypeClause\"\n            ),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            OptionReturnTypeClause::Empty(x) => x.as_syntax_node(),\n            OptionReturnTypeClause::ReturnTypeClause(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        OptionReturnTypeClausePtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct OptionReturnTypeClauseEmpty {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl OptionReturnTypeClauseEmpty {\n    pub fn new_green(db: &dyn SyntaxGroup) -> OptionReturnTypeClauseEmptyGreen {\n        let children: Vec<GreenId> = vec![];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        OptionReturnTypeClauseEmptyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::OptionReturnTypeClauseEmpty,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl OptionReturnTypeClauseEmpty {}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionReturnTypeClauseEmptyPtr(pub SyntaxStablePtrId);\nimpl OptionReturnTypeClauseEmptyPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionReturnTypeClauseEmptyGreen(pub GreenId);\nimpl TypedSyntaxNode for OptionReturnTypeClauseEmpty {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::OptionReturnTypeClauseEmpty);\n    type StablePtr = OptionReturnTypeClauseEmptyPtr;\n    type Green = OptionReturnTypeClauseEmptyGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        OptionReturnTypeClauseEmptyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::OptionReturnTypeClauseEmpty,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::OptionReturnTypeClauseEmpty,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::OptionReturnTypeClauseEmpty\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        OptionReturnTypeClauseEmptyPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum Statement {\n    Let(StatementLet),\n    Expr(StatementExpr),\n    Return(StatementReturn),\n    Missing(StatementMissing),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct StatementPtr(pub SyntaxStablePtrId);\nimpl StatementPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<StatementLetPtr> for StatementPtr {\n    fn from(value: StatementLetPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<StatementExprPtr> for StatementPtr {\n    fn from(value: StatementExprPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<StatementReturnPtr> for StatementPtr {\n    fn from(value: StatementReturnPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<StatementMissingPtr> for StatementPtr {\n    fn from(value: StatementMissingPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<StatementLetGreen> for StatementGreen {\n    fn from(value: StatementLetGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<StatementExprGreen> for StatementGreen {\n    fn from(value: StatementExprGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<StatementReturnGreen> for StatementGreen {\n    fn from(value: StatementReturnGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<StatementMissingGreen> for StatementGreen {\n    fn from(value: StatementMissingGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct StatementGreen(pub GreenId);\nimpl TypedSyntaxNode for Statement {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = StatementPtr;\n    type Green = StatementGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        StatementGreen(StatementMissing::missing(db).0)\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::StatementLet => Statement::Let(StatementLet::from_syntax_node(db, node)),\n            SyntaxKind::StatementExpr => Statement::Expr(StatementExpr::from_syntax_node(db, node)),\n            SyntaxKind::StatementReturn => {\n                Statement::Return(StatementReturn::from_syntax_node(db, node))\n            }\n            SyntaxKind::StatementMissing => {\n                Statement::Missing(StatementMissing::from_syntax_node(db, node))\n            }\n            _ => panic!(\"Unexpected syntax kind {:?} when constructing {}.\", kind, \"Statement\"),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            Statement::Let(x) => x.as_syntax_node(),\n            Statement::Expr(x) => x.as_syntax_node(),\n            Statement::Return(x) => x.as_syntax_node(),\n            Statement::Missing(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        StatementPtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct StatementList(ElementList<Statement, 1>);\nimpl Deref for StatementList {\n    type Target = ElementList<Statement, 1>;\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\nimpl StatementList {\n    pub fn new_green(db: &dyn SyntaxGroup, children: Vec<StatementGreen>) -> StatementListGreen {\n        let width = children.iter().map(|id| db.lookup_intern_green(id.0).width()).sum();\n        StatementListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::StatementList,\n            details: GreenNodeDetails::Node {\n                children: children.iter().map(|x| x.0).collect(),\n                width,\n            },\n        }))\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct StatementListPtr(pub SyntaxStablePtrId);\nimpl StatementListPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct StatementListGreen(pub GreenId);\nimpl TypedSyntaxNode for StatementList {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::StatementList);\n    type StablePtr = StatementListPtr;\n    type Green = StatementListGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        StatementListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::StatementList,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        Self(ElementList::new(node))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        StatementListPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct StatementMissing {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl StatementMissing {\n    pub fn new_green(db: &dyn SyntaxGroup) -> StatementMissingGreen {\n        let children: Vec<GreenId> = vec![];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        StatementMissingGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::StatementMissing,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl StatementMissing {}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct StatementMissingPtr(pub SyntaxStablePtrId);\nimpl StatementMissingPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct StatementMissingGreen(pub GreenId);\nimpl TypedSyntaxNode for StatementMissing {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::StatementMissing);\n    type StablePtr = StatementMissingPtr;\n    type Green = StatementMissingGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        StatementMissingGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::StatementMissing,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::StatementMissing,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::StatementMissing\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        StatementMissingPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct StatementLet {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl StatementLet {\n    pub const INDEX_LET_KW: usize = 0;\n    pub const INDEX_PATTERN: usize = 1;\n    pub const INDEX_TYPE_CLAUSE: usize = 2;\n    pub const INDEX_EQ: usize = 3;\n    pub const INDEX_RHS: usize = 4;\n    pub const INDEX_SEMICOLON: usize = 5;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        let_kw: TerminalLetGreen,\n        pattern: PatternGreen,\n        type_clause: OptionTypeClauseGreen,\n        eq: TerminalEqGreen,\n        rhs: ExprGreen,\n        semicolon: TerminalSemicolonGreen,\n    ) -> StatementLetGreen {\n        let children: Vec<GreenId> =\n            vec![let_kw.0, pattern.0, type_clause.0, eq.0, rhs.0, semicolon.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        StatementLetGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::StatementLet,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl StatementLet {\n    pub fn let_kw(&self, db: &dyn SyntaxGroup) -> TerminalLet {\n        TerminalLet::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn pattern(&self, db: &dyn SyntaxGroup) -> Pattern {\n        Pattern::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn type_clause(&self, db: &dyn SyntaxGroup) -> OptionTypeClause {\n        OptionTypeClause::from_syntax_node(db, self.children[2].clone())\n    }\n    pub fn eq(&self, db: &dyn SyntaxGroup) -> TerminalEq {\n        TerminalEq::from_syntax_node(db, self.children[3].clone())\n    }\n    pub fn rhs(&self, db: &dyn SyntaxGroup) -> Expr {\n        Expr::from_syntax_node(db, self.children[4].clone())\n    }\n    pub fn semicolon(&self, db: &dyn SyntaxGroup) -> TerminalSemicolon {\n        TerminalSemicolon::from_syntax_node(db, self.children[5].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct StatementLetPtr(pub SyntaxStablePtrId);\nimpl StatementLetPtr {\n    pub fn pattern_green(self, db: &dyn SyntaxGroup) -> PatternGreen {\n        let ptr = db.lookup_intern_stable_ptr(self.0);\n        if let SyntaxStablePtr::Child { key_fields, .. } = ptr {\n            PatternGreen(key_fields[0])\n        } else {\n            panic!(\"Unexpected key field query on root.\");\n        }\n    }\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct StatementLetGreen(pub GreenId);\nimpl TypedSyntaxNode for StatementLet {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::StatementLet);\n    type StablePtr = StatementLetPtr;\n    type Green = StatementLetGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        StatementLetGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::StatementLet,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    TerminalLet::missing(db).0,\n                    Pattern::missing(db).0,\n                    OptionTypeClause::missing(db).0,\n                    TerminalEq::missing(db).0,\n                    Expr::missing(db).0,\n                    TerminalSemicolon::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::StatementLet,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::StatementLet\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        StatementLetPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum OptionTerminalSemicolon {\n    Empty(OptionTerminalSemicolonEmpty),\n    TerminalSemicolon(TerminalSemicolon),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionTerminalSemicolonPtr(pub SyntaxStablePtrId);\nimpl OptionTerminalSemicolonPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<OptionTerminalSemicolonEmptyPtr> for OptionTerminalSemicolonPtr {\n    fn from(value: OptionTerminalSemicolonEmptyPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalSemicolonPtr> for OptionTerminalSemicolonPtr {\n    fn from(value: TerminalSemicolonPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<OptionTerminalSemicolonEmptyGreen> for OptionTerminalSemicolonGreen {\n    fn from(value: OptionTerminalSemicolonEmptyGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalSemicolonGreen> for OptionTerminalSemicolonGreen {\n    fn from(value: TerminalSemicolonGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionTerminalSemicolonGreen(pub GreenId);\nimpl TypedSyntaxNode for OptionTerminalSemicolon {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = OptionTerminalSemicolonPtr;\n    type Green = OptionTerminalSemicolonGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::OptionTerminalSemicolonEmpty => OptionTerminalSemicolon::Empty(\n                OptionTerminalSemicolonEmpty::from_syntax_node(db, node),\n            ),\n            SyntaxKind::TerminalSemicolon => OptionTerminalSemicolon::TerminalSemicolon(\n                TerminalSemicolon::from_syntax_node(db, node),\n            ),\n            _ => panic!(\n                \"Unexpected syntax kind {:?} when constructing {}.\",\n                kind, \"OptionTerminalSemicolon\"\n            ),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            OptionTerminalSemicolon::Empty(x) => x.as_syntax_node(),\n            OptionTerminalSemicolon::TerminalSemicolon(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        OptionTerminalSemicolonPtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct OptionTerminalSemicolonEmpty {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl OptionTerminalSemicolonEmpty {\n    pub fn new_green(db: &dyn SyntaxGroup) -> OptionTerminalSemicolonEmptyGreen {\n        let children: Vec<GreenId> = vec![];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        OptionTerminalSemicolonEmptyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::OptionTerminalSemicolonEmpty,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl OptionTerminalSemicolonEmpty {}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionTerminalSemicolonEmptyPtr(pub SyntaxStablePtrId);\nimpl OptionTerminalSemicolonEmptyPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionTerminalSemicolonEmptyGreen(pub GreenId);\nimpl TypedSyntaxNode for OptionTerminalSemicolonEmpty {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::OptionTerminalSemicolonEmpty);\n    type StablePtr = OptionTerminalSemicolonEmptyPtr;\n    type Green = OptionTerminalSemicolonEmptyGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        OptionTerminalSemicolonEmptyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::OptionTerminalSemicolonEmpty,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::OptionTerminalSemicolonEmpty,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::OptionTerminalSemicolonEmpty\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        OptionTerminalSemicolonEmptyPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct StatementExpr {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl StatementExpr {\n    pub const INDEX_EXPR: usize = 0;\n    pub const INDEX_SEMICOLON: usize = 1;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        expr: ExprGreen,\n        semicolon: OptionTerminalSemicolonGreen,\n    ) -> StatementExprGreen {\n        let children: Vec<GreenId> = vec![expr.0, semicolon.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        StatementExprGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::StatementExpr,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl StatementExpr {\n    pub fn expr(&self, db: &dyn SyntaxGroup) -> Expr {\n        Expr::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn semicolon(&self, db: &dyn SyntaxGroup) -> OptionTerminalSemicolon {\n        OptionTerminalSemicolon::from_syntax_node(db, self.children[1].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct StatementExprPtr(pub SyntaxStablePtrId);\nimpl StatementExprPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct StatementExprGreen(pub GreenId);\nimpl TypedSyntaxNode for StatementExpr {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::StatementExpr);\n    type StablePtr = StatementExprPtr;\n    type Green = StatementExprGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        StatementExprGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::StatementExpr,\n            details: GreenNodeDetails::Node {\n                children: vec![Expr::missing(db).0, OptionTerminalSemicolon::missing(db).0],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::StatementExpr,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::StatementExpr\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        StatementExprPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct StatementReturn {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl StatementReturn {\n    pub const INDEX_RETURN_KW: usize = 0;\n    pub const INDEX_EXPR: usize = 1;\n    pub const INDEX_SEMICOLON: usize = 2;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        return_kw: TerminalReturnGreen,\n        expr: ExprGreen,\n        semicolon: TerminalSemicolonGreen,\n    ) -> StatementReturnGreen {\n        let children: Vec<GreenId> = vec![return_kw.0, expr.0, semicolon.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        StatementReturnGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::StatementReturn,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl StatementReturn {\n    pub fn return_kw(&self, db: &dyn SyntaxGroup) -> TerminalReturn {\n        TerminalReturn::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn expr(&self, db: &dyn SyntaxGroup) -> Expr {\n        Expr::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn semicolon(&self, db: &dyn SyntaxGroup) -> TerminalSemicolon {\n        TerminalSemicolon::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct StatementReturnPtr(pub SyntaxStablePtrId);\nimpl StatementReturnPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct StatementReturnGreen(pub GreenId);\nimpl TypedSyntaxNode for StatementReturn {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::StatementReturn);\n    type StablePtr = StatementReturnPtr;\n    type Green = StatementReturnGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        StatementReturnGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::StatementReturn,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    TerminalReturn::missing(db).0,\n                    Expr::missing(db).0,\n                    TerminalSemicolon::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::StatementReturn,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::StatementReturn\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        StatementReturnPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct Param {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Param {\n    pub const INDEX_MODIFIERS: usize = 0;\n    pub const INDEX_NAME: usize = 1;\n    pub const INDEX_TYPE_CLAUSE: usize = 2;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        modifiers: ModifierListGreen,\n        name: TerminalIdentifierGreen,\n        type_clause: TypeClauseGreen,\n    ) -> ParamGreen {\n        let children: Vec<GreenId> = vec![modifiers.0, name.0, type_clause.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ParamGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::Param,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl Param {\n    pub fn modifiers(&self, db: &dyn SyntaxGroup) -> ModifierList {\n        ModifierList::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn name(&self, db: &dyn SyntaxGroup) -> TerminalIdentifier {\n        TerminalIdentifier::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn type_clause(&self, db: &dyn SyntaxGroup) -> TypeClause {\n        TypeClause::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ParamPtr(pub SyntaxStablePtrId);\nimpl ParamPtr {\n    pub fn name_green(self, db: &dyn SyntaxGroup) -> TerminalIdentifierGreen {\n        let ptr = db.lookup_intern_stable_ptr(self.0);\n        if let SyntaxStablePtr::Child { key_fields, .. } = ptr {\n            TerminalIdentifierGreen(key_fields[0])\n        } else {\n            panic!(\"Unexpected key field query on root.\");\n        }\n    }\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ParamGreen(pub GreenId);\nimpl TypedSyntaxNode for Param {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::Param);\n    type StablePtr = ParamPtr;\n    type Green = ParamGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ParamGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::Param,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    ModifierList::missing(db).0,\n                    TerminalIdentifier::missing(db).0,\n                    TypeClause::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::Param,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::Param\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ParamPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ModifierList(ElementList<Modifier, 1>);\nimpl Deref for ModifierList {\n    type Target = ElementList<Modifier, 1>;\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\nimpl ModifierList {\n    pub fn new_green(db: &dyn SyntaxGroup, children: Vec<ModifierGreen>) -> ModifierListGreen {\n        let width = children.iter().map(|id| db.lookup_intern_green(id.0).width()).sum();\n        ModifierListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ModifierList,\n            details: GreenNodeDetails::Node {\n                children: children.iter().map(|x| x.0).collect(),\n                width,\n            },\n        }))\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ModifierListPtr(pub SyntaxStablePtrId);\nimpl ModifierListPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ModifierListGreen(pub GreenId);\nimpl TypedSyntaxNode for ModifierList {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ModifierList);\n    type StablePtr = ModifierListPtr;\n    type Green = ModifierListGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ModifierListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ModifierList,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        Self(ElementList::new(node))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ModifierListPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum Modifier {\n    Ref(TerminalRef),\n    Mut(TerminalMut),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ModifierPtr(pub SyntaxStablePtrId);\nimpl ModifierPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<TerminalRefPtr> for ModifierPtr {\n    fn from(value: TerminalRefPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalMutPtr> for ModifierPtr {\n    fn from(value: TerminalMutPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalRefGreen> for ModifierGreen {\n    fn from(value: TerminalRefGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalMutGreen> for ModifierGreen {\n    fn from(value: TerminalMutGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ModifierGreen(pub GreenId);\nimpl TypedSyntaxNode for Modifier {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = ModifierPtr;\n    type Green = ModifierGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::TerminalRef => Modifier::Ref(TerminalRef::from_syntax_node(db, node)),\n            SyntaxKind::TerminalMut => Modifier::Mut(TerminalMut::from_syntax_node(db, node)),\n            _ => panic!(\"Unexpected syntax kind {:?} when constructing {}.\", kind, \"Modifier\"),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            Modifier::Ref(x) => x.as_syntax_node(),\n            Modifier::Mut(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ModifierPtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ParamList(ElementList<Param, 2>);\nimpl Deref for ParamList {\n    type Target = ElementList<Param, 2>;\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\nimpl ParamList {\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        children: Vec<ParamListElementOrSeparatorGreen>,\n    ) -> ParamListGreen {\n        let width = children.iter().map(|id| db.lookup_intern_green(id.id()).width()).sum();\n        ParamListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ParamList,\n            details: GreenNodeDetails::Node {\n                children: children.iter().map(|x| x.id()).collect(),\n                width,\n            },\n        }))\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ParamListPtr(pub SyntaxStablePtrId);\nimpl ParamListPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub enum ParamListElementOrSeparatorGreen {\n    Separator(TerminalCommaGreen),\n    Element(ParamGreen),\n}\nimpl From<TerminalCommaGreen> for ParamListElementOrSeparatorGreen {\n    fn from(value: TerminalCommaGreen) -> Self {\n        ParamListElementOrSeparatorGreen::Separator(value)\n    }\n}\nimpl From<ParamGreen> for ParamListElementOrSeparatorGreen {\n    fn from(value: ParamGreen) -> Self {\n        ParamListElementOrSeparatorGreen::Element(value)\n    }\n}\nimpl ParamListElementOrSeparatorGreen {\n    fn id(&self) -> GreenId {\n        match self {\n            ParamListElementOrSeparatorGreen::Separator(green) => green.0,\n            ParamListElementOrSeparatorGreen::Element(green) => green.0,\n        }\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ParamListGreen(pub GreenId);\nimpl TypedSyntaxNode for ParamList {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ParamList);\n    type StablePtr = ParamListPtr;\n    type Green = ParamListGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ParamListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ParamList,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        Self(ElementList::new(node))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ParamListPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ImplicitsClause {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ImplicitsClause {\n    pub const INDEX_IMPLICITS_KW: usize = 0;\n    pub const INDEX_LPAREN: usize = 1;\n    pub const INDEX_IMPLICITS: usize = 2;\n    pub const INDEX_RPAREN: usize = 3;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        implicits_kw: TerminalImplicitsGreen,\n        lparen: TerminalLParenGreen,\n        implicits: ImplicitsListGreen,\n        rparen: TerminalRParenGreen,\n    ) -> ImplicitsClauseGreen {\n        let children: Vec<GreenId> = vec![implicits_kw.0, lparen.0, implicits.0, rparen.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ImplicitsClauseGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ImplicitsClause,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ImplicitsClause {\n    pub fn implicits_kw(&self, db: &dyn SyntaxGroup) -> TerminalImplicits {\n        TerminalImplicits::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn lparen(&self, db: &dyn SyntaxGroup) -> TerminalLParen {\n        TerminalLParen::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn implicits(&self, db: &dyn SyntaxGroup) -> ImplicitsList {\n        ImplicitsList::from_syntax_node(db, self.children[2].clone())\n    }\n    pub fn rparen(&self, db: &dyn SyntaxGroup) -> TerminalRParen {\n        TerminalRParen::from_syntax_node(db, self.children[3].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ImplicitsClausePtr(pub SyntaxStablePtrId);\nimpl ImplicitsClausePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ImplicitsClauseGreen(pub GreenId);\nimpl TypedSyntaxNode for ImplicitsClause {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ImplicitsClause);\n    type StablePtr = ImplicitsClausePtr;\n    type Green = ImplicitsClauseGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ImplicitsClauseGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ImplicitsClause,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    TerminalImplicits::missing(db).0,\n                    TerminalLParen::missing(db).0,\n                    ImplicitsList::missing(db).0,\n                    TerminalRParen::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ImplicitsClause,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ImplicitsClause\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ImplicitsClausePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ImplicitsList(ElementList<ExprPath, 2>);\nimpl Deref for ImplicitsList {\n    type Target = ElementList<ExprPath, 2>;\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\nimpl ImplicitsList {\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        children: Vec<ImplicitsListElementOrSeparatorGreen>,\n    ) -> ImplicitsListGreen {\n        let width = children.iter().map(|id| db.lookup_intern_green(id.id()).width()).sum();\n        ImplicitsListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ImplicitsList,\n            details: GreenNodeDetails::Node {\n                children: children.iter().map(|x| x.id()).collect(),\n                width,\n            },\n        }))\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ImplicitsListPtr(pub SyntaxStablePtrId);\nimpl ImplicitsListPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub enum ImplicitsListElementOrSeparatorGreen {\n    Separator(TerminalCommaGreen),\n    Element(ExprPathGreen),\n}\nimpl From<TerminalCommaGreen> for ImplicitsListElementOrSeparatorGreen {\n    fn from(value: TerminalCommaGreen) -> Self {\n        ImplicitsListElementOrSeparatorGreen::Separator(value)\n    }\n}\nimpl From<ExprPathGreen> for ImplicitsListElementOrSeparatorGreen {\n    fn from(value: ExprPathGreen) -> Self {\n        ImplicitsListElementOrSeparatorGreen::Element(value)\n    }\n}\nimpl ImplicitsListElementOrSeparatorGreen {\n    fn id(&self) -> GreenId {\n        match self {\n            ImplicitsListElementOrSeparatorGreen::Separator(green) => green.0,\n            ImplicitsListElementOrSeparatorGreen::Element(green) => green.0,\n        }\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ImplicitsListGreen(pub GreenId);\nimpl TypedSyntaxNode for ImplicitsList {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ImplicitsList);\n    type StablePtr = ImplicitsListPtr;\n    type Green = ImplicitsListGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ImplicitsListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ImplicitsList,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        Self(ElementList::new(node))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ImplicitsListPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum OptionImplicitsClause {\n    Empty(OptionImplicitsClauseEmpty),\n    ImplicitsClause(ImplicitsClause),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionImplicitsClausePtr(pub SyntaxStablePtrId);\nimpl OptionImplicitsClausePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<OptionImplicitsClauseEmptyPtr> for OptionImplicitsClausePtr {\n    fn from(value: OptionImplicitsClauseEmptyPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ImplicitsClausePtr> for OptionImplicitsClausePtr {\n    fn from(value: ImplicitsClausePtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<OptionImplicitsClauseEmptyGreen> for OptionImplicitsClauseGreen {\n    fn from(value: OptionImplicitsClauseEmptyGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ImplicitsClauseGreen> for OptionImplicitsClauseGreen {\n    fn from(value: ImplicitsClauseGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionImplicitsClauseGreen(pub GreenId);\nimpl TypedSyntaxNode for OptionImplicitsClause {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = OptionImplicitsClausePtr;\n    type Green = OptionImplicitsClauseGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::OptionImplicitsClauseEmpty => {\n                OptionImplicitsClause::Empty(OptionImplicitsClauseEmpty::from_syntax_node(db, node))\n            }\n            SyntaxKind::ImplicitsClause => {\n                OptionImplicitsClause::ImplicitsClause(ImplicitsClause::from_syntax_node(db, node))\n            }\n            _ => panic!(\n                \"Unexpected syntax kind {:?} when constructing {}.\",\n                kind, \"OptionImplicitsClause\"\n            ),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            OptionImplicitsClause::Empty(x) => x.as_syntax_node(),\n            OptionImplicitsClause::ImplicitsClause(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        OptionImplicitsClausePtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct OptionImplicitsClauseEmpty {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl OptionImplicitsClauseEmpty {\n    pub fn new_green(db: &dyn SyntaxGroup) -> OptionImplicitsClauseEmptyGreen {\n        let children: Vec<GreenId> = vec![];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        OptionImplicitsClauseEmptyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::OptionImplicitsClauseEmpty,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl OptionImplicitsClauseEmpty {}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionImplicitsClauseEmptyPtr(pub SyntaxStablePtrId);\nimpl OptionImplicitsClauseEmptyPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionImplicitsClauseEmptyGreen(pub GreenId);\nimpl TypedSyntaxNode for OptionImplicitsClauseEmpty {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::OptionImplicitsClauseEmpty);\n    type StablePtr = OptionImplicitsClauseEmptyPtr;\n    type Green = OptionImplicitsClauseEmptyGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        OptionImplicitsClauseEmptyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::OptionImplicitsClauseEmpty,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::OptionImplicitsClauseEmpty,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::OptionImplicitsClauseEmpty\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        OptionImplicitsClauseEmptyPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum OptionTerminalNoPanic {\n    Empty(OptionTerminalNoPanicEmpty),\n    TerminalNoPanic(TerminalNoPanic),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionTerminalNoPanicPtr(pub SyntaxStablePtrId);\nimpl OptionTerminalNoPanicPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<OptionTerminalNoPanicEmptyPtr> for OptionTerminalNoPanicPtr {\n    fn from(value: OptionTerminalNoPanicEmptyPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalNoPanicPtr> for OptionTerminalNoPanicPtr {\n    fn from(value: TerminalNoPanicPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<OptionTerminalNoPanicEmptyGreen> for OptionTerminalNoPanicGreen {\n    fn from(value: OptionTerminalNoPanicEmptyGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalNoPanicGreen> for OptionTerminalNoPanicGreen {\n    fn from(value: TerminalNoPanicGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionTerminalNoPanicGreen(pub GreenId);\nimpl TypedSyntaxNode for OptionTerminalNoPanic {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = OptionTerminalNoPanicPtr;\n    type Green = OptionTerminalNoPanicGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::OptionTerminalNoPanicEmpty => {\n                OptionTerminalNoPanic::Empty(OptionTerminalNoPanicEmpty::from_syntax_node(db, node))\n            }\n            SyntaxKind::TerminalNoPanic => {\n                OptionTerminalNoPanic::TerminalNoPanic(TerminalNoPanic::from_syntax_node(db, node))\n            }\n            _ => panic!(\n                \"Unexpected syntax kind {:?} when constructing {}.\",\n                kind, \"OptionTerminalNoPanic\"\n            ),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            OptionTerminalNoPanic::Empty(x) => x.as_syntax_node(),\n            OptionTerminalNoPanic::TerminalNoPanic(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        OptionTerminalNoPanicPtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct OptionTerminalNoPanicEmpty {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl OptionTerminalNoPanicEmpty {\n    pub fn new_green(db: &dyn SyntaxGroup) -> OptionTerminalNoPanicEmptyGreen {\n        let children: Vec<GreenId> = vec![];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        OptionTerminalNoPanicEmptyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::OptionTerminalNoPanicEmpty,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl OptionTerminalNoPanicEmpty {}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionTerminalNoPanicEmptyPtr(pub SyntaxStablePtrId);\nimpl OptionTerminalNoPanicEmptyPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionTerminalNoPanicEmptyGreen(pub GreenId);\nimpl TypedSyntaxNode for OptionTerminalNoPanicEmpty {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::OptionTerminalNoPanicEmpty);\n    type StablePtr = OptionTerminalNoPanicEmptyPtr;\n    type Green = OptionTerminalNoPanicEmptyGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        OptionTerminalNoPanicEmptyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::OptionTerminalNoPanicEmpty,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::OptionTerminalNoPanicEmpty,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::OptionTerminalNoPanicEmpty\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        OptionTerminalNoPanicEmptyPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct FunctionSignature {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl FunctionSignature {\n    pub const INDEX_LPAREN: usize = 0;\n    pub const INDEX_PARAMETERS: usize = 1;\n    pub const INDEX_RPAREN: usize = 2;\n    pub const INDEX_RET_TY: usize = 3;\n    pub const INDEX_IMPLICITS_CLAUSE: usize = 4;\n    pub const INDEX_OPTIONAL_NO_PANIC: usize = 5;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        lparen: TerminalLParenGreen,\n        parameters: ParamListGreen,\n        rparen: TerminalRParenGreen,\n        ret_ty: OptionReturnTypeClauseGreen,\n        implicits_clause: OptionImplicitsClauseGreen,\n        optional_no_panic: OptionTerminalNoPanicGreen,\n    ) -> FunctionSignatureGreen {\n        let children: Vec<GreenId> = vec![\n            lparen.0,\n            parameters.0,\n            rparen.0,\n            ret_ty.0,\n            implicits_clause.0,\n            optional_no_panic.0,\n        ];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        FunctionSignatureGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::FunctionSignature,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl FunctionSignature {\n    pub fn lparen(&self, db: &dyn SyntaxGroup) -> TerminalLParen {\n        TerminalLParen::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn parameters(&self, db: &dyn SyntaxGroup) -> ParamList {\n        ParamList::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn rparen(&self, db: &dyn SyntaxGroup) -> TerminalRParen {\n        TerminalRParen::from_syntax_node(db, self.children[2].clone())\n    }\n    pub fn ret_ty(&self, db: &dyn SyntaxGroup) -> OptionReturnTypeClause {\n        OptionReturnTypeClause::from_syntax_node(db, self.children[3].clone())\n    }\n    pub fn implicits_clause(&self, db: &dyn SyntaxGroup) -> OptionImplicitsClause {\n        OptionImplicitsClause::from_syntax_node(db, self.children[4].clone())\n    }\n    pub fn optional_no_panic(&self, db: &dyn SyntaxGroup) -> OptionTerminalNoPanic {\n        OptionTerminalNoPanic::from_syntax_node(db, self.children[5].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct FunctionSignaturePtr(pub SyntaxStablePtrId);\nimpl FunctionSignaturePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct FunctionSignatureGreen(pub GreenId);\nimpl TypedSyntaxNode for FunctionSignature {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::FunctionSignature);\n    type StablePtr = FunctionSignaturePtr;\n    type Green = FunctionSignatureGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        FunctionSignatureGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::FunctionSignature,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    TerminalLParen::missing(db).0,\n                    ParamList::missing(db).0,\n                    TerminalRParen::missing(db).0,\n                    OptionReturnTypeClause::missing(db).0,\n                    OptionImplicitsClause::missing(db).0,\n                    OptionTerminalNoPanic::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::FunctionSignature,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::FunctionSignature\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        FunctionSignaturePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct Member {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Member {\n    pub const INDEX_NAME: usize = 0;\n    pub const INDEX_TYPE_CLAUSE: usize = 1;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        name: TerminalIdentifierGreen,\n        type_clause: TypeClauseGreen,\n    ) -> MemberGreen {\n        let children: Vec<GreenId> = vec![name.0, type_clause.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        MemberGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::Member,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl Member {\n    pub fn name(&self, db: &dyn SyntaxGroup) -> TerminalIdentifier {\n        TerminalIdentifier::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn type_clause(&self, db: &dyn SyntaxGroup) -> TypeClause {\n        TypeClause::from_syntax_node(db, self.children[1].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct MemberPtr(pub SyntaxStablePtrId);\nimpl MemberPtr {\n    pub fn name_green(self, db: &dyn SyntaxGroup) -> TerminalIdentifierGreen {\n        let ptr = db.lookup_intern_stable_ptr(self.0);\n        if let SyntaxStablePtr::Child { key_fields, .. } = ptr {\n            TerminalIdentifierGreen(key_fields[0])\n        } else {\n            panic!(\"Unexpected key field query on root.\");\n        }\n    }\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct MemberGreen(pub GreenId);\nimpl TypedSyntaxNode for Member {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::Member);\n    type StablePtr = MemberPtr;\n    type Green = MemberGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        MemberGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::Member,\n            details: GreenNodeDetails::Node {\n                children: vec![TerminalIdentifier::missing(db).0, TypeClause::missing(db).0],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::Member,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::Member\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        MemberPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct MemberList(ElementList<Member, 2>);\nimpl Deref for MemberList {\n    type Target = ElementList<Member, 2>;\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\nimpl MemberList {\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        children: Vec<MemberListElementOrSeparatorGreen>,\n    ) -> MemberListGreen {\n        let width = children.iter().map(|id| db.lookup_intern_green(id.id()).width()).sum();\n        MemberListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::MemberList,\n            details: GreenNodeDetails::Node {\n                children: children.iter().map(|x| x.id()).collect(),\n                width,\n            },\n        }))\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct MemberListPtr(pub SyntaxStablePtrId);\nimpl MemberListPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub enum MemberListElementOrSeparatorGreen {\n    Separator(TerminalCommaGreen),\n    Element(MemberGreen),\n}\nimpl From<TerminalCommaGreen> for MemberListElementOrSeparatorGreen {\n    fn from(value: TerminalCommaGreen) -> Self {\n        MemberListElementOrSeparatorGreen::Separator(value)\n    }\n}\nimpl From<MemberGreen> for MemberListElementOrSeparatorGreen {\n    fn from(value: MemberGreen) -> Self {\n        MemberListElementOrSeparatorGreen::Element(value)\n    }\n}\nimpl MemberListElementOrSeparatorGreen {\n    fn id(&self) -> GreenId {\n        match self {\n            MemberListElementOrSeparatorGreen::Separator(green) => green.0,\n            MemberListElementOrSeparatorGreen::Element(green) => green.0,\n        }\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct MemberListGreen(pub GreenId);\nimpl TypedSyntaxNode for MemberList {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::MemberList);\n    type StablePtr = MemberListPtr;\n    type Green = MemberListGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        MemberListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::MemberList,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        Self(ElementList::new(node))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        MemberListPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum Item {\n    Constant(ItemConstant),\n    Module(ItemModule),\n    Use(ItemUse),\n    FreeFunction(FunctionWithBody),\n    ExternFunction(ItemExternFunction),\n    ExternType(ItemExternType),\n    Trait(ItemTrait),\n    Impl(ItemImpl),\n    Struct(ItemStruct),\n    Enum(ItemEnum),\n    TypeAlias(ItemTypeAlias),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ItemPtr(pub SyntaxStablePtrId);\nimpl ItemPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<ItemConstantPtr> for ItemPtr {\n    fn from(value: ItemConstantPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ItemModulePtr> for ItemPtr {\n    fn from(value: ItemModulePtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ItemUsePtr> for ItemPtr {\n    fn from(value: ItemUsePtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<FunctionWithBodyPtr> for ItemPtr {\n    fn from(value: FunctionWithBodyPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ItemExternFunctionPtr> for ItemPtr {\n    fn from(value: ItemExternFunctionPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ItemExternTypePtr> for ItemPtr {\n    fn from(value: ItemExternTypePtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ItemTraitPtr> for ItemPtr {\n    fn from(value: ItemTraitPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ItemImplPtr> for ItemPtr {\n    fn from(value: ItemImplPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ItemStructPtr> for ItemPtr {\n    fn from(value: ItemStructPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ItemEnumPtr> for ItemPtr {\n    fn from(value: ItemEnumPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ItemTypeAliasPtr> for ItemPtr {\n    fn from(value: ItemTypeAliasPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ItemConstantGreen> for ItemGreen {\n    fn from(value: ItemConstantGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ItemModuleGreen> for ItemGreen {\n    fn from(value: ItemModuleGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ItemUseGreen> for ItemGreen {\n    fn from(value: ItemUseGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<FunctionWithBodyGreen> for ItemGreen {\n    fn from(value: FunctionWithBodyGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ItemExternFunctionGreen> for ItemGreen {\n    fn from(value: ItemExternFunctionGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ItemExternTypeGreen> for ItemGreen {\n    fn from(value: ItemExternTypeGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ItemTraitGreen> for ItemGreen {\n    fn from(value: ItemTraitGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ItemImplGreen> for ItemGreen {\n    fn from(value: ItemImplGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ItemStructGreen> for ItemGreen {\n    fn from(value: ItemStructGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ItemEnumGreen> for ItemGreen {\n    fn from(value: ItemEnumGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ItemTypeAliasGreen> for ItemGreen {\n    fn from(value: ItemTypeAliasGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ItemGreen(pub GreenId);\nimpl TypedSyntaxNode for Item {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = ItemPtr;\n    type Green = ItemGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::ItemConstant => Item::Constant(ItemConstant::from_syntax_node(db, node)),\n            SyntaxKind::ItemModule => Item::Module(ItemModule::from_syntax_node(db, node)),\n            SyntaxKind::ItemUse => Item::Use(ItemUse::from_syntax_node(db, node)),\n            SyntaxKind::FunctionWithBody => {\n                Item::FreeFunction(FunctionWithBody::from_syntax_node(db, node))\n            }\n            SyntaxKind::ItemExternFunction => {\n                Item::ExternFunction(ItemExternFunction::from_syntax_node(db, node))\n            }\n            SyntaxKind::ItemExternType => {\n                Item::ExternType(ItemExternType::from_syntax_node(db, node))\n            }\n            SyntaxKind::ItemTrait => Item::Trait(ItemTrait::from_syntax_node(db, node)),\n            SyntaxKind::ItemImpl => Item::Impl(ItemImpl::from_syntax_node(db, node)),\n            SyntaxKind::ItemStruct => Item::Struct(ItemStruct::from_syntax_node(db, node)),\n            SyntaxKind::ItemEnum => Item::Enum(ItemEnum::from_syntax_node(db, node)),\n            SyntaxKind::ItemTypeAlias => Item::TypeAlias(ItemTypeAlias::from_syntax_node(db, node)),\n            _ => panic!(\"Unexpected syntax kind {:?} when constructing {}.\", kind, \"Item\"),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            Item::Constant(x) => x.as_syntax_node(),\n            Item::Module(x) => x.as_syntax_node(),\n            Item::Use(x) => x.as_syntax_node(),\n            Item::FreeFunction(x) => x.as_syntax_node(),\n            Item::ExternFunction(x) => x.as_syntax_node(),\n            Item::ExternType(x) => x.as_syntax_node(),\n            Item::Trait(x) => x.as_syntax_node(),\n            Item::Impl(x) => x.as_syntax_node(),\n            Item::Struct(x) => x.as_syntax_node(),\n            Item::Enum(x) => x.as_syntax_node(),\n            Item::TypeAlias(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ItemPtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ItemList(ElementList<Item, 1>);\nimpl Deref for ItemList {\n    type Target = ElementList<Item, 1>;\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\nimpl ItemList {\n    pub fn new_green(db: &dyn SyntaxGroup, children: Vec<ItemGreen>) -> ItemListGreen {\n        let width = children.iter().map(|id| db.lookup_intern_green(id.0).width()).sum();\n        ItemListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ItemList,\n            details: GreenNodeDetails::Node {\n                children: children.iter().map(|x| x.0).collect(),\n                width,\n            },\n        }))\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ItemListPtr(pub SyntaxStablePtrId);\nimpl ItemListPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ItemListGreen(pub GreenId);\nimpl TypedSyntaxNode for ItemList {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ItemList);\n    type StablePtr = ItemListPtr;\n    type Green = ItemListGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ItemListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ItemList,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        Self(ElementList::new(node))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ItemListPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct Attribute {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Attribute {\n    pub const INDEX_HASH: usize = 0;\n    pub const INDEX_LBRACK: usize = 1;\n    pub const INDEX_ATTR: usize = 2;\n    pub const INDEX_ARGS: usize = 3;\n    pub const INDEX_RBRACK: usize = 4;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        hash: TerminalHashGreen,\n        lbrack: TerminalLBrackGreen,\n        attr: TerminalIdentifierGreen,\n        args: OptionAttributeArgsGreen,\n        rbrack: TerminalRBrackGreen,\n    ) -> AttributeGreen {\n        let children: Vec<GreenId> = vec![hash.0, lbrack.0, attr.0, args.0, rbrack.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        AttributeGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::Attribute,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl Attribute {\n    pub fn hash(&self, db: &dyn SyntaxGroup) -> TerminalHash {\n        TerminalHash::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn lbrack(&self, db: &dyn SyntaxGroup) -> TerminalLBrack {\n        TerminalLBrack::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn attr(&self, db: &dyn SyntaxGroup) -> TerminalIdentifier {\n        TerminalIdentifier::from_syntax_node(db, self.children[2].clone())\n    }\n    pub fn args(&self, db: &dyn SyntaxGroup) -> OptionAttributeArgs {\n        OptionAttributeArgs::from_syntax_node(db, self.children[3].clone())\n    }\n    pub fn rbrack(&self, db: &dyn SyntaxGroup) -> TerminalRBrack {\n        TerminalRBrack::from_syntax_node(db, self.children[4].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct AttributePtr(pub SyntaxStablePtrId);\nimpl AttributePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct AttributeGreen(pub GreenId);\nimpl TypedSyntaxNode for Attribute {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::Attribute);\n    type StablePtr = AttributePtr;\n    type Green = AttributeGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        AttributeGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::Attribute,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    TerminalHash::missing(db).0,\n                    TerminalLBrack::missing(db).0,\n                    TerminalIdentifier::missing(db).0,\n                    OptionAttributeArgs::missing(db).0,\n                    TerminalRBrack::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::Attribute,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::Attribute\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        AttributePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct AttributeList(ElementList<Attribute, 1>);\nimpl Deref for AttributeList {\n    type Target = ElementList<Attribute, 1>;\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\nimpl AttributeList {\n    pub fn new_green(db: &dyn SyntaxGroup, children: Vec<AttributeGreen>) -> AttributeListGreen {\n        let width = children.iter().map(|id| db.lookup_intern_green(id.0).width()).sum();\n        AttributeListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::AttributeList,\n            details: GreenNodeDetails::Node {\n                children: children.iter().map(|x| x.0).collect(),\n                width,\n            },\n        }))\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct AttributeListPtr(pub SyntaxStablePtrId);\nimpl AttributeListPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct AttributeListGreen(pub GreenId);\nimpl TypedSyntaxNode for AttributeList {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::AttributeList);\n    type StablePtr = AttributeListPtr;\n    type Green = AttributeListGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        AttributeListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::AttributeList,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        Self(ElementList::new(node))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        AttributeListPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ItemModule {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ItemModule {\n    pub const INDEX_ATTRIBUTES: usize = 0;\n    pub const INDEX_MODULE_KW: usize = 1;\n    pub const INDEX_NAME: usize = 2;\n    pub const INDEX_BODY: usize = 3;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        attributes: AttributeListGreen,\n        module_kw: TerminalModuleGreen,\n        name: TerminalIdentifierGreen,\n        body: MaybeModuleBodyGreen,\n    ) -> ItemModuleGreen {\n        let children: Vec<GreenId> = vec![attributes.0, module_kw.0, name.0, body.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ItemModuleGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ItemModule,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ItemModule {\n    pub fn attributes(&self, db: &dyn SyntaxGroup) -> AttributeList {\n        AttributeList::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn module_kw(&self, db: &dyn SyntaxGroup) -> TerminalModule {\n        TerminalModule::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn name(&self, db: &dyn SyntaxGroup) -> TerminalIdentifier {\n        TerminalIdentifier::from_syntax_node(db, self.children[2].clone())\n    }\n    pub fn body(&self, db: &dyn SyntaxGroup) -> MaybeModuleBody {\n        MaybeModuleBody::from_syntax_node(db, self.children[3].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ItemModulePtr(pub SyntaxStablePtrId);\nimpl ItemModulePtr {\n    pub fn name_green(self, db: &dyn SyntaxGroup) -> TerminalIdentifierGreen {\n        let ptr = db.lookup_intern_stable_ptr(self.0);\n        if let SyntaxStablePtr::Child { key_fields, .. } = ptr {\n            TerminalIdentifierGreen(key_fields[0])\n        } else {\n            panic!(\"Unexpected key field query on root.\");\n        }\n    }\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ItemModuleGreen(pub GreenId);\nimpl TypedSyntaxNode for ItemModule {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ItemModule);\n    type StablePtr = ItemModulePtr;\n    type Green = ItemModuleGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ItemModuleGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ItemModule,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    AttributeList::missing(db).0,\n                    TerminalModule::missing(db).0,\n                    TerminalIdentifier::missing(db).0,\n                    MaybeModuleBody::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ItemModule,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ItemModule\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ItemModulePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum MaybeModuleBody {\n    Some(ModuleBody),\n    None(TerminalSemicolon),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct MaybeModuleBodyPtr(pub SyntaxStablePtrId);\nimpl MaybeModuleBodyPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<ModuleBodyPtr> for MaybeModuleBodyPtr {\n    fn from(value: ModuleBodyPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalSemicolonPtr> for MaybeModuleBodyPtr {\n    fn from(value: TerminalSemicolonPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ModuleBodyGreen> for MaybeModuleBodyGreen {\n    fn from(value: ModuleBodyGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalSemicolonGreen> for MaybeModuleBodyGreen {\n    fn from(value: TerminalSemicolonGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct MaybeModuleBodyGreen(pub GreenId);\nimpl TypedSyntaxNode for MaybeModuleBody {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = MaybeModuleBodyPtr;\n    type Green = MaybeModuleBodyGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::ModuleBody => MaybeModuleBody::Some(ModuleBody::from_syntax_node(db, node)),\n            SyntaxKind::TerminalSemicolon => {\n                MaybeModuleBody::None(TerminalSemicolon::from_syntax_node(db, node))\n            }\n            _ => {\n                panic!(\"Unexpected syntax kind {:?} when constructing {}.\", kind, \"MaybeModuleBody\")\n            }\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            MaybeModuleBody::Some(x) => x.as_syntax_node(),\n            MaybeModuleBody::None(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        MaybeModuleBodyPtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ModuleBody {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ModuleBody {\n    pub const INDEX_LBRACE: usize = 0;\n    pub const INDEX_ITEMS: usize = 1;\n    pub const INDEX_RBRACE: usize = 2;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        lbrace: TerminalLBraceGreen,\n        items: ItemListGreen,\n        rbrace: TerminalRBraceGreen,\n    ) -> ModuleBodyGreen {\n        let children: Vec<GreenId> = vec![lbrace.0, items.0, rbrace.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ModuleBodyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ModuleBody,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ModuleBody {\n    pub fn lbrace(&self, db: &dyn SyntaxGroup) -> TerminalLBrace {\n        TerminalLBrace::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn items(&self, db: &dyn SyntaxGroup) -> ItemList {\n        ItemList::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn rbrace(&self, db: &dyn SyntaxGroup) -> TerminalRBrace {\n        TerminalRBrace::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ModuleBodyPtr(pub SyntaxStablePtrId);\nimpl ModuleBodyPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ModuleBodyGreen(pub GreenId);\nimpl TypedSyntaxNode for ModuleBody {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ModuleBody);\n    type StablePtr = ModuleBodyPtr;\n    type Green = ModuleBodyGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ModuleBodyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ModuleBody,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    TerminalLBrace::missing(db).0,\n                    ItemList::missing(db).0,\n                    TerminalRBrace::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ModuleBody,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ModuleBody\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ModuleBodyPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum OptionAttributeArgs {\n    Empty(OptionAttributeArgsEmpty),\n    AttributeArgs(AttributeArgs),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionAttributeArgsPtr(pub SyntaxStablePtrId);\nimpl OptionAttributeArgsPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<OptionAttributeArgsEmptyPtr> for OptionAttributeArgsPtr {\n    fn from(value: OptionAttributeArgsEmptyPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<AttributeArgsPtr> for OptionAttributeArgsPtr {\n    fn from(value: AttributeArgsPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<OptionAttributeArgsEmptyGreen> for OptionAttributeArgsGreen {\n    fn from(value: OptionAttributeArgsEmptyGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<AttributeArgsGreen> for OptionAttributeArgsGreen {\n    fn from(value: AttributeArgsGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionAttributeArgsGreen(pub GreenId);\nimpl TypedSyntaxNode for OptionAttributeArgs {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = OptionAttributeArgsPtr;\n    type Green = OptionAttributeArgsGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::OptionAttributeArgsEmpty => {\n                OptionAttributeArgs::Empty(OptionAttributeArgsEmpty::from_syntax_node(db, node))\n            }\n            SyntaxKind::AttributeArgs => {\n                OptionAttributeArgs::AttributeArgs(AttributeArgs::from_syntax_node(db, node))\n            }\n            _ => panic!(\n                \"Unexpected syntax kind {:?} when constructing {}.\",\n                kind, \"OptionAttributeArgs\"\n            ),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            OptionAttributeArgs::Empty(x) => x.as_syntax_node(),\n            OptionAttributeArgs::AttributeArgs(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        OptionAttributeArgsPtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct OptionAttributeArgsEmpty {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl OptionAttributeArgsEmpty {\n    pub fn new_green(db: &dyn SyntaxGroup) -> OptionAttributeArgsEmptyGreen {\n        let children: Vec<GreenId> = vec![];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        OptionAttributeArgsEmptyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::OptionAttributeArgsEmpty,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl OptionAttributeArgsEmpty {}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionAttributeArgsEmptyPtr(pub SyntaxStablePtrId);\nimpl OptionAttributeArgsEmptyPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionAttributeArgsEmptyGreen(pub GreenId);\nimpl TypedSyntaxNode for OptionAttributeArgsEmpty {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::OptionAttributeArgsEmpty);\n    type StablePtr = OptionAttributeArgsEmptyPtr;\n    type Green = OptionAttributeArgsEmptyGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        OptionAttributeArgsEmptyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::OptionAttributeArgsEmpty,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::OptionAttributeArgsEmpty,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::OptionAttributeArgsEmpty\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        OptionAttributeArgsEmptyPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct AttributeArgs {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl AttributeArgs {\n    pub const INDEX_LPAREN: usize = 0;\n    pub const INDEX_ARG_LIST: usize = 1;\n    pub const INDEX_RPAREN: usize = 2;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        lparen: TerminalLParenGreen,\n        arg_list: AttributeArgListGreen,\n        rparen: TerminalRParenGreen,\n    ) -> AttributeArgsGreen {\n        let children: Vec<GreenId> = vec![lparen.0, arg_list.0, rparen.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        AttributeArgsGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::AttributeArgs,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl AttributeArgs {\n    pub fn lparen(&self, db: &dyn SyntaxGroup) -> TerminalLParen {\n        TerminalLParen::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn arg_list(&self, db: &dyn SyntaxGroup) -> AttributeArgList {\n        AttributeArgList::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn rparen(&self, db: &dyn SyntaxGroup) -> TerminalRParen {\n        TerminalRParen::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct AttributeArgsPtr(pub SyntaxStablePtrId);\nimpl AttributeArgsPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct AttributeArgsGreen(pub GreenId);\nimpl TypedSyntaxNode for AttributeArgs {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::AttributeArgs);\n    type StablePtr = AttributeArgsPtr;\n    type Green = AttributeArgsGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        AttributeArgsGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::AttributeArgs,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    TerminalLParen::missing(db).0,\n                    AttributeArgList::missing(db).0,\n                    TerminalRParen::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::AttributeArgs,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::AttributeArgs\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        AttributeArgsPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct AttributeArgList(ElementList<Expr, 2>);\nimpl Deref for AttributeArgList {\n    type Target = ElementList<Expr, 2>;\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\nimpl AttributeArgList {\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        children: Vec<AttributeArgListElementOrSeparatorGreen>,\n    ) -> AttributeArgListGreen {\n        let width = children.iter().map(|id| db.lookup_intern_green(id.id()).width()).sum();\n        AttributeArgListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::AttributeArgList,\n            details: GreenNodeDetails::Node {\n                children: children.iter().map(|x| x.id()).collect(),\n                width,\n            },\n        }))\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct AttributeArgListPtr(pub SyntaxStablePtrId);\nimpl AttributeArgListPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub enum AttributeArgListElementOrSeparatorGreen {\n    Separator(TerminalCommaGreen),\n    Element(ExprGreen),\n}\nimpl From<TerminalCommaGreen> for AttributeArgListElementOrSeparatorGreen {\n    fn from(value: TerminalCommaGreen) -> Self {\n        AttributeArgListElementOrSeparatorGreen::Separator(value)\n    }\n}\nimpl From<ExprGreen> for AttributeArgListElementOrSeparatorGreen {\n    fn from(value: ExprGreen) -> Self {\n        AttributeArgListElementOrSeparatorGreen::Element(value)\n    }\n}\nimpl AttributeArgListElementOrSeparatorGreen {\n    fn id(&self) -> GreenId {\n        match self {\n            AttributeArgListElementOrSeparatorGreen::Separator(green) => green.0,\n            AttributeArgListElementOrSeparatorGreen::Element(green) => green.0,\n        }\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct AttributeArgListGreen(pub GreenId);\nimpl TypedSyntaxNode for AttributeArgList {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::AttributeArgList);\n    type StablePtr = AttributeArgListPtr;\n    type Green = AttributeArgListGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        AttributeArgListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::AttributeArgList,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        Self(ElementList::new(node))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        AttributeArgListPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct FunctionDeclaration {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl FunctionDeclaration {\n    pub const INDEX_FUNCTION_KW: usize = 0;\n    pub const INDEX_NAME: usize = 1;\n    pub const INDEX_GENERIC_PARAMS: usize = 2;\n    pub const INDEX_SIGNATURE: usize = 3;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        function_kw: TerminalFunctionGreen,\n        name: TerminalIdentifierGreen,\n        generic_params: OptionWrappedGenericParamListGreen,\n        signature: FunctionSignatureGreen,\n    ) -> FunctionDeclarationGreen {\n        let children: Vec<GreenId> = vec![function_kw.0, name.0, generic_params.0, signature.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        FunctionDeclarationGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::FunctionDeclaration,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl FunctionDeclaration {\n    pub fn function_kw(&self, db: &dyn SyntaxGroup) -> TerminalFunction {\n        TerminalFunction::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn name(&self, db: &dyn SyntaxGroup) -> TerminalIdentifier {\n        TerminalIdentifier::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn generic_params(&self, db: &dyn SyntaxGroup) -> OptionWrappedGenericParamList {\n        OptionWrappedGenericParamList::from_syntax_node(db, self.children[2].clone())\n    }\n    pub fn signature(&self, db: &dyn SyntaxGroup) -> FunctionSignature {\n        FunctionSignature::from_syntax_node(db, self.children[3].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct FunctionDeclarationPtr(pub SyntaxStablePtrId);\nimpl FunctionDeclarationPtr {\n    pub fn name_green(self, db: &dyn SyntaxGroup) -> TerminalIdentifierGreen {\n        let ptr = db.lookup_intern_stable_ptr(self.0);\n        if let SyntaxStablePtr::Child { key_fields, .. } = ptr {\n            TerminalIdentifierGreen(key_fields[0])\n        } else {\n            panic!(\"Unexpected key field query on root.\");\n        }\n    }\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct FunctionDeclarationGreen(pub GreenId);\nimpl TypedSyntaxNode for FunctionDeclaration {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::FunctionDeclaration);\n    type StablePtr = FunctionDeclarationPtr;\n    type Green = FunctionDeclarationGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        FunctionDeclarationGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::FunctionDeclaration,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    TerminalFunction::missing(db).0,\n                    TerminalIdentifier::missing(db).0,\n                    OptionWrappedGenericParamList::missing(db).0,\n                    FunctionSignature::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::FunctionDeclaration,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::FunctionDeclaration\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        FunctionDeclarationPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ItemConstant {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ItemConstant {\n    pub const INDEX_ATTRIBUTES: usize = 0;\n    pub const INDEX_CONST_KW: usize = 1;\n    pub const INDEX_NAME: usize = 2;\n    pub const INDEX_TYPE_CLAUSE: usize = 3;\n    pub const INDEX_EQ: usize = 4;\n    pub const INDEX_VALUE: usize = 5;\n    pub const INDEX_SEMICOLON: usize = 6;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        attributes: AttributeListGreen,\n        const_kw: TerminalConstGreen,\n        name: TerminalIdentifierGreen,\n        type_clause: TypeClauseGreen,\n        eq: TerminalEqGreen,\n        value: ExprGreen,\n        semicolon: TerminalSemicolonGreen,\n    ) -> ItemConstantGreen {\n        let children: Vec<GreenId> =\n            vec![attributes.0, const_kw.0, name.0, type_clause.0, eq.0, value.0, semicolon.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ItemConstantGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ItemConstant,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ItemConstant {\n    pub fn attributes(&self, db: &dyn SyntaxGroup) -> AttributeList {\n        AttributeList::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn const_kw(&self, db: &dyn SyntaxGroup) -> TerminalConst {\n        TerminalConst::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn name(&self, db: &dyn SyntaxGroup) -> TerminalIdentifier {\n        TerminalIdentifier::from_syntax_node(db, self.children[2].clone())\n    }\n    pub fn type_clause(&self, db: &dyn SyntaxGroup) -> TypeClause {\n        TypeClause::from_syntax_node(db, self.children[3].clone())\n    }\n    pub fn eq(&self, db: &dyn SyntaxGroup) -> TerminalEq {\n        TerminalEq::from_syntax_node(db, self.children[4].clone())\n    }\n    pub fn value(&self, db: &dyn SyntaxGroup) -> Expr {\n        Expr::from_syntax_node(db, self.children[5].clone())\n    }\n    pub fn semicolon(&self, db: &dyn SyntaxGroup) -> TerminalSemicolon {\n        TerminalSemicolon::from_syntax_node(db, self.children[6].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ItemConstantPtr(pub SyntaxStablePtrId);\nimpl ItemConstantPtr {\n    pub fn name_green(self, db: &dyn SyntaxGroup) -> TerminalIdentifierGreen {\n        let ptr = db.lookup_intern_stable_ptr(self.0);\n        if let SyntaxStablePtr::Child { key_fields, .. } = ptr {\n            TerminalIdentifierGreen(key_fields[0])\n        } else {\n            panic!(\"Unexpected key field query on root.\");\n        }\n    }\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ItemConstantGreen(pub GreenId);\nimpl TypedSyntaxNode for ItemConstant {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ItemConstant);\n    type StablePtr = ItemConstantPtr;\n    type Green = ItemConstantGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ItemConstantGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ItemConstant,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    AttributeList::missing(db).0,\n                    TerminalConst::missing(db).0,\n                    TerminalIdentifier::missing(db).0,\n                    TypeClause::missing(db).0,\n                    TerminalEq::missing(db).0,\n                    Expr::missing(db).0,\n                    TerminalSemicolon::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ItemConstant,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ItemConstant\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ItemConstantPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct FunctionWithBody {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl FunctionWithBody {\n    pub const INDEX_ATTRIBUTES: usize = 0;\n    pub const INDEX_DECLARATION: usize = 1;\n    pub const INDEX_BODY: usize = 2;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        attributes: AttributeListGreen,\n        declaration: FunctionDeclarationGreen,\n        body: ExprBlockGreen,\n    ) -> FunctionWithBodyGreen {\n        let children: Vec<GreenId> = vec![attributes.0, declaration.0, body.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        FunctionWithBodyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::FunctionWithBody,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl FunctionWithBody {\n    pub fn attributes(&self, db: &dyn SyntaxGroup) -> AttributeList {\n        AttributeList::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn declaration(&self, db: &dyn SyntaxGroup) -> FunctionDeclaration {\n        FunctionDeclaration::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn body(&self, db: &dyn SyntaxGroup) -> ExprBlock {\n        ExprBlock::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct FunctionWithBodyPtr(pub SyntaxStablePtrId);\nimpl FunctionWithBodyPtr {\n    pub fn declaration_green(self, db: &dyn SyntaxGroup) -> FunctionDeclarationGreen {\n        let ptr = db.lookup_intern_stable_ptr(self.0);\n        if let SyntaxStablePtr::Child { key_fields, .. } = ptr {\n            FunctionDeclarationGreen(key_fields[0])\n        } else {\n            panic!(\"Unexpected key field query on root.\");\n        }\n    }\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct FunctionWithBodyGreen(pub GreenId);\nimpl TypedSyntaxNode for FunctionWithBody {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::FunctionWithBody);\n    type StablePtr = FunctionWithBodyPtr;\n    type Green = FunctionWithBodyGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        FunctionWithBodyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::FunctionWithBody,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    AttributeList::missing(db).0,\n                    FunctionDeclaration::missing(db).0,\n                    ExprBlock::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::FunctionWithBody,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::FunctionWithBody\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        FunctionWithBodyPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ItemExternFunction {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ItemExternFunction {\n    pub const INDEX_ATTRIBUTES: usize = 0;\n    pub const INDEX_EXTERN_KW: usize = 1;\n    pub const INDEX_DECLARATION: usize = 2;\n    pub const INDEX_SEMICOLON: usize = 3;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        attributes: AttributeListGreen,\n        extern_kw: TerminalExternGreen,\n        declaration: FunctionDeclarationGreen,\n        semicolon: TerminalSemicolonGreen,\n    ) -> ItemExternFunctionGreen {\n        let children: Vec<GreenId> = vec![attributes.0, extern_kw.0, declaration.0, semicolon.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ItemExternFunctionGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ItemExternFunction,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ItemExternFunction {\n    pub fn attributes(&self, db: &dyn SyntaxGroup) -> AttributeList {\n        AttributeList::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn extern_kw(&self, db: &dyn SyntaxGroup) -> TerminalExtern {\n        TerminalExtern::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn declaration(&self, db: &dyn SyntaxGroup) -> FunctionDeclaration {\n        FunctionDeclaration::from_syntax_node(db, self.children[2].clone())\n    }\n    pub fn semicolon(&self, db: &dyn SyntaxGroup) -> TerminalSemicolon {\n        TerminalSemicolon::from_syntax_node(db, self.children[3].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ItemExternFunctionPtr(pub SyntaxStablePtrId);\nimpl ItemExternFunctionPtr {\n    pub fn declaration_green(self, db: &dyn SyntaxGroup) -> FunctionDeclarationGreen {\n        let ptr = db.lookup_intern_stable_ptr(self.0);\n        if let SyntaxStablePtr::Child { key_fields, .. } = ptr {\n            FunctionDeclarationGreen(key_fields[0])\n        } else {\n            panic!(\"Unexpected key field query on root.\");\n        }\n    }\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ItemExternFunctionGreen(pub GreenId);\nimpl TypedSyntaxNode for ItemExternFunction {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ItemExternFunction);\n    type StablePtr = ItemExternFunctionPtr;\n    type Green = ItemExternFunctionGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ItemExternFunctionGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ItemExternFunction,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    AttributeList::missing(db).0,\n                    TerminalExtern::missing(db).0,\n                    FunctionDeclaration::missing(db).0,\n                    TerminalSemicolon::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ItemExternFunction,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ItemExternFunction\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ItemExternFunctionPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ItemExternType {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ItemExternType {\n    pub const INDEX_ATTRIBUTES: usize = 0;\n    pub const INDEX_EXTERN_KW: usize = 1;\n    pub const INDEX_TYPE_KW: usize = 2;\n    pub const INDEX_NAME: usize = 3;\n    pub const INDEX_GENERIC_PARAMS: usize = 4;\n    pub const INDEX_SEMICOLON: usize = 5;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        attributes: AttributeListGreen,\n        extern_kw: TerminalExternGreen,\n        type_kw: TerminalTypeGreen,\n        name: TerminalIdentifierGreen,\n        generic_params: OptionWrappedGenericParamListGreen,\n        semicolon: TerminalSemicolonGreen,\n    ) -> ItemExternTypeGreen {\n        let children: Vec<GreenId> =\n            vec![attributes.0, extern_kw.0, type_kw.0, name.0, generic_params.0, semicolon.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ItemExternTypeGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ItemExternType,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ItemExternType {\n    pub fn attributes(&self, db: &dyn SyntaxGroup) -> AttributeList {\n        AttributeList::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn extern_kw(&self, db: &dyn SyntaxGroup) -> TerminalExtern {\n        TerminalExtern::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn type_kw(&self, db: &dyn SyntaxGroup) -> TerminalType {\n        TerminalType::from_syntax_node(db, self.children[2].clone())\n    }\n    pub fn name(&self, db: &dyn SyntaxGroup) -> TerminalIdentifier {\n        TerminalIdentifier::from_syntax_node(db, self.children[3].clone())\n    }\n    pub fn generic_params(&self, db: &dyn SyntaxGroup) -> OptionWrappedGenericParamList {\n        OptionWrappedGenericParamList::from_syntax_node(db, self.children[4].clone())\n    }\n    pub fn semicolon(&self, db: &dyn SyntaxGroup) -> TerminalSemicolon {\n        TerminalSemicolon::from_syntax_node(db, self.children[5].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ItemExternTypePtr(pub SyntaxStablePtrId);\nimpl ItemExternTypePtr {\n    pub fn name_green(self, db: &dyn SyntaxGroup) -> TerminalIdentifierGreen {\n        let ptr = db.lookup_intern_stable_ptr(self.0);\n        if let SyntaxStablePtr::Child { key_fields, .. } = ptr {\n            TerminalIdentifierGreen(key_fields[0])\n        } else {\n            panic!(\"Unexpected key field query on root.\");\n        }\n    }\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ItemExternTypeGreen(pub GreenId);\nimpl TypedSyntaxNode for ItemExternType {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ItemExternType);\n    type StablePtr = ItemExternTypePtr;\n    type Green = ItemExternTypeGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ItemExternTypeGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ItemExternType,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    AttributeList::missing(db).0,\n                    TerminalExtern::missing(db).0,\n                    TerminalType::missing(db).0,\n                    TerminalIdentifier::missing(db).0,\n                    OptionWrappedGenericParamList::missing(db).0,\n                    TerminalSemicolon::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ItemExternType,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ItemExternType\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ItemExternTypePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ItemTrait {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ItemTrait {\n    pub const INDEX_ATTRIBUTES: usize = 0;\n    pub const INDEX_TRAIT_KW: usize = 1;\n    pub const INDEX_NAME: usize = 2;\n    pub const INDEX_GENERIC_PARAMS: usize = 3;\n    pub const INDEX_BODY: usize = 4;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        attributes: AttributeListGreen,\n        trait_kw: TerminalTraitGreen,\n        name: TerminalIdentifierGreen,\n        generic_params: OptionWrappedGenericParamListGreen,\n        body: MaybeTraitBodyGreen,\n    ) -> ItemTraitGreen {\n        let children: Vec<GreenId> =\n            vec![attributes.0, trait_kw.0, name.0, generic_params.0, body.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ItemTraitGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ItemTrait,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ItemTrait {\n    pub fn attributes(&self, db: &dyn SyntaxGroup) -> AttributeList {\n        AttributeList::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn trait_kw(&self, db: &dyn SyntaxGroup) -> TerminalTrait {\n        TerminalTrait::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn name(&self, db: &dyn SyntaxGroup) -> TerminalIdentifier {\n        TerminalIdentifier::from_syntax_node(db, self.children[2].clone())\n    }\n    pub fn generic_params(&self, db: &dyn SyntaxGroup) -> OptionWrappedGenericParamList {\n        OptionWrappedGenericParamList::from_syntax_node(db, self.children[3].clone())\n    }\n    pub fn body(&self, db: &dyn SyntaxGroup) -> MaybeTraitBody {\n        MaybeTraitBody::from_syntax_node(db, self.children[4].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ItemTraitPtr(pub SyntaxStablePtrId);\nimpl ItemTraitPtr {\n    pub fn name_green(self, db: &dyn SyntaxGroup) -> TerminalIdentifierGreen {\n        let ptr = db.lookup_intern_stable_ptr(self.0);\n        if let SyntaxStablePtr::Child { key_fields, .. } = ptr {\n            TerminalIdentifierGreen(key_fields[0])\n        } else {\n            panic!(\"Unexpected key field query on root.\");\n        }\n    }\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ItemTraitGreen(pub GreenId);\nimpl TypedSyntaxNode for ItemTrait {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ItemTrait);\n    type StablePtr = ItemTraitPtr;\n    type Green = ItemTraitGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ItemTraitGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ItemTrait,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    AttributeList::missing(db).0,\n                    TerminalTrait::missing(db).0,\n                    TerminalIdentifier::missing(db).0,\n                    OptionWrappedGenericParamList::missing(db).0,\n                    MaybeTraitBody::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ItemTrait,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ItemTrait\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ItemTraitPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum MaybeTraitBody {\n    Some(TraitBody),\n    None(TerminalSemicolon),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct MaybeTraitBodyPtr(pub SyntaxStablePtrId);\nimpl MaybeTraitBodyPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<TraitBodyPtr> for MaybeTraitBodyPtr {\n    fn from(value: TraitBodyPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalSemicolonPtr> for MaybeTraitBodyPtr {\n    fn from(value: TerminalSemicolonPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TraitBodyGreen> for MaybeTraitBodyGreen {\n    fn from(value: TraitBodyGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalSemicolonGreen> for MaybeTraitBodyGreen {\n    fn from(value: TerminalSemicolonGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct MaybeTraitBodyGreen(pub GreenId);\nimpl TypedSyntaxNode for MaybeTraitBody {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = MaybeTraitBodyPtr;\n    type Green = MaybeTraitBodyGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::TraitBody => MaybeTraitBody::Some(TraitBody::from_syntax_node(db, node)),\n            SyntaxKind::TerminalSemicolon => {\n                MaybeTraitBody::None(TerminalSemicolon::from_syntax_node(db, node))\n            }\n            _ => {\n                panic!(\"Unexpected syntax kind {:?} when constructing {}.\", kind, \"MaybeTraitBody\")\n            }\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            MaybeTraitBody::Some(x) => x.as_syntax_node(),\n            MaybeTraitBody::None(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        MaybeTraitBodyPtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TraitBody {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl TraitBody {\n    pub const INDEX_LBRACE: usize = 0;\n    pub const INDEX_ITEMS: usize = 1;\n    pub const INDEX_RBRACE: usize = 2;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        lbrace: TerminalLBraceGreen,\n        items: TraitItemListGreen,\n        rbrace: TerminalRBraceGreen,\n    ) -> TraitBodyGreen {\n        let children: Vec<GreenId> = vec![lbrace.0, items.0, rbrace.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TraitBodyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TraitBody,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl TraitBody {\n    pub fn lbrace(&self, db: &dyn SyntaxGroup) -> TerminalLBrace {\n        TerminalLBrace::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn items(&self, db: &dyn SyntaxGroup) -> TraitItemList {\n        TraitItemList::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn rbrace(&self, db: &dyn SyntaxGroup) -> TerminalRBrace {\n        TerminalRBrace::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TraitBodyPtr(pub SyntaxStablePtrId);\nimpl TraitBodyPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TraitBodyGreen(pub GreenId);\nimpl TypedSyntaxNode for TraitBody {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TraitBody);\n    type StablePtr = TraitBodyPtr;\n    type Green = TraitBodyGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TraitBodyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TraitBody,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    TerminalLBrace::missing(db).0,\n                    TraitItemList::missing(db).0,\n                    TerminalRBrace::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TraitBody,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TraitBody\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TraitBodyPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TraitItemList(ElementList<TraitItem, 1>);\nimpl Deref for TraitItemList {\n    type Target = ElementList<TraitItem, 1>;\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\nimpl TraitItemList {\n    pub fn new_green(db: &dyn SyntaxGroup, children: Vec<TraitItemGreen>) -> TraitItemListGreen {\n        let width = children.iter().map(|id| db.lookup_intern_green(id.0).width()).sum();\n        TraitItemListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TraitItemList,\n            details: GreenNodeDetails::Node {\n                children: children.iter().map(|x| x.0).collect(),\n                width,\n            },\n        }))\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TraitItemListPtr(pub SyntaxStablePtrId);\nimpl TraitItemListPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TraitItemListGreen(pub GreenId);\nimpl TypedSyntaxNode for TraitItemList {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TraitItemList);\n    type StablePtr = TraitItemListPtr;\n    type Green = TraitItemListGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TraitItemListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TraitItemList,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        Self(ElementList::new(node))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TraitItemListPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum TraitItem {\n    Function(TraitItemFunction),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TraitItemPtr(pub SyntaxStablePtrId);\nimpl TraitItemPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<TraitItemFunctionPtr> for TraitItemPtr {\n    fn from(value: TraitItemFunctionPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TraitItemFunctionGreen> for TraitItemGreen {\n    fn from(value: TraitItemFunctionGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TraitItemGreen(pub GreenId);\nimpl TypedSyntaxNode for TraitItem {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = TraitItemPtr;\n    type Green = TraitItemGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::TraitItemFunction => {\n                TraitItem::Function(TraitItemFunction::from_syntax_node(db, node))\n            }\n            _ => panic!(\"Unexpected syntax kind {:?} when constructing {}.\", kind, \"TraitItem\"),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            TraitItem::Function(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TraitItemPtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TraitItemFunction {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl TraitItemFunction {\n    pub const INDEX_ATTRIBUTES: usize = 0;\n    pub const INDEX_DECLARATION: usize = 1;\n    pub const INDEX_BODY: usize = 2;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        attributes: AttributeListGreen,\n        declaration: FunctionDeclarationGreen,\n        body: MaybeTraitFunctionBodyGreen,\n    ) -> TraitItemFunctionGreen {\n        let children: Vec<GreenId> = vec![attributes.0, declaration.0, body.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TraitItemFunctionGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TraitItemFunction,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl TraitItemFunction {\n    pub fn attributes(&self, db: &dyn SyntaxGroup) -> AttributeList {\n        AttributeList::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn declaration(&self, db: &dyn SyntaxGroup) -> FunctionDeclaration {\n        FunctionDeclaration::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn body(&self, db: &dyn SyntaxGroup) -> MaybeTraitFunctionBody {\n        MaybeTraitFunctionBody::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TraitItemFunctionPtr(pub SyntaxStablePtrId);\nimpl TraitItemFunctionPtr {\n    pub fn declaration_green(self, db: &dyn SyntaxGroup) -> FunctionDeclarationGreen {\n        let ptr = db.lookup_intern_stable_ptr(self.0);\n        if let SyntaxStablePtr::Child { key_fields, .. } = ptr {\n            FunctionDeclarationGreen(key_fields[0])\n        } else {\n            panic!(\"Unexpected key field query on root.\");\n        }\n    }\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TraitItemFunctionGreen(pub GreenId);\nimpl TypedSyntaxNode for TraitItemFunction {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TraitItemFunction);\n    type StablePtr = TraitItemFunctionPtr;\n    type Green = TraitItemFunctionGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TraitItemFunctionGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TraitItemFunction,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    AttributeList::missing(db).0,\n                    FunctionDeclaration::missing(db).0,\n                    MaybeTraitFunctionBody::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TraitItemFunction,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TraitItemFunction\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TraitItemFunctionPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum MaybeTraitFunctionBody {\n    Some(ExprBlock),\n    None(TerminalSemicolon),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct MaybeTraitFunctionBodyPtr(pub SyntaxStablePtrId);\nimpl MaybeTraitFunctionBodyPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<ExprBlockPtr> for MaybeTraitFunctionBodyPtr {\n    fn from(value: ExprBlockPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalSemicolonPtr> for MaybeTraitFunctionBodyPtr {\n    fn from(value: TerminalSemicolonPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ExprBlockGreen> for MaybeTraitFunctionBodyGreen {\n    fn from(value: ExprBlockGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalSemicolonGreen> for MaybeTraitFunctionBodyGreen {\n    fn from(value: TerminalSemicolonGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct MaybeTraitFunctionBodyGreen(pub GreenId);\nimpl TypedSyntaxNode for MaybeTraitFunctionBody {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = MaybeTraitFunctionBodyPtr;\n    type Green = MaybeTraitFunctionBodyGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::ExprBlock => {\n                MaybeTraitFunctionBody::Some(ExprBlock::from_syntax_node(db, node))\n            }\n            SyntaxKind::TerminalSemicolon => {\n                MaybeTraitFunctionBody::None(TerminalSemicolon::from_syntax_node(db, node))\n            }\n            _ => panic!(\n                \"Unexpected syntax kind {:?} when constructing {}.\",\n                kind, \"MaybeTraitFunctionBody\"\n            ),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            MaybeTraitFunctionBody::Some(x) => x.as_syntax_node(),\n            MaybeTraitFunctionBody::None(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        MaybeTraitFunctionBodyPtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ItemImpl {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ItemImpl {\n    pub const INDEX_ATTRIBUTES: usize = 0;\n    pub const INDEX_IMPL_KW: usize = 1;\n    pub const INDEX_NAME: usize = 2;\n    pub const INDEX_GENERIC_PARAMS: usize = 3;\n    pub const INDEX_OF_KW: usize = 4;\n    pub const INDEX_TRAIT_PATH: usize = 5;\n    pub const INDEX_BODY: usize = 6;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        attributes: AttributeListGreen,\n        impl_kw: TerminalImplGreen,\n        name: TerminalIdentifierGreen,\n        generic_params: OptionWrappedGenericParamListGreen,\n        of_kw: TerminalOfGreen,\n        trait_path: ExprPathGreen,\n        body: MaybeImplBodyGreen,\n    ) -> ItemImplGreen {\n        let children: Vec<GreenId> =\n            vec![attributes.0, impl_kw.0, name.0, generic_params.0, of_kw.0, trait_path.0, body.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ItemImplGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ItemImpl,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ItemImpl {\n    pub fn attributes(&self, db: &dyn SyntaxGroup) -> AttributeList {\n        AttributeList::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn impl_kw(&self, db: &dyn SyntaxGroup) -> TerminalImpl {\n        TerminalImpl::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn name(&self, db: &dyn SyntaxGroup) -> TerminalIdentifier {\n        TerminalIdentifier::from_syntax_node(db, self.children[2].clone())\n    }\n    pub fn generic_params(&self, db: &dyn SyntaxGroup) -> OptionWrappedGenericParamList {\n        OptionWrappedGenericParamList::from_syntax_node(db, self.children[3].clone())\n    }\n    pub fn of_kw(&self, db: &dyn SyntaxGroup) -> TerminalOf {\n        TerminalOf::from_syntax_node(db, self.children[4].clone())\n    }\n    pub fn trait_path(&self, db: &dyn SyntaxGroup) -> ExprPath {\n        ExprPath::from_syntax_node(db, self.children[5].clone())\n    }\n    pub fn body(&self, db: &dyn SyntaxGroup) -> MaybeImplBody {\n        MaybeImplBody::from_syntax_node(db, self.children[6].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ItemImplPtr(pub SyntaxStablePtrId);\nimpl ItemImplPtr {\n    pub fn name_green(self, db: &dyn SyntaxGroup) -> TerminalIdentifierGreen {\n        let ptr = db.lookup_intern_stable_ptr(self.0);\n        if let SyntaxStablePtr::Child { key_fields, .. } = ptr {\n            TerminalIdentifierGreen(key_fields[0])\n        } else {\n            panic!(\"Unexpected key field query on root.\");\n        }\n    }\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ItemImplGreen(pub GreenId);\nimpl TypedSyntaxNode for ItemImpl {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ItemImpl);\n    type StablePtr = ItemImplPtr;\n    type Green = ItemImplGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ItemImplGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ItemImpl,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    AttributeList::missing(db).0,\n                    TerminalImpl::missing(db).0,\n                    TerminalIdentifier::missing(db).0,\n                    OptionWrappedGenericParamList::missing(db).0,\n                    TerminalOf::missing(db).0,\n                    ExprPath::missing(db).0,\n                    MaybeImplBody::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ItemImpl,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ItemImpl\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ItemImplPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum MaybeImplBody {\n    Some(ImplBody),\n    None(TerminalSemicolon),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct MaybeImplBodyPtr(pub SyntaxStablePtrId);\nimpl MaybeImplBodyPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<ImplBodyPtr> for MaybeImplBodyPtr {\n    fn from(value: ImplBodyPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalSemicolonPtr> for MaybeImplBodyPtr {\n    fn from(value: TerminalSemicolonPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<ImplBodyGreen> for MaybeImplBodyGreen {\n    fn from(value: ImplBodyGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalSemicolonGreen> for MaybeImplBodyGreen {\n    fn from(value: TerminalSemicolonGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct MaybeImplBodyGreen(pub GreenId);\nimpl TypedSyntaxNode for MaybeImplBody {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = MaybeImplBodyPtr;\n    type Green = MaybeImplBodyGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::ImplBody => MaybeImplBody::Some(ImplBody::from_syntax_node(db, node)),\n            SyntaxKind::TerminalSemicolon => {\n                MaybeImplBody::None(TerminalSemicolon::from_syntax_node(db, node))\n            }\n            _ => panic!(\"Unexpected syntax kind {:?} when constructing {}.\", kind, \"MaybeImplBody\"),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            MaybeImplBody::Some(x) => x.as_syntax_node(),\n            MaybeImplBody::None(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        MaybeImplBodyPtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ImplBody {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ImplBody {\n    pub const INDEX_LBRACE: usize = 0;\n    pub const INDEX_ITEMS: usize = 1;\n    pub const INDEX_RBRACE: usize = 2;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        lbrace: TerminalLBraceGreen,\n        items: ItemListGreen,\n        rbrace: TerminalRBraceGreen,\n    ) -> ImplBodyGreen {\n        let children: Vec<GreenId> = vec![lbrace.0, items.0, rbrace.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ImplBodyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ImplBody,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ImplBody {\n    pub fn lbrace(&self, db: &dyn SyntaxGroup) -> TerminalLBrace {\n        TerminalLBrace::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn items(&self, db: &dyn SyntaxGroup) -> ItemList {\n        ItemList::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn rbrace(&self, db: &dyn SyntaxGroup) -> TerminalRBrace {\n        TerminalRBrace::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ImplBodyPtr(pub SyntaxStablePtrId);\nimpl ImplBodyPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ImplBodyGreen(pub GreenId);\nimpl TypedSyntaxNode for ImplBody {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ImplBody);\n    type StablePtr = ImplBodyPtr;\n    type Green = ImplBodyGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ImplBodyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ImplBody,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    TerminalLBrace::missing(db).0,\n                    ItemList::missing(db).0,\n                    TerminalRBrace::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ImplBody,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ImplBody\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ImplBodyPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ItemStruct {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ItemStruct {\n    pub const INDEX_ATTRIBUTES: usize = 0;\n    pub const INDEX_STRUCT_KW: usize = 1;\n    pub const INDEX_NAME: usize = 2;\n    pub const INDEX_GENERIC_PARAMS: usize = 3;\n    pub const INDEX_LBRACE: usize = 4;\n    pub const INDEX_MEMBERS: usize = 5;\n    pub const INDEX_RBRACE: usize = 6;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        attributes: AttributeListGreen,\n        struct_kw: TerminalStructGreen,\n        name: TerminalIdentifierGreen,\n        generic_params: OptionWrappedGenericParamListGreen,\n        lbrace: TerminalLBraceGreen,\n        members: MemberListGreen,\n        rbrace: TerminalRBraceGreen,\n    ) -> ItemStructGreen {\n        let children: Vec<GreenId> = vec![\n            attributes.0,\n            struct_kw.0,\n            name.0,\n            generic_params.0,\n            lbrace.0,\n            members.0,\n            rbrace.0,\n        ];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ItemStructGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ItemStruct,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ItemStruct {\n    pub fn attributes(&self, db: &dyn SyntaxGroup) -> AttributeList {\n        AttributeList::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn struct_kw(&self, db: &dyn SyntaxGroup) -> TerminalStruct {\n        TerminalStruct::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn name(&self, db: &dyn SyntaxGroup) -> TerminalIdentifier {\n        TerminalIdentifier::from_syntax_node(db, self.children[2].clone())\n    }\n    pub fn generic_params(&self, db: &dyn SyntaxGroup) -> OptionWrappedGenericParamList {\n        OptionWrappedGenericParamList::from_syntax_node(db, self.children[3].clone())\n    }\n    pub fn lbrace(&self, db: &dyn SyntaxGroup) -> TerminalLBrace {\n        TerminalLBrace::from_syntax_node(db, self.children[4].clone())\n    }\n    pub fn members(&self, db: &dyn SyntaxGroup) -> MemberList {\n        MemberList::from_syntax_node(db, self.children[5].clone())\n    }\n    pub fn rbrace(&self, db: &dyn SyntaxGroup) -> TerminalRBrace {\n        TerminalRBrace::from_syntax_node(db, self.children[6].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ItemStructPtr(pub SyntaxStablePtrId);\nimpl ItemStructPtr {\n    pub fn name_green(self, db: &dyn SyntaxGroup) -> TerminalIdentifierGreen {\n        let ptr = db.lookup_intern_stable_ptr(self.0);\n        if let SyntaxStablePtr::Child { key_fields, .. } = ptr {\n            TerminalIdentifierGreen(key_fields[0])\n        } else {\n            panic!(\"Unexpected key field query on root.\");\n        }\n    }\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ItemStructGreen(pub GreenId);\nimpl TypedSyntaxNode for ItemStruct {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ItemStruct);\n    type StablePtr = ItemStructPtr;\n    type Green = ItemStructGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ItemStructGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ItemStruct,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    AttributeList::missing(db).0,\n                    TerminalStruct::missing(db).0,\n                    TerminalIdentifier::missing(db).0,\n                    OptionWrappedGenericParamList::missing(db).0,\n                    TerminalLBrace::missing(db).0,\n                    MemberList::missing(db).0,\n                    TerminalRBrace::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ItemStruct,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ItemStruct\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ItemStructPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ItemEnum {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ItemEnum {\n    pub const INDEX_ATTRIBUTES: usize = 0;\n    pub const INDEX_ENUM_KW: usize = 1;\n    pub const INDEX_NAME: usize = 2;\n    pub const INDEX_GENERIC_PARAMS: usize = 3;\n    pub const INDEX_LBRACE: usize = 4;\n    pub const INDEX_VARIANTS: usize = 5;\n    pub const INDEX_RBRACE: usize = 6;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        attributes: AttributeListGreen,\n        enum_kw: TerminalEnumGreen,\n        name: TerminalIdentifierGreen,\n        generic_params: OptionWrappedGenericParamListGreen,\n        lbrace: TerminalLBraceGreen,\n        variants: MemberListGreen,\n        rbrace: TerminalRBraceGreen,\n    ) -> ItemEnumGreen {\n        let children: Vec<GreenId> =\n            vec![attributes.0, enum_kw.0, name.0, generic_params.0, lbrace.0, variants.0, rbrace.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ItemEnumGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ItemEnum,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ItemEnum {\n    pub fn attributes(&self, db: &dyn SyntaxGroup) -> AttributeList {\n        AttributeList::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn enum_kw(&self, db: &dyn SyntaxGroup) -> TerminalEnum {\n        TerminalEnum::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn name(&self, db: &dyn SyntaxGroup) -> TerminalIdentifier {\n        TerminalIdentifier::from_syntax_node(db, self.children[2].clone())\n    }\n    pub fn generic_params(&self, db: &dyn SyntaxGroup) -> OptionWrappedGenericParamList {\n        OptionWrappedGenericParamList::from_syntax_node(db, self.children[3].clone())\n    }\n    pub fn lbrace(&self, db: &dyn SyntaxGroup) -> TerminalLBrace {\n        TerminalLBrace::from_syntax_node(db, self.children[4].clone())\n    }\n    pub fn variants(&self, db: &dyn SyntaxGroup) -> MemberList {\n        MemberList::from_syntax_node(db, self.children[5].clone())\n    }\n    pub fn rbrace(&self, db: &dyn SyntaxGroup) -> TerminalRBrace {\n        TerminalRBrace::from_syntax_node(db, self.children[6].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ItemEnumPtr(pub SyntaxStablePtrId);\nimpl ItemEnumPtr {\n    pub fn name_green(self, db: &dyn SyntaxGroup) -> TerminalIdentifierGreen {\n        let ptr = db.lookup_intern_stable_ptr(self.0);\n        if let SyntaxStablePtr::Child { key_fields, .. } = ptr {\n            TerminalIdentifierGreen(key_fields[0])\n        } else {\n            panic!(\"Unexpected key field query on root.\");\n        }\n    }\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ItemEnumGreen(pub GreenId);\nimpl TypedSyntaxNode for ItemEnum {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ItemEnum);\n    type StablePtr = ItemEnumPtr;\n    type Green = ItemEnumGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ItemEnumGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ItemEnum,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    AttributeList::missing(db).0,\n                    TerminalEnum::missing(db).0,\n                    TerminalIdentifier::missing(db).0,\n                    OptionWrappedGenericParamList::missing(db).0,\n                    TerminalLBrace::missing(db).0,\n                    MemberList::missing(db).0,\n                    TerminalRBrace::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ItemEnum,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ItemEnum\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ItemEnumPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ItemTypeAlias {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ItemTypeAlias {\n    pub const INDEX_ATTRIBUTES: usize = 0;\n    pub const INDEX_TYPE_KW: usize = 1;\n    pub const INDEX_NAME: usize = 2;\n    pub const INDEX_GENERIC_PARAMS: usize = 3;\n    pub const INDEX_EQ: usize = 4;\n    pub const INDEX_TY: usize = 5;\n    pub const INDEX_SEMICOLON: usize = 6;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        attributes: AttributeListGreen,\n        type_kw: TerminalTypeGreen,\n        name: TerminalIdentifierGreen,\n        generic_params: OptionWrappedGenericParamListGreen,\n        eq: TerminalEqGreen,\n        ty: ExprGreen,\n        semicolon: TerminalSemicolonGreen,\n    ) -> ItemTypeAliasGreen {\n        let children: Vec<GreenId> =\n            vec![attributes.0, type_kw.0, name.0, generic_params.0, eq.0, ty.0, semicolon.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ItemTypeAliasGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ItemTypeAlias,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ItemTypeAlias {\n    pub fn attributes(&self, db: &dyn SyntaxGroup) -> AttributeList {\n        AttributeList::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn type_kw(&self, db: &dyn SyntaxGroup) -> TerminalType {\n        TerminalType::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn name(&self, db: &dyn SyntaxGroup) -> TerminalIdentifier {\n        TerminalIdentifier::from_syntax_node(db, self.children[2].clone())\n    }\n    pub fn generic_params(&self, db: &dyn SyntaxGroup) -> OptionWrappedGenericParamList {\n        OptionWrappedGenericParamList::from_syntax_node(db, self.children[3].clone())\n    }\n    pub fn eq(&self, db: &dyn SyntaxGroup) -> TerminalEq {\n        TerminalEq::from_syntax_node(db, self.children[4].clone())\n    }\n    pub fn ty(&self, db: &dyn SyntaxGroup) -> Expr {\n        Expr::from_syntax_node(db, self.children[5].clone())\n    }\n    pub fn semicolon(&self, db: &dyn SyntaxGroup) -> TerminalSemicolon {\n        TerminalSemicolon::from_syntax_node(db, self.children[6].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ItemTypeAliasPtr(pub SyntaxStablePtrId);\nimpl ItemTypeAliasPtr {\n    pub fn name_green(self, db: &dyn SyntaxGroup) -> TerminalIdentifierGreen {\n        let ptr = db.lookup_intern_stable_ptr(self.0);\n        if let SyntaxStablePtr::Child { key_fields, .. } = ptr {\n            TerminalIdentifierGreen(key_fields[0])\n        } else {\n            panic!(\"Unexpected key field query on root.\");\n        }\n    }\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ItemTypeAliasGreen(pub GreenId);\nimpl TypedSyntaxNode for ItemTypeAlias {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ItemTypeAlias);\n    type StablePtr = ItemTypeAliasPtr;\n    type Green = ItemTypeAliasGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ItemTypeAliasGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ItemTypeAlias,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    AttributeList::missing(db).0,\n                    TerminalType::missing(db).0,\n                    TerminalIdentifier::missing(db).0,\n                    OptionWrappedGenericParamList::missing(db).0,\n                    TerminalEq::missing(db).0,\n                    Expr::missing(db).0,\n                    TerminalSemicolon::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ItemTypeAlias,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ItemTypeAlias\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ItemTypeAliasPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ItemUse {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl ItemUse {\n    pub const INDEX_ATTRIBUTES: usize = 0;\n    pub const INDEX_USE_KW: usize = 1;\n    pub const INDEX_NAME: usize = 2;\n    pub const INDEX_SEMICOLON: usize = 3;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        attributes: AttributeListGreen,\n        use_kw: TerminalUseGreen,\n        name: ExprPathGreen,\n        semicolon: TerminalSemicolonGreen,\n    ) -> ItemUseGreen {\n        let children: Vec<GreenId> = vec![attributes.0, use_kw.0, name.0, semicolon.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        ItemUseGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ItemUse,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl ItemUse {\n    pub fn attributes(&self, db: &dyn SyntaxGroup) -> AttributeList {\n        AttributeList::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn use_kw(&self, db: &dyn SyntaxGroup) -> TerminalUse {\n        TerminalUse::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn name(&self, db: &dyn SyntaxGroup) -> ExprPath {\n        ExprPath::from_syntax_node(db, self.children[2].clone())\n    }\n    pub fn semicolon(&self, db: &dyn SyntaxGroup) -> TerminalSemicolon {\n        TerminalSemicolon::from_syntax_node(db, self.children[3].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ItemUsePtr(pub SyntaxStablePtrId);\nimpl ItemUsePtr {\n    pub fn name_green(self, db: &dyn SyntaxGroup) -> ExprPathGreen {\n        let ptr = db.lookup_intern_stable_ptr(self.0);\n        if let SyntaxStablePtr::Child { key_fields, .. } = ptr {\n            ExprPathGreen(key_fields[0])\n        } else {\n            panic!(\"Unexpected key field query on root.\");\n        }\n    }\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct ItemUseGreen(pub GreenId);\nimpl TypedSyntaxNode for ItemUse {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::ItemUse);\n    type StablePtr = ItemUsePtr;\n    type Green = ItemUseGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        ItemUseGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::ItemUse,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    AttributeList::missing(db).0,\n                    TerminalUse::missing(db).0,\n                    ExprPath::missing(db).0,\n                    TerminalSemicolon::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::ItemUse,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::ItemUse\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        ItemUsePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct GenericArgExpr {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl GenericArgExpr {\n    pub const INDEX_VALUE: usize = 0;\n    pub fn new_green(db: &dyn SyntaxGroup, value: ExprGreen) -> GenericArgExprGreen {\n        let children: Vec<GreenId> = vec![value.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        GenericArgExprGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::GenericArgExpr,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl GenericArgExpr {\n    pub fn value(&self, db: &dyn SyntaxGroup) -> Expr {\n        Expr::from_syntax_node(db, self.children[0].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct GenericArgExprPtr(pub SyntaxStablePtrId);\nimpl GenericArgExprPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct GenericArgExprGreen(pub GreenId);\nimpl TypedSyntaxNode for GenericArgExpr {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::GenericArgExpr);\n    type StablePtr = GenericArgExprPtr;\n    type Green = GenericArgExprGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        GenericArgExprGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::GenericArgExpr,\n            details: GreenNodeDetails::Node {\n                children: vec![Expr::missing(db).0],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::GenericArgExpr,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::GenericArgExpr\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        GenericArgExprPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum GenericArg {\n    Underscore(TerminalUnderscore),\n    Expr(GenericArgExpr),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct GenericArgPtr(pub SyntaxStablePtrId);\nimpl GenericArgPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<TerminalUnderscorePtr> for GenericArgPtr {\n    fn from(value: TerminalUnderscorePtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<GenericArgExprPtr> for GenericArgPtr {\n    fn from(value: GenericArgExprPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<TerminalUnderscoreGreen> for GenericArgGreen {\n    fn from(value: TerminalUnderscoreGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<GenericArgExprGreen> for GenericArgGreen {\n    fn from(value: GenericArgExprGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct GenericArgGreen(pub GreenId);\nimpl TypedSyntaxNode for GenericArg {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = GenericArgPtr;\n    type Green = GenericArgGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::TerminalUnderscore => {\n                GenericArg::Underscore(TerminalUnderscore::from_syntax_node(db, node))\n            }\n            SyntaxKind::GenericArgExpr => {\n                GenericArg::Expr(GenericArgExpr::from_syntax_node(db, node))\n            }\n            _ => panic!(\"Unexpected syntax kind {:?} when constructing {}.\", kind, \"GenericArg\"),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            GenericArg::Underscore(x) => x.as_syntax_node(),\n            GenericArg::Expr(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        GenericArgPtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct GenericArgs {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl GenericArgs {\n    pub const INDEX_LANGLE: usize = 0;\n    pub const INDEX_GENERIC_ARGS: usize = 1;\n    pub const INDEX_RANGLE: usize = 2;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        langle: TerminalLTGreen,\n        generic_args: GenericArgListGreen,\n        rangle: TerminalGTGreen,\n    ) -> GenericArgsGreen {\n        let children: Vec<GreenId> = vec![langle.0, generic_args.0, rangle.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        GenericArgsGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::GenericArgs,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl GenericArgs {\n    pub fn langle(&self, db: &dyn SyntaxGroup) -> TerminalLT {\n        TerminalLT::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn generic_args(&self, db: &dyn SyntaxGroup) -> GenericArgList {\n        GenericArgList::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn rangle(&self, db: &dyn SyntaxGroup) -> TerminalGT {\n        TerminalGT::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct GenericArgsPtr(pub SyntaxStablePtrId);\nimpl GenericArgsPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct GenericArgsGreen(pub GreenId);\nimpl TypedSyntaxNode for GenericArgs {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::GenericArgs);\n    type StablePtr = GenericArgsPtr;\n    type Green = GenericArgsGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        GenericArgsGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::GenericArgs,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    TerminalLT::missing(db).0,\n                    GenericArgList::missing(db).0,\n                    TerminalGT::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::GenericArgs,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::GenericArgs\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        GenericArgsPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct GenericArgList(ElementList<GenericArg, 2>);\nimpl Deref for GenericArgList {\n    type Target = ElementList<GenericArg, 2>;\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\nimpl GenericArgList {\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        children: Vec<GenericArgListElementOrSeparatorGreen>,\n    ) -> GenericArgListGreen {\n        let width = children.iter().map(|id| db.lookup_intern_green(id.id()).width()).sum();\n        GenericArgListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::GenericArgList,\n            details: GreenNodeDetails::Node {\n                children: children.iter().map(|x| x.id()).collect(),\n                width,\n            },\n        }))\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct GenericArgListPtr(pub SyntaxStablePtrId);\nimpl GenericArgListPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub enum GenericArgListElementOrSeparatorGreen {\n    Separator(TerminalCommaGreen),\n    Element(GenericArgGreen),\n}\nimpl From<TerminalCommaGreen> for GenericArgListElementOrSeparatorGreen {\n    fn from(value: TerminalCommaGreen) -> Self {\n        GenericArgListElementOrSeparatorGreen::Separator(value)\n    }\n}\nimpl From<GenericArgGreen> for GenericArgListElementOrSeparatorGreen {\n    fn from(value: GenericArgGreen) -> Self {\n        GenericArgListElementOrSeparatorGreen::Element(value)\n    }\n}\nimpl GenericArgListElementOrSeparatorGreen {\n    fn id(&self) -> GreenId {\n        match self {\n            GenericArgListElementOrSeparatorGreen::Separator(green) => green.0,\n            GenericArgListElementOrSeparatorGreen::Element(green) => green.0,\n        }\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct GenericArgListGreen(pub GreenId);\nimpl TypedSyntaxNode for GenericArgList {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::GenericArgList);\n    type StablePtr = GenericArgListPtr;\n    type Green = GenericArgListGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        GenericArgListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::GenericArgList,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        Self(ElementList::new(node))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        GenericArgListPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum OptionWrappedGenericParamList {\n    Empty(OptionWrappedGenericParamListEmpty),\n    WrappedGenericParamList(WrappedGenericParamList),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionWrappedGenericParamListPtr(pub SyntaxStablePtrId);\nimpl OptionWrappedGenericParamListPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<OptionWrappedGenericParamListEmptyPtr> for OptionWrappedGenericParamListPtr {\n    fn from(value: OptionWrappedGenericParamListEmptyPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<WrappedGenericParamListPtr> for OptionWrappedGenericParamListPtr {\n    fn from(value: WrappedGenericParamListPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<OptionWrappedGenericParamListEmptyGreen> for OptionWrappedGenericParamListGreen {\n    fn from(value: OptionWrappedGenericParamListEmptyGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<WrappedGenericParamListGreen> for OptionWrappedGenericParamListGreen {\n    fn from(value: WrappedGenericParamListGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionWrappedGenericParamListGreen(pub GreenId);\nimpl TypedSyntaxNode for OptionWrappedGenericParamList {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = OptionWrappedGenericParamListPtr;\n    type Green = OptionWrappedGenericParamListGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::OptionWrappedGenericParamListEmpty => OptionWrappedGenericParamList::Empty(\n                OptionWrappedGenericParamListEmpty::from_syntax_node(db, node),\n            ),\n            SyntaxKind::WrappedGenericParamList => {\n                OptionWrappedGenericParamList::WrappedGenericParamList(\n                    WrappedGenericParamList::from_syntax_node(db, node),\n                )\n            }\n            _ => panic!(\n                \"Unexpected syntax kind {:?} when constructing {}.\",\n                kind, \"OptionWrappedGenericParamList\"\n            ),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            OptionWrappedGenericParamList::Empty(x) => x.as_syntax_node(),\n            OptionWrappedGenericParamList::WrappedGenericParamList(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        OptionWrappedGenericParamListPtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct OptionWrappedGenericParamListEmpty {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl OptionWrappedGenericParamListEmpty {\n    pub fn new_green(db: &dyn SyntaxGroup) -> OptionWrappedGenericParamListEmptyGreen {\n        let children: Vec<GreenId> = vec![];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        OptionWrappedGenericParamListEmptyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::OptionWrappedGenericParamListEmpty,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl OptionWrappedGenericParamListEmpty {}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionWrappedGenericParamListEmptyPtr(pub SyntaxStablePtrId);\nimpl OptionWrappedGenericParamListEmptyPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct OptionWrappedGenericParamListEmptyGreen(pub GreenId);\nimpl TypedSyntaxNode for OptionWrappedGenericParamListEmpty {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::OptionWrappedGenericParamListEmpty);\n    type StablePtr = OptionWrappedGenericParamListEmptyPtr;\n    type Green = OptionWrappedGenericParamListEmptyGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        OptionWrappedGenericParamListEmptyGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::OptionWrappedGenericParamListEmpty,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::OptionWrappedGenericParamListEmpty,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::OptionWrappedGenericParamListEmpty\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        OptionWrappedGenericParamListEmptyPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct WrappedGenericParamList {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl WrappedGenericParamList {\n    pub const INDEX_LANGLE: usize = 0;\n    pub const INDEX_GENERIC_PARAMS: usize = 1;\n    pub const INDEX_RANGLE: usize = 2;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        langle: TerminalLTGreen,\n        generic_params: GenericParamListGreen,\n        rangle: TerminalGTGreen,\n    ) -> WrappedGenericParamListGreen {\n        let children: Vec<GreenId> = vec![langle.0, generic_params.0, rangle.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        WrappedGenericParamListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::WrappedGenericParamList,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl WrappedGenericParamList {\n    pub fn langle(&self, db: &dyn SyntaxGroup) -> TerminalLT {\n        TerminalLT::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn generic_params(&self, db: &dyn SyntaxGroup) -> GenericParamList {\n        GenericParamList::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn rangle(&self, db: &dyn SyntaxGroup) -> TerminalGT {\n        TerminalGT::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct WrappedGenericParamListPtr(pub SyntaxStablePtrId);\nimpl WrappedGenericParamListPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct WrappedGenericParamListGreen(pub GreenId);\nimpl TypedSyntaxNode for WrappedGenericParamList {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::WrappedGenericParamList);\n    type StablePtr = WrappedGenericParamListPtr;\n    type Green = WrappedGenericParamListGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        WrappedGenericParamListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::WrappedGenericParamList,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    TerminalLT::missing(db).0,\n                    GenericParamList::missing(db).0,\n                    TerminalGT::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::WrappedGenericParamList,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::WrappedGenericParamList\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        WrappedGenericParamListPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct GenericParamList(ElementList<GenericParam, 2>);\nimpl Deref for GenericParamList {\n    type Target = ElementList<GenericParam, 2>;\n    fn deref(&self) -> &Self::Target {\n        &self.0\n    }\n}\nimpl GenericParamList {\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        children: Vec<GenericParamListElementOrSeparatorGreen>,\n    ) -> GenericParamListGreen {\n        let width = children.iter().map(|id| db.lookup_intern_green(id.id()).width()).sum();\n        GenericParamListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::GenericParamList,\n            details: GreenNodeDetails::Node {\n                children: children.iter().map(|x| x.id()).collect(),\n                width,\n            },\n        }))\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct GenericParamListPtr(pub SyntaxStablePtrId);\nimpl GenericParamListPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub enum GenericParamListElementOrSeparatorGreen {\n    Separator(TerminalCommaGreen),\n    Element(GenericParamGreen),\n}\nimpl From<TerminalCommaGreen> for GenericParamListElementOrSeparatorGreen {\n    fn from(value: TerminalCommaGreen) -> Self {\n        GenericParamListElementOrSeparatorGreen::Separator(value)\n    }\n}\nimpl From<GenericParamGreen> for GenericParamListElementOrSeparatorGreen {\n    fn from(value: GenericParamGreen) -> Self {\n        GenericParamListElementOrSeparatorGreen::Element(value)\n    }\n}\nimpl GenericParamListElementOrSeparatorGreen {\n    fn id(&self) -> GreenId {\n        match self {\n            GenericParamListElementOrSeparatorGreen::Separator(green) => green.0,\n            GenericParamListElementOrSeparatorGreen::Element(green) => green.0,\n        }\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct GenericParamListGreen(pub GreenId);\nimpl TypedSyntaxNode for GenericParamList {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::GenericParamList);\n    type StablePtr = GenericParamListPtr;\n    type Green = GenericParamListGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        GenericParamListGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::GenericParamList,\n            details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        Self(ElementList::new(node))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        GenericParamListPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub enum GenericParam {\n    Type(GenericParamType),\n    Const(GenericParamConst),\n    Impl(GenericParamImpl),\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct GenericParamPtr(pub SyntaxStablePtrId);\nimpl GenericParamPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\nimpl From<GenericParamTypePtr> for GenericParamPtr {\n    fn from(value: GenericParamTypePtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<GenericParamConstPtr> for GenericParamPtr {\n    fn from(value: GenericParamConstPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<GenericParamImplPtr> for GenericParamPtr {\n    fn from(value: GenericParamImplPtr) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<GenericParamTypeGreen> for GenericParamGreen {\n    fn from(value: GenericParamTypeGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<GenericParamConstGreen> for GenericParamGreen {\n    fn from(value: GenericParamConstGreen) -> Self {\n        Self(value.0)\n    }\n}\nimpl From<GenericParamImplGreen> for GenericParamGreen {\n    fn from(value: GenericParamImplGreen) -> Self {\n        Self(value.0)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct GenericParamGreen(pub GreenId);\nimpl TypedSyntaxNode for GenericParam {\n    const OPTIONAL_KIND: Option<SyntaxKind> = None;\n    type StablePtr = GenericParamPtr;\n    type Green = GenericParamGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        panic!(\"No missing variant.\");\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        match kind {\n            SyntaxKind::GenericParamType => {\n                GenericParam::Type(GenericParamType::from_syntax_node(db, node))\n            }\n            SyntaxKind::GenericParamConst => {\n                GenericParam::Const(GenericParamConst::from_syntax_node(db, node))\n            }\n            SyntaxKind::GenericParamImpl => {\n                GenericParam::Impl(GenericParamImpl::from_syntax_node(db, node))\n            }\n            _ => panic!(\"Unexpected syntax kind {:?} when constructing {}.\", kind, \"GenericParam\"),\n        }\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        match self {\n            GenericParam::Type(x) => x.as_syntax_node(),\n            GenericParam::Const(x) => x.as_syntax_node(),\n            GenericParam::Impl(x) => x.as_syntax_node(),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        GenericParamPtr(self.as_syntax_node().0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct GenericParamType {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl GenericParamType {\n    pub const INDEX_NAME: usize = 0;\n    pub fn new_green(db: &dyn SyntaxGroup, name: TerminalIdentifierGreen) -> GenericParamTypeGreen {\n        let children: Vec<GreenId> = vec![name.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        GenericParamTypeGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::GenericParamType,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl GenericParamType {\n    pub fn name(&self, db: &dyn SyntaxGroup) -> TerminalIdentifier {\n        TerminalIdentifier::from_syntax_node(db, self.children[0].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct GenericParamTypePtr(pub SyntaxStablePtrId);\nimpl GenericParamTypePtr {\n    pub fn name_green(self, db: &dyn SyntaxGroup) -> TerminalIdentifierGreen {\n        let ptr = db.lookup_intern_stable_ptr(self.0);\n        if let SyntaxStablePtr::Child { key_fields, .. } = ptr {\n            TerminalIdentifierGreen(key_fields[0])\n        } else {\n            panic!(\"Unexpected key field query on root.\");\n        }\n    }\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct GenericParamTypeGreen(pub GreenId);\nimpl TypedSyntaxNode for GenericParamType {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::GenericParamType);\n    type StablePtr = GenericParamTypePtr;\n    type Green = GenericParamTypeGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        GenericParamTypeGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::GenericParamType,\n            details: GreenNodeDetails::Node {\n                children: vec![TerminalIdentifier::missing(db).0],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::GenericParamType,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::GenericParamType\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        GenericParamTypePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct GenericParamConst {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl GenericParamConst {\n    pub const INDEX_CONST_KW: usize = 0;\n    pub const INDEX_NAME: usize = 1;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        const_kw: TerminalConstGreen,\n        name: TerminalIdentifierGreen,\n    ) -> GenericParamConstGreen {\n        let children: Vec<GreenId> = vec![const_kw.0, name.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        GenericParamConstGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::GenericParamConst,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl GenericParamConst {\n    pub fn const_kw(&self, db: &dyn SyntaxGroup) -> TerminalConst {\n        TerminalConst::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn name(&self, db: &dyn SyntaxGroup) -> TerminalIdentifier {\n        TerminalIdentifier::from_syntax_node(db, self.children[1].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct GenericParamConstPtr(pub SyntaxStablePtrId);\nimpl GenericParamConstPtr {\n    pub fn name_green(self, db: &dyn SyntaxGroup) -> TerminalIdentifierGreen {\n        let ptr = db.lookup_intern_stable_ptr(self.0);\n        if let SyntaxStablePtr::Child { key_fields, .. } = ptr {\n            TerminalIdentifierGreen(key_fields[0])\n        } else {\n            panic!(\"Unexpected key field query on root.\");\n        }\n    }\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct GenericParamConstGreen(pub GreenId);\nimpl TypedSyntaxNode for GenericParamConst {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::GenericParamConst);\n    type StablePtr = GenericParamConstPtr;\n    type Green = GenericParamConstGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        GenericParamConstGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::GenericParamConst,\n            details: GreenNodeDetails::Node {\n                children: vec![TerminalConst::missing(db).0, TerminalIdentifier::missing(db).0],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::GenericParamConst,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::GenericParamConst\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        GenericParamConstPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct GenericParamImpl {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl GenericParamImpl {\n    pub const INDEX_IMPL_KW: usize = 0;\n    pub const INDEX_NAME: usize = 1;\n    pub const INDEX_COLON: usize = 2;\n    pub const INDEX_TRAIT_PATH: usize = 3;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        impl_kw: TerminalImplGreen,\n        name: TerminalIdentifierGreen,\n        colon: TerminalColonGreen,\n        trait_path: ExprPathGreen,\n    ) -> GenericParamImplGreen {\n        let children: Vec<GreenId> = vec![impl_kw.0, name.0, colon.0, trait_path.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        GenericParamImplGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::GenericParamImpl,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl GenericParamImpl {\n    pub fn impl_kw(&self, db: &dyn SyntaxGroup) -> TerminalImpl {\n        TerminalImpl::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn name(&self, db: &dyn SyntaxGroup) -> TerminalIdentifier {\n        TerminalIdentifier::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn colon(&self, db: &dyn SyntaxGroup) -> TerminalColon {\n        TerminalColon::from_syntax_node(db, self.children[2].clone())\n    }\n    pub fn trait_path(&self, db: &dyn SyntaxGroup) -> ExprPath {\n        ExprPath::from_syntax_node(db, self.children[3].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct GenericParamImplPtr(pub SyntaxStablePtrId);\nimpl GenericParamImplPtr {\n    pub fn name_green(self, db: &dyn SyntaxGroup) -> TerminalIdentifierGreen {\n        let ptr = db.lookup_intern_stable_ptr(self.0);\n        if let SyntaxStablePtr::Child { key_fields, .. } = ptr {\n            TerminalIdentifierGreen(key_fields[0])\n        } else {\n            panic!(\"Unexpected key field query on root.\");\n        }\n    }\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct GenericParamImplGreen(pub GreenId);\nimpl TypedSyntaxNode for GenericParamImpl {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::GenericParamImpl);\n    type StablePtr = GenericParamImplPtr;\n    type Green = GenericParamImplGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        GenericParamImplGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::GenericParamImpl,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    TerminalImpl::missing(db).0,\n                    TerminalIdentifier::missing(db).0,\n                    TerminalColon::missing(db).0,\n                    ExprPath::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::GenericParamImpl,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::GenericParamImpl\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        GenericParamImplPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenIdentifier {\n    node: SyntaxNode,\n}\nimpl Token for TokenIdentifier {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenIdentifierGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenIdentifier,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenIdentifierPtr(pub SyntaxStablePtrId);\nimpl TokenIdentifierPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenIdentifierGreen(pub GreenId);\nimpl TokenIdentifierGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenIdentifier {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenIdentifier);\n    type StablePtr = TokenIdentifierPtr;\n    type Green = TokenIdentifierGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenIdentifierGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenIdentifier)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenIdentifierPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalIdentifier {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalIdentifier {\n    const KIND: SyntaxKind = SyntaxKind::TerminalIdentifier;\n    type TokenType = TokenIdentifier;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalIdentifier as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalIdentifierGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalIdentifier,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalIdentifier {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenIdentifier {\n        TokenIdentifier::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalIdentifierPtr(pub SyntaxStablePtrId);\nimpl TerminalIdentifierPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalIdentifierGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalIdentifier {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalIdentifier);\n    type StablePtr = TerminalIdentifierPtr;\n    type Green = TerminalIdentifierGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalIdentifierGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalIdentifier,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenIdentifier::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalIdentifier,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalIdentifier\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalIdentifierPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenLiteralNumber {\n    node: SyntaxNode,\n}\nimpl Token for TokenLiteralNumber {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenLiteralNumberGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenLiteralNumber,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenLiteralNumberPtr(pub SyntaxStablePtrId);\nimpl TokenLiteralNumberPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenLiteralNumberGreen(pub GreenId);\nimpl TokenLiteralNumberGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenLiteralNumber {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenLiteralNumber);\n    type StablePtr = TokenLiteralNumberPtr;\n    type Green = TokenLiteralNumberGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenLiteralNumberGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => panic!(\n                \"Expected a token {:?}, not an internal node\",\n                SyntaxKind::TokenLiteralNumber\n            ),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenLiteralNumberPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalLiteralNumber {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalLiteralNumber {\n    const KIND: SyntaxKind = SyntaxKind::TerminalLiteralNumber;\n    type TokenType = TokenLiteralNumber;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalLiteralNumber as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalLiteralNumberGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalLiteralNumber,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalLiteralNumber {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenLiteralNumber {\n        TokenLiteralNumber::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalLiteralNumberPtr(pub SyntaxStablePtrId);\nimpl TerminalLiteralNumberPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalLiteralNumberGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalLiteralNumber {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalLiteralNumber);\n    type StablePtr = TerminalLiteralNumberPtr;\n    type Green = TerminalLiteralNumberGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalLiteralNumberGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalLiteralNumber,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenLiteralNumber::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalLiteralNumber,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalLiteralNumber\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalLiteralNumberPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenShortString {\n    node: SyntaxNode,\n}\nimpl Token for TokenShortString {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenShortStringGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenShortString,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenShortStringPtr(pub SyntaxStablePtrId);\nimpl TokenShortStringPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenShortStringGreen(pub GreenId);\nimpl TokenShortStringGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenShortString {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenShortString);\n    type StablePtr = TokenShortStringPtr;\n    type Green = TokenShortStringGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenShortStringGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenShortString)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenShortStringPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalShortString {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalShortString {\n    const KIND: SyntaxKind = SyntaxKind::TerminalShortString;\n    type TokenType = TokenShortString;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalShortString as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalShortStringGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalShortString,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalShortString {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenShortString {\n        TokenShortString::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalShortStringPtr(pub SyntaxStablePtrId);\nimpl TerminalShortStringPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalShortStringGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalShortString {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalShortString);\n    type StablePtr = TerminalShortStringPtr;\n    type Green = TerminalShortStringGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalShortStringGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalShortString,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenShortString::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalShortString,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalShortString\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalShortStringPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenConst {\n    node: SyntaxNode,\n}\nimpl Token for TokenConst {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenConstGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenConst,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenConstPtr(pub SyntaxStablePtrId);\nimpl TokenConstPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenConstGreen(pub GreenId);\nimpl TokenConstGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenConst {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenConst);\n    type StablePtr = TokenConstPtr;\n    type Green = TokenConstGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenConstGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenConst)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenConstPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalConst {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalConst {\n    const KIND: SyntaxKind = SyntaxKind::TerminalConst;\n    type TokenType = TokenConst;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalConst as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalConstGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalConst,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalConst {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenConst {\n        TokenConst::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalConstPtr(pub SyntaxStablePtrId);\nimpl TerminalConstPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalConstGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalConst {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalConst);\n    type StablePtr = TerminalConstPtr;\n    type Green = TerminalConstGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalConstGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalConst,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenConst::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalConst,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalConst\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalConstPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenElse {\n    node: SyntaxNode,\n}\nimpl Token for TokenElse {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenElseGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenElse,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenElsePtr(pub SyntaxStablePtrId);\nimpl TokenElsePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenElseGreen(pub GreenId);\nimpl TokenElseGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenElse {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenElse);\n    type StablePtr = TokenElsePtr;\n    type Green = TokenElseGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenElseGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenElse)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenElsePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalElse {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalElse {\n    const KIND: SyntaxKind = SyntaxKind::TerminalElse;\n    type TokenType = TokenElse;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalElse as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalElseGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalElse,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalElse {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenElse {\n        TokenElse::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalElsePtr(pub SyntaxStablePtrId);\nimpl TerminalElsePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalElseGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalElse {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalElse);\n    type StablePtr = TerminalElsePtr;\n    type Green = TerminalElseGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalElseGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalElse,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenElse::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalElse,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalElse\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalElsePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenEnum {\n    node: SyntaxNode,\n}\nimpl Token for TokenEnum {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenEnumGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenEnum,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenEnumPtr(pub SyntaxStablePtrId);\nimpl TokenEnumPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenEnumGreen(pub GreenId);\nimpl TokenEnumGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenEnum {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenEnum);\n    type StablePtr = TokenEnumPtr;\n    type Green = TokenEnumGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenEnumGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenEnum)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenEnumPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalEnum {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalEnum {\n    const KIND: SyntaxKind = SyntaxKind::TerminalEnum;\n    type TokenType = TokenEnum;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalEnum as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalEnumGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalEnum,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalEnum {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenEnum {\n        TokenEnum::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalEnumPtr(pub SyntaxStablePtrId);\nimpl TerminalEnumPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalEnumGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalEnum {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalEnum);\n    type StablePtr = TerminalEnumPtr;\n    type Green = TerminalEnumGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalEnumGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalEnum,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenEnum::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalEnum,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalEnum\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalEnumPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenExtern {\n    node: SyntaxNode,\n}\nimpl Token for TokenExtern {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenExternGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenExtern,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenExternPtr(pub SyntaxStablePtrId);\nimpl TokenExternPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenExternGreen(pub GreenId);\nimpl TokenExternGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenExtern {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenExtern);\n    type StablePtr = TokenExternPtr;\n    type Green = TokenExternGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenExternGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenExtern)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenExternPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalExtern {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalExtern {\n    const KIND: SyntaxKind = SyntaxKind::TerminalExtern;\n    type TokenType = TokenExtern;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalExtern as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalExternGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalExtern,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalExtern {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenExtern {\n        TokenExtern::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalExternPtr(pub SyntaxStablePtrId);\nimpl TerminalExternPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalExternGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalExtern {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalExtern);\n    type StablePtr = TerminalExternPtr;\n    type Green = TerminalExternGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalExternGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalExtern,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenExtern::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalExtern,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalExtern\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalExternPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenFalse {\n    node: SyntaxNode,\n}\nimpl Token for TokenFalse {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenFalseGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenFalse,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenFalsePtr(pub SyntaxStablePtrId);\nimpl TokenFalsePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenFalseGreen(pub GreenId);\nimpl TokenFalseGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenFalse {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenFalse);\n    type StablePtr = TokenFalsePtr;\n    type Green = TokenFalseGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenFalseGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenFalse)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenFalsePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalFalse {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalFalse {\n    const KIND: SyntaxKind = SyntaxKind::TerminalFalse;\n    type TokenType = TokenFalse;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalFalse as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalFalseGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalFalse,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalFalse {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenFalse {\n        TokenFalse::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalFalsePtr(pub SyntaxStablePtrId);\nimpl TerminalFalsePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalFalseGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalFalse {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalFalse);\n    type StablePtr = TerminalFalsePtr;\n    type Green = TerminalFalseGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalFalseGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalFalse,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenFalse::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalFalse,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalFalse\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalFalsePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenFunction {\n    node: SyntaxNode,\n}\nimpl Token for TokenFunction {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenFunctionGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenFunction,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenFunctionPtr(pub SyntaxStablePtrId);\nimpl TokenFunctionPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenFunctionGreen(pub GreenId);\nimpl TokenFunctionGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenFunction {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenFunction);\n    type StablePtr = TokenFunctionPtr;\n    type Green = TokenFunctionGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenFunctionGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenFunction)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenFunctionPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalFunction {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalFunction {\n    const KIND: SyntaxKind = SyntaxKind::TerminalFunction;\n    type TokenType = TokenFunction;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalFunction as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalFunctionGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalFunction,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalFunction {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenFunction {\n        TokenFunction::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalFunctionPtr(pub SyntaxStablePtrId);\nimpl TerminalFunctionPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalFunctionGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalFunction {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalFunction);\n    type StablePtr = TerminalFunctionPtr;\n    type Green = TerminalFunctionGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalFunctionGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalFunction,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenFunction::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalFunction,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalFunction\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalFunctionPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenIf {\n    node: SyntaxNode,\n}\nimpl Token for TokenIf {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenIfGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenIf,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenIfPtr(pub SyntaxStablePtrId);\nimpl TokenIfPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenIfGreen(pub GreenId);\nimpl TokenIfGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenIf {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenIf);\n    type StablePtr = TokenIfPtr;\n    type Green = TokenIfGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenIfGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenIf)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenIfPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalIf {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalIf {\n    const KIND: SyntaxKind = SyntaxKind::TerminalIf;\n    type TokenType = TokenIf;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalIf as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalIfGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalIf,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalIf {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenIf {\n        TokenIf::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalIfPtr(pub SyntaxStablePtrId);\nimpl TerminalIfPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalIfGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalIf {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalIf);\n    type StablePtr = TerminalIfPtr;\n    type Green = TerminalIfGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalIfGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalIf,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenIf::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalIf,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalIf\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalIfPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenImpl {\n    node: SyntaxNode,\n}\nimpl Token for TokenImpl {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenImplGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenImpl,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenImplPtr(pub SyntaxStablePtrId);\nimpl TokenImplPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenImplGreen(pub GreenId);\nimpl TokenImplGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenImpl {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenImpl);\n    type StablePtr = TokenImplPtr;\n    type Green = TokenImplGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenImplGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenImpl)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenImplPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalImpl {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalImpl {\n    const KIND: SyntaxKind = SyntaxKind::TerminalImpl;\n    type TokenType = TokenImpl;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalImpl as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalImplGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalImpl,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalImpl {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenImpl {\n        TokenImpl::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalImplPtr(pub SyntaxStablePtrId);\nimpl TerminalImplPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalImplGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalImpl {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalImpl);\n    type StablePtr = TerminalImplPtr;\n    type Green = TerminalImplGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalImplGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalImpl,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenImpl::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalImpl,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalImpl\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalImplPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenImplicits {\n    node: SyntaxNode,\n}\nimpl Token for TokenImplicits {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenImplicitsGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenImplicits,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenImplicitsPtr(pub SyntaxStablePtrId);\nimpl TokenImplicitsPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenImplicitsGreen(pub GreenId);\nimpl TokenImplicitsGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenImplicits {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenImplicits);\n    type StablePtr = TokenImplicitsPtr;\n    type Green = TokenImplicitsGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenImplicitsGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenImplicits)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenImplicitsPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalImplicits {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalImplicits {\n    const KIND: SyntaxKind = SyntaxKind::TerminalImplicits;\n    type TokenType = TokenImplicits;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalImplicits as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalImplicitsGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalImplicits,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalImplicits {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenImplicits {\n        TokenImplicits::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalImplicitsPtr(pub SyntaxStablePtrId);\nimpl TerminalImplicitsPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalImplicitsGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalImplicits {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalImplicits);\n    type StablePtr = TerminalImplicitsPtr;\n    type Green = TerminalImplicitsGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalImplicitsGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalImplicits,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenImplicits::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalImplicits,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalImplicits\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalImplicitsPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenLet {\n    node: SyntaxNode,\n}\nimpl Token for TokenLet {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenLetGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenLet,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenLetPtr(pub SyntaxStablePtrId);\nimpl TokenLetPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenLetGreen(pub GreenId);\nimpl TokenLetGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenLet {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenLet);\n    type StablePtr = TokenLetPtr;\n    type Green = TokenLetGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenLetGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenLet)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenLetPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalLet {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalLet {\n    const KIND: SyntaxKind = SyntaxKind::TerminalLet;\n    type TokenType = TokenLet;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalLet as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalLetGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalLet,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalLet {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenLet {\n        TokenLet::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalLetPtr(pub SyntaxStablePtrId);\nimpl TerminalLetPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalLetGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalLet {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalLet);\n    type StablePtr = TerminalLetPtr;\n    type Green = TerminalLetGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalLetGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalLet,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenLet::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalLet,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalLet\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalLetPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenMatch {\n    node: SyntaxNode,\n}\nimpl Token for TokenMatch {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenMatchGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMatch,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenMatchPtr(pub SyntaxStablePtrId);\nimpl TokenMatchPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenMatchGreen(pub GreenId);\nimpl TokenMatchGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenMatch {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenMatch);\n    type StablePtr = TokenMatchPtr;\n    type Green = TokenMatchGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenMatchGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenMatch)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenMatchPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalMatch {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalMatch {\n    const KIND: SyntaxKind = SyntaxKind::TerminalMatch;\n    type TokenType = TokenMatch;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalMatch as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalMatchGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalMatch,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalMatch {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenMatch {\n        TokenMatch::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalMatchPtr(pub SyntaxStablePtrId);\nimpl TerminalMatchPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalMatchGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalMatch {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalMatch);\n    type StablePtr = TerminalMatchPtr;\n    type Green = TerminalMatchGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalMatchGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalMatch,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenMatch::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalMatch,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalMatch\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalMatchPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenModule {\n    node: SyntaxNode,\n}\nimpl Token for TokenModule {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenModuleGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenModule,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenModulePtr(pub SyntaxStablePtrId);\nimpl TokenModulePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenModuleGreen(pub GreenId);\nimpl TokenModuleGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenModule {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenModule);\n    type StablePtr = TokenModulePtr;\n    type Green = TokenModuleGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenModuleGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenModule)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenModulePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalModule {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalModule {\n    const KIND: SyntaxKind = SyntaxKind::TerminalModule;\n    type TokenType = TokenModule;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalModule as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalModuleGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalModule,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalModule {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenModule {\n        TokenModule::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalModulePtr(pub SyntaxStablePtrId);\nimpl TerminalModulePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalModuleGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalModule {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalModule);\n    type StablePtr = TerminalModulePtr;\n    type Green = TerminalModuleGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalModuleGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalModule,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenModule::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalModule,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalModule\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalModulePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenMut {\n    node: SyntaxNode,\n}\nimpl Token for TokenMut {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenMutGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMut,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenMutPtr(pub SyntaxStablePtrId);\nimpl TokenMutPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenMutGreen(pub GreenId);\nimpl TokenMutGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenMut {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenMut);\n    type StablePtr = TokenMutPtr;\n    type Green = TokenMutGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenMutGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenMut)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenMutPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalMut {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalMut {\n    const KIND: SyntaxKind = SyntaxKind::TerminalMut;\n    type TokenType = TokenMut;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalMut as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalMutGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalMut,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalMut {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenMut {\n        TokenMut::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalMutPtr(pub SyntaxStablePtrId);\nimpl TerminalMutPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalMutGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalMut {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalMut);\n    type StablePtr = TerminalMutPtr;\n    type Green = TerminalMutGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalMutGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalMut,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenMut::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalMut,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalMut\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalMutPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenNoPanic {\n    node: SyntaxNode,\n}\nimpl Token for TokenNoPanic {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenNoPanicGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenNoPanic,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenNoPanicPtr(pub SyntaxStablePtrId);\nimpl TokenNoPanicPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenNoPanicGreen(pub GreenId);\nimpl TokenNoPanicGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenNoPanic {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenNoPanic);\n    type StablePtr = TokenNoPanicPtr;\n    type Green = TokenNoPanicGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenNoPanicGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenNoPanic)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenNoPanicPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalNoPanic {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalNoPanic {\n    const KIND: SyntaxKind = SyntaxKind::TerminalNoPanic;\n    type TokenType = TokenNoPanic;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalNoPanic as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalNoPanicGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalNoPanic,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalNoPanic {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenNoPanic {\n        TokenNoPanic::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalNoPanicPtr(pub SyntaxStablePtrId);\nimpl TerminalNoPanicPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalNoPanicGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalNoPanic {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalNoPanic);\n    type StablePtr = TerminalNoPanicPtr;\n    type Green = TerminalNoPanicGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalNoPanicGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalNoPanic,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenNoPanic::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalNoPanic,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalNoPanic\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalNoPanicPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenOf {\n    node: SyntaxNode,\n}\nimpl Token for TokenOf {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenOfGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenOf,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenOfPtr(pub SyntaxStablePtrId);\nimpl TokenOfPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenOfGreen(pub GreenId);\nimpl TokenOfGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenOf {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenOf);\n    type StablePtr = TokenOfPtr;\n    type Green = TokenOfGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenOfGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenOf)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenOfPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalOf {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalOf {\n    const KIND: SyntaxKind = SyntaxKind::TerminalOf;\n    type TokenType = TokenOf;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalOf as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalOfGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalOf,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalOf {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenOf {\n        TokenOf::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalOfPtr(pub SyntaxStablePtrId);\nimpl TerminalOfPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalOfGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalOf {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalOf);\n    type StablePtr = TerminalOfPtr;\n    type Green = TerminalOfGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalOfGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalOf,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenOf::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalOf,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalOf\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalOfPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenRef {\n    node: SyntaxNode,\n}\nimpl Token for TokenRef {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenRefGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenRef,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenRefPtr(pub SyntaxStablePtrId);\nimpl TokenRefPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenRefGreen(pub GreenId);\nimpl TokenRefGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenRef {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenRef);\n    type StablePtr = TokenRefPtr;\n    type Green = TokenRefGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenRefGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenRef)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenRefPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalRef {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalRef {\n    const KIND: SyntaxKind = SyntaxKind::TerminalRef;\n    type TokenType = TokenRef;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalRef as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalRefGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalRef,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalRef {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenRef {\n        TokenRef::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalRefPtr(pub SyntaxStablePtrId);\nimpl TerminalRefPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalRefGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalRef {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalRef);\n    type StablePtr = TerminalRefPtr;\n    type Green = TerminalRefGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalRefGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalRef,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenRef::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalRef,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalRef\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalRefPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenReturn {\n    node: SyntaxNode,\n}\nimpl Token for TokenReturn {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenReturnGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenReturn,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenReturnPtr(pub SyntaxStablePtrId);\nimpl TokenReturnPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenReturnGreen(pub GreenId);\nimpl TokenReturnGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenReturn {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenReturn);\n    type StablePtr = TokenReturnPtr;\n    type Green = TokenReturnGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenReturnGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenReturn)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenReturnPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalReturn {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalReturn {\n    const KIND: SyntaxKind = SyntaxKind::TerminalReturn;\n    type TokenType = TokenReturn;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalReturn as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalReturnGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalReturn,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalReturn {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenReturn {\n        TokenReturn::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalReturnPtr(pub SyntaxStablePtrId);\nimpl TerminalReturnPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalReturnGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalReturn {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalReturn);\n    type StablePtr = TerminalReturnPtr;\n    type Green = TerminalReturnGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalReturnGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalReturn,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenReturn::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalReturn,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalReturn\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalReturnPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenStruct {\n    node: SyntaxNode,\n}\nimpl Token for TokenStruct {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenStructGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenStruct,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenStructPtr(pub SyntaxStablePtrId);\nimpl TokenStructPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenStructGreen(pub GreenId);\nimpl TokenStructGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenStruct {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenStruct);\n    type StablePtr = TokenStructPtr;\n    type Green = TokenStructGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenStructGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenStruct)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenStructPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalStruct {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalStruct {\n    const KIND: SyntaxKind = SyntaxKind::TerminalStruct;\n    type TokenType = TokenStruct;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalStruct as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalStructGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalStruct,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalStruct {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenStruct {\n        TokenStruct::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalStructPtr(pub SyntaxStablePtrId);\nimpl TerminalStructPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalStructGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalStruct {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalStruct);\n    type StablePtr = TerminalStructPtr;\n    type Green = TerminalStructGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalStructGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalStruct,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenStruct::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalStruct,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalStruct\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalStructPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenTrait {\n    node: SyntaxNode,\n}\nimpl Token for TokenTrait {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenTraitGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenTrait,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenTraitPtr(pub SyntaxStablePtrId);\nimpl TokenTraitPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenTraitGreen(pub GreenId);\nimpl TokenTraitGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenTrait {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenTrait);\n    type StablePtr = TokenTraitPtr;\n    type Green = TokenTraitGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenTraitGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenTrait)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenTraitPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalTrait {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalTrait {\n    const KIND: SyntaxKind = SyntaxKind::TerminalTrait;\n    type TokenType = TokenTrait;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalTrait as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalTraitGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalTrait,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalTrait {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenTrait {\n        TokenTrait::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalTraitPtr(pub SyntaxStablePtrId);\nimpl TerminalTraitPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalTraitGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalTrait {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalTrait);\n    type StablePtr = TerminalTraitPtr;\n    type Green = TerminalTraitGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalTraitGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalTrait,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenTrait::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalTrait,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalTrait\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalTraitPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenTrue {\n    node: SyntaxNode,\n}\nimpl Token for TokenTrue {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenTrueGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenTrue,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenTruePtr(pub SyntaxStablePtrId);\nimpl TokenTruePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenTrueGreen(pub GreenId);\nimpl TokenTrueGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenTrue {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenTrue);\n    type StablePtr = TokenTruePtr;\n    type Green = TokenTrueGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenTrueGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenTrue)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenTruePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalTrue {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalTrue {\n    const KIND: SyntaxKind = SyntaxKind::TerminalTrue;\n    type TokenType = TokenTrue;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalTrue as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalTrueGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalTrue,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalTrue {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenTrue {\n        TokenTrue::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalTruePtr(pub SyntaxStablePtrId);\nimpl TerminalTruePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalTrueGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalTrue {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalTrue);\n    type StablePtr = TerminalTruePtr;\n    type Green = TerminalTrueGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalTrueGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalTrue,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenTrue::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalTrue,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalTrue\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalTruePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenType {\n    node: SyntaxNode,\n}\nimpl Token for TokenType {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenTypeGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenType,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenTypePtr(pub SyntaxStablePtrId);\nimpl TokenTypePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenTypeGreen(pub GreenId);\nimpl TokenTypeGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenType {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenType);\n    type StablePtr = TokenTypePtr;\n    type Green = TokenTypeGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenTypeGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenType)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenTypePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalType {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalType {\n    const KIND: SyntaxKind = SyntaxKind::TerminalType;\n    type TokenType = TokenType;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalType as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalTypeGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalType,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalType {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenType {\n        TokenType::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalTypePtr(pub SyntaxStablePtrId);\nimpl TerminalTypePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalTypeGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalType {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalType);\n    type StablePtr = TerminalTypePtr;\n    type Green = TerminalTypeGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalTypeGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalType,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenType::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalType,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalType\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalTypePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenUse {\n    node: SyntaxNode,\n}\nimpl Token for TokenUse {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenUseGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenUse,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenUsePtr(pub SyntaxStablePtrId);\nimpl TokenUsePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenUseGreen(pub GreenId);\nimpl TokenUseGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenUse {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenUse);\n    type StablePtr = TokenUsePtr;\n    type Green = TokenUseGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenUseGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenUse)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenUsePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalUse {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalUse {\n    const KIND: SyntaxKind = SyntaxKind::TerminalUse;\n    type TokenType = TokenUse;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalUse as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalUseGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalUse,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalUse {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenUse {\n        TokenUse::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalUsePtr(pub SyntaxStablePtrId);\nimpl TerminalUsePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalUseGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalUse {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalUse);\n    type StablePtr = TerminalUsePtr;\n    type Green = TerminalUseGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalUseGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalUse,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenUse::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalUse,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalUse\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalUsePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenAnd {\n    node: SyntaxNode,\n}\nimpl Token for TokenAnd {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenAndGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenAnd,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenAndPtr(pub SyntaxStablePtrId);\nimpl TokenAndPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenAndGreen(pub GreenId);\nimpl TokenAndGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenAnd {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenAnd);\n    type StablePtr = TokenAndPtr;\n    type Green = TokenAndGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenAndGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenAnd)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenAndPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalAnd {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalAnd {\n    const KIND: SyntaxKind = SyntaxKind::TerminalAnd;\n    type TokenType = TokenAnd;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalAnd as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalAndGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalAnd,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalAnd {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenAnd {\n        TokenAnd::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalAndPtr(pub SyntaxStablePtrId);\nimpl TerminalAndPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalAndGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalAnd {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalAnd);\n    type StablePtr = TerminalAndPtr;\n    type Green = TerminalAndGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalAndGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalAnd,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenAnd::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalAnd,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalAnd\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalAndPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenAndAnd {\n    node: SyntaxNode,\n}\nimpl Token for TokenAndAnd {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenAndAndGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenAndAnd,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenAndAndPtr(pub SyntaxStablePtrId);\nimpl TokenAndAndPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenAndAndGreen(pub GreenId);\nimpl TokenAndAndGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenAndAnd {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenAndAnd);\n    type StablePtr = TokenAndAndPtr;\n    type Green = TokenAndAndGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenAndAndGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenAndAnd)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenAndAndPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalAndAnd {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalAndAnd {\n    const KIND: SyntaxKind = SyntaxKind::TerminalAndAnd;\n    type TokenType = TokenAndAnd;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalAndAnd as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalAndAndGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalAndAnd,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalAndAnd {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenAndAnd {\n        TokenAndAnd::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalAndAndPtr(pub SyntaxStablePtrId);\nimpl TerminalAndAndPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalAndAndGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalAndAnd {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalAndAnd);\n    type StablePtr = TerminalAndAndPtr;\n    type Green = TerminalAndAndGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalAndAndGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalAndAnd,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenAndAnd::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalAndAnd,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalAndAnd\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalAndAndPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenArrow {\n    node: SyntaxNode,\n}\nimpl Token for TokenArrow {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenArrowGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenArrow,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenArrowPtr(pub SyntaxStablePtrId);\nimpl TokenArrowPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenArrowGreen(pub GreenId);\nimpl TokenArrowGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenArrow {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenArrow);\n    type StablePtr = TokenArrowPtr;\n    type Green = TokenArrowGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenArrowGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenArrow)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenArrowPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalArrow {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalArrow {\n    const KIND: SyntaxKind = SyntaxKind::TerminalArrow;\n    type TokenType = TokenArrow;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalArrow as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalArrowGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalArrow,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalArrow {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenArrow {\n        TokenArrow::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalArrowPtr(pub SyntaxStablePtrId);\nimpl TerminalArrowPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalArrowGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalArrow {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalArrow);\n    type StablePtr = TerminalArrowPtr;\n    type Green = TerminalArrowGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalArrowGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalArrow,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenArrow::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalArrow,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalArrow\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalArrowPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenAt {\n    node: SyntaxNode,\n}\nimpl Token for TokenAt {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenAtGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenAt,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenAtPtr(pub SyntaxStablePtrId);\nimpl TokenAtPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenAtGreen(pub GreenId);\nimpl TokenAtGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenAt {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenAt);\n    type StablePtr = TokenAtPtr;\n    type Green = TokenAtGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenAtGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenAt)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenAtPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalAt {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalAt {\n    const KIND: SyntaxKind = SyntaxKind::TerminalAt;\n    type TokenType = TokenAt;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalAt as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalAtGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalAt,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalAt {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenAt {\n        TokenAt::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalAtPtr(pub SyntaxStablePtrId);\nimpl TerminalAtPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalAtGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalAt {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalAt);\n    type StablePtr = TerminalAtPtr;\n    type Green = TerminalAtGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalAtGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalAt,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenAt::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalAt,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalAt\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalAtPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenBadCharacters {\n    node: SyntaxNode,\n}\nimpl Token for TokenBadCharacters {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenBadCharactersGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenBadCharacters,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenBadCharactersPtr(pub SyntaxStablePtrId);\nimpl TokenBadCharactersPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenBadCharactersGreen(pub GreenId);\nimpl TokenBadCharactersGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenBadCharacters {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenBadCharacters);\n    type StablePtr = TokenBadCharactersPtr;\n    type Green = TokenBadCharactersGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenBadCharactersGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => panic!(\n                \"Expected a token {:?}, not an internal node\",\n                SyntaxKind::TokenBadCharacters\n            ),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenBadCharactersPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalBadCharacters {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalBadCharacters {\n    const KIND: SyntaxKind = SyntaxKind::TerminalBadCharacters;\n    type TokenType = TokenBadCharacters;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalBadCharacters as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalBadCharactersGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalBadCharacters,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalBadCharacters {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenBadCharacters {\n        TokenBadCharacters::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalBadCharactersPtr(pub SyntaxStablePtrId);\nimpl TerminalBadCharactersPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalBadCharactersGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalBadCharacters {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalBadCharacters);\n    type StablePtr = TerminalBadCharactersPtr;\n    type Green = TerminalBadCharactersGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalBadCharactersGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalBadCharacters,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenBadCharacters::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalBadCharacters,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalBadCharacters\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalBadCharactersPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenColon {\n    node: SyntaxNode,\n}\nimpl Token for TokenColon {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenColonGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenColon,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenColonPtr(pub SyntaxStablePtrId);\nimpl TokenColonPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenColonGreen(pub GreenId);\nimpl TokenColonGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenColon {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenColon);\n    type StablePtr = TokenColonPtr;\n    type Green = TokenColonGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenColonGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenColon)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenColonPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalColon {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalColon {\n    const KIND: SyntaxKind = SyntaxKind::TerminalColon;\n    type TokenType = TokenColon;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalColon as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalColonGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalColon,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalColon {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenColon {\n        TokenColon::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalColonPtr(pub SyntaxStablePtrId);\nimpl TerminalColonPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalColonGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalColon {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalColon);\n    type StablePtr = TerminalColonPtr;\n    type Green = TerminalColonGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalColonGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalColon,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenColon::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalColon,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalColon\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalColonPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenColonColon {\n    node: SyntaxNode,\n}\nimpl Token for TokenColonColon {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenColonColonGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenColonColon,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenColonColonPtr(pub SyntaxStablePtrId);\nimpl TokenColonColonPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenColonColonGreen(pub GreenId);\nimpl TokenColonColonGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenColonColon {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenColonColon);\n    type StablePtr = TokenColonColonPtr;\n    type Green = TokenColonColonGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenColonColonGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenColonColon)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenColonColonPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalColonColon {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalColonColon {\n    const KIND: SyntaxKind = SyntaxKind::TerminalColonColon;\n    type TokenType = TokenColonColon;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalColonColon as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalColonColonGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalColonColon,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalColonColon {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenColonColon {\n        TokenColonColon::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalColonColonPtr(pub SyntaxStablePtrId);\nimpl TerminalColonColonPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalColonColonGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalColonColon {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalColonColon);\n    type StablePtr = TerminalColonColonPtr;\n    type Green = TerminalColonColonGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalColonColonGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalColonColon,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenColonColon::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalColonColon,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalColonColon\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalColonColonPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenComma {\n    node: SyntaxNode,\n}\nimpl Token for TokenComma {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenCommaGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenComma,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenCommaPtr(pub SyntaxStablePtrId);\nimpl TokenCommaPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenCommaGreen(pub GreenId);\nimpl TokenCommaGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenComma {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenComma);\n    type StablePtr = TokenCommaPtr;\n    type Green = TokenCommaGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenCommaGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenComma)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenCommaPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalComma {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalComma {\n    const KIND: SyntaxKind = SyntaxKind::TerminalComma;\n    type TokenType = TokenComma;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalComma as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalCommaGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalComma,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalComma {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenComma {\n        TokenComma::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalCommaPtr(pub SyntaxStablePtrId);\nimpl TerminalCommaPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalCommaGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalComma {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalComma);\n    type StablePtr = TerminalCommaPtr;\n    type Green = TerminalCommaGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalCommaGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalComma,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenComma::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalComma,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalComma\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalCommaPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenDiv {\n    node: SyntaxNode,\n}\nimpl Token for TokenDiv {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenDivGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenDiv,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenDivPtr(pub SyntaxStablePtrId);\nimpl TokenDivPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenDivGreen(pub GreenId);\nimpl TokenDivGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenDiv {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenDiv);\n    type StablePtr = TokenDivPtr;\n    type Green = TokenDivGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenDivGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenDiv)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenDivPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalDiv {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalDiv {\n    const KIND: SyntaxKind = SyntaxKind::TerminalDiv;\n    type TokenType = TokenDiv;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalDiv as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalDivGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalDiv,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalDiv {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenDiv {\n        TokenDiv::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalDivPtr(pub SyntaxStablePtrId);\nimpl TerminalDivPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalDivGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalDiv {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalDiv);\n    type StablePtr = TerminalDivPtr;\n    type Green = TerminalDivGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalDivGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalDiv,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenDiv::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalDiv,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalDiv\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalDivPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenDivEq {\n    node: SyntaxNode,\n}\nimpl Token for TokenDivEq {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenDivEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenDivEq,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenDivEqPtr(pub SyntaxStablePtrId);\nimpl TokenDivEqPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenDivEqGreen(pub GreenId);\nimpl TokenDivEqGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenDivEq {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenDivEq);\n    type StablePtr = TokenDivEqPtr;\n    type Green = TokenDivEqGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenDivEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenDivEq)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenDivEqPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalDivEq {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalDivEq {\n    const KIND: SyntaxKind = SyntaxKind::TerminalDivEq;\n    type TokenType = TokenDivEq;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalDivEq as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalDivEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalDivEq,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalDivEq {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenDivEq {\n        TokenDivEq::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalDivEqPtr(pub SyntaxStablePtrId);\nimpl TerminalDivEqPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalDivEqGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalDivEq {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalDivEq);\n    type StablePtr = TerminalDivEqPtr;\n    type Green = TerminalDivEqGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalDivEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalDivEq,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenDivEq::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalDivEq,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalDivEq\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalDivEqPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenDot {\n    node: SyntaxNode,\n}\nimpl Token for TokenDot {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenDotGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenDot,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenDotPtr(pub SyntaxStablePtrId);\nimpl TokenDotPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenDotGreen(pub GreenId);\nimpl TokenDotGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenDot {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenDot);\n    type StablePtr = TokenDotPtr;\n    type Green = TokenDotGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenDotGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenDot)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenDotPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalDot {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalDot {\n    const KIND: SyntaxKind = SyntaxKind::TerminalDot;\n    type TokenType = TokenDot;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalDot as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalDotGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalDot,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalDot {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenDot {\n        TokenDot::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalDotPtr(pub SyntaxStablePtrId);\nimpl TerminalDotPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalDotGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalDot {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalDot);\n    type StablePtr = TerminalDotPtr;\n    type Green = TerminalDotGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalDotGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalDot,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenDot::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalDot,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalDot\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalDotPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenDotDot {\n    node: SyntaxNode,\n}\nimpl Token for TokenDotDot {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenDotDotGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenDotDot,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenDotDotPtr(pub SyntaxStablePtrId);\nimpl TokenDotDotPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenDotDotGreen(pub GreenId);\nimpl TokenDotDotGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenDotDot {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenDotDot);\n    type StablePtr = TokenDotDotPtr;\n    type Green = TokenDotDotGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenDotDotGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenDotDot)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenDotDotPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalDotDot {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalDotDot {\n    const KIND: SyntaxKind = SyntaxKind::TerminalDotDot;\n    type TokenType = TokenDotDot;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalDotDot as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalDotDotGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalDotDot,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalDotDot {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenDotDot {\n        TokenDotDot::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalDotDotPtr(pub SyntaxStablePtrId);\nimpl TerminalDotDotPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalDotDotGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalDotDot {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalDotDot);\n    type StablePtr = TerminalDotDotPtr;\n    type Green = TerminalDotDotGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalDotDotGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalDotDot,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenDotDot::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalDotDot,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalDotDot\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalDotDotPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenEndOfFile {\n    node: SyntaxNode,\n}\nimpl Token for TokenEndOfFile {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenEndOfFileGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenEndOfFile,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenEndOfFilePtr(pub SyntaxStablePtrId);\nimpl TokenEndOfFilePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenEndOfFileGreen(pub GreenId);\nimpl TokenEndOfFileGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenEndOfFile {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenEndOfFile);\n    type StablePtr = TokenEndOfFilePtr;\n    type Green = TokenEndOfFileGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenEndOfFileGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenEndOfFile)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenEndOfFilePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalEndOfFile {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalEndOfFile {\n    const KIND: SyntaxKind = SyntaxKind::TerminalEndOfFile;\n    type TokenType = TokenEndOfFile;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalEndOfFile as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalEndOfFileGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalEndOfFile,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalEndOfFile {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenEndOfFile {\n        TokenEndOfFile::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalEndOfFilePtr(pub SyntaxStablePtrId);\nimpl TerminalEndOfFilePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalEndOfFileGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalEndOfFile {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalEndOfFile);\n    type StablePtr = TerminalEndOfFilePtr;\n    type Green = TerminalEndOfFileGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalEndOfFileGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalEndOfFile,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenEndOfFile::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalEndOfFile,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalEndOfFile\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalEndOfFilePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenEq {\n    node: SyntaxNode,\n}\nimpl Token for TokenEq {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenEq,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenEqPtr(pub SyntaxStablePtrId);\nimpl TokenEqPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenEqGreen(pub GreenId);\nimpl TokenEqGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenEq {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenEq);\n    type StablePtr = TokenEqPtr;\n    type Green = TokenEqGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenEq)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenEqPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalEq {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalEq {\n    const KIND: SyntaxKind = SyntaxKind::TerminalEq;\n    type TokenType = TokenEq;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalEq as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalEq,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalEq {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenEq {\n        TokenEq::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalEqPtr(pub SyntaxStablePtrId);\nimpl TerminalEqPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalEqGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalEq {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalEq);\n    type StablePtr = TerminalEqPtr;\n    type Green = TerminalEqGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalEq,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenEq::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalEq,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalEq\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalEqPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenEqEq {\n    node: SyntaxNode,\n}\nimpl Token for TokenEqEq {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenEqEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenEqEq,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenEqEqPtr(pub SyntaxStablePtrId);\nimpl TokenEqEqPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenEqEqGreen(pub GreenId);\nimpl TokenEqEqGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenEqEq {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenEqEq);\n    type StablePtr = TokenEqEqPtr;\n    type Green = TokenEqEqGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenEqEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenEqEq)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenEqEqPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalEqEq {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalEqEq {\n    const KIND: SyntaxKind = SyntaxKind::TerminalEqEq;\n    type TokenType = TokenEqEq;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalEqEq as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalEqEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalEqEq,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalEqEq {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenEqEq {\n        TokenEqEq::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalEqEqPtr(pub SyntaxStablePtrId);\nimpl TerminalEqEqPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalEqEqGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalEqEq {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalEqEq);\n    type StablePtr = TerminalEqEqPtr;\n    type Green = TerminalEqEqGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalEqEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalEqEq,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenEqEq::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalEqEq,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalEqEq\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalEqEqPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenGE {\n    node: SyntaxNode,\n}\nimpl Token for TokenGE {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenGEGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenGE,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenGEPtr(pub SyntaxStablePtrId);\nimpl TokenGEPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenGEGreen(pub GreenId);\nimpl TokenGEGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenGE {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenGE);\n    type StablePtr = TokenGEPtr;\n    type Green = TokenGEGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenGEGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenGE)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenGEPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalGE {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalGE {\n    const KIND: SyntaxKind = SyntaxKind::TerminalGE;\n    type TokenType = TokenGE;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalGE as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalGEGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalGE,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalGE {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenGE {\n        TokenGE::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalGEPtr(pub SyntaxStablePtrId);\nimpl TerminalGEPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalGEGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalGE {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalGE);\n    type StablePtr = TerminalGEPtr;\n    type Green = TerminalGEGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalGEGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalGE,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenGE::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalGE,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalGE\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalGEPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenGT {\n    node: SyntaxNode,\n}\nimpl Token for TokenGT {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenGTGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenGT,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenGTPtr(pub SyntaxStablePtrId);\nimpl TokenGTPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenGTGreen(pub GreenId);\nimpl TokenGTGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenGT {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenGT);\n    type StablePtr = TokenGTPtr;\n    type Green = TokenGTGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenGTGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenGT)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenGTPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalGT {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalGT {\n    const KIND: SyntaxKind = SyntaxKind::TerminalGT;\n    type TokenType = TokenGT;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalGT as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalGTGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalGT,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalGT {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenGT {\n        TokenGT::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalGTPtr(pub SyntaxStablePtrId);\nimpl TerminalGTPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalGTGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalGT {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalGT);\n    type StablePtr = TerminalGTPtr;\n    type Green = TerminalGTGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalGTGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalGT,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenGT::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalGT,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalGT\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalGTPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenHash {\n    node: SyntaxNode,\n}\nimpl Token for TokenHash {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenHashGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenHash,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenHashPtr(pub SyntaxStablePtrId);\nimpl TokenHashPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenHashGreen(pub GreenId);\nimpl TokenHashGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenHash {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenHash);\n    type StablePtr = TokenHashPtr;\n    type Green = TokenHashGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenHashGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenHash)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenHashPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalHash {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalHash {\n    const KIND: SyntaxKind = SyntaxKind::TerminalHash;\n    type TokenType = TokenHash;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalHash as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalHashGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalHash,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalHash {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenHash {\n        TokenHash::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalHashPtr(pub SyntaxStablePtrId);\nimpl TerminalHashPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalHashGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalHash {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalHash);\n    type StablePtr = TerminalHashPtr;\n    type Green = TerminalHashGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalHashGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalHash,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenHash::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalHash,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalHash\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalHashPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenLBrace {\n    node: SyntaxNode,\n}\nimpl Token for TokenLBrace {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenLBraceGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenLBrace,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenLBracePtr(pub SyntaxStablePtrId);\nimpl TokenLBracePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenLBraceGreen(pub GreenId);\nimpl TokenLBraceGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenLBrace {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenLBrace);\n    type StablePtr = TokenLBracePtr;\n    type Green = TokenLBraceGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenLBraceGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenLBrace)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenLBracePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalLBrace {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalLBrace {\n    const KIND: SyntaxKind = SyntaxKind::TerminalLBrace;\n    type TokenType = TokenLBrace;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalLBrace as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalLBraceGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalLBrace,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalLBrace {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenLBrace {\n        TokenLBrace::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalLBracePtr(pub SyntaxStablePtrId);\nimpl TerminalLBracePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalLBraceGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalLBrace {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalLBrace);\n    type StablePtr = TerminalLBracePtr;\n    type Green = TerminalLBraceGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalLBraceGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalLBrace,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenLBrace::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalLBrace,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalLBrace\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalLBracePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenLBrack {\n    node: SyntaxNode,\n}\nimpl Token for TokenLBrack {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenLBrackGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenLBrack,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenLBrackPtr(pub SyntaxStablePtrId);\nimpl TokenLBrackPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenLBrackGreen(pub GreenId);\nimpl TokenLBrackGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenLBrack {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenLBrack);\n    type StablePtr = TokenLBrackPtr;\n    type Green = TokenLBrackGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenLBrackGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenLBrack)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenLBrackPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalLBrack {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalLBrack {\n    const KIND: SyntaxKind = SyntaxKind::TerminalLBrack;\n    type TokenType = TokenLBrack;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalLBrack as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalLBrackGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalLBrack,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalLBrack {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenLBrack {\n        TokenLBrack::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalLBrackPtr(pub SyntaxStablePtrId);\nimpl TerminalLBrackPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalLBrackGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalLBrack {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalLBrack);\n    type StablePtr = TerminalLBrackPtr;\n    type Green = TerminalLBrackGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalLBrackGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalLBrack,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenLBrack::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalLBrack,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalLBrack\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalLBrackPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenLE {\n    node: SyntaxNode,\n}\nimpl Token for TokenLE {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenLEGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenLE,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenLEPtr(pub SyntaxStablePtrId);\nimpl TokenLEPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenLEGreen(pub GreenId);\nimpl TokenLEGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenLE {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenLE);\n    type StablePtr = TokenLEPtr;\n    type Green = TokenLEGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenLEGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenLE)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenLEPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalLE {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalLE {\n    const KIND: SyntaxKind = SyntaxKind::TerminalLE;\n    type TokenType = TokenLE;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalLE as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalLEGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalLE,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalLE {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenLE {\n        TokenLE::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalLEPtr(pub SyntaxStablePtrId);\nimpl TerminalLEPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalLEGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalLE {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalLE);\n    type StablePtr = TerminalLEPtr;\n    type Green = TerminalLEGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalLEGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalLE,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenLE::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalLE,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalLE\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalLEPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenLParen {\n    node: SyntaxNode,\n}\nimpl Token for TokenLParen {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenLParenGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenLParen,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenLParenPtr(pub SyntaxStablePtrId);\nimpl TokenLParenPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenLParenGreen(pub GreenId);\nimpl TokenLParenGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenLParen {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenLParen);\n    type StablePtr = TokenLParenPtr;\n    type Green = TokenLParenGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenLParenGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenLParen)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenLParenPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalLParen {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalLParen {\n    const KIND: SyntaxKind = SyntaxKind::TerminalLParen;\n    type TokenType = TokenLParen;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalLParen as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalLParenGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalLParen,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalLParen {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenLParen {\n        TokenLParen::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalLParenPtr(pub SyntaxStablePtrId);\nimpl TerminalLParenPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalLParenGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalLParen {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalLParen);\n    type StablePtr = TerminalLParenPtr;\n    type Green = TerminalLParenGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalLParenGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalLParen,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenLParen::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalLParen,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalLParen\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalLParenPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenLT {\n    node: SyntaxNode,\n}\nimpl Token for TokenLT {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenLTGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenLT,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenLTPtr(pub SyntaxStablePtrId);\nimpl TokenLTPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenLTGreen(pub GreenId);\nimpl TokenLTGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenLT {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenLT);\n    type StablePtr = TokenLTPtr;\n    type Green = TokenLTGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenLTGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenLT)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenLTPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalLT {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalLT {\n    const KIND: SyntaxKind = SyntaxKind::TerminalLT;\n    type TokenType = TokenLT;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalLT as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalLTGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalLT,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalLT {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenLT {\n        TokenLT::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalLTPtr(pub SyntaxStablePtrId);\nimpl TerminalLTPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalLTGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalLT {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalLT);\n    type StablePtr = TerminalLTPtr;\n    type Green = TerminalLTGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalLTGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalLT,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenLT::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalLT,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalLT\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalLTPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenMatchArrow {\n    node: SyntaxNode,\n}\nimpl Token for TokenMatchArrow {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenMatchArrowGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMatchArrow,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenMatchArrowPtr(pub SyntaxStablePtrId);\nimpl TokenMatchArrowPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenMatchArrowGreen(pub GreenId);\nimpl TokenMatchArrowGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenMatchArrow {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenMatchArrow);\n    type StablePtr = TokenMatchArrowPtr;\n    type Green = TokenMatchArrowGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenMatchArrowGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenMatchArrow)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenMatchArrowPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalMatchArrow {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalMatchArrow {\n    const KIND: SyntaxKind = SyntaxKind::TerminalMatchArrow;\n    type TokenType = TokenMatchArrow;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalMatchArrow as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalMatchArrowGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalMatchArrow,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalMatchArrow {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenMatchArrow {\n        TokenMatchArrow::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalMatchArrowPtr(pub SyntaxStablePtrId);\nimpl TerminalMatchArrowPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalMatchArrowGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalMatchArrow {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalMatchArrow);\n    type StablePtr = TerminalMatchArrowPtr;\n    type Green = TerminalMatchArrowGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalMatchArrowGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalMatchArrow,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenMatchArrow::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalMatchArrow,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalMatchArrow\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalMatchArrowPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenMinus {\n    node: SyntaxNode,\n}\nimpl Token for TokenMinus {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenMinusGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMinus,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenMinusPtr(pub SyntaxStablePtrId);\nimpl TokenMinusPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenMinusGreen(pub GreenId);\nimpl TokenMinusGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenMinus {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenMinus);\n    type StablePtr = TokenMinusPtr;\n    type Green = TokenMinusGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenMinusGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenMinus)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenMinusPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalMinus {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalMinus {\n    const KIND: SyntaxKind = SyntaxKind::TerminalMinus;\n    type TokenType = TokenMinus;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalMinus as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalMinusGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalMinus,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalMinus {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenMinus {\n        TokenMinus::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalMinusPtr(pub SyntaxStablePtrId);\nimpl TerminalMinusPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalMinusGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalMinus {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalMinus);\n    type StablePtr = TerminalMinusPtr;\n    type Green = TerminalMinusGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalMinusGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalMinus,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenMinus::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalMinus,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalMinus\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalMinusPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenMinusEq {\n    node: SyntaxNode,\n}\nimpl Token for TokenMinusEq {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenMinusEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMinusEq,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenMinusEqPtr(pub SyntaxStablePtrId);\nimpl TokenMinusEqPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenMinusEqGreen(pub GreenId);\nimpl TokenMinusEqGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenMinusEq {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenMinusEq);\n    type StablePtr = TokenMinusEqPtr;\n    type Green = TokenMinusEqGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenMinusEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenMinusEq)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenMinusEqPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalMinusEq {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalMinusEq {\n    const KIND: SyntaxKind = SyntaxKind::TerminalMinusEq;\n    type TokenType = TokenMinusEq;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalMinusEq as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalMinusEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalMinusEq,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalMinusEq {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenMinusEq {\n        TokenMinusEq::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalMinusEqPtr(pub SyntaxStablePtrId);\nimpl TerminalMinusEqPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalMinusEqGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalMinusEq {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalMinusEq);\n    type StablePtr = TerminalMinusEqPtr;\n    type Green = TerminalMinusEqGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalMinusEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalMinusEq,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenMinusEq::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalMinusEq,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalMinusEq\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalMinusEqPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenMod {\n    node: SyntaxNode,\n}\nimpl Token for TokenMod {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenModGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMod,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenModPtr(pub SyntaxStablePtrId);\nimpl TokenModPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenModGreen(pub GreenId);\nimpl TokenModGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenMod {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenMod);\n    type StablePtr = TokenModPtr;\n    type Green = TokenModGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenModGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenMod)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenModPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalMod {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalMod {\n    const KIND: SyntaxKind = SyntaxKind::TerminalMod;\n    type TokenType = TokenMod;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalMod as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalModGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalMod,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalMod {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenMod {\n        TokenMod::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalModPtr(pub SyntaxStablePtrId);\nimpl TerminalModPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalModGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalMod {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalMod);\n    type StablePtr = TerminalModPtr;\n    type Green = TerminalModGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalModGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalMod,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenMod::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalMod,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalMod\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalModPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenModEq {\n    node: SyntaxNode,\n}\nimpl Token for TokenModEq {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenModEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenModEq,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenModEqPtr(pub SyntaxStablePtrId);\nimpl TokenModEqPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenModEqGreen(pub GreenId);\nimpl TokenModEqGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenModEq {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenModEq);\n    type StablePtr = TokenModEqPtr;\n    type Green = TokenModEqGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenModEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenModEq)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenModEqPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalModEq {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalModEq {\n    const KIND: SyntaxKind = SyntaxKind::TerminalModEq;\n    type TokenType = TokenModEq;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalModEq as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalModEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalModEq,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalModEq {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenModEq {\n        TokenModEq::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalModEqPtr(pub SyntaxStablePtrId);\nimpl TerminalModEqPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalModEqGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalModEq {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalModEq);\n    type StablePtr = TerminalModEqPtr;\n    type Green = TerminalModEqGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalModEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalModEq,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenModEq::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalModEq,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalModEq\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalModEqPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenMul {\n    node: SyntaxNode,\n}\nimpl Token for TokenMul {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenMulGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMul,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenMulPtr(pub SyntaxStablePtrId);\nimpl TokenMulPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenMulGreen(pub GreenId);\nimpl TokenMulGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenMul {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenMul);\n    type StablePtr = TokenMulPtr;\n    type Green = TokenMulGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenMulGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenMul)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenMulPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalMul {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalMul {\n    const KIND: SyntaxKind = SyntaxKind::TerminalMul;\n    type TokenType = TokenMul;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalMul as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalMulGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalMul,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalMul {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenMul {\n        TokenMul::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalMulPtr(pub SyntaxStablePtrId);\nimpl TerminalMulPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalMulGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalMul {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalMul);\n    type StablePtr = TerminalMulPtr;\n    type Green = TerminalMulGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalMulGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalMul,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenMul::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalMul,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalMul\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalMulPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenMulEq {\n    node: SyntaxNode,\n}\nimpl Token for TokenMulEq {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenMulEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMulEq,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenMulEqPtr(pub SyntaxStablePtrId);\nimpl TokenMulEqPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenMulEqGreen(pub GreenId);\nimpl TokenMulEqGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenMulEq {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenMulEq);\n    type StablePtr = TokenMulEqPtr;\n    type Green = TokenMulEqGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenMulEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenMulEq)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenMulEqPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalMulEq {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalMulEq {\n    const KIND: SyntaxKind = SyntaxKind::TerminalMulEq;\n    type TokenType = TokenMulEq;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalMulEq as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalMulEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalMulEq,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalMulEq {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenMulEq {\n        TokenMulEq::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalMulEqPtr(pub SyntaxStablePtrId);\nimpl TerminalMulEqPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalMulEqGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalMulEq {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalMulEq);\n    type StablePtr = TerminalMulEqPtr;\n    type Green = TerminalMulEqGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalMulEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalMulEq,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenMulEq::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalMulEq,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalMulEq\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalMulEqPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenNeq {\n    node: SyntaxNode,\n}\nimpl Token for TokenNeq {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenNeqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenNeq,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenNeqPtr(pub SyntaxStablePtrId);\nimpl TokenNeqPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenNeqGreen(pub GreenId);\nimpl TokenNeqGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenNeq {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenNeq);\n    type StablePtr = TokenNeqPtr;\n    type Green = TokenNeqGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenNeqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenNeq)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenNeqPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalNeq {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalNeq {\n    const KIND: SyntaxKind = SyntaxKind::TerminalNeq;\n    type TokenType = TokenNeq;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalNeq as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalNeqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalNeq,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalNeq {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenNeq {\n        TokenNeq::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalNeqPtr(pub SyntaxStablePtrId);\nimpl TerminalNeqPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalNeqGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalNeq {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalNeq);\n    type StablePtr = TerminalNeqPtr;\n    type Green = TerminalNeqGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalNeqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalNeq,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenNeq::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalNeq,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalNeq\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalNeqPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenNot {\n    node: SyntaxNode,\n}\nimpl Token for TokenNot {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenNotGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenNot,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenNotPtr(pub SyntaxStablePtrId);\nimpl TokenNotPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenNotGreen(pub GreenId);\nimpl TokenNotGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenNot {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenNot);\n    type StablePtr = TokenNotPtr;\n    type Green = TokenNotGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenNotGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenNot)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenNotPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalNot {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalNot {\n    const KIND: SyntaxKind = SyntaxKind::TerminalNot;\n    type TokenType = TokenNot;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalNot as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalNotGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalNot,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalNot {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenNot {\n        TokenNot::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalNotPtr(pub SyntaxStablePtrId);\nimpl TerminalNotPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalNotGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalNot {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalNot);\n    type StablePtr = TerminalNotPtr;\n    type Green = TerminalNotGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalNotGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalNot,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenNot::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalNot,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalNot\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalNotPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenOr {\n    node: SyntaxNode,\n}\nimpl Token for TokenOr {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenOrGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenOr,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenOrPtr(pub SyntaxStablePtrId);\nimpl TokenOrPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenOrGreen(pub GreenId);\nimpl TokenOrGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenOr {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenOr);\n    type StablePtr = TokenOrPtr;\n    type Green = TokenOrGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenOrGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenOr)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenOrPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalOr {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalOr {\n    const KIND: SyntaxKind = SyntaxKind::TerminalOr;\n    type TokenType = TokenOr;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalOr as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalOrGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalOr,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalOr {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenOr {\n        TokenOr::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalOrPtr(pub SyntaxStablePtrId);\nimpl TerminalOrPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalOrGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalOr {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalOr);\n    type StablePtr = TerminalOrPtr;\n    type Green = TerminalOrGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalOrGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalOr,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenOr::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalOr,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalOr\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalOrPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenOrOr {\n    node: SyntaxNode,\n}\nimpl Token for TokenOrOr {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenOrOrGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenOrOr,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenOrOrPtr(pub SyntaxStablePtrId);\nimpl TokenOrOrPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenOrOrGreen(pub GreenId);\nimpl TokenOrOrGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenOrOr {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenOrOr);\n    type StablePtr = TokenOrOrPtr;\n    type Green = TokenOrOrGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenOrOrGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenOrOr)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenOrOrPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalOrOr {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalOrOr {\n    const KIND: SyntaxKind = SyntaxKind::TerminalOrOr;\n    type TokenType = TokenOrOr;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalOrOr as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalOrOrGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalOrOr,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalOrOr {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenOrOr {\n        TokenOrOr::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalOrOrPtr(pub SyntaxStablePtrId);\nimpl TerminalOrOrPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalOrOrGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalOrOr {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalOrOr);\n    type StablePtr = TerminalOrOrPtr;\n    type Green = TerminalOrOrGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalOrOrGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalOrOr,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenOrOr::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalOrOr,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalOrOr\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalOrOrPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenPlus {\n    node: SyntaxNode,\n}\nimpl Token for TokenPlus {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenPlusGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenPlus,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenPlusPtr(pub SyntaxStablePtrId);\nimpl TokenPlusPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenPlusGreen(pub GreenId);\nimpl TokenPlusGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenPlus {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenPlus);\n    type StablePtr = TokenPlusPtr;\n    type Green = TokenPlusGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenPlusGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenPlus)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenPlusPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalPlus {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalPlus {\n    const KIND: SyntaxKind = SyntaxKind::TerminalPlus;\n    type TokenType = TokenPlus;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalPlus as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalPlusGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalPlus,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalPlus {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenPlus {\n        TokenPlus::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalPlusPtr(pub SyntaxStablePtrId);\nimpl TerminalPlusPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalPlusGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalPlus {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalPlus);\n    type StablePtr = TerminalPlusPtr;\n    type Green = TerminalPlusGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalPlusGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalPlus,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenPlus::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalPlus,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalPlus\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalPlusPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenPlusEq {\n    node: SyntaxNode,\n}\nimpl Token for TokenPlusEq {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenPlusEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenPlusEq,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenPlusEqPtr(pub SyntaxStablePtrId);\nimpl TokenPlusEqPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenPlusEqGreen(pub GreenId);\nimpl TokenPlusEqGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenPlusEq {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenPlusEq);\n    type StablePtr = TokenPlusEqPtr;\n    type Green = TokenPlusEqGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenPlusEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenPlusEq)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenPlusEqPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalPlusEq {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalPlusEq {\n    const KIND: SyntaxKind = SyntaxKind::TerminalPlusEq;\n    type TokenType = TokenPlusEq;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalPlusEq as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalPlusEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalPlusEq,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalPlusEq {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenPlusEq {\n        TokenPlusEq::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalPlusEqPtr(pub SyntaxStablePtrId);\nimpl TerminalPlusEqPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalPlusEqGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalPlusEq {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalPlusEq);\n    type StablePtr = TerminalPlusEqPtr;\n    type Green = TerminalPlusEqGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalPlusEqGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalPlusEq,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenPlusEq::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalPlusEq,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalPlusEq\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalPlusEqPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenQuestionMark {\n    node: SyntaxNode,\n}\nimpl Token for TokenQuestionMark {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenQuestionMarkGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenQuestionMark,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenQuestionMarkPtr(pub SyntaxStablePtrId);\nimpl TokenQuestionMarkPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenQuestionMarkGreen(pub GreenId);\nimpl TokenQuestionMarkGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenQuestionMark {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenQuestionMark);\n    type StablePtr = TokenQuestionMarkPtr;\n    type Green = TokenQuestionMarkGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenQuestionMarkGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenQuestionMark)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenQuestionMarkPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalQuestionMark {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalQuestionMark {\n    const KIND: SyntaxKind = SyntaxKind::TerminalQuestionMark;\n    type TokenType = TokenQuestionMark;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalQuestionMark as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalQuestionMarkGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalQuestionMark,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalQuestionMark {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenQuestionMark {\n        TokenQuestionMark::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalQuestionMarkPtr(pub SyntaxStablePtrId);\nimpl TerminalQuestionMarkPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalQuestionMarkGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalQuestionMark {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalQuestionMark);\n    type StablePtr = TerminalQuestionMarkPtr;\n    type Green = TerminalQuestionMarkGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalQuestionMarkGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalQuestionMark,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenQuestionMark::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalQuestionMark,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalQuestionMark\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalQuestionMarkPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenRBrace {\n    node: SyntaxNode,\n}\nimpl Token for TokenRBrace {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenRBraceGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenRBrace,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenRBracePtr(pub SyntaxStablePtrId);\nimpl TokenRBracePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenRBraceGreen(pub GreenId);\nimpl TokenRBraceGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenRBrace {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenRBrace);\n    type StablePtr = TokenRBracePtr;\n    type Green = TokenRBraceGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenRBraceGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenRBrace)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenRBracePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalRBrace {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalRBrace {\n    const KIND: SyntaxKind = SyntaxKind::TerminalRBrace;\n    type TokenType = TokenRBrace;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalRBrace as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalRBraceGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalRBrace,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalRBrace {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenRBrace {\n        TokenRBrace::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalRBracePtr(pub SyntaxStablePtrId);\nimpl TerminalRBracePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalRBraceGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalRBrace {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalRBrace);\n    type StablePtr = TerminalRBracePtr;\n    type Green = TerminalRBraceGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalRBraceGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalRBrace,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenRBrace::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalRBrace,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalRBrace\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalRBracePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenRBrack {\n    node: SyntaxNode,\n}\nimpl Token for TokenRBrack {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenRBrackGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenRBrack,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenRBrackPtr(pub SyntaxStablePtrId);\nimpl TokenRBrackPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenRBrackGreen(pub GreenId);\nimpl TokenRBrackGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenRBrack {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenRBrack);\n    type StablePtr = TokenRBrackPtr;\n    type Green = TokenRBrackGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenRBrackGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenRBrack)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenRBrackPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalRBrack {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalRBrack {\n    const KIND: SyntaxKind = SyntaxKind::TerminalRBrack;\n    type TokenType = TokenRBrack;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalRBrack as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalRBrackGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalRBrack,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalRBrack {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenRBrack {\n        TokenRBrack::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalRBrackPtr(pub SyntaxStablePtrId);\nimpl TerminalRBrackPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalRBrackGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalRBrack {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalRBrack);\n    type StablePtr = TerminalRBrackPtr;\n    type Green = TerminalRBrackGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalRBrackGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalRBrack,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenRBrack::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalRBrack,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalRBrack\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalRBrackPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenRParen {\n    node: SyntaxNode,\n}\nimpl Token for TokenRParen {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenRParenGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenRParen,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenRParenPtr(pub SyntaxStablePtrId);\nimpl TokenRParenPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenRParenGreen(pub GreenId);\nimpl TokenRParenGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenRParen {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenRParen);\n    type StablePtr = TokenRParenPtr;\n    type Green = TokenRParenGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenRParenGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenRParen)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenRParenPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalRParen {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalRParen {\n    const KIND: SyntaxKind = SyntaxKind::TerminalRParen;\n    type TokenType = TokenRParen;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalRParen as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalRParenGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalRParen,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalRParen {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenRParen {\n        TokenRParen::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalRParenPtr(pub SyntaxStablePtrId);\nimpl TerminalRParenPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalRParenGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalRParen {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalRParen);\n    type StablePtr = TerminalRParenPtr;\n    type Green = TerminalRParenGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalRParenGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalRParen,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenRParen::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalRParen,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalRParen\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalRParenPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenSemicolon {\n    node: SyntaxNode,\n}\nimpl Token for TokenSemicolon {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenSemicolonGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenSemicolon,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenSemicolonPtr(pub SyntaxStablePtrId);\nimpl TokenSemicolonPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenSemicolonGreen(pub GreenId);\nimpl TokenSemicolonGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenSemicolon {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenSemicolon);\n    type StablePtr = TokenSemicolonPtr;\n    type Green = TokenSemicolonGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenSemicolonGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenSemicolon)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenSemicolonPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalSemicolon {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalSemicolon {\n    const KIND: SyntaxKind = SyntaxKind::TerminalSemicolon;\n    type TokenType = TokenSemicolon;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalSemicolon as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalSemicolonGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalSemicolon,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalSemicolon {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenSemicolon {\n        TokenSemicolon::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalSemicolonPtr(pub SyntaxStablePtrId);\nimpl TerminalSemicolonPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalSemicolonGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalSemicolon {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalSemicolon);\n    type StablePtr = TerminalSemicolonPtr;\n    type Green = TerminalSemicolonGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalSemicolonGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalSemicolon,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenSemicolon::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalSemicolon,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalSemicolon\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalSemicolonPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenUnderscore {\n    node: SyntaxNode,\n}\nimpl Token for TokenUnderscore {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenUnderscoreGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenUnderscore,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenUnderscorePtr(pub SyntaxStablePtrId);\nimpl TokenUnderscorePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenUnderscoreGreen(pub GreenId);\nimpl TokenUnderscoreGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenUnderscore {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenUnderscore);\n    type StablePtr = TokenUnderscorePtr;\n    type Green = TokenUnderscoreGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenUnderscoreGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenUnderscore)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenUnderscorePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalUnderscore {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalUnderscore {\n    const KIND: SyntaxKind = SyntaxKind::TerminalUnderscore;\n    type TokenType = TokenUnderscore;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalUnderscore as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalUnderscoreGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalUnderscore,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalUnderscore {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenUnderscore {\n        TokenUnderscore::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalUnderscorePtr(pub SyntaxStablePtrId);\nimpl TerminalUnderscorePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalUnderscoreGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalUnderscore {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalUnderscore);\n    type StablePtr = TerminalUnderscorePtr;\n    type Green = TerminalUnderscoreGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalUnderscoreGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalUnderscore,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenUnderscore::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalUnderscore,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalUnderscore\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalUnderscorePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenXor {\n    node: SyntaxNode,\n}\nimpl Token for TokenXor {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenXorGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenXor,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenXorPtr(pub SyntaxStablePtrId);\nimpl TokenXorPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenXorGreen(pub GreenId);\nimpl TokenXorGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenXor {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenXor);\n    type StablePtr = TokenXorPtr;\n    type Green = TokenXorGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenXorGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenXor)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenXorPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TerminalXor {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl Terminal for TerminalXor {\n    const KIND: SyntaxKind = SyntaxKind::TerminalXor;\n    type TokenType = TokenXor;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<TerminalXor as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> Self::Green {\n        let children: Vec<GreenId> = vec![leading_trivia.0, token.0, trailing_trivia.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        TerminalXorGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalXor,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.token(db).text(db)\n    }\n}\nimpl TerminalXor {\n    pub fn leading_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn token(&self, db: &dyn SyntaxGroup) -> TokenXor {\n        TokenXor::from_syntax_node(db, self.children[1].clone())\n    }\n    pub fn trailing_trivia(&self, db: &dyn SyntaxGroup) -> Trivia {\n        Trivia::from_syntax_node(db, self.children[2].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalXorPtr(pub SyntaxStablePtrId);\nimpl TerminalXorPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TerminalXorGreen(pub GreenId);\nimpl TypedSyntaxNode for TerminalXor {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TerminalXor);\n    type StablePtr = TerminalXorPtr;\n    type Green = TerminalXorGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TerminalXorGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TerminalXor,\n            details: GreenNodeDetails::Node {\n                children: vec![\n                    Trivia::missing(db).0,\n                    TokenXor::missing(db).0,\n                    Trivia::missing(db).0,\n                ],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::TerminalXor,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::TerminalXor\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TerminalXorPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct SyntaxFile {\n    node: SyntaxNode,\n    children: Vec<SyntaxNode>,\n}\nimpl SyntaxFile {\n    pub const INDEX_ITEMS: usize = 0;\n    pub const INDEX_EOF: usize = 1;\n    pub fn new_green(\n        db: &dyn SyntaxGroup,\n        items: ItemListGreen,\n        eof: TerminalEndOfFileGreen,\n    ) -> SyntaxFileGreen {\n        let children: Vec<GreenId> = vec![items.0, eof.0];\n        let width = children.iter().copied().map(|id| db.lookup_intern_green(id).width()).sum();\n        SyntaxFileGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::SyntaxFile,\n            details: GreenNodeDetails::Node { children, width },\n        }))\n    }\n}\nimpl SyntaxFile {\n    pub fn items(&self, db: &dyn SyntaxGroup) -> ItemList {\n        ItemList::from_syntax_node(db, self.children[0].clone())\n    }\n    pub fn eof(&self, db: &dyn SyntaxGroup) -> TerminalEndOfFile {\n        TerminalEndOfFile::from_syntax_node(db, self.children[1].clone())\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct SyntaxFilePtr(pub SyntaxStablePtrId);\nimpl SyntaxFilePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct SyntaxFileGreen(pub GreenId);\nimpl TypedSyntaxNode for SyntaxFile {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::SyntaxFile);\n    type StablePtr = SyntaxFilePtr;\n    type Green = SyntaxFileGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        SyntaxFileGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::SyntaxFile,\n            details: GreenNodeDetails::Node {\n                children: vec![ItemList::missing(db).0, TerminalEndOfFile::missing(db).0],\n                width: TextWidth::default(),\n            },\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        let kind = node.kind(db);\n        assert_eq!(\n            kind,\n            SyntaxKind::SyntaxFile,\n            \"Unexpected SyntaxKind {:?}. Expected {:?}.\",\n            kind,\n            SyntaxKind::SyntaxFile\n        );\n        let children = node.children(db).collect();\n        Self { node, children }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        SyntaxFilePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenSingleLineComment {\n    node: SyntaxNode,\n}\nimpl Token for TokenSingleLineComment {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenSingleLineCommentGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenSingleLineComment,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenSingleLineCommentPtr(pub SyntaxStablePtrId);\nimpl TokenSingleLineCommentPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenSingleLineCommentGreen(pub GreenId);\nimpl TokenSingleLineCommentGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenSingleLineComment {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenSingleLineComment);\n    type StablePtr = TokenSingleLineCommentPtr;\n    type Green = TokenSingleLineCommentGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenSingleLineCommentGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => panic!(\n                \"Expected a token {:?}, not an internal node\",\n                SyntaxKind::TokenSingleLineComment\n            ),\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenSingleLineCommentPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenWhitespace {\n    node: SyntaxNode,\n}\nimpl Token for TokenWhitespace {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenWhitespaceGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenWhitespace,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenWhitespacePtr(pub SyntaxStablePtrId);\nimpl TokenWhitespacePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenWhitespaceGreen(pub GreenId);\nimpl TokenWhitespaceGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenWhitespace {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenWhitespace);\n    type StablePtr = TokenWhitespacePtr;\n    type Green = TokenWhitespaceGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenWhitespaceGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenWhitespace)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenWhitespacePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenNewline {\n    node: SyntaxNode,\n}\nimpl Token for TokenNewline {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenNewlineGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenNewline,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenNewlinePtr(pub SyntaxStablePtrId);\nimpl TokenNewlinePtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenNewlineGreen(pub GreenId);\nimpl TokenNewlineGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenNewline {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenNewline);\n    type StablePtr = TokenNewlinePtr;\n    type Green = TokenNewlineGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenNewlineGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenNewline)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenNewlinePtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenMissing {\n    node: SyntaxNode,\n}\nimpl Token for TokenMissing {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenMissingGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenMissingPtr(pub SyntaxStablePtrId);\nimpl TokenMissingPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenMissingGreen(pub GreenId);\nimpl TokenMissingGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenMissing {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenMissing);\n    type StablePtr = TokenMissingPtr;\n    type Green = TokenMissingGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenMissingGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenMissing)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenMissingPtr(self.node.0.stable_ptr)\n    }\n}\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct TokenSkipped {\n    node: SyntaxNode,\n}\nimpl Token for TokenSkipped {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n        TokenSkippedGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenSkipped,\n            details: GreenNodeDetails::Token(text),\n        }))\n    }\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenSkippedPtr(pub SyntaxStablePtrId);\nimpl TokenSkippedPtr {\n    pub fn untyped(&self) -> SyntaxStablePtrId {\n        self.0\n    }\n}\n#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\npub struct TokenSkippedGreen(pub GreenId);\nimpl TokenSkippedGreen {\n    pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n    }\n}\nimpl TypedSyntaxNode for TokenSkipped {\n    const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::TokenSkipped);\n    type StablePtr = TokenSkippedPtr;\n    type Green = TokenSkippedGreen;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n        TokenSkippedGreen(db.intern_green(GreenNode {\n            kind: SyntaxKind::TokenMissing,\n            details: GreenNodeDetails::Token(\"\".into()),\n        }))\n    }\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n        match db.lookup_intern_green(node.0.green).details {\n            GreenNodeDetails::Token(_) => Self { node },\n            GreenNodeDetails::Node { .. } => {\n                panic!(\"Expected a token {:?}, not an internal node\", SyntaxKind::TokenSkipped)\n            }\n        }\n    }\n    fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n        Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n    }\n    fn as_syntax_node(&self) -> SyntaxNode {\n        self.node.clone()\n    }\n    fn stable_ptr(&self) -> Self::StablePtr {\n        TokenSkippedPtr(self.node.0.stable_ptr)\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_filesystem::span::{TextOffset, TextWidth};\nuse pretty_assertions::assert_eq;\nuse smol_str::SmolStr;\nuse test_log::test;\n\nuse super::ast::{\n    ExprBinary, ExprPath, PathSegmentGreen, PathSegmentSimple, SyntaxFileGreen, TerminalIdentifier,\n    TerminalLiteralNumber, TerminalPlus, TokenIdentifier, TokenLiteralNumber, TokenPlus,\n    TokenWhitespace, Trivia,\n};\nuse super::kind::SyntaxKind;\nuse super::{SyntaxGroup, SyntaxNode, Terminal, Token};\nuse crate::node::test_utils::DatabaseForTesting;\n\nfn traverse(\n    db: &dyn SyntaxGroup,\n    node: SyntaxNode,\n) -> Vec<(SyntaxKind, Option<SmolStr>, TextOffset, TextWidth)> {\n    let mut res = vec![(node.kind(db), node.text(db), node.offset(), node.width(db))];\n    for child in node.children(db) {\n        res.append(&mut traverse(db, child));\n    }\n    res\n}\n\n#[test]\nfn test_ast() {\n    let db_val = DatabaseForTesting::default();\n    let db = &db_val;\n    let root = setup(db);\n\n    assert_eq!(\n        traverse(db, root),\n        [\n            (\n                SyntaxKind::ExprBinary,\n                None,\n                TextOffset::default().add_width(TextWidth::new_for_testing(0)),\n                TextWidth::new_for_testing(7)\n            ),\n            (\n                SyntaxKind::ExprPath,\n                None,\n                TextOffset::default().add_width(TextWidth::new_for_testing(0)),\n                TextWidth::new_for_testing(4)\n            ),\n            (\n                SyntaxKind::PathSegmentSimple,\n                None,\n                TextOffset::default().add_width(TextWidth::new_for_testing(0)),\n                TextWidth::new_for_testing(4)\n            ),\n            (\n                SyntaxKind::TerminalIdentifier,\n                None,\n                TextOffset::default().add_width(TextWidth::new_for_testing(0)),\n                TextWidth::new_for_testing(4)\n            ),\n            (\n                SyntaxKind::Trivia,\n                None,\n                TextOffset::default().add_width(TextWidth::new_for_testing(0)),\n                TextWidth::new_for_testing(0)\n            ),\n            (\n                SyntaxKind::TokenIdentifier,\n                Some(\"foo\".into()),\n                TextOffset::default().add_width(TextWidth::new_for_testing(0)),\n                TextWidth::new_for_testing(3)\n            ),\n            (\n                SyntaxKind::Trivia,\n                None,\n                TextOffset::default().add_width(TextWidth::new_for_testing(3)),\n                TextWidth::new_for_testing(1)\n            ),\n            (\n                SyntaxKind::TokenWhitespace,\n                Some(\" \".into()),\n                TextOffset::default().add_width(TextWidth::new_for_testing(3)),\n                TextWidth::new_for_testing(1)\n            ),\n            (\n                SyntaxKind::TerminalPlus,\n                None,\n                TextOffset::default().add_width(TextWidth::new_for_testing(4)),\n                TextWidth::new_for_testing(2)\n            ),\n            (\n                SyntaxKind::Trivia,\n                None,\n                TextOffset::default().add_width(TextWidth::new_for_testing(4)),\n                TextWidth::new_for_testing(0)\n            ),\n            (\n                SyntaxKind::TokenPlus,\n                Some(\"+\".into()),\n                TextOffset::default().add_width(TextWidth::new_for_testing(4)),\n                TextWidth::new_for_testing(1)\n            ),\n            (\n                SyntaxKind::Trivia,\n                None,\n                TextOffset::default().add_width(TextWidth::new_for_testing(5)),\n                TextWidth::new_for_testing(1)\n            ),\n            (\n                SyntaxKind::TokenWhitespace,\n                Some(\" \".into()),\n                TextOffset::default().add_width(TextWidth::new_for_testing(5)),\n                TextWidth::new_for_testing(1)\n            ),\n            (\n                SyntaxKind::TerminalLiteralNumber,\n                None,\n                TextOffset::default().add_width(TextWidth::new_for_testing(6)),\n                TextWidth::new_for_testing(1)\n            ),\n            (\n                SyntaxKind::Trivia,\n                None,\n                TextOffset::default().add_width(TextWidth::new_for_testing(6)),\n                TextWidth::new_for_testing(0)\n            ),\n            (\n                SyntaxKind::TokenLiteralNumber,\n                Some(\"5\".into()),\n                TextOffset::default().add_width(TextWidth::new_for_testing(6)),\n                TextWidth::new_for_testing(1)\n            ),\n            (\n                SyntaxKind::Trivia,\n                None,\n                TextOffset::default().add_width(TextWidth::new_for_testing(7)),\n                TextWidth::new_for_testing(0)\n            )\n        ]\n    )\n}\n\n#[test]\nfn test_stable_ptr() {\n    let db_val = DatabaseForTesting::default();\n    let db = &db_val;\n    let root = setup(db);\n    traverse_and_verify_ptr(db, &root, root.clone());\n}\nfn traverse_and_verify_ptr(db: &dyn SyntaxGroup, root: &SyntaxNode, node: SyntaxNode) {\n    let ptr = node.stable_ptr();\n    let looked_up_node = root.lookup_ptr(db, ptr);\n    assert_eq!(node, looked_up_node);\n    for c in node.children(db) {\n        traverse_and_verify_ptr(db, root, c);\n    }\n}\n\nfn setup(db: &DatabaseForTesting) -> SyntaxNode {\n    // TODO: Use a builder for easier construction of token.\n    // Construct green nodes.\n    let token_foo = TokenIdentifier::new_green(db, \"foo\".into());\n    let token_whitespace1 = TokenWhitespace::new_green(db, \" \".into());\n    let token_plus = TokenPlus::new_green(db, \"+\".into());\n    let token_whitespace2 = TokenWhitespace::new_green(db, \" \".into());\n    let token5 = TokenLiteralNumber::new_green(db, \"5\".into());\n    assert_eq!(token_whitespace1, token_whitespace2);\n    let no_trivia = Trivia::new_green(db, vec![]);\n    let triviums = vec![token_whitespace1, token_whitespace2];\n    assert_eq!(triviums[0], triviums[1]);\n    let terminal_foo = TerminalIdentifier::new_green(\n        db,\n        no_trivia,\n        token_foo,\n        Trivia::new_green(db, vec![triviums[0].into()]),\n    );\n    let terminal_plus = TerminalPlus::new_green(\n        db,\n        no_trivia,\n        token_plus,\n        Trivia::new_green(db, vec![triviums[1].into()]),\n    );\n    let terminal5 = TerminalLiteralNumber::new_green(db, no_trivia, token5, no_trivia);\n    let expr = ExprBinary::new_green(\n        db,\n        ExprPath::new_green(\n            db,\n            vec![PathSegmentGreen::from(PathSegmentSimple::new_green(db, terminal_foo)).into()],\n        )\n        .into(),\n        terminal_plus.into(),\n        terminal5.into(),\n    );\n    // SyntaxNode::new_root only accepts ast::SyntaxFileGreen, but we only have an expression.\n    // This is a hack to crate a green id of \"SyntaxFile\" from \"Expr\".\n    let root = SyntaxFileGreen(expr.0);\n    SyntaxNode::new_root(db, root)\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_filesystem::db::FilesGroup;\nuse cairo_lang_utils::Upcast;\n\nuse super::green::GreenNode;\nuse super::ids::{GreenId, SyntaxStablePtrId};\nuse super::stable_ptr::SyntaxStablePtr;\n\n// Salsa database interface.\n#[salsa::query_group(SyntaxDatabase)]\npub trait SyntaxGroup: FilesGroup + Upcast<dyn FilesGroup> {\n    #[salsa::interned]\n    fn intern_green(&self, field: GreenNode) -> GreenId;\n    #[salsa::interned]\n    fn intern_stable_ptr(&self, field: SyntaxStablePtr) -> SyntaxStablePtrId;\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::marker::PhantomData;\n\nuse super::SyntaxGroup;\nuse crate::node::{SyntaxNode, TypedSyntaxNode};\n\n// A typed view of an element list node.\n// STEP=1 means a sequence of elements (e.g. sequence of trivia elements).\n// STEP=2 means a separated sequence (e.g. argument list separated by `,`).\n#[derive(Clone, Debug, Eq, Hash, PartialEq)]\npub struct ElementList<T: TypedSyntaxNode, const STEP: usize> {\n    pub node: SyntaxNode,\n    phantom: PhantomData<T>,\n}\nimpl<T: TypedSyntaxNode, const STEP: usize> ElementList<T, STEP> {\n    pub fn new(node: SyntaxNode) -> Self {\n        Self { node, phantom: PhantomData {} }\n    }\n    pub fn elements(&self, db: &dyn SyntaxGroup) -> Vec<T> {\n        self.node.children(db).step_by(STEP).map(|x| T::from_syntax_node(db, x)).collect()\n    }\n    pub fn has_tail(&self, db: &dyn SyntaxGroup) -> bool {\n        self.node.children(db).len() % STEP != 0\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_filesystem::span::TextWidth;\nuse smol_str::SmolStr;\n\nuse super::ids::GreenId;\nuse super::kind::SyntaxKind;\n\n#[derive(Clone, Debug, Hash, PartialEq, Eq)]\npub enum GreenNodeDetails {\n    Token(SmolStr),\n    Node { children: Vec<GreenId>, width: TextWidth },\n}\n/// Green node. Underlying untyped representation of the syntax tree.\n#[derive(Clone, Debug, Hash, PartialEq, Eq)]\npub struct GreenNode {\n    pub kind: SyntaxKind,\n    pub details: GreenNodeDetails,\n}\nimpl GreenNode {\n    pub fn width(&self) -> TextWidth {\n        match &self.details {\n            GreenNodeDetails::Token(text) => TextWidth::from_str(text),\n            GreenNodeDetails::Node { width, .. } => *width,\n        }\n    }\n    pub fn children(self) -> Vec<GreenId> {\n        match self.details {\n            GreenNodeDetails::Token(_text) => Vec::new(),\n            GreenNodeDetails::Node { children, .. } => children,\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "#[cfg(test)]\n#[path = \"helpers_test.rs\"]\nmod test;\n\nuse smol_str::SmolStr;\n\nuse super::ast::{\n    self, FunctionDeclaration, FunctionDeclarationGreen, FunctionWithBody, FunctionWithBodyPtr,\n    Item, ItemConstant, ItemEnum, ItemExternFunction, ItemExternFunctionPtr, ItemExternType,\n    ItemImpl, ItemModule, ItemStruct, ItemTrait, ItemTypeAlias, ItemUse, Modifier,\n    TerminalIdentifierGreen, TokenIdentifierGreen, TraitItemFunction, TraitItemFunctionPtr,\n};\nuse super::db::SyntaxGroup;\nuse super::Terminal;\nuse crate::node::green::GreenNodeDetails;\n\npub trait GetIdentifier {\n    fn identifier(&self, db: &dyn SyntaxGroup) -> SmolStr;\n}\nimpl GetIdentifier for ast::ExprPathGreen {\n    /// Retrieves the text of the last identifier in the path.\n    fn identifier(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        let children = match db.lookup_intern_green(self.0).details {\n            GreenNodeDetails::Node { children, width: _ } => children,\n            _ => panic!(\"Unexpected token\"),\n        };\n        assert_eq!(children.len() & 1, 1, \"Expected an odd number of elements in the path.\");\n        let segment_green = ast::PathSegmentGreen(*children.last().unwrap());\n        let children = match db.lookup_intern_green(segment_green.0).details {\n            GreenNodeDetails::Node { children, width: _ } => children,\n            _ => panic!(\"Unexpected token\"),\n        };\n        let identifier = ast::TerminalIdentifierGreen(children[0]);\n        identifier.identifier(db)\n    }\n}\nimpl GetIdentifier for ast::TerminalIdentifierGreen {\n    fn identifier(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        match db.lookup_intern_green(self.0).details {\n            GreenNodeDetails::Token(_) => \"Unexpected token\".into(),\n            GreenNodeDetails::Node { children, width: _ } => {\n                TokenIdentifierGreen(children[1]).text(db)\n            }\n        }\n    }\n}\nimpl GetIdentifier for ast::ExprPath {\n    /// Retrieves the identifier of the last segment of the path.\n    fn identifier(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.elements(db).last().cloned().unwrap().identifier(db)\n    }\n}\n\n/// Helper trait for ast::PathSegment.\npub trait PathSegmentEx {\n    fn identifier_ast(&self, db: &dyn SyntaxGroup) -> ast::TerminalIdentifier;\n    fn generic_args(&self, db: &dyn SyntaxGroup) -> Option<Vec<ast::GenericArg>>;\n}\nimpl PathSegmentEx for ast::PathSegment {\n    /// Retrieves the identifier ast of a path segment.\n    fn identifier_ast(&self, db: &dyn SyntaxGroup) -> ast::TerminalIdentifier {\n        match self {\n            ast::PathSegment::Simple(segment) => segment.ident(db),\n            ast::PathSegment::WithGenericArgs(segment) => segment.ident(db),\n        }\n    }\n    fn generic_args(&self, db: &dyn SyntaxGroup) -> Option<Vec<ast::GenericArg>> {\n        match self {\n            ast::PathSegment::Simple(_) => None,\n            ast::PathSegment::WithGenericArgs(segment) => {\n                Some(segment.generic_args(db).generic_args(db).elements(db))\n            }\n        }\n    }\n}\nimpl GetIdentifier for ast::PathSegment {\n    /// Retrieves the text of the segment (without the generic args).\n    fn identifier(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        self.identifier_ast(db).text(db)\n    }\n}\nimpl GetIdentifier for ast::Modifier {\n    fn identifier(&self, db: &dyn SyntaxGroup) -> SmolStr {\n        match self {\n            Modifier::Ref(r) => r.text(db),\n            Modifier::Mut(m) => m.text(db),\n        }\n    }\n}\n\n/// Trait for ast object with a name terminal.\npub trait NameGreen {\n    /// Returns the TerminalIdentifierGreen of the `name` node.\n    fn name_green(self, db: &dyn SyntaxGroup) -> TerminalIdentifierGreen;\n}\n\nimpl NameGreen for FunctionDeclarationGreen {\n    fn name_green(self, db: &dyn SyntaxGroup) -> TerminalIdentifierGreen {\n        TerminalIdentifierGreen(\n            db.lookup_intern_green(self.0).children()[FunctionDeclaration::INDEX_NAME],\n        )\n    }\n}\n\nimpl NameGreen for FunctionWithBodyPtr {\n    fn name_green(self, db: &dyn SyntaxGroup) -> TerminalIdentifierGreen {\n        self.declaration_green(db).name_green(db)\n    }\n}\n\nimpl NameGreen for ItemExternFunctionPtr {\n    fn name_green(self, db: &dyn SyntaxGroup) -> TerminalIdentifierGreen {\n        self.declaration_green(db).name_green(db)\n    }\n}\n\nimpl NameGreen for TraitItemFunctionPtr {\n    fn name_green(self, db: &dyn SyntaxGroup) -> TerminalIdentifierGreen {\n        self.declaration_green(db).name_green(db)\n    }\n}\n\n/// Trait for querying attributes of AST items.\npub trait QueryAttrs {\n    fn has_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool;\n    fn last_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool;\n}\nimpl QueryAttrs for ItemConstant {\n    fn has_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        self.attributes(db).elements(db).iter().any(|a| a.attr(db).text(db) == attr)\n    }\n    fn last_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        match self.attributes(db).elements(db).last() {\n            None => false,\n            Some(last_attr) => last_attr.attr(db).text(db) == attr,\n        }\n    }\n}\nimpl QueryAttrs for ItemModule {\n    fn has_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        self.attributes(db).elements(db).iter().any(|a| a.attr(db).text(db) == attr)\n    }\n    fn last_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        match self.attributes(db).elements(db).last() {\n            None => false,\n            Some(last_attr) => last_attr.attr(db).text(db) == attr,\n        }\n    }\n}\nimpl QueryAttrs for FunctionWithBody {\n    fn has_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        self.attributes(db).elements(db).iter().any(|a| a.attr(db).text(db) == attr)\n    }\n    fn last_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        match self.attributes(db).elements(db).last() {\n            None => false,\n            Some(last_attr) => last_attr.attr(db).text(db) == attr,\n        }\n    }\n}\nimpl QueryAttrs for ItemUse {\n    fn has_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        self.attributes(db).elements(db).iter().any(|a| a.attr(db).text(db) == attr)\n    }\n    fn last_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        match self.attributes(db).elements(db).last() {\n            None => false,\n            Some(last_attr) => last_attr.attr(db).text(db) == attr,\n        }\n    }\n}\nimpl QueryAttrs for ItemExternFunction {\n    fn has_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        self.attributes(db).elements(db).iter().any(|a| a.attr(db).text(db) == attr)\n    }\n    fn last_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        match self.attributes(db).elements(db).last() {\n            None => false,\n            Some(last_attr) => last_attr.attr(db).text(db) == attr,\n        }\n    }\n}\nimpl QueryAttrs for ItemExternType {\n    fn has_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        self.attributes(db).elements(db).iter().any(|a| a.attr(db).text(db) == attr)\n    }\n    fn last_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        match self.attributes(db).elements(db).last() {\n            None => false,\n            Some(last_attr) => last_attr.attr(db).text(db) == attr,\n        }\n    }\n}\nimpl QueryAttrs for ItemTrait {\n    fn has_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        self.attributes(db).elements(db).iter().any(|a| a.attr(db).text(db) == attr)\n    }\n    fn last_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        match self.attributes(db).elements(db).last() {\n            None => false,\n            Some(last_attr) => last_attr.attr(db).text(db) == attr,\n        }\n    }\n}\nimpl QueryAttrs for ItemImpl {\n    fn has_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        self.attributes(db).elements(db).iter().any(|a| a.attr(db).text(db) == attr)\n    }\n    fn last_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        match self.attributes(db).elements(db).last() {\n            None => false,\n            Some(last_attr) => last_attr.attr(db).text(db) == attr,\n        }\n    }\n}\nimpl QueryAttrs for ItemStruct {\n    fn has_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        self.attributes(db).elements(db).iter().any(|a| a.attr(db).text(db) == attr)\n    }\n    fn last_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        match self.attributes(db).elements(db).last() {\n            None => false,\n            Some(last_attr) => last_attr.attr(db).text(db) == attr,\n        }\n    }\n}\nimpl QueryAttrs for ItemEnum {\n    fn has_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        self.attributes(db).elements(db).iter().any(|a| a.attr(db).text(db) == attr)\n    }\n    fn last_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        match self.attributes(db).elements(db).last() {\n            None => false,\n            Some(last_attr) => last_attr.attr(db).text(db) == attr,\n        }\n    }\n}\nimpl QueryAttrs for ItemTypeAlias {\n    fn has_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        self.attributes(db).elements(db).iter().any(|a| a.attr(db).text(db) == attr)\n    }\n    fn last_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        match self.attributes(db).elements(db).last() {\n            None => false,\n            Some(last_attr) => last_attr.attr(db).text(db) == attr,\n        }\n    }\n}\nimpl QueryAttrs for TraitItemFunction {\n    fn has_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        self.attributes(db).elements(db).iter().any(|a| a.attr(db).text(db) == attr)\n    }\n    fn last_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        match self.attributes(db).elements(db).last() {\n            None => false,\n            Some(last_attr) => last_attr.attr(db).text(db) == attr,\n        }\n    }\n}\n\nimpl QueryAttrs for Item {\n    fn has_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        match self {\n            ast::Item::Constant(item) => item.has_attr(db, attr),\n            ast::Item::Module(item) => item.has_attr(db, attr),\n            ast::Item::FreeFunction(item) => item.has_attr(db, attr),\n            ast::Item::Use(item) => item.has_attr(db, attr),\n            ast::Item::ExternFunction(item) => item.has_attr(db, attr),\n            ast::Item::ExternType(item) => item.has_attr(db, attr),\n            ast::Item::Trait(item) => item.has_attr(db, attr),\n            ast::Item::Impl(item) => item.has_attr(db, attr),\n            ast::Item::Struct(item) => item.has_attr(db, attr),\n            ast::Item::Enum(item) => item.has_attr(db, attr),\n            ast::Item::TypeAlias(item) => item.has_attr(db, attr),\n        }\n    }\n\n    fn last_attr(&self, db: &dyn SyntaxGroup, attr: &str) -> bool {\n        match self {\n            ast::Item::Constant(item) => item.last_attr(db, attr),\n            ast::Item::Module(item) => item.last_attr(db, attr),\n            ast::Item::FreeFunction(item) => item.last_attr(db, attr),\n            ast::Item::Use(item) => item.last_attr(db, attr),\n            ast::Item::ExternFunction(item) => item.last_attr(db, attr),\n            ast::Item::ExternType(item) => item.last_attr(db, attr),\n            ast::Item::Trait(item) => item.last_attr(db, attr),\n            ast::Item::Impl(item) => item.last_attr(db, attr),\n            ast::Item::Struct(item) => item.last_attr(db, attr),\n            ast::Item::Enum(item) => item.last_attr(db, attr),\n            ast::Item::TypeAlias(item) => item.last_attr(db, attr),\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use super::GetIdentifier;\nuse crate::node::ast::{\n    ExprPath, ExprPathElementOrSeparatorGreen, PathSegmentGreen, PathSegmentSimple,\n    TerminalColonColon, TerminalIdentifier, TokenColonColon, TokenIdentifier, Trivia,\n};\nuse crate::node::test_utils::DatabaseForTesting;\nuse crate::node::{Terminal, Token};\n\n#[test]\nfn test_expr_path_identifier() {\n    let db_val = DatabaseForTesting::default();\n    let db = &db_val;\n\n    let no_trivia = Trivia::new_green(db, vec![]);\n    let token_foo = TokenIdentifier::new_green(db, \"foo\".into());\n    let terminal_foo = TerminalIdentifier::new_green(db, no_trivia, token_foo, no_trivia);\n\n    let token_bar = TokenIdentifier::new_green(db, \"bar\".into());\n    let terminal_bar = TerminalIdentifier::new_green(db, no_trivia, token_bar, no_trivia);\n\n    let token_separator = TokenColonColon::new_green(db, \"::\".into());\n    let separator = TerminalColonColon::new_green(db, no_trivia, token_separator, no_trivia);\n\n    PathSegmentSimple::new_green(db, terminal_foo);\n\n    let children: Vec<ExprPathElementOrSeparatorGreen> = vec![\n        PathSegmentGreen::from(PathSegmentSimple::new_green(db, terminal_foo)).into(),\n        separator.into(),\n        PathSegmentGreen::from(PathSegmentSimple::new_green(db, terminal_bar)).into(),\n    ];\n\n    assert_eq!(ExprPath::new_green(db, children).identifier(db), \"bar\");\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_filesystem::span::TextWidth;\nuse cairo_lang_utils::define_short_id;\n\nuse super::db::SyntaxGroup;\nuse super::green::GreenNode;\nuse crate::node::stable_ptr::SyntaxStablePtr;\n\ndefine_short_id!(GreenId, GreenNode, SyntaxGroup, lookup_intern_green);\nimpl GreenId {\n    /// Returns the width of the node of this green id.\n    pub fn width(&self, db: &dyn SyntaxGroup) -> TextWidth {\n        match db.lookup_intern_green(*self).details {\n            super::green::GreenNodeDetails::Token(text) => TextWidth::from_str(&text),\n            super::green::GreenNodeDetails::Node { width, .. } => width,\n        }\n    }\n}\n\ndefine_short_id!(SyntaxStablePtrId, SyntaxStablePtr, SyntaxGroup, lookup_intern_stable_ptr);\n",
    "metadata": {}
  },
  {
    "pageContent": "// Autogenerated file. To regenerate, please run `cargo run --bin generate-syntax`.\nuse super::ids::GreenId;\nuse super::kind::SyntaxKind;\n/// Gets the vector of children ids that are the indexing key for this SyntaxKind.\n/// Each SyntaxKind has some children that are defined in the spec to be its indexing key\n/// for its stable pointer. See [super::stable_ptr].\npub fn get_key_fields(kind: SyntaxKind, children: Vec<GreenId>) -> Vec<GreenId> {\n    match kind {\n        SyntaxKind::Trivia => vec![],\n        SyntaxKind::ExprList => vec![],\n        SyntaxKind::ArgNameClause => vec![],\n        SyntaxKind::OptionArgNameClauseEmpty => vec![],\n        SyntaxKind::Arg => vec![],\n        SyntaxKind::ArgClauseNamed => vec![],\n        SyntaxKind::ArgClauseUnnamed => vec![],\n        SyntaxKind::ArgClauseFieldInitShorthand => vec![],\n        SyntaxKind::ExprFieldInitShorthand => vec![],\n        SyntaxKind::ArgList => vec![],\n        SyntaxKind::ExprMissing => vec![],\n        SyntaxKind::PathSegmentSimple => vec![],\n        SyntaxKind::OptionTerminalColonColonEmpty => vec![],\n        SyntaxKind::PathSegmentWithGenericArgs => vec![],\n        SyntaxKind::ExprPath => vec![],\n        SyntaxKind::ExprParenthesized => vec![],\n        SyntaxKind::ExprUnary => vec![],\n        SyntaxKind::ExprBinary => vec![],\n        SyntaxKind::ExprTuple => vec![],\n        SyntaxKind::ExprFunctionCall => vec![],\n        SyntaxKind::ArgListParenthesized => vec![],\n        SyntaxKind::ExprStructCtorCall => vec![],\n        SyntaxKind::ExprBlock => vec![],\n        SyntaxKind::ExprMatch => vec![],\n        SyntaxKind::MatchArms => vec![],\n        SyntaxKind::MatchArm => vec![],\n        SyntaxKind::ExprIf => vec![],\n        SyntaxKind::ElseClause => vec![],\n        SyntaxKind::OptionElseClauseEmpty => vec![],\n        SyntaxKind::ExprErrorPropagate => vec![],\n        SyntaxKind::ExprIndexed => vec![],\n        SyntaxKind::StructArgExpr => vec![],\n        SyntaxKind::OptionStructArgExprEmpty => vec![],\n        SyntaxKind::StructArgSingle => vec![/* identifier */ children[0]],\n        SyntaxKind::StructArgTail => vec![],\n        SyntaxKind::StructArgList => vec![],\n        SyntaxKind::ArgListBraced => vec![],\n        SyntaxKind::PatternIdentifier => vec![/* name */ children[1]],\n        SyntaxKind::PatternStruct => vec![],\n        SyntaxKind::PatternStructParamList => vec![],\n        SyntaxKind::PatternTuple => vec![],\n        SyntaxKind::PatternList => vec![],\n        SyntaxKind::PatternStructParamWithExpr => vec![],\n        SyntaxKind::PatternEnum => vec![],\n        SyntaxKind::TypeClause => vec![],\n        SyntaxKind::OptionTypeClauseEmpty => vec![],\n        SyntaxKind::ReturnTypeClause => vec![],\n        SyntaxKind::OptionReturnTypeClauseEmpty => vec![],\n        SyntaxKind::StatementList => vec![],\n        SyntaxKind::StatementMissing => vec![],\n        SyntaxKind::StatementLet => vec![/* pattern */ children[1]],\n        SyntaxKind::OptionTerminalSemicolonEmpty => vec![],\n        SyntaxKind::StatementExpr => vec![],\n        SyntaxKind::StatementReturn => vec![],\n        SyntaxKind::Param => vec![/* name */ children[1]],\n        SyntaxKind::ModifierList => vec![],\n        SyntaxKind::ParamList => vec![],\n        SyntaxKind::ImplicitsClause => vec![],\n        SyntaxKind::ImplicitsList => vec![],\n        SyntaxKind::OptionImplicitsClauseEmpty => vec![],\n        SyntaxKind::OptionTerminalNoPanicEmpty => vec![],\n        SyntaxKind::FunctionSignature => vec![],\n        SyntaxKind::Member => vec![/* name */ children[0]],\n        SyntaxKind::MemberList => vec![],\n        SyntaxKind::ItemList => vec![],\n        SyntaxKind::Attribute => vec![],\n        SyntaxKind::AttributeList => vec![],\n        SyntaxKind::ItemModule => vec![/* name */ children[2]],\n        SyntaxKind::ModuleBody => vec![],\n        SyntaxKind::OptionAttributeArgsEmpty => vec![],\n        SyntaxKind::AttributeArgs => vec![],\n        SyntaxKind::AttributeArgList => vec![],\n        SyntaxKind::FunctionDeclaration => vec![/* name */ children[1]],\n        SyntaxKind::ItemConstant => vec![/* name */ children[2]],\n        SyntaxKind::FunctionWithBody => vec![/* declaration */ children[1]],\n        SyntaxKind::ItemExternFunction => vec![/* declaration */ children[2]],\n        SyntaxKind::ItemExternType => vec![/* name */ children[3]],\n        SyntaxKind::ItemTrait => vec![/* name */ children[2]],\n        SyntaxKind::TraitBody => vec![],\n        SyntaxKind::TraitItemList => vec![],\n        SyntaxKind::TraitItemFunction => vec![/* declaration */ children[1]],\n        SyntaxKind::ItemImpl => vec![/* name */ children[2]],\n        SyntaxKind::ImplBody => vec![],\n        SyntaxKind::ItemStruct => vec![/* name */ children[2]],\n        SyntaxKind::ItemEnum => vec![/* name */ children[2]],\n        SyntaxKind::ItemTypeAlias => vec![/* name */ children[2]],\n        SyntaxKind::ItemUse => vec![/* name */ children[2]],\n        SyntaxKind::GenericArgExpr => vec![],\n        SyntaxKind::GenericArgs => vec![],\n        SyntaxKind::GenericArgList => vec![],\n        SyntaxKind::OptionWrappedGenericParamListEmpty => vec![],\n        SyntaxKind::WrappedGenericParamList => vec![],\n        SyntaxKind::GenericParamList => vec![],\n        SyntaxKind::GenericParamType => vec![/* name */ children[0]],\n        SyntaxKind::GenericParamConst => vec![/* name */ children[1]],\n        SyntaxKind::GenericParamImpl => vec![/* name */ children[1]],\n        SyntaxKind::TokenIdentifier => vec![],\n        SyntaxKind::TerminalIdentifier => vec![],\n        SyntaxKind::TokenLiteralNumber => vec![],\n        SyntaxKind::TerminalLiteralNumber => vec![],\n        SyntaxKind::TokenShortString => vec![],\n        SyntaxKind::TerminalShortString => vec![],\n        SyntaxKind::TokenConst => vec![],\n        SyntaxKind::TerminalConst => vec![],\n        SyntaxKind::TokenElse => vec![],\n        SyntaxKind::TerminalElse => vec![],\n        SyntaxKind::TokenEnum => vec![],\n        SyntaxKind::TerminalEnum => vec![],\n        SyntaxKind::TokenExtern => vec![],\n        SyntaxKind::TerminalExtern => vec![],\n        SyntaxKind::TokenFalse => vec![],\n        SyntaxKind::TerminalFalse => vec![],\n        SyntaxKind::TokenFunction => vec![],\n        SyntaxKind::TerminalFunction => vec![],\n        SyntaxKind::TokenIf => vec![],\n        SyntaxKind::TerminalIf => vec![],\n        SyntaxKind::TokenImpl => vec![],\n        SyntaxKind::TerminalImpl => vec![],\n        SyntaxKind::TokenImplicits => vec![],\n        SyntaxKind::TerminalImplicits => vec![],\n        SyntaxKind::TokenLet => vec![],\n        SyntaxKind::TerminalLet => vec![],\n        SyntaxKind::TokenMatch => vec![],\n        SyntaxKind::TerminalMatch => vec![],\n        SyntaxKind::TokenModule => vec![],\n        SyntaxKind::TerminalModule => vec![],\n        SyntaxKind::TokenMut => vec![],\n        SyntaxKind::TerminalMut => vec![],\n        SyntaxKind::TokenNoPanic => vec![],\n        SyntaxKind::TerminalNoPanic => vec![],\n        SyntaxKind::TokenOf => vec![],\n        SyntaxKind::TerminalOf => vec![],\n        SyntaxKind::TokenRef => vec![],\n        SyntaxKind::TerminalRef => vec![],\n        SyntaxKind::TokenReturn => vec![],\n        SyntaxKind::TerminalReturn => vec![],\n        SyntaxKind::TokenStruct => vec![],\n        SyntaxKind::TerminalStruct => vec![],\n        SyntaxKind::TokenTrait => vec![],\n        SyntaxKind::TerminalTrait => vec![],\n        SyntaxKind::TokenTrue => vec![],\n        SyntaxKind::TerminalTrue => vec![],\n        SyntaxKind::TokenType => vec![],\n        SyntaxKind::TerminalType => vec![],\n        SyntaxKind::TokenUse => vec![],\n        SyntaxKind::TerminalUse => vec![],\n        SyntaxKind::TokenAnd => vec![],\n        SyntaxKind::TerminalAnd => vec![],\n        SyntaxKind::TokenAndAnd => vec![],\n        SyntaxKind::TerminalAndAnd => vec![],\n        SyntaxKind::TokenArrow => vec![],\n        SyntaxKind::TerminalArrow => vec![],\n        SyntaxKind::TokenAt => vec![],\n        SyntaxKind::TerminalAt => vec![],\n        SyntaxKind::TokenBadCharacters => vec![],\n        SyntaxKind::TerminalBadCharacters => vec![],\n        SyntaxKind::TokenColon => vec![],\n        SyntaxKind::TerminalColon => vec![],\n        SyntaxKind::TokenColonColon => vec![],\n        SyntaxKind::TerminalColonColon => vec![],\n        SyntaxKind::TokenComma => vec![],\n        SyntaxKind::TerminalComma => vec![],\n        SyntaxKind::TokenDiv => vec![],\n        SyntaxKind::TerminalDiv => vec![],\n        SyntaxKind::TokenDivEq => vec![],\n        SyntaxKind::TerminalDivEq => vec![],\n        SyntaxKind::TokenDot => vec![],\n        SyntaxKind::TerminalDot => vec![],\n        SyntaxKind::TokenDotDot => vec![],\n        SyntaxKind::TerminalDotDot => vec![],\n        SyntaxKind::TokenEndOfFile => vec![],\n        SyntaxKind::TerminalEndOfFile => vec![],\n        SyntaxKind::TokenEq => vec![],\n        SyntaxKind::TerminalEq => vec![],\n        SyntaxKind::TokenEqEq => vec![],\n        SyntaxKind::TerminalEqEq => vec![],\n        SyntaxKind::TokenGE => vec![],\n        SyntaxKind::TerminalGE => vec![],\n        SyntaxKind::TokenGT => vec![],\n        SyntaxKind::TerminalGT => vec![],\n        SyntaxKind::TokenHash => vec![],\n        SyntaxKind::TerminalHash => vec![],\n        SyntaxKind::TokenLBrace => vec![],\n        SyntaxKind::TerminalLBrace => vec![],\n        SyntaxKind::TokenLBrack => vec![],\n        SyntaxKind::TerminalLBrack => vec![],\n        SyntaxKind::TokenLE => vec![],\n        SyntaxKind::TerminalLE => vec![],\n        SyntaxKind::TokenLParen => vec![],\n        SyntaxKind::TerminalLParen => vec![],\n        SyntaxKind::TokenLT => vec![],\n        SyntaxKind::TerminalLT => vec![],\n        SyntaxKind::TokenMatchArrow => vec![],\n        SyntaxKind::TerminalMatchArrow => vec![],\n        SyntaxKind::TokenMinus => vec![],\n        SyntaxKind::TerminalMinus => vec![],\n        SyntaxKind::TokenMinusEq => vec![],\n        SyntaxKind::TerminalMinusEq => vec![],\n        SyntaxKind::TokenMod => vec![],\n        SyntaxKind::TerminalMod => vec![],\n        SyntaxKind::TokenModEq => vec![],\n        SyntaxKind::TerminalModEq => vec![],\n        SyntaxKind::TokenMul => vec![],\n        SyntaxKind::TerminalMul => vec![],\n        SyntaxKind::TokenMulEq => vec![],\n        SyntaxKind::TerminalMulEq => vec![],\n        SyntaxKind::TokenNeq => vec![],\n        SyntaxKind::TerminalNeq => vec![],\n        SyntaxKind::TokenNot => vec![],\n        SyntaxKind::TerminalNot => vec![],\n        SyntaxKind::TokenOr => vec![],\n        SyntaxKind::TerminalOr => vec![],\n        SyntaxKind::TokenOrOr => vec![],\n        SyntaxKind::TerminalOrOr => vec![],\n        SyntaxKind::TokenPlus => vec![],\n        SyntaxKind::TerminalPlus => vec![],\n        SyntaxKind::TokenPlusEq => vec![],\n        SyntaxKind::TerminalPlusEq => vec![],\n        SyntaxKind::TokenQuestionMark => vec![],\n        SyntaxKind::TerminalQuestionMark => vec![],\n        SyntaxKind::TokenRBrace => vec![],\n        SyntaxKind::TerminalRBrace => vec![],\n        SyntaxKind::TokenRBrack => vec![],\n        SyntaxKind::TerminalRBrack => vec![],\n        SyntaxKind::TokenRParen => vec![],\n        SyntaxKind::TerminalRParen => vec![],\n        SyntaxKind::TokenSemicolon => vec![],\n        SyntaxKind::TerminalSemicolon => vec![],\n        SyntaxKind::TokenUnderscore => vec![],\n        SyntaxKind::TerminalUnderscore => vec![],\n        SyntaxKind::TokenXor => vec![],\n        SyntaxKind::TerminalXor => vec![],\n        SyntaxKind::SyntaxFile => vec![],\n        SyntaxKind::TokenSingleLineComment => vec![],\n        SyntaxKind::TokenWhitespace => vec![],\n        SyntaxKind::TokenNewline => vec![],\n        SyntaxKind::TokenMissing => vec![],\n        SyntaxKind::TokenSkipped => vec![],\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "// Autogenerated file. To regenerate, please run `cargo run --bin generate-syntax`.\nuse core::fmt;\n#[derive(Copy, Clone, Debug, Hash, PartialEq, Eq)]\npub enum SyntaxKind {\n    Trivia,\n    ExprList,\n    ArgNameClause,\n    OptionArgNameClauseEmpty,\n    Arg,\n    ArgClauseNamed,\n    ArgClauseUnnamed,\n    ArgClauseFieldInitShorthand,\n    ExprFieldInitShorthand,\n    ArgList,\n    ExprMissing,\n    PathSegmentSimple,\n    OptionTerminalColonColonEmpty,\n    PathSegmentWithGenericArgs,\n    ExprPath,\n    ExprParenthesized,\n    ExprUnary,\n    ExprBinary,\n    ExprTuple,\n    ExprFunctionCall,\n    ArgListParenthesized,\n    ExprStructCtorCall,\n    ExprBlock,\n    ExprMatch,\n    MatchArms,\n    MatchArm,\n    ExprIf,\n    ElseClause,\n    OptionElseClauseEmpty,\n    ExprErrorPropagate,\n    ExprIndexed,\n    StructArgExpr,\n    OptionStructArgExprEmpty,\n    StructArgSingle,\n    StructArgTail,\n    StructArgList,\n    ArgListBraced,\n    PatternIdentifier,\n    PatternStruct,\n    PatternStructParamList,\n    PatternTuple,\n    PatternList,\n    PatternStructParamWithExpr,\n    PatternEnum,\n    TypeClause,\n    OptionTypeClauseEmpty,\n    ReturnTypeClause,\n    OptionReturnTypeClauseEmpty,\n    StatementList,\n    StatementMissing,\n    StatementLet,\n    OptionTerminalSemicolonEmpty,\n    StatementExpr,\n    StatementReturn,\n    Param,\n    ModifierList,\n    ParamList,\n    ImplicitsClause,\n    ImplicitsList,\n    OptionImplicitsClauseEmpty,\n    OptionTerminalNoPanicEmpty,\n    FunctionSignature,\n    Member,\n    MemberList,\n    ItemList,\n    Attribute,\n    AttributeList,\n    ItemModule,\n    ModuleBody,\n    OptionAttributeArgsEmpty,\n    AttributeArgs,\n    AttributeArgList,\n    FunctionDeclaration,\n    ItemConstant,\n    FunctionWithBody,\n    ItemExternFunction,\n    ItemExternType,\n    ItemTrait,\n    TraitBody,\n    TraitItemList,\n    TraitItemFunction,\n    ItemImpl,\n    ImplBody,\n    ItemStruct,\n    ItemEnum,\n    ItemTypeAlias,\n    ItemUse,\n    GenericArgExpr,\n    GenericArgs,\n    GenericArgList,\n    OptionWrappedGenericParamListEmpty,\n    WrappedGenericParamList,\n    GenericParamList,\n    GenericParamType,\n    GenericParamConst,\n    GenericParamImpl,\n    TokenIdentifier,\n    TerminalIdentifier,\n    TokenLiteralNumber,\n    TerminalLiteralNumber,\n    TokenShortString,\n    TerminalShortString,\n    TokenConst,\n    TerminalConst,\n    TokenElse,\n    TerminalElse,\n    TokenEnum,\n    TerminalEnum,\n    TokenExtern,\n    TerminalExtern,\n    TokenFalse,\n    TerminalFalse,\n    TokenFunction,\n    TerminalFunction,\n    TokenIf,\n    TerminalIf,\n    TokenImpl,\n    TerminalImpl,\n    TokenImplicits,\n    TerminalImplicits,\n    TokenLet,\n    TerminalLet,\n    TokenMatch,\n    TerminalMatch,\n    TokenModule,\n    TerminalModule,\n    TokenMut,\n    TerminalMut,\n    TokenNoPanic,\n    TerminalNoPanic,\n    TokenOf,\n    TerminalOf,\n    TokenRef,\n    TerminalRef,\n    TokenReturn,\n    TerminalReturn,\n    TokenStruct,\n    TerminalStruct,\n    TokenTrait,\n    TerminalTrait,\n    TokenTrue,\n    TerminalTrue,\n    TokenType,\n    TerminalType,\n    TokenUse,\n    TerminalUse,\n    TokenAnd,\n    TerminalAnd,\n    TokenAndAnd,\n    TerminalAndAnd,\n    TokenArrow,\n    TerminalArrow,\n    TokenAt,\n    TerminalAt,\n    TokenBadCharacters,\n    TerminalBadCharacters,\n    TokenColon,\n    TerminalColon,\n    TokenColonColon,\n    TerminalColonColon,\n    TokenComma,\n    TerminalComma,\n    TokenDiv,\n    TerminalDiv,\n    TokenDivEq,\n    TerminalDivEq,\n    TokenDot,\n    TerminalDot,\n    TokenDotDot,\n    TerminalDotDot,\n    TokenEndOfFile,\n    TerminalEndOfFile,\n    TokenEq,\n    TerminalEq,\n    TokenEqEq,\n    TerminalEqEq,\n    TokenGE,\n    TerminalGE,\n    TokenGT,\n    TerminalGT,\n    TokenHash,\n    TerminalHash,\n    TokenLBrace,\n    TerminalLBrace,\n    TokenLBrack,\n    TerminalLBrack,\n    TokenLE,\n    TerminalLE,\n    TokenLParen,\n    TerminalLParen,\n    TokenLT,\n    TerminalLT,\n    TokenMatchArrow,\n    TerminalMatchArrow,\n    TokenMinus,\n    TerminalMinus,\n    TokenMinusEq,\n    TerminalMinusEq,\n    TokenMod,\n    TerminalMod,\n    TokenModEq,\n    TerminalModEq,\n    TokenMul,\n    TerminalMul,\n    TokenMulEq,\n    TerminalMulEq,\n    TokenNeq,\n    TerminalNeq,\n    TokenNot,\n    TerminalNot,\n    TokenOr,\n    TerminalOr,\n    TokenOrOr,\n    TerminalOrOr,\n    TokenPlus,\n    TerminalPlus,\n    TokenPlusEq,\n    TerminalPlusEq,\n    TokenQuestionMark,\n    TerminalQuestionMark,\n    TokenRBrace,\n    TerminalRBrace,\n    TokenRBrack,\n    TerminalRBrack,\n    TokenRParen,\n    TerminalRParen,\n    TokenSemicolon,\n    TerminalSemicolon,\n    TokenUnderscore,\n    TerminalUnderscore,\n    TokenXor,\n    TerminalXor,\n    SyntaxFile,\n    TokenSingleLineComment,\n    TokenWhitespace,\n    TokenNewline,\n    TokenMissing,\n    TokenSkipped,\n}\nimpl SyntaxKind {\n    pub fn is_token(&self) -> bool {\n        matches!(\n            *self,\n            SyntaxKind::TokenIdentifier\n                | SyntaxKind::TokenLiteralNumber\n                | SyntaxKind::TokenShortString\n                | SyntaxKind::TokenConst\n                | SyntaxKind::TokenElse\n                | SyntaxKind::TokenEnum\n                | SyntaxKind::TokenExtern\n                | SyntaxKind::TokenFalse\n                | SyntaxKind::TokenFunction\n                | SyntaxKind::TokenIf\n                | SyntaxKind::TokenImpl\n                | SyntaxKind::TokenImplicits\n                | SyntaxKind::TokenLet\n                | SyntaxKind::TokenMatch\n                | SyntaxKind::TokenModule\n                | SyntaxKind::TokenMut\n                | SyntaxKind::TokenNoPanic\n                | SyntaxKind::TokenOf\n                | SyntaxKind::TokenRef\n                | SyntaxKind::TokenReturn\n                | SyntaxKind::TokenStruct\n                | SyntaxKind::TokenTrait\n                | SyntaxKind::TokenTrue\n                | SyntaxKind::TokenType\n                | SyntaxKind::TokenUse\n                | SyntaxKind::TokenAnd\n                | SyntaxKind::TokenAndAnd\n                | SyntaxKind::TokenArrow\n                | SyntaxKind::TokenAt\n                | SyntaxKind::TokenBadCharacters\n                | SyntaxKind::TokenColon\n                | SyntaxKind::TokenColonColon\n                | SyntaxKind::TokenComma\n                | SyntaxKind::TokenDiv\n                | SyntaxKind::TokenDivEq\n                | SyntaxKind::TokenDot\n                | SyntaxKind::TokenDotDot\n                | SyntaxKind::TokenEndOfFile\n                | SyntaxKind::TokenEq\n                | SyntaxKind::TokenEqEq\n                | SyntaxKind::TokenGE\n                | SyntaxKind::TokenGT\n                | SyntaxKind::TokenHash\n                | SyntaxKind::TokenLBrace\n                | SyntaxKind::TokenLBrack\n                | SyntaxKind::TokenLE\n                | SyntaxKind::TokenLParen\n                | SyntaxKind::TokenLT\n                | SyntaxKind::TokenMatchArrow\n                | SyntaxKind::TokenMinus\n                | SyntaxKind::TokenMinusEq\n                | SyntaxKind::TokenMod\n                | SyntaxKind::TokenModEq\n                | SyntaxKind::TokenMul\n                | SyntaxKind::TokenMulEq\n                | SyntaxKind::TokenNeq\n                | SyntaxKind::TokenNot\n                | SyntaxKind::TokenOr\n                | SyntaxKind::TokenOrOr\n                | SyntaxKind::TokenPlus\n                | SyntaxKind::TokenPlusEq\n                | SyntaxKind::TokenQuestionMark\n                | SyntaxKind::TokenRBrace\n                | SyntaxKind::TokenRBrack\n                | SyntaxKind::TokenRParen\n                | SyntaxKind::TokenSemicolon\n                | SyntaxKind::TokenUnderscore\n                | SyntaxKind::TokenXor\n                | SyntaxKind::TokenSingleLineComment\n                | SyntaxKind::TokenWhitespace\n                | SyntaxKind::TokenNewline\n                | SyntaxKind::TokenMissing\n                | SyntaxKind::TokenSkipped\n        )\n    }\n    pub fn is_terminal(&self) -> bool {\n        matches!(\n            *self,\n            SyntaxKind::TerminalIdentifier\n                | SyntaxKind::TerminalLiteralNumber\n                | SyntaxKind::TerminalShortString\n                | SyntaxKind::TerminalConst\n                | SyntaxKind::TerminalElse\n                | SyntaxKind::TerminalEnum\n                | SyntaxKind::TerminalExtern\n                | SyntaxKind::TerminalFalse\n                | SyntaxKind::TerminalFunction\n                | SyntaxKind::TerminalIf\n                | SyntaxKind::TerminalImpl\n                | SyntaxKind::TerminalImplicits\n                | SyntaxKind::TerminalLet\n                | SyntaxKind::TerminalMatch\n                | SyntaxKind::TerminalModule\n                | SyntaxKind::TerminalMut\n                | SyntaxKind::TerminalNoPanic\n                | SyntaxKind::TerminalOf\n                | SyntaxKind::TerminalRef\n                | SyntaxKind::TerminalReturn\n                | SyntaxKind::TerminalStruct\n                | SyntaxKind::TerminalTrait\n                | SyntaxKind::TerminalTrue\n                | SyntaxKind::TerminalType\n                | SyntaxKind::TerminalUse\n                | SyntaxKind::TerminalAnd\n                | SyntaxKind::TerminalAndAnd\n                | SyntaxKind::TerminalArrow\n                | SyntaxKind::TerminalAt\n                | SyntaxKind::TerminalBadCharacters\n                | SyntaxKind::TerminalColon\n                | SyntaxKind::TerminalColonColon\n                | SyntaxKind::TerminalComma\n                | SyntaxKind::TerminalDiv\n                | SyntaxKind::TerminalDivEq\n                | SyntaxKind::TerminalDot\n                | SyntaxKind::TerminalDotDot\n                | SyntaxKind::TerminalEndOfFile\n                | SyntaxKind::TerminalEq\n                | SyntaxKind::TerminalEqEq\n                | SyntaxKind::TerminalGE\n                | SyntaxKind::TerminalGT\n                | SyntaxKind::TerminalHash\n                | SyntaxKind::TerminalLBrace\n                | SyntaxKind::TerminalLBrack\n                | SyntaxKind::TerminalLE\n                | SyntaxKind::TerminalLParen\n                | SyntaxKind::TerminalLT\n                | SyntaxKind::TerminalMatchArrow\n                | SyntaxKind::TerminalMinus\n                | SyntaxKind::TerminalMinusEq\n                | SyntaxKind::TerminalMod\n                | SyntaxKind::TerminalModEq\n                | SyntaxKind::TerminalMul\n                | SyntaxKind::TerminalMulEq\n                | SyntaxKind::TerminalNeq\n                | SyntaxKind::TerminalNot\n                | SyntaxKind::TerminalOr\n                | SyntaxKind::TerminalOrOr\n                | SyntaxKind::TerminalPlus\n                | SyntaxKind::TerminalPlusEq\n                | SyntaxKind::TerminalQuestionMark\n                | SyntaxKind::TerminalRBrace\n                | SyntaxKind::TerminalRBrack\n                | SyntaxKind::TerminalRParen\n                | SyntaxKind::TerminalSemicolon\n                | SyntaxKind::TerminalUnderscore\n                | SyntaxKind::TerminalXor\n        )\n    }\n    pub fn is_keyword_token(&self) -> bool {\n        matches!(\n            *self,\n            SyntaxKind::TokenConst\n                | SyntaxKind::TokenElse\n                | SyntaxKind::TokenEnum\n                | SyntaxKind::TokenExtern\n                | SyntaxKind::TokenFalse\n                | SyntaxKind::TokenFunction\n                | SyntaxKind::TokenIf\n                | SyntaxKind::TokenImpl\n                | SyntaxKind::TokenImplicits\n                | SyntaxKind::TokenLet\n                | SyntaxKind::TokenMatch\n                | SyntaxKind::TokenModule\n                | SyntaxKind::TokenMut\n                | SyntaxKind::TokenNoPanic\n                | SyntaxKind::TokenOf\n                | SyntaxKind::TokenRef\n                | SyntaxKind::TokenReturn\n                | SyntaxKind::TokenStruct\n                | SyntaxKind::TokenTrait\n                | SyntaxKind::TokenTrue\n                | SyntaxKind::TokenType\n                | SyntaxKind::TokenUse\n        )\n    }\n    pub fn is_keyword_terminal(&self) -> bool {\n        matches!(\n            *self,\n            SyntaxKind::TerminalConst\n                | SyntaxKind::TerminalElse\n                | SyntaxKind::TerminalEnum\n                | SyntaxKind::TerminalExtern\n                | SyntaxKind::TerminalFalse\n                | SyntaxKind::TerminalFunction\n                | SyntaxKind::TerminalIf\n                | SyntaxKind::TerminalImpl\n                | SyntaxKind::TerminalImplicits\n                | SyntaxKind::TerminalLet\n                | SyntaxKind::TerminalMatch\n                | SyntaxKind::TerminalModule\n                | SyntaxKind::TerminalMut\n                | SyntaxKind::TerminalNoPanic\n                | SyntaxKind::TerminalOf\n                | SyntaxKind::TerminalRef\n                | SyntaxKind::TerminalReturn\n                | SyntaxKind::TerminalStruct\n                | SyntaxKind::TerminalTrait\n                | SyntaxKind::TerminalTrue\n                | SyntaxKind::TerminalType\n                | SyntaxKind::TerminalUse\n        )\n    }\n}\nimpl fmt::Display for SyntaxKind {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"{self:?}\")\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use core::hash::Hash;\nuse std::collections::hash_map::Entry;\nuse std::collections::HashMap;\nuse std::fmt::Display;\nuse std::sync::Arc;\nuse std::vec;\n\nuse cairo_lang_filesystem::span::{TextOffset, TextSpan, TextWidth};\nuse smol_str::SmolStr;\n\nuse self::ast::TriviaGreen;\nuse self::db::SyntaxGroup;\nuse self::green::GreenNode;\nuse self::ids::{GreenId, SyntaxStablePtrId};\nuse self::key_fields::get_key_fields;\nuse self::kind::SyntaxKind;\nuse self::stable_ptr::SyntaxStablePtr;\n\npub mod ast;\npub mod db;\npub mod element_list;\npub mod green;\npub mod helpers;\npub mod ids;\npub mod key_fields;\npub mod kind;\npub mod stable_ptr;\npub mod utils;\n\n#[cfg(test)]\nmod ast_test;\n#[cfg(test)]\nmod test_utils;\n\n/// SyntaxNode. Untyped view of the syntax tree. Adds parent() and offset() capabilities.\n#[derive(Clone, Debug, Hash, PartialEq, Eq)]\npub struct SyntaxNode(Arc<SyntaxNodeInner>);\n#[derive(Clone, Debug, Hash, PartialEq, Eq)]\nstruct SyntaxNodeInner {\n    green: GreenId,\n    /// Number of characters from the beginning of the file to the start of the span of this\n    /// syntax subtree.\n    offset: TextOffset,\n    parent: Option<SyntaxNode>,\n    stable_ptr: SyntaxStablePtrId,\n}\nimpl SyntaxNode {\n    pub fn new_root(db: &dyn SyntaxGroup, green: ast::SyntaxFileGreen) -> Self {\n        let inner = SyntaxNodeInner {\n            green: green.0,\n            offset: TextOffset::default(),\n            parent: None,\n            stable_ptr: db.intern_stable_ptr(SyntaxStablePtr::Root),\n        };\n        Self(Arc::new(inner))\n    }\n    pub fn offset(&self) -> TextOffset {\n        self.0.offset\n    }\n    pub fn width(&self, db: &dyn SyntaxGroup) -> TextWidth {\n        self.green_node(db).width()\n    }\n    pub fn kind(&self, db: &dyn SyntaxGroup) -> SyntaxKind {\n        self.green_node(db).kind\n    }\n    pub fn span(&self, db: &dyn SyntaxGroup) -> TextSpan {\n        let start = self.offset();\n        let end = start.add_width(self.width(db));\n        TextSpan { start, end }\n    }\n    /// Returns the text of the token if this node is a token.\n    pub fn text(&self, db: &dyn SyntaxGroup) -> Option<SmolStr> {\n        match self.green_node(db).details {\n            green::GreenNodeDetails::Token(text) => Some(text),\n            green::GreenNodeDetails::Node { .. } => None,\n        }\n    }\n    pub fn green_node(&self, db: &dyn SyntaxGroup) -> GreenNode {\n        db.lookup_intern_green(self.0.green)\n    }\n    pub fn span_without_trivia(&self, db: &dyn SyntaxGroup) -> TextSpan {\n        let start = self.span_start_without_trivia(db);\n        let end = self.span_end_without_trivia(db);\n        TextSpan { start, end }\n    }\n    pub fn children<'db>(&self, db: &'db dyn SyntaxGroup) -> SyntaxNodeChildIterator<'db> {\n        SyntaxNodeChildIterator {\n            db,\n            node: self.clone(),\n            green_iterator: self.green_node(db).children().into_iter(),\n            offset: self.0.offset,\n            key_map: HashMap::new(),\n        }\n    }\n    pub fn parent(&self) -> Option<SyntaxNode> {\n        self.0.parent.as_ref().cloned()\n    }\n    pub fn stable_ptr(&self) -> SyntaxStablePtrId {\n        self.0.stable_ptr\n    }\n\n    /// Lookups a syntax node using a stable syntax pointer.\n    /// Should only be called on the root from which the stable pointer was generated.\n    pub fn lookup_ptr(&self, db: &dyn SyntaxGroup, stable_ptr: SyntaxStablePtrId) -> SyntaxNode {\n        assert!(self.0.parent.is_none(), \"May only be called on the root.\");\n        let ptr = db.lookup_intern_stable_ptr(stable_ptr);\n        match ptr {\n            SyntaxStablePtr::Root => self.clone(),\n            SyntaxStablePtr::Child { parent, .. } => {\n                let parent = self.lookup_ptr(db, parent);\n                for child in parent.children(db) {\n                    if child.stable_ptr() == stable_ptr {\n                        return child;\n                    }\n                }\n                unreachable!();\n            }\n        }\n    }\n\n    /// Gets the inner token from a terminal SyntaxNode. If the given node is not a terminal,\n    /// returns None.\n    pub fn get_terminal_token(&self, db: &dyn SyntaxGroup) -> Option<SyntaxNode> {\n        let green_node = self.green_node(db);\n        if !green_node.kind.is_terminal() {\n            return None;\n        }\n        // At this point we know we should have a second child which is the token.\n        let token_node = self.children(db).nth(1).unwrap();\n        Some(token_node)\n    }\n\n    pub fn span_start_without_trivia(&self, db: &dyn SyntaxGroup) -> TextOffset {\n        let green_node = self.green_node(db);\n        match green_node.details {\n            green::GreenNodeDetails::Node { .. } => {\n                if let Some(token_node) = self.get_terminal_token(db) {\n                    return token_node.offset();\n                }\n                let children = &mut self.children(db);\n                if let Some(child) = children.find(|child| child.width(db) != TextWidth::default())\n                {\n                    child.span_start_without_trivia(db)\n                } else {\n                    self.offset()\n                }\n            }\n            green::GreenNodeDetails::Token(_) => self.offset(),\n        }\n    }\n    pub fn span_end_without_trivia(&self, db: &dyn SyntaxGroup) -> TextOffset {\n        let green_node = self.green_node(db);\n        match green_node.details {\n            green::GreenNodeDetails::Node { .. } => {\n                if let Some(token_node) = self.get_terminal_token(db) {\n                    return token_node.span(db).end;\n                }\n                let children = &mut self.children(db);\n                if let Some(child) =\n                    children.filter(|child| child.width(db) != TextWidth::default()).last()\n                {\n                    child.span_end_without_trivia(db)\n                } else {\n                    self.span(db).end\n                }\n            }\n            green::GreenNodeDetails::Token(_) => self.span(db).end,\n        }\n    }\n\n    /// Lookups a syntax node using an offset.\n    pub fn lookup_offset(&self, db: &dyn SyntaxGroup, offset: TextOffset) -> SyntaxNode {\n        for child in self.children(db) {\n            if child.offset().add_width(child.width(db)) > offset {\n                return child.lookup_offset(db, offset);\n            }\n        }\n        self.clone()\n    }\n\n    /// Returns all the text under the syntax node.\n    /// Note that this traverses the syntax tree, and generates a new string, so use responsibly.\n    pub fn get_text(&self, db: &dyn SyntaxGroup) -> String {\n        format!(\"{}\", NodeTextFormatter { node: self, db })\n    }\n\n    /// Returns all the text under the syntax node, without the outmost trivia (the leading trivia\n    /// of the first token and the trailing trivia of the last token).\n    ///\n    /// Note that this traverses the syntax tree, and generates a new string, so use responsibly.\n    pub fn get_text_without_trivia(self, db: &dyn SyntaxGroup) -> String {\n        let trimmed_span = self.span_without_trivia(db);\n\n        self.get_text_of_span(db, trimmed_span)\n    }\n\n    /// Returns the text under the syntax node, according to the given span.\n    ///\n    /// `span` is assumed to be contained within the span of self.\n    ///\n    /// Note that this traverses the syntax tree, and generates a new string, so use responsibly.\n    pub fn get_text_of_span(self, db: &dyn SyntaxGroup, span: TextSpan) -> String {\n        let orig_span = self.span(db);\n        assert!(orig_span.contains(span));\n        let full_text = self.get_text(db);\n        let zero_offset = TextOffset::default();\n\n        let span_in_span = TextSpan {\n            start: zero_offset.add_width(span.start - orig_span.start),\n            end: zero_offset.add_width(span.end - orig_span.start),\n        };\n        span_in_span.take(&full_text).to_string()\n    }\n}\npub struct SyntaxNodeChildIterator<'db> {\n    db: &'db dyn SyntaxGroup,\n    node: SyntaxNode,\n    green_iterator: vec::IntoIter<GreenId>,\n    /// The current offset in the source file of the start of the child.\n    offset: TextOffset,\n    /// Mapping from (kind, key_fields) to the number of times this indexing pair has been seen.\n    /// This is used to maintain the correct index for creating each StablePtr.\n    /// See [`self::key_fields`].\n    key_map: HashMap<(SyntaxKind, Vec<GreenId>), usize>,\n}\nimpl<'db> Iterator for SyntaxNodeChildIterator<'db> {\n    type Item = SyntaxNode;\n\n    fn next(&mut self) -> Option<Self::Item> {\n        let green_id = self.green_iterator.next()?;\n        self.next_inner(green_id)\n    }\n}\nimpl<'db> DoubleEndedIterator for SyntaxNodeChildIterator<'db> {\n    fn next_back(&mut self) -> Option<<SyntaxNodeChildIterator<'db> as Iterator>::Item> {\n        let green_id = self.green_iterator.next_back()?;\n        self.next_inner(green_id)\n    }\n}\nimpl<'db> ExactSizeIterator for SyntaxNodeChildIterator<'db> {\n    fn len(&self) -> usize {\n        self.green_iterator.len()\n    }\n}\nimpl<'db> SyntaxNodeChildIterator<'db> {\n    fn next_inner(\n        &mut self,\n        green_id: GreenId,\n    ) -> Option<<SyntaxNodeChildIterator<'db> as Iterator>::Item> {\n        let green = self.db.lookup_intern_green(green_id);\n        let width = green.width();\n        let kind = green.kind;\n        let key_fields: Vec<GreenId> = get_key_fields(kind, green.children());\n        let index = match self.key_map.entry((kind, key_fields.clone())) {\n            Entry::Occupied(mut entry) => entry.insert(entry.get() + 1),\n            Entry::Vacant(entry) => {\n                entry.insert(1);\n                0\n            }\n        };\n        let stable_ptr = self.db.intern_stable_ptr(SyntaxStablePtr::Child {\n            parent: self.node.0.stable_ptr,\n            kind,\n            key_fields,\n            index,\n        });\n        // Create the SyntaxNode view for the child.\n        let res = SyntaxNode(Arc::new(SyntaxNodeInner {\n            green: green_id,\n            offset: self.offset,\n            parent: Some(self.node.clone()),\n            stable_ptr,\n        }));\n        self.offset = self.offset.add_width(width);\n        Some(res)\n    }\n}\n\n/// Trait for the typed view of the syntax tree. All the internal node implementations are under\n/// the ast module.\npub trait TypedSyntaxNode {\n    /// The relevant SyntaxKind. None for enums.\n    const OPTIONAL_KIND: Option<SyntaxKind>;\n    type StablePtr;\n    type Green;\n    fn missing(db: &dyn SyntaxGroup) -> Self::Green;\n    // TODO(spapini): Make this return an Option, if the kind is wrong.\n    fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self;\n    fn from_ptr(db: &dyn SyntaxGroup, root: &ast::SyntaxFile, node: Self::StablePtr) -> Self;\n    fn as_syntax_node(&self) -> SyntaxNode;\n    fn stable_ptr(&self) -> Self::StablePtr;\n}\n\npub trait Token: TypedSyntaxNode {\n    fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green;\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr;\n}\n\npub trait Terminal: TypedSyntaxNode {\n    const KIND: SyntaxKind;\n    type TokenType: Token;\n    fn new_green(\n        db: &dyn SyntaxGroup,\n        leading_trivia: TriviaGreen,\n        token: <<Self as Terminal>::TokenType as TypedSyntaxNode>::Green,\n        trailing_trivia: TriviaGreen,\n    ) -> <Self as TypedSyntaxNode>::Green;\n    /// Returns the text of the token of this terminal (excluding the trivia).\n    fn text(&self, db: &dyn SyntaxGroup) -> SmolStr;\n}\n\n/// Wrapper for formatting the text of syntax nodes.\npub struct NodeTextFormatter<'a> {\n    /// The node to format.\n    pub node: &'a SyntaxNode,\n    /// The syntax db.\n    pub db: &'a dyn SyntaxGroup,\n}\nimpl<'a> Display for NodeTextFormatter<'a> {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        let node = self.node.green_node(self.db);\n        match node.details {\n            green::GreenNodeDetails::Token(text) => write!(f, \"{text}\")?,\n            green::GreenNodeDetails::Node { .. } => {\n                for child in self.node.children(self.db) {\n                    write!(f, \"{}\", NodeTextFormatter { node: &child, db: self.db })?;\n                }\n            }\n        }\n        Ok(())\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use super::ids::{GreenId, SyntaxStablePtrId};\nuse super::kind::SyntaxKind;\n\n/// Stable pointer to a node in the syntax tree.\n/// Has enough information to uniquely define a node in the AST, given the tree.\n/// Has undefined behavior when used with the wrong tree.\n/// This is not a real pointer in the low-level sense, just a representation of the path from the\n/// root to the node.\n/// Stable means that when the AST is changed, pointers of unchanged items tend to stay the same.\n/// For example, if a function is changed, the pointer of an unrelated function in the AST should\n/// remain the same, as much as possible.\n#[derive(Clone, Debug, Hash, PartialEq, Eq)]\npub enum SyntaxStablePtr {\n    /// The root node of the tree.\n    Root,\n    /// A child node.\n    Child {\n        /// The parent of the node.\n        parent: SyntaxStablePtrId,\n        /// The SyntaxKind of the node.\n        kind: SyntaxKind,\n        /// A list of field values for this node, to index by.\n        /// Which fields are used is determined by each SyntaxKind.\n        /// For example, a function item might use the name of the function.\n        key_fields: Vec<GreenId>,\n        /// Chronological index among all nodes with the same (parent, kind, key_fields).\n        index: usize,\n    },\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_filesystem::db::{FilesDatabase, FilesGroup};\nuse cairo_lang_utils::Upcast;\n\nuse super::db::SyntaxDatabase;\n\n#[salsa::database(SyntaxDatabase, FilesDatabase)]\n#[derive(Default)]\npub struct DatabaseForTesting {\n    storage: salsa::Storage<DatabaseForTesting>,\n}\nimpl salsa::Database for DatabaseForTesting {}\nimpl Upcast<dyn FilesGroup> for DatabaseForTesting {\n    fn upcast(&self) -> &(dyn FilesGroup + 'static) {\n        self\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use super::db::SyntaxGroup;\nuse super::kind::SyntaxKind;\nuse super::SyntaxNode;\n\n/// Checks whether the given node has a parent of the given kind.\npub fn is_parent_of_kind(db: &dyn SyntaxGroup, node: &SyntaxNode, kind: SyntaxKind) -> bool {\n    let Some(parent) = node.parent() else {\n        return false;\n    };\n    parent.kind(db) == kind\n}\n\n/// Checks whether the given node has a grandparent of the given kind.\npub fn is_grandparent_of_kind(db: &dyn SyntaxGroup, node: &SyntaxNode, kind: SyntaxKind) -> bool {\n    let Some(parent) = node.parent() else {\n        return false;\n    };\n    let Some(grandparent) = parent.parent() else {\n        return false;\n    };\n    grandparent.kind(db) == kind\n}\n\n/// Gets the kind of the parent of the given node, if it exists.\npub fn parent_kind(db: &dyn SyntaxGroup, syntax_node: &SyntaxNode) -> Option<SyntaxKind> {\n    Some(syntax_node.parent()?.kind(db))\n}\n\n/// Gets the kind of the grandparent of the given node, if it exists.\npub fn grandparent_kind(db: &dyn SyntaxGroup, syntax_node: &SyntaxNode) -> Option<SyntaxKind> {\n    Some(syntax_node.parent()?.parent()?.kind(db))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use crate::spec::{EnumBuilder, Node, NodesAggregator, StructBuilder};\n\n/// The specific syntax specification of Cairo.\npub fn get_spec() -> Vec<Node> {\n    NodesAggregator::default()\n    .add_list(\"Trivia\", \"Trivium\")\n    .add_enum(\n        EnumBuilder::new(\"Trivium\")\n            .node_with_explicit_kind(\"SingleLineComment\", \"TokenSingleLineComment\")\n            .node_with_explicit_kind(\"Whitespace\", \"TokenWhitespace\")\n            .node_with_explicit_kind(\"Newline\", \"TokenNewline\")\n            .node_with_explicit_kind(\"Skipped\", \"TokenSkipped\"),\n    )\n    // --- Expressions ---\n    .add_enum(EnumBuilder::new(\"Expr\")\n        .missing(\"Missing\")\n        .node(\"Path\")\n        .node_with_explicit_kind(\"Literal\", \"TerminalLiteralNumber\")\n        .node_with_explicit_kind(\"ShortString\", \"TerminalShortString\")\n        .node_with_explicit_kind(\"False\", \"TerminalFalse\")\n        .node_with_explicit_kind(\"True\", \"TerminalTrue\")\n        .node(\"Parenthesized\")\n        .node(\"Unary\")\n        .node(\"Binary\")\n        .node(\"Tuple\")\n        .node(\"FunctionCall\")\n        .node(\"StructCtorCall\")\n        .node(\"Block\")\n        .node(\"Match\")\n        .node(\"If\")\n        .node(\"ErrorPropagate\")\n        .node(\"FieldInitShorthand\")\n        .node(\"Indexed\"),\n    )\n    .add_separated_list(\"ExprList\", \"Expr\", \"TerminalComma\")\n    .add_struct(StructBuilder::new(\"ArgNameClause\")\n        .node(\"name\", \"TerminalIdentifier\")\n        .node(\"colon\", \"TerminalColon\")\n    )\n    .add_option(\"ArgNameClause\")\n    .add_struct(StructBuilder::new(\"Arg\")\n        .node(\"modifiers\", \"ModifierList\")\n        .node(\"arg_clause\", \"ArgClause\")\n    )\n    .add_enum(EnumBuilder::new(\"ArgClause\")\n        .node(\"Unnamed\")\n        .node(\"Named\")\n        .node(\"FieldInitShorthand\")\n    )\n    .add_struct(StructBuilder::new(\"ArgClauseNamed\")\n        .node(\"name\", \"TerminalIdentifier\")\n        .node(\"colon\", \"TerminalColon\")\n        .node(\"value\", \"Expr\")\n    )\n    .add_struct(StructBuilder::new(\"ArgClauseUnnamed\")\n        .node(\"value\", \"Expr\")\n    )\n    .add_struct(StructBuilder::new(\"ArgClauseFieldInitShorthand\")\n        .node(\"colon\", \"TerminalColon\")\n        .node(\"name\", \"ExprFieldInitShorthand\")\n    )\n    .add_struct(StructBuilder::new(\"ExprFieldInitShorthand\")\n        .node(\"name\", \"TerminalIdentifier\")\n    )\n    .add_separated_list(\"ArgList\", \"Arg\", \"TerminalComma\")\n    .add_struct(StructBuilder::new(\"ExprMissing\"))\n    .add_enum(EnumBuilder::new(\"PathSegment\").missing(\"Simple\").node(\"WithGenericArgs\"))\n    .add_struct(StructBuilder::new(\"PathSegmentSimple\").node(\"ident\", \"TerminalIdentifier\"))\n    .add_option(\"TerminalColonColon\")\n    .add_struct(StructBuilder::new(\"PathSegmentWithGenericArgs\")\n        .node(\"ident\", \"TerminalIdentifier\")\n        .node(\"separator\", \"OptionTerminalColonColon\")\n        .node(\"generic_args\", \"GenericArgs\")\n    )\n    .add_separated_list(\"ExprPath\", \"PathSegment\", \"TerminalColonColon\")\n    .add_struct(StructBuilder::new(\"ExprParenthesized\")\n        .node(\"lparen\", \"TerminalLParen\")\n        .node(\"expr\", \"Expr\")\n        .node(\"rparen\", \"TerminalRParen\")\n    )\n    .add_struct(StructBuilder::new(\"ExprUnary\").node(\"op\", \"UnaryOperator\").node(\"expr\", \"Expr\"))\n    .add_enum(EnumBuilder::new(\"UnaryOperator\")\n        .node_with_explicit_kind(\"Not\", \"TerminalNot\")\n        .node_with_explicit_kind(\"Minus\", \"TerminalMinus\")\n        .node_with_explicit_kind(\"At\", \"TerminalAt\")\n        .node_with_explicit_kind(\"Desnap\", \"TerminalMul\")\n    )\n    .add_struct(StructBuilder::new(\"ExprBinary\")\n        .node(\"lhs\", \"Expr\")\n        .node(\"op\", \"BinaryOperator\")\n        .node(\"rhs\", \"Expr\")\n    )\n    .add_enum(EnumBuilder::new(\"BinaryOperator\")\n        .node_with_explicit_kind(\"Dot\", \"TerminalDot\")\n        .node_with_explicit_kind(\"Not\", \"TerminalNot\")\n        .node_with_explicit_kind(\"Mul\", \"TerminalMul\")\n        .node_with_explicit_kind(\"MulEq\", \"TerminalMulEq\")\n        .node_with_explicit_kind(\"Div\", \"TerminalDiv\")\n        .node_with_explicit_kind(\"DivEq\", \"TerminalDivEq\")\n        .node_with_explicit_kind(\"Mod\", \"TerminalMod\")\n        .node_with_explicit_kind(\"ModEq\", \"TerminalModEq\")\n        .node_with_explicit_kind(\"Plus\", \"TerminalPlus\")\n        .node_with_explicit_kind(\"PlusEq\", \"TerminalPlusEq\")\n        .node_with_explicit_kind(\"Minus\", \"TerminalMinus\")\n        .node_with_explicit_kind(\"MinusEq\", \"TerminalMinusEq\")\n        .node_with_explicit_kind(\"EqEq\", \"TerminalEqEq\")\n        .node_with_explicit_kind(\"Neq\", \"TerminalNeq\")\n        .node_with_explicit_kind(\"Eq\", \"TerminalEq\")\n        // TODO(yuval): not yet implemented in parser.\n        .node_with_explicit_kind(\"And\", \"TerminalAnd\")\n        .node_with_explicit_kind(\"Or\", \"TerminalOr\")\n        .node_with_explicit_kind(\"Xor\", \"TerminalXor\")\n        .node_with_explicit_kind(\"LE\", \"TerminalLE\")\n        .node_with_explicit_kind(\"GE\", \"TerminalGE\")\n        .node_with_explicit_kind(\"LT\", \"TerminalLT\")\n        .node_with_explicit_kind(\"GT\", \"TerminalGT\")\n    )\n    .add_struct(StructBuilder::new(\"ExprTuple\")\n        .node(\"lparen\", \"TerminalLParen\")\n        .node(\"expressions\", \"ExprList\")\n        .node(\"rparen\", \"TerminalRParen\")\n    )\n    .add_struct(StructBuilder::new(\"ExprFunctionCall\")\n        .node(\"path\", \"ExprPath\")\n        .node(\"arguments\", \"ArgListParenthesized\")\n    )\n    .add_struct(StructBuilder::new(\"ArgListParenthesized\")\n        .node(\"lparen\", \"TerminalLParen\")\n        .node(\"args\", \"ArgList\")\n        .node(\"rparen\", \"TerminalRParen\")\n    )\n    .add_struct(StructBuilder::new(\"ExprStructCtorCall\")\n        .node(\"path\", \"ExprPath\")\n        .node(\"arguments\", \"ArgListBraced\")\n    )\n    .add_struct(StructBuilder::new(\"ExprBlock\")\n        .node(\"lbrace\", \"TerminalLBrace\")\n        .node(\"statements\", \"StatementList\")\n        .node(\"rbrace\", \"TerminalRBrace\")\n    )\n    .add_struct(StructBuilder::new(\"ExprMatch\")\n        .node(\"match_kw\", \"TerminalMatch\")\n        // TODO(yuval): change to SimpleExpr\n        .node(\"expr\", \"Expr\")\n        .node(\"lbrace\", \"TerminalLBrace\")\n        .node(\"arms\", \"MatchArms\")\n        .node(\"rbrace\", \"TerminalRBrace\")\n    )\n    .add_separated_list(\"MatchArms\", \"MatchArm\", \"TerminalComma\")\n    .add_struct(StructBuilder::new(\"MatchArm\")\n        .node(\"pattern\", \"Pattern\")\n        .node(\"arrow\", \"TerminalMatchArrow\")\n        .node(\"expression\", \"Expr\")\n    )\n    .add_struct(StructBuilder::new(\"ExprIf\")\n        .node(\"if_kw\", \"TerminalIf\")\n        .node(\"condition\", \"Expr\")\n        .node(\"if_block\", \"ExprBlock\")\n        .node(\"else_clause\", \"OptionElseClause\")\n    )\n    .add_enum(EnumBuilder::new(\"BlockOrIf\")\n        .node_with_explicit_kind(\"Block\", \"ExprBlock\")\n        .node_with_explicit_kind(\"If\", \"ExprIf\")\n    )\n    .add_struct(StructBuilder::new(\"ElseClause\")\n        .node(\"else_kw\", \"TerminalElse\")\n        .node(\"else_block_or_if\", \"BlockOrIf\")\n    )\n    .add_option(\"ElseClause\")\n    .add_struct(StructBuilder::new(\"ExprErrorPropagate\").node(\"expr\", \"Expr\").node(\"op\", \"TerminalQuestionMark\"))\n    .add_struct(StructBuilder::new(\"ExprIndexed\")\n        .node(\"expr\", \"Expr\")\n        .node(\"lbrack\", \"TerminalLBrack\")\n        .node(\"index_expr\", \"Expr\")\n        .node(\"rbrack\", \"TerminalRBrack\")\n    )\n    // --- Struct ctor ---\n    .add_struct(StructBuilder::new(\"StructArgExpr\")\n        .node(\"colon\", \"TerminalColon\")\n        .node(\"expr\", \"Expr\")\n    )\n    .add_option(\"StructArgExpr\")\n    .add_struct(StructBuilder::new(\"StructArgSingle\")\n        .key_node(\"identifier\", \"TerminalIdentifier\")\n        .node(\"arg_expr\", \"OptionStructArgExpr\")\n    )\n    .add_struct(StructBuilder::new(\"StructArgTail\")\n        .node(\"dotdot\", \"TerminalDotDot\")\n        .node(\"expression\", \"Expr\")\n    )\n    .add_enum(EnumBuilder::new(\"StructArg\")\n        .node_with_explicit_kind(\"StructArgSingle\", \"StructArgSingle\")\n        .node_with_explicit_kind(\"StructArgTail\", \"StructArgTail\")\n    )\n    .add_separated_list(\"StructArgList\", \"StructArg\", \"TerminalComma\")\n    .add_struct(StructBuilder::new(\"ArgListBraced\")\n        .node(\"lbrace\", \"TerminalLBrace\")\n        .node(\"arguments\", \"StructArgList\")\n        .node(\"rbrace\", \"TerminalRBrace\")\n    )\n    // ---Patterns ---\n    // TODO(spapini): Support \"Or\" patterns (e.g. 1 | 2).\n    // TODO(spapini): Support tuple patterns (e.g. (x, _)).\n    .add_enum(EnumBuilder::new(\"Pattern\")\n        .node_with_explicit_kind(\"Underscore\", \"TerminalUnderscore\")\n        .node_with_explicit_kind(\"Literal\", \"TerminalLiteralNumber\")\n        .node_with_explicit_kind(\"ShortString\", \"TerminalShortString\")\n        .node(\"Identifier\")\n        .node(\"Struct\")\n        .node(\"Tuple\")\n        .node(\"Enum\")\n        .node_with_explicit_kind(\"Path\", \"ExprPath\")\n    )\n    .add_struct(StructBuilder::new(\"PatternIdentifier\")\n        .node(\"modifiers\", \"ModifierList\")\n        .key_node(\"name\", \"TerminalIdentifier\")\n    )\n    .add_struct(StructBuilder::new(\"PatternStruct\")\n        // TODO(spapini): Use SimplePath instead - which is not an expr.\n        .node(\"path\", \"ExprPath\")\n        .node(\"lbrace\", \"TerminalLBrace\")\n        .node(\"params\", \"PatternStructParamList\")\n        .node(\"rbrace\", \"TerminalRBrace\")\n    )\n    .add_separated_list(\"PatternStructParamList\", \"PatternStructParam\", \"TerminalComma\")\n    .add_struct(StructBuilder::new(\"PatternTuple\")\n        .node(\"lparen\", \"TerminalLParen\")\n        .node(\"patterns\", \"PatternList\")\n        .node(\"rparen\", \"TerminalRParen\")\n    )\n    .add_separated_list(\"PatternList\", \"Pattern\", \"TerminalComma\")\n    .add_enum(EnumBuilder::new(\"PatternStructParam\")\n        .node_with_explicit_kind(\"Single\", \"PatternIdentifier\")\n        .node(\"WithExpr\")\n        .node_with_explicit_kind(\"Tail\", \"TerminalDotDot\")\n    )\n    .add_struct(StructBuilder::new(\"PatternStructParamWithExpr\")\n        .node(\"modifiers\", \"ModifierList\")\n        .node(\"name\", \"TerminalIdentifier\")\n        .node(\"colon\", \"TerminalColon\")\n        .node(\"pattern\", \"Pattern\")\n    )\n    .add_struct(StructBuilder::new(\"PatternEnum\")\n        .node(\"path\", \"ExprPath\")\n        .node(\"lparen\", \"TerminalLParen\")\n        .node(\"pattern\", \"Pattern\")\n        .node(\"rparen\", \"TerminalRParen\")\n    )\n    // --- Type clauses ---\n    // TODO(yuval): support SimpleExpr instead of Expr\n    .add_struct(StructBuilder::new(\"TypeClause\").node(\"colon\", \"TerminalColon\").node(\"ty\", \"Expr\"))\n    .add_option(\"TypeClause\")\n    .add_struct(StructBuilder::new(\"ReturnTypeClause\")\n        .node(\"arrow\", \"TerminalArrow\")\n        .node(\"ty\", \"Expr\")\n    )\n    .add_option(\"ReturnTypeClause\")\n    // --- Statements ---\n    .add_enum(EnumBuilder::new(\"Statement\")\n        .missing(\"Missing\")\n        .node(\"Let\")\n        .node(\"Expr\")\n        .node(\"Return\")\n    )\n    .add_list(\"StatementList\", \"Statement\")\n    .add_struct(StructBuilder::new(\"StatementMissing\"))\n    .add_struct(StructBuilder::new(\"StatementLet\")\n        .node(\"let_kw\", \"TerminalLet\")\n        .key_node(\"pattern\", \"Pattern\")\n        .node(\"type_clause\", \"OptionTypeClause\")\n        .node(\"eq\", \"TerminalEq\")\n        .node(\"rhs\", \"Expr\")\n        .node(\"semicolon\", \"TerminalSemicolon\")\n    )\n    .add_option(\"TerminalSemicolon\")\n    .add_struct(StructBuilder::new(\"StatementExpr\")\n        .node(\"expr\", \"Expr\")\n        .node(\"semicolon\", \"OptionTerminalSemicolon\")\n    )\n    .add_struct(StructBuilder::new(\"StatementReturn\")\n        .node(\"return_kw\", \"TerminalReturn\")\n        .node(\"expr\", \"Expr\")\n        .node(\"semicolon\", \"TerminalSemicolon\")\n    )\n    // --- Functions ---\n    .add_struct(StructBuilder::new(\"Param\")\n        .node(\"modifiers\", \"ModifierList\")\n        .key_node(\"name\", \"TerminalIdentifier\")\n        .node(\"type_clause\", \"TypeClause\")\n    )\n    .add_list(\"ModifierList\", \"Modifier\")\n    .add_enum(EnumBuilder::new(\"Modifier\")\n        .node_with_explicit_kind(\"Ref\", \"TerminalRef\")\n        .node_with_explicit_kind(\"Mut\", \"TerminalMut\")\n    )\n    .add_separated_list(\"ParamList\", \"Param\", \"TerminalComma\")\n    .add_struct(StructBuilder::new(\"ImplicitsClause\")\n        .node(\"implicits_kw\", \"TerminalImplicits\")\n        .node(\"lparen\", \"TerminalLParen\")\n        .node(\"implicits\", \"ImplicitsList\")\n        .node(\"rparen\", \"TerminalRParen\")\n    )\n    .add_separated_list(\"ImplicitsList\", \"ExprPath\", \"TerminalComma\")\n    .add_option(\"ImplicitsClause\")\n    .add_option(\"TerminalNoPanic\")\n    // TODO(spapini): Add generic params.\n    // This is an unnamed signature, e.g. \"() -> Type\".\n    .add_struct(StructBuilder::new(\"FunctionSignature\")\n        .node(\"lparen\", \"TerminalLParen\")\n        .node(\"parameters\", \"ParamList\")\n        .node(\"rparen\", \"TerminalRParen\")\n        .node(\"ret_ty\", \"OptionReturnTypeClause\")\n        .node(\"implicits_clause\", \"OptionImplicitsClause\")\n        .node(\"optional_no_panic\", \"OptionTerminalNoPanic\")\n    )\n    // --- Struct Members ---\n    // Struct member and enum variant have the same structure.\n    .add_struct(StructBuilder::new(\"Member\")\n        .key_node(\"name\", \"TerminalIdentifier\")\n        .node(\"type_clause\", \"TypeClause\")\n    )\n    .add_separated_list(\"MemberList\", \"Member\", \"TerminalComma\")\n    // --- Items ---\n    .add_enum(EnumBuilder::new(\"Item\")\n        .node(\"Constant\")\n        .node(\"Module\")\n        .node(\"Use\")\n        .node_with_explicit_kind(\"FreeFunction\", \"FunctionWithBody\")\n        .node(\"ExternFunction\")\n        .node(\"ExternType\")\n        .node(\"Trait\")\n        .node(\"Impl\")\n        .node(\"Struct\")\n        .node(\"Enum\")\n        .node(\"TypeAlias\")\n    )\n    .add_list(\"ItemList\", \"Item\")\n    .add_struct(StructBuilder::new(\"Attribute\")\n         .node(\"hash\", \"TerminalHash\")\n         .node(\"lbrack\", \"TerminalLBrack\")\n         .node(\"attr\", \"TerminalIdentifier\")\n         .node(\"args\", \"OptionAttributeArgs\")\n         .node(\"rbrack\", \"TerminalRBrack\")\n    )\n    .add_list(\"AttributeList\", \"Attribute\")\n    .add_struct(StructBuilder::new(\"ItemModule\")\n        .node(\"attributes\" ,\"AttributeList\")\n        .node(\"module_kw\", \"TerminalModule\")\n        .key_node(\"name\", \"TerminalIdentifier\")\n        .node(\"body\", \"MaybeModuleBody\")\n    )\n    .add_enum(EnumBuilder::new(\"MaybeModuleBody\")\n        .node_with_explicit_kind(\"Some\", \"ModuleBody\")\n        .node_with_explicit_kind(\"None\", \"TerminalSemicolon\")\n     )\n    .add_struct(StructBuilder::new(\"ModuleBody\")\n            .node(\"lbrace\", \"TerminalLBrace\")\n            .node(\"items\", \"ItemList\")\n            .node(\"rbrace\", \"TerminalRBrace\")\n    )\n    .add_option(\"AttributeArgs\")\n    .add_struct(StructBuilder::new(\"AttributeArgs\")\n        .node(\"lparen\", \"TerminalLParen\")\n        .node(\"arg_list\", \"AttributeArgList\")\n        .node(\"rparen\", \"TerminalRParen\")\n    )\n    .add_separated_list(\"AttributeArgList\", \"Expr\", \"TerminalComma\")\n    .add_struct(StructBuilder::new(\"FunctionDeclaration\")\n        .node(\"function_kw\", \"TerminalFunction\")\n        .key_node(\"name\", \"TerminalIdentifier\")\n        .node(\"generic_params\", \"OptionWrappedGenericParamList\")\n        .node(\"signature\", \"FunctionSignature\")\n    )\n    .add_struct(StructBuilder::new(\"ItemConstant\")\n        .node(\"attributes\" ,\"AttributeList\")\n        .node(\"const_kw\", \"TerminalConst\")\n        .key_node(\"name\", \"TerminalIdentifier\")\n        .node(\"type_clause\", \"TypeClause\")\n        .node(\"eq\", \"TerminalEq\")\n        .node(\"value\", \"Expr\")\n        .node(\"semicolon\", \"TerminalSemicolon\")\n    )\n    .add_struct(StructBuilder::new(\"FunctionWithBody\")\n        .node(\"attributes\" ,\"AttributeList\")\n         // TODO(ilya): Use only the name as key node.\n        .key_node(\"declaration\", \"FunctionDeclaration\")\n        .node(\"body\", \"ExprBlock\")\n    )\n    .add_struct(StructBuilder::new(\"ItemExternFunction\")\n        .node(\"attributes\" ,\"AttributeList\")\n        .node(\"extern_kw\", \"TerminalExtern\")\n         // TODO(ilya): Use only the name as key node.\n        .key_node(\"declaration\", \"FunctionDeclaration\")\n        .node(\"semicolon\", \"TerminalSemicolon\")\n    )\n    .add_struct(StructBuilder::new(\"ItemExternType\")\n        .node(\"attributes\" ,\"AttributeList\")\n        .node(\"extern_kw\", \"TerminalExtern\")\n        .node(\"type_kw\", \"TerminalType\")\n        .key_node(\"name\", \"TerminalIdentifier\")\n        .node(\"generic_params\", \"OptionWrappedGenericParamList\")\n        .node(\"semicolon\", \"TerminalSemicolon\")\n    )\n    // TODO(spapini): consider having specific ItemLists here.\n    .add_struct(StructBuilder::new(\"ItemTrait\")\n        .node(\"attributes\" ,\"AttributeList\")\n        .node(\"trait_kw\", \"TerminalTrait\")\n        .key_node(\"name\", \"TerminalIdentifier\")\n        .node(\"generic_params\", \"OptionWrappedGenericParamList\")\n        .node(\"body\", \"MaybeTraitBody\")\n    )\n    .add_enum(EnumBuilder::new(\"MaybeTraitBody\")\n        .node_with_explicit_kind(\"Some\", \"TraitBody\")\n        .node_with_explicit_kind(\"None\", \"TerminalSemicolon\")\n    )\n    .add_struct(StructBuilder::new(\"TraitBody\")\n        .node(\"lbrace\", \"TerminalLBrace\")\n        .node(\"items\", \"TraitItemList\")\n        .node(\"rbrace\", \"TerminalRBrace\")\n    )\n    .add_list(\"TraitItemList\", \"TraitItem\")\n    .add_enum(EnumBuilder::new(\"TraitItem\")\n        // TODO(spapini): types and constants.\n        .node(\"Function\")\n    )\n    .add_struct(StructBuilder::new(\"TraitItemFunction\")\n        .node(\"attributes\" ,\"AttributeList\")\n         // TODO(ilya): Use only the name as key node.\n        .key_node(\"declaration\", \"FunctionDeclaration\")\n        .node(\"body\", \"MaybeTraitFunctionBody\")\n    )\n    .add_enum(EnumBuilder::new(\"MaybeTraitFunctionBody\")\n        .node_with_explicit_kind(\"Some\", \"ExprBlock\")\n        .node_with_explicit_kind(\"None\", \"TerminalSemicolon\")\n    )\n    .add_struct(StructBuilder::new(\"ItemImpl\")\n        .node(\"attributes\" ,\"AttributeList\")\n        .node(\"impl_kw\", \"TerminalImpl\")\n        .key_node(\"name\", \"TerminalIdentifier\")\n        .node(\"generic_params\", \"OptionWrappedGenericParamList\")\n        .node(\"of_kw\", \"TerminalOf\")\n        .node(\"trait_path\", \"ExprPath\")\n        .node(\"body\", \"MaybeImplBody\")\n    )\n    .add_enum(EnumBuilder::new(\"MaybeImplBody\")\n        .node_with_explicit_kind(\"Some\", \"ImplBody\")\n        .node_with_explicit_kind(\"None\", \"TerminalSemicolon\")\n    )\n    .add_struct(StructBuilder::new(\"ImplBody\")\n            .node(\"lbrace\", \"TerminalLBrace\")\n            .node(\"items\", \"ItemList\")\n            .node(\"rbrace\", \"TerminalRBrace\")\n    )\n    .add_struct(StructBuilder::new(\"ItemStruct\")\n        .node(\"attributes\" ,\"AttributeList\")\n        .node(\"struct_kw\", \"TerminalStruct\")\n        .key_node(\"name\", \"TerminalIdentifier\")\n        .node(\"generic_params\", \"OptionWrappedGenericParamList\")\n        .node(\"lbrace\", \"TerminalLBrace\")\n        .node(\"members\", \"MemberList\")\n        .node(\"rbrace\", \"TerminalRBrace\")\n    )\n    .add_struct(StructBuilder::new(\"ItemEnum\")\n        .node(\"attributes\" ,\"AttributeList\")\n        .node(\"enum_kw\", \"TerminalEnum\")\n        .key_node(\"name\", \"TerminalIdentifier\")\n        .node(\"generic_params\", \"OptionWrappedGenericParamList\")\n        .node(\"lbrace\", \"TerminalLBrace\")\n        .node(\"variants\", \"MemberList\")\n        .node(\"rbrace\", \"TerminalRBrace\")\n    )\n    .add_struct(StructBuilder::new(\"ItemTypeAlias\")\n        .node(\"attributes\" ,\"AttributeList\")\n        .node(\"type_kw\", \"TerminalType\")\n        .key_node(\"name\", \"TerminalIdentifier\")\n        .node(\"generic_params\", \"OptionWrappedGenericParamList\")\n        .node(\"eq\", \"TerminalEq\")\n        .node(\"ty\", \"Expr\")\n        .node(\"semicolon\", \"TerminalSemicolon\")\n    )\n    .add_struct(StructBuilder::new(\"ItemUse\")\n        .node(\"attributes\" ,\"AttributeList\")\n        .node(\"use_kw\", \"TerminalUse\")\n        .key_node(\"name\", \"ExprPath\")\n        .node(\"semicolon\", \"TerminalSemicolon\")\n    )\n    // --- Generics ---\n    .add_struct(StructBuilder::new(\"GenericArgExpr\")\n        .node(\"value\", \"Expr\")\n    )\n    .add_enum(\n        EnumBuilder::new(\"GenericArg\")\n        .node_with_explicit_kind(\"Underscore\", \"TerminalUnderscore\")\n        .node(\"Expr\")\n    )\n    .add_struct(StructBuilder::new(\"GenericArgs\")\n        .node(\"langle\", \"TerminalLT\")\n        .node(\"generic_args\", \"GenericArgList\")\n        .node(\"rangle\", \"TerminalGT\")\n    )\n    .add_separated_list(\"GenericArgList\", \"GenericArg\", \"TerminalComma\")\n    .add_option(\"WrappedGenericParamList\")\n    .add_struct(StructBuilder::new(\"WrappedGenericParamList\")\n        .node(\"langle\", \"TerminalLT\")\n        .node(\"generic_params\", \"GenericParamList\")\n        .node(\"rangle\", \"TerminalGT\")\n    )\n    .add_separated_list(\"GenericParamList\", \"GenericParam\", \"TerminalComma\")\n    // TODO(spapini): Remove this indirection.\n    .add_enum(EnumBuilder::new(\"GenericParam\")\n        .node(\"Type\")\n        .node(\"Const\")\n        .node(\"Impl\")\n    )\n    .add_struct(StructBuilder::new(\"GenericParamType\")\n        .key_node(\"name\", \"TerminalIdentifier\")\n    )\n    .add_struct(StructBuilder::new(\"GenericParamConst\")\n        .node(\"const_kw\", \"TerminalConst\")\n        .key_node(\"name\", \"TerminalIdentifier\")\n    )\n    .add_struct(StructBuilder::new(\"GenericParamImpl\")\n        .node(\"impl_kw\", \"TerminalImpl\")\n        .key_node(\"name\", \"TerminalIdentifier\")\n        .node(\"colon\", \"TerminalColon\")\n        .node(\"trait_path\", \"ExprPath\")\n    )\n    // --- Tokens + Terminals ---\n    .add_token_and_terminal(\"Identifier\")\n    .add_token_and_terminal(\"LiteralNumber\")\n    .add_token_and_terminal(\"ShortString\")\n    .add_keyword_token_and_terminal(\"Const\")\n    .add_keyword_token_and_terminal(\"Else\")\n    .add_keyword_token_and_terminal(\"Enum\")\n    .add_keyword_token_and_terminal(\"Extern\")\n    .add_keyword_token_and_terminal(\"False\")\n    .add_keyword_token_and_terminal(\"Function\")\n    .add_keyword_token_and_terminal(\"If\")\n    .add_keyword_token_and_terminal(\"Impl\")\n    .add_keyword_token_and_terminal(\"Implicits\")\n    .add_keyword_token_and_terminal(\"Let\")\n    .add_keyword_token_and_terminal(\"Match\")\n    .add_keyword_token_and_terminal(\"Module\")\n    .add_keyword_token_and_terminal(\"Mut\")\n    .add_keyword_token_and_terminal(\"NoPanic\")\n    .add_keyword_token_and_terminal(\"Of\")\n    .add_keyword_token_and_terminal(\"Ref\")\n    .add_keyword_token_and_terminal(\"Return\")\n    .add_keyword_token_and_terminal(\"Struct\")\n    .add_keyword_token_and_terminal(\"Trait\")\n    .add_keyword_token_and_terminal(\"True\")\n    .add_keyword_token_and_terminal(\"Type\")\n    .add_keyword_token_and_terminal(\"Use\")\n    .add_token_and_terminal(\"And\")\n    .add_token_and_terminal(\"AndAnd\")\n    .add_token_and_terminal(\"Arrow\")\n    .add_token_and_terminal(\"At\")\n    .add_token_and_terminal(\"BadCharacters\")\n    .add_token_and_terminal(\"Colon\")\n    .add_token_and_terminal(\"ColonColon\")\n    .add_token_and_terminal(\"Comma\")\n    .add_token_and_terminal(\"Div\")\n    .add_token_and_terminal(\"DivEq\")\n    .add_token_and_terminal(\"Dot\")\n    .add_token_and_terminal(\"DotDot\")\n    .add_token_and_terminal(\"EndOfFile\")\n    .add_token_and_terminal(\"Eq\")\n    .add_token_and_terminal(\"EqEq\")\n    .add_token_and_terminal(\"GE\")\n    .add_token_and_terminal(\"GT\")\n    .add_token_and_terminal(\"Hash\")\n    .add_token_and_terminal(\"LBrace\")\n    .add_token_and_terminal(\"LBrack\")\n    .add_token_and_terminal(\"LE\")\n    .add_token_and_terminal(\"LParen\")\n    .add_token_and_terminal(\"LT\")\n    .add_token_and_terminal(\"MatchArrow\")\n    .add_token_and_terminal(\"Minus\")\n    .add_token_and_terminal(\"MinusEq\")\n    .add_token_and_terminal(\"Mod\")\n    .add_token_and_terminal(\"ModEq\")\n    .add_token_and_terminal(\"Mul\")\n    .add_token_and_terminal(\"MulEq\")\n    .add_token_and_terminal(\"Neq\")\n    .add_token_and_terminal(\"Not\")\n    .add_token_and_terminal(\"Or\")\n    .add_token_and_terminal(\"OrOr\")\n    .add_token_and_terminal(\"Plus\")\n    .add_token_and_terminal(\"PlusEq\")\n    .add_token_and_terminal(\"QuestionMark\")\n    .add_token_and_terminal(\"RBrace\")\n    .add_token_and_terminal(\"RBrack\")\n    .add_token_and_terminal(\"RParen\")\n    .add_token_and_terminal(\"Semicolon\")\n    .add_token_and_terminal(\"Underscore\")\n    .add_token_and_terminal(\"Xor\")\n    // --- Meta ---\n    .add_struct(StructBuilder::new(\"SyntaxFile\")\n        .node(\"items\", \"ItemList\")\n        .node(\"eof\", \"TerminalEndOfFile\")\n    )\n    .add_token(\"SingleLineComment\")\n    .add_token(\"Whitespace\")\n    .add_token(\"Newline\")\n    .add_token(\"Missing\")\n    .add_token(\"Skipped\").get()\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_lang_syntax_codegen::generator::{ensure_file_content, get_codes, project_root};\nuse cairo_lang_utils::logging::init_logging;\n\nfn main() {\n    init_logging(log::LevelFilter::Info);\n    log::info!(\"Starting syntax generation.\");\n\n    for (suffix, code) in get_codes() {\n        let filename = project_root().join(suffix);\n        ensure_file_content(filename, code);\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::fs;\nuse std::path::PathBuf;\n\nuse genco::prelude::*;\nuse xshell::{cmd, Shell};\n\nuse crate::cairo_spec::get_spec;\nuse crate::spec::{Member, Node, NodeKind, Variant};\n\npub fn project_root() -> PathBuf {\n    // This is the directory of Cargo.toml of the syntax_codegen crate.\n    let dir = env!(\"CARGO_MANIFEST_DIR\");\n    // Pop the \"/crates/cairo-lang-syntax-codegen\" suffix.\n    let res = PathBuf::from(dir).parent().unwrap().parent().unwrap().to_owned();\n    assert!(res.join(\"Cargo.toml\").exists(), \"Could not find project root directory.\");\n    res\n}\n\npub fn ensure_file_content(filename: PathBuf, content: String) {\n    if let Ok(old_contents) = fs::read_to_string(&filename) {\n        if old_contents == content {\n            return;\n        }\n    }\n\n    fs::write(&filename, content).unwrap();\n}\n\npub fn get_codes() -> Vec<(String, String)> {\n    vec![\n        (\n            \"crates/cairo-lang-syntax/src/node/ast.rs\".into(),\n            reformat_rust_code(generate_ast_code().to_string().unwrap()),\n        ),\n        (\n            \"crates/cairo-lang-syntax/src/node/kind.rs\".into(),\n            reformat_rust_code(generate_kinds_code().to_string().unwrap()),\n        ),\n        (\n            \"crates/cairo-lang-syntax/src/node/key_fields.rs\".into(),\n            reformat_rust_code(generate_key_fields_code().to_string().unwrap()),\n        ),\n    ]\n}\n\npub fn reformat_rust_code(text: String) -> String {\n    // Since rustfmt is used with nightly features, it takes 2 runs to reach a fixed point.\n    reformat_rust_code_inner(reformat_rust_code_inner(text))\n}\npub fn reformat_rust_code_inner(text: String) -> String {\n    let sh = Shell::new().unwrap();\n    sh.set_var(\"RUSTUP_TOOLCHAIN\", \"nightly-2022-11-03\");\n    let rustfmt_toml = project_root().join(\"rustfmt.toml\");\n    let mut stdout = cmd!(sh, \"rustfmt --config-path {rustfmt_toml}\").stdin(text).read().unwrap();\n    if !stdout.ends_with('\\n') {\n        stdout.push('\\n');\n    }\n    stdout\n}\n\nfn generate_kinds_code() -> rust::Tokens {\n    let spec = get_spec();\n    let mut tokens = quote! {\n        $(\"// Autogenerated file. To regenerate, please run `cargo run --bin generate-syntax`.\\n\")\n        use core::fmt;\n    };\n    let mut kinds = rust::Tokens::new();\n    let mut token_kinds = rust::Tokens::new();\n    let mut keyword_token_kinds = rust::Tokens::new();\n    let mut terminal_kinds = rust::Tokens::new();\n    let mut keyword_terminal_kinds = rust::Tokens::new();\n\n    // SyntaxKind.\n    for Node { name, kind } in spec.iter() {\n        match kind {\n            NodeKind::Enum { .. } => {}\n            _ => {\n                kinds.extend(quote! {\n                    $name,\n                });\n            }\n        }\n    }\n\n    for Node { name, kind } in spec.into_iter() {\n        match kind {\n            NodeKind::Token { is_keyword } => {\n                append_rust_token(&mut token_kinds, &name);\n                if is_keyword {\n                    append_rust_token(&mut keyword_token_kinds, &name);\n                }\n            }\n            NodeKind::Terminal { is_keyword, .. } => {\n                append_rust_token(&mut terminal_kinds, &name);\n                if is_keyword {\n                    append_rust_token(&mut keyword_terminal_kinds, &name);\n                }\n            }\n            _ => {}\n        }\n    }\n\n    tokens.extend(quote! {\n        #[derive(Copy, Clone, Debug, Hash, PartialEq, Eq)]\n        pub enum SyntaxKind {\n            $kinds\n        }\n        impl SyntaxKind {\n            pub fn is_token(&self) -> bool {\n                matches!(\n                    *self,\n                    $token_kinds\n                )\n            }\n            pub fn is_terminal(&self) -> bool {\n                matches!(\n                    *self,\n                    $terminal_kinds\n                )\n            }\n            pub fn is_keyword_token(&self) -> bool {\n                matches!(\n                    *self,\n                    $keyword_token_kinds\n                )\n            }\n            pub fn is_keyword_terminal(&self) -> bool {\n                matches!(\n                    *self,\n                    $keyword_terminal_kinds\n                )\n            }\n        }\n        impl fmt::Display for SyntaxKind {\n            fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n                write!(f, \"{self:?}\")\n            }\n        }\n    });\n    tokens\n}\n\nfn generate_key_fields_code() -> rust::Tokens {\n    let spec = get_spec();\n    let mut arms = rust::Tokens::new();\n\n    for Node { name, kind } in spec.into_iter() {\n        match kind {\n            NodeKind::Struct { members } | NodeKind::Terminal { members, .. } => {\n                let mut fields = rust::Tokens::new();\n                for (i, member) in members.into_iter().enumerate() {\n                    let field_name = member.name;\n                    if member.key {\n                        fields.extend(quote! { $(\"/*\") $field_name $(\"*/\") children[$i] });\n                    }\n                }\n                arms.extend(quote! {\n                    SyntaxKind::$name => vec![$fields],\n                });\n            }\n            NodeKind::List { .. } | NodeKind::SeparatedList { .. } | NodeKind::Token { .. } => {\n                arms.extend(quote! {\n                    SyntaxKind::$name => vec![],\n                });\n            }\n            NodeKind::Enum { .. } => {}\n        }\n    }\n    let tokens = quote! {\n        $(\"// Autogenerated file. To regenerate, please run `cargo run --bin generate-syntax`.\\n\")\n        use super::ids::GreenId;\n        use super::kind::SyntaxKind;\n\n        $(\"/// Gets the vector of children ids that are the indexing key for this SyntaxKind.\\n\")\n        $(\"/// Each SyntaxKind has some children that are defined in the spec to be its indexing key\\n\")\n        $(\"/// for its stable pointer. See [super::stable_ptr].\\n\")\n        pub fn get_key_fields(kind: SyntaxKind, children: Vec<GreenId>) -> Vec<GreenId> {\n            // TODO(spapini): Implement this.\n            match kind {\n                $arms\n            }\n        }\n    };\n    tokens\n}\n\nfn generate_ast_code() -> rust::Tokens {\n    let spec = get_spec();\n    let mut tokens = quote! {\n        $(\"// Autogenerated file. To regenerate, please run `cargo run --bin generate-syntax`.\\n\")\n        #![allow(clippy::match_single_binding)]\n        #![allow(clippy::too_many_arguments)]\n        #![allow(dead_code)]\n        #![allow(unused_variables)]\n        use std::ops::Deref;\n\n        use cairo_lang_filesystem::span::TextWidth;\n        use cairo_lang_utils::extract_matches;\n        use smol_str::SmolStr;\n\n        use super::element_list::ElementList;\n        use super::green::GreenNodeDetails;\n        use super::kind::SyntaxKind;\n        use super::{\n            GreenId, GreenNode, SyntaxGroup, SyntaxNode, SyntaxStablePtr, SyntaxStablePtrId,\n            Terminal, Token, TypedSyntaxNode,\n        };\n    };\n    for Node { name, kind } in spec.into_iter() {\n        tokens.extend(match kind {\n            NodeKind::Enum { variants, missing_variant } => {\n                gen_enum_code(name, variants, missing_variant)\n            }\n            NodeKind::Struct { members } => gen_struct_code(name, members, false),\n            NodeKind::Terminal { members, .. } => gen_struct_code(name, members, true),\n            NodeKind::Token { .. } => gen_token_code(name),\n            NodeKind::List { element_type } => gen_list_code(name, element_type),\n            NodeKind::SeparatedList { element_type, separator_type } => {\n                gen_separated_list_code(name, element_type, separator_type)\n            }\n        })\n    }\n    tokens\n}\n\nfn gen_list_code(name: String, element_type: String) -> rust::Tokens {\n    // TODO(spapini): Change Deref to Borrow.\n    let ptr_name = format!(\"{name}Ptr\");\n    let green_name = format!(\"{name}Green\");\n    let element_green_name = format!(\"{element_type}Green\");\n    let common_code = gen_common_list_code(&name, &green_name, &ptr_name);\n    quote! {\n        #[derive(Clone, Debug, Eq, Hash, PartialEq)]\n        pub struct $(&name)(ElementList<$(&element_type),1>);\n        impl Deref for $(&name){\n            type Target = ElementList<$(&element_type),1>;\n\n            fn deref(&self) -> &Self::Target {\n                &self.0\n            }\n        }\n        impl $(&name){\n            pub fn new_green(\n                db: &dyn SyntaxGroup, children: Vec<$(&element_green_name)>\n            ) -> $(&green_name) {\n                let width = children.iter().map(|id|\n                    db.lookup_intern_green(id.0).width()).sum();\n                $(&green_name)(db.intern_green(GreenNode {\n                    kind: SyntaxKind::$(&name),\n                    details: GreenNodeDetails::Node {\n                        children: children.iter().map(|x| x.0).collect(),\n                        width,\n                    },\n                }))\n            }\n        }\n        #[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\n        pub struct $(&ptr_name)(pub SyntaxStablePtrId);\n        impl $(&ptr_name) {\n            pub fn untyped(&self) -> SyntaxStablePtrId {\n                self.0\n            }\n        }\n        $common_code\n    }\n}\n\nfn gen_separated_list_code(\n    name: String,\n    element_type: String,\n    separator_type: String,\n) -> rust::Tokens {\n    // TODO(spapini): Change Deref to Borrow.\n    let ptr_name = format!(\"{name}Ptr\");\n    let green_name = format!(\"{name}Green\");\n    let element_or_separator_green_name = format!(\"{name}ElementOrSeparatorGreen\");\n    let element_green_name = format!(\"{element_type}Green\");\n    let separator_green_name = format!(\"{separator_type}Green\");\n    let common_code = gen_common_list_code(&name, &green_name, &ptr_name);\n    quote! {\n        #[derive(Clone, Debug, Eq, Hash, PartialEq)]\n        pub struct $(&name)(ElementList<$(&element_type),2>);\n        impl Deref for $(&name){\n            type Target = ElementList<$(&element_type),2>;\n\n            fn deref(&self) -> &Self::Target {\n                &self.0\n            }\n        }\n        impl $(&name){\n            pub fn new_green(\n                db: &dyn SyntaxGroup, children: Vec<$(&element_or_separator_green_name)>\n            ) -> $(&green_name) {\n                let width = children.iter().map(|id|\n                    db.lookup_intern_green(id.id()).width()).sum();\n                $(&green_name)(db.intern_green(GreenNode {\n                    kind: SyntaxKind::$(&name),\n                    details: GreenNodeDetails::Node {\n                        children: children.iter().map(|x| x.id()).collect(),\n                        width,\n                    },\n                }))\n            }\n        }\n        #[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\n        pub struct $(&ptr_name)(pub SyntaxStablePtrId);\n        impl $(&ptr_name) {\n            pub fn untyped(&self) -> SyntaxStablePtrId {\n                self.0\n            }\n        }\n        #[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\n        pub enum $(&element_or_separator_green_name) {\n            Separator($(&separator_green_name)),\n            Element($(&element_green_name)),\n        }\n        impl From<$(&separator_green_name)> for $(&element_or_separator_green_name) {\n            fn from(value: $(&separator_green_name)) -> Self {\n                $(&element_or_separator_green_name)::Separator(value)\n            }\n        }\n        impl From<$(&element_green_name)> for $(&element_or_separator_green_name) {\n            fn from(value: $(&element_green_name)) -> Self {\n                $(&element_or_separator_green_name)::Element(value)\n            }\n        }\n        impl $(&element_or_separator_green_name) {\n            fn id(&self) -> GreenId {\n                match self {\n                    $(&element_or_separator_green_name)::Separator(green) => green.0,\n                    $(&element_or_separator_green_name)::Element(green) => green.0,\n                }\n            }\n        }\n        $common_code\n    }\n}\n\nfn gen_common_list_code(name: &str, green_name: &str, ptr_name: &str) -> rust::Tokens {\n    quote! {\n        #[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\n        pub struct $green_name(pub GreenId);\n        impl TypedSyntaxNode for $name {\n            const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::$name);\n            type StablePtr = $ptr_name;\n            type Green = $green_name;\n            fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n                $green_name(db.intern_green(\n                    GreenNode {\n                        kind: SyntaxKind::$name,\n                        details: GreenNodeDetails::Node { children: vec![], width: TextWidth::default() },\n                    })\n                )\n            }\n            fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n                Self(ElementList::new(node))\n            }\n            fn as_syntax_node(&self) -> SyntaxNode{\n                self.node.clone()\n            }\n            fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n                Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n            }\n            fn stable_ptr(&self) -> Self::StablePtr {\n                $ptr_name(self.node.0.stable_ptr)\n            }\n        }\n    }\n}\n\nfn gen_enum_code(\n    name: String,\n    variants: Vec<Variant>,\n    missing_variant: Option<Variant>,\n) -> rust::Tokens {\n    let ptr_name = format!(\"{name}Ptr\");\n    let green_name = format!(\"{name}Green\");\n    let mut enum_body = quote! {};\n    let mut from_node_body = quote! {};\n    let mut ptr_conversions = quote! {};\n    let mut green_conversions = quote! {};\n    for variant in &variants {\n        let n = &variant.name;\n        let k = &variant.kind;\n\n        enum_body.extend(quote! {\n            $n($k),\n        });\n        from_node_body.extend(quote! {\n            SyntaxKind::$k => $(&name)::$n($k::from_syntax_node(db, node)),\n        });\n        let variant_ptr = format!(\"{k}Ptr\");\n        ptr_conversions.extend(quote! {\n            impl From<$(&variant_ptr)> for $(&ptr_name) {\n                fn from(value: $(&variant_ptr)) -> Self {\n                    Self(value.0)\n                }\n            }\n        });\n        let variant_green = format!(\"{k}Green\");\n        green_conversions.extend(quote! {\n            impl From<$(&variant_green)> for $(&green_name) {\n                fn from(value: $(&variant_green)) -> Self {\n                    Self(value.0)\n                }\n            }\n        });\n    }\n    let missing_body = match missing_variant {\n        Some(missing) => quote! {\n            $(&green_name)($(missing.kind)::missing(db).0)\n        },\n        None => quote! {\n            panic!(\"No missing variant.\");\n        },\n    };\n    quote! {\n        #[derive(Clone, Debug, Eq, Hash, PartialEq)]\n        pub enum $(&name){\n            $enum_body\n        }\n        #[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\n        pub struct $(&ptr_name)(pub SyntaxStablePtrId);\n        impl $(&ptr_name) {\n            pub fn untyped(&self) -> SyntaxStablePtrId {\n                self.0\n            }\n        }\n        $ptr_conversions\n        $green_conversions\n        #[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\n        pub struct $(&green_name)(pub GreenId);\n        impl TypedSyntaxNode for $(&name){\n            const OPTIONAL_KIND: Option<SyntaxKind> = None;\n            type StablePtr = $(&ptr_name);\n            type Green = $(&green_name);\n            fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n                $missing_body\n            }\n            fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n                let kind = node.kind(db);\n                match kind{\n                    $from_node_body\n                    _ => panic!(\n                        \"Unexpected syntax kind {:?} when constructing {}.\",\n                        kind,\n                        $[str]($[const](&name))),\n                }\n            }\n            fn as_syntax_node(&self) -> SyntaxNode {\n                match self {\n                    $(for v in &variants => $(&name)::$(&v.name)(x) => x.as_syntax_node(),)\n                }\n            }\n            fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n                Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n            }\n            fn stable_ptr(&self) -> Self::StablePtr {\n                $(&ptr_name)(self.as_syntax_node().0.stable_ptr)\n            }\n        }\n    }\n}\n\nfn gen_token_code(name: String) -> rust::Tokens {\n    let green_name = format!(\"{name}Green\");\n    let ptr_name = format!(\"{name}Ptr\");\n\n    quote! {\n        #[derive(Clone, Debug, Eq, Hash, PartialEq)]\n        pub struct $(&name) {\n            node: SyntaxNode,\n        }\n        impl Token for $(&name) {\n            fn new_green(db: &dyn SyntaxGroup, text: SmolStr) -> Self::Green {\n                $(&green_name)(db.intern_green(GreenNode {\n                    kind: SyntaxKind::$(&name),\n                    details: GreenNodeDetails::Token(text),\n                }))\n            }\n            fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n                extract_matches!(db.lookup_intern_green(self.node.0.green).details, GreenNodeDetails::Token)\n            }\n        }\n        #[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\n        pub struct $(&ptr_name)(pub SyntaxStablePtrId);\n        impl $(&ptr_name) {\n            pub fn untyped(&self) -> SyntaxStablePtrId {\n                self.0\n            }\n        }\n        #[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\n        pub struct $(&green_name)(pub GreenId);\n        impl $(&green_name) {\n            pub fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n                extract_matches!(db.lookup_intern_green(self.0).details, GreenNodeDetails::Token)\n            }\n        }\n        impl TypedSyntaxNode for $(&name){\n            const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::$(&name));\n            type StablePtr = $(&ptr_name);\n            type Green = $(&green_name);\n            fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n                $(&green_name)(db.intern_green(GreenNode {\n                    kind: SyntaxKind::TokenMissing,\n                    details: GreenNodeDetails::Token(\"\".into()),\n                }))\n            }\n            fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n                match db.lookup_intern_green(node.0.green).details {\n                    GreenNodeDetails::Token(_) => Self { node },\n                    GreenNodeDetails::Node { .. } => panic!(\n                        \"Expected a token {:?}, not an internal node\",\n                        SyntaxKind::$(&name)\n                    ),\n                }\n            }\n            fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n                Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n            }\n            fn as_syntax_node(&self) -> SyntaxNode {\n                self.node.clone()\n            }\n            fn stable_ptr(&self) -> Self::StablePtr {\n                $(&ptr_name)(self.node.0.stable_ptr)\n            }\n        }\n    }\n}\n\nfn gen_struct_code(name: String, members: Vec<Member>, is_terminal: bool) -> rust::Tokens {\n    let green_name = format!(\"{name}Green\");\n    let mut body = rust::Tokens::new();\n    let mut field_indices = quote! {};\n    let mut args = quote! {};\n    let mut params = quote! {};\n    let mut arg_missings = quote! {};\n    let mut ptr_getters = quote! {};\n    let mut key_field_index: usize = 0;\n    for (i, Member { name, kind, key }) in members.iter().enumerate() {\n        let index_name = format!(\"INDEX_{}\", name.to_uppercase());\n        field_indices.extend(quote! {\n            pub const $index_name : usize = $i;\n        });\n        let key_name_green = format!(\"{name}_green\");\n        args.extend(quote! {$name.0,});\n        // TODO(spapini): Validate that children SyntaxKinds are as expected.\n\n        let child_green = format!(\"{kind}Green\");\n        params.extend(quote! {$name: $(&child_green),});\n        body.extend(quote! {\n            pub fn $name(&self, db: &dyn SyntaxGroup) -> $kind {\n                $kind::from_syntax_node(db, self.children[$i].clone())\n            }\n        });\n        arg_missings.extend(quote! {$kind::missing(db).0,});\n\n        if *key {\n            ptr_getters.extend(quote! {\n                pub fn $(&key_name_green)(self, db: &dyn SyntaxGroup) -> $(&child_green) {\n                    let ptr = db.lookup_intern_stable_ptr(self.0);\n                    if let SyntaxStablePtr::Child { key_fields, .. } = ptr {\n                        $(&child_green)(key_fields[$key_field_index])\n                    } else {\n                        panic!(\"Unexpected key field query on root.\");\n                    }\n                }\n            });\n            key_field_index += 1;\n        }\n    }\n    let ptr_name = format!(\"{name}Ptr\");\n    let new_green_impl = if is_terminal {\n        let token_name = name.replace(\"Terminal\", \"Token\");\n        quote! {\n            impl Terminal for $(&name) {\n                const KIND: SyntaxKind = SyntaxKind::$(&name);\n                type TokenType = $(&token_name);\n                fn new_green(\n                    db: &dyn SyntaxGroup,\n                    leading_trivia: TriviaGreen,\n                    token: <<$(&name) as Terminal>::TokenType as TypedSyntaxNode>::Green,\n                    trailing_trivia: TriviaGreen\n                ) -> Self::Green {\n                    let children: Vec<GreenId> = vec![$args];\n                    let width = children.iter().copied().map(|id|\n                        db.lookup_intern_green(id).width()).sum();\n                    $(&green_name)(db.intern_green(GreenNode {\n                        kind: SyntaxKind::$(&name),\n                        details: GreenNodeDetails::Node { children, width },\n                    }))\n                }\n                fn text(&self, db: &dyn SyntaxGroup) -> SmolStr {\n                    self.token(db).text(db)\n                }\n            }\n        }\n    } else {\n        quote! {\n            impl $(&name) {\n                $field_indices\n                pub fn new_green(db: &dyn SyntaxGroup, $params) -> $(&green_name) {\n                    let children: Vec<GreenId> = vec![$args];\n                    let width = children.iter().copied().map(|id|\n                        db.lookup_intern_green(id).width()).sum();\n                    $(&green_name)(db.intern_green(GreenNode {\n                        kind: SyntaxKind::$(&name),\n                        details: GreenNodeDetails::Node { children, width },\n                    }))\n                }\n            }\n        }\n    };\n    quote! {\n        #[derive(Clone, Debug, Eq, Hash, PartialEq)]\n        pub struct $(&name){\n            node: SyntaxNode,\n            children: Vec<SyntaxNode>,\n        }\n        $new_green_impl\n        impl $(&name) {\n            $body\n        }\n        #[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\n        pub struct $(&ptr_name)(pub SyntaxStablePtrId);\n        impl $(&ptr_name) {\n            $ptr_getters\n\n            pub fn untyped(&self) -> SyntaxStablePtrId {\n                self.0\n            }\n        }\n        #[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\n        pub struct $(&green_name)(pub GreenId);\n        impl TypedSyntaxNode for $(&name){\n            const OPTIONAL_KIND: Option<SyntaxKind> = Some(SyntaxKind::$(&name));\n            type StablePtr = $(&ptr_name);\n            type Green = $(&green_name);\n            fn missing(db: &dyn SyntaxGroup) -> Self::Green {\n                // Note: A missing syntax element should result in an internal green node\n                // of width 0, with as much structure as possible.\n                $(&green_name)(db.intern_green(GreenNode {\n                    kind: SyntaxKind::$(&name),\n                    details: GreenNodeDetails::Node {\n                        children: vec![$arg_missings],\n                        width: TextWidth::default(),\n                    },\n                }))\n            }\n            fn from_syntax_node(db: &dyn SyntaxGroup, node: SyntaxNode) -> Self {\n                let kind = node.kind(db);\n                assert_eq!(kind, SyntaxKind::$(&name), \"Unexpected SyntaxKind {:?}. Expected {:?}.\", kind, SyntaxKind::$(&name));\n                let children = node.children(db).collect();\n                Self { node, children }\n            }\n            fn from_ptr(db: &dyn SyntaxGroup, root: &SyntaxFile, ptr: Self::StablePtr) -> Self {\n                Self::from_syntax_node(db, root.as_syntax_node().lookup_ptr(db, ptr.0))\n            }\n            fn as_syntax_node(&self) -> SyntaxNode {\n                self.node.clone()\n            }\n            fn stable_ptr(&self) -> Self::StablePtr {\n                $(&ptr_name)(self.node.0.stable_ptr)\n            }\n        }\n    }\n}\n\n/// Appends the given rust token to the given list\nfn append_rust_token(list: &mut rust::Tokens, name: &str) {\n    if list.is_empty() {\n        list.append(format!(\"SyntaxKind::{name}\"));\n    } else {\n        list.append(format!(\"| SyntaxKind::{name}\"));\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::fs;\n\nuse test_log::test;\n\nuse crate::generator::{get_codes, project_root};\n\n#[test]\nfn sourcegen_ast() {\n    for (suffix, code) in get_codes() {\n        let filename = project_root().join(suffix);\n        if fs::read_to_string(filename).unwrap() != code {\n            panic!(\"Some files are not up to date. Please run `cargo run --bin generate-syntax`\");\n        }\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Code generation for the `syntax` crate.\n\npub mod cairo_spec;\npub mod generator;\n#[cfg(test)]\nmod golden_test;\npub mod spec;\n",
    "metadata": {}
  },
  {
    "pageContent": "// Representation of the AST specifications.\npub struct Node {\n    pub name: String,\n    pub kind: NodeKind,\n}\n#[derive(Clone)]\npub enum NodeKind {\n    Enum { variants: Vec<Variant>, missing_variant: Option<Variant> },\n    Struct { members: Vec<Member> },\n    Terminal { is_keyword: bool, members: Vec<Member> },\n    List { element_type: String },\n    SeparatedList { element_type: String, separator_type: String },\n    Token { is_keyword: bool },\n}\n#[derive(Clone)]\npub struct Member {\n    pub name: String,\n    pub kind: String,\n    /// Whether this member serves as a key in the stable pointer of this syntax node.\n    /// See `syntax::node::stable_ptr`.\n    pub key: bool,\n}\n#[derive(Clone)]\npub struct Variant {\n    pub name: String,\n    pub kind: String,\n}\n\n// Helpers to build AST specifications.\n\n/// Builds spec for a struct node.\npub struct StructBuilder {\n    name: String,\n    members: Vec<Member>,\n    is_terminal: bool,\n    is_keyword: bool,\n}\nimpl StructBuilder {\n    pub fn new(name: &str) -> Self {\n        Self { name: name.into(), members: Vec::new(), is_terminal: false, is_keyword: false }\n    }\n    pub fn new_terminal(name: &str, is_keyword: bool) -> Self {\n        Self { name: name.into(), members: Vec::new(), is_terminal: true, is_keyword }\n    }\n    pub fn node(mut self, field: &str, kind: &str) -> StructBuilder {\n        self.members.push(Member { name: field.into(), kind: kind.into(), key: false });\n        self\n    }\n    pub fn key_node(mut self, field: &str, kind: &str) -> StructBuilder {\n        self.members.push(Member { name: field.into(), kind: kind.into(), key: true });\n        self\n    }\n    pub fn build(self) -> Node {\n        Node {\n            name: self.name,\n            kind: if self.is_terminal {\n                NodeKind::Terminal { is_keyword: self.is_keyword, members: self.members }\n            } else {\n                NodeKind::Struct { members: self.members }\n            },\n        }\n    }\n}\n/// Builds spec for an enum node.\npub struct EnumBuilder {\n    name: String,\n    variants: Vec<Variant>,\n    missing_variant: Option<Variant>,\n}\nimpl EnumBuilder {\n    pub fn new(name: &str) -> Self {\n        Self { name: name.into(), variants: Vec::new(), missing_variant: None }\n    }\n    pub fn missing(mut self, name: &str) -> EnumBuilder {\n        let kind_name = self.name.clone() + name;\n        self.missing_variant = Some(Variant { name: name.to_string(), kind: kind_name });\n        self\n    }\n    pub fn node(self, name: &str) -> EnumBuilder {\n        let kind_name = self.name.clone() + name;\n        self.node_with_explicit_kind(name, &kind_name)\n    }\n    pub fn node_with_explicit_kind(mut self, name: &str, kind: &str) -> EnumBuilder {\n        self.variants.push(Variant { name: name.to_string(), kind: kind.to_string() });\n        self\n    }\n    pub fn build(mut self) -> Node {\n        if let Some(member) = &self.missing_variant {\n            self.variants.push(member.clone());\n        }\n        Node {\n            name: self.name,\n            kind: NodeKind::Enum { variants: self.variants, missing_variant: self.missing_variant },\n        }\n    }\n}\n\n/// A tool to aggregate/gather nodes in various forms and eventually emit them as a vector.\n#[derive(Default)]\npub struct NodesAggregator {\n    nodes: Vec<Node>,\n}\nimpl NodesAggregator {\n    /// Gets all the aggregated nodes.\n    pub fn get(self) -> Vec<Node> {\n        self.nodes\n    }\n\n    /// Adds a struct node.\n    pub fn add_struct(mut self, builder: StructBuilder) -> Self {\n        self.nodes.push(builder.build());\n        self\n    }\n\n    /// Adds an enum node.\n    pub fn add_enum(mut self, builder: EnumBuilder) -> Self {\n        self.nodes.push(builder.build());\n        self\n    }\n\n    /// Adds a node for a list of syntax elements.\n    pub fn add_list(mut self, name: &str, element_type: &str) -> Self {\n        self.nodes.push(Node {\n            name: name.into(),\n            kind: NodeKind::List { element_type: element_type.into() },\n        });\n        self\n    }\n\n    /// Adds a node for a list of syntax elements separated by a terminal.\n    pub fn add_separated_list(\n        mut self,\n        name: &str,\n        element_type: &str,\n        separator_type: &str,\n    ) -> Self {\n        self.nodes.push(Node {\n            name: name.into(),\n            kind: NodeKind::SeparatedList {\n                element_type: element_type.into(),\n                separator_type: separator_type.into(),\n            },\n        });\n        self\n    }\n\n    /// Adds a non-keyword node for a token node (similar to an empty struct).\n    pub fn add_token(mut self, pure_name: &str) -> Self {\n        self.nodes.push(Node {\n            name: format!(\"Token{pure_name}\"),\n            kind: NodeKind::Token { is_keyword: false },\n        });\n        self\n    }\n\n    /// Adds a keyword node for a token node (similar to an empty struct).\n    pub fn add_keyword_token(mut self, pure_name: &str) -> Self {\n        self.nodes.push(Node {\n            name: format!(\"Token{pure_name}\"),\n            kind: NodeKind::Token { is_keyword: true },\n        });\n        self\n    }\n\n    /// Adds a node for a token node (similar to an empty struct).\n    pub fn add_terminal(self, pure_name: &str, is_keyword: bool) -> Self {\n        self.add_struct(\n            StructBuilder::new_terminal(format!(\"Terminal{pure_name}\").as_str(), is_keyword)\n                .node(\"leading_trivia\", \"Trivia\")\n                .node(\"token\", format!(\"Token{pure_name}\").as_str())\n                .node(\"trailing_trivia\", \"Trivia\"),\n        )\n    }\n\n    /// Adds a keyword token node and a keyword terminal node of the relevant names. e.g. for\n    /// pure_name=\"Identifier\" it creates TokenIdentifier and TerminalIdentifier.\n    pub fn add_keyword_token_and_terminal(self, pure_name: &str) -> Self {\n        self.add_keyword_token(pure_name).add_terminal(pure_name, true)\n    }\n\n    /// Adds a non-keyword token node and a non-keyword terminal node of the relevant names. e.g.\n    /// for pure_name=\"Identifier\" it creates TokenIdentifier and TerminalIdentifier.\n    pub fn add_token_and_terminal(self, pure_name: &str) -> Self {\n        self.add_token(pure_name).add_terminal(pure_name, false)\n    }\n\n    /// Adds an enum node for an option with 2 variants: empty and non-empty. Creates the empty\n    /// struct to be used for the empty variant. The Type for the non-empty variant is `name`\n    /// and it should exist independently of this call.\n    ///\n    /// For example, for name=TypeClause, creates an enum OptionTypeClause with variants\n    /// Empty(OptionTypeClauseEmpty) and TypeClause(TypeClause), where OptionTypeClauseEmpty is\n    /// created here and TypeClause should exist independently.\n    pub fn add_option(self, name: &str) -> Self {\n        self.add_enum(\n            EnumBuilder::new(format!(\"Option{name}\").as_str())\n                .node(\"Empty\")\n                .node_with_explicit_kind(name, name),\n        )\n        .add_struct(StructBuilder::new(format!(\"Option{name}Empty\").as_str()))\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Compiles and runs a Cairo program.\n\nuse std::collections::HashSet;\nuse std::path::Path;\nuse std::sync::{Arc, Mutex};\n\nuse anyhow::{bail, Context};\nuse cairo_lang_compiler::db::RootDatabase;\nuse cairo_lang_compiler::diagnostics::DiagnosticsReporter;\nuse cairo_lang_compiler::project::setup_project;\nuse cairo_lang_debug::DebugWithDb;\nuse cairo_lang_defs::ids::{FreeFunctionId, FunctionWithBodyId, ModuleItemId};\nuse cairo_lang_diagnostics::ToOption;\nuse cairo_lang_filesystem::ids::CrateId;\nuse cairo_lang_plugins::config::ConfigPlugin;\nuse cairo_lang_plugins::derive::DerivePlugin;\nuse cairo_lang_plugins::panicable::PanicablePlugin;\nuse cairo_lang_runner::short_string::as_cairo_short_string;\nuse cairo_lang_runner::{RunResultValue, SierraCasmRunner};\nuse cairo_lang_semantic::db::SemanticGroup;\nuse cairo_lang_semantic::items::functions::GenericFunctionId;\nuse cairo_lang_semantic::plugin::SemanticPlugin;\nuse cairo_lang_semantic::{ConcreteFunction, ConcreteFunctionWithBodyId, FunctionLongId};\nuse cairo_lang_sierra_generator::db::SierraGenGroup;\nuse cairo_lang_sierra_generator::replace_ids::replace_sierra_ids_in_program;\nuse cairo_lang_starknet::plugin::StarkNetPlugin;\nuse clap::Parser;\nuse colored::Colorize;\nuse itertools::Itertools;\nuse plugin::TestPlugin;\nuse rayon::prelude::{IntoParallelIterator, ParallelIterator};\nuse test_config::{try_extract_test_config, TestConfig};\n\nuse crate::test_config::{PanicExpectation, TestExpectation};\n\nmod plugin;\nmod test_config;\n\n/// Command line args parser.\n/// Exits with 0/1 if the input is formatted correctly/incorrectly.\n#[derive(Parser, Debug)]\n#[clap(version, verbatim_doc_comment)]\nstruct Args {\n    /// The path to compile and run its tests.\n    #[arg(short, long)]\n    path: String,\n    /// The filter for the tests, running only tests containing the filter string.\n    #[arg(short, long, default_value_t = String::default())]\n    filter: String,\n    /// Should we run ignored tests as well.\n    #[arg(long, default_value_t = false)]\n    include_ignored: bool,\n    /// Should we run only the ignored tests.\n    #[arg(long, default_value_t = false)]\n    ignored: bool,\n    /// Should we add the starknet plugin to run the tests.\n    #[arg(long, default_value_t = false)]\n    starknet: bool,\n}\n\n/// The status of a ran test.\nenum TestStatus {\n    Success,\n    Fail(RunResultValue),\n    Ignore,\n}\n\nfn main() -> anyhow::Result<()> {\n    let args = Args::parse();\n\n    // TODO(orizi): Use `get_default_plugins` and just update the config plugin.\n    let mut plugins: Vec<Arc<dyn SemanticPlugin>> = vec![\n        Arc::new(DerivePlugin {}),\n        Arc::new(PanicablePlugin {}),\n        Arc::new(ConfigPlugin { configs: HashSet::from([\"test\".to_string()]) }),\n        Arc::new(TestPlugin {}),\n    ];\n    if args.starknet {\n        plugins.push(Arc::new(StarkNetPlugin {}));\n    }\n    let db = &mut RootDatabase::builder().with_plugins(plugins).detect_corelib().build()?;\n\n    let main_crate_ids = setup_project(db, Path::new(&args.path))?;\n\n    if DiagnosticsReporter::stderr().check(db) {\n        bail!(\"failed to compile: {}\", args.path);\n    }\n    let all_tests = find_all_tests(db, main_crate_ids);\n    let sierra_program = db\n        .get_sierra_program_for_functions(\n            all_tests\n                .iter()\n                .flat_map(|(func_id, _cfg)| {\n                    ConcreteFunctionWithBodyId::from_no_generics_free(db, *func_id)\n                })\n                .collect(),\n        )\n        .to_option()\n        .with_context(|| \"Compilation failed without any diagnostics.\")?;\n    let sierra_program = replace_sierra_ids_in_program(db, &sierra_program);\n    let total_tests_count = all_tests.len();\n    let named_tests = all_tests\n        .into_iter()\n        .map(|(func_id, mut test)| {\n            // Un-ignoring all the tests in `include-ignored` mode.\n            if args.include_ignored {\n                test.ignored = false;\n            }\n            (\n                format!(\n                    \"{:?}\",\n                    FunctionLongId {\n                        function: ConcreteFunction {\n                            generic_function: GenericFunctionId::Free(func_id),\n                            generic_args: vec![]\n                        }\n                    }\n                    .debug(db)\n                ),\n                test,\n            )\n        })\n        .filter(|(name, _)| name.contains(&args.filter))\n        // Filtering unignored tests in `ignored` mode.\n        .filter(|(_, test)| !args.ignored || test.ignored)\n        .collect_vec();\n    let filtered_out = total_tests_count - named_tests.len();\n    let TestsSummary { passed, failed, ignored, failed_run_results } =\n        run_tests(named_tests, sierra_program)?;\n    if failed.is_empty() {\n        println!(\n            \"test result: {}. {} passed; {} failed; {} ignored; {filtered_out} filtered out;\",\n            \"ok\".bright_green(),\n            passed.len(),\n            failed.len(),\n            ignored.len()\n        );\n        Ok(())\n    } else {\n        println!(\"failures:\");\n        for (failure, run_result) in failed.iter().zip_eq(failed_run_results) {\n            print!(\"   {failure} - \");\n            match run_result {\n                RunResultValue::Success(_) => {\n                    println!(\"expected panic but finished successfully.\");\n                }\n                RunResultValue::Panic(values) => {\n                    print!(\"panicked with [\");\n                    for value in &values {\n                        match as_cairo_short_string(value) {\n                            Some(as_string) => print!(\"{value} ('{as_string}'), \"),\n                            None => print!(\"{value}, \"),\n                        }\n                    }\n                    println!(\"].\")\n                }\n            }\n        }\n        println!();\n        bail!(\n            \"test result: {}. {} passed; {} failed; {} ignored\",\n            \"FAILED\".bright_red(),\n            passed.len(),\n            failed.len(),\n            ignored.len()\n        );\n    }\n}\n\n/// Summary data of the ran tests.\nstruct TestsSummary {\n    passed: Vec<String>,\n    failed: Vec<String>,\n    ignored: Vec<String>,\n    failed_run_results: Vec<RunResultValue>,\n}\n\n/// Runs the tests and process the results for a summary.\nfn run_tests(\n    named_tests: Vec<(String, TestConfig)>,\n    sierra_program: cairo_lang_sierra::program::Program,\n) -> anyhow::Result<TestsSummary> {\n    let runner =\n        SierraCasmRunner::new(sierra_program, true).with_context(|| \"Failed setting up runner.\")?;\n    println!(\"running {} tests\", named_tests.len());\n    let wrapped_summary = Mutex::new(Ok(TestsSummary {\n        passed: vec![],\n        failed: vec![],\n        ignored: vec![],\n        failed_run_results: vec![],\n    }));\n    named_tests\n        .into_par_iter()\n        .map(|(name, test)| -> anyhow::Result<(String, TestStatus)> {\n            if test.ignored {\n                return Ok((name, TestStatus::Ignore));\n            }\n            let result = runner\n                .run_function(name.as_str(), &[], test.available_gas)\n                .with_context(|| format!(\"Failed to run the function `{}`.\", name.as_str()))?;\n            Ok((\n                name,\n                match &result.value {\n                    RunResultValue::Success(_) => match test.expectation {\n                        TestExpectation::Success => TestStatus::Success,\n                        TestExpectation::Panics(_) => TestStatus::Fail(result.value),\n                    },\n                    RunResultValue::Panic(value) => match test.expectation {\n                        TestExpectation::Success => TestStatus::Fail(result.value),\n                        TestExpectation::Panics(panic_expectation) => match panic_expectation {\n                            PanicExpectation::Exact(expected) if value != &expected => {\n                                TestStatus::Fail(result.value)\n                            }\n                            _ => TestStatus::Success,\n                        },\n                    },\n                },\n            ))\n        })\n        .for_each(|r| {\n            let mut wrapped_summary = wrapped_summary.lock().unwrap();\n            if wrapped_summary.is_err() {\n                return;\n            }\n            let (name, status) = match r {\n                Ok((name, status)) => (name, status),\n                Err(err) => {\n                    *wrapped_summary = Err(err);\n                    return;\n                }\n            };\n            let summary = wrapped_summary.as_mut().unwrap();\n            let (res_type, status_str) = match status {\n                TestStatus::Success => (&mut summary.passed, \"ok\".bright_green()),\n                TestStatus::Fail(run_result) => {\n                    summary.failed_run_results.push(run_result);\n                    (&mut summary.failed, \"fail\".bright_red())\n                }\n                TestStatus::Ignore => (&mut summary.ignored, \"ignored\".bright_yellow()),\n            };\n            println!(\"test {name} ... {status_str}\",);\n            res_type.push(name);\n        });\n    wrapped_summary.into_inner().unwrap()\n}\n\n/// Finds the tests in the requested crates.\nfn find_all_tests(\n    db: &dyn SemanticGroup,\n    main_crates: Vec<CrateId>,\n) -> Vec<(FreeFunctionId, TestConfig)> {\n    let mut tests = vec![];\n    for crate_id in main_crates {\n        let modules = db.crate_modules(crate_id);\n        for module_id in modules.iter() {\n            let Ok(module_items) = db.module_items(*module_id) else {\n                continue;\n            };\n            tests.extend(\n                module_items.iter().filter_map(|item| {\n                    let ModuleItemId::FreeFunction(func_id) = item else { return None };\n                    let Ok(attrs) = db.function_with_body_attributes(FunctionWithBodyId::Free(*func_id)) else { return None };\n                    Some((*func_id, try_extract_test_config(db.upcast(), attrs).unwrap()?))\n                }),\n            );\n        }\n    }\n    tests\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::sync::Arc;\n\nuse cairo_lang_defs::plugin::{MacroPlugin, PluginResult};\nuse cairo_lang_semantic::items::attribute::ast_attributes_to_semantic;\nuse cairo_lang_semantic::plugin::{AsDynMacroPlugin, SemanticPlugin};\nuse cairo_lang_syntax::node::ast;\nuse cairo_lang_syntax::node::db::SyntaxGroup;\n\nuse crate::test_config::try_extract_test_config;\n\n/// Plugin to create diagnostics for tests attributes.\n#[derive(Debug)]\npub struct TestPlugin;\n\nimpl MacroPlugin for TestPlugin {\n    fn generate_code(&self, db: &dyn SyntaxGroup, item_ast: ast::Item) -> PluginResult {\n        PluginResult {\n            code: None,\n            diagnostics: if let ast::Item::FreeFunction(free_func_ast) = item_ast {\n                try_extract_test_config(\n                    db,\n                    ast_attributes_to_semantic(db, free_func_ast.attributes(db)),\n                )\n                .err()\n            } else {\n                None\n            }\n            .unwrap_or_default(),\n            remove_original_item: false,\n        }\n    }\n}\nimpl AsDynMacroPlugin for TestPlugin {\n    fn as_dyn_macro_plugin<'a>(self: Arc<Self>) -> Arc<dyn MacroPlugin + 'a>\n    where\n        Self: 'a,\n    {\n        self\n    }\n}\nimpl SemanticPlugin for TestPlugin {}\n",
    "metadata": {}
  },
  {
    "pageContent": "use cairo_felt::Felt as Felt252;\nuse cairo_lang_defs::plugin::PluginDiagnostic;\nuse cairo_lang_semantic::items::attribute::Attribute;\nuse cairo_lang_semantic::literals::LiteralLongId;\nuse cairo_lang_syntax::node::db::SyntaxGroup;\nuse cairo_lang_syntax::node::{ast, Terminal, Token, TypedSyntaxNode};\nuse cairo_lang_utils::OptionHelper;\nuse unescaper::unescape;\n\n/// Expectation for a panic case.\npub enum PanicExpectation {\n    /// Accept any panic value.\n    Any,\n    /// Accept only this specific vector of panics.\n    Exact(Vec<Felt252>),\n}\n\n/// Expectation for a result of a test.\npub enum TestExpectation {\n    /// Running the test should not panic.\n    Success,\n    /// Running the test should result in a panic.\n    Panics(PanicExpectation),\n}\n\n/// The configuration for running a single test.\npub struct TestConfig {\n    /// The amount of gas the test requested.\n    pub available_gas: Option<usize>,\n    /// The expected result of the run.\n    pub expectation: TestExpectation,\n    /// Should the test be ignored.\n    pub ignored: bool,\n}\n\n/// Extracts the configuration of a tests from attributes, or returns the diagnostics if the\n/// attributes are set illegally.\npub fn try_extract_test_config(\n    db: &dyn SyntaxGroup,\n    attrs: Vec<Attribute>,\n) -> Result<Option<TestConfig>, Vec<PluginDiagnostic>> {\n    let test_attr = attrs.iter().find(|attr| attr.id.as_str() == \"test\");\n    let ignore_attr = attrs.iter().find(|attr| attr.id.as_str() == \"ignore\");\n    let available_gas_attr = attrs.iter().find(|attr| attr.id.as_str() == \"available_gas\");\n    let should_panic_attr = attrs.iter().find(|attr| attr.id.as_str() == \"should_panic\");\n    let mut diagnostics = vec![];\n    if let Some(attr) = test_attr {\n        if !attr.args.is_empty() {\n            diagnostics.push(PluginDiagnostic {\n                stable_ptr: attr.id_stable_ptr.untyped(),\n                message: \"Attribute should not have arguments.\".into(),\n            });\n        }\n    } else {\n        for attr in [ignore_attr, available_gas_attr, should_panic_attr].into_iter().flatten() {\n            diagnostics.push(PluginDiagnostic {\n                stable_ptr: attr.id_stable_ptr.untyped(),\n                message: \"Attribute should only appear on tests.\".into(),\n            });\n        }\n    }\n    let ignored = if let Some(attr) = ignore_attr {\n        if !attr.args.is_empty() {\n            diagnostics.push(PluginDiagnostic {\n                stable_ptr: attr.id_stable_ptr.untyped(),\n                message: \"Attribute should not have arguments.\".into(),\n            });\n        }\n        true\n    } else {\n        false\n    };\n    let available_gas = if let Some(attr) = available_gas_attr {\n        if let [ast::Expr::Literal(literal)] = &attr.args[..] {\n            literal.token(db).text(db).parse::<usize>().ok()\n        } else {\n            diagnostics.push(PluginDiagnostic {\n                stable_ptr: attr.id_stable_ptr.untyped(),\n                message: \"Attribute should have a single value argument.\".into(),\n            });\n            None\n        }\n    } else {\n        None\n    };\n    let (should_panic, expected_panic_value) = if let Some(attr) = should_panic_attr {\n        if attr.args.is_empty() {\n            (true, None)\n        } else {\n            (\n                true,\n                extract_panic_values(db, attr).on_none(|| {\n                    diagnostics.push(PluginDiagnostic {\n                        stable_ptr: attr.args_stable_ptr.untyped(),\n                        message: \"Expected panic must be of the form `expected = <tuple of \\\n                                  felt252s>`.\"\n                            .into(),\n                    });\n                }),\n            )\n        }\n    } else {\n        (false, None)\n    };\n    if !diagnostics.is_empty() {\n        return Err(diagnostics);\n    }\n    Ok(if test_attr.is_none() {\n        None\n    } else {\n        Some(TestConfig {\n            available_gas,\n            expectation: if should_panic {\n                TestExpectation::Panics(if let Some(values) = expected_panic_value {\n                    PanicExpectation::Exact(values)\n                } else {\n                    PanicExpectation::Any\n                })\n            } else {\n                TestExpectation::Success\n            },\n            ignored,\n        })\n    })\n}\n\n/// Tries to extract the relevant expected panic values.\nfn extract_panic_values(db: &dyn SyntaxGroup, attr: &Attribute) -> Option<Vec<Felt252>> {\n    let [ast::Expr::Binary(binary)] = &attr.args[..] else { return None; };\n    if !matches!(binary.op(db), ast::BinaryOperator::Eq(_)) {\n        return None;\n    }\n    if binary.lhs(db).as_syntax_node().get_text_without_trivia(db) != \"expected\" {\n        return None;\n    }\n    let ast::Expr::Tuple(panics) = binary.rhs(db) else { return None };\n    panics\n        .expressions(db)\n        .elements(db)\n        .into_iter()\n        .map(|value| match value {\n            ast::Expr::Literal(literal) => {\n                Felt252::try_from(LiteralLongId::try_from(literal.token(db).text(db)).ok()?.value)\n                    .ok()\n            }\n            ast::Expr::ShortString(short_string_syntax) => {\n                let text = short_string_syntax.text(db);\n                let (literal, _) = text[1..].rsplit_once('\\'')?;\n                let unescaped_literal = unescape(literal).ok()?;\n                Some(Felt252::from_bytes_be(unescaped_literal.as_bytes()))\n            }\n            _ => None,\n        })\n        .collect::<Option<Vec<_>>>()\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "pub mod parse_test_file;\nuse std::fs;\nuse std::path::Path;\n\npub use parse_test_file::parse_test_file;\n\n/// Returns the content of the relevant test file.\nfn get_expected_contents(path: &Path) -> String {\n    fs::read_to_string(path).unwrap_or_else(|_| panic!(\"Could not read file: '{path:?}'\"))\n}\n\n/// Overrides the test file data.\nfn set_contents(path: &Path, content: String) {\n    fs::write(path, content).unwrap_or_else(|_| panic!(\"Could not write file: '{path:?}'\"));\n}\n\n/// Compares content to examples content, or overrides it if the `CAIRO_FIX_TESTS` environment\n/// value is set to `1`.\npub fn compare_contents_or_fix_with_path(path: &Path, content: String) {\n    let is_fix_mode = std::env::var(\"CAIRO_FIX_TESTS\") == Ok(\"1\".into());\n    if is_fix_mode {\n        set_contents(path, content);\n    } else {\n        pretty_assertions::assert_eq!(content, get_expected_contents(path));\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "#[cfg(test)]\n#[path = \"parse_test_file_test.rs\"]\nmod test;\nuse std::fs;\nuse std::io::{self, BufRead};\nuse std::path::Path;\n\nuse cairo_lang_utils::ordered_hash_map::OrderedHashMap;\nuse cairo_lang_utils::ResultHelper;\n\nconst TAG_PREFIX: &str = \"//! > \";\nconst TEST_SEPARATOR: &str =\n    \"==========================================================================\";\n\n#[derive(Default)]\nstruct Tag {\n    name: String,\n    content: String,\n}\n\n/// Represents a single test from the test file.\n#[derive(Clone)]\npub struct Test {\n    pub attributes: OrderedHashMap<String, String>,\n    pub line_num: usize,\n}\n\n#[derive(Default)]\nstruct TestBuilder {\n    tests: OrderedHashMap<String, Test>,\n    current_test: Option<Test>,\n    current_test_name: Option<String>,\n    current_tag: Option<Tag>,\n}\n\npub fn parse_test_file(filename: &Path) -> io::Result<OrderedHashMap<String, Test>> {\n    let file = fs::File::open(filename).on_err(|_| log::error!(\"File not found: {filename:?}\"))?;\n    let mut lines = io::BufReader::new(file).lines();\n    let mut builder = TestBuilder::default();\n    let mut line_num: usize = 0;\n    while let Some(Ok(line)) = lines.next() {\n        line_num += 1;\n        if let Some(line) = line.strip_prefix(TAG_PREFIX) {\n            if builder.current_test_name.is_none() {\n                builder.set_test_name(line.into(), line_num);\n            } else if line.starts_with(\"===\") {\n                // Separate tests.\n                assert_eq!(line, TEST_SEPARATOR, \"Wrong test separator on line {line_num}.\");\n                builder.new_test()\n            } else {\n                builder.open_tag(line.into());\n            }\n        } else {\n            builder.add_content_line(line);\n        }\n    }\n    Ok(builder.finalize())\n}\n\npub fn dump_to_test_file(\n    tests: OrderedHashMap<String, Test>,\n    filename: &str,\n) -> Result<(), std::io::Error> {\n    let mut test_strings = Vec::new();\n    for (test_name, test) in tests {\n        let mut tag_strings = vec![TAG_PREFIX.to_string() + &test_name];\n        for (tag, content) in test.attributes {\n            tag_strings.push(\n                TAG_PREFIX.to_string()\n                    + &tag\n                    + if content.is_empty() { \"\" } else { \"\\n\" }\n                    + &content,\n            );\n        }\n        test_strings.push(tag_strings.join(\"\\n\\n\"));\n    }\n    fs::write(\n        filename,\n        test_strings.join(&(\"\\n\\n\".to_string() + TAG_PREFIX + TEST_SEPARATOR + \"\\n\\n\")) + \"\\n\",\n    )\n}\n\nimpl TestBuilder {\n    /// Closes a tag if one is open, otherwise does nothing.\n    fn close_open_tag(&mut self) {\n        if let Some(tag) = &mut self.current_tag {\n            let attributes = &mut self.current_test.as_mut().unwrap().attributes;\n            assert!(\n                !attributes.contains_key(&tag.name),\n                \"Duplicate tag '{}' found in test (test name: {}).\",\n                tag.name,\n                self.current_test_name.as_ref().unwrap_or(&\"<unknown>\".into())\n            );\n            attributes.insert(std::mem::take(&mut tag.name), tag.content.trim().to_string());\n            self.current_tag = None;\n        }\n    }\n\n    fn open_tag(&mut self, line: String) {\n        self.close_open_tag();\n        self.current_tag = Some(Tag { name: line, content: \"\".into() });\n    }\n\n    fn set_test_name(&mut self, line: String, line_num: usize) {\n        self.current_test_name = Some(line);\n        self.current_test = Some(Test { attributes: OrderedHashMap::default(), line_num });\n    }\n\n    fn add_content_line(&mut self, line: String) {\n        if let Some(tag) = &mut self.current_tag {\n            if !tag.content.is_empty() {\n                tag.content += \"\\n\"\n            }\n            tag.content += &line;\n        } else {\n            // Only allow empty lines outside tags.\n            assert!(line.is_empty(), \"No tag found for content line: '{line}'.\");\n        }\n    }\n\n    fn new_test(&mut self) {\n        self.close_open_tag();\n        let name = self.current_test_name.as_ref().expect(\"No name found for test.\");\n        let old_test =\n            self.tests.insert(name.clone(), std::mem::take(&mut self.current_test).unwrap());\n        assert!(old_test.is_none(), \"Found two tests named {name}.\");\n        self.current_test_name = None;\n        self.current_tag = None;\n    }\n\n    fn finalize(&mut self) -> OrderedHashMap<String, Test> {\n        self.new_test();\n        std::mem::take(&mut self.tests)\n    }\n}\n\n/// Trait for running a parsed test file.\npub trait TestFileRunner {\n    /// Reads tags from the input map, and returns the output map, that should match the expected\n    /// outputs.\n    fn run(&mut self, inputs: &OrderedHashMap<String, String>) -> OrderedHashMap<String, String>;\n}\n\n/// Creates a test that reads test files for a given function.\n/// test_name - the name of the test.\n/// filenames - a vector of tests files the test applies to.\n/// runner - the struct implementing `TestFileRunner + Default`.\n///\n/// The structure of the file must be of the following form:\n/// ```text\n/// //! > test description\n///\n/// //! > test_runner_name\n/// TestToUpperRunner\n///\n/// //! > input1\n/// hello\n///\n/// //! > input2\n/// world\n///\n/// //! > expected_output1\n/// HELLO\n///\n/// //! > expected_output2\n/// WORLD\n///\n/// //! > ==========================================================================\n///\n/// <another test>\n/// ```\n///\n/// The call to the macro looks like:\n/// ```ignore\n/// test_file_test_with_runner!(\n///     test_suite_name,\n///     \"path/to/test/dir\",\n///     {\n///         test_name1: \"test_file1\",\n///         test_name2: \"test_file2\",\n///     },\n///     TestToUpperRunner\n/// );\n/// ```\n#[macro_export]\nmacro_rules! test_file_test_with_runner {\n    ($suite:ident, $base_dir:expr, { $($test_name:ident : $test_file:expr),* $(,)? }, $runner:ident) => {\n        mod $suite {\n            use super::*;\n        $(\n            #[test_log::test]\n            fn $test_name() -> Result<(), std::io::Error> {\n                let path: std::path::PathBuf = [env!(\"CARGO_MANIFEST_DIR\"), $base_dir, $test_file].iter().collect();\n                cairo_lang_test_utils::parse_test_file::run_test_file(\n                    path.as_path(),\n                    stringify!($runner),\n                    &mut $runner::default(),\n                )\n            }\n        )*\n        }\n    };\n}\n\n/// Simple runner wrapping a test function.\npub struct SimpleRunner {\n    pub func: fn(&OrderedHashMap<String, String>) -> OrderedHashMap<String, String>,\n}\nimpl TestFileRunner for SimpleRunner {\n    fn run(&mut self, inputs: &OrderedHashMap<String, String>) -> OrderedHashMap<String, String> {\n        (self.func)(inputs)\n    }\n}\n\n/// Creates a test that reads test files for a given function.\n/// test_name - the name of the test.\n/// filenames - a vector of tests files the test applies to.\n/// func - the function to be applied on the test params to generate the tested result.\n///\n/// The signature of `func` should be of the form:\n/// ```ignore\n/// fn func(\n///     inputs: &OrderedHashMap<String, String>\n/// ) -> OrderedHashMap<String, String>;\n/// ```\n/// And `func` can read the tags from the file from the input map. It should return the expected\n/// outputs with the same tags as the file, in the output map.\n///\n/// The structure of the file must be of the following form:\n/// ```text\n/// //! > test description\n///\n/// //! > test_runner_name\n/// test_to_upper\n///\n/// //! > input1\n/// hello\n///\n/// //! > input2\n/// world\n///\n/// //! > expected_output1\n/// HELLO\n///\n/// //! > expected_output2\n/// WORLD\n///\n/// //! > ==========================================================================\n///\n/// <another test>\n/// ```\n///\n/// The call to the macro looks like:\n/// ```ignore\n/// test_file_test!(\n///     test_suite_name,\n///     \"path/to/test/dir\",\n///     {\n///         test_name1: \"test_file1\",\n///         test_name2: \"test_file2\",\n///     },\n///     test_to_upper\n/// );\n/// ```\n#[macro_export]\nmacro_rules! test_file_test {\n    ($suite:ident, $base_dir:expr, { $($test_name:ident : $test_file:expr),* $(,)? }, $test_func:ident) => {\n        mod $suite {\n            use super::*;\n        $(\n            #[test_log::test]\n            fn $test_name() -> Result<(), std::io::Error> {\n                let path: std::path::PathBuf = [env!(\"CARGO_MANIFEST_DIR\"), $base_dir, $test_file].iter().collect();\n                cairo_lang_test_utils::parse_test_file::run_test_file(\n                    path.as_path(),\n                    stringify!($test_func),\n                    &mut cairo_lang_test_utils::parse_test_file::SimpleRunner { func: $test_func },\n                )\n            }\n        )*\n        }\n    };\n}\n\n/// Runs a test based on file at `path` named `test_func_name` by running `test_func` on it.\n/// Fixes the test file if the `CAIRO_FIX_TESTS` environment variable is set to `1`.\npub fn run_test_file(\n    path: &Path,\n    runner_name: &str,\n    runner: &mut dyn TestFileRunner,\n) -> Result<(), std::io::Error> {\n    let filename = path.file_name().unwrap().to_str().unwrap();\n    let is_fix_mode = std::env::var(\"CAIRO_FIX_TESTS\") == Ok(\"1\".into());\n    let tests = parse_test_file(path)?;\n    let mut new_tests = OrderedHashMap::<String, Test>::default();\n    for (test_name, test) in tests {\n        log::debug!(r#\"Running test: {runner_name}::{filename}::\"{test_name}\"\"#);\n        let outputs = runner.run(&test.attributes);\n        let line_num = test.line_num;\n        let full_filename = std::fs::canonicalize(path)?;\n        let full_filename_str = full_filename.to_str().unwrap();\n\n        let get_attr = |key: &str| {\n            test.attributes.get(key).unwrap_or_else(|| {\n                panic!(\n                    \"Missing attribute {key} in test '{test_name}'.\\nIn \\\n                     {full_filename_str}:{line_num}\"\n                )\n            })\n        };\n\n        pretty_assertions::assert_eq!(get_attr(\"test_runner_name\"), runner_name);\n\n        if is_fix_mode {\n            let mut new_test = test.clone();\n            for (key, value) in outputs {\n                new_test.attributes.insert(key.to_string(), value.trim().to_string());\n            }\n            new_tests.insert(test_name.to_string(), new_test);\n        } else {\n            for (key, value) in outputs {\n                pretty_assertions::assert_eq!(\n                    value.trim(),\n                    get_attr(&key),\n                    \"Test \\\"{test_name}\\\" failed.\\nIn {full_filename_str}:{line_num}.\\nRerun with \\\n                     CAIRO_FIX_TESTS=1 to fix.\"\n                );\n            }\n        }\n    }\n    if is_fix_mode {\n        dump_to_test_file(new_tests, path.to_str().unwrap())?;\n    }\n    Ok(())\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::path::Path;\n\nuse test_log::test;\n\nuse crate::parse_test_file;\n\n#[test]\nfn test_parse_test_file() -> Result<(), std::io::Error> {\n    let tests = parse_test_file::parse_test_file(Path::new(\"test_data/test_example\"))?;\n    let test1 = &tests[\"Test Example\"];\n    assert_eq!(test1.attributes[\"Expression\"], \"foo\");\n    assert_eq!(test1.attributes[\"Expected\"], \"bar\");\n\n    let test2 = &tests[\"Another Test Example\"];\n    assert_eq!(test2.attributes[\"Expression\"], \"foo\\n//! bar\");\n    assert_eq!(test2.attributes[\"Expected\"], \"baz\");\n    assert_eq!(test2.attributes[\"Empty\"], \"\");\n    Ok(())\n}\n\n#[test]\nfn test_dump_to_test_file() -> Result<(), std::io::Error> {\n    let tests = parse_test_file::parse_test_file(Path::new(\"test_data/test_example\"))?;\n    parse_test_file::dump_to_test_file(tests, \"test_data/test_example_expected\")?;\n    assert_eq!(\n        std::fs::read_to_string(\"test_data/test_example\")?,\n        std::fs::read_to_string(\"test_data/test_example_expected\")?\n    );\n    std::fs::remove_file(\"test_data/test_example_expected\")\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "#[cfg(test)]\n#[path = \"bigint_test.rs\"]\nmod test;\n\nuse std::ops::Neg;\n\nuse num_bigint::{BigInt, BigUint, ToBigInt};\nuse num_traits::{Num, Signed};\nuse serde::ser::Serializer;\nuse serde::{Deserialize, Deserializer, Serialize};\n\n// A wrapper for BigUint that serializes as hex.\n#[derive(Default, Debug, PartialEq, Eq, Serialize, Deserialize)]\n#[serde(transparent)]\npub struct BigUintAsHex {\n    /// A field element that encodes the signature of the called function.\n    #[serde(serialize_with = \"serialize_big_uint\", deserialize_with = \"deserialize_big_uint\")]\n    pub value: BigUint,\n}\n\nfn deserialize_from_str<'a, D>(s: &str) -> Result<BigUint, D::Error>\nwhere\n    D: Deserializer<'a>,\n{\n    match s.strip_prefix(\"0x\") {\n        Some(num_no_prefix) => BigUint::from_str_radix(num_no_prefix, 16)\n            .map_err(|error| serde::de::Error::custom(format!(\"{error}\"))),\n        None => Err(serde::de::Error::custom(format!(\"{s} does not start with `0x` is missing.\"))),\n    }\n}\n\npub fn serialize_big_uint<S>(num: &BigUint, serializer: S) -> Result<S::Ok, S::Error>\nwhere\n    S: Serializer,\n{\n    serializer.serialize_str(&format!(\"{num:#x}\"))\n}\n\npub fn deserialize_big_uint<'a, D>(deserializer: D) -> Result<BigUint, D::Error>\nwhere\n    D: Deserializer<'a>,\n{\n    let s = &String::deserialize(deserializer)?;\n    deserialize_from_str::<D>(s)\n}\n\n// A wrapper for BigInt that serializes as hex.\n#[derive(Default, Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]\n#[serde(transparent)]\npub struct BigIntAsHex {\n    /// A field element that encodes the signature of the called function.\n    #[serde(serialize_with = \"serialize_big_int\", deserialize_with = \"deserialize_big_int\")]\n    pub value: BigInt,\n}\n\nimpl<T: Into<BigInt>> From<T> for BigIntAsHex {\n    fn from(x: T) -> Self {\n        Self { value: x.into() }\n    }\n}\n\npub fn serialize_big_int<S>(num: &BigInt, serializer: S) -> Result<S::Ok, S::Error>\nwhere\n    S: Serializer,\n{\n    serializer.serialize_str(&format!(\n        \"{}{:#x}\",\n        if num.is_negative() { \"-\" } else { \"\" },\n        num.magnitude()\n    ))\n}\n\npub fn deserialize_big_int<'a, D>(deserializer: D) -> Result<BigInt, D::Error>\nwhere\n    D: Deserializer<'a>,\n{\n    let s = &String::deserialize(deserializer)?;\n    match s.strip_prefix('-') {\n        Some(abs_value) => Ok(deserialize_from_str::<D>(abs_value)?.to_bigint().unwrap().neg()),\n        None => Ok(deserialize_from_str::<D>(s)?.to_bigint().unwrap()),\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::ops::Neg;\n\nuse num_bigint::BigInt;\nuse num_traits::Num;\nuse test_case::test_case;\n\nuse crate::bigint::BigIntAsHex;\n\n#[test_case(\"800000000000011000000000000000000000000000000000000000000000001\", true; \"positive\")]\n#[test_case(\"800000000000011000000000000000000000000000000000000000000000001\", false; \"negative\")]\n#[test_case(\"0\", false; \"zero\")]\nfn test_bigint_serde(s: &str, is_negative: bool) {\n    let mut num = BigIntAsHex { value: BigInt::from_str_radix(s, 16).unwrap() };\n    if is_negative {\n        num = num.value.neg().into();\n    }\n\n    let serialized = serde_json::to_string_pretty(&num).unwrap();\n    assert_eq!(serialized, format!(\"\\\"{}0x{}\\\"\", if is_negative { \"-\" } else { \"\" }, s));\n\n    assert_eq!(num, serde_json::from_str(&serialized).unwrap())\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "/// Casts a usize to an i16 if there is no overflow.\n/// Panics on overflow.\npub fn usize_as_i16(n: usize) -> i16 {\n    i16::try_from(n).unwrap_or_else(|_| panic!(\"Cast from usize to i16 failed: {n}\"))\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "#[cfg(test)]\n#[path = \"collection_arithmetics_test.rs\"]\nmod test;\n\nuse std::hash::Hash;\nuse std::ops::{Add, Sub};\n\nuse crate::ordered_hash_map::OrderedHashMap;\n\n/// A trait for types which have a zero value.\n///\n/// Functions may assume the following:\n/// * `x = x + zero() = zero() + x`\npub trait HasZero {\n    /// Returns the zero value for the type.\n    fn zero() -> Self;\n}\nimpl HasZero for i64 {\n    fn zero() -> Self {\n        0\n    }\n}\n\n/// Returns a map which contains the sum of the values from the given two maps, for each key.\n///\n/// If the key is missing from one of them, it is treated as zero.\npub fn add_maps<Key: Hash + Eq, Value: HasZero + Add<Output = Value> + Clone + Eq>(\n    lhs: OrderedHashMap<Key, Value>,\n    rhs: OrderedHashMap<Key, Value>,\n) -> OrderedHashMap<Key, Value> {\n    let mut res = lhs;\n    for (key, rhs_val) in rhs {\n        let lhs_val = res.get(&key).cloned().unwrap_or_else(Value::zero);\n        let new_val = lhs_val + rhs_val;\n        if new_val == Value::zero() {\n            res.swap_remove(&key);\n        } else {\n            res.insert(key, new_val);\n        }\n    }\n    res\n}\n\n/// Returns a map which contains the difference of the values from the given two maps, for each key.\n///\n/// If the key is missing from one of them, it is treated as zero.\npub fn sub_maps<Key: Hash + Eq, Value: HasZero + Sub<Output = Value> + Clone + Eq>(\n    lhs: OrderedHashMap<Key, Value>,\n    rhs: OrderedHashMap<Key, Value>,\n) -> OrderedHashMap<Key, Value> {\n    let mut res = lhs;\n    for (key, rhs_val) in rhs {\n        let lhs_val = res.get(&key).cloned().unwrap_or_else(Value::zero);\n        let new_val = lhs_val - rhs_val;\n        if new_val == Value::zero() {\n            res.swap_remove(&key);\n        } else {\n            res.insert(key, new_val);\n        }\n    }\n    res\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use test_log::test;\n\nuse crate::collection_arithmetics::{add_maps, sub_maps};\nuse crate::ordered_hash_map::OrderedHashMap;\n\n#[test]\nfn test_add_map_and_sub_map() {\n    let x = OrderedHashMap::<i64, i64>::from_iter([(10, 3), (20, 7), (30, 3), (40, 3)]);\n    let y = OrderedHashMap::<i64, i64>::from_iter([(0, 2), (10, 5), (30, -3), (40, 3)]);\n\n    assert_eq!(\n        add_maps(x.clone(), y.clone()),\n        OrderedHashMap::<i64, i64>::from_iter([(10, 8), (20, 7), (0, 2), (40, 6)])\n    );\n    assert_eq!(\n        sub_maps(x, y),\n        OrderedHashMap::<i64, i64>::from_iter([(10, -2), (20, 7), (30, 6), (0, -2)])\n    );\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "/// Macro to try to evaluate an expression as a pattern and extract its fields.\n/// # Examples:\n/// ```\n/// use cairo_lang_utils::try_extract_matches;\n///\n/// #[derive(Debug, Clone, Copy)]\n/// struct Point {\n///     x: u32,\n///     y: u32,\n/// }\n/// #[derive(Debug)]\n/// enum MyEnum {\n///     Point(Point),\n///     Value(u32),\n/// }\n/// let p = MyEnum::Point(Point { x: 3, y: 5 });\n/// if let Some(Point { x, y: _ }) = try_extract_matches!(p, MyEnum::Point) {\n///     assert_eq!(x, 3);\n/// }\n/// ```\n#[macro_export]\nmacro_rules! try_extract_matches {\n    ($e:expr, $variant:path) => {\n        if let $variant(x) = $e { Some(x) } else { None }\n    };\n}\n\n/// Macro to verify an expression matches a pattern and extract its fields.\n/// # Examples:\n/// ```\n/// use cairo_lang_utils::extract_matches;\n///\n/// #[derive(Debug, Clone, Copy)]\n/// struct Point {\n///     x: u32,\n///     y: u32,\n/// }\n/// #[derive(Debug)]\n/// enum MyEnum {\n///     Point(Point),\n///     Value(u32),\n/// }\n/// let p = MyEnum::Point(Point { x: 3, y: 5 });\n/// let Point { x, y: _ } = extract_matches!(p, MyEnum::Point);\n/// assert_eq!(x, 3);\n///\n/// // Would panic with 'assertion failed: `Point(Point { x: 3, y: 5 })` does not match `MyEnum::Value`:\n/// // Expected a point!'\n/// // let _value = extract_matches!(p, MyEnum::Value, \"Expected a point!\");\n/// ```\n#[macro_export]\nmacro_rules! extract_matches {\n    ($e:expr, $variant:path) => {\n        match $e {\n            $variant(x) => x,\n            ref e => {\n                panic!(\"Variant extract failed: `{:?}` is not of variant `{}`\", e, stringify!($variant))\n            }\n        }\n    };\n    ( $e:expr , $variant:path , $($arg:tt)* ) => {\n        match $e {\n            $variant(x) => x,\n            ref e => panic!(\"Variant extract failed: `{:?}` is not of variant `{}`: {}\",\n                e, stringify!($variant), format_args!($($arg)*))\n        }\n    };\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! A feedback-vertex-set is a set of vertices whose removal leaves a graph without cycles\n//! (<https://en.wikipedia.org/wiki/Feedback_vertex_set>).\n//! We use this algorithm to spot the relevant places for adding `withdraw_gas` statements in the\n//! resulting Sierra code - there should be a `withdraw_gas` call in every recursive call, or in\n//! other words, in any cycle in the function call graph.\n//! An efficient algorithm to find the minimum feedback-vertex-set in a directed graph is not known,\n//! so here we implement some straight-forward algorithm that guarantees to cover all the cycles in\n//! the graph, but doesn't necessarily produce the minimum size of such a set.\n\nuse std::collections::HashSet;\n\nuse super::graph_node::GraphNode;\nuse super::scc_graph_node::SccGraphNode;\nuse super::strongly_connected_components::ComputeScc;\n\n#[cfg(test)]\n#[path = \"feedback_set_test.rs\"]\nmod feedback_set_test;\n\n/// Context for the feedback-set algorithm.\nstruct FeedbackSetAlgoContext<Node: GraphNode> {\n    /// The accumulated feedback set so far in the process of the algorithm. In the end of the\n    /// algorithm, this is also the result.\n    pub feedback_set: HashSet<Node::NodeId>,\n    /// Nodes that are currently during the recursion call on them. That is - if one of these is\n    /// reached, it indicates it's in some cycle that was not \"resolved\" yet.\n    pub in_flight: HashSet<Node::NodeId>,\n}\nimpl<Node: GraphNode> FeedbackSetAlgoContext<Node> {\n    fn new() -> Self {\n        FeedbackSetAlgoContext {\n            feedback_set: HashSet::<Node::NodeId>::new(),\n            in_flight: HashSet::<Node::NodeId>::new(),\n        }\n    }\n}\n\n/// Calculates the feedback set of an SCC.\npub fn calc_feedback_set<Node: GraphNode + ComputeScc>(\n    node: &SccGraphNode<Node>,\n) -> HashSet<Node::NodeId> {\n    let mut ctx = FeedbackSetAlgoContext::<Node>::new();\n    calc_feedback_set_recursive(node, &mut ctx);\n    ctx.feedback_set\n}\n\nfn calc_feedback_set_recursive<Node: GraphNode + ComputeScc>(\n    node: &SccGraphNode<Node>,\n    ctx: &mut FeedbackSetAlgoContext<Node>,\n) {\n    let cur_node_id = node.get_id();\n    ctx.in_flight.insert(cur_node_id.clone());\n    for neighbor in node.get_neighbors() {\n        let neighbor_id = neighbor.get_id();\n        if ctx.feedback_set.contains(&neighbor_id) {\n            continue;\n        } else if ctx.in_flight.contains(&neighbor_id) {\n            ctx.feedback_set.insert(neighbor_id);\n        } else {\n            calc_feedback_set_recursive(&neighbor, ctx);\n        }\n\n        // `node` might have been added to the fset during this iteration of the loop. If so, no\n        // need to continue this loop.\n        if ctx.feedback_set.contains(&cur_node_id) {\n            break;\n        }\n    }\n    ctx.in_flight.remove(&cur_node_id);\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashSet;\n\nuse itertools::chain;\nuse test_case::test_case;\nuse test_log::test;\n\nuse crate::graph_algos::feedback_set::calc_feedback_set;\nuse crate::graph_algos::graph_node::GraphNode;\nuse crate::graph_algos::strongly_connected_components::{compute_scc, ComputeScc};\n\n// A node in the graph\n#[derive(PartialEq, Eq, Hash, Clone)]\nstruct IntegerNode {\n    id: usize,\n    /// The neighbors of each node.\n    graph: Vec<Vec<usize>>,\n}\nimpl GraphNode for IntegerNode {\n    type NodeId = usize;\n\n    fn get_neighbors(&self) -> Vec<Self> {\n        self.graph[self.id]\n            .iter()\n            .map(|neighbor_id| IntegerNode { id: *neighbor_id, graph: self.graph.clone() })\n            .collect()\n    }\n\n    fn get_id(&self) -> Self::NodeId {\n        self.id\n    }\n}\nimpl ComputeScc for IntegerNode {\n    fn compute_scc(&self) -> Vec<Self::NodeId> {\n        compute_scc(self)\n    }\n}\n\n#[test]\nfn test_list() {\n    // Nodes 0 to 9 have only one neighbor (i -> i + 1), and 10 is a leaf.\n    let mut graph: Vec<Vec<usize>> = (0..10).map(|id| vec![id + 1]).collect();\n    graph.push(vec![]);\n\n    let fset = HashSet::<usize>::from_iter(calc_feedback_set(&IntegerNode { id: 0, graph }.into()));\n    assert!(fset.is_empty());\n}\n\n#[test]\nfn test_cycle() {\n    // Each node has only one neighbor. i -> i + 1 for i = 0...8, and 9 -> 0.\n    let graph: Vec<Vec<usize>> = (0..10).map(|id| vec![(id + 1) % 10]).collect();\n\n    let fset = HashSet::<usize>::from_iter(calc_feedback_set(&IntegerNode { id: 0, graph }.into()));\n    assert_eq!(fset, HashSet::from([0]));\n}\n\n#[test]\nfn test_root_points_to_cycle() {\n    // 0 to 9 form a cycle.\n    let mut graph: Vec<Vec<usize>> = (0..10).map(|id| vec![(id + 1) % 10]).collect();\n    // And 10 (the root) has and edge to 0.\n    graph.push(/* 10: */ vec![0]);\n\n    // Note 10 is used as a root.\n    let fset = HashSet::<usize>::from_iter(calc_feedback_set(&IntegerNode { id: 0, graph }.into()));\n    assert_eq!(fset, HashSet::from([0]));\n}\n\n#[test]\nfn test_connected_cycles() {\n    // 0 to 4 form one cycle and 5 to 9 form another cycle.\n    let mut graph: Vec<Vec<usize>> =\n        chain!((0..5).map(|id| vec![(id + 1) % 5]), (0..5).map(|id| vec![5 + (id + 1) % 5]))\n            .collect();\n\n    // 4 is connected to 5.\n    graph[4].push(5);\n\n    // Make sure the cycle that's not in the SCC of the root is not covered.\n    let fset = HashSet::<usize>::from_iter(calc_feedback_set(&IntegerNode { id: 0, graph }.into()));\n    assert_eq!(fset, HashSet::from([0]));\n}\n\n#[test]\nfn test_mesh() {\n    // Each node has edges to all other nodes.\n    let graph = (0..5).map(|i| (0..5).filter(|j| *j != i).collect::<Vec<usize>>()).collect();\n\n    let fset = HashSet::<usize>::from_iter(calc_feedback_set(&IntegerNode { id: 0, graph }.into()));\n    assert_eq!(fset, HashSet::from_iter(0..4));\n}\n\n// The feedback set depends on the root node we start from (but it's stable given the same root).\n#[test_case(0, HashSet::from([0, 3]); \"root_0\")]\n#[test_case(3, HashSet::from([3]); \"root_3\")]\nfn test_tangent_cycles(root: usize, expected_fset: HashSet<usize>) {\n    // 0 to 3 form one cycle and 3 to 6 form another cycle. Note 3 is in both.\n    // 0 -> 1 -> 2 ->  3  -> 4 -> 6\n    // ^______________| ^_________|\n    let graph: Vec<Vec<usize>> = chain!(\n        (0..3).map(|id| vec![id + 1]),\n        // 3:\n        vec![vec![0, 4]].into_iter(),\n        (0..3).map(|id| vec![3 + (id + 2) % 4])\n    )\n    .collect();\n\n    let fset =\n        HashSet::<usize>::from_iter(calc_feedback_set(&IntegerNode { id: root, graph }.into()));\n    assert_eq!(fset, expected_fset);\n}\n\n// Test a graph with multiple cycles.\n#[test_case(0, HashSet::from([0]); \"root_0\")]\n#[test_case(1, HashSet::from([1, 2]); \"root_1\")]\n#[test_case(2, HashSet::from([2, 3]); \"root_2\")]\n#[test_case(3, HashSet::from([3]); \"root_3\")]\nfn test_multiple_cycles(root: usize, expected_fset: HashSet<usize>) {\n    let graph: Vec<Vec<usize>> = chain!(\n        // 0:\n        vec![vec![1, 2]].into_iter(),\n        // 1:\n        vec![vec![2, 3]].into_iter(),\n        // 2:\n        vec![vec![3]].into_iter(),\n        // 3:\n        vec![vec![0]].into_iter(),\n    )\n    .collect();\n\n    let fset =\n        HashSet::<usize>::from_iter(calc_feedback_set(&IntegerNode { id: root, graph }.into()));\n    assert_eq!(fset, expected_fset);\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use core::hash::Hash;\n\n/// A trait for a node in a graph. Note that a GraphNode has to be able to provide its neighbors\n/// by itself, without additional information.\npub trait GraphNode: Sized + Clone {\n    /// The type used to identify the nodes in the graph.\n    type NodeId: PartialEq + Eq + Hash + Clone;\n\n    /// Returns a list of the node's neighbors.\n    /// Must be stable for the SCC result to be stable. i.e. if the output for a node here doesn't\n    /// change between different runs, the computed SCC of the node is guaranteed to also not\n    /// change.\n    fn get_neighbors(&self) -> Vec<Self>;\n\n    /// Gets the node's ID.\n    fn get_id(&self) -> Self::NodeId;\n\n    /// Helper function to get the neighbors of the node, given its SCC. Default-implemented and\n    /// thus can be used in simple implementations of get_neighbors_in_scc.\n    fn get_neighbors_in_given_scc(&self, scc: Vec<Self::NodeId>) -> Vec<Self> {\n        let mut neighbors_in_scc = Vec::new();\n        for neighbor in self.get_neighbors() {\n            if scc.contains(&neighbor.get_id()) {\n                neighbors_in_scc.push(neighbor);\n            }\n        }\n        neighbors_in_scc\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "pub mod feedback_set;\npub mod graph_node;\npub mod scc_graph_node;\npub mod strongly_connected_components;\n",
    "metadata": {}
  },
  {
    "pageContent": "use super::graph_node::GraphNode;\nuse super::strongly_connected_components::ComputeScc;\n\n/// A node whose neighbors are only the subset of its neighbors in the full graph, which are also in\n/// the same SCC (strongly-connected-component) with it.\n#[derive(Clone)]\npub struct SccGraphNode<Node: GraphNode>(Node);\nimpl<Node: GraphNode + ComputeScc> GraphNode for SccGraphNode<Node> {\n    type NodeId = Node::NodeId;\n\n    fn get_neighbors(&self) -> Vec<Self> {\n        let scc = self.0.compute_scc();\n        self.0.get_neighbors_in_given_scc(scc).into_iter().map(SccGraphNode::<Node>).collect()\n    }\n\n    fn get_id(&self) -> Self::NodeId {\n        self.0.get_id()\n    }\n}\nimpl<Node: GraphNode> From<Node> for SccGraphNode<Node> {\n    fn from(value: Node) -> Self {\n        SccGraphNode::<Node>(value)\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Logic for computing the strongly connected component of a node in a graph.\n\nuse core::hash::Hash;\nuse std::collections::HashMap;\n\nuse super::graph_node::GraphNode;\n\n#[cfg(test)]\n#[path = \"strongly_connected_components_test.rs\"]\nmod strongly_connected_components_test;\n\n/// A trait for a type that can compute its strongly-connected-component.\npub trait ComputeScc\nwhere\n    Self: GraphNode,\n{\n    fn compute_scc(&self) -> Vec<Self::NodeId>;\n}\n\n/// A wrapper node to a GraphNode, to be used in the SCC algorithm. Contains the GraphNode\n/// additional state for the algorithm.\n#[derive(Default, PartialEq, Eq, Hash, Clone)]\nstruct SccAlgoNode<Node: GraphNode> {\n    /// The wrapped GraphNode\n    node: Node,\n    /// The index of the node in the algorithm. The smaller the index, the earlier the node was\n    /// reached.\n    index: u32,\n    /// The smallest index of a node that's reachable from this node (so far).\n    lowlink: u32,\n    /// Whether the node is currently on the DFS stack.\n    on_stack: bool,\n}\n\n/// The context of the SCC algorithm.\nstruct SccAlgoContext<Node: GraphNode> {\n    /// The next index to allocate to a first-seen node.\n    next_index: u32,\n    /// The stack of the nodes in the DFS.\n    stack: Vec<Node::NodeId>,\n    /// All visited nodes. If a graph node is not in the map, it wasn't yet visited.\n    known_nodes: HashMap<Node::NodeId, SccAlgoNode<Node>>,\n    /// The ID of the node we want to find the SCC of.\n    target_node_id: Node::NodeId,\n    /// The SCC of the `target_node_id`. Populated only at the end of the algorithm.\n    result: Vec<Node::NodeId>,\n}\nimpl<Node: GraphNode> SccAlgoContext<Node> {\n    fn new(target_node_id: Node::NodeId) -> Self {\n        SccAlgoContext::<Node> {\n            next_index: 0,\n            stack: Vec::new(),\n            known_nodes: HashMap::new(),\n            target_node_id,\n            result: Vec::new(),\n        }\n    }\n}\n\n/// Computes the SCC (Strongly Connected Component) of the given node in its graph.\npub fn compute_scc<Node: GraphNode>(root: &Node) -> Vec<Node::NodeId> {\n    let mut ctx = SccAlgoContext::new(root.get_id());\n    compute_scc_recursive(&mut ctx, root);\n    ctx.result\n}\n\n/// The recursive call to compute the SCC of a given node.\nfn compute_scc_recursive<Node: GraphNode>(ctx: &mut SccAlgoContext<Node>, current_node: &Node) {\n    let mut current_wrapper_node = SccAlgoNode {\n        node: current_node.clone(),\n        index: ctx.next_index,\n        lowlink: ctx.next_index,\n        on_stack: true,\n    };\n    let current_node_id = current_node.get_id();\n    ctx.known_nodes.insert(current_node_id.clone(), current_wrapper_node.clone());\n    ctx.next_index += 1;\n    ctx.stack.push(current_node_id.clone());\n\n    for neighbor in current_node.get_neighbors() {\n        let neighbor_id = neighbor.get_id();\n        match ctx.known_nodes.get(&neighbor_id) {\n            None => {\n                // neighbor was not visited yet. Visit it and maybe apply its lowlink to root.\n                compute_scc_recursive(ctx, &neighbor);\n                // Now neighbor should be in known_nodes.\n                current_wrapper_node.lowlink = std::cmp::min(\n                    current_wrapper_node.lowlink,\n                    ctx.known_nodes[&neighbor_id].lowlink,\n                );\n            }\n            Some(neighbor_node) => {\n                if ctx.known_nodes[&neighbor_id].on_stack {\n                    // This is a back edge, meaning neighbor is in current_node's SCC.\n                    current_wrapper_node.lowlink =\n                        std::cmp::min(current_wrapper_node.lowlink, neighbor_node.index);\n                } else {\n                    // If neighbor is known but not on stack, it's in a concluded dropped SCC.\n                    // Ignore it.\n                    continue;\n                }\n            }\n        };\n\n        // Update current_node in ctx.known_nodes.\n        ctx.known_nodes.insert(current_node_id.clone(), current_wrapper_node.clone());\n    }\n\n    if current_wrapper_node.lowlink != current_wrapper_node.index {\n        // `current_node` is not a root of an SCC. We only conclude SCCs when we reach their roots.\n        return;\n    }\n\n    // `current_node` is a root of an SCC. Conclude this SCC.\n    // Push the nodes from the latest to earliest in the call hierarchy, so that the reverse of the\n    // SCC vector would form a valid path on the graph.\n    let mut scc = Vec::new();\n    while let Some(other_node_id) = ctx.stack.pop() {\n        let other_node = ctx.known_nodes.get_mut(&other_node_id).unwrap();\n        other_node.on_stack = false;\n        scc.push(other_node_id.clone());\n\n        // Stop once the popped node is the current node which is the root on the SCC.\n        if other_node_id == current_node_id {\n            break;\n        }\n    }\n\n    // If this SCC is the one we are looking for, update it in ctx. Otherwise, throw this\n    // SCC away.\n    if current_node_id == ctx.target_node_id {\n        ctx.result = scc;\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::HashSet;\n\nuse itertools::chain;\nuse test_case::test_case;\nuse test_log::test;\n\nuse super::GraphNode;\nuse crate::graph_algos::strongly_connected_components::compute_scc;\n\n#[derive(PartialEq, Eq, Hash, Clone)]\nstruct IntegerNode {\n    id: usize,\n    /// The neighbors of each node.\n    graph: Vec<Vec<usize>>,\n}\nimpl GraphNode for IntegerNode {\n    type NodeId = usize;\n\n    fn get_neighbors(&self) -> Vec<Self> {\n        self.graph[self.id]\n            .iter()\n            .map(|neighbor_id| IntegerNode { id: *neighbor_id, graph: self.graph.clone() })\n            .collect()\n    }\n\n    fn get_id(&self) -> Self::NodeId {\n        self.id\n    }\n}\n\n#[test]\nfn test_short_list() {\n    let graph = vec![/* 0: */ vec![1], /* 1: */ vec![]];\n\n    let scc = HashSet::<usize>::from_iter(compute_scc(&IntegerNode { id: 0, graph }));\n    assert_eq!(scc, HashSet::from([0]));\n}\n\n#[test]\nfn test_list() {\n    // Nodes 0 to 9 have only one neighbor (i -> i + 1), and 10 is a leaf.\n    let mut graph: Vec<Vec<usize>> = (0..10).map(|id| vec![id + 1]).collect();\n    graph.push(vec![]);\n\n    let scc = HashSet::<usize>::from_iter(compute_scc(&IntegerNode { id: 0, graph }));\n    assert_eq!(scc, HashSet::from([0]));\n}\n\n#[test]\nfn test_cycle() {\n    // Each node has only one neighbor. i -> i + 1 for i = 0...8, and 9 -> 0.\n    let graph: Vec<Vec<usize>> = (0..10).map(|id| vec![(id + 1) % 10]).collect();\n\n    let scc = HashSet::<usize>::from_iter(compute_scc(&IntegerNode { id: 0, graph }));\n    assert_eq!(scc, HashSet::from_iter(0..10));\n}\n\n#[test]\nfn test_mesh() {\n    // Each node has edges to all other nodes.\n    let graph = (0..5).map(|i| (0..5).filter(|j| *j != i).collect::<Vec<usize>>()).collect();\n\n    let scc = HashSet::<usize>::from_iter(compute_scc(&IntegerNode { id: 0, graph }));\n    assert_eq!(scc, HashSet::from_iter(0..5));\n}\n\n#[test]\nfn test_list_with_back_edges() {\n    let graph = vec![\n        // 0:\n        vec![1],\n        // 1:\n        vec![2],\n        // 2:\n        vec![0, 3],\n        // 3:\n        vec![1],\n    ];\n\n    let scc = HashSet::<usize>::from_iter(compute_scc(&IntegerNode { id: 0, graph }));\n    assert_eq!(scc, HashSet::from_iter(0..4));\n}\n\n#[test]\nfn test_root_points_to_cycle() {\n    // 0 to 9 form a cycle.\n    let mut graph: Vec<Vec<usize>> = (0..10).map(|id| vec![(id + 1) % 10]).collect();\n    // And 10 (the root) has and edge to 0.\n    graph.push(/* 10: */ vec![0]);\n\n    // Note 10 is used as a root.\n    let scc = HashSet::<usize>::from_iter(compute_scc(&IntegerNode { id: 10, graph }));\n    assert_eq!(scc, HashSet::from([10]));\n}\n\n#[test_case(true; \"root_in_first_cycle\")]\n#[test_case(false; \"root_in_second_cycle\")]\nfn test_connected_cycles(root_in_first_cycle: bool) {\n    // 0 to 4 form one cycle and 5 to 9 form another cycle.\n    let mut graph: Vec<Vec<usize>> =\n        chain!((0..5).map(|id| vec![(id + 1) % 5]), (0..5).map(|id| vec![5 + (id + 1) % 5]))\n            .collect();\n\n    // Add an edge between 4 and 5 to connect the cycles. Determine the direction according to\n    // root_in_first_cycle.\n    if root_in_first_cycle {\n        graph[4].push(5);\n    } else {\n        graph[5].push(4);\n    }\n\n    let scc = HashSet::<usize>::from_iter(compute_scc(&IntegerNode { id: 0, graph }));\n    assert_eq!(scc, HashSet::from_iter(0..5));\n}\n\n#[test]\nfn test_tangent_cycles() {\n    // 0 to 3 form one cycle and 3 to 6 form another cycle. Note 3 is in both.\n    // 0 -> 1 -> 2 ->  3  -> 4 -> 6\n    // ^______________| ^_________|\n    let graph: Vec<Vec<usize>> = chain!(\n        (0..3).map(|id| vec![id + 1]),\n        // 3:\n        vec![vec![0, 4]].into_iter(),\n        (0..3).map(|id| vec![3 + (id + 2) % 4])\n    )\n    .collect();\n\n    let scc = HashSet::<usize>::from_iter(compute_scc(&IntegerNode { id: 0, graph }));\n    assert_eq!(scc, HashSet::from_iter(0..7));\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "//! Cairo utilities.\nuse std::fmt;\n\npub mod bigint;\npub mod casts;\npub mod collection_arithmetics;\npub mod extract_matches;\npub mod graph_algos;\npub mod logging;\npub mod ordered_hash_map;\npub mod ordered_hash_set;\npub mod unordered_hash_map;\npub mod unordered_hash_set;\n\n/// Similar to From / TryFrom, but returns an option.\npub trait OptionFrom<T>\nwhere\n    Self: Sized,\n{\n    fn option_from(other: T) -> Option<Self>;\n}\n\npub fn write_comma_separated<Iter: IntoIterator<Item = V>, V: std::fmt::Display>(\n    f: &mut fmt::Formatter<'_>,\n    values: Iter,\n) -> fmt::Result {\n    let mut iter = values.into_iter();\n    if let Some(value) = iter.next() {\n        write!(f, \"{value}\")?;\n    }\n    for value in iter {\n        write!(f, \", {value}\")?;\n    }\n    Ok(())\n}\n\n/// Helper operations on `Option<T>`.\npub trait OptionHelper {\n    fn on_none<F: FnOnce()>(self, f: F) -> Self;\n}\nimpl<T> OptionHelper for Option<T> {\n    fn on_none<F: FnOnce()>(self, f: F) -> Self {\n        if self.is_none() {\n            f();\n        }\n        self\n    }\n}\n\n/// Helper operations on `Option<T>`.\npub trait ResultHelper<E> {\n    fn on_err<F: FnOnce(&E)>(self, f: F) -> Self;\n}\nimpl<T, E> ResultHelper<E> for Result<T, E> {\n    fn on_err<F: FnOnce(&E)>(self, f: F) -> Self {\n        match &self {\n            Ok(_) => self,\n            Err(e) => {\n                f(e);\n                self\n            }\n        }\n    }\n}\n\n/// Borrows a mutable reference as Box for the lifespan of this function. Runs the given closure\n/// with the boxed value as a parameter.\n/// The closure is expected to return a boxed value, whose changes will be reflected on the mutable\n/// reference.\n/// Example:\n/// ```\n/// use cairo_lang_utils::borrow_as_box;\n/// let mut x = 5;\n/// borrow_as_box(&mut x, |mut x: Box<usize>| {\n///     *x += 1;\n///     ((), x)\n/// });\n/// assert_eq!(x, 6);\n/// ```\npub fn borrow_as_box<T: Default, R, F: FnOnce(Box<T>) -> (R, Box<T>)>(ptr: &mut T, f: F) -> R {\n    // TODO(spapini): Consider replacing take with something the leaves the memory dangling, instead\n    // of filling with default().\n    let (res, boxed) = f(Box::new(std::mem::take(ptr)));\n    *ptr = *boxed;\n    res\n}\n\n// Defines a short id struct for use with salsa interning.\n// Interning is the process of representing a value as an id in a table.\n// We usually denote the value type as \"long id\", and the id type as \"short id\" or just \"id\".\n// Example:\n//   A function's long id may be the module in which it is defined and its name. The function is\n//   assigned a sequential integer (salsa::InternId) which will be its short id. Salsa will hold a\n//   table to translate between the two representations. Note that a long id of an entity will\n//   usually include the short id of the entity's parent.\n#[macro_export]\nmacro_rules! define_short_id {\n    ($short_id:ident, $long_id:ident, $db:ident, $lookup:ident) => {\n        #[derive(Copy, Clone, Debug, Hash, PartialEq, Eq)]\n        pub struct $short_id(salsa::InternId);\n        impl salsa::InternKey for $short_id {\n            fn from_intern_id(salsa_id: salsa::InternId) -> Self {\n                Self(salsa_id)\n            }\n\n            fn as_intern_id(&self) -> salsa::InternId {\n                self.0\n            }\n        }\n        // Impl transparent DebugWithDb.\n        impl<T: ?Sized + cairo_lang_utils::Upcast<dyn $db + 'static>>\n            cairo_lang_debug::DebugWithDb<T> for $short_id\n        {\n            fn fmt(&self, f: &mut std::fmt::Formatter<'_>, db: &T) -> std::fmt::Result {\n                use std::fmt::Debug;\n\n                use cairo_lang_debug::helper::Fallback;\n                let db = db.upcast();\n                cairo_lang_debug::helper::HelperDebug::<$long_id, dyn $db>::helper_debug(\n                    &db.$lookup(*self),\n                    db,\n                )\n                .fmt(f)\n            }\n        }\n    };\n}\n\npub trait Upcast<T: ?Sized> {\n    fn upcast(&self) -> &T;\n}\n\nimpl<T: ?Sized> Upcast<T> for T {\n    fn upcast(&self) -> &T {\n        self\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::io::Write;\n\nuse log::LevelFilter;\n\n/// Initializes env_logger.\n/// The format is:\n/// `<level>  /path/to/file:<line_number>  <time>  <log_message>`\npub fn init_logging(log_level: LevelFilter) {\n    env_logger::Builder::new()\n        .filter_level(log_level)\n        .format(|buf, record| {\n            let location =\n                format!(\"{}:{}\", record.file().unwrap_or(\"unknown\"), record.line().unwrap_or(0),);\n            writeln!(\n                buf,\n                \"{:7}{:45} {} {}\",\n                record.level(),\n                location,\n                chrono::Local::now().format(\"%H:%M:%S\"),\n                record.args()\n            )\n        })\n        .filter(Some(\"salsa\"), LevelFilter::Off)\n        .init();\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::hash::Hash;\nuse std::ops::{Index, IndexMut};\n\nuse indexmap::{Equivalent, IndexMap};\nuse itertools::zip_eq;\n\n#[derive(Clone, Debug)]\npub struct OrderedHashMap<Key: Hash + Eq, Value>(IndexMap<Key, Value>);\n\nimpl<Key: Hash + Eq, Value> OrderedHashMap<Key, Value> {\n    /// Returns a reference to the value stored for key, if it is present, else None.\n    ///\n    /// Computes in O(1) time (average).\n    pub fn get<Q: ?Sized + Hash + Equivalent<Key>>(&self, key: &Q) -> Option<&Value> {\n        self.0.get(key)\n    }\n\n    /// Returns a mutable reference to the value stored for key, if it is present, else None.\n    ///\n    /// Computes in O(1) time (average).\n    pub fn get_mut<Q: ?Sized + Hash + Equivalent<Key>>(&mut self, key: &Q) -> Option<&mut Value> {\n        self.0.get_mut(key)\n    }\n\n    /// Gets the given keys corresponding entry in the map for insertion and/or in-place\n    /// manipulation.\n    ///\n    /// Computes in O(1) time (amortized average).\n    pub fn entry(&mut self, key: Key) -> indexmap::map::Entry<'_, Key, Value> {\n        self.0.entry(key)\n    }\n\n    /// Returns an iterator over the key-value pairs of the map, in their order.\n    pub fn iter(&self) -> indexmap::map::Iter<'_, Key, Value> {\n        self.0.iter()\n    }\n\n    /// Returns a mutable iterator over the key-value pairs of the map, in their order.\n    pub fn iter_mut(&mut self) -> indexmap::map::IterMut<'_, Key, Value> {\n        self.0.iter_mut()\n    }\n\n    /// Returns an iterator over the keys of the map, in their order.\n    pub fn keys(&self) -> indexmap::map::Keys<'_, Key, Value> {\n        self.0.keys()\n    }\n\n    /// Returns a consuming iterator over the keys of the map, in their order.\n    pub fn into_keys(self) -> indexmap::map::IntoKeys<Key, Value> {\n        self.0.into_keys()\n    }\n\n    /// Returns an iterator over the values of the map, in their order.\n    pub fn values(&self) -> indexmap::map::Values<'_, Key, Value> {\n        self.0.values()\n    }\n\n    /// Insert a key-value pair in the map.\n    ///\n    /// If an equivalent key already exists in the map: the key remains and retains in its place in\n    /// the order, its corresponding value is updated with value and the older value is returned\n    /// inside Some(_).\n    ///\n    /// If no equivalent key existed in the map: the new key-value pair is inserted, last in order,\n    /// and None is returned.\n    ///\n    /// Computes in O(1) time (amortized average).\n    ///\n    /// See also entry if you you want to insert or modify or if you need to get the index of the\n    /// corresponding key-value pair.\n    pub fn insert(&mut self, key: Key, value: Value) -> Option<Value> {\n        self.0.insert(key, value)\n    }\n\n    /// Returns true if an equivalent to key exists in the map.\n    pub fn contains_key<Q: ?Sized + Hash + Equivalent<Key>>(&self, key: &Q) -> bool {\n        self.0.contains_key(key)\n    }\n\n    /// Returns the number of key-value pairs in the map.\n    pub fn len(&self) -> usize {\n        self.0.len()\n    }\n\n    /// Returns true if the map contains no elements.\n    pub fn is_empty(&self) -> bool {\n        self.0.is_empty()\n    }\n\n    /// Removes all the entries for the map.\n    pub fn clear(&mut self) {\n        self.0.clear()\n    }\n\n    /// Removes the entry for the given key, preserving the order of entries.\n    ///\n    /// Returns the value associated with the key (if present).\n    pub fn shift_remove<Q: ?Sized + Hash + Equivalent<Key>>(&mut self, key: &Q) -> Option<Value> {\n        self.0.shift_remove(key)\n    }\n\n    /// Removes the entry for the given key by swapping it with the last element.\n    /// Thus the order of elements is not preserved, but the resulting order is still deterministic.\n    ///\n    /// Returns the value associated with the key (if present).\n    pub fn swap_remove<Q: ?Sized + Hash + Equivalent<Key>>(&mut self, key: &Q) -> Option<Value> {\n        self.0.swap_remove(key)\n    }\n}\n\nimpl<Key: Hash + Eq, Value> IntoIterator for OrderedHashMap<Key, Value> {\n    type Item = (Key, Value);\n    type IntoIter = indexmap::map::IntoIter<Key, Value>;\n    fn into_iter(self) -> Self::IntoIter {\n        let OrderedHashMap(inner) = self;\n        inner.into_iter()\n    }\n}\n\nimpl<Key: Hash + Eq, IndexType: Into<Key>, Value> Index<IndexType> for OrderedHashMap<Key, Value> {\n    type Output = Value;\n\n    fn index(&self, index: IndexType) -> &Self::Output {\n        &self.0[&index.into()]\n    }\n}\n\nimpl<Key: Hash + Eq, IndexType: Into<Key>, Value> IndexMut<IndexType>\n    for OrderedHashMap<Key, Value>\n{\n    fn index_mut(&mut self, index: IndexType) -> &mut Value {\n        self.0.index_mut(&index.into())\n    }\n}\n\nimpl<Key: Hash + Eq, Value: Eq> PartialEq for OrderedHashMap<Key, Value> {\n    fn eq(&self, other: &Self) -> bool {\n        if self.0.len() != other.0.len() {\n            return false;\n        };\n\n        zip_eq(self.0.iter(), other.0.iter()).all(|(a, b)| a == b)\n    }\n}\n\nimpl<Key: Hash + Eq, Value: Eq> Eq for OrderedHashMap<Key, Value> {\n    fn assert_receiver_is_total_eq(&self) {}\n}\n\nimpl<Key: Hash + Eq, Value> Default for OrderedHashMap<Key, Value> {\n    fn default() -> Self {\n        Self(Default::default())\n    }\n}\n\nimpl<Key: Hash + Eq, Value> FromIterator<(Key, Value)> for OrderedHashMap<Key, Value> {\n    fn from_iter<T: IntoIterator<Item = (Key, Value)>>(iter: T) -> Self {\n        Self(iter.into_iter().collect())\n    }\n}\n\nimpl<Key: Hash + Eq, Value, const N: usize> From<[(Key, Value); N]> for OrderedHashMap<Key, Value> {\n    fn from(init_map: [(Key, Value); N]) -> Self {\n        Self(init_map.into())\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::collections::hash_map::RandomState;\nuse std::hash::Hash;\nuse std::ops::Sub;\n\nuse indexmap::{Equivalent, IndexSet};\nuse itertools::zip_eq;\n\n#[derive(Clone, Debug)]\npub struct OrderedHashSet<Key: Hash + Eq, S = RandomState>(IndexSet<Key, S>);\n\npub type Iter<'a, Key> = indexmap::set::Iter<'a, Key>;\n\nimpl<Key: Hash + Eq> OrderedHashSet<Key> {\n    /// Returns an iterator over the values of the set, in their order.\n    pub fn iter(&self) -> Iter<'_, Key> {\n        self.0.iter()\n    }\n\n    /// Inserts the value into the set.\n    ///\n    /// If an equivalent item already exists in the set, returns `false`. Otherwise, returns `true`.\n    pub fn insert(&mut self, key: Key) -> bool {\n        self.0.insert(key)\n    }\n\n    /// Extends the set with the content of the given iterator.\n    pub fn extend<I: IntoIterator<Item = Key>>(&mut self, iter: I) {\n        self.0.extend(iter)\n    }\n\n    /// Returns true if an equivalent to value exists in the set.\n    pub fn contains<Q: ?Sized + Hash + Equivalent<Key>>(&self, value: &Q) -> bool {\n        self.0.contains(value)\n    }\n\n    /// Returns the number of elements in the set.\n    pub fn len(&self) -> usize {\n        self.0.len()\n    }\n\n    /// Returns true if the set contains no elements.\n    pub fn is_empty(&self) -> bool {\n        self.0.is_empty()\n    }\n\n    /// Remove all elements in the set, while preserving its capacity.\n    ///\n    /// Computes in O(n) time.\n    pub fn clear(&mut self) {\n        self.0.clear()\n    }\n\n    /// Removes the value from the set, preserving the order of elements.\n    ///\n    /// Returns true if the value was present in the set.\n    pub fn shift_remove<Q: ?Sized + Hash + Equivalent<Key>>(&mut self, value: &Q) -> bool {\n        self.0.shift_remove(value)\n    }\n\n    /// Removes the value by swapping it with the last element, thus the order of elements is not\n    /// preserved, but the resulting order is still deterministic.\n    ///\n    /// Returns true if the value was present in the set.\n    pub fn swap_remove<Q: ?Sized + Hash + Equivalent<Key>>(&mut self, value: &Q) -> bool {\n        self.0.swap_remove(value)\n    }\n\n    pub fn difference<'a, S2>(\n        &'a self,\n        other: &'a OrderedHashSet<Key, S2>,\n    ) -> indexmap::set::Difference<'a, Key, S2>\n    where\n        S2: std::hash::BuildHasher,\n    {\n        self.0.difference(&other.0)\n    }\n}\n\nimpl<Key: Hash + Eq> IntoIterator for OrderedHashSet<Key> {\n    type Item = Key;\n    type IntoIter = <IndexSet<Key> as IntoIterator>::IntoIter;\n\n    fn into_iter(self) -> Self::IntoIter {\n        self.0.into_iter()\n    }\n}\n\nimpl<Key: Hash + Eq> PartialEq for OrderedHashSet<Key> {\n    fn eq(&self, other: &Self) -> bool {\n        if self.0.len() != other.0.len() {\n            return false;\n        };\n\n        zip_eq(self.0.iter(), other.0.iter()).all(|(a, b)| a == b)\n    }\n}\n\nimpl<Key: Hash + Eq> Eq for OrderedHashSet<Key> {\n    fn assert_receiver_is_total_eq(&self) {}\n}\n\nimpl<Key: Hash + Eq> Default for OrderedHashSet<Key> {\n    fn default() -> Self {\n        Self(Default::default())\n    }\n}\n\nimpl<Key: Hash + Eq> FromIterator<Key> for OrderedHashSet<Key> {\n    fn from_iter<T: IntoIterator<Item = Key>>(iter: T) -> Self {\n        Self(iter.into_iter().collect())\n    }\n}\n\nimpl<'a, Key: Hash + Eq + Clone> Sub<&'a OrderedHashSet<Key>> for &'a OrderedHashSet<Key> {\n    type Output = OrderedHashSet<Key>;\n\n    fn sub(self, rhs: Self) -> Self::Output {\n        OrderedHashSet::<Key>(&self.0 - &rhs.0)\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::borrow::Borrow;\nuse std::collections::{hash_map, HashMap};\nuse std::hash::Hash;\nuse std::ops::Index;\n\n/// A hash map that does not care about the order of insertion.\n/// In particular, it does not support iterating, in order to guarantee deterministic compilation.\n/// For an iterable version see [OrderedHashMap](crate::ordered_hash_map::OrderedHashMap).\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct UnorderedHashMap<Key: Hash + Eq, Value>(HashMap<Key, Value>);\n\nimpl<Key: Hash + Eq, Value> UnorderedHashMap<Key, Value> {\n    /// Returns a reference to the value corresponding to the key.\n    ///\n    /// The key may be any borrowed form of the map's key type, but `Hash` and `Eq` on the borrowed\n    /// form must match those for the key type.\n    pub fn get<Q: ?Sized>(&self, key: &Q) -> Option<&Value>\n    where\n        Key: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        self.0.get(key)\n    }\n\n    /// Inserts a key-value pair into the map.\n    ///\n    /// If the map did not have this key present, None is returned.\n    ///\n    /// If the map did have this key present, the value is updated, and the old value is returned.\n    /// The key is not updated, though; this matters for types that can be == without being\n    /// identical.\n    pub fn insert(&mut self, key: Key, value: Value) -> Option<Value> {\n        self.0.insert(key, value)\n    }\n\n    /// Removes a key from the map, returning the value at the key if the key was previously in the\n    /// map.\n    ///\n    /// The key may be any borrowed form of the map's key type, but Hash and Eq on the borrowed form\n    /// must match those for the key type.\n    pub fn remove<Q: ?Sized>(&mut self, key: &Q) -> Option<Value>\n    where\n        Key: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        self.0.remove(key)\n    }\n\n    /// Gets the given key's corresponding entry in the map for in-place manipulation.\n    pub fn entry(&mut self, key: Key) -> hash_map::Entry<'_, Key, Value> {\n        self.0.entry(key)\n    }\n\n    /// Returns true if the map contains a value for the specified key.\n    pub fn contains_key<Q>(&self, key: &Q) -> bool\n    where\n        Q: ?Sized,\n        Key: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        self.0.contains_key(key)\n    }\n\n    /// Returns the number of elements in the map.\n    pub fn len(&self) -> usize {\n        self.0.len()\n    }\n\n    /// Returns true if the map contains no elements.\n    pub fn is_empty(&self) -> bool {\n        self.0.is_empty()\n    }\n}\n\nimpl<Key: Hash + Eq, IndexType: Into<Key>, Value> Index<IndexType>\n    for UnorderedHashMap<Key, Value>\n{\n    type Output = Value;\n\n    fn index(&self, index: IndexType) -> &Self::Output {\n        &self.0[&index.into()]\n    }\n}\n\nimpl<Key: Hash + Eq, Value> Default for UnorderedHashMap<Key, Value> {\n    fn default() -> Self {\n        Self(Default::default())\n    }\n}\n\nimpl<Key: Hash + Eq, Value> FromIterator<(Key, Value)> for UnorderedHashMap<Key, Value> {\n    fn from_iter<T: IntoIterator<Item = (Key, Value)>>(iter: T) -> Self {\n        Self(iter.into_iter().collect())\n    }\n}\n",
    "metadata": {}
  },
  {
    "pageContent": "use std::borrow::Borrow;\nuse std::collections::HashSet;\nuse std::hash::Hash;\nuse std::ops::Sub;\n\n/// A hash set that does not care about the order of insertion.\n/// In particular, it does not support iterating, in order to guarantee deterministic compilation.\n/// For an iterable version see [OrderedHashSet](crate::ordered_hash_set::OrderedHashSet).\n#[derive(Clone, Debug, PartialEq, Eq)]\npub struct UnorderedHashSet<Key: Hash + Eq>(HashSet<Key>);\n\nimpl<Key: Hash + Eq> UnorderedHashSet<Key> {\n    /// Inserts the value into the set.\n    ///\n    /// If an equivalent item already exists in the set, returns `false`. Otherwise, returns `true`.\n    pub fn insert(&mut self, key: Key) -> bool {\n        self.0.insert(key)\n    }\n\n    /// Extends the set with the content of the given iterator.\n    pub fn extend<I: IntoIterator<Item = Key>>(&mut self, iter: I) {\n        self.0.extend(iter)\n    }\n\n    /// Extends the set with the content of another set.\n    pub fn extend_unordered(&mut self, other: Self) {\n        self.0.extend(other.0)\n    }\n\n    /// Returns true if an equivalent to value exists in the set.\n    pub fn contains<Q: ?Sized + Hash + Eq>(&self, value: &Q) -> bool\n    where\n        Key: Borrow<Q>,\n    {\n        self.0.contains(value)\n    }\n\n    /// Returns the number of elements in the set.\n    pub fn len(&self) -> usize {\n        self.0.len()\n    }\n\n    /// Returns true if the set contains no elements.\n    pub fn is_empty(&self) -> bool {\n        self.0.is_empty()\n    }\n\n    /// Clears the set, removing all values.\n    pub fn clear(&mut self) {\n        self.0.clear()\n    }\n}\n\nimpl<Key: Hash + Eq> Default for UnorderedHashSet<Key> {\n    fn default() -> Self {\n        Self(Default::default())\n    }\n}\n\nimpl<Key: Hash + Eq> FromIterator<Key> for UnorderedHashSet<Key> {\n    fn from_iter<T: IntoIterator<Item = Key>>(iter: T) -> Self {\n        Self(iter.into_iter().collect())\n    }\n}\n\nimpl<'a, Key: Hash + Eq + Clone> Sub<&'a UnorderedHashSet<Key>> for &'a UnorderedHashSet<Key> {\n    type Output = UnorderedHashSet<Key>;\n\n    fn sub(self, rhs: Self) -> Self::Output {\n        UnorderedHashSet::<Key>(&self.0 - &rhs.0)\n    }\n}\n",
    "metadata": {}
  }
]